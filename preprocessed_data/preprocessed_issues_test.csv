repo,issue_text,label
facebook/react,"bug : [ <number> . <number> - canary ] rendertostring hoists some tags to top ( working in <number> ) < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> . <number> - canary - 4 9 3 f72b0a - <number> # # steps to reproduce <number> . run following code . ` ` ` js import * as reactdomserver from "" react - dom / server "" ; const element = ( <html> <head> {/* meta and title are hoisted */} < meta charset = "" utf - <number> "" / > <title> title </title> {/* the script tag is not hoisted */} < script src = "" foo "" > </script> {/* but this is hoisted */} < script src = "" foo "" async > </script> </head> </html> ); console . log ( reactdomserver . rendertostring ( element ) ); ` ` ` < ! - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : <url> < ! - - please provide a codesandbox ( <url> a link to a repository on github , or provide a minimal code example that reproduces the problem . you may provide a screenshot of the application if you think it is relevant to your bug report . here are some tips for providing a minimal example - - > # # the current behavior console . log outputs ` < meta charset = "" utf - <number> "" / > < script src = "" foo "" async = "" "" > </script> <title> title </title> <html> <head> < script src = "" foo "" > </script> </head> </html> ` # # the expected behavior console . log outputs ` <html> <head> < meta charset = "" utf - <number> "" / > <title> title </title> < script src = "" foo "" > </script> < script src = "" foo "" async = "" "" > </script> </head> </html> `",0
facebook/react,"[ devtools bug ] : chrome extension gets disconnected from the page after 3 0 sec of inactivity # # # website or app <url> # # # repro steps steps : <number> . go to a react page like <url> <number> . open the devtools components tab , everything works correctly . <number> . change tab ( a non react one ) and wait <number> sec - <number> min ( not super exact ) <number> . go back to the tab that has the react page you are debugging <number> . the components does not work anywore : you can not select and view components on the page . [ screenshot <number> - <number> - <number> at <number> <number> <number> pm ] ( <url> my guess is that it ' s related to chrome killing the service worker after inactivity on the page . see <url> ! [ screenshot <number> - <number> - <number> at <number> <number> <number> pm ] ( <url> going back to the page does not seem to wake the serviceworker up . chrome : version <number> . <number> ( official build ) (x 8 6 _64 ) react extension : <number> . <number> macos # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] __react_devtools_global_hook__ ? <repeated> # # # website or app n / a # # # repro steps hi , i have heard that the new versions of react will not support the react_devtools_global_hook . if there any information about this update that you can share . is there a new way to achieve the same result of using the react_devtools_global_hook but with a different method ? what is the future of react without the react_devtools_global_hook ? # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] devtools stuck at loading react element tree , troubleshooting instructions are chrome - specific # # # website or app corporate project ( private ) # # # repro steps load page , then open react devtools . reloading or closing and reopening the tab does not fix the problem . quitting and reopening firefox sometimes fixes the problem . < img width = "" <number> "" alt = "" image "" src = "" <url> the [ linked troubleshooting instructions ] ( <url> provide no guidance for users of browsers other than chrome ; i am running firefox v114 ( on macos <number> . <number> ) . # # # how often does this bug happen ? often # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"bug : radio button onchange not called in current react canary < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> . <number> - canary - a1f97589f - <number> # # steps to reproduce <number> . create radio buttons that toggle ` disabled ` in ` onchange ` <number> . after selecting each radio button , ` onchange ` is no longer called < ! - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : the following codesandbox demonstrates the issue with the current react canary version . the issue is not present when react & react - dom versions are changed to stable <number> . <number> <url> < ! - - please provide a codesandbox ( <url> a link to a repository on github , or provide a minimal code example that reproduces the problem . you may provide a screenshot of the application if you think it is relevant to your bug report . here are some tips for providing a minimal example - - > # # the current behavior ` < input type = "" radio "" / > ` ' s ` onchange ` prop is not called on subsequent clicks of the input # # the expected behavior ` < input type = "" radio "" / > ` ' s ` onchange ` prop should be called on subsequent clicks of the input",0
facebook/react,"[ devtools bug ] : strict mode badge points to the old docs # # # website or app <url> # # # repro steps the strict mode warning badge points to <url> which points to the strict mode section in [ the old docs ] ( <url> instead of [ the new docs ] ( <url> badge : < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> code # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] - profiling does not store props value # # # website or app does not apply # # # repro steps old version of devtools provided ability to see changes in props / state between commits . <url> current version provide information about the reason to re - render , but lack of ability to see exactly how props / state variables are changing between re - renders is a huge regression for utility of profiler . components tab keeps only the latest values for the props / state . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app local repo # # # repro steps loading a react component with the react profiler recording enabled # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 7 f8c501f6 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] : react pages not being detected as using react in incognito mode # # # website or app <url> # # # repro steps it seems that with the latest update of chrome and react devtools , it cannot detect pages as using react on incognito . screenshot attached below : < img width = "" <number> "" alt = "" image "" src = "" <url> * _chrome version : <number> . <number> ( arm64 ) _ * _react devtools version ( <date> ) _ # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] : components tree not loaded in microsoft edge # # # website or app <url> # # # repro steps <number> . load react app in microsoft edge <number> . open dev tools and go to components tree <number> . the tree is not loaded : <number> . this is the message i get : loading react element tree . <repeated> if this seems stuck , please follow the [ troubleshooting instructions ] ( <url> edge version - latest edge version <number> . <number> ( official build ) ( <number> - bit ) [ image ] ( <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app local react development # # # repro steps open react dev tools # # # how often does this bug happen ? often # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 2 8 ce1c171 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,[ devtools bug ] settings are not being saved in the edge browser # # # website or app <url> # # # repro steps <number> . open devtools <number> . click view settings <number> . change one of the options <number> . refresh page <number> . no option is being saved # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_,0
facebook/react,"[ devtools bug ] to find react on the page ' in incognito on firefox # # # website or app <url> # # # repro steps <number> . open an incognito tab <number> . visit a react <number> website <number> . try and use dev tools ( i am on ` <number> . <number> ` ) < img width = "" <number> "" alt = "" cleanshot <number> - <number> - <number> at <number> <number> <number> <user> "" src = "" <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app localhost # # # repro steps tried to use the react dev tools components tab inspector tool # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 1 a88fbb67 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"bug : error occurs when returning empty fragment ' < > < / > ' on a page in was working when i comment a code and see this error then i start to test possible ways of reproduce the bug notes : <number> . using < > { null } < / > dont give the error <number> . using < > { undefined } < / > give the error react version # # steps to reproduce <number> . import { fragment } from "" react "" ; export default async function companies ( ) { return ( < fragment > < / fragment > {/* or => <></>* / } ); } <number> . start the localhost ( dev server , etc ) # # the current behavior < img width = "" <number> "" alt = "" image "" src = "" <url> # # the expected behavior < img width = "" <number> "" alt = "" image "" src = "" <url>",0
facebook/react,"why not ? [ devtools bug ] website or app website # # # repro steps loading react element tree . <repeated> if this seems stuck , please follow the [ troubleshooting instructions ] ( <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) loading react element tree . <repeated> if this seems stuck , please follow the troubleshooting instructions . # # # devtools version ( automated ) loading react element tree . <repeated> if this seems stuck , please follow the troubleshooting instructions . # # # error message ( automated ) loading react element tree . <repeated> if this seems stuck , please follow the troubleshooting instructions . # # # error call stack ( automated ) ` ` ` text loading react element tree . <repeated> if this seems stuck , please follow the troubleshooting instructions . ` ` ` # # # error component stack ( automated ) ` ` ` text loading react element tree . <repeated> if this seems stuck , please follow the troubleshooting instructions . ` ` ` # # # github query string ( automated ) ` ` ` text loading react element tree . <repeated> if this seems stuck , please follow the troubleshooting instructions . ` ` `",0
facebook/react,unable to establish connection with the sandpack bundler . [ devtools bug ] website or app <url> # # # repro steps <url> unable to establish connection with the sandpack bundler . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_,0
facebook/react,[ devtools bug ] : react dev tools breaks craigslist ? # # # website or app <url> # # # repro steps <number> . enable react dev tools <number> . visit <url> <number> . <percent> of the time you will see broken page <url> <number> . disable react dev tools <number> . visit <url> <number> . <percent> of the time you will see a working page # # # how often does this bug happen ? often # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) ` ` ` text typeerror : svs - boot - setmanifest - exception : cannot read properties of null ( reading ' insertbefore ' ) at cl . injectcss ( bbe8a523a089547e594fa2f101021699a377645c . js : <time> <number> ) at cl . injectresource ( bbe8a523a089547e594fa2f101021699a377645c . js : <time> <number> ) at bbe8a523a089547e594fa2f101021699a377645c . js : <time> <number> at array . foreach ( <anonymous> ) at injectresourceset ( bbe8a523a089547e594fa2f101021699a377645c . js : <time> <number> ) at bigbang ( bbe8a523a089547e594fa2f101021699a377645c . js : <time> <number> ) at cl . setmanifest ( bbe8a523a089547e594fa2f101021699a377645c . js : <time> <number> ) at manifest . js : <number> : <number> cl . unexpected @ bbe8a523a089547e594fa2f101021699a377645c . js : <number> cl . setmanifest @ bbe8a523a089547e594fa2f101021699a377645c . js : <number> ( anonymous ) @ manifest . js : <number> vm1218 : <number> uncaught syntaxerror end of json input at json . parse ( <anonymous> ) at localstorage - 0 9 2 e9f9e2f09450529e744902aa7cdb3a5cc868d . html : <number> <time> ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_,0
facebook/react,"[ devtools bug ] static flag was missing # # # website or app <url> # # # repro steps this error reproduces on initial page load . i can not seem to find what caused it to start showing up , as it points to a part of my code that has existed since well before i first got the error . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"error typeerror : cannot read property ' createelement ' of undefined , js engine : hermes # # # website or app i am using flipper to debug react - native app # # # repro steps migrate to current version of rn - <number> . <number> using flipper enable hermes engine run the app [ see ] ( <url> [ here ] ( <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) ` ` ` text error typeerror : cannot read property ' createelement ' of undefined , js engine : hermes error typeerror : cannot read property ' createelement ' of undefined , js engine : hermes error typeerror : cannot read property ' createelement ' of undefined , js engine : hermes error typeerror : cannot read property ' createelement ' of undefined , js engine : hermes ` ` ` # # # error component stack ( automated ) ` ` ` text this is related to - - - > > path : node_modules / react - devtools - core / dist / backend . js function initialize ( ) { canvas = window . document . createelement ( ' canvas ' ); canvas . style . csstext = "" \ \ n xx - background - color : red ;\\ n xx - opacity : <number> ;\\ n bottom : <number> ;\\ n left : <number> ;\\ n pointer - events : none ;\\ n position : fixed ;\\ n right : <number> ;\\ n top : <number> ;\\ n z - index "" ; var root = window . document . documentelement ; root . insertbefore ( canvas , root . firstchild ) ; } ` ` ` # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] page does not appear to be using react # # # website or app reactjs . org # # # repro steps go to website . click on the react devtools icon in the extensions . after reaload , hover the extension . [ image ] ( <url> ! [ image ] ( <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"bug : suspense | client component should have a queue react version : <number> . <number> next version : <number> . <number> # # steps to reproduce <number> . suspend using a ( fake ) promise in a client component in app dir ( next ) <number> . try to usestate after the use ( ) call ` ` ` ` ts ' use client ' ; import { use , usestate } from ' react ' ; const testpromise = new promise ( ( resolve ) => { settimeout ( ( ) => { resolve ( ' use test promise ' ); }); }); export default function page ( ) { use ( testpromise ) ; usestate ( <number> ); return <h1> test </h1> ; } ` ` ` ` link to code example : <url> # # the current behavior suspending for a promise in a client component and using state / reducer after results in errors during hydration : ` ` ` react - dom . development . js ? 9 d87 : <number> warning : an error occurred during hydration . the server html was replaced with client react - dom . development . js ? 9 d87 : <number> warning : you are accessing "" digest "" from the errorinfo object passed to onrecoverableerror . on - recoverable - error . js ? eb9 <time> uncaught error have a queue . this is likely a bug in react . please file an issue . ` ` ` # # the expected behavior no error during hydration .",0
facebook/react,"[ devtools bug ] much recursion - firefox & appsync # # # website or app <url> # # # repro steps <number> . use firefox with react dev tools added <number> . log into aws , go to appsync console and select an api <number> . the app will then freeze and you should get a ` too much recursion ` error in the console this only seems to happen in firefox . not confident on whether this is a devtools , firefox or appsync issue but it only seems to happen when devtools is enabled . [ screenshot <number> - <number> - <number> at <number> <number> <number> ] ( <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app local dev environment # # # repro steps occurs on app launch # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app <url> # # # repro steps e # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app http :// localhost : <number> # # # repro steps someone know solution ? i saw a peoples that have same problem , but no one helped <annoyed> # # # how often does this bug happen ? only once # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] tab does not show up # # # website or app <url> # # # repro steps <number> . visit website <number> . open dev tools this happens on <url> but i first noticed in on a personal project ( localhost ) . when i open the dev tools , the cpu goes up . at first , the components tab does not show up . after a long <elongated> time , it does show up , however when i click on it nothing renders inside . [ screenshot <number> - <number> - <number> at <number> <number> <number> ] ( <url> i do not know if it ' s the newest chrome version or the newest extension version that ' s causing it . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app . # # # repro steps . # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app the error was thrown at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> # # # repro steps the error occurred at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app http :// localhost : <number> / managercr # # # repro steps al darle un nuevo key al form , para que este se resetee , me salta este error # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app test # # # repro steps react devtool send me this error , how i can fix it # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app localhost # # # repro steps if click to the app > state , browser drop me a error "" element "" <number> "" not found "" , and more red line , i do not understand what is it . browser updating <number> minutes later to <number> . <number> version . help me # # # how often does this bug happen ? only once # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] element "" <number> "" not found # # # website or app <url> # # # repro steps map list # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - bd2ad89a4 # # # error message ( automated ) element "" <number> "" not found # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] : react - devtools depends on vulnerable version of electron # # # website or app <url> # # # repro steps # # # issue electron package versions < <number> . <number> suffer from a security vulnerability of hashed smb credentials on windows via file :// redirect "" . see <url> # # # solution upgrade electron dependency in react - devtools to > <number> . <number> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] could not find id for fiber "" middlesectioncontainer "" # # # website or app / / / # # # repro steps log in inspect element # # # how often does this bug happen ? only once # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 3 3 6 ac8ceb # # # error message ( automated ) could not find id for fiber "" middlesectioncontainer "" # # # error call stack ( automated ) ` ` ` text at getfiberidthrows ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at fibertoserializedelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at inspectelementraw ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at object . inspectelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> : <number> ) ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not find id for fiber "" middlesectioncontainer "" in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app - - - - # # # repro steps - - - - # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 3 3 6 ac8ceb # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] extension tab in edge devtools does not have emoji prefix in title . # # # website or app <url> # # # repro steps <number> . open developer tools with react extension on any website that using react in edge . <number> . check the react extension tab ( profiler and components ) , it does not have emoji prefix in the title like chrome does . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] should not skip over keyed fragments in the tree # # # website or app <url> # # # repro steps <number> . wrap something into ` < fragment key = "" stuff "" > ` <number> . it does not show up in devtools we filter out fragments because they tend to be useless . but this one is important keys are crucial and we should show anything with a key in the tree . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"bug : out of order application of usestate changes after updating my app to react <number> i had problem with inconsistent state from usestate i created code example with the problem : * i have <number> states ` const [ done , setdone ] = usestate ( false ) ; ` ( inside hook ) and ` const [ ids , setids ] = react . usestate ( [ ] ) ` * i call ` setids ( [ <number> , <number> ] ) ` ( inside await , but it ' s executed immediately , as we see in console ) and then ` setdone ( true ) ` * then component is rerendered with updated ` done ` but original ` ids ` * then component is rerendered , but with both states updated react version : <number> . <number> , <number> . <number> - next link to code example : < <url> smaller repro : < <url> ( from eps1lon ' s comment ) # # the current behavior in the example after clicking run : ` inner ` is rerendered with ` done : true ` , but without updated ` ids ` . ` formiklike ` is created with empty ` ids ` . ` [ ] ` is displayed under button . # # the expected behavior first ` inner ` rerender should have updated ` ids ` state . ` formiklike ` should be created with non - empty ` ids ` . ` [ <number> , <number> ] ` is displayed under button . it workied this way in react <number> . in <url> <user> wrote > but can you trust react to update the state in the same order as setstate is called for the same component ? > > yes . answer was for class components , but i hope the same is true for multiple usestate hooks in single function component .",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app <url> # # # repro steps <number> ) npm install <number> ) npm start <number> ) inspect element <number> ) components tab # # # how often does this bug happen ? sometimes # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 3 3 6 ac8ceb # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text emit <user> - extension :// 9 9 0 8 b50a - 4 8 f2 - 4 0 b1 - <number> - 7 9 8 1 3 e5a6947 / build / main . js : <number> <time> bridge_bridge / this . _wallunlisten < <user> - extension :// 9 9 0 8 b50a - 4 8 f2 - 4 0 b1 - <number> - 7 9 8 1 3 e5a6947 / build / main . js : <number> <time> listener <user> - extension :// 9 9 0 8 b50a - 4 8 f2 - 4 0 b1 - <number> - 7 9 8 1 3 e5a6947 / build / main . js : <number> <time> ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] in editor "" not working for vscode remote files # # # website or app empty # # # repro steps / data / home / x <elongated> / src / test . tsx <number> . inspect component <number> . user clicks "" open in editor "" <number> . file not found # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,[ devtools bug ] : window . bundle . js : <number> typeerror read properties of undefined ( reading ' action ' ) # # # website or app <url> # # # repro steps <number> . load webpage <number> . tools doesnt work # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_,0
facebook/react,"[ devtools bug ] could not inspect element with id "" <number> "" # # # website or app internal company application # # # repro steps sometimes i got this error , i solve it be restart my device # # # how often does this bug happen ? sometimes # # # devtools package ( automated ) react - devtools - core # # # devtools version ( automated ) <number> . <number> - d0ec283819 # # # error message ( automated ) could not inspect element with id "" <number> "" # # # error call stack ( automated ) ` ` ` text uncaught error : could not inspect element with id "" <number> "" the error occurred at ni ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at suspense at yl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at div at tl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at ji ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at div at div at oa ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at va ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at yl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at div at div at ns ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at vn ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at un ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at pl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at kc ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) ` ` ` # # # error component stack ( automated ) ` ` ` text at ni ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at suspense at yl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at div at tl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at ji ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at div at div at oa ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at va ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at yl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at div at div at ns ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at vn ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at un ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at pl ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at kc ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not inspect element with id in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot remove node "" <number> "" because no matching node was found in the store . # # # website or app bitbucket repo # # # repro steps just npm react - devtools and run # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - core # # # devtools version ( automated ) <number> . <number> - 7 f673317f # # # error message ( automated ) cannot remove node "" <number> "" because no matching node was found in the store . # # # error call stack ( automated ) ` ` ` text at / users / matt / . config / yarn / global / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at f . emit ( / users / matt / . config / yarn / global / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / users / matt / . config / yarn / global / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at / users / matt / . config / yarn / global / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> at array . foreach ( <anonymous> ) at a . e . onmessage ( / users / matt / . config / yarn / global / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at a . t ( / users / matt / . config / yarn / global / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at a . emit ( events . js : <number> <time> ) at e . exports . l ( / users / matt / . config / yarn / global / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . emit ( events . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> remove node because no matching node was found in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] : uncaught typeerror : hook . sub is not a function # # # website or app new project created by cra # # # repro steps <number> . create a new project by cra on mac os monterey v12 . <number> ; <number> . import ' react - devtools ' at first line of ` src / index . tsx ` ; <number> . sudo npm i - - location = global react - devtools ; <number> . npx react - devtools ; <number> . in my raect app console run ` t = document . createelement ( ' script ' ); t . type = ' text / javascript ' ; t . src = ' http :// localhost : <number> ' ; document . head . prepend ( t ) ` ; <number> . uncaught typeerror is not a function , below are some screenshots . < img width = "" <number> "" alt = "" error "" src = "" <url> < img width = "" <number> "" alt = "" location "" src = "" <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] cannot remove node "" <number> "" because no matching node was found in the store . # # # website or app localhost # # # repro steps this error occurs every time i rebuild my react app # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 7 f673317f # # # error message ( automated ) cannot remove node "" <number> "" because no matching node was found in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> remove node because no matching node was found in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] show every page use ` react ` # # # website or app <url> # # # repro steps open the [ vue3 ] ( <url> doc site , then ` react ` devtool show this page use procution build of ` react ` < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> and github too < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> i am using crome version <number> . <number> ( official build ) (x 8 6 _64 ) < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] : warning : internal react error : expected static flag was missing . please notify the react team . # # # website or app <url> # # # repro steps the component is successfully rendered with all the interactions working properly . as far as i can tell , the error is only shown in the console . the traceback point to the line <number> of the codepen _ahr = await scontract . methods . rewardperhour ( ) . call ( ); # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] when inspecting , hook values after ` usedeferredvalue ` are offset # # # website or app <url> # # # repro steps <number> . start the app in either dev or production mode . <number> . open the react dev tools <number> . click on the "" app "" component <number> . the first memo has the value ` <number> ` ( the value that the second memo should have ) instead of ` <number> ` if you want it to throw an error instead of just looking at the values , you can set ` window . throwifincorrect = true ` before devtools inspects the component . i tried in codesandbox ' s embedded react dev tools as well - the issue happens in react <number> ( though the first hook has no value and the second has the first hook ' s value ) but it does not happen in <number> . # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 8 2 7 6 2 bea5 # # # error message ( automated ) first is <number> when it should be <number> # # # error call stack ( automated ) ` ` ` text i <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> : <number> exports . inspecthooksoffiber <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> inspectelementraw <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> : <number> inspectelement <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> agent_agent / < <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> emit <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> bridge / this . _wallunlisten < <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> listener <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> eventlistener . handleevent*listen <censored> <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> bridge <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> setup <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> welcome <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> : <number> eventlistener . handleevent * <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> : <number> __webpack_require__ <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <time> <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / react_devtools_backend . js : <number> <time> ` ` ` # # # error component stack ( automated ) ` ` ` text inspectedelementcontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> suspense errorboundary_errorboundary <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> : <number> div inspectedelementerrorboundarywrapper <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> nativestylecontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> div div ownerslistcontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> settingsmodalcontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> components_components <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> errorboundary_errorboundary <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> : <number> div div themeprovider <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> portaledcontent <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> div div div themeprovider <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> timelinecontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> profilercontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> treecontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> settingscontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> modaldialogcontextcontroller <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> devtools_devtools <user> - extension :// 3 8 b0497f - 3 7 d9 - 4 9 e7 - <number> - <number> / build / main . js : <number> <time> ` ` ` # # # github query string ( automated ) ` ` ` text <url> is <number> when it should be <number> in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app http :// localhost : <number> / typeoffood # # # repro steps . # # # how often does this bug happen ? often # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - ca7a38ae4 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,[ devtools bug ] devtools missing from chrome extensions webstore - <number> response # # # website or app <url> # # # repro steps the download page for the chrome react devtools extension returns <number> . i checked the firefox developer tools download page and that ' s still up . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_,0
facebook/react,"[ devtools bug ] crashes when i enable devtools on chrome # # # website or app <url> # # # repro steps for checking whenever my project will work correctly , when i run a command ` next dev ` , errors which are shown below occurred . [ image ] ( <url> when i pass a first argument which is an * object <emphasis> * to ` console . log ( ) ` , ` console . error ( ) ` , ` console . warn ( ) ` , i can repro the errors . for example , ` ` ` console . log ( []); console . error ( {}); ` ` ` before a few days , the errors had never occured . when i disable devtools , the errors calm down . i think , the errors may be caused by the codes which are shown below . <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] : component shown twice in flame graph when using react . memo # # # website or app i cannot provide . private . # # # versions - react developer tools <number> . <number> ( <date> ) - "" react "" : "" ^ <number> . <number> "" , - "" react - dom "" : "" ^ <number> . <number> "" , # # # repro steps i am using react - devtools to profile my app . when a component is wrapped in react . memo and a custom comparison function is provided , that component shows up twice in the flamegraph . i tried with different components in the app and the behaviour is always the same . i tried with both the chrome extension and the stand - alone npm package . shows only one instance in flamegraph : ` export default react . memo ( surfacesselector ) ` shows up twice in flamegraph : ` export default react . memo ( surfacesselector , customshallowequal ) ` or ` ` ` export default react . memo ( surfacesselector , ( prevprops : surfacesselectorprops , nextprops => { if ( deepequal ( prevprops . enabledsurfaces , nextprops . enabledsurfaces ) ) { return false ; } if ( deepequal ( prevprops . surfaces , nextprops . surfaces ) ) { return false ; } return shallowequal ( prevprops , nextprops ) ; } ) ` ` ` see the following screenshots for the result . [ screen shot <number> - <number> - <number> at <number> <number> <number> ] ( <url> ! [ screen shot <number> - <number> - <number> at <number> <number> <number> ] ( <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"bug : setstate is not flushed if an iframe is added in the same tick in safari batched state changes are not flushed if the promise code changes the dom <happy> attaching an iframe ) . reproduceable with safari . react version : <number> . <number> # # steps to reproduce <number> . open [ codepen ] ( <url> with safari . <number> . click "" upload "" <number> . => "" spinner "" text does not render while promise is in pending link to code example # # the current behavior state changes are not executed . # # the expected behavior state should change to true and render spinner component . after promise is resolved ( <number> seconds timeout ) , state should switch back to false and spinner component should unmount . # # original discussion <url>",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app <url> # # # repro steps running react - native debugger # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - core # # # devtools version ( automated ) <number> . <number> - d0ec283819 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at c . emit ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> at / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at array . foreach ( <anonymous> ) at s . gc . e . onmessage ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at s . n ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at s . emit ( events . js : <number> <time> ) at e . exports . p ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at e . exports . emit ( events . js : <number> <time> ) at e . exports . datamessage ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . getdata ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . startloop ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . _write ( / usr / lib / react - native - debugger / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at dowrite ( _stream_writable . js : <number> <time> ) at writeorbuffer ( _stream_writable . js : <number> : <number> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] : error in event handler : error to use a disconnected port object # # # website or app <url> # # # repro steps <number> . create a react app ` ` ` yarn create react - app test - react cd test - react yarn start ` ` ` <number> . create ` . env . development ` file in root . ` ` ` https = true port = <number> browser = none ` ` ` <number> . visit https :// localhost : <number> / in chrome v100 . <number> . <number> <number> . open react devtools by inspecting page , some times it shows ` components ` tab but in large application it does not show the ` components ` tab . if it shows the tab the error message is sent to dev tools every second . <number> . see error message in [ chrome :// extensions / ] ( chrome :// extensions / ) # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"bug : incorrect hydration mismatch detection during suspense - "" hydration failed because the initial ui does not match what was rendered on the server . "" react version : <number> . <number> # # steps to reproduce <number> . add a suspense boundary <number> . add a * * component that will suspend * * to load some data ( faked ) . <number> . render at least one * * sibling component * * _after_ the suspending component . <number> . render server - side using rendertopipeablestream ( ) <number> . render client - side using hydrateroot ( ) __reproductions in codesandbox : __ - [ reproduction <number> ] ( <url> with next . js [ edit ] ( <url> - [ reproduction <number> ] ( <url> using rendertopipeablestream ( based on [ example demo ] ( <url> ` ` ` ` jsx < > <h4> this headline hydrates fine . </h4> < somethinga />{/* will suspend on client and server */} <h3> 💥 this element after the suspending component triggers an error ( only in development ) . </h3> < / > ` ` ` ` # # the current behavior - the sibling component following the suspending component is incorrectly seen as a * * hydration mismatch * * . - console will show errors ( and next . js will show big error overlay ) : ` ` ` ` warning : expected server html to contain a matching <h3> in <div> . at h3 at indexpage at suspense at app ( webpack - internal :/// . / pages / _app . js : <number> <time> ) at errorboundary ( webpack - internal :/// . / node_modules / next / dist / compiled / <user> / react - dev - overlay / client . js : <time> <number> ) at reactdevoverlay ( webpack - internal :/// . / node_modules / next / dist / compiled / <user> / react - dev - overlay / client . js : <time> <number> ) at container ( webpack - internal :/// . / node_modules / next / dist / client / index . js : <number> : <number> ) at appcontainer ( webpack - internal :/// . / node_modules / next / dist / client / index . js : <number> <time> ) at root ( webpack - internal :/// . / node_modules / next / dist / client / index . js : <number> <time> ) ` ` ` ` ` ` ` ` uncaught error failed because the initial ui does not match what was rendered on the server . at throwonhydrationmismatch ( react - dom . development . js ? ac8 <time> <number> : <number> ) at trytoclaimnexthydratableinstance ( react - dom . development . js ? ac8 <time> <number> : <number> ) at updatehostcomponent <money> ( react - dom . development . js ? ac8 <time> <number> : <number> ) at beginwork ( react - dom . development . js ? ac8 <time> <number> : <number> ) at htmlunknownelement . callcallback ( react - dom . development . js ? ac8 <time> <number> : <number> ) at object . invokeguardedcallbackdev ( react - dom . development . js ? ac8 <time> <number> : <number> ) at invokeguardedcallback ( react - dom . development . js ? ac8 <time> <number> : <number> ) ` ` ` ` - depending on the location of the suspending component and their siblings , there are errors or no errors at all . when the suspending component is the last component , there are no errors logged . - error can be suppressed by wrapping the suspending component in a suspense boundary directly # # the expected behavior - i expect to be able to use the same fetching mechanism using suspense on server and client in [ react v18 ] ( <url> _or_ - if this is unsupported usage , the errors should be more clear and consistent .",0
facebook/react,"bug : some transition updates have not been rendered < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> . <number> # # steps to reproduce <number> . write a react component with the following code : ` ` ` jsx import react , { usestate , starttransition } from ' react ' ; export default function app ( ) { const arr = array ( <number> ) . fill ( <number> ); const [ value , setvalue ] = usestate ( <number> ); const handleinputchange = ( e ) => { console . log ( e . target . value ) ; starttransition ( ( ) => { setvalue ( e . target . value ) ; }); }; const getvalues = ( ) => { return arr . map ( ( item , index ) => { return ( < div key ={ index } > { value } - { index } </div> ); }); }; return ( <div> < input type = "" text "" onchange ={ handleinputchange } / > <div> { getvalues ( ) } </div> </div> ); } ` ` ` <number> . input content in the ` < input / > ` at a very fast speed . <number> . as shown in the figure below , all the contents i entered for the first time have been rendered . but the second time i input ` <number> ` , only ` <number> ` is rendered , and the following characters are not rendered . ! [ img ] ( <url> < ! - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : <url> < ! - - please provide a codesandbox ( <url> a link to a repository on github , or provide a minimal code example that reproduces the problem . you may provide a screenshot of the application if you think it is relevant to your bug report . here are some tips for providing a minimal example - - > # # the current behavior as shown in the figure below , all the contents i input for the first time have been rendered . but the second time i input ` <number> ` , only ` <number> ` is rendered , and the following characters are not rendered . # # the expected behavior everything i input should be rendered .",0
facebook/react,"bug : componentwillunmount is called twice react version : <number> . <number> # # steps to reproduce ` componentwillunmount ` is called twice upon toggling the rendered component . even when * strictmode <emphasis> * is disabled link to code example # # the current behavior after upgrading to react <number> we have seen some different behavior in a conditionally rendered , lazy class component . in the provided code example the class component is rendered first . after the first toggle , the class component ' s componentwillunmount is called twice . subsequent toggle calls correctly lead to a single componentwillunmount invocation . this does only seem to affect the class component when its rendered first . if the condition is changed to initially show the other function component the class component unmounts just fine # # the expected behavior the class component ' s componentwillunmount is only called once",0
facebook/react,"bug : ` suppresshydrationwarning ` is not taken into account in production builds in react <number> < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> # # steps to reproduce <number> . clone <url> <number> . run : npm install <number> . run : npm build <number> . run : npm run start - example - build <number> . go to the following url : http :// localhost : <number> / fr - ca / tests / routes - dynamiques / <number> <number> . open the console log : no errors <number> . kill the app , and update the react and react - dom package to version <number> <number> . re - run steps <number> to <number> <number> . open the console log : lots of hydration errors #[ <number> ] ( <url> #[ <number> ] ( <url> and #[ <number> ] ( <url> < ! - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : <url> < ! - - please provide a codesandbox ( <url> a link to a repository on github , or provide a minimal code example that reproduces the problem . you may provide a screenshot of the application if you think it is relevant to your bug report . here are some tips for providing a minimal example : <url> - - > # # the current behavior using react <number> , the tests are failing because of the errors being thrown in the console . < img width = "" <number> "" alt = "" image "" src = "" <url> i confirmed this was related to ` suppresshydrationwarning ` because as soon as i removed the following code from ` ` ` jsx <tr> <td> { messages . format ( ' rowlocalizedwithaspath ' ) } </td> {/* adding ` suppresshydrationwarning ` until <url> is resolved */} < td suppresshydrationwarning ={ true } > { aspath } </td> </tr> ` ` ` the errors stop . however , i could not find any mention that ` suppresshydrationwarning ` was no longer supported with react <number> and these errors are only triggered on builds , not in dev mode ( which is why i am opening this issue ) # # the expected behavior ` suppresshydrationwarning ` should prevent these errors from being thrown .",0
facebook/react,"[ devtools bug ] cannot add child "" <number> "" to parent "" <number> "" because parent node was not found in the store . # # # website or app <url> # # # repro steps clone the repo at the linked commit - npm install - npm run dev - open localhost : <number> - open react devtools - refresh the page # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - core # # # devtools version ( automated ) <number> . <number> - e28a0db22 # # # error message ( automated ) cannot add child "" <number> "" to parent "" <number> "" because parent node was not found in the store . # # # error call stack ( automated ) ` ` ` text at / usr / local / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at c . emit ( / usr / local / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / usr / local / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at / usr / local / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> at array . foreach ( <anonymous> ) at a . e . onmessage ( / usr / local / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at a . t ( / usr / local / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at a . emit ( events . js : <number> <time> ) at e . exports . l ( / usr / local / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . emit ( events . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add child to parent because parent node was not found in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"npm "" version "" export format changed ( now includes sha and date ) react version : <number> . <number> # # steps to reproduce <number> . ` import { version } from "" react "" ` <number> . ` console . log ( version ) ` < - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : <url> # # the current behavior version is : ` <number> . <number> - fc46dba67 - <number> ` # # the expected behavior version is ( or ` <number> . <number> ` 😉 )",0
facebook/react,"[ devtools bug ] hook incorrectly labelled as reason for component rendering # # # website or app <url> # # # repro steps <number> . start profiling <number> . click the button <number> . stop profiling <number> . check the reasons for rendering < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> am "" src = "" <url> < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> am "" src = "" <url> it is incorrect to say that hook <number> is why this rendered . hook <number> is why it rendered . hook <number> was rescheduled during that render . these really need to be separated as they are completely different things . in a component with a lot of effects it can be tedious to find which hook was the one that caused it to render ( especially with transpilling , minifying etc where hooks are not always shown nicely ) . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] unsupported bridge operation "" <number> "" # # # website or app react native init app # # # repro steps just run the react - devtools and then forward to port <number> to debug in real device # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - core # # # devtools version ( automated ) <number> . <number> - ac574d688 # # # error message ( automated ) unsupported bridge operation "" <number> "" # # # error call stack ( automated ) ` ` ` text at / users / tb921t / . npm - global / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at f . emit ( / users / tb921t / . npm - global / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / users / tb921t / . npm - global / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at / users / tb921t / . npm - global / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> at array . foreach ( <anonymous> ) at a . zh . e . onmessage ( / users / tb921t / . npm - global / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at a . t ( / users / tb921t / . npm - global / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at a . emit ( events . js : <number> <time> ) at e . exports . l ( / users / tb921t / . npm - global / lib / node_modules / react - devtools / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . emit ( events . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> bridge operation in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,[ devtools bug ] : components + profile tabs not showing up in chrome <number> # # # website or app <url> # # # repro steps <number> . open up chrome inspector <number> . expect components + profile tabs to appear computer : <number> macbook pro ( intel ) browser : google chrome version <number> . <number> ( official build ) (x 8 6 _64 ) devtools ( <date> ) # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_,0
facebook/react,"rendertoreadablestream passes reusable chunks <url> we switched to using "" bytes "" streams but , by spec , chunks get transferred in that format . totally reasonable . however , we pass reusable chunks which then get detached . i am not sure why the polyfill or fixtures did not catch this . we really should be using the byob model instead and copy into a larger chunk for perf anyway so this just makes that more urgent .",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app local running intranet web app # # # repro steps <number> . start intranet web app <number> . call in devtools from react devtools "" components "" # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - e28a0db22 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot read properties of undefined ( reading ' skin ' ) # # # website or app <url> # # # repro steps using the react dev tools , example : search for moleculequestionsfreetext in the story book , then the context is undefined hence the error ( the provider shows that the skin is ok but the context does not reach the component - at least for the dev tools , because it actually reaches as the context is used ) , the patch is easy to get a default value in case it is undefined but it should not be needed because it would only for the devtools ' sake . # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - e28a0db22 # # # error message ( automated ) cannot read properties of undefined ( reading ' skin ' ) # # # error call stack ( automated ) ` ` ` text at freetext ( <url> at h ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> : <number> ) at exports . inspecthooksoffiber ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at inspectelementraw ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> : <number> ) at object . inspectelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> : <number> ) ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> read properties of undefined ( reading ' skin ' ) in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] could not find node with id "" <number> "" in commit tree # # # website or app <url> # # # repro steps just try and load the <number> / <number> and <number> / <number> report from a reload and start profiling instance . change ` react_app_api_url ` to ` <url> in order to launch the app without needing the full . net <number> environment and the corresponding data in the postgres database . # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - e28a0db22 # # # error message ( automated ) could not find node with id "" <number> "" in commit tree # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at map . foreach ( <anonymous> ) at rankedchartbuilder_getchartdata ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at profilingcache_profilingcache . getrankedchartdata ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at commitrankedautosizer ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at gi ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at zj ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at jl ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at il ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at hl ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) ` ` ` text at commitrankedautosizer ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at div at div at div at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profiler_profiler ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not find node with id in commit tree in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] could not find id for fiber "" app "" # # # website or app <url> # # # repro steps run the next app , open up react dev tools and inspect the box component , rendered by <user> - three / fiber . # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - e28a0db22 # # # error message ( automated ) could not find id for fiber "" app "" # # # error call stack ( automated ) ` ` ` text at getfiberidthrows ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at fibertoserializedelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at inspectelementraw ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at object . inspectelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> : <number> ) ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at timelinecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not find id for fiber "" app "" in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] : different results in chrome and firefox # # # website or app <url> <url> # # # repro steps i was using the youtube website . i have a habit of checking if the website i have visited was using react or not . as always i checked for youtube website too . but the react developer tools extension was showing the youtube website is using react . just to make sure it was right i have installed the firefox browser then installed the react developer tools extension and opened the youtube website , but in firefox , the extension was saying the youtube is not using react . for confirming with other websites , i have visited mdn and github docs in both chrome and firefox . the chrome react developer tools extension says that the mdn is using react and the firefox react developer tools extension says that the mdn is not using react . for the github docs website , the chrome extension says that the github docs website was using the react whereas the firefox react developer tools extension shows that the github docs website does not use the react . i am attaching the screen recording . to differentiate what websites i have visited in chrome and firefox i previously opened the websites in chrome and showed the results , for firefox i have typed the query and showed the results . can you tell why it was happening like this ? <url> repro steps <number> . login to the website <number> . scrolling the website <number> . noticed the bug versions : chrome : <number> . <number> firefox react developer tools : <number> . <number> # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] : not sure if bug or not marks youtube as built with react . # # # website or app <url> # # # repro steps i was watching a video on youtube when i noticed the new video hover features which were not there on the 1 5 th of <date> . this then led me to the react dev tools which i noticed had turned blue , never had before . wanted to know of this is a bug or not . i have restarted my computer and browser severally . [ ] ( url [ tube ] ( <url> ) # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools ] : confusing "" why did this render ? "" with hooks # # # website or app <url> # # # repro steps <number> . visit <url> <number> . start recording profile <number> . click a button ( to update the context value ) <number> . check the report width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> # # # problem the list of hooks that were changed is * correct <emphasis> * . however , this list is not really the reason why this component has been rendered . the only thing that changed and led to this rerender is the context value . i think the list of changed hooks is useful but this should be listed separately . for the "" why did this render ? "" only context and state ( and maybe usesyncexternalstore snapshots ) should be listed . as only those actually cause rerenders . on a separate note - it ' s a bummer that contexts are not counted within the changed hooks list and the only report we get is that "" context has changed "" . if i use multiple contexts in a component this information is often not enough because i can not easily check which context has been updated . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app code sandbox app # # # repro steps <number> . clcik inspect from google chrome <number> . click components <number> . it will show up this message # # # how often does this bug happen ? sometimes # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 0 2 2 9 baee2 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot add child "" <number> "" to parent "" <number> "" because parent node was not found in the store . # # # website or app localhost # # # repro steps just started profiler and reloaded the page # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 0 2 2 9 baee2 # # # error message ( automated ) cannot add child "" <number> "" to parent "" <number> "" because parent node was not found in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add child to parent because parent node was not found in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app it ' s empty project creating with ' react - native init ' # # # repro steps <number> . start rn app in debug mode # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - core # # # devtools version ( automated ) <number> . <number> - d0ec283819 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at c . emit ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> at / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at array . foreach ( <anonymous> ) at s . gc . e . onmessage ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at s . n ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at s . emit ( events . js : <number> <time> ) at e . exports . p ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at e . exports . emit ( events . js : <number> <time> ) at e . exports . datamessage ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . getdata ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . startloop ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at e . exports . _write ( / applications / react native debugger . app / contents / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at dowrite ( _stream_writable . js : <number> <time> ) at writeorbuffer ( _stream_writable . js : <number> : <number> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] could not find id for fiber "" route "" # # # website or app null # # # repro steps i wrote a component using dhtmlxgantt : ` ` ` < div ref ={ ganttcontent } / > ` ` ` initialized in this way : ` ` ` useeffect ( ( ) => { gantt . init ( ganttcontent . current ) ; gantt . parse ( data ) ; } , []); ` ` ` # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 2 f8f60ca8 # # # error message ( automated ) could not find id for fiber "" route "" # # # error call stack ( automated ) ` ` ` text at getfiberidthrows ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at fibertoserializedelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at inspectelementraw ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at object . inspectelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> : <number> ) ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at schedulingprofilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not find id for fiber "" route "" in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app just in my local machine # # # repro steps <number> . load page . <number> . open react components . # # # how often does this bug happen ? only once # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 2 f8f60ca8 # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] could not find id for fiber "" app "" # # # website or app not public # # # repro steps i have two code bases in a yarn workspaces linked monorepo . one is using react - three - fiber ( the lib ) , and the other one is really thin wrapper around it with some simple ui , just couple of buttons . both are using multiple ( <number> ) zustand stores . # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 2 f8f60ca8 # # # error message ( automated ) could not find id for fiber "" app "" # # # error call stack ( automated ) ` ` ` text at getfiberidthrows ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at fibertoserializedelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at inspectelementraw ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at object . inspectelement ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / react_devtools_backend . js : <number> : <number> ) ` ` ` # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at schedulingprofilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not find id for fiber "" app "" in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,revert changes to react - devtools - inline webpack config from pr # <number> resolves # <number>,0
facebook/react,"[ react - devtools - inline ] [ <number> . <number> <sad> broken published package # # steps to reproduce <number> . install ` react - devtools - inline ` in a project that has ` react ` and ` react - is ` <number> . open node <number> . ` require ( ' react - devtools - inline ' ) ` <number> . see error : ` ` ` uncaught : error : cannot find module ' / users / jstejada / code / jstejada - react / build / oss - experimental / react - is ' require stack : - / home / avi / projects / temp / inlinetest / node_modules / react - devtools - inline / dist / backend . js - <repl> at function . module . _resolvefilename ( node : internal / modules / cjs / loader : <number> <time> ) at function . module . _load ( node : internal / modules / cjs / loader : <number> <time> ) at module . require ( node : internal / modules / cjs / loader : <number> <time> ) at require ( node : internal / modules / cjs / helpers : <number> <time> ) at object . <number> ( / home / avi / projects / temp / inlinetest / node_modules / react - devtools - inline / dist / backend . js : <number> <time> ) at __webpack_require__ ( / home / avi / projects / temp / inlinetest / node_modules / react - devtools - inline / dist / backend . js : <time> ) at object . <number> ( / home / avi / projects / temp / inlinetest / node_modules / react - devtools - inline / dist / backend . js : <number> <time> ) at __webpack_require__ ( / home / avi / projects / temp / inlinetest / node_modules / react - devtools - inline / dist / backend . js : <time> ) at object . <number> ( / home / avi / projects / temp / inlinetest / node_modules / react - devtools - inline / dist / backend . js : <number> : <number> ) at __webpack_require__ ( / home / avi / projects / temp / inlinetest / node_modules / react - devtools - inline / dist / backend . js : <time> ) ` ` ` # # the current behavior published package contains the following code module . exports = require ( "" / users / jstejada / code / jstejada - react / build / oss - experimental / react - is "" ); . <repeated> module . exports = require ( "" / users / jstejada / code / jstejada - react / build / oss - experimental / react "" ); ` ` ` # # the expected behavior no absolute paths in bundle . successful evaluation .",0
facebook/react,"[ devtools bug ] could not find node with id "" <number> "" in commit tree # # # website or app <url> # # # repro steps <number> . visit homepage <number> . start profiler <number> . visit coffee page via navbar <number> . visit home page via navbar <number> . boom error # # # how often does this bug happen ? sometimes # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 2 f8f60ca8 # # # error message ( automated ) could not find node with id "" <number> "" in commit tree # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) ` ` ` text commitrankedautosizer <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> div div div settingsmodalcontextcontroller <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> profiler_profiler <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> errorboundary_errorboundary <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> : <number> div div themeprovider <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> portaledcontent <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> div div div themeprovider <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> schedulingprofilercontextcontroller <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> profilercontextcontroller <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> treecontextcontroller <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> settingscontextcontroller <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> modaldialogcontextcontroller <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> devtools_devtools <user> - extension :// 8 4 9 4 5 e53 - 7 ac8 - <number> - 9 da2 - ed4bcec5b8a4 / build / main . js : <number> <time> ` ` ` # # # github query string ( automated ) ` ` ` text <url> not find node with id in commit tree in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] : cdn - based site not working # # # website or app <url> # # # repro steps dev tools not working in ff or chrome , says "" this page does not appear to be using react "" . react is included via cdn as shown on react website <url> ` ` < script crossorigin = "" anonymous "" src = "" <url> ` ` web console on said page says : ` ` download the react devtools for a better development experience ` ` # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] profiler tab does not show up in devtools # # # website or app <url> # # # repro steps <number> . open [ this codesandbox ] ( <url> <number> . open the app in new window <number> . open profiler tab of the react devtools _ ( ver <number> . <number> - 2 f8f60ca8 ) _ <number> . see no scheduling profiler icon < img width = "" <number> "" alt = "" image "" src = "" <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 2 f8f60ca8 # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"react <number> bug : hydration mismatch if empty string is rendered < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> . <number> - beta - 4 ff5f5719 - <number> # # steps to reproduce <number> . render empty string ` reactdomserver . rendertostring ( "" "" ) ` link to code example : <url> original issue : [ ` f9d729e ` (# <number> ) ] ( <url> did some spelunking in the codebase and it seems to me that the reconciler is looking for a hydrateable instance ( <url> but since an empty string will not appear as a text node ( if we just set ` innerhtml = string ` ) , the reconciler thinks there ' s a mismatch . in legacy roots we did not throw but warn * * unless we had an empty string * * : <url> # # the current behavior console error is logged with "" an error occurred during hydration . the server html was replaced with client content "" # # the expected behavior no hydration mismatch just like in react <number>",0
facebook/react,"[ devtools bug ] cannot add node "" <number> "" because a node with that id is already in the store . # # # website or app private localhost # # # repro steps not sure . <repeated> it happened when i recorded a new profile # # # how often does this bug happen ? sometimes # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - e5f486b5a # # # error message ( automated ) cannot add node "" <number> "" because a node with that id is already in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add node because a node with that id is already in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"[ devtools bug ] cannot add child "" <number> "" to parent "" <number> "" because parent node was not found in the store . # # # website or app <url> # # # repro steps hello , i hope you are great . <number> . make a git clone and go to ` 0x0 3 - react_props / task_2 / dashboard / ` directory <number> . install the node_modules using ` npm install ` <number> . then execute ` npm run start ` <number> . and go to http :// localhost : <number> / <number> . you need to install the react developer tools extension for google chrome ( link [ here ] ( <url> <number> . open the chrome devtools by pressing ` f12 ` <number> . now in the tabs of the new window opened by pressing ` f12 ` choose the tab ` profiler ` <number> . and click on the ` reload and start profiling ` button to see the error . see an example here and thanks in advance : [ react_developer_tools_error ] ( <url> also , i have other extensions just in case you need ! [ image ] ( <url> and in another google chrome profile that i tried , has these extensions ! [ image ] ( <url> # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - 2 f8f60ca8 # # # error message ( automated ) cannot add child "" <number> "" to parent "" <number> "" because parent node was not found in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> add child to parent because parent node was not found in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"named hooks parsing fails for certain code sandbox examples noticed some parsing bugs when writing some example code for react conf . taking this sandbox . <repeated> <url> - - - this fails by loading neither hook : ` ` ` js function example ( { defaultname = "" - "" , defaultlocation = "" - "" } ) { const [ name , setname ] = usestate ( "" - "" ); const [ location , setlocation ] = usestate ( "" - "" ); return ( < div style ={ style } > <div> name : { name } </div> <div> location : { location } </div> </div> ); } ` ` ` - - - even worse , this fails by only loading "" location "" and showing it first ( instead of state ) ` ` ` js function example ( { defaultname = "" - "" , defaultlocation = "" - "" } ) { / / asd const [ name , setname ] = usestate ( "" - "" ); / / asd const [ location , setlocation ] = usestate ( "" - "" ); return ( < div style ={ style } > <div> name : { name } </div> <div> location : { location } </div> </div> ); } ` ` ` - - - this ails by only loading the location hook , but at least the name shows beside the right hook : ` ` ` js function example ( ) { const [ name ] = usestate ( "" - "" ); const [ location ] = usestate ( "" - "" ); return ( < div style ={ style } > <div> name : { name } </div> <div> location : { location } </div> </div> ); } ` ` ` interestingly , changing the order of the hooks _still_ only lets it load ` location ` , although it also still shows it as the second hook ( bug ) . ` ` ` js function example ( ) { const [ location ] = usestate ( "" - "" ); const [ name ] = usestate ( "" - "" ); return ( < div style ={ style } > <div> name : { name } </div> <div> location : { location } </div> </div> ); } ` ` ` - - - this format also only loads "" location "" : ` ` ` js function example ( props ) { const statea = usestate ( null ) ; const name = statea [ <number> ]; const stateb = usestate ( null ) ; const location = stateb [ <number> ]; return ( < div style ={ style } > <div> name : { name } </div> <div> location </div> ); ` ` `",0
facebook/react,"[ devtools bug ] and start profiling "" button is missing on microsoft edge # # # website or app any development url are ok # # # repro steps <number> . open the react developer tools extension on chrome and navigate to the profiler tab . note the presence of the "" reload and start profiling "" button . <number> . open the react developer tools extension on microsoft edge and navigate to the profiler tab . note the absence of this button . i have checked # <number> , and ` document . featurepolicy . allowsfeature ( ' sync - xhr ' ) ` returns ` true ` . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) <number> . <number> # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] cannot remove node "" <number> "" because no matching node was found in the store . # # # website or app <url> # # # repro steps i open chrome developer tools width react - developer - tool to view layout page and : v while i scroll page : v # # # how often does this bug happen ? often # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - e5f486b5a # # # error message ( automated ) cannot remove node "" <number> "" because no matching node was found in the store . # # # error call stack ( automated ) ` ` ` text at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at bridge_bridge . emit ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> at listener ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) ` ` ` # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) ` ` ` text <url> remove node because no matching node was found in the store . in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,[ devtools bug ] : loading / parsing hook names is failing on v4 . <number> # # # website or app reactjs . org # # # repro steps <number> . open a website that uses react . <number> . inspect an element that uses hooks . <number> . attempt to load hook names . <number> . loading hook names always fails,0
facebook/react,[ devtools bug ] and edge show error in console about unrecognized installation on v4 . <number> # # # website or app reactjs . org # # # repro steps <number> . install react devtools v4 . <number> in firefox <number> . load reactjs . org in firefox <number> . open firefox devtools <number> . observe error in console [ image ] ( <url> # # # how often does this bug happen ? every time,0
facebook/react,"standalone devtools splash page unresponsive after client disconnects # # # website or app any client that connects to the standalone devtools # # # repro steps while using the standalone devtools app connect a client to the devtools <number> . disconnect that client and you should be redirected to the introduction page the event listeners are not re - attached to the splash page elements after the client disconnects . the <script> tags that can be copied on click and the "" profiler tab "" link stop working . # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools bug ] could not inspect element with id "" <number> "" . error thrown : cached data for element "" <number> "" not found # # # website or app <url> # # # repro steps attempting to change the line of the code which locks the store in an online game , this usually works but this time it did not # # # how often does this bug happen ? every time # # # devtools package ( automated ) react - devtools - extensions # # # devtools version ( automated ) <number> . <number> - f58bbcf9a # # # error message ( automated ) could not inspect element with id "" <number> "" . error thrown : cached data for element "" <number> "" not found # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) ` ` ` text at inspectedelementcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at suspense at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at inspectedelementerrorboundarywrapper ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at nativestylecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at ownerslistcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingsmodalcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at components_components ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> <time> ) at errorboundary_errorboundary ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at portaledcontent ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at div at div at div at themeprovider ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at schedulingprofilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at profilercontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at treecontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at settingscontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at modaldialogcontextcontroller ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) at devtools_devtools ( chrome - extension :// fmkadmapgofadopljbjfkapdkoienihi / build / main . js : <number> : <number> ) ` ` ` # # # github query string ( automated ) ` ` ` text <url> not inspect element with id . error thrown : cached data for element not found in : title is : issue is : open is : public label : "" component tools "" repo : facebook / react ` ` `",0
facebook/react,"bug : setstate updater called but not rendered , in safari , in concurrent mode < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> . <number> - alpha - 9 1 7 5 f4d15 - <number> # # steps to reproduce minimal reproduction in [ this codesandbox ] ( <url> this issue only appears in safari , including mobile safari . it works fine in chrome and firefox . in order to reproduce , you will need to : <number> . render the app with ` createroot ` in the latest <number> alpha <number> . within an element ' s ` ref ` function , append an iframe to that element using ` appendchild ` * the following steps have been removed after simplifying the reproduction <kiss> ~ ~ <number> . make a state change originating in a message from a youtube embed iframe . i assume the same issue would occur with messages from other cross domain iframes , although i have not tested this . the issue does not <emphasis> appear when making an async state change through ` settimeout ` . ~ ~ ~ ~ <number> . render a tooltip using the "" tippy . js "" library . i have not dug into what inside of tippy is causing this , but commenting out the tippy element resolves the issue . i have confirmed that rendering a simple portal does not <emphasis> reproduce the issue . ~ ~ link to code example # # the current behavior in the example in safari , the updater function passed to ` setstate ` is run ( confirmed with the "" run state updater "" console . log ) . <repeated> but the new state is never passed to the component function , leaving the app hanging with no error message , and displaying "" not done "" . # # the expected behavior in chrome and firefox , the app component updates after the state updater function is called , as expected , displaying "" done "" . - - - thanks for all the wonderful work on react , btw ! it ' s been a lot of fun playing with the new concurrent react features . can not wait to see them hit a stable release !",0
facebook/react,"bug : components inside typescript namespaces cause referenceerror forwarded from <url> by <user> - rusty based on the recommendation of <user> , which stated that this should be considered as a bug in the ` react - refresh ` package . - - - - # # # describe the bug apparently components inside namespaces is not supported . i do not exactly know if the error comes from esbuild or something , but it would nice . the bug is that is not shown as a compilation error . # # # reproduction simply start a ` react - ts ` project with ` $ npm init <user> / app my - vue - app - - template react - ts ` and write the following code : ` ` ` ts namespace lol { export const lol = ( ) ={ return ( <div> <p> some component </p> </div> ); }; } function app ( ) { return ( < div classname = "" app "" > < header classname = "" app - header "" > < lol . lol / > <p> hello vite + react </p> </header> </div> ); } export default app ; ` ` ` # # # system info ` ` ` js system : os : linux <number> ubuntu <number> . <number> lts ( focal fossa ) cpu : ( <number> ) x64 intel ( r ) core ( tm ) i5 - 1 0 2 1 0 u cpu @ <number> . 6 0 ghz memory : <number> mb / <number> gb container : yes shell : <number> - / usr / bin / zsh binaries : node : <number> . <number> - / usr / local / bin / node npm : <date> - / usr / local / bin / npm browsers : chrome : <number> . <number> firefox : <number> . <number> ` ` ` used package manager : npm # # # logs i get the following runtime error : ` ` ` js app . tsx : <number> uncaught referenceerror is not defined at app . tsx : <number> at app . tsx : <number> ` ` ` i suppose it should be a compilation error ?",0
facebook/react,"error : "" cannot read property ' length ' of undefined "" describe what you were doing when the bug occurred : <number> . just trying to profile an react native app [ screenshot_2021 - <number> - 1 6 _07 - <number> - <number> ] ( <url> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - please do not remove the text below this line - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - devtools version : <number> . <number> - 3 a8c04e3b2 call stack : at jc ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at ii ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at kl ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at ns ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at is ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at os ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <time> <number> ) at gs ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> : <number> ) at w ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at messageport . a . port1 . onmessage ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) component stack jc ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at div at div at fi ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at hi ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> at div at div at lu ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at en ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at jn ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at ji ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> ) at nd ( / nix / store / dhc43b6q83i2d842ry36ydnwck64wlyc - react - native - debugger - <number> . <number> / share / resources / app . asar / node_modules / react - devtools - core / dist / standalone . js : <number> <time> <number> )",0
facebook/react,[ devtools bug ] resolution throws fetch failure # # # website or app n / a # # # repro steps have a webpack project that uses a domain mapped to your local ip such as ( appx . whenidev . net ) in my case that ' s served with https try to resolve hook names check console and observe the million errors <url> shows my console # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_,0
facebook/react,"bug : maximum call stack size exceeded ( react devtools ) i encountered the same issue as # <number> but using ` react - devtools ` as a stand - alone app instead of from the the browser . the bottom line is that the profiler becomes unresponsive after any interaction with a heavily loaded react page . react version : * react : <number> . <number> * reactdom : <number> . <number> * react devtools : <number> . <number> # # steps to reproduce <number> . attach a react - devtools stand - alone ( ` yarn run react - devtools ` ) to a session <number> . start profiling <number> . do something on your app that would cause a huge number of updates <number> . the profiler stops functioning # # diagnostics i actually went through and found out the origin of the issue , however i am not sure what would be the best approach to fix it . it seems the the origin is a ( very ) big incoming message : < img width = "" <number> "" alt = "" image "" src = "" <url> that eventually causes a maximum call stack exceeded error : < img width = "" <number> "" alt = "" image "" src = "" <url> coming from ` util . js : <number> ` : ` ` ` ts export function utfdecodestring ( array : array <number> <sad> string { return string . fromcodepoint ( . <repeated> array ) ; } ` ` ` and interestingly enough , doing spread operator with an array with <number> elements actually causes a ` maximum call stack size exceeded ` error 😄 i tried replacing the code above with the following replacement and it seems to work : ` ` ` ts export function utfdecodestring ( array : array <number> ) { return array . map ( c => string . fromcodepoint ( c ) ) . join ( "" "" ) } ` ` `",0
facebook/react,"[ devtools ] support providing the number of components above selected or "" depth "" # # # website or app <url> # # # context while implementing appium e2e tests we found this limitation <url> i am trying to figure out how to solve this and understand if my changes are reducing the number of layers above a certain component # # # how often does this bug happen ? sometimes # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",0
facebook/react,"[ devtools ] manifest version <number> is deprecated # # # website or app <url> # # # repro steps use latest react devtools with electron ( chromium ) ( <number> . <number> / chromium <number> ) ` ` ` ( node : <number> ) extensionloadwarning : warnings loading extension at . / node_modules / electron - devtools - vendor / extensions / react - developer - tools version <number> is deprecated , and support will be removed in <number> . see <url> for more details . ` ` ` # # # how often does this bug happen ? every time # # # devtools package ( automated ) _no response_ # # # devtools version ( automated ) _no response_ # # # error message ( automated ) _no response_ # # # error call stack ( automated ) _no response_ # # # error component stack ( automated ) _no response_ # # # github query string ( automated ) _no response_",1
facebook/react,"bug : react - devtools not working inside react based chrome extensions react - devtools not working inside react based chrome extensions react version : <number> . <number> # # steps to reproduce <number> . install react - devtools extension in chrome <number> . git clone <url> <number> . cd into directory <number> . yarn install <number> . yarn build <number> . open chrome extensions page <number> . change to developer mode <number> . load unpacked , point to the directory build within chrome - extension - boilerplate - react directory <number> . click on react dev tools extension <number> . the following text is displayed "" this is a restricted browser page . react devtools cannot access this page . "" <number> . when inspecting the page , the tabs components and profiler are not shown link to code example : <url> # # the current behavior <number> . when clicking on the react devtools chrome extension : "" this is a restricted browser page . react devtools cannot access this page . "" <number> . also when inspecting the pages of the chrome extension , the tabs components and profiler are not shown # # the expected behavior <number> . when clicking on the react devtools chrome extension devtools recognize that the page is using react <number> . when inspecting the pages of the chrome extension , the tabs components and profiler are shown and populated",1
facebook/react,"suggestion : show hoc names in profiler ( deleted template as this is a suggestion , not a bug . ) the dev tools helpfully extracts hoc names and shows them in the components tree . [ example ] ( <url> [ image ] ( <url> however , it does not give the same treatment to components in the profiler in large trees , it is very confusing to see two components with the same name , so it would be useful to show the hoc name here as well . as a workaround for now , users can click through to the "" components "" tab from the profiler , when a component is selected in the profiler flamegraph , to see this extra information .",1
facebook/react,"add https support to standalone devtools i notice that the standalone react - devtools use http instead https like ` "" < script src = "" <url> ( [ src code ] ( <url> my website is always https , so it will get broken because i cant change it to http if it ' s in ` iframe ` ( it ' s diffcult to change the host environment / website protocol ) . i am not familar with the react - devtools implementations , maybe something cause it can only use http to open the server , happy to hear the details , thanks react - devtools",1
facebook/react,improve ux of finding full ` key ` value # # the current behavior the full value of the ` key ` is very difficult / impossible to find and use in the interface of the react devtools . [ kapture <number> - <number> - <number> at <number> <number> <number> ] ( <url> only managed to find it by accident <sad> # # the expected behavior the ` key ` is visible in the props list to the right . # # # detailed proposal as mentioned below in <url> add a light divider and new section in the props panel to the right . potentially also add a question mark that shows an explanation about the fact that things in this section are not really props . ref ( original implementation ),1
facebook/react,"expose api like ` createstyles ` for converting style object to css string # # feature request provide api on react - dom to convert style object to css string . the api could be used to build dynamic css easily . # # # approach <number> ` ` ` js import { createcss } from ' react - dom ' const inlinestylestring = createcss ( { overflow : ' hidden ' , display : ' - webkit - box ' , webkitlineclamp : <number> , } ) return <style> { ` . clamp - text { ${ inlinestylestring } } ` } </style> ` ` ` # # # approach <number> another approach is to only map the key and value from the original style object , and let user play with it . ` ` ` js import { createstyles } from ' react - dom ' / / return a object with key - value pairs of css rules const csstyleobject <elongated> = createcss ( { webkittransform : ' scale ( <number> ) ' , } ) / / return { ' - webkit - transform ' : ' scale ( <number> ) ' } const inlinestylestring = object . keys ( csstyleobject <elongated> ) . reduce ( ( serialized , key ) => { serialized + = ` ${ key } return serialized } , ' ' ) return <style> { ` . clamp - text { ${ inlinestylestring } } ` } </style> ` ` ` # # why see other react styling library like * radium <emphasis> * , the way to build css is quite similar with react inline style if they need anything aligned with react like browser prefix such as ` webkit ` or detect the unit less number for some special rule such as ` line - height ` , they have to re - implement the logic . the style object in react is quite convenient , but it ' s can only used for inline style . hope react team could consider to expose it in the react - dom . might not the origin function name , but the same functionality .",1
facebook/react,profiler should highlight host components ( e . g . dom elements ) on mouseover feature request from a devtools user at faceook if i mouse over a node in the flame graph if you can highlight it in the view like the inspector that would be really amazing,1
facebook/react,"adding visible state to suspense fallback component to enhance css transitions . < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature i suppose . * * what is the current behavior ? * * suspense fallback component flashes on and immediately unmounts ( flashes off ) when fetching is complete . see similar discussions [ here ] ( <url> and [ here ] ( <url> * * what is the expected behavior ? * * it would be ideal to add better transitions to the fallback component when it mounts and unmounts , but doing so requires using something like [ transitiongroup ] ( <url> or [ framer motion ] ( <url> which require a prop to listen to know when to mount and unmount . if we could somehow have the fallback component receive some kind of state from suspense on when it is mounting and unmounting the fallback component , that would be great .",1
facebook/react,"make it easier to debug ( undefined components ) in production * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * so for whatever reason , terser / minification causes a bug where one of my components is undefined during render . what i get is the standard production mode minified error . for some reason this time , i can not seem to do any <emphasis> of the following : <number> . see any stack information for the component ( react just says "" something somewhere is undefined "" ) <number> . set a breakpoint on the error point ( for some reason with webpack + devtool sourcemap , chrome is not letting me do a mid - line breakpoint at any place above the error ) <number> . disable reacts error catching temporarily so i can pause on the actual error <number> . use a development version of react with any ease but with the prod settings ( i tried turning off both process . env . node_env checks but then you get an error ` it is not supported to run the profiling version of a renderer ( for example , react - dom / profiling ) without also replacing the scheduler / tracing ) ` a big upgrade here would be to fix all of these ( except <number> , which is either a webpack or chrome bug ) . can we get better stacks in production mode ? that ' s the ideal . that with number <number> would be the most helpful : a query like ` ? disableniceerrors = true ` that prevents react from catching / re - throwing the error later would make it so much easier . as it is now , it ' s incredibly painful to debug ( already an hour into it and without the breakpoints working on minified react it ' s hard to really even figure out where besides manual code commenting ) . edit fifth would be source maps for react itself in production bundles which may work .",1
facebook/react,"add "" search "" functionality to profiler graphs < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * it ‘ s hard for me to find a component in the profiler tab * * what is the expected behavior ? * * add a search function , just like components tab",1
facebook/react,"react - devtools : tiny feature request ( copy to clipboard related ) hey guys , great job with the new devtools 💯 perhaps this request can be put in the backlog for a future release as i think it could be quite useful and could save a few steps for developers . * * what is the current behavior ? * * - copying data to clipboard stringifies all key - value pairs of an object - when the keys ' values happen to be objects or arrays , the values are given in constructor form rather than seeing the contents of that object / array this is what was copied : < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> this is a pasted version in vscode : < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> * * what is the desired behavior ? * * - when i click on "" copy to clipboard "" in react - devtools , my copied object ' s data _keys_ and _values_ are in an unstringified format , or at least , i am presented the option to have this copied in an unstringified format - the _values_ of each key is readable , e . g the value is an object , i can see the expanded object and all its key - value pairs clearly as shown here ( this is logged into chrome console from react - devtools ) < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url>",1
facebook/react,"devtools : impossible to debug firefox webextension moz - extension : pages due to strict csp < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * * feature request * original issue is : <url> * there are more details . * mozilla ' s bugzilla * * what is the current behavior ? * * the react - devtools toolbar button does not light up and clicking on it says "" this page does not appear to be using react "" . this is probably since extensions are not allowed to inject scripts into other extensions ' pages . * * what is the expected behavior ? * * the react - devtools toolbar button should light up and the addon should be able to debug the page * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * this is still reproducible * firefox v68 ~ * react devtools v4 . <number> * react v16 . <number>",1
facebook/react,"devtools to save inspected values as global variable ( as it was in previous version ) hi , i really like new dev tools ( <number> . <number> ) , but i would like to request one useful feature . in previous version it was possible to save inspected value ( prop / state / context ) and its parts as a global variable using context menu - > store as global variable , so it can be easily be accessed through console using ` $ tmp { n } ` . in current version this is behaviour was replaced be creating new "" bug "" button which will just print all values in console . unfortunately it ' s hard to navigate through this object , because $ _ in console will return undefined . and in order to access it you need to expand group , find desired property and open context menu - > store as global variable . it would be perfect if you combine these <number> approaches so it would be possible to both print values using "" bug "" button and opening context menu directly in react dev tools panel wihtout need of intermediate step . thanks",1
facebook/react,"new react developer tools does not clearly indicate empty object or array * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug / unexpected behavior . * * what is the current behavior ? * * when an object or array is empty , there ' s no arrow to expand and see that it ' s empty , nor is there an ` ( empty ) ` indication . initially , i was concerned that i could not expand any object or array from the new react devtools due to this . [ screen shot <number> - <number> - <number> at <number> <number> <number> pm ] ( <url> * * what is the expected behavior ? * * i would expect to either be able to expand the empty object , or to see ` ( empty ) ` next to the non - expandable object . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * chrome version : <number> . <number> ( official build ) ( <number> - bit ) react developer tools version ( <date> ) [ reference discussion on twitter ] ( <url>",1
facebook/react,"new react devtools can not access immutable . js objects ? < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * when the state or props are formed by immutable . js objects , react devtools cannot expand it nor copy to temporal variable anymore . ! [ screenshot from <number> - <number> - <number> <date> ] ( <url> * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * <url> * * what is the expected behavior ? * * be able to inspect the value of the immutable object or at least , copy it into a temporal variable . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number> . <number> chrome version <number> . <number> ( official build ) ( <number> - bit )",1
facebook/react,"devtools in production environment < - - note : if the issue is about documentation or the website , please file it at - - > ! [ <number> - <number> - 2 9 _13 - <number> ] ( <url> * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i think the production environment , react devtools you should not show any information about the state or components . similar to redux devtools . * * what is the current behavior ? * * just now i can edit some information with react devtools in the production environment",1
facebook/react,"act ( ) should warn in testing frameworks besides jest * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature request * * what is the current behavior ? * * the warnings for missing act ( ) warnings around updates only happen in jest . * * what is the expected behavior ? * * we should support other test runners / frameworks as well ( like jasmine , karma , etc ) * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number> . <number> +",1
facebook/react,"allow to disable style hydration missmatch warning some background dealing with inline styles ( e . g . radium ) , ssr and caching of ssr results , you might run into problems because of differences in vendor prefixes . best tradeof is to render always with all vendor prefixes on the server . but this will lead to style missmatches on hydration . you can use ` suppresshydrationwarning ` , but then you have to add this property to every element that receives these styles , which is not practical . * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * style missmatch causes a warning on development . * * what is the expected behavior ? * * you can set a global flag to supress style missmatch warnings * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number>",1
facebook/react,useref eslint rule proposal proposal : ensure that all reads from a ` ref ` use ` . current ` . ` ` ` js export function mycomponent ( ) { const isactiveref = useref <boolean> ( false ) ; / / proposal should be a linting violation if ( isactiveref ) { console . log ( ' will always be true ' ); } / / reads need to be done from . current if ( isactiveref . current ) { console . log ( ' correct usage ' ); } } ` ` ` i often find myself doing boolean checks based on the ` . current ` value of a ` ref ` . i am paranoid that if i leave the ` . current ` off then i am creating a bug,1
facebook/react,"hook equivalent for ` getsnapshotbeforeupdate ` < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * there is no hook based equivalent for ` getsnapshotbeforeupdate ` . the docs state : > our goal is for hooks to cover all use cases for classes as soon as possible . there are no hook equivalents to the uncommon getsnapshotbeforeupdate and componentdidcatch lifecycles yet , but we plan to add them soon . * * what is the expected behavior ? * * there is a hook based equivalent for ` getsnapshotbeforeupdate ` , maybe something like : ` ` ` js function scrollinglist ( props ) { const lengthref = react . useref ( <number> ); const listref = react . useref ( null ) ; const prevheight = react . usesnapshot ( ( ) => { if ( lengthref . current < props . list . length ) { const list = listref . current ; return list . scrollheight - list . scrolltop ; } }); react . useeffect ( ( ) => { lengthref . current = props . list . length ; } , [ props . list . length ] ); react . useeffect ( ( ) => { if ( prevheight ! = null ) { const list = listref . current ; list . scrolltop = list . scrollheight - prevheight ; } } , [ prevheight ] ); return ( < div ref ={ listref } >{/* . <repeated> */}</ div > ); } ` ` ` this code probably is bug - ridden and not the best use of hooks but you get the idea . i ’ d like to know if this feature is planned or on the roadmap . <number> . what the proposed api will be . <number> . if anyone is working on this . sorry , if this is being tracked somewhere and i haven ’ t seen it . i ’ m planning an intense component which will use ` getsnapshotbeforeupdate ` and i ’ d love some guidance about the future of this lifecycle method . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react v16 . <number> and later . all browsers and oses .",1
facebook/react,"[ eslint - plugin - react - hooks ] add option to require functions from core hooks in dependencies < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * the ` react - hooks / exhaustive - deps ` will currently accept either ( and fix neither ) of the following : ` ` ` javascript / / scenario a : function returned by core hook is not specified as a dependency . const [ value , setvalue ] = usestate ( initialvalue ) ; const toggle = usecallback ( ( ) => setvalue ( v => ! v ) , []); ` ` ` ` ` ` javascript / / scenario b : function returned by core hook is specified as a dependency . const [ value , setvalue ] = usestate ( initialvalue ) ; const toggle = usecallback ( ( ) => setvalue ( v => ! v ) , [ setvalue ] ); ` ` ` * * what is the expected behavior ? * * if we add the following to our ` . eslintrc . js ` ` ` ` / / introduces a ` requirecorefunctions ` config option . ' react - hooks / exhaustive - deps ' : [ ' error ' , { requirecorefunctions } ] ` ` ` then the rule should fail in scenario a , and fixing should result in scenario b . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * n / a",1
facebook/react,"eslint - react - hooks we enforce to use react . usememo if there is no state hooks ? <number> . regarding the performance optimization , should we always use react . usememo in case there is no state hooks inside a function component ? <number> . if the answer is yes , can we use some eslint rules to make sure everyone do it ?",1
facebook/react,"collapse forwardref and other wrappers in react error stacks * feature <emphasis> * * * what is the current behavior ? * * with a ui kit that uses forwardrefs , i get error messages like this : [ image ] ( <url> * * what is the expected behavior ? * * it would look a lot better if forwardrefs were a bit less obtrusive , and if they picked up the functions displayname rather than just the name of the function they wrap . in our ui kit we have a pattern like : ` ` ` const view = forwardref ( function uiview ( ) { return < div / > } ) view . displayname = ' somedisplayname ' ` ` ` for some reason it ' s not showing that , just showing the inner one . further the "" bigness "" of forwardref ( ) makes it hard to see visually when scanning . perhaps something more like this would help : ` ` ` warning : encountered two children with the same key , ` confluence ` . keys should be unique so that components maintain their identity across updates . non - unique keys may cause children to be duplicated and / or omitted — the behavior is unsupported and could change in a future version . in div ( created by forwardref ( gloss ) ) in gloss ( forwardref ) in gloss ( forwardref ) ( created by onboardmain ) in div ( created by gloss ( forwardref ) ) in gloss ( forwardref ) in gloss ( forwardref ) ( created by sliderpane ) ` ` ` further , the ` created by ` information is often more useful to me , but it ' s never aligned nicely . could do something like : ` ` ` warning : encountered two children with the same key , ` confluence ` . keys should be unique so that components maintain their identity across updates . non - unique keys may cause children to be duplicated and / or omitted — the behavior is unsupported and could change in a future version . in div ( created by forwardref ( gloss ) ) in gloss ( forwardref ) from onboardmain : in gloss ( forwardref ) from gloss ( forwardref ) : in div in gloss ( forwardref ) from sliderpane : in gloss ( forwardref ) ` ` ` all together , if it would pick up displaynames , the stack would be far more readable for me : ` ` ` warning : encountered two children with the same key , ` confluence ` . keys should be unique so that components maintain their identity across updates . non - unique keys may cause children to be duplicated and / or omitted — the behavior is unsupported and could change in a future version . in div ( created by row ) in view ( forwardref ) from onboardmain : in row ( forwardref ) from col ( forwardref ) : in div in grid ( forwardref ) from sliderpane view ( forwardref ) ` ` `",1
facebook/react,"shallow renderer does not support react . memo * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * in normal rendering , you can memoize a class - based component : <url> with the shallow renderer , it seems like you can not this might be blocking <url> in which tests are failing with ` cannot call a class as a function ` . ( it ' s tough to repro stuff with the shallow renderer )",1
facebook/react,"simultaneous key events in effect handled out of order * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * report a bug . * * what is the current behavior ? * * i have an app that ' s registering event listeners for ` window ` ' s key events ( via ` useeffect ` ) . those event listeners are triggering state updates ( via ` usestate ` ) . i think i have found a bug where simultaneous key events occurring in the same frame ( whether down or up ) will be handled out of order , causing state to becoming out of sync . take the following simple app ( <url> i have kept this as keyup only for simplicity . ` ` ` function app ( ) { const [ keys , setkeys ] = usestate ( []); console . log ( ' app ' , keys ) ; const onkeyup = function ( event ) { console . log ( ' onkeyup ' , event . key , keys ) ; setkeys ( [ . <repeated> keys , event . key ] ); }; useeffect ( function ( ) { console . log ( ' effect ' , keys ) ; window . addeventlistener ( ' keyup ' , onkeyup ) ; return function ( ) { console . log ( ' removing event listener ' , keys ) ; window . removeeventlistener ( ' keyup ' , onkeyup ) ; }; }); return <p> { keys . join ( ' , ' ) } </p> ; } ` ` ` if i press down any two keys , e . g . the "" q "" and "" w "" keys , and then release them at precisely the same time , the following happens : - the ` keyup ` event listener for ` w ` is called , which in turn calls ` setkeys ` with ` [ ' w ' ] ` - ` app ` is re - rendered with ` keys = = = [ ' w ' ] ` - the ` keyup ` event listener for ` q ` is called , which in turn calls ` setkeys ` with ` [ ' q ' ] ` - the effect ' s cleanup function is called , removing the event listener with ` keys = = = [ ] ` - the effect is run again , the event listener being added with ` keys = = = [ ' w ' ] ` - ` app ` is re - rendered with ` keys = = = [ ' q ' ] ` - the effect ' s cleanup function is called , removing the event listener with ` keys = ==[ ' w ' ] ` - the effect is run again , the event listener being added with ` keys = = = [ ' q ' ] ` this results in ` keys = = = [ ' q ' ] ` . the render with ` w ` has been lost . with three keys , only two keys are reliably shown . four keys - only two are reliably shown . if i add another ` usestate ` call , the first ` usestate ` has no issues - all keys are reliably detected . see <url> function app ( ) { const [ keys , setkeys ] = usestate ( []); const [ dummy , setdummy ] = usestate ( ' foo ' ); console . log ( "" rendering app "" , keys ) ; const onkeyup = function ( event ) { console . log ( "" onkeyup event received "" , event . key , keys ) ; setkeys ( [ . <repeated> keys , event . key ] ); setdummy ( ' foo ' ); }; useeffect ( function ( ) { console . log ( "" adding event listener "" , keys ) ; window . addeventlistener ( "" keyup "" , onkeyup ) ; return function ( ) { console . log ( "" removing event listener "" , keys ) ; window . removeeventlistener ( "" keyup "" , onkeyup ) ; }; }); return ( <div> <p> keyups received :</ p > <p> { keys . join ( "" , "" ) } </p> < button onclick ={() => setkeys ( [ ] ) } > reset </button> </div> ); } ` ` ` * * what is the expected behavior ? * * i would expect the final state array to contain all keys released , in order . there are a few workarounds for this issue ( e . g . passing a function to ` setstate ` to retrieve the current value instead of using the rendered value ) , but from the documentation it seems that is an escape hatch for use when the effect ' s callback is not renewed on each state change , and should not be necessary in this case ( unless i have misunderstood ) . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * it happens on both versions that support hooks - ` <number> . <number> - alpha . <number> ` and ` <number> . <number> - alpha . <number> ` . this is on chrome / safari / firefox on macos mojave .",1
facebook/react,"allow the same dom node to use both a callback and a refobject in its ref prop * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * the ` ref ` attribute passed to a dom node can be either a callback or a ` refobject ` , but not both . sometimes , that ' s exactly what ' s required : for example , a library like [ react - pose ] ( <url> demands ref forwarding to work with a react component , but you ' d also like to retain a reference to the _same_ parent dom node within that component itself for a different reason . it ' s often not possible to nest dom nodes to achieve a similar thing using two different ref attributes as that breaks layout . here ' s a link to a naive attempt to achieve this i am not surprised this does not work as there ' s no reason for the parent ref callback to fire , but i do not know how else to go about it . * * what is the expected behavior ? * * the callback provides the component with its own reference to the parent dom node , whilst also providing it to the parent component via the passed ` refobject ` .",1
facebook/react,"react . suspense provide a lifecycle so components can handle the ` display : none ` removal * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * it ' s a feature . * * what is the current behavior ? * * react . suspense mounts its children with a ` display : none ` style if a promise is thrown . once the thrown promise is resolved , react removes the ` display : none ` style . * * what is the expected behavior ? * * the children components have no easy way to know when the ` display : none ` style is removed by react . this is problematic when one child component needs to read from the dom layout to correctly display its elements . most people wait for the ` componentdidmount ` callback to trigger , but because the element is ` display : none ` , it can not read any value from the dom layout . the issue was discovered in <url> i believe that react should provide a lifecycle so the children components know when they are visible , that it ' s safe to do layout computations . the best workaround i am aware of it to use the [ intersection observer api ] ( <url> but it requires a polyfill on ie <number> and safari . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * version",1
facebook/react,"[ hooks ] proposal : expose info about current component for custom hooks < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * the core built - in hooks – ` useref ` , ` usememo ` , etc . – rely on internal react state which is not exposed , namely the current rendering component . this means that these hooks cannot be implemented in user - land . similar hooks cannot be implemented either . i am proposing adding a built - in hook which would provide information about the current rendering component . this would enable more advanced hooks to be implementable in user - land . i have a use case which is a perfect example . i need a hook similar to ` usememo ` , but where the computed value is shared across all components of the same type . i ’ m calling it ` usesharedmemo ` . the ideal api would look something like this : ` ` ` typescript const component = ( { cachekey } ) => { const value1 = usesharedmemo ( ( ) => /* expensive computation <number> */ , [ cachekey ] ); const value2 = usesharedmemo ( ( ) => /* expensive computation <number> */ , [ cachekey ] ); return < > { value1 } { value2 } </>; }; ` ` ` in the code above , every instance of ` component ` would get the same values for ` value1 ` and ` value2 ` , provided ` cachekey ` is the same . when ` cachekey ` changes , the two values would recompute once and the new values would be returned to all instances as they re - render . ( the actual use case in my app is styles that need to update only when the theme changes . ) i have a [ hacky implementation ] ( <url> of this hook that works , but it requires changing the api to the following : ` ` ` typescript const usesharedmemo = createusesharedmemo ( ); const component = ( { cachekey } ) => { const ref = react . useref ( ); const value1 = usesharedmemo ( ref , ( ) => /* expensive computation <number> */ , [ cachekey ] ); const value2 = usesharedmemo ( ref , ( ) => /* expensive computation <number> */ , [ cachekey ] ); return < > { value1 } { value2 } </>; }; ` ` ` for this to work , the [ implementation ] ( <url> has to keep a counter of calls that resets every time a component ’ s render call starts or ends . this would be trivial if there were a way to know which component is currently rendering . since there is no way , the implementation has to make up for it by requiring a ` ref ` be passed in . since it has no information about the type of the current component , it also requires that a ` usesharedmemo ` “ instance ” be created in the component definition ’ s enclosing scope . worse , the implementation uses ` uselayouteffect ` to detect when the render is done , which might break with concurrent mode or with future react changes . * * what is the expected behavior ? * * if react provided information about the current rendering component , the implementation of ` usesharedmemo ` would be much easier and less brittle . a possible solution is a hook like the following : ` ` ` typescript const [ currenttype , currentref ] = react . usecurrentcomponent ( ); ` ` ` with this information , we can implement the ideal api above and we do not have to rely on ` uselayouteffect ` let values = new weakmap ( ); let cachekeys = new weakmap ( ); let lastref = null ; let callindex = <number> ; function usesharedmemo ( fn , keys ) { const [ currenttype , currentref ] = react . usecurrentcomponent ( ); if ( currentref ! = = lastref ) { callindex = <number> ; } const index = callindex ; callindex + + ; const typevalues = values . get ( currenttype ) || []; const typecachekeys = cachekeys . get ( currenttype ) || []; if ( ! typevalues [ index ] || ! comparekeys ( keys , typecachekeys [ index ] ) ) { typevalues [ index ] = fn ( ); typecachekeys [ index ] = keys ; values . set ( currenttype , typevalues ) ; cachekeys . set ( currenttype , typecachekeys ) ; } return typevalues [ index ] ; } ` ` ` ( note that i ’ m treating ` currenttype ` and ` currentref ` as opaque values , so for my purposes it doesn ’ t matter if they are the actual type and an actual ref to the component instance . i imagine having them be accurate would be a more powerful api , but the implementation might require them to be opaque values . ) p . s . - a common use case that would benefit from ` usesharedmemo ` is ` usecallback ` . <percent> of the time callbacks are identical across components of the same type . it ’ s wasteful not to share the cache . * demo <emphasis> * <url>",1
facebook/react,"[ scheduler ] add support for delayed scheduling of callbacks . has the react team considered adding the ability to specify a time delay when scheduling callbacks on scheduler . this would be useful to enable using scheduler as a general scheduling solution in a js environment , removing the need to use and manage settimeouts / setinterval calls .",1
facebook/react,provide a way to pass context to rendertostaticmarkup on the client see <url> and <url> this accidentally worked for a few releases but was a bug . however we might want to consider actually supporting this with an opt - in api .,1
facebook/react,"react . lazy does not allow retrying a rejected promise * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * it can be seen as a feature or a bug , depending on angle . let us say it ' s an enhancement to how ` lazy ` works . * * what is the current behavior ? * * when using ` react . lazy ` , if the given promise rejects while trying to asynchronously load a component , it ' s no longer possible to retry loading the component chunk because ` lazy ` internally caches the promise rejection . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * this does not seem to work great in codesandbox because it ' s using service workers , which get in the way when simulating offline mode , yet this small app illustrates the issue * * what is the expected behavior ? * * a promise rejection should not be cached by ` lazy ` and another attempt to render the component should call the function again , giving it the chance to return a new promise . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * afaik all version of react that include ` lazy ` .",1
facebook/react,"setstate / dispatch 2 nd arg callback or emiteffect ( ) use case # feature request # # current behavior usestate / usereducers hook ' s updater / dispatch functions do not expose a way to execute code _after_ the update has been made . # # expected behavior usestate or usereducer hooks expose some way to locally execute the equivalent of inline useeffect / didupdate etc . ( to allow for overriding default side effect behavior ) ( e . g . emiteffect ( ( ) => . <repeated> ) ) . # # use case formik exposes <number> props which control when form validation occurs : ` validateonchange ` and ` validateonblur ` . when ` validateonchange ` set to ` true ` , form validation will run whenever ` handlechange ` , ` setfieldvalue ` , or ` setvalues ` are called ( these fns all update form ` values ` ) . similarly , when ` validateonblur ` is ` true ` , validation will also run whenever ` handleblur ` , ` setfieldtouched ` , and ` settouched ` are called ( these fns all update the ` touched ` state of the form ) . the reason that formik does not centralize orchestrating validation logic into ` componentdidupdate ` ( i . e . run validation whenever either ` this . state . values ` or ` this . state . touched ` changes ) is to allow for local overrides in custom input components . for example , often times in a 3 rd party input component ( e . g . like airbnb ' s rheostat ( <url> the value and touched state need to update together because there is not a real "" blur "" event for the component or there is not a prop for it . with formik , you get around this by updating the field ' s value and touched state imperatively but override the validation behavior to only run once . to do this , formik ' s current non - hooks api exposes an extra parameter to the ` setfieldvalue ` and ` setfieldtouched ` methods which allow you to opt out of running validation after the update is made . internally this looks like : ` ` ` js setfieldvalue ( name , value , shouldvalidate = true ) { this . setstate ( prevstate => setin ( prevstate . values , name , value ) , ( ) => { if ( this . props . validateonchange & & shouldvalidate ) { this . validateform ( this . state . values ) } } ) } setfieldtouched ( name , touch = true , shouldvalidate = true ) { this . setstate ( prevstate => setin ( prevstate . touched , name , touch ) , ( ) => { if ( this . props . validateonblur & & shouldvalidate ) { this . validateform ( this . state . values ) } } ) } ` ` ` if a callback was supported by either ` usereducer ` ' s ` dispatch ` or ` usestate ` update fn , formik could maintain its current api footprint and allow for the following code to work as expected const customrangedinput = ( props ) => { const formik = useformikcontext ( ); function handlechangevalue ( value ) { / / set the value formik . setfieldvalue ( props . name , value , false /* avoid normal validation logic */) / / mark the field as touched formik . setfieldtouched ( props . name , true ) } return < rheostat onvaluechange ={ handlechangevalue } min ={ <number> } max ={ <number> } values ={[ <number> , <number> ] } />; } ` ` ` however , with the current hooks api ' s there is not a way for me to expose this to users , since i have to lift update the validateonchange / validateonblur validation logic to ` useeffect ` . in my current formik x hooks pr , this looks like ` ` ` js react . useeffect ( ( ) => { if ( ! didmount . current & & ! <repeated> validateonchange & & ! state . issubmitting ) { validateform ( state . values ) ; } } , [ state . values , validateonchange , state . issubmitting ] ); react . useeffect ( ( ) => { if ( ! <repeated> didmount . current & & ! <repeated> validateonblur & & ! state . issubmitting ) { validateform ( state . values ) ; } } , [ state . touched , validateonblur , state . issubmitting ] ); ` ` ` this will execute whenever ` state . values ` or ` state . touched ` change , which is usually what people want <percent> of the time . however , i do not know / see a way to make this compatible with the old api ( where you can locally override validation ) . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number> . <number> - alpha",1
facebook/react,"<option> and <textarea> elements should be able to contain components that return strings and render their output correctly < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature request * * what is the current behavior ? * * if you use a component that returns a string inside an option or textarea element , the component will be rendered as ' [ object object ] ' * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * <url> * * what is the expected behavior ? * * the string returned by the component should be rendered as the elements innerhtml . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * this was working accidentally in react v16 . <number> - v16 . <number> but was apparently buggy and crash prone . it no longer works at all in react v16 . <number>",1
facebook/react,"more helpful interaction for "" react does not recognize the ' propname ' prop on a dom element "" * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * when you pass a unknown prop to a dom element - common when you pass ` { . <repeated> props } ` to something that turns out to be a div / span / any other dom element rather than a composite component - you get a warning like so : ` ` ` warning does not recognize the ` propname ` prop on a dom element . . <repeated> ` ` ` if the tree is pretty complicated , especially if you are using hocs , it can be very hard to find where this prop has been passed and to which dom element . * * what is the expected behavior ? * * we had a quick muck around with react - dom and logging the dom element that triggers this warning allows you to see the element in the dom and makes it much easier to work out where the prop is being accidentally passed . you can even use the react dev tools to work out exactly which line the component is defined in the code . simply logging the element is obviously not the most elegant way of showing the user where the mistake is , but would it be possible to do _something_ in order to make it quicker to fix mistaken prop passing like this ? * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * all .",1
facebook/react,"support for classlist < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * only ` classname ` exists right now . * * what is the expected behavior ? * * i think adding ` classlist ` property for dom elements would be useful . as far as i understand react fire will drop support for ie11 but even in ie11 , you can add or remove classlist from elements . another idea might be adding support for for array type for ` classname ` ( or future ` class ` , which will make more sense because array ) . if array is passed , ` classlist ` will be used for dom elements . otherwise , ` classname ` is used as usual in the real dom side . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * all versions . i hope this is added in react fire .",1
facebook/react,"accessing reactdebugcurrentframe without using __secret_internals_do_not_use_or_you_will_be_fired * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * request a feature . * * what is the current behavior ? * * i am working on writing a custom react renderer ( <url> and right now i have to use ` react . __secret_internals_do_not_use_or_you_will_be_fired ` in order to access stack information for the current frame in order to display warnings for the developer ( <url> * * what is the expected behavior ? * * i would like to be able to access the stack information for the current frame without worrying for the safety of my employment . is there a better way for me to be doing this ? * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number> . <number>",1
facebook/react,"make possible to get component stack or at least its hash < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature <emphasis> * * what is the current behavior ? * * there is no good way to get the a list of component parents . the only way to do it is to wrap the rendered component to an error boundary , throw a dummy error and pass ` componentstack ` to the rendered component without throwing the error again . ! [ image ] ( <url> unfortunately the idea of hiding thrown errors was refused ( see <url> so this experimental hack is not useful . * * what is the expected behavior ? * * i ' d like to deterministically identify components at dom tree and use this data to assign persistent data to it without using any custom identifiers . for example store visibility state for a specific component at window . localstorage . related to <url>",1
facebook/react,"keyboardevent . repeat is not normalized * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * documentation of syntheticevent claims : "" react normalizes events so that they have consistent properties across different browsers . "" <url> documentation of keyboard events lists ` boolean repeat ` as a supported field : <url> ie11 / edge do not natively support ` repeat ` , but react does not normalize the event to set ` repeat : true ` when a keydown event repeats ( i . e . when a key is held down ) . ( edge has an open bug on this but of course ie11 is abandonware . ) * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . * * tab to to the only div in this repro and hold down a key : <url> bug alert does not appear in ie11 * * what is the expected behavior ? * * an alert dialog showing ' repeat ! ' should appear in any browser that react supports . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * current version of react , any browser which does not natively support ` keyboardevent . repeat ` but ie / edge in particular ( chrome always supported ; ff since <number> ; safari since <number> ) . unknown if this worked in previous versions of react .",1
facebook/react,"react . cloneelement cannot remove existing props * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * a feature . * * what is the current behavior ? * * when an element is cloned with [ react . cloneelement ] ( <url> it ' s possible to add new props or modify existing ones , but not to remove existing props . [ relevant code ] ( <url> example of how it works right now : ` ` ` const element = react . createelement ( "" a "" , { href : "" <url> const newelement = react . cloneelement ( element , { href : undefined } ); console . log ( newelement . props ) ; / / { href : undefined } ` ` ` * * what is the desired behavior ? * * it would be great to add some way to remove props ( passing ` undefined ` as value ? <sad> ` ` ` const element = react . createelement ( "" a "" , { href : "" <url> const newelement = react . cloneelement ( element , { href console . log ( newelement . props ) ; / / { } ` ` ` i guess i could use directly ` react . createelement ` but , afaik , i will have also to worry about special attributes like ` key ` and ` ref ` . i ' d rather not mess with internals . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * i think it has worked this way in all react versions . * * what ' s your use case ? * * i am applying a map transformation of elements recursively and i need to remove some virtual props before passing the real elements for react to render . console shows ` react does not recognize the [ unknownprop ] prop on a dom element ` for those props , i ' d want to avoid that .",1
facebook/react,"setting rendering mode to <surface> component of react - art < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * ` <surface> ` of canvas mode and ` <surface> ` of svg mode cannot be used in a document at the same time . * * what is the expected behavior ? * * two more ` <surface> ` components with each other modes can be used in a document at the same time . currently developers can set only one rending mode globally in react - art , using ` setcurrent ( ) ` of ` art / modes / current ` module . so there is no way to use ` <surface> ` of canvas mode and ` <surface> ` of svg mode in a document together . on the other hand , ` art . js ` internally used in ` react - art ` provides a way to use each other modes together as directly importing their corresponding modules . ( e . g . svg . js for svg mode , canvas . js for canvas mode in ` art . js ` lib ) . i would like to suggest a way to set own rendering mode per instance of ` <surface> ` component by new property ` mode ` . this feature makes ` <surface> ` with canvas mode and ` <surface> ` with svg mode to be used together in a document like the following . ` ` ` javascript const { surface , group , shape } = require ( ' react - art ' ); class testcomponent extends react . component { render ( ) { return ( < react . fragment > < surface mode = "" svg "" width ={ <number> } height ={ <number> } > <group> < shape width ={ <number> } height ={ <number> } / > </group> </surface> < surface mode = "" canvas "" width ={ <number> } height ={ <number> } > <group> < shape width ={ <number> } height ={ <number> } / > </group> </surface> < / react . fragment > ); } }; ` ` ` if ` mode ` property is not set , ` <surface> ` works as canvas mode for compatibility . i have made a pr for this feature to show how to work and use it ([# <number> ] ( <url> and you can check this feature through ` art ` fixture of my pr . feel free to discuss about this feature .",1
facebook/react,"some means of determining component order in hierarchy i apologise for raising this issue again , i am not intending to be annoying or disrespectful by this , but my previous issue # <number> was closed with a suggestion which i believe not does mitigate the feature request . i am simply not aware if i should take the hint and go away , if there ' s a bit of a backlog and i should hang in there , or if it ' s been missed . i am assuming the latter , but beg forgiveness if that is not the case . should you want me to go away i will do so <happy> thanks . i am trying to build a container component and child component , whereby the children can sit anywhere in the hierarchy beneath the container , but know their relative order / index within that hierarchy . my use - case is to build a helper wrapper for css grids , allowing subcomponents to themselves render a "" row "" component which knows it must be the next index , and may or may not progress the row counter for the next "" row "" component found in order . i have looked into two possible avenues - recursing using react . children on the component , which stops when it hits a component without props . children ( e . g . a redux - connect ( ) - ed one ) , and passing some means of counting via context , which fails because it seems the render ( ) methods of the child components is not always called in "" dom order "" . more background here - <url> it would be great to have some feature in react which might allow for this . <user> had previously suggested in # <number> that context could do this with nesting , however i ' d raised the thought that this would give an indication of recursion depth , not relative position .",1
facebook/react,"allow ` ref ` attribute on custom elements * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * creating a custom element with a ` ref ` attribute currently is not possible , because ` react . createelement ( ' my - element ' , { ref } ) ` will interprete the ` ref ` attribute in a special sense . * * what is the expected behavior ? * * like for ` htmlfor ` it would be great if there were an alias that allows creating a ` ref ` attribute on a custom element . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number>",1
facebook/react,"reactis . typeof for non - elements * * what is the current behavior ? * * ` reactis . typeof ` currently only works for element types , it does not allow you to pass a raw ` component ` or ` forwardref ` to know the type . the use case for this is in ` hoist - non - react - statics ` i now need a [ special cases for ` forwardrefs ` ] ( <url> to do this , i will need to know the type of the source and target components , but currently i would need to turn them into elements first . all of the ` reactis . is * ` functions also have this issue since they use the ` typeof ` function internally . ` ` ` js const forwardcomponent = react . forwardref ( ( ) => {}); reactis . typeof ( forwardcomponent ) ; / / undefined reactis . typeof ( react . createelement ( forwardcomponent ) ); / / symbol ( react . forward_ref ) ` ` ` * * what is the expected behavior ? * * ideally i could pass in just the component and get the type of it reactis . typeof ( forwardcomponent ) / / symbol ( react . forward_ref ) ` ` ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * reactis <user> . <number>",1
facebook/react,"callback in react - test - renderer for component changes < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * many react components render multiple times automatically . take a graphql component . first it will render a loading spinner , then the data after it has been fetched . in react - test - renderer , it ' s difficult to get a snapshot to consistently render for these types of components . currently , we set an interval timer and check the component tree to see if the data has loaded and thus rendered . this approach results in a bunch of unnecessary checks and slows down tests because the interval timer will run after the component has been rendered . * * what is the expected behavior ? * * i would expect react - test - render to allow a callback that will be invoked each time any component in the component tree changes , basically after any component ' s ` componentdidupdate ` ran . i would expect an api like import testrenderer from ' react - test - renderer ' ; const testrenderer = testrenderer . create ( < todos / > ); testrenderer . onchange ( ( ) => { / / check todos for whether the data has loaded and do the snapshot } ) ` ` ` this would be useful in react - dom and react - native . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * it ' s a proposal for a new feature , does not affect any existing react versions",1
facebook/react,"expose a way of creating a reacttestinstance for react dom nodes * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i would like to request a new feature . * * what is the current behavior ? * * at the moment there is no way to create an instance of a ` reacttestinstance ` . i would love to be able to do something like const div = document . createelement ( ' div ' ); const componentref = reactdom . render ( < mycomponentundertest / > , div ) ; / / or renderintodocument const testinstance = new reacttestinstance ( componentref ) ; / / now i can run queries using the api of reacttestinstance / / against a component tree that has been fully dom rendered testinstance . findall ( . <repeated> ) testinstance . children . foreach ( ( ) => {}); testinstance . parent ` ` ` * * why ? * * libraries such as [ enzyme ] ( <url> can be used to test react components by [ full dom rendering ] ( <url> and providing an api to find components and get information about them . as far as i know , there is no way of querying the component tree created by ` reactdom . render ` without relying on the internals of react nodes . this means that enzyme , in order to support full dom rendering and it ' s querying api , it has to interact with react nodes directly . this reliance causes problems in enzyme whenever react adds a new node type ( forwardref , contextprovider / consumer for example ) . i have started [ this rfc ] ( <url> that proposes that enzyme uses ` reacttestwrapper ` from ` react - test - renderer ` as a layer on top of react node objects . this allows the library to be decoupled from the internals of react . the solution proposed in the rfc relies on the being able to create a ` reacttestinstance ` from a ` reactdom . render ` component tree . please let me know if this is something you would consider 😄",1
facebook/react,"show culprit in ` cannot update during an existing state transition . <repeated> ` ? * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * * feature . * * * what is the current behavior ? * * we are probably all familiar with the following message . ` ` ` bundle . js : <number> warning : cannot update during an existing state transition ( such as within ` render ` or another component ' s constructor ) . render methods should be a pure function of props and state ; constructor side - effects are an anti - pattern , but can be moved to ` componentwillmount ` . ` ` ` for those who never came across this message , it can be created simply by mounting the following component . ` ` ` js class updateduringrender extends component { constructor ( props ) { super ( props ) ; this . state = { text : ' initial ' , }; } updatestate ( text ) { this . setstate ( { text }); } render ( ) { this . updatestate ( ' updated ' ); return ( <div> { this . state . text } </div> ); } } ` ` ` * * what is the expected behavior ? * * can we be more specific which component triggers this warning ( i think it could be even treated as an optional error ) ? when this suddenly appears in the app , sometimes it ' s tough to find the culprit . some stack trace or at least the offending component would be helpful in the warning message . not sure how it ' s solved internally , but yeah , would be a nice hint to help remove anti - patterns . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * ` "" react """,1
facebook/react,"support partial hydration for static content < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * hydrating some server - rendered content can be difficult , inefficient or impossible . for example , in the process of rendering on the server , significant work or additional data may be required for data processing and conversion , such as custom templating or localization . the content can be large too , such as product information or a news article . when the resulting content is highly dynamic and changes with state , there is no choice but recreate it within react paradigm and recreate it on client . however , complicated server - generated content is often ( if not typically ) static . delivering a redundant copy of static content to client just to compare and ignore it during hydration seems a waste of resources and can be prohibitively expensive . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * <url> * * what is the expected behavior ? * * instead of additional complications of recreating it on the client with hydration , wouldn ’ t it be much easier to just accept the content from server as - is and tell hydrate ( ) to leave it alone ? there may be a few options for non - hydrating ssr : <number> . add a new callback ` shouldcomponenthydrate ( ) ` to disable hydration of component content ` ` ` javascript export default class nohydrate extends component { / / return false to avoid re - rendering of this component in hydrate ( ) shouldcomponenthydrate ( ) { return false ; } render ( ) { / / on server , simply render content / / on client , this is never called and server content is accepted as - is return ( <div> { this . props . children } </div> ); } } ` ` ` <number> . access ssr content from dom in ` render ( ) ` _this is probably the worst option , though it is the only one that definitely works currently . _ ` ` ` javascript export default class autohydrate extends component { render ( ) { / / on server , simply render content / / on client , find ssr in dom and re - render using dangerouslysetinnerhtml / / * * requires a unique id , generated before or during server rendering * * return ( typeof window = = = ' undefined ' ) ? ( < div id ={ this . props . id } > { this . props . children } < / div ) : ( < div id ={ this . props . id } dangerouslysetinnerhtml ={{ __html : document . getelementbyid ( this . props . id ) . innerhtml } } / > ); } } ` ` ` <number> . use ` dangerouslysetinnerhtml ` with empty content _it actually works now , but it is not documented that it is supposed to . _ ` ` ` javascript export default class ssr extends component { render ( ) { / / on server , simply render content / / on client , render empty content using dangerouslysetinnerhtml , / / which normally causes a warning of content mismatch and keeps the existing content / / also add suppresshydrationwarning to turn off the warning . return ( typeof window = = = ' undefined ' ) ? ( <div> { this . props . children } </div> ) : ( < div dangerouslysetinnerhtml ={{ __html } } suppresshydrationwarning / > ); } } ` ` ` considering that there is a way to make it work now , documenting ( <number> ) may be all that needs to happen . however if ( <number> ) could be added with same behavior , it would look cleaner . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * version <number> . not sure if the working option <number> has worked before or is supposed to work in future versions .",1
facebook/react,"uncaught error : unexpected object passed to reacttestinstance constructor ( tag : <number> ) . this is probably a bug in react . hello , i am testing v16 . <number> and i am getting this warning : ` ` ` warning : detected multiple renderers concurrently rendering the same context provider . this is currently unsupported ` ` ` my use case is that i wanted to render react test renderer ( for ex ) from a component in an another ( reactdom ) renderer but it does not seem to work - i wanted to use same provider in both containers . i thought ` react . createcontext ` create objects with no state and could be shared across renderers / fiber containers . <repeated> is there workaround for this ? are there any thoughts on this , is this a definite behaviour ? following the warning , i eventually get the error message which i believe is related to the warning : ` ` ` uncaught error : unexpected object passed to reacttestinstance constructor ( tag this is probably a bug in react . ` ` ` thank you for any guidance <happy>",1
facebook/react,"[ svg ] enable focusable to accept boolean values moved discussion from <url> # # situation the [ ` focusable ` attribute ] ( <url> from the svg specifications is an [ enumerated attribute ] ( <url> accepting values ` "" true "" ` , ` "" false "" ` and ` "" auto "" ` . because it is technically not a boolean attribute ( although it certainly somehow looks like it ) , react expects the value to be passed as a string . see the following example : ` ` ` diff - < svg focusable > i should be focusable </svg> - < svg focusable ={ true } > i should be focusable </svg> + < svg focusable = ' true ' > i should be focusable </svg> ` ` ` the thing is , the ` focusable ` attribute is often used in conjunction with elements from the aria specification , in which attributes are booleans and not enumerated attributes with ` "" true "" ` and ` "" false "" ` values . the [ ` aria - hidden ` attribute ] ( <url> is a good example of that . for instance , [ following a good practice for icon - buttons ] ( <url> ` ` ` html < button type = "" button "" > < svg aria - hidden = "" true "" focusable = "" false "" > < use xlink : href = "" <hashtag> icon play </hashtag> "" > </use> </svg> < span class = "" access - label "" > start playback </span> </button> ` ` ` from an authoring perspective , the above snippet would likely be written like this in jsx : ` ` ` jsx < button type = ' button ' > < icon icon = ' play ' aria - hidden ={ true } focusable ={ false } / > < span class = ' access - label ' > start playback </span> </button> ` ` ` the problem is that ` focusable ` * cannot <emphasis> * be authored as a boolean , otherwise it will * not <emphasis> * be printed out in the dom . on the other hand , ` aria - hidden ` is perfectly fine being written as a boolean at it gets coerced by react . # # proposal given the default value for the ` focusable ` attribute is ` "" auto "" ` , this is very likely this attribute gets authored to change its value to ` true ` or ` false ` . in that regard , it is confusing that it has to be specified as a string , when other attributes accepting booleans can be authored as such . the suggestion would be to make it possible for ` focusable ` to be specified as either a boolean or a string , like other similar attributes . in other words , all the following should work < svg focusable > i should be focusable </svg> < svg focusable ={ true } > i should be focusable </svg> < svg focusable = ' true ' > i should be focusable </svg> < svg focusable ={ false } > i should not be focusable </svg> < svg focusable = ' false ' > i should not be focusable </svg> < svg focusable = ' auto ' > i should be focusable </svg> ` ` ` from an authoring perspective , i believe this would be the most straightforward and less confusing .",1
facebook/react,"elements loose focus when moving to or from a portal * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * perhaps a bug , but could also be seen as a feature * * what is the current behavior ? * * when you move an element to a portal through ` reactdom . createportal ` the element looses focus if it had focus . if the element gains focus while in a portal , when moving out of the portal it looses focus . * * what is the expected behavior ? * * i would have expected react to maintain focus of the element when moving in or out of a portal * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * tested with react version : <number> browsers : latest chrome and firefox . i did not test others but expect the behaviour to be the same os on mac high sierra",1
facebook/react,"expose the ` onselect ` event for any focusable element ? i was curious earlier if the ` onselect ` event works on things other than form elements and ` contenteditable ` elements , and by disabling a couple of conditions in the code , it seems — at first brush , at least — that ` onselect ` works splendidly on any element that is focusable ( via the ` tabindex ` attribute ) , to obtain things like would there be any problem with relaxing the conditions for allowing ` onselect ` to include elements that have a ` tabindex ` attribute ? ( other than the case where existing implementations in userland rely on the event being disabled when ` contenteditable = true ` is removed from an element ) .",1
facebook/react,"support for changing a portal ' s container without remounting children ? ( this is related to <url> i am working on a project with a lot of globally unique component instances . ( in other words , their ` key ` s are essentially database ids . ) it also has dnd functionality . for reordering , everything is fine , but moving an instance from one parent to another causes a complete re - render of the instance . instead of moving the nodes around myself , i was thinking of using portals . each instance has a prop for which element id they should render inside . then , to reparent them , it ' d be a simple case of passing a different element id . ( i am using redux , so it ' d just be a ` string ` in the state . ) however , changing a portal ' s container node also causes a complete re - render of everything passed to ` reactdom . createportal ` . ( see this [ codepen ] ( <url> would it be possible to skip this re - rendering and effectively move the portal contents instead ?",1
facebook/react,"context transform with the new context api it is really bulky to create a middle man that consumes one context value , transforms it and provides another one . you have to create many components and store an intermediate state to avoid rerendering the provider if the input is unchanged . we could have a convenience api for this use case . ` ` ` js function transform ( inputvalue ) { return [ . <repeated> inputvalue , extradata ] ; } < context . middleware transform ={ transform } > { children } < / context . middleware > ` ` ` cc <user>",1
facebook/react,"[ feature ] implement a ` getstate ` method to get the sync state since ` setstate ` is async . * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * <h2> feature request </h2> * * what is the current behavior ? * * ` ` ` js class mycomponent extends component { state = { a : <number> } method1 = ( ) => { this . setstate ( { a : <number> }); this . method2 ( ); } method2 = ( ) => { / / it can not log <number> in the console . console . log ( this . state . a ) ; } / / x <elongated> . <repeated> } ` ` ` * * what is the expected behavior ? * * ` ` ` js class mycomponent extends component { state = { a : <number> } method1 = ( ) => { this . setstate ( { a }); this . method2 ( ); } method2 = ( ) => { / / with the ` getstate ` method , it should log <number> in the console . console . log ( this . getstate ( ) . a ) ; } / / x <elongated> . <repeated> } ` ` `",1
facebook/react,"feature request : middleware this is an incomplete draft for a feature i think could be really cool . it can replace higher order components and context in a way i think is more in the component spirit of react . i do not know if this feature is feasible or desirable for react , especially as it would lead to a bigger api surface . the proposal is written as if it was documentation to give a feel for how it would be to use it . # about react middleware a middleware is applied somewhere in the component tree and are instantiated just after child components are instantiated and just before they mount . in this context , child components means child components at any depth . middleware is used just like normal components , but it works slightly differently . when a middleware element is used it added to the middleware stack . if it is already on the middleware stack , it removed from the stack and pushed to the end , with the most innermost props . # # simplified example in addition to the actual classes , the stack also includes its most recent props . but this is roughly how it works . ` ` ` javascript <middlewarea> {/* middleware stack for "" a "" : [ middlewarea ] */} < a / > <middlewareb> {/* middleware stack for "" b "" : [ middlewarea , middlewareb ] */} <b> < middlewarea {/* middleware stack for "" c "" : [ middlewareb , middlewarea ] */} < c / > </middlewarea> </b> </middlewareb> </middlewareb> ` ` ` # lifecycle methods # # additions to the existing lifecycle methods # # # mounting - new : middleware . shouldmiddlewaremount - new : middleware . shouldmiddlewarepropagate - component <hashtag> constructor </hashtag> - new : middleware <hashtag> constructor </hashtag> - new : middleware <hashtag> middleware will mount </hashtag> ( ) - component <hashtag> component will mount </hashtag> ( ) - component <hashtag> render </hashtag> ( ) - new : middleware <hashtag> intercept render </hashtag> ( ) - component <hashtag> component did mount </hashtag> # # # unmounting - new : middleware <hashtag> middleware will u n mount </hashtag> # # static shouldmiddlewaremount ( reactcomponent ) determine if the current middleware should apply for a component . if the method is not implemented , the middleware will always be applied . if a middleware is on the middleware stack , this method is called every time a component is constructed . # # # example ` ` ` javascript class transforminlinestyles extends react . middleware { /* * * only mount middleware when you set * transforminlinestyles to a truthy * value . children of the given * component can still enable * the middleware */ static shouldmiddlewaremount ( component ) { return component . transforminlinestyles } / / . <repeated> } const a = props => ( / / . <repeated> ) const b = props => ( / / . <repeated> ) b . transforminlinestyles = true const app = ( ) => ( <transforminlinestyles> {/* not applied to "" a "" */} <a> {/* applied to "" b "" */} < b / > </a> </transforminlinestyles> ) ` ` ` # # static shouldmiddlewarepropagate ( reactcomponent ) determine whether the middleware should remain on the middleware stack or be excluded for the subtree below the given component . if not specified it returns false , in other words : the default behavior for middleware is to propagate . this is useful if you want to limit middleware from affecting deeply nested children . it is also useful for only giving middleware access to its immediate children . # # # example ` ` ` javascript import react from ' react ' class providetheme extends react . middleware { static stoppropagation = props => props . children static shouldmiddlewarepropagate ( component ) { return component = = this . stoppropagation } / / . <repeated> } const app = ( ) => ( <providetheme> {/* middleware stack for "" a "" : [ providetheme ] */} <a> < providetheme . stoppropagation > {/* middleware stack for "" b "" : [ ] */} < b / > < / providetheme . stoppropagation > {/* middleware stack for "" c "" : [ providetheme ] */} < c / > </a> </providetheme> ) ` ` ` # # middlewarewillmount ( reactinstance ) called before the child component calls componentwillmount . this is a good place to initialize state for the middleware instance . # # middlewarewillunmount ( reactinstance ) called before the child component calls componentwillunmount . # # # example this is a naïve example of how it could be used to trigger automatic updates with mobx . ` ` ` javascript class observer extends react . middleware { middlewarewillmount ( reactinstance ) { this . dispose = autorun ( ( ) => { / / let mobx track the observables / / used in the render method . reactinstance . render ( ) / / force update the component instance / / after mobx has stopped tracking the / / autorun function . / / / / . <repeated> yes , i know it ' s hacky . settimeout ( ( ) => { reactinstance . forceupdate ( ) } ) } ) } middlewarewillunmount ( reactinstance ) { / / stop listening for changes from mobx this . dispose ( ) } } ` ` ` # # interceptrender ( children ) interceptrender is called with the result from the render function of the component . the resulting value is what is used to render the dom . # # # example this is an example of a middleware that transforms object classes into a string . the result works similarly to how ng - class works in angularjs . ` ` ` javascript class objectclassnames extends react . middleware { /* * * this is a life cycle method . * * intercept the render method and recursively * loop through all children , performing * this . transformprops ( ) on their props . */ interceptrender ( children ) { return react . children . map ( children , child => { if ( ! react . isvalidelement ( child ) ) { return child } return { . <repeated> child , props : this . transformprops ( child . props ) , children : this . interceptrender ( child . children ) } } ) } /* * * if a child has an object classname , call * this . transformclassname ( ) on it . */ transformprops ( props ) { if ( ! props || ! props . classname || typeof props . classname ! = = ' object ' ) { return props } return { . <repeated> props , classname : this . transformclassname ( props . classname ) } } /* * * concatenate the truthy keys of the classname * object into a string . */ transformclassname ( classname ) { const result = [ ] for ( const key of object . keys ( classname ) ) { if ( classname [ key ] ) { result . push ( key ) } } return result . join ( ' ' ) } } const widget = ( props ) => ( < div classname ={{ ' widget ' : true , ' widget - - active ' } } > some widget </div> ) const app = ( ) => ( <objectclassnames> < widget active ={ true } / > </objectclassnames> ) ` ` ` # why middleware ? react middleware can replace two problematic patterns used with react . # # context the h2 on context in the react docs says "" why not to use context "" . context is however a very useful feature . and people have been and will continue to use and abuse it in the forseeable future . react router has started abusing context in its most recent version , which shows that there is clearly a need here . with middleware , as i propose it , you would be able to inject props into an arbitrary subtree of your app . this has performance implications , but would be an ideal scenario for libraries such as react router , as the relevant props ( or as it is now , context ) rarely changes . with middleware shouldcomponentupdate will still function like you would expect . # # higher order components a primal rule of programming is dry . when using mobx with react , you must use the observer decorator on all reactive classes . this is not a really big deal , but not having to include that would reduce the size of every single observer component by two lines and most importantly , i would not forget it . when creating a higher order component static properties are no longer available . the package hoist - non - react - static is designed so that you should be able to access static properties of higher order components transparently . if a static property is initialized in the lifecycle methods of a component , it will however not be proxied . creating higher order components is also a messy affair . with middleware you could achive the same thing in a react way . to replace connect from react - redux you could set shouldmiddlewarepropagate to return false , and it would affect only one component . alternatively you could use static properties for mapstatetoprops and mapdispatchtoprops .",1
facebook/react,"add react . isfragment api for verifying fragment < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i want to request a feature . * * what is the current behavior ? * * we have no api to verify a reactnode is a react <number> fragment . though now we can use ` react . isvalidelement ( instance ) & & typeof instance . type = = = ' symbol ' ` to distinguish it . it ' s verbose and seems uncertianly right . * * what is the expected behavior ? * * add api react . isfragment ( object ) ` ` ` verifies the object is a react . fragment . returns true or false . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number>",1
facebook/react,"react . children . toarray and react . cloneelement do not work with portal elements < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug or undefined behaviour * * what is the current behavior ? * * doing ` ` ` react . children . toarray ( reactdom . createportal ( . <repeated> ) ) ` ` ` fails with : ` ` ` objects are not valid as a react child ( found : object with keys {$ $ typeof , key , children , containerinfo , implementation } ) . if you meant to render a collection of children , use an array instead . ` ` ` namely , the following complete snippet fails : ` ` ` jsx import react from ' react ' ; import { render , createportal } from ' react - dom ' ; const renderchildren = ( { children } ) => { children = react . children . toarray ( children ) return <h1> renders children with toarray : { children } </h1> } const app = ( ) => ( < renderchildren name = "" codesandbox "" > { createportal ( <div> rendered in portal </div> , document . getelementbyid ( ' portal ' ) ) } </renderchildren> ); render ( < app / > , document . getelementbyid ( ' root ' )); ` ` ` while the following one , which wraps the portal in another element works just fine ` ` ` jsx import react from ' react ' ; import { render , createportal } from ' react - dom ' ; const renderchildren = ( { children } ) => { children = react . children . toarray ( children ) return <h1> renders children with toarray } const app = ( ) => ( < renderchildren name = "" codesandbox "" > <div> { createportal ( <div> rendered in portal </div> , document . getelementbyid ( ' portal ' ) ) } </div> </renderchildren> ); render ( < app / > , document . getelementbyid ( ' root ' )); ` ` ` * * what is the expected behavior ? * * i am aware that ` createportal ` is a new feature , but in the best case scenario it should be possible to use it everywhere other valid nodes are accepted . the same thing is happening for ` react . cloneelement ( reactdom . createportal ( . <repeated> ) ) ` - it ' s probably weird to try and clone a portal 😄 - but maybe we should specify in the ` createportal ` documentation that it cannot be cloned , at least for now . should i open a pr for that ? let me know your thoughts * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * i am using react <number> . *",1
facebook/react,"lifecycle methods for reactdom . hydrate < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * there is no way to distinguish if a ` componentdidmount ` or ` componentwillmount ` lifecycle method was called in response to a call to ` reactdom . hydrate ` . * * what is the expected behavior ? * * i have a component that scrolls to the top of the page in componentdidmount . this makes sense when the component is first created within the client . however , it does not make sense when the component has been hydrated , as ` componentdidmount ` is called after the content is already visible , and possibly after the user has already scrolled . would it be possible to add a ` componentwillhydrate ` lifecycle method ? then i could do something like this to achieve the desired behavior componentwillhydrate ( ) { this . hydrated = true } componentdidmount ( ) { if ( ! this . hydrated ) { this . scrolltotop ( ) } } ` ` ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * all",1
facebook/react,"include component props into the stack from componentdidcatch ( ) second argument of ` componentdidcatch ` contains componentstack like this { "" componentstack "" : "" in _header ( created by onlyupdateforkeys ( _header ) ) in onlyupdateforkeys ( _header ) ( created by tdsection ) in tdsection ( created by container ) in container ( created by autolookup ) in autolookup ( created by autolookup ) in autolookup ( created by groupcontainer ) in groupcontainer ( created by container ) in container ( created by autolookup ) in autolookup ( created by _content ) in div ( created by _content ) in _content ( created by pure ( _content ) ) in pure ( _content ) ( created by contentlist ) in contentlist ( created by tabcontainer ) in tabcontainer ( created by container ) in container ( created by autolookup ) in autolookup ( created by autolookup ) in autolookup ( created by cardbase ) in div ( created by sharedstorage ) in sharedstorage ( created by cardbase ) in tdvalidation ( created by cardbase ) in cardbase ( created by wrapper ) in wrapper ( created by connect ( wrapper ) ) in connect ( wrapper ) ( created by mapprops ( connect ( wrapper ) ) ) in mapprops ( connect ( wrapper ) ) ( created by connect ( mapprops ( connect ( wrapper ) ) ) ) in connect ( mapprops ( connect ( wrapper ) ) ) ( created by getcontext ( connect ( mapprops ( connect ( wrapper ) ) ) ) ) in getcontext ( connect ( mapprops ( connect ( wrapper ) ) ) ) ( created by card ) in card ( created by branch ( card ) ) in branch ( card ) ( created by connect ( branch ( card ) ) ) in connect ( branch ( card ) ) ( created by getcontext ( connect ( branch ( card ) ) ) ) in getcontext ( connect ( branch ( card ) ) ) ( created by connect ( getcontext ( connect ( branch ( card ) ) ) ) ) in connect ( getcontext ( connect ( branch ( card ) ) ) ) ( created by getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ) in getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ( created by mapprops ( getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ) ) in mapprops ( getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ) ( created by connect ( mapprops ( getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ) ) ) in connect ( mapprops ( getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ) ) ( created by getcontext ( connect ( mapprops ( getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ) ) ) ) in getcontext ( connect ( mapprops ( getcontext ( connect ( getcontext ( connect ( branch ( card ) ) ) ) ) ) ) ) ( created by _tab ) in div ( created by loadingwrapper ) in div ( created by loadingwrapper ) in loadingwrapper ( created by connect ( loadingwrapper ) ) in connect ( loadingwrapper ) ( created by _tab ) in div ( created by _tab ) in _tab ( created by connect ( _tab ) ) in connect ( _tab ) ( created by withcontext ( connect ( _tab ) ) ) in withcontext ( connect ( _tab ) ) ( created by page ) in page ( created by connect ( page ) ) in connect ( page ) ( created by onlyupdateforkeys ( connect ( page ) ) ) in onlyupdateforkeys ( connect ( page ) ) ( created by contentrouter ) in contentrouter ( created by _content ) in _content ( created by connect ( _content ) ) in connect ( _content ) ( created by _splitpane ) in div ( created by contentwrapper ) in div ( created by contentwrapper ) in contentwrapper ( created by _splitpane ) in div ( created by _splitpane ) in _splitpane ( created by connect ( _splitpane ) ) in connect ( _splitpane ) ( created by _masterlayout ) in div ( created by _masterlayout ) in div ( created by _masterlayout ) in _masterlayout ( created by connect ( _masterlayout ) ) in connect ( _masterlayout ) ( created by root ) in div ( created by themechanger ) in themechanger ( created by connect ( themechanger ) ) in connect ( themechanger ) ( created by root ) in startupsync ( created by connect ( startupsync ) ) in connect ( startupsync ) ( created by root ) in _default ( created by root ) in provider ( created by root ) in root in appcontainer "" } ` ` ` this data do not contain any helpful error data if user send me ticket to bugtracker . can info contain props of every component ?",1
facebook/react,"enable synchronously toggling experimental addusertiminglistener currently reactinternals . addusertiminglistener enables logging to the user timing api inside a ` settimeout ` . however , for the use case of building a profiling tool where instrumentation is turned off most of the time to avoid overhead , then randomly turned on for a period to take a sample , it would be ideal to be able to enable this logging synchronously ( eg . turn it on at the start of a callstack and turn it off again at the end of the synchronous stack ) . this is complicated by the fact that the enabled state of the logging should not be toggled inside a react callstack . as the profiler would have control over when the toggling happens , i think it would be fine to throw an error / return false / something like that if the logging was toggled while inside a react stack , allowing the profiler to try again later . in fact , if the toggling was synchronous the profiler cp avoid this error by doing the toggling at the start and end of an event handler / settimeout / reqanimframe etc which would ensure that we are not inside synchronous call into react ( though i am not quite sure what the implications of fiber are here ; would react async rendering mean that we could re - enter from the event loop at a time when this toggling should not happen ? ) . alternatively the toggling could happen ' async but just later in the same react stack ' ( like setstate ) . in this case the code requesting the toggling would probably need some kind of callback to know that toggling happened so it can keep track of whether react ' s logging is on or off . however this variant seems like it would be more complicated to implement , and for our use case i do not think it ' s any more useful than having the toggling just fail in a recoverable way . cc <user>",1
facebook/react,"smarter autofocus i believe autofocus should be improved for the better <sad> . browser - native autofocus is nice and all but does not work when a component is updated . sure , that ' s fine . but it ' s pretty common to need focus after a component has been updated . yep , declaratively . how ? immutable data ftw . at least , it works for me . i use this wrapper component <url> check componentdidupdate method . i hope it makes sense .",1
facebook/react,"add a < reactdom . portal / > element < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i ’ d like to request a feature . * * what is the current behavior ? * * to create a portal , you currently have to use a function function mycomponent ( props ) { return <foo> . <repeated> { reactdom . createportal ( <bar> . <repeated> </bar> , myelement ) } </foo> } ` ` ` * * what is the expected behavior ? * * ` ` ` jsx function mycomponent ( props ) { return <foo> . <repeated> < reactdom . portal target ={ myelement } > <bar> . <repeated> </bar> < / reactdom . portal > </foo> } ` ` `",1
facebook/react,"make react resilient to dom mutations from google translate # # coming from search ? see workaround here : <url> and star this issue : <url> * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug , though there ' s a decent chance it ' s a chrome / google translate one * * what is the current behavior ? * * when using google translate on a page using react <number> , a certain code pattern produces a javascript error ( ` failed to execute ' removechild ' on ' node ' : the node to be removed is not a child of this node . ` ) when the rendered content changes . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem via <url> or similar ( template for react <number> : <url> template for react <number> : <url> ( this has only been checked on macos <number> . <number> ) <number> . navigate to <url> in a chrome browser set to some language other than japanese . <number> . right click the page and select "" translate to english "" <number> . click the checkbox , and the error will show . the source of the example can be found at <url> the part of the code that seems to cause it is the following two lines : ` ` ` js { this . state . checked & & "" 選択済み "" } { this . state . checked & & "" 無選択 "" } ` ` ` changing this to the following fixes the behavior with google translate : ` ` ` js { this . state . checked ? "" 選択済み "" : "" 無選択 "" } ` ` ` * * what is the expected behavior ? * * it should not produce an error . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * i created an identical example with react <number> at the following pages <url> when repeating the same steps outlined above , no error was produced . it only seems to affect react <number> . as this is a chrome - only feature , it only affects chrome .",1
facebook/react,"support onend svg event hi , i am trying to use the \ \ < animatetransform \ \ > element in a react project . but i am not able to use the "" onend "" attribute : > warning event handler property ` onend ` . it will be ignored . is there a workaround for this ?",1
facebook/react,"html5 templates apart from jsx for non programmatic situations just before i have my view , please take a look at these <number> examples hello world react => [ app . jsx ] ( <url> hello world vue => [ app . vue ] ( <url> identical ? is not it ? yes these are two different * paradigm <emphasis> * but hey they are expressing same things and both are doing it in the same way by taking benefits of the virtual dom my feature request is that , just like vue supports [ jsx ] ( <url> for programmatic situations . i think react should also support html5 templates for non programmatic situations ? <repeated> also , * * imagine trying to create a website based on an existing theme that you purchased . changing it over to jsx literally will feel like sticking a knife through your eyeballs . with templates , existing html just works . * * please also note that programmatic situations have a low use case and non programmatic situations have a high use case .",1
facebook/react,"new way to bind event handler function currently there is no way to use event handlers in functional components without performance degradation e . g - unnecessary function recreations through . bind or arrow functions ` ` ` function node ( { node } ) { return ( <div> < button onclick ={() => node . parent . removechild ( node ) } > remove </button> <div> { node . text } </div> </div> ) } ` ` ` in this case on each render a new handler will be created , and also react will need to perform some bookkeeping - remove previous handler from dom element and add new handler ( ok , with event delegation system react will not touch dom elements and only replace handler somewhere in internal structure but what about events which do not bubble ? ) and all this take some noticeable time in my application . sure i can change to class components and solve problem by bind handlers only once when component will be created but what if i want to use functional components ? so in my application i came up with new and fastest method of binding handlers . actually it does not preform binding at all ) . what is the reason of binding function in event handler ? - we need to access current component props or current component state . is there another way to get props or state of component ? react does not describe this in docs but yes - we can access to props or state of current component without any unnecessary functions recreations on each render . ` ` ` function node ( { node } ) { return ( <div> < button onclick ={ onclick } > remove </button> <div> { node . text } </div> </div> ) } function onclick ( e ) { const { node } = getprops ( e ) ; node . parent . removechild ( node ) } function getprops ( e ) { return e . target [ object . keys ( e . target ) . filter ( k => k . indexof ( ' __reactinternalinstance ' ) = = - <number> ) [ <number> ] ] . _debugowner . memoizedprops ; } ` ` ` and this demo <url> to perform event delegations in an efficient way react need to assign current vdom - element to each rendered dom element . and vdom - element has link to actual owner component where we can get our props and state . so why react concealed this from developers and made them suffer not only from performance degradation but also from choosing problem ( how many articles and advices recommend or investigate this rule to not bind handlers in render function , and how many solutions exist - use bind in constructor ? - use class field properties with arrow functions ? - use autobind decorators ? ) ? <repeated> and my solution not need even to recreate handlers on each component instantiation like all current solutions does , so it definitely the fastest way . i highly suggest make this api public or make some helper to get current props and state from event . target",1
facebook/react,"need a hook for hydration mismatch * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * in react <number> , the ` data - react - checksum ` attribute was removed from the server rendered markup . in previous versions , we used this attribute to beacon checksum mismatches to our log servers to be notified of production issues . with the attribute removed , we have no mechanism to determine if a checksum mismatch occurred . i am aware that checksum issues no longer cause the entire dom to re - render , however , it is still important that we know when they do occur . a typical use case is when we display ads or autoplay video . we want to know if an ad gets re - rendered ( double counted ) or an autoplay video is interrupted due to react re - rendering the dom . other related bugs / requests ability to debug checksums in production - <url> * * what is the expected behavior ? * * the solution does not necessarily need to re - introduce the checksum attribute again . it could be some other event , hook , or callback that applications can leverage to handle checksum issues . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * - react <number> - all browsers - worked in <= react <number>",1
facebook/react,"support srcobject attribute for video element * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * currently you cannot set the srcobject for a video . you get an error : ` ` ` warning : react does not recognize the ` srcobject ` prop on a dom element . if you intentionally want it to appear in the dom as a custom attribute , spell it as lowercase ` srcobject ` instead . if you accidentally passed it from a parent component , remove it from the dom element . ` ` ` * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem via <url> or similar ( template for react <number> : <url> template for react <number> : <url> ` ` ` return ( < video srcobject ={ this . props . stream } > ) ` ` ` there is another issue that was closed but the issue was never resolved : <url> firefox has deprecated using ` url . createobjecturl ( ) ` and safari does not support it . * * what is the expected behavior ? * * the ability to set the ` srcobject ` on a video element . this is common for webrtc applications now . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * "" react """,1
facebook/react,"warn about unexpected html inside svg react and react - dom versions : <number> . <number> ` ` ` js const { createelement : h } = require ( ' react ' ); const { rendertostaticmarkup } = require ( ' react - dom - server ' ); rendertostaticmarkup ( h ( ' div ' , null , h ( ' svg ' , null , h ( ' span ' ) ) ) ) / / ' <div> <svg> <span> </span> </svg> </div> ' ` ` ` but they should not be mixed : in browser console new range ( ) . createcontextualfragment ( ' <div> <svg> <span> </span> </svg> </div> ' ) / / "" <div> <svg> </svg> <span> </span> </div> "" ` ` ` i guess it ' s programmer responsibility to avoid that case ? i understand that for performance you do not check this",1
facebook/react,"feature request didupdate ( ) currently , its not easy to write global logic that executes after react has re - rendered . the ` componentdidupdate ` lifecycle method works great when your logic is isolated to a component , but i have found myself more and more recently wanting a global ` didupdate ` hook baked into react . a simple example where this is useful is if you want an isolated function ( perhaps a keyboard shortcut ) that creates an element on the screen and then focuses it . ` ` ` js const createnewtodo = async ( ) => { const id = createtodo ( ) await react . didupdate ( ) focustodoitem ( id ) } ` ` ` at [ notion ] ( <url> we have written custom logic for doing this , but it makes upgrading with react more difficult and unstable . i think this would be useful for others too , particularly those who use redux and are building complicated ui interactions .",1
facebook/react,"react <number> does not lowercase html attributes in generated html * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * reactdomserver generates camelcased markup for the ` cellspacing ` and ` cellpadding ` attributes : ` < table cellspacing = "" <number> "" cellpadding = "" <number> "" > </table> ` ( here ' s an example pen : <url> i believe these attributes are canonically lowercased . if i lowercase the attributes in jsx , react warns that i am not using the right names : ` ` ` warning : invalid dom property ` cellpadding ` . did you mean ` cellpadding ` ? ` ` ` * * what is the expected behavior ? * * the attribute names would be rendered lowercase cellspacing = "" <number> "" cellpadding = "" <number> "" > </table> ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * this is in <number> . <number> . prior versions of react stripped these attributes .",1
facebook/react,"support for string targets for isomorphic createportal this is a proposal for the ` createportal ` api to in addition to nodes support strings for the second argument ( container ) , which could pave a declarative way to achieve out of order server side rendering . ` ` ` js <hashtag> create portal </hashtag> ( . <repeated> , container . <repeated> ) ` ` ` the server could render a portals children in - place and have the client - side hydration process move it to the right location client - side using ` document . queryselector ` if the container is a string .",1
facebook/react,"make on / off , yes / no boolean attributes work when you pass a boolean to some attributes ( e . g . ` autosave ` , ` autocorrect ` ) in <number> , they do not work correctly because they actually want a specific string ( ` yes ` and ` no ` ) . i think there were also some attributes that want ` on ` and ` off ` . let us just “ make them work ” ? could use a special flag / whitelist for that . there should be very few of these . similarly we should probably make ` < script crossorigin / > ` be valid and turn into ` < script crossorigin = "" anonymous "" / > ` . currently i don ’ t think this works on master .",1
facebook/react,"implement silent updates in the state update queue [ reason react ] ( <url> has silent updates . meaning it ' s a normal update in the state queue that can be reverted . the only difference is , it does not need a rerender by itself . if props have changed , it does rerender . unclear if we expose this to the existing classcomponent api or make it a feature of new apis .",1
facebook/react,"more permissive rehydration logic so for the last little while i have been pursuing an idea called [ react snapshot ] ( <url> where instead of running your code in a node environment to generate static html , you run it in a virtual browser ( jsdom or chrome headless ) and take a snapshot of the dom at a particularly moment in time , then host the snapshots like any other static file ( technique also known as pre - rendering ) . i have been tossing around different api choices ( <url> in order to handle components that have async data fetching requirements , but i am already starting to see real promise in this approach . because the snapshot environment is so similar to the client one , far fewer changes are needed to get the performance & accessibility benefits of serving real html to your users . this is an example of the react snapshot async api to make a component snapshottable : ` ` ` diff + import { snapshot } from ' react - snapshot ' class home extends react . component { state = { quotes : null } componentwillmount ( ) { + snapshot ( ( ) => ( fetch ( ' / api / quotes ' ) . then ( response => response . json ( ) ) + ) ) . then ( quotes => { this . setstate ( { quotes } ) } ) } render ( ) { const { quotes } = this . state return ( < div classname = "" quotes "" > { quotes & & quotes . map ( ( quote , i ) => < quote key ={ i } quote ={ quote } / > ) } </div> ) } } ` ` ` the idea is that any async parts of your app can be wrapped in a ` snapshot ` call , which caches responses and rehydrates on the client . however , i have hit a few walls that i think means i ' d need changes to react itself to take this to its logical conclusion . hence , i wanted to start the discussion about whether such changes would be compatible with react ' s future direction . # # # rehydration as far as i can tell from my experimentation and from reading the code , the two criteria for reusing the existing dom elements in a pre - rendered html page is : * the adler32 hash of the initial client - rendered markup has to match the ` data - react - checksum ` present on the ` rootelement ` . * the ` _domid ` of each instance in the render tree needs to match the ` data - react - id ` on each dom element between those two criteria , its enforced that the _structure_ and the _content_ of the dom is the same . i can kinda see why both are needed — the checksum is the cheapest way to confirm the structure will be the same , but the id of each element is needed to actually wire everything up . also , ` data - react - checksum ` is just an attribute , and could be calculated off something that ' s no longer present in the html . however , generating the exact right checksum in any other way than the existing ssr api turns out to be pretty difficult # # # html - escaping woes i hit this problem where i was rendering the react app like normal , then taking the ` innerhtml ` of the root container , then passing it to [ ` addchecksumtomarkup ` ] ( <url> and not getting the same checksum as ` reactdomserver . rendertostring ` . i first realised i needed to add the ` data - reactid ` to each element along the way , which wasn ' t too hard , but still it wasn ' t working . i figured out it ' s due to [ ` escapetextcontentforbrowser ` ] ( <url> converting things like ` ' ` to ` & <hashtag> x27 </hashtag> ; ` and ` "" ` to ` "" ` , meaning that while the content _appears_ the same once rendered , the precise string is not , therefore the checksum is not , and no rehydration takes place . from what i can understand , again by reading the code , react _always_ sanitises the html content before generating markup ( on server or in client ) , it ' s just the fact that once its injected into the dom , ` innerhtml ` does not re - sanitise things like quotes . they do not technically need to be , as discussed in issue <url> and so if that were to be changed this particular problem would disappear , but there may well be more i just have not hit yet . to me , the real issue is needing to have the content be byte - for - byte equivalent , rather than just functionally ( and structurally ) equivalent . # # # my interim solution at the moment , i have realised its easier to boot up the app in its entirety , wait for all async processes to take place , then effectively reboot the app using ` reactdomserver . rendertostring ` and splice the markup in place . any side - effects relying on ` componentdidmount ` ( like css injection or meta tags in the head ) that affect the dom _outside_ the react app are preserved , but the markup and checksum of the react - rendered html are guaranteed to be correct . it works , but its not ideal . you still have to understand that your components are running in two different "" modes "" , they will run different lifecycle methods in each , and only one generates the final snapshot . which i think adds an unreasonable conceptual burden , much the same way server - rendering does . that ' s really the problem i see with the status quo and why i started looking into this problem in the first place . if snapshot / server rendering requires too much overhead , most people will not do it , which is exactly where we are at . create - react - app does not include any because none of the options are simple enough with a broad enough applicability . the official [ react router docs ] ( <url> warn agains combining server - rendering and code - splitting . server - rendering boilerplates include fairly specific webpack hacks to provide the same environment on server and client , etc . the result is that most people only ever do client - rendering . they serve a blank page & render everything client - side . code splitting and service worker caching offer useful advantages but imo it ' s not enough . snapshot rendering _could_ be the solution , but only if it can offer big benefits for small changes to application code . # # # my dream solution architecturally , what i ' d like is for an arbitrary react app to be launched on one browser , executed until ready ( async resources complete ) , snapshotted ( serialised to html ) , then resumed on another browser . those snapshots would be generated then cached at the edge of a cdn during deployment , or periodically depending on how often the content changes . practically , i think that would require two changes to react ' s architecture first is for a weaker check for rehydration — some other fingerprint than a hash of the escaped html . some other method for a snapshot to indicate to react to reuse as much of the existing dom as possible . the second would be for only parts of the tree to be rehydrated rather than the whole thing . if a component has some side - effect , say in a ` componentdidmount ` , then the snapshotted html would include the result of that side - effect . but when the app boots on the client side , the render method will generate the initial behaviour . at the moment react would replace what ' s there with what ' s just been rendered , but it might be preferable to leave the dom unchanged on the first render , then wire things up later . i do not know the exact specifics of a solution , nor do i know enough of the internals of react as it is now or as it will become , but i wanted to start the discussion and see if there was any interest from the react team & wider community in this use case and direction . i look forward to hearing your thoughts !",1
facebook/react,"add default property for es2015 modules * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * ` ` ` js import * as react from "" react "" ` ` ` the above code causes deprecation warnings because of how ` _interoprequirewildcard ` works in babel : ` ` ` warning : accessing proptypes via the main react package is deprecated , and will be removed in react v16 . <number> . use the latest available v15 . * prop - types package from npm instead . for info on usage , compatibility , migration and more , see <url> warning : accessing createclass via the main react package is deprecated , and will be removed in react v16 . <number> . use a plain javascript class instead . if you are not yet ready to migrate , create - react - class v15 . * is available on npm as a temporary , drop - in replacement . for more info see <url> ` ` ` you can use this with babel : ` ` ` js import react from "" react "" ` ` ` this works because of synthetic import support in babel , using ` __esmodule ` . if you use typescript the above does not work unless you set ` allowsyntheticdefaultimports ` to true in tsconfig . json . most packages work fine with ` * as module ` , but react ' s deprecated warnings get tripped because babel copies the object with ` _interoprequirewildcard ` . * * what is the expected behavior ? * * ` ` ` js import react from "" react "" ` ` ` the above should work without needing to set ` allowsyntheticdefaultimports ` . this can be done by providing a ` default ` property . possibly by adding this to ` src / isomorphic / reactentry . js ` react . default = react ` ` ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number> . <number> chrome <number> os x <number> . <number> node <number> . <number> does not work in previous versions since deprecation warning was added .",1
facebook/react,"feature request hook * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i want to request a feature <emphasis> . * * what is the current behavior ? * * - warning code is hardcoded to call ` fbjs / lib / warning ` . this makes it hard to integrate warnings with tools . - as a workaround we could use webpack ’ s ` resolve . alias ` to alias ` fbjs / lib / warning ` into our fork which displays it on - screen . - this use case is similar to <url> - another use case is to integrate react warnings with our testing infrastructure . this helps us to better see which warning belongs to which test . [ image ] ( <url> * * what is the expected behavior ? * * - react allows library user to override the default warnings behavior . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * - the workaround works in react <number> and should still work in react <number> , as the flat bundles does ` var warning = require ( ' fbjs / lib / warning ' ) ` which means we can still hook into it for now . - this probably breaks when the flat bundles stopped doing ` var warning = require ( ' fbjs / lib / warning ' ) ` .",1
facebook/react,"include canary tests of community packages as part of the release process ( cc <user> , from <url> in general , there ' s lots of little utilities that are helpful to have as standalone packages . one of them is <url> for example . it ' d be ideal for the react team to maintain this package - primarily , so that it would be guaranteed to either not break when a new react version is released , or be updated to work with the upcoming version prior to release . in the interests of the react team not signing up to maintain all the package requests that might come in , would it be possible to make "" part of the release process "" be "" ensure compatible versions of community packages exist "" ? i ' d be happy to create the above package , for example , and i know the community would love a guarantee that enzyme would always work with any official react version release , prior to the release .",1
facebook/react,"set initial state to undefined * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * initial state is null . * * what is the expected behavior ? * * initial state is undefined . we can manually set the state to undefined in the class , but it would make sense to be out of the box as it would allow destructuring without errors . * * version : * * react <number> . <number> react - dom <number> . <number> sorry if this has been suggested before .",1
facebook/react,children foreach filters functions * * react v15 . <number> * * unexpected behaviour of ` react . children . foreach ` – silently filters functions . * * current behavior : * * ` ` ` jsx const element = ( <div> { ( ) => { } } { ( ) => { } } </div> ); console . log ( react . children . toarray ( element . props . children ) ) / / output ` ` ` * * expected behavior : * * children . foreach should throw invariant <emphasis> error then function <emphasis> type child is met . or children . foreach should not filter function <emphasis> type children .,1
facebook/react,"warn when purecomponent renders impure ones as its children * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * when a purecomponent renders an impure one as its child , no warning in console or devtool * * what is the expected behavior ? * * it could be better if we get a warning message for such cases this may be related to <url> since react now disallow purecomponent to have a custom ` shouldcomponentupdate ` implement , so a "" pure "" component with customized and more efficient ` shouldcomponentupdate ` method must inherit from ` component ` base class and add a ` ispurereactcomponent ` property themselves in order to prevent the warning message appear * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number> . <number>",1
facebook/react,"feature request : dangerouslysetinnerhtml as a return value i haven ’ t fully thought through this yet , so hoping for some feedback on whether it is viable or breaks too many assumptions . the goal is to create an escape hatch that would support rendering to conditional comments , alternative method for web components , and other unknown and probably bad ideas . something along the lines of : ` ` ` jsx const dangerouscomment = ( { children } ) => ( { dangerouslysetinnerhtml : { __html : ` < - - ${ children } - - > ` } }); reactdomserver . rendertostring ( <head> <dangerouscomment> { "" [ if lte ie <number> ] > < script src ='/ public / media . match . js ' > </script> < ! [ endif ] "" } </dangerouscomment> </head> ); / / <head> < ! - - [ if lte ie <number> ] > < script src ='/ public / media . match . js ' > </script> < ! [ endif ] - - > </head> ` ` ` ` ` ` jsx const webcomponent = ( { children } ) => ( { dangerouslysetinnerhtml : { __html : ` < ! - - ${ children } - - > ` } }); reactdom . render ( ( ) => ( <webcomponent> ` < app - toolbar arbitary - prop = "" sure - y - not "" > < div main - title > web components ! </div> < / app - toolbar > ` </webcomponent> ) , document . body . firstchild ) ; ` ` ` the first example is the one i ’ m more interested at this point in time . the benefit here is this could work on both the dom and server renderer without userland hacks like <url> or ` componentdidmount ` ref replacement ( client only , i believe ? ) . a couple initial problems i see with this are ( may or may not be solvable / avoidable with slight tweaks ) : * returning an arbitrary object ` render ` which isn ’ t supported * how will unmounting this work ? alternative proposal a new dom - renderer primitive ` < comment / > ` or ` < dangerouscomment / > ` ( to follow a similar approach to ` dangerouslysetinnerhtml ` clearly indicating the caveats that come with rendering comments ) . this alternative solution only solves the conditional comment issue above .",1
facebook/react,"serializing to "" html with only as much js as necessary "" this is sort of a feature request , mostly because i have not been able to make the current react tooling do what i need it to do . i have a massively huge article up on <url> that consists of a single page of react - managed content , of which the bulk is "" passive "" html content . paragraphs , headings , that kind of stuff . however , there are also active components with js interaction bindings , and so i was trying to figure out a way to turn this article into a "" react - managed by the client "" into a "" thin ui managed by the client , react - built offline "" solution . i had a look at reactdomserver . rendertostaticmarkup , but while this generates all the html nicely , it also loses any and all js bindings that are necessary to keep the ui working . as this is an ~ 8 0 0 kb article not counting static assets ( there ' s some <number> . 6 mb of images on top of that ) , the notion of first loading the plain markup content and then loading the react bundle on top of that , to hook into the preloaded markup would be a terrible experience for people in the slightly - less - wealthy parts of the world . is there some way to , or would there be a sense in developing a way to render react content to html "" as much as possible "" while preserving react ' s management of interactive ui components ? essentially , a solution in between ` rendertostring ` and ` rendertostaticmarkup ` , to prevent as much data duplication between the pregenerated html and the react application itself ? it seems that the heavy payload ( in bytes , but certainly in client - side processing as well ) incurred by using a fully react - managed bundle could be relieved significantly if "" content that is guaranteed passive , regular html "" could be serialized out as html with react hooking back into that code only for elements that require active management . ( i have no idea how much work that would be , but i am pretty sure it would help bring down the average page size down again , which on a global scale would save quite a lot of time and money , while allowing content to be loaded by people for whom parts of the internet are currently inaccessible due to load time and byte cost )",1
facebook/react,"expose more through __react_devtools_global_hook__ . inject this feature request came out of a brief discussion on twitter with <user> : <url> ` __react_devtools_global_hook__ . inject ` exposes access to ` getclosestinstancefromnode ` , ` getnodefrominstance ` , ` reactmount ` and ` reactreconciler ` . this is great , and we use it to collect component level performance metrics for our customers in production , however , there are more things we ' d love to have access to for the purpose of helping our users pinpoint performance issues in their applications . this "" issue "" includes some initial observations , but i hope we can keep an open dialogue about this - in particular considering fiber will probably change the landscape with regards to what the most common performance problems are and we ' d instrument according to that . i understand the urge to keep the api surface area as small as possible in order to create minimal commitment to apis to allow for internals to move fast . exposing additional internals with the explicit warning that you are not committed to their api is fine for us , as a tool vendor . we have looked at using ` batchedupdates ` to highlight the batched nature of the work performed by react . e . g . is the work in your application getting batched properly . if we only have access to the component updating methods on ` reactreconciler ` ( ` mountcomponent ` , ` receivecomponent ` , ` unmountcomponent ` etc ) we can not really know when a batch of work starts and when it ends . ` batchedupdates ` is available in reactdom with the ` unstable_ ` prefix , but exposing it in the ` inject ` hook would be very useful : <url> we have also ( experimentally ) hooked into ` eventpluginutils . executedispatchesinorder ` in order to capture events and measure the work resulting from these , but i suspect there is a better place to do this ( ` reacteventlistener . dispatchevent ` ? ) . in any case , having access to the event system would be very useful . again , using the "" unstable_ "" prefix to indicate non - committal would be fine for us . i have not had much time to look into what we ' d need access to for fiber instrumentation , but so far it looks like a hook into ` beginwork ` would be very useful",1
facebook/react,"feature request auxclick event ( onauxclick ) version <number> . <number> as starting chrome <number> , there is a new event ` auxclick ` to handle middle click , and ` click ` does not trigger by middle click anymore <url>",1
facebook/react,"skip comparing known constant props during reconciliation * * do you want to request a _feature_ or report a _bug_ ? * * _feature_ * * what is the current behavior ? * * currently , whether a prop is expected to change or not , it is passed through props . there is no way for us as developers to mark a prop as fixed ( should never change over the lifecycle of a component ) . * * what is the expected behavior ? * * these would _not_ be static properties , i . e . they can change from instance to instance . but they are created at initial render and never change (`===` ) from the original . ideally , though i am not sure on implementation , they would also always be ` deepequal ` to the original ( perhaps something like ` object . freeze ( object . assign ( { } , originalobject ) ) ` . advantages to allowing props to be explicitly marked as fixed : <number> . shouldcomponentupdate would be better if a lot if certain props automatically do not / can not change <number> . allow for errors / warnings when a prop marked as fixed is changed after the initial render . <number> . possible compiler / render optimizations knowing that particular props will never change over the course of multiple renders . in particular , if a component only has fixed props ( including children ) , we know the render output is fixed , and we can just inline that output into the parent render output . one possible api would allow a separate fixedprops category . ` react . createelement ( mycomponent , { name : ' hello ' } , children , { message : ' always this one string ' } ) ` ( maintain signature ) for jsx , one ( very mediocre ) idea would be something like : ` < mycomponent name = "" hello "" $ fixed . message = "" always this one string "" / > ` another would be a separate prop called $ fixed or something similar . ` react . createelement ( mycomponent , { name : ' hello ' , $ fixed : { message : ' always this one string ' } } , children ) ` ` < mycomponent name = "" hello "" $ fixed ={{ message this one string ' } } / > ` it would be critical that ` props ` and ` fixedprops ` would be merged when the component is actually created . ` this . props ` would always contain all props , functional components still get one arg , and thus nobody has to rewrite render for any component .",1
facebook/react,"support symbol keys for props * * do you want to request a _feature_ or report a _bug_ ? * * i want to report a bug * * what is the current behavior ? * * ` render ( ) ` does not receive props with symbol keys ( for example , ` { [ symbol ( ) ] i guess it is because of ` hasownproperty ` in [ reactelement . createelement ] ( <url> * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem via jsfiddle or similar . * * <url> * * what is the expected behavior ? * * symbol - keyed ` props ` passed to ` render ( ) ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * every single one , as far as i know",1
facebook/react,"highlight element that failed checksum at the moment , when the server - rendered markup does not match the client - rendered markup , a big red error is shown , but it can be difficult / impossible to locate the element where this occurred . would something that logged the offending element to the console be considered as a pull request ? [ react - diff ] ( <url> <url>",1
facebook/react,"having this . state in the constructor and this . setstate everywhere else is violating the "" uniform access principle "" es6 style of creating components in react is clearly violating the [ uniform access principle ] ( <url> it ' s a general source of confusion ( and bugs ) to be able to set state in two different ways you must do ` this . state = { } ` if you are in the constructor - you must do ` this . setstate ( ) ` everywhere else . i believe it ' d be much better to have just <number> way to set state in general , and it should be universal . if we are already accessing state through ` this . state ` , and setting state in the constructor with ` this . state ` , why not do it everywhere else ? the behavior of ` this . setstate ` could be easily replicated with [ es6 proxies ] ( <url>",1
facebook/react,"polyfill mouseevent . buttons for safari during mouse move event , ' e . buttons ' returns ' undefined ' in safari . behaving correctly in chrome . while pressing the left mouse button and moving the mouse expect ' e . buttons ' to return <number> . ' e . nativeevent . which ' returns the correct result on safari . sample code : ` ` ` javascript import react from ' react ' ; export default class canvas extends react . component { constructor ( props ) { super ( props ) ; } mousedown ( e ) { console . log ( "" mouse down "" , e . buttons , e . nativeevent . which ) ; } mousemove ( e ) { console . log ( "" mouse move "" , e . buttons , e . nativeevent . which ) ; } mouseup ( e ) { console . log ( "" mouse up "" , e . buttons , e . nativeevent . which ) ; } render ( ) { var canvasstyle = { backgroundcolor : ' rgba ( <number> , <number> , <number> , <number> ) ' , position : ' absolute ' , top : ' 0 px ' , left : ' 0 px ' , width : ' <percent> ' , height : ' <percent> ' } return ( <div> < canvas id = "" canvas "" style ={ canvasstyle } onmousedown ={ this . mousedown . bind ( this ) } onmousemove ={ this . mousemove . bind ( this ) } onmouseup ={ this . mouseup . bind ( this ) } > </canvas> </div> ); } } ` ` ` * versions <emphasis> * react : <number> . <number> safari : <number> . <number> ( <number> . <number> ) * os <emphasis> * os x el capitan version <number> . <number> * computer <emphasis> * model name : macbook air model identifier : macbookair6 , <number> processor name : intel core i7 processor speed : <number> ghz number of processors : <number> total number of cores : <number> l2 cache ( per core ) : <number> kb l3 cache : <number> mb memory gb",1
facebook/react,"warn for string refs where owner = __self sebastian wants to warn when ` owner ! = = __self ` , because this is the hard case to find when codemodding from string refs to callback refs .",1
facebook/react,"rfc : make refs opt - in * * note : this is my personal proposal . * * * * please don ’ t announce it anywhere as “ react dropping refs ” * * 😄 higher order components solve many problems of mixins , however they come with their own problems . the most painful one in my experience is that they hide the ref of the wrapped component , so they can ’ t be treated as transparent wrappers . this is well described in # <number> . as we prepare for de - emphasizing ` createclass ` and mixins i think it ’ s important that we * * treat higher order components as first class pattern in react , and provide full support for it without clashes with existing features * * . this means we need to fix refs to work well with higher order components . in the community , i see that people embrace stateless functional components even though they don ’ t have public instances and don ’ t support refs pointed at them . i think that this is a good indication that refs are moving from being a commonly needed feature to an escape hatch , and so it can be further de - emphasized by becoming opt - in . # # # what doesn ’ t change ` < div ref ={ . <repeated> } / > ` works like before and provides node in a callback . ` < statelessfunctionalcomponent ref ={ . <repeated> } / > ` works like before and provides ` null ` in a callback . # # # classes opt into exposing a ref in the spirit of <url> i propose that * * ` this . ref ` becomes an opt - in api on every class component . * * if you want your components to be “ reffable ” ( that is , to expose their public instances as refs ) , you need to manually call it in your constructor : ` ` ` js class mycomponent extends component { constructor ( props ) { super ( props ) this . ref ( this ) / / i am exposing my public instance ! } . <repeated> } / / will print mycomponent instance < mycomponent ref ={ instance => console . log ( instance ) } / > ` ` ` # # # by default , don ’ t expose refs if you don ’ t call ` this . ref ( this ) ` during the constructor , react will automatically call it with ` null ` : ` ` ` js class mycomponent extends component { . <repeated> } / / will print null < mycomponent ref ={ instance => console . log ( instance ) } / > ` ` ` this means that by default , class components will act just like functional components . there is no access to the instance unless the class opts in . # # # automatic cleanup if the class opts in , it only needs to call ` this . ref ` in the constructor . react will take care of automatically calling it with ` null ` when the component unmounts . # # # new ! forwarding a ref to another component * * this is the new feature here . * * since we opt into refs , we can cleanly support ref forwarding for higher order components : ` ` ` js function wrap ( wrappedcomponent ) { return class extends component { . <repeated> render ( ) { return < wrappedcomponent ref ={ this . ref } / > } } } ` ` ` by passing ` ref ={ this . ref } ` , we let ` wrappedcomponent ` supply its own instance , if available . this way the fact that it ’ s wrapped with a higher order component becomes unobservable . this also works fine if you conditionally switch between different components or delay rendering : ` ` ` js function wrap ( wrappedcomponent ) { return class extends component { . <repeated> render ( ) { return this . state . isready ? < spinner / > : < wrappedcomponent ref ={ this . ref } / > } } } ` ` ` let ’ s say ` isready ` is ` false ` initially . react would take care of calling ` this . ref ( null ) ` after the constructor ran ( since it knows the constructor never called ` this . ref ( this ) ` ) . so initially the parent receives ` null ` , as expected . when ` wrappedcomponent ` mounts , it will call ` this . ref ( this ) ` with its instance , which make it available to the parent . when ` wrappedcomponent ` unmounts , react will call ` this . ref ( null ) ` for its instance , cleaning it up again . the same works if we alternate between ` < wrappedcomponent ref ={ this . ref } / > ` and ` < someothercomponent ref ={ this . ref } / > ` . # # # upsides # # # # higher order components are unobservable this removes a common pain point in that wrapping a component with a hoc changes its public api . # # # # refs are further discouraged by making them opt - in , we better signal that you shouldn ’ t use them for data flow . the component can also be certain that changing or removing an imperative method is not a breaking change because by default it doesn ’ t expose the ref . if it exposes the ref , this is done intentionally . # # # # providing explicit imperative apis the component may also choose to provide a subset of methods as its public api : ` ` ` js class mycomponent extends component { constructor ( props ) { super ( props ) / / i am exposing just some stuff ! this . ref ( { focus : this . focus . bind ( this ) } ) } focus ( ) { . <repeated> } privatemethodidontwantanybodytocall ( ) { . <repeated> } } ` ` ` this lets the component choose _which_ methods it wants to expose imperatively , and which are still considered implementation details . # # # downsides # # # # migration cost this would be an easy enough codemod for most components ( just add ` this . ref ( this ) ` to any class component ) . but it ’ s still a cost considering some of those components are on npm and out of your control . arguably most third party components don ’ t provide imperative methods anyway , but this will cause some trouble . # # # # potential for misuse i can imagine people doing ` this . ref ( this ) ` and then ` < wrappedcomponent ref ={ this . ref } / > ` in the ` render ` method . this could get confusing but i don ’ t see any easy way to prevent or warn about this . # # # # too much freedom technically you ’ d be able to pass ` this . ref ( <number> ) ` , ` this . ref ( finddomnode ( this ) ) ` or other weird things . maybe we could limit possible values to react public instances and ` null ` . on the other hand , the ability to only provide a subset of methods as described in “ providing explicit imperative apis ” seems useful . # # # other considerations # # # # ` this . props . ref ` ? we could have provided ` ref ` inside ` this . props ` as ` this . props . ref ` . i would argue that we don ’ t want to do this for two reasons we want react to still “ manage ” it partially by calling ` this . ref ( null ) ` when component unmounts . otherwise it ’ s too easy to introduce memory leaks . having magic behavior for one of the props would be unexpected . - we don ’ t want ` { . <repeated> this . props } ` to transfer the ref over to the child as that would be unexpected in most cases . - - - what do you think ? cc <user> / react - core",1
facebook/react,"reactperf <number> . <number> - alpha . <number> expose isprofiling on the exported object ? i have tested the new perf tools on one of the screens in one app i am working on and it works great <happy> one thing i wanted also on the old one perf tools was to be able to check whether the perf tools are started or stopped , so basically exposing ` reactdebugtool ` ' s ` isprofiling ` variable . my use for that is that i have a keyboard shortcut ( in development ) bound to start / stop the perf tools and currently i am forced to maintain such a variable myself to know whether to start or stop ( which gets out of sync if i start / stop the perf tools without the keyboard shortcut ) . if you do not think it ' s worthwhile to expose ` isprofiling ` feel free to close this issue .",1
facebook/react,support for event . movementx / y [ feature - request ] currently it seems synthetic events do not have those properties on mousemove,1
facebook/react,"introduce __profile__ build as discussed in # <number> , we plan to add a new build configuration that does _not_ have the ` __dev__ ` overhead but that comes with the new ` reactperf ` enabled . this means that developer warnings , etc , will need to be gated by ` __dev__ ` , but the component tree (# <number> ) and some other events ( e . g . # <number> ) will need to be gated by ` __profile__ ` . i ’ m curious how this could be implemented . right now our system is simple : # # # current system # # # # variables - ` __dev__ = ( process . env . node_env = = ' production ' ) ` # # # # development build ( any ` node_env ` except ` ' production ' ` ) - ` __dev__ ` is ` true ` # # # # production build ( ` node_env ` is ` ' production ' ` ) - ` __dev__ ` is ` false ` as you can see , if ` process . env . node_env ` is omitted , we assume ` __dev__ ` mode . this is a sensible assumption , and not the one we want to change , as most projects today don ’ t specify anything as ` node_env ` in development , and we don ’ t want them to suddenly lose all developer warnings . therefore , i propose the following new system proposed system # # # # variables - ` __dev__ = ( process . env . node_env ! = = ' profile ' & & process . env . node_env ! = = ' production ' ) ` - ` __profile__ = ( process . env . node_env = = = ' profile ' ` ) # # # # development build ( any ` node_env ` except ` ' profile ' ` or ` ' production ' ` ) - ` __dev__ ` is ` true ` - ` __profile__ ` is ` true ` # # # # profile build ( ` node_env ` is ` ' profile ' ` ) - ` __dev__ ` is ` false ` - ` __profile__ ` is ` true ` # # # # production build ( ` node_env ` is ` ' production ' ` ) - ` __dev__ ` is ` false ` - ` __profile__ ` is ` false ` this would let us have three separate build configurations . we can use the same pattern in other ` fbjs ` projects as well , if desired . i would say it ’ s unlikely we ’ d ever want to add a separate fourth configuration so this should cover all our needs . any thoughts why this would be a bad idea ? should i implement this in ` fbjs ` ? cc <user> / react - core",1
facebook/react,"proposal node_env with react_env for __dev__ replacement this has come up a couple times lately as being an issue (# <number> , # <number> , # <number> ) , i think perhaps because we added the minification warning and people are ending up seeing they are not getting prod code when they expected it . but there ' s also the argument that you want react to be production and still use node_env for other purposes . there would be a few things to figure out to make sure envify works , and deciding what we do for other projects which currently also use the node_env pattern ( eg , relay , fbjs , third - party code , etc ) . this might not be a good idea at all though and definitely is not happening immediately , but wanted to start the discussion .",1
facebook/react,"support for asynchronous values ( like promises and observables ) at the moment , it is quite cumbersome to work with promises in react . either you write a lot of code to update the state inside the ` then ( ) ` callbacks or you use a library like [ react - promise ] ( <url> which only works for children ( not properties ) because it is based on components . another option is to traverse the whole virtual dom and replace promises before they are passed to react . ( i have read once a blog post about this but cannot find it any longer . ) this is obviously not ideal for the rendering performance . since promises are now a standard , i think there should be simpler way to use them directly in the view . one option would be to introduce an asyncvalue type with a promise implementation . the asyncvalue type would then be supported for children as well as properties . promises could then simply be used like this : ` ` ` javascript <div> { promise ( this . state . mypromise ) } </div> ` ` ` opposed to supporting promises everywhere ( directly without the promise function ) , this should not have unexpected side effects . moreover , other types of asynchronous values ( for example observables ) could be added later easily just by creating another asynctype implementation . angular <number> takes a similar route with the [ async pipe ] ( <url> there you can simply write ` ` ` javascript { { mypromise | async } } ` ` ` in attributes as well as normal content . this feature would also be very convinient for libraries like flux because it allows to fetch properties directly inside the view and avoids the reptition which you have with relay javascript <div> { promise ( this . state . model . get ( ' property ' ) ) } </div> ` ` ` what do you think about this proposal ? has this been discussed before ? i could not find a thread which covers this particular topic .",1
facebook/react,"componentdidunmount functionality ( in addition to componentwillunmount ) it would be great if it was possible to run some code after the component actually unmounted . this is useful where you consider the following : ` ` ` component parent { has service service has child child componentwillunmount : { destroys service } render : { service gets passed to child as prop } } component child { componentwillmount : { starts listening to service } componentwillunmount : { stops listening to service } } ` ` ` the above will throw exception during child componentwillunmount since parent gets unmounted first so service is already destroyed . if there existed componentdidunmount the service can be destroyed after the children are unmounted , i . e . ` ` ` component parent { has service service has child child componentdidunmount : { destroys service } render : { service gets passed to child as prop } } component child { componentwillmount : { starts listening to service } componentwillunmount stops listening to service } } ` ` `",1
facebook/react,"onfocusin / onfocusout events like mouse enter / leave , these are almost always what you want , not the ` onfocus ` and ` onblur ` events we currently expose . i run into this semi - frequently when actually doing product work . we should add them .",1
facebook/react,"feature request : innerhtml alternative i think many people agree that the ` dangerouslysetinnerhtml ={{ __html : . <repeated> } } ` api is gross even though there is great reasoning behind it . i have a few issues with it beyond it ' s verbosity that i think could be added as static method on the react class . # # # # my issues with ` dangerouslysetinnerhtml ` verbose and not always dangerous . <number> ) can not mix safe and unsafe html . <number> ) can not mix html with react elements . <number> ) have to manually concat html strings . - - - a better solution would be to provide a way to mark html as "" safe "" . ` ` ` js var react = require ( "" react "" ); / / use <hashtag> mark safe </hashtag> method to bypass reacts automatic html escaping . var myreactel = <div> { react . marksafe ( "" <br/> "" ) } </div> ; ` ` ` this is still explicitly telling react that we trust the html but solves all of the problems above . ` ` ` js / / mixing safe and unsafe html . ( <div> { react . marksafe ( "" <br/> "" ) } { "" <br/> "" } </div> ); / / mixing html with react elements . ( <div> { react . marksafe ( "" <br/> "" ) } <span> hello </span> </div> ); / / multiple innerhtml sets . ( <div> { react . marksafe ( "" <br/> "" ) } { react . marksafe ( "" <hr/> "" ) } </div> ); ` ` ` i think this api would be much friendlier than the current html api and probably would not even require a major version bump . thoughts ?",1
facebook/react,bug : infinite function component rendering with lazy loading unexpected behavior ( infinite function component rendering ) when lazy loading component with string interpolation ( reactive variable state ) react version : <number> . <number> rc3 # # steps to reproduce <number> . not working : ` ` ` javascript import { lazy } from ' react ' ; export default ( { langauge } ) => { const privacy = lazy ( ( ) => import ( ` . / privacy - ${ langauge } . jsx ` )); return < privacy />; }; ` ` ` <number> . working : ` ` ` javascript import { lazy } from ' react ' ; const privacypt = lazy ( ( ) => import ( ` . / privacy - pt . jsx ` )); const privacyes = lazy ( ( ) => import ( ` . / privacy - es . jsx ` )); const privacyen = lazy ( ( ) => import ( ` . / privacy - en . jsx ` )); export default ( { language } ) => { return ( < > { language = = = ' pt ' & & ( < privacypt / > ) } { language = = = ' es ' & & ( < privacyes / > ) } { language = = = ' en ' & & ( < privacyen / > ) } < / > ); }; ` ` ` link to code example [ screenshot from <number> - <number> - <number> <date> ] ( <url> # # the current behavior # # the expected behavior,2
facebook/react,"question on reconciliation let us say on first render , first datastore as below : ` ` ` json [ { id : <number> , name : "" duke "" } , { id : <number> , name : "" villanova "" } , { id : <number> , name : "" neclause "" } , { id : <number> , name : "" derk "" } , { id : <number> , name : "" lily "" } ] ` ` ` we render following : <ul> < li key = "" <number> "" > duke </li> < li key = "" <number> "" > villanova </li> < li key = "" <number> "" > neclause </li> < li key = "" <number> "" > derk </li> < li key = "" <number> "" > lily </li> </ul> i changed the datasource to ` [ { id : <number> , name : "" derk second time "" } , { id : <number> , name : "" lily second time "" } ] ` after a settimeout , what i expect on next render is : <ul> < li key = "" <number> "" > derk second time </li> < li key = "" <number> "" > lily second time </li> </ul> but it render the following result , key = "" <number> "" li remains in the dom tree , which i expect to be eliminated . <ul> < li key = "" <number> "" > duke </li> < li key = "" <number> "" > villanova </li> < li key = "" <number> "" > derk second time </li> < li key = "" <number> "" > lily second time </li> </ul> hower when i changed the datasource to ` [ ] ` after a settimeout , what i expect on next render is < li key = "" <number> "" > duke </li> < li key = "" <number> "" > villanova </li> < li key = "" <number> "" > derk second time </li> < li key = "" <number> "" > lily second time </li> </ul> out ot my expection , i got following a empty dom tree ? <repeated> a online demo is accessiable on <url> can someone explain the reconciliation for me this case , thanks",2
facebook/react,"react <number> : usestate ' sharing ' state value between components of the same type < - - ask a question or share feedback about the react <number> release here . - - > i created a custom table component that has pagination , search bar and export to excel button . the main usage of the component is as follows < clientstable dataset ={ sellsinfo } headers ={ sellsinfoheaders } downloadfilename ={ ` ordenescliente - ${ clientid } ` } pagesize ={ <number> } identifier ={ ' id ' } / > ` ` ` to enable pagination , global filter and dataset download , i used state variables using ` usestate ` hook , as follows . ` ` ` jsx const clientstable = ( props ) => { let { dataset , headers , pagesize , actions , identifier , downloadfilename } = props ; const [ displaydataset , setdisplaydataset ] = usestate ( dataset ) ; const [ pageindex , setpageindex ] = usestate ( <number> ); const numpages = math . ceil ( displaydataset . length / pagesize ) ; const [ cannextpage , setcannextpage ] = usestate ( true ) ; const [ canprevpage , setcanprevpage ] = usestate ( false ) ; const [ sortsmalltolarge , setsortsmalltolarge ] = usestate ( true ) ; const [ sortingfield , setsortingfield ] = usestate ( null ) ; / / some logic for filtering , pagination and rendering } ` ` ` rendering only one table component in an app view works just fine . however , rendering two or more implies that react uses the same state variables for all table components in the view . this is unintended behavior for me . in particular , i created a custom tab component that renders two different tables on tab selection . the two tables have the same state variables , different pros though , which causes conflicts in the view . how can i render multiple table components in my app without having this behavior ? thanks in advance .",2
facebook/react,"bug : setstate run twice with own hooks react version : <number> . <number> # # steps to reproduce <number> . click . app <number> . link to code example : ` ` ` js const usel = ( service ) => { const [ l , setl ] = usestate ( [ ] ) const [ ab , setab ] = usestate ( {}); const load = async ( ) => { const res = await service ( ) setab ( ( t ) => { / / log twice console . log ( "" <number> "" ); setl ( [ . <repeated> l , . <repeated> res . l ] ); return t ; }); } useeffect ( ( ) => { load ( ) } , [ ] ) return { list : l , load } } export default function app ( ) { const [ a , seta ] = usestate ( []); const { load } = usel ( ( ) => { return new promise ( res => { settimeout ( ( ) => { seta ( <number> ) res ( { l <number> ] } ) } , <number> ) } ) } ) const handle = ( ) => { load ( ); }; return ( < div classname = "" app "" onclick ={() => handle ( ) } > <h1> hello codesandbox </h1> <h2> start editing to see some magic happen </h2> </div> ); } ` ` ` why log twice * edited <emphasis> * by <user> to fix formatting .",2
facebook/react,"bug : useeffect happens synchronously when uselayouteffect was called react version : <number> . <number> ( also tested on <number> . <number> , same result ) # # steps to reproduce <number> . open this codesandbox : <url> ( [ source ] ( <url> <number> . try to click on the "" works "" button <number> . dropdown opens <number> . try to click on the "" broken "" button <number> . dropdown does not open < - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : <url> the issue is related to how ` useeffect ` calls are scheduled . we have this effect : ` ` ` js useeffect ( ( ) => { if ( ! open ) { return ; } const clicklistener = ( event ) => { if ( ! dropdownref . current . contains ( event . target ) ) { ondropdownclose ( ); } }; window . addeventlistener ( "" click "" , clicklistener ) ; return ( ) => { window . removeeventlistener ( "" click "" , clicklistener ) ; }; } , [ open , ondropdownclose ] ); ` ` ` normally , this effect happens asynchronously . however , sometimes , it is synchronous and we add listener to the ` window ` before the event fully bubbles and the dropdown gets closed by the same event . this only happens if any underlying component contains ` uselayouteffect ` with ` setstate ` call ( as shown on codesandbox ) . looks like this causes forced render and this chain of events . p . s . the report looks very similar to another one however , i decided to open a new issue , because the circumstances are different ( no portals in this case )",2
facebook/react,"state not getting updated properly while using usereducer with context api due to proprietary code issue , can not share the code but will explain the issue elaborately . i have two functions , * * function <number> * * and * * function <number> * * . inside * * function <number> * * , i am updating my state twice by calling dispatch with two different action . type each time . after updating my state , i want to call * * function <number> * * ( from * * function <number> * <wink> , and read state ' s value . but my state is not getting updated properly . can you please help me with this issue . i am using usereducer with context api , for state management .",2
facebook/react,"bug : inconsistent behavior between development and production builds i was trying to implement ` useon ` , a hook lets you write the following code : ` ` ` js useon ( ) . who ( window ) . when ( ' resize ' ) . what ( ( ) => { console . log ( ' resize ' ); }); ` ` ` my approach worked in production , but not in development . i discovered some pretty unexpected behavior by react . when running ` useon ` in development , it seemed like the resize event listener is not being removed when the resizecomponent gets unmounted ( turned out it was actually being added twice ) . so i added a ` console . log ` , just above the call to ` addeventlistener ` , but only one log appeared . i then added a ` debugger ` statement just above the call to ` console . log ` and noticed that it is indeed being called twice , but in the second time it ' s called , ` console . log ` is overwritten by react ' s ` disabledlog ( ) ` . react version : <number> . <number> # # steps to reproduce ( tip : you can skip checking out the repo ( steps <number> to <number> ) , as it can be reproduced in [ the repo ' s codesandbox ] ( <url> <number> . check out <url> <number> . ` yarn ` then ` yarn start ` <number> . ( chrome will start up ) <number> . open the devtools ' console <number> . click on "" mount resize component "" <number> . resize window <number> . ( you should see "" resize ! "" printed in the console ) <number> . click on "" unmount resize component "" <number> . "" resize ! "" messages should stop showing up in the console , but they do not . i did make some un - orthodox stuff in that hook . but i believe this is a bug since when trying this hook in a production build , it worked fine . to test out a production build : ( tip can skip checking out the repo ( steps <number> to <number> ) , as it can be reproduced in [ the repo ' s deployed version ] ( <url> <number> . check out <url> <number> . ` yarn ` then ` yarn start : prod ` <number> . complete steps <number> - <number> from above ❤️",2
facebook/react,"bug : <number> . <number> npm packages were not built from <number> . <number> source code ? < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> . <number> # # steps to reproduce <number> . go at <url> <number> . then reproduce the famous "" warning "" (* * the issue is not about this warning * <wink> ! [ image ] ( <url> ( type something in the tool id ) ( the codesandboxe may freeze a little bit , try to reload the page ) <number> . open the browser console ( chrome in my case ) and you will see ! [ image ] ( <url> then go to the code ( red arrow on the image above ) <number> . make a breakpoint here ! [ image ] ( <url> reload the page and initiate the "" warning "" again ( see <number> ) <number> . go down the callstack and you can see the "" warning "" is written by this code ! [ image ] ( <url> <number> . now the question . <repeated> i am using the <number> . <number> version and this code should not exist there . check this out <url> and you can find only this : ! [ image ] ( <url> as you can see instead of ` error ( ' a component is changing . <repeated> ` we have ` console . error ( ' a component is changing . <repeated> ` . the changes were made by this <url> long time ago . <number> . does it mean that <number> . <number> version of react and react - dom packeges were not built from this source code <url> ? seems like a big issue then . <number> . it happens without codesandbox as well . < ! - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : <url> < ! - - please provide a codesandbox ( <url> a link to a repository on github , or provide a minimal code example that reproduces the problem . you may provide a screenshot of the application if you think it is relevant to your bug report . here are some tips for providing a minimal example - - > # # the current behavior we keep seeing the word "" warning "" ( which is produced by ` warning ` function , though it ' s not a warning but an error ) ! [ image ] ( <url> # # the expected behavior we should not see the word "" warning "" if the packages v . <number> . <number> were bilt from <url> sourcecode ( because it calls ` console . error ( ' a component is changing . <repeated> ` instead of ` error ( ' a component is changing . <repeated> ` ) ! [ image ] ( <url>",2
facebook/react,mixin rewrite with react and higher - order - functions <user> how would you re - write the following mixins ? <url> helpers . js,2
facebook/react,"can i help ? hi guys , i would really like to join you in order to help with the maintenance of react . my change proposal is to apply the clean code rules to react codebase ; for example better name to variables - single point of return - have short functions with a single purpose - . <repeated> in order to avoid a long code review process , i would like to make <number> pr for each package that i am going to edit . i have already signed the cla . hope you will be interested in this , matteo",2
facebook/react,react build files contain the version of react being used is there any way to hide react version or is it designed to have react versions in the build files which are given in the production,2
facebook/react,suggestion release date in the experimental ( <number> . <number> ) version <url> it ' s hard to know which one is the latest experimental react version in the ` yarn ` or ` npm ` . <number> . <number> - experimental - ede917064 <number> . <number> - experimental - 4 c8c98ab9 <number> . <number> - experimental - 7 f28234f8 can you tell which one is newer without doing querying on the web ? i suggest adding a release date in the version . ` <number> . <number> - experimental - <number> - 3 d0895557 `,2
facebook/react,"bug inspect well react warnings for ` componentwillreceiveprops has been renamed ` cf the screenshot bellow . i have no ` componentwillreceiveprops ` in my code , so the warning comes from a library . i do not know how to quickly identify which library causes this warning and make a fix pull request on the repo of this library . any tips to also remove the warning ? thanks a lot [ image ] ( <url>",2
facebook/react,"which approach is better for getting data from state ? let us say our state is as follows : ` ` ` state : { user : { name : ' dave ' , email } } ` ` ` so while getting the user property from the state which one of the following should i do ? * * case <number> : * * ` ` ` const user = this . state . user this way following is valid user = = this . state . user / / true user . name = ' manny ' ; console . log ( this . state . user . name ) / / manny ` ` ` though it will not cause re - render until we use setstate ( ) but basically the value of the state variable has changed . * * case <number> : * * ` ` ` const user = { . <repeated> this . state . user } ; this way user = = this . state . user / / false user . name = ' manny ' ; console . log ( this . state . user . name ) / / dave ` ` ` which approach is better or are there any side effects of any of them ?",2
facebook/react,"when waiting for an async action to end , and in the meantime the state changes , there is no way to know about the change < - - in a functional component , when waiting for an async action to complete and meanwhile changing any state - at the end of the async action the component stays in the previous lifecycle , thus does not know about the state change . - - > react version : <number> # # steps to reproduce <number> . create a functional component with <number> elements <number> . the component will have an integer - counter prop and is initialised with <number> value . <number> . the first element has an "" onclick "" action , which increases the counter . <number> . the second element has an "" onclick "" action , which is asynced and waits for a timeout promise and only then increases the counter . <number> . press the second element , and while waiting for the async action to complete press the firs element as well . ` ` ` import react , { usestate } from "" react "" ; export default function app ( ) { const [ counter , setcounter ] = usestate ( <number> ); return ( < div classname = "" app "" > <div> < button onclick ={ async ( ) => { await new promise ( resolve => { settimeout ( ( ) => { resolve ( ); } , <number> ); }); setcounter ( counter + <number> ); } } > async </button> <label> { counter } </label> </div> <div> < button onclick ={() => { / / increases the counter state setcounter ( counter + <number> ); } } > add <number> </button> <label> { counter } </label> </div> </div> ); } ` ` ` link to code example : <url> - - a different version of the same issue <url> # # the current behavior current behaviour : the counter value at the end of the async action will equal to <number> # # the expected behavior expected behaviour counter value at the end of the async action will equal to <number>",2
facebook/react,"bug : react function getting called for no reason < - - the problem is that a random function is getting called up , for no reason , i tried to trace it and looked like there is a problem with react - development . react - development is calling a long ago used function - - > react version : ^ <number> . <number> # # steps to reproduce <number> . click on task <number> <number> . check the dsdfdsf tab , and check it <number> . click on create a new task <number> . create a new task link to code example code - - > <url> - - > # # the current behavior when adding a new task , the last used function of a different component gets called for no reason . the milestone of the list gets cleared when adding a new task # # the expected behavior the function should not be called , the already existing list should not be cleared",2
facebook/react,"click event and settimeout update state , different times of rendering when i try to batch update all the states with click events , the final render is once . when the state is updated in batch with settimeout , the result is multiple times . may i ask what is the usestatehook running mechanism inside react ? is the same asynchronous function , but the times of rendering is not the same ? react version : <number> . <number> # # steps to reproduce <number> . bind a single click event to the dom and handle multiple state updates in batches <number> . after the component is mounted , create a settimeout timer , which is also a batch update of state < - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example # # the current behavior click event batch update and timer batch update rendering times are different # # the expected behavior also triggers an update what is the operation mechanism of usestate hook ? why not the same number of asynchronous renderings ?",2
facebook/react,"bug : function component cannot have ref property when passing ref property to a function component , validatefunctioncomponentindev shows a warning about it being a bad thing . react version : head while this might have been true for stateless function components ( as many places refer to func components ) , probably since the introduction of hooks , they can have state , and i had the impression that one could rewrite any class component into a function based one . ` ` ` function testcomponent ( { ref } ) { const [ state ] = react . usestate ( { statefield1 }); assignref ( ref , state ) ; return ( <div> { state . statefield1 } </div> ); } this code wont work , caller would never be able to get the answer . caller is sad . ` ` ` # # the current behavior react giving a warning and making the ref prop defunct . # # the expected behavior remove limitation and let ref on my function component live happily ever after .",2
facebook/react,"{ [ styles . box , { transform : [ { scale : this . state . scalenum } ] } ] } > 当这样给scale赋值时 ， 初始化生效 ， 但是在一个事件中改变scalenum的值 ， scalenum的值改变了 ， 页面貌似没有重新渲染 ？ < view style ={[ styles . box , { transform scale : this . state . scalenum } ] } > 当这样给scale赋值时 ， 初始化生效 ， 但是在一个事件中改变scalenum的值 ， scalenum的值改变了 ， 页面貌似没有重新渲染 ？",2
facebook/react,question not problem just question in my mind why all implements of hooks in ` react - dom ` and we have to import from ` react ` ? just i want to know about it,2
facebook/react,"question : how to use "" useref "" when it is passed through portal ? hi . i create ` ref ` in root component in my app . when i bind ` ref ` to element , which is a child of another element that is render in the portal , ref "" current "" property is always ` undefined ` . sandbox with example here how can i use refs with portals with expected behaviour ?",2
facebook/react,"question : can i lie to useeffect about its dependencies in this case ? you [ frequently ] [ <number> ] [ see ] [ <number> ] warnings that you should not lie to ` useeffect ` and ` usememo ` about their dependencies . i am wondering about this special case , which i see throughout the codebase at work : ` ` ` useeffect ( ( ) => { / / we want effect to run when a changes , but not b dostuff ( a , b ) , [ a ] ) ` ` ` let us say ` a ` changes every <number> seconds , and ` b ` changes every second , and we want to ` dostuff ` whenever ` a ` changes . this works , is simple and elegant . yet all guides discourage this , suggesting to do this instead : ` ` ` let bref = useref ( ) useeffect ( ( ) => { bref . current = b } ) useeffect ( ( ) => { dostuff ( a , bref . current ) } , [ a ] ) ` ` ` why ? are not those equivalent ? i could see a potential issue with ` usememo ( ( ) => compute ( a , b ) , [ a ] ) ` . it can be accessed in the entire component , and sometimes it will be stale , which contradicts the meaning of memoization . but what about that useeffect case ? [ <number> <sad> <url> [ <number> ]",2
facebook/react,"question : can usememo be used instead of useref ? hi , just out of curiosity can ` usememo ` be used instead of ` useref ` when doing it as following : example : ` ` ` javascript const ref = useref ( null ) ; const ref2 = usememo ( ( ) => { current } , []); ` ` ` it looks to me that both refs will be working just fine as dom ref and as mutable value similar to instance fields in classes . why then ` useref ` is implemented differently comparing to ` usememo ` considering [ reactfiberhooks . js ] ( <url> code for ` useref ` and ` usememo ` ? thanks",2
facebook/react,"bug : react - devtools profiler does not show props < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > according to docs , it ' s possible to see props and state of a component at each commit . <url> yet , in every project i have tried all i see is the names of changed props , but not their values , like the gif from docs claims . react version : <number> . <number> extension ( <date> ) . <repeated> created from revision f749045a5 on <date> # # steps to reproduce <number> . create counter app with cra or another method <number> . open profiler and change state <number> . observe how only the name of the prop is visible , but not its value < ! - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > ` ` ` function app ( ) { let [ a , seta ] = usestate ( <number> ); return ( < div classname = "" app "" > < button onclick ={() => seta ( v => v + <number> ) } > inc </button> < kid a ={ a } / > </div> ); } function kid ( ) { return null ; } ` ` ` # # the current behavior [ current behavior ] ( <url> # # the expected behavior [ expected behavior ] ( <url> am i doing something wrong or has this feature been removed ? i know you can see props in the inspector , but there it ' s only the most recent ones .",2
facebook/react,question the usecontext hook be used without a provider ? is it a correct form to use the usecontext hook without the enclosing provider ? see this simple [ sandbox ] ( <url> which uses the jedicontext . provider . in this modified [ sandbox ] ( <url> i removed the provider and the usecontext hook still works . what are the consequences of using the usecontext hook without a provider ?,2
facebook/react,"question have a lot of very nice and smart vuejs components . is there a way to use it in an react project ? 🚨 this issue tracker is not for questions . 🚨 as it happens , support requests that are created as issues are likely to be closed . we want to make sure you are able to find the help you seek . please take a look at the following resources . # # coding questions if you have a coding question related to close this page - now and close this page - now dom , it might be better suited for stack overflow . it ' s a great place to browse through frequent questions about using close this page - now , as well as ask for help with specific questions . <url> this page - now # # talk to other close this page - now developers there are many online forums which are a great place for discussion about best practices and application architecture as well as the future of close this page - now . https :// close this page - nowjs . org / community / support . html <hashtag> popular discussion forums </hashtag> # # proposals if you ' d like to discuss topics related to the future of close this page - now , or would like to propose a new feature or change before sending a pull request , please check out the discussions and proposals repository . <url> this page - nowjs / rfcs",2
facebook/react,"bug : useref can not return a persist ref object < - - please provide a clear and concise description of what the bug is . include screenshots if needed . please test using the latest version of the relevant react packages to make sure your issue has not already been fixed . - - > react version : <number> . <number> # # steps to reproduce <number> . click button ， view print data <number> . click button ， view print data < ! - - your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . issues without reproduction steps or code examples may be immediately closed as not actionable . - - > link to code example : <url> < ! - - please provide a codesandbox ( <url> a link to a repository on github , or provide a minimal code example that reproduces the problem . you may provide a screenshot of the application if you think it is relevant to your bug report . here are some tips for providing a minimal example - - > # # the current behavior every time you click the button , the printed data will change # # the expected behavior every time i click the button , the printed data should be an empty object",2
facebook/react,the worst arabic translation language and translation i am sure that you translated your react site by google the worst result at all i hope you correct it <url>,2
facebook/react,"in react and react - dom <number> upgrade , getting error : uncaught typeerror : cannot read property ' input ' of undefined i am trying to upgrade my reactjs and react - dom versions from v15 . <number> to ^ v16 . <number> and am getting the above error . clicking through the error in the console , i see that the _react $ dom is undefined . i have followed all the migration instructions on the react . org site and looked extensively , but cannot seem to get rid of this error on versions of react and react - dom of v16 and above . any ideas on what that issue is and how i can resolve it ? below are my package . json and webpack . config . they are pre - upgrade to v16 , but i have tried adding core - js per reactjs . org . ` ` ` var _react $ dom = _react2 . default . dom , input = _react $ dom . input , < < < here is the highlighted error select = _react $ dom . select , textarea = _react $ dom . textarea ; my dependencies in package . json : ` ` ` ` ` ` "" devdependencies "" : { "" babel - loader "" : "" ^ <number> . <number> "" , "" babel - preset - es2015 "" : "" ^ <date> "" , "" babel - preset - react "" : "" ^ <date> "" , "" babel - preset - stage - <number> "" : "" ^ <number> . <number> "" , "" chai "" : "" ^ <number> . <number> "" , "" chai - jquery "" : "" ^ <number> . <number> "" , "" css - loader "" : "" ^ <number> . <number> "" , "" eslint - config - rallycoding "" : "" ^ <number> . <number> "" , "" mocha "" : "" ^ <number> . <number> "" , "" react - addons - test - utils "" : "" ^ <number> . <number> "" , "" style - loader "" : "" ^ <number> . <number> "" , "" webpack - cli "" : "" ^ <number> . <number> "" , "" webpack - dev - server "" : "" ^ <number> . <number> "" } , "" dependencies "" : { "" actioncable "" : "" ^ <number> . <number> "" , "" axios "" : "" ^ <number> . <number> "" , "" babel - core "" : "" ^ <number> . <number> "" , "" babel - polyfill "" : "" ^ <number> . <number> "" , "" babel - preset - stage - <number> "" : "" ^ <date> "" , "" cloudinary - core "" : "" ^ <number> . <number> "" , "" cloudinary - react "" : "" ^ <number> . <number> "" , "" dotenv - webpack "" : "" ^ <number> . <number> "" , "" file - loader "" : "" ^ <number> . <number> "" , "" jquery "" : "" ^ <number> . <number> "" , "" jsdom "" : "" ^ <number> . <number> "" , "" lodash "" : "" ^ <number> . <number> "" , "" prop - types "" : "" ^ <number> . <number> "" , "" react "" : "" ^ <number> . <number> "" , "" react - bootstrap "" : "" ^ <number> . <number> "" , "" react - day - picker "" : "" ^ <number> . <number> "" , "" react - dom "" : "" ^ <number> . <number> "" , "" react - dropzone "" : "" ^ <number> . <number> "" , "" react - helmet "" : "" ^ <number> . <number> "" , "" react - redux "" : "" ^ <number> . <number> "" , "" react - router - dom "" : "" ^ <number> . <number> "" , "" react - stripe - elements "" : "" ^ <number> . <number> "" , "" redux "" : "" ^ <number> . <number> "" , "" redux - form "" : "" ^ <number> . <number> "" , "" redux - thunk "" : "" ^ <number> . <number> "" , "" sha1 "" : "" ^ <number> . <number> "" , "" webpack "" : "" ^ <number> . <number> "" } ` ` ` my webpack . config : ` ` ` const webpack = require ( ' webpack ' ); const dotenv = require ( ' dotenv - webpack ' ); const raf = require ( ' raf ' ) const path = require ( ' path ' ); module . exports = { mode : ' none ' , watch : false , entry : [ ' babel - polyfill ' , ' . / src / index . js ' ] , output : { path : __dirname , publicpath : ' / ' , filename : ' bundle . js ' } , module : { rules : [ { test : / \ \ . ( jpg | png | svg ) $/ , use : [ { loader : ' file - loader ' , options : { name : ' [ path ] [ name ] . [ hash ] . [ ext ] ' } } ] } , { test : / \ \ . js ? $/ , exclude : / node_modules / , use : { loader : ' babel - loader ' , options : { presets : [ ' react ' , ' es2015 ' , ' stage - <number> ' ] } } } ] / / end of loaders devserver : { historyapifallback : true , contentbase : ' . / ' } , plugins : [ new webpack . defineplugin ( { ' process . env . node_env ' } ) , new dotenv ( ) ] }; ` ` `",2
facebook/react,"my navbar work fine until next day hi , i am newbie for web dev . i am starting learning react and next . js and i got issue now i have to do a navbar so i use navbar from reactstrap to my next . js project it work fine but nextday i open my project and then my project kaboom . = = error : invalid hook call . hooks can only be called inside of the body of a function component . this could happen for one of the following reasons you might have mismatching versions of react and the renderer ( such as react dom ) <number> . you might be breaking the rules of hooks <number> . you might have more than one copy of react in the same app see <url> for tips about how to debug and fix this problem . ▶ <number> stack frames were collapsed . example . / components / mainnav . js : <number> <number> | import ' bootstrap / dist / css / bootstrap . min . css ' <number> | <number> | const example = ( props ) => { > <number> | const [ isopen , setisopen ] = usestate ( false ) ; <number> | <number> | const toggle = ( ) => setisopen ( isopen ) ; <number> | view compiled ▶ <number> stack frames were collapsed . = = this is my navbar code = = ` ` ` import react , { usestate } from ' react ' ; import { collapse , navbar , navbartoggler , navbarbrand , nav , navitem , navlink , uncontrolleddropdown , dropdowntoggle , dropdownmenu , dropdownitem , navbartext } from ' reactstrap ' ; import ' bootstrap / dist / css / bootstrap . min . css ' const example = ( props ) => { const [ isopen , setisopen ] = usestate ( false ) ; const toggle = ( ) => setisopen ( ! isopen ) ; return ( <div> < navbar color = "" light "" light expand = "" md "" > < navbarbrand href =""/ "" > reactstrap </navbarbrand> < navbartoggler onclick ={ toggle } / > < collapse isopen ={ isopen } navbar > < nav classname = "" mr - auto "" navbar > <navitem> < navlink href =""/ "" > home </navlink> </navitem> <navitem> < navlink href =""/ "" > what </navlink> </navitem> <navitem> < navlink href =""/ "" > who </navlink> </navitem> <navitem> < navlink href =""/ "" > branch </navlink> </navitem> <navitem> < navlink href =""/ "" > where </navlink> </navitem> <navitem> < navlink href =""/ "" > when </navlink> </navitem> <navitem> < navlink href =""/ "" > faqs </navlink> </navitem> <navitem> < navlink href =""/ "" > game </navlink> </navitem> </nav> <navbartext> simple text </navbartext> </collapse> </navbar> </div> ); } export default example ; ` ` ` = = what wrong is it and what should i do to resolve this . thank .",2
facebook/react,"function passed as parameter and saved in context api store takes old store from context api when i get <number> status code from backend i run refreshtoken method with passing the function where expired token occurred . in refreshtoken method i get new token and set in refreshtokenlastfunc property function from parameter . then i watch when refreshtokenlastfunc was updated using react useeffect and run once again the function where expired token occurred . the problem is while i run store . refreshtokenlastfunc ( ) in useeffect , the function in refreshtokenlastfunc property uses old context api store ( so it uses old token not the new one ) . you can read my comment in useeffect for store . refreshtokenlastfunc . * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i do not actually know if it is a react bug or i do not understand js properly * * what is the current behavior ? * * if i ran * * store . refreshtokenlastfunc * * function in useeffect it takes old store , not the new one * * what is the expected behavior ? * * i want * * store . refreshtokenlastfunc * * function to run with new store , because store was modified before this function run * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react verison : <number> . <number> browser : google chrome : <number> my code : ` ` ` js export const storeprovider = props => { const gettoken = ( ) => localstorage . getitem ( "" token "" ); const initstate = ( ) => ( { token : gettoken ( ) , isauth : false , userrole : "" old role "" , mainurl : mainurl , apiurl : apiurl , refreshtokenlastfunc : ( ) => { } }); const [ store , setstore ] = usestate ( initstate ( )); const getuserinfo = async ( ) => { if ( gettoken ( ) ) { try { const apiconfig = { method : "" get "" , headers : { "" content - type "" : "" application / json "" , authorization : ` bearer ${ store . token } ` } }; const response = await fetch ( ` ${ store . apiurl } get - me ` , apiconfig ) ; const responsejson = await response . json ( ); if ( response . ok ) { / / update context api setstore ( { . <repeated> store , userrole : responsejson . role , username : responsejson . name , usergroupid : responsejson . group_id , isauth : true }); } else if ( response . status = = = <number> ) { refreshtoken ( getuserinfo ) ; } else { throw new error ( ` some error occurred ` ); } } catch ( error ) { console . log ( error ) ; } } }; const refreshtoken = async func => { try { const apiconfig = { method : "" get "" , headers : { accept : "" application / json "" , authorization : ` bearer ${ store . token } ` } }; const response = await fetch ( ` ${ store . mainurl } refresh - token ` , apiconfig ) ; const responsejson = await response . json ( ); if ( response . ok ) { / / update token in local storage localstorage . setitem ( "" token "" , responsejson . token ) ; / / update context api setstore ( { . <repeated> store , userrole : "" new role "" , token : responsejson . token , refreshtokenlastfunc : func }); } else { throw new error ( ` some error . <repeated> ` ); } } catch ( error ) { throw error ; } }; useeffect ( ( ) => { getuserinfo ( ); } , []); useeffect ( ( ) => { / / if i console log my store before calling function , store is correctly updated , but the function uses old store . console . log ( "" store from useeffect store ) ; / / store . userrole = ' new role ' which is correct store . refreshtokenlastfunc ( ); / / store . userrole = ' old role ' which should be ' new role ' } , [ store . refreshtokenlastfunc ] ); return ( < storecontext . provider value ={[ store , setstore , logout , getuserinfo ] } > { props . children } < / storecontext . provider > ); }; ` ` `",2
facebook/react,how can i change react umd version in node_modules ? i saw react package have ` cjs ` and ` umd ` folder and ` index . js ` in react output ` cjs ` version so if i want to use ` umd ` how can i change ? [ image ] ( <url>,2
facebook/react,"opinions on ionic reac hello , feasibility of making a project in ionic reaction . i am interested in knowing more about ionic react . and i would like to know if it is advisable to do a project with ionic react . how scalable the project would be . and you can use all the tools that have both ionic and rea , example maps , notifications , routes , among others . i appreciate if you can advise me . thank you",2
facebook/react,"unexpected function component call using usestate * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * question <emphasis> * * what is the current behavior ? * * ` ` ` typescript import react , { usestate , useeffect } from "" react "" ; import reactdom from "" react - dom "" ; import "" . / styles . css "" ; function child ( ) { console . log ( "" child render "" ); return null ; } function app ( ) { const [ count , setcount ] = usestate ( <number> ); console . log ( "" render "" ); useeffect ( ( ) => { console . log ( "" count changed "" , count ) ; } , [ count ] ); return ( <div> <h2> usestate </h2> <p> clicked : { count } </p> < button onclick ={() => { setcount ( count + <number> ); } } > + <number> </button> < button onclick ={() => { setcount ( count ) ; } } > + <number> </button> < child / > </div> ); } const rootelement = document . getelementbyid ( "" root "" ); reactdom . render ( < app / > , rootelement ) ; ` ` ` there are two button in this count example . clicking one makes count + <number> ， another makes count no change . if clicking the no change button first , "" render "" will not be logged . but if clicking the + <number> button first and then clicking anthor ， "" render "" will show twice , but "" "" child render "" will only show once . i found the explain in document . > if you update a state hook to the same value as the current state , react will bail out without rendering the children or firing effects . ( react uses the object . is comparison algorithm . ) does react only promise that children component will not be rendered in this situation ? the current component may still be rendered ? this is an example in sandbox . <url> * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * "" react "" : "" ^ <number> . <number> "" , "" react - dom """,2
facebook/react,"question about this . state and this . setstate here is my question : there is a multiselect child component , the value is maintained in its parent component [ this . state . values ] like this : parent { state ={ values :[] } render ( ) { return ( multiselect value ={ this . state . values } ) } } in the multiselect ' s [ onchange ] function i control the multiselect value in two ways and two different render results : first : onchange = ()=> { this . setstate ( { values : this . handlevalue ( this . state . values ) }); } handlevalues = ( values ) =>{ / / here to add or splice , eg : values . push ( ' treenode1 ' ); return values } when i print this . state . values in the render ( ) function , the ' treenode1 ' is added , however ths multiselect component ' s ' treenode1 ' option wasn , t selected ; but if change the onchange ( ) function like this , it works right : onchange = ()=> { this . setstate ( { values : this . handlevalue ( object . assign ( [ ] , this . state . values ) )}); } i pass the copy of the [ this . state . values ] rather than [ this . state . values ] . i , m confused . i know that we can , t change varibles in the state directly , however in the first way , [ this . state . values ] in the render ( ) function is added by ' treenode1 ' , it looks correctly . here is my guess maintains a real state . when react renders it can get the ' real ' state of [ this . state . values ] which works actually rather than the [ this . state . values ] that i changed directly in the onchange function by adding ' treenode1 ' . the state value [ this . state . values ] printed in the render ( ) function looks correct , because the directly change in the handlevalues ( ) function rather than changed by this . setstate ( ) . i wonder how and why this happens and is my guess right ? <happy>",2
facebook/react,why useeffect ' s default behavior is to run on every render ? * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * api design question about ` useeffect ` * * what is the current behavior ? * * currently ` useeffect ` runs on every render . this default behavior can be dangerous in situations like dealing with http requests when you forget to pass the second argument . this seems to be a common mistake especially for newcomers like myself . i can not think of many ( any ) patterns where you want to run ` useeffect ` on every render . what was the reasoning behind not defaulting to run once ?,2
facebook/react,"static rendering strategy does not work on codesplitted routes i am not really sure if it is a bug or not but i am facing problems trying to use static rendering strategy + injecting dom elements manually to a non hydrated react component . * * what is the expected behavior ? * * the thing that i expect to do is the next : <number> - render a component on server side and server it to client <number> - on the head of my app having a js that will inject some dom elements ( ads ) on non hydratable components . <number> - on client avoid hydratation of that component using the hacky thing of empty dangeroushtml * * what is the current behavior ? * * the thing that i expect to do is the next - render a component on server side and server it to client <number> - on the head of my app having a js that will inject some dom elements ( ads ) on non hydratable components . <number> - on client hydratation the code is throwing a ssr vs csr missmatch and is re - building everything . i have tested it on pages without code - splitting and them seem to work like a charm , only have this behavior on code splitted routes . what i am doing wrong ?",2
facebook/react,"missing react tab in chrome dev tools < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * * * what is the current behavior ? * * there is no react tab in my chrome dev toolbar anymore . i have deleted and reinstalled the react extension but the issue was not resolved . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * * * what is the expected behavior ? * * there use to be a react tab in the chrome dev console toolbar * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * i am using ios on google chrome .",2
facebook/react,""" devtools v4 is incompatible with this version of react "" with react native & latest version of react < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * after starting react - devtools , i get the following error message : ` ` ` devtools v4 is incompatible with this version of react either upgrade react or install react devtools v3 * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * * use expo cli to initialize an expo app * run ` yarn add react <user> ` to ensure the most recent version of react is installed ( currently v16 . <number> ) * run ` yarn add react - devtools ` to install react - devtools * run ` yarn start ` to start the app * run ` npx react - devtools ` to open react - devtools * * what is the expected behavior ? * * react - devtools should work with react native and the latest version of react * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number> . <number> react native <number> . <number> fedora <number>",2
facebook/react,""" de - opting to synchronous mode "" in use - subscription readme < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * outdated readme ( maybe ? ) * * what do the docs currently say ? * * > use - subscription is safe to use in concurrent mode . however , [ it achieves correctness by sometimes de - opting to synchronous mode ] ( <url> obviating the benefits of concurrent rendering . in the linked issue , <user> [ explains ] ( <url> that this is referring to chains of synchronous updates using ` componentdidupdate ` . however , the ` usesubscription ` hook now uses a passive ` useeffect ( ) ` , as opposed to a synchronous ` componentdidupdate ( ) ` . would this mean that it ' s no longer "" de - opting to sync mode "" , and the warning could be removed from the readme ?",2
facebook/react,can not get the profiler screenshot feature working in the react devtools i have recently come across [ this tweet ] ( <url> and saw that the new devtools profiler apparently would be able to capture images of the dom after each commit and display them on the right side ( below the commit information ) . was this feature indeed added to devtools <number> . <number> ? or is it coming out in a future version ? just asking because i did not manage to get it working while trying with my projects . * react <emphasis> * * * browser : * * google chrome <number> . <number> * * devtools : * * <number> . <number> - a8b8ffb89,2
facebook/react,"components not correctly displayed * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * elements not reconized * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * only use components tab in console of chrome . * * what is the expected behavior ? * * see any elements react * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * window <number> 6 4 bit react ^ <number> . <number> [ image ] ( <url> this is my console component visualizzation , the same page visualizated with linux & chrome not have any issue",2
facebook/react,"plans for handling ` hidden ` differently in one of talks about react suspense [ dan mentioned ] ( <url> that ` < div hidden ={ true } / > ` would be deprioritized by react but still rendered if it has the time . in his example he used it to prerender content that was seemingly part of another page . however in another talk by andrew it was used to [ prerender tabs ] ( <url> the second showcase is incorrect according to the [ living standard for this attribute ] ( <url> the hidden attribute must not be used to hide content that could legitimately be shown in another presentation . for example , it is incorrect to use hidden to hide panels in a tabbed dialog , because the tabbed interface is merely a kind of overflow presentation — one could equally well just show all the form controls in one big page with a scrollbar . i do not necessarily agree with the reasoning given in the spec but i am more interested if the core team is aware of this conflict and if there are plans to resolve this somehow or simply ignore it .",2
facebook/react,"add third parameter to usestate to get current value * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * if you set a callback on something , e . g . inside useeffect , your callback captures the current value of that state and can never update it . to know the most up - to - date value , you currently have to call the setter with a function containing the new value , even if you only return the value you receive from it . cf . <url> * * what is the expected behavior ? * * there should be a way to access the current state via a getter for these situations . adding this as a third return value from usestate would be non - intrusive and backwards compatible . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * n / a",2
facebook/react,"react devtools downgrade not working for chrome . * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * the following command fails ` ` ` yarn run test : chrome ` ` ` error message : ` ` `  yarn run v1 . <number> $ node . / shells / chrome / test internal / validators . js : <number> throw new err_invalid_arg_type ( name , ' string ' , value ) ; ^ typeerror [ err_invalid_arg_type ] "" file "" argument must be of type string . received type object at validatestring ( internal / validators . js : <number> <time> ) at normalizespawnarguments ( child_process . js : <number> : <number> ) at spawn ( child_process . js : <number> <time> ) at launchchrome ( / home / andrei / src / react - devtools / node_modules / chrome - launch / index . js : <time> ) at object . <anonymous> ( / home / andrei / src / react - devtools / shells / chrome / test . js : <number> : <number> ) at module . _compile ( internal / modules / cjs / loader . js : <number> <time> ) at object . module . _extensions . <repeated> js ( internal / modules / cjs / loader . js : <number> <time> ) at module . load ( internal / modules / cjs / loader . js : <number> <time> ) at function . module . _load ( internal / modules / cjs / loader . js : <number> <time> ) at function . module . runmain ( internal / modules / cjs / loader . js : <number> <time> ) error command failed with exit code <number> . ` ` ` * * what is the expected behavior ? * * launch a new browser window . the following command works ` ` ` yarn run test : firefox ` ` ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * using version <number> . <number> ( official build ) ( <number> - bit ) , / usr / bin / google - chrome - stable is aliased to chrome . any help is appreciated , we are running a old version of react at work and upgrading it would be nontrivial . hence i need the old version of the react devtools .",2
facebook/react,"[ dev tools ] chrome component console errors get output from "" backend . js "" * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * when i get a component stack trace , the log trace comes from the dev tools extension * * what is the expected behavior ? * * i use that trace usually to click and set a debugger so i can debug some react internals .",2
facebook/react,"inline settimeout within the render causes a random number to appear on screen . reporting a bug : the current behaviour is that settimeout , inside a render method , is producing a random number , for no explained reason . the number persist after the settimeout has gone off , and the settimeout still produces the desired effect , for example , if it was to log something the console , it would still do that . ` ` ` jsx / / sample code ( not the original code in which the problem occurred , but i was able to reproduce the problem in codesandbox . io ) : * * start of code example * * ( styles . css = . app { font - family : sans - serif ; text - align } ) import react from "" react "" ; import reactdom from "" react - dom "" ; import "" . / styles . css "" ; function app ( ) { return ( < div classname = "" app "" > <h1> hello codesandbox </h1> <h2> start editing to see some magic happen </h2> { settimeout ( ( ) => console . log ( "" hello world "" ) , <number> ) } </div> ); } const rootelement = document . getelementbyid ( "" root "" ); reactdom . render ( < app / > , rootelement ) ; ` ` ` /* ( output of webpage ) */ hello codesandbox start editing to see some magic happen ! <number> * * end of code * * the expected behaviour was that the settimeout function would produce no trace of any text , whilst still working . it is present in react version <number> . <number>",2
facebook/react,"can not use instance values without refs i am experimenting with migrating some of my class components to hooks . my use case is explained in detail [ here ] ( <url> but i can quickly explain the idea . i have a class component ` <mjx> ` which exposes a ` . ready ` promise . since ` <mjx> ` produces a ` <span> ` element , i guess i can use the ` useimperativehandle ` hook to attach ` . ready ` to the ref i use for the ` <span> ` . this is no problem . however , i also have a class component ` <rendergroup> ` which uses ` react . children ` to collect the ` . ready ` promises from all its ` <mjx> ` descendants , and exposes ` promise . all ` of that array of promises as its own ` . ready ` value . since ` <rendergroup> ` does not produce any markup of its own , and you can not place refs on ` < react . fragment > ` , i do not see how to use ` useimperativehandle ` here : there ' s nowhere to attach the ref . here is the relevant code : ` ` ` tsx export class rendergroup extends react . component { private promises : promise <void> []; ready : promise <void> ; componentdidmount ( ) { this . ready = promise . all ( this . promises ) . then ( ( ) => {}); } render ( ) { this . promises = []; return recursivemap ( this . props . children , node => { if ( shouldinspect ( node ) ) { const originalref = node . ref ; return react . cloneelement ( node , { ref : ( ref : mjx ) => { if ( ref ) return ; this . promises . push ( ref . ready ) ; if ( typeof originalref = = = "" function "" ) { originalref ( ref ) ; } else if ( originalref & & typeof originalref = = = "" object "" ) { ( originalref as react . mutablerefobject <mjx> ) . current = ref ; } } }); } return node ; }); } } function shouldinspect ( node : reactnode ) : node is react . reactelement & react . refattributes <mjx> { return react . isvalidelement ( node ) & & typeof node . type = = = "" function "" & & node . type . prototype instanceof mjx ; } export function recursivemap ( children : reactnode , fn : ( child : reactnode ) => reactnode ) { return react . children . map ( children , ( child ) => { if ( ! react . isvalidelement ( child ) ) { return child ; } if ( "" children "" in child . props ) { child = react . cloneelement ( child , { children fn ) }); } return fn ( child ) ; }); } ` ` `",2
facebook/react,"how should we set up apps for hmr now that fast refresh replaces react - hot - loader ? dan abramov mentioned that devtools v4 will be making ` react - hot - loader ` obsolete : <url> > * * me : * * > i have this hook : > ` ` ` require ( "" react - reconciler "" ) ( hostconfig ) . injectintodevtools ( opts ) ; ` ` ` > but hmr has always worked completely without it . is this now a new requirement ? > * * dan : * * > yes , that ' s what the new mechanism uses . the new mechanism does not need "" react - hot - loader "" so by the time you update , you ' d want to remove that package . ( it ' s pretty invasive ) i can not see any mention of hmr in the devtools documentation , however ; now that ` react - hot - loader ` has become obsolete ( and with it , the ` require ( "" react - hot - loader / root "" ) . hot ` method ) , how should we set up apps for hmr in react dom apps * react native apps * react custom renderer apps i ' d be particularly interested in a migration guide specifically for anyone who ' s already set up hmr via ` react - hot - loader ` . also , for hmr , does it matter whether we are using the standalone devtools or the browser - extension devtools ?",2
facebook/react,"hook component can not been clicked in react - dev - tool if you want it works well . # # # issue type bug # # # issue description look at the code blow ( it is very very very simple ) . ` ` ` jsx import react , { usestate } from ' react ' ; export default function democounter ( ) { const [ fnwrapper ] = usestate ( ' fn ' ); const [ count , setcount ] = usestate ( <number> ); fnwrapper . __proto__ . setcount = s => { setcount ( s ) ; } / / assign fnwrapper . __proto__ . setcount to callsetcount const callsetcount = fnwrapper . __proto__ . setcount ; return ( < div style ={{ border : ' 1 px solid blue ' , margin : ' 8 px ' } } > count {/* this does not work if i open react - dev - tool and click the dom node */} < input value ={ count } onchange ={ e => fnwrapper . __proto__ . setcount ( e . currenttarget . value ) } / > {/* this always works not matter i open react - dev - tool and click the dom node or not */} < input value ={ count } onchange ={ e => callsetcount ( e . currenttarget . value ) } / > </div> ); } ` ` ` # # # why callsetcount always works but ` fnwrapper . __proto__ . setcount ` not if and only if after i open the react - dev - tool and click the dom node ~ ~ ~ ~(>_<)~ ~ ~ ~ ， # # # please tell me the truth .",2
facebook/react,"is that possible to get legacy version of react debugger ? < - - note : if the issue is about documentation or the website , please file it at : <url> - - > bug : highlight element is no available in ver <number> + react debugger feature version of react develop is good , bug sometimes i need legacy version of develop tool ( i jest need both of them ) , can you provide both of them ?",2
facebook/react,"infinite lint error of react - hooks / exhaustive - deps first attempt was : ` ` ` javascript const setfield = ( args ) => { const newform = object . assign ( { } , form ) ; for ( let i in args ) { if ( args . hasownproperty ( i ) ) { newform [ i ] = args [ i ] ; } } setform ( newform ) ; } useeffect ( ( ) => { setautocomplete ( address . current , ( args ) => { setfield ( args ) ; }); } , []); ` ` ` i have the error : > react hook useeffect has a missing dependency : ' setfield ' . either include it or remove the dependency array if i follow what the lint says : ` ` ` javascript const setfield = ( args ) => { const newform = object . assign ( { } , form ) ; for ( let i in args ) { if ( args . hasownproperty ( i ) ) { newform [ i ] = args [ i ] ; } } setform ( newform ) ; } useeffect ( ( ) => { setautocomplete ( address . current , ( args ) => { setfield ( args ) ; }); } , [ setfield ] ); ` ` ` i have another error : > line <number> : the ' setfield ' function makes the dependencies of useeffect hook ( at line <number> ) change on every render . to fix this , wrap the ' setfield ' definition into its own usecallback ( ) hook then i follow the advise again : ` ` ` javascript const setfield = ( args ) => { const newform = object . assign ( { } , form ) ; for ( let i in args ) { if ( args . hasownproperty ( i ) ) { newform [ i ] = args [ i ] ; } } setform ( newform ) ; } const mycallback = usecallback ( ( ) => setfield , []); useeffect ( ( ) => { setautocomplete ( address . current , ( args ) => { mycallback ( args ) ; }); } , [ mycallback ] ); ` ` ` then the error is : > line <number> : react hook usecallback has a missing dependency : ' setfield ' . either include it or remove the dependency array and then the code : ` ` ` javascript const setfield = ( args ) => { const newform = object . assign ( { } , form ) ; for ( let i in args ) { if ( args . hasownproperty ( i ) ) { newform [ i ] = args [ i ] ; } } setform ( newform ) ; } const mycallback = usecallback ( ( ) => setfield , [ setfield ] ); useeffect ( ( ) => { setautocomplete ( address . current , ( args ) => { mycallback ( args ) ; }); } , [ mycallback ] ); ` ` ` then the error > line <number> ' setfield ' function makes the dependencies of usecallback hook ( at line <number> ) change on every render . to fix this , wrap the ' setfield ' definition into its own usecallback ( ) hook am i doing something wrong ? thanks",2
facebook/react,"understanding ` act ` behaviour i have been trying to use ` act ` for the first time , and having some issues , and so i am wondering if my expectations are wrong about what it is supposed to do , or if i am "" doing it wrong "" . * * what is the current behavior ? * * the only way i can observe the results of state changes i initiate is by using a timeout . * * paste the link to your jsfiddle or codesandbox example below : * * <url> * * what is the expected behavior ? * * what i expect is that by wrapping a state change or render operation in ` act ` , all of the resulting state changes / side - effects / re - renders will be complete by the time ` act ` returns , so that the operation appears ( or is coerced to be ) synchronous . i created an example ( <url> wherein i render a view via ` unstable_concurrentmode ` . in the view , i create a ` usestate ` hook with a value of ` <number> ` . after the view is rendered , i use that hook ' s setter to change its state to ` <number> ` . below is a log of the [ steps i take ] ( <url> showing three values at each time : ` seenbyrender ` , the last state - value that appeared within the render body ; ` calculated ` , the last value returned from my state - update function ; and ` seenbyeffect ` , the last value observed from a ` useeffect ` i create in the view . ` ` ` <number> . before act / render : seenbyrender : null , calculated : null , seenbyeffect : null <number> . after act / render : seenbyrender : <number> , calculated : null , seenbyeffect : <number> <number> . - - - incrementing with act / setstate - - - <number> . after act / increment : seenbyrender : <number> , calculated : <number> , seenbyeffect : <number> <number> . after timeout : seenbyrender : <number> , calculated : <number> , seenbyeffect ` ` ` what i am wanting / expecting is for step <number> to look like step <number> , ie , i can somehow test the full consequences of my setstate call . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number> . <number> , using unstable_concurrentmode",2
facebook/react,license for source code examples & tutorials on <url> what is the license for the tutorials and examples on <url>,2
facebook/react,"[ eslint - plugin - react - hooks ] : bug react hook "" x <elongated> "" is called in function "" children "" < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * bug <emphasis> * * * what is the current behavior ? * * the hooks created in children function provided in defaultprops populates error ` react - hooks / rules - of - hooks ` . ` ` ` js const app = props => props . children ( props ) ; app . defaultprops = { children : props => { const [ count , setcount ] = usestate ( <number> ); return ( < > count : { count } < button onclick ={() => setcount ( count + <number> ) } > increment </button> < / > ); } , }; ` ` ` ` react hook "" usestate "" is called in function "" children "" which is neither a react function component or a custom react hook function react - hooks / rules - of - hooks ` <url> * * what is the expected behavior ? * * hooks inside children function in defaultprops should not create an error when hook is used . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * same as in the codesandbox . ` ` ` "" dependencies "" : { "" react "" : "" <number> . <number> "" , "" react - dom "" : "" <number> . <number> "" , "" react - scripts "" } , ` ` `",2
facebook/react,"why useffect run return ( ) at frist ` ` ` jsx export const useconfigstatehook = ( ) => { const [ visible , setvisible ] = usestate ( ' hidden ' ) const [ cofigvisible , setcofigvisible ] = usestate ( false ) const [ card , setcard ] = usestate ( < div / > ) useeffect ( ( ) => { eventproxy . on ( ' setconfigbtn ' , ( value ) => { setvisible ( value ) } ) eventproxy . on ( ' setconfigopen ' , ( value ) => { setcofigvisible ( value ? false } ) eventproxy . on ( ' setcard ' , ( card ) => { const { ichart , props } = card if ( ! ichart ) return setcard ( < div / > ) setcard ( < ichart ref ={( e ) => { e & & eventproxy . trigger ( ' chartref ' , e ) e & & settimeout ( ( ) => { eventproxy . trigger ( ' setconfigview ' , e . renderconfig ( ) ) } , <number> ) } } { . <repeated> props } / > ) } ) return ( ) => { eventproxy . off ( ' setcard ' ) eventproxy . off ( ' setconfigbtn ' ) eventproxy . off ( ' setconfigopen ' ) eventproxy . off ( ' setconfigview ' ) } } ) return { visible , cofigvisible , card } } ` ` `",2
facebook/react,"using app shell architecture throws warning : expected server html to contain a matching <div> in <div> . i am currently using workbox along with webpack . the app shell url is / app - shell . i tried following <number> approaches : <number> . in server . js , i created a dedicated route to handle / app - shell url . ` ` ` javascript server . get ( ' / app - shell ' , ( request , response ) => { response . set ( ' content - type ' , ' text / html ' ); response . write ( ` < doctype html > … <body> < div id = "" root "" > </div> < script src = "" js / client . js "" > </script> < script src = "" js / vendor . js "" > </script> <script> if ( ' serviceworker ' in navigator ) { window . addeventlistener ( ' load ' , ( ) => { navigator . serviceworker . register ( ' / service - worker . js ' , { scope : ' / ' } ) . then ( ( registration ) => { console . log ( ' serviceworker registration successful with scope : ' , registration . scope ) ; } ) . catch ( ( registrationerror ) => { console . log ( ' sw registration failed : ' , registrationerror ) ; }); }); } </script> </body> ` ); }); ` ` ` <number> . second approach , i created a route / app - shell which corresponds to an element with content “ loading … ” . ` ` ` javascript const appshellcomponent : react . fc < { } > = ( ) => ( <main> loading . <repeated> </main> ); ` ` ` in both cases , i get the above mismatch warning . if i make appshellcomponent exactly same as homecomponent i . e . path / , then the error goes away if the app is invoked from the home page path i . e . / . however , if any other route is invoked , the warning comes back again . please suggest a better approach . thanks .",2
facebook/react,"testutils . renderintodocument returns ` null ` when valid functional component passed . * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i want to report a bug . * * what is the current behavior ? * * currently when valid functional component is passed to * * testutils . renderintodocument * * it returns a * null <emphasis> * and raise no error . * demo <emphasis> * this behavior was reproduced in a sandbox : <url> check the console , to see * * testutils . renderintodocument * * output of prepared sample components . * workarounds <emphasis> * workaround that satisfies both sfc and fc is wrapping component into container : ` ` ` const fccounter = ( ) => { const [ count , setcount ] = usestate ( <number> ); return ( <div> <div> { count } </div> < button onclick ={() => setcount ( count + <number> ) } > + <number> </button> </div> ); }; testutils . renderintodocument ( <div> < fccounter / > </div> ); ` ` ` * * what is the expected behavior ? * * - to render a functional component . - in worst case - providing an error . * * which versions of react are affected by this issue ? * * react version",2
facebook/react,"react hooks : a few inconveniences <number> ) when using useeffect , can not get latest state . for example , i add a event listener in componentdidmount . ` ` ` const app = ( ) => { const [ state1 , setstate1 ] = usestate ( ' state1 ' ); const [ state2 , setstate2 ] = usestate ( ' state2 ' ); useeffect ( ( ) => { function handler ( ) { / / can not get the latest state1 and state2 because of the scope . } document . addeventlistener ( ' click ' , handler ) ; return ( ) => document . removeeventlistener ( ' click ' , handler ) ; } , [ ] ) } ` ` ` i have to change code into this const app = ( ) => { const [ state1 , setstate1 ] = usestate ( ' state1 ' ); const [ state2 , setstate2 ] = usestate ( ' state2 ' ); useeffect ( ( ) => { function handler ( ) { / / for the reason of scope , can not get the latest state1 and state2 . } document . addeventlistener ( ' click ' , handler ) ; return ( ) => document . removeeventlistener ( ' click ' , handler ) ; } , [ state1 , state2 ] ) . <repeated> } ` ` ` problem solved , but the effect executes again . ( wasteful ? <repeated> ) <number> ) functional props cause updating subcomponent every time . ` ` ` const app = ( ) => { const [ state , usestate ] = usestate ( <number> ) function handlechange ( ) { / / do something } return ( < subcomponent onchange ={ handlechange } / > ); } ` ` ` in this case , subcomponent will update every time app rerender , because the onchange prop is changed . if we need to use state or props in handlechange , we have nothing to do with it . ( if we usecallback , see no . <number> , the lastest state issue ) .",2
facebook/react,"hook for forwardref * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * today we use forwardref as a hoc around functional component , like this : ` ` ` js const mycomponent = react . forwardref ( ( props , ref ) => { return ( < div { . <repeated> props } ref ={ ref } > some text </div> ); }); mycomponent . displayname = ' mycomponent ' ; ` ` ` * * what is the expected behavior ? * * is it possible to use hooks to forward ref ? for example , something like this const mycomponent = ( props ) => { / / will return ref that was passed from parent component const forwardedref = useforwardredref ( ); return ( < div { . <repeated> props } ref ={ forwardedref } > some text </div> ); } ` ` ` with this approach we do not need to manually set displayname all the time , also this would be great for libraries , as you still export same component , not a forwardref hoc . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number> and upper",2
facebook/react,"useeffect firing in children before parent < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature ( i believe ) * * what is the current behavior ? * * right now , the effects in useeffect fire children - first . i know this makes sense , since the behaviour of the first render has a close correlation to cdm . however , i cannot seem to find a way to fire events parent - first . before , i could do it with cwm , and after that was deprecated , in the constructor . how can i accomplish that with hooks ? * * codesandbox example : * * <url> * * what is the use case ? * * imagine i want to post to an external server when two components were first rendered , to measure a sort of meaningful paint . ` ` ` - component a - > post ( "" first render "" "" , component : a ) - - - - - - - - - - - - - - - - - - - - - - - - component b - > post ( "" first render "" , component ` ` ` how could i accomplish this with hooks ?",2
facebook/react,"is passing a ref to usememo considered cheating ? i have an object which is created via usememo i do not want this object to be recreated every time a certain dependency changes , and yet i want it to always see the latest version of that dependency ( not just what it was upon initial creation ) currently , i am doing something like this : ` ` ` / / bar changes between renders const latestfoo = useref ( bar ) ; / / obj will only be created once , yet it sees the updated latestfoo const obj = usememo ( ( ) => ( { dosomething : ( ) => { / / use and / or set latestfoo . current } } ) , [ latestfoo ] ); ` ` ` this feels like a little bit of a lie . <repeated> because it kindof depends on an updated ` latestfoo . current ` . <repeated> not really ` latestfoo ` the ref , if that makes sense . yet it works fine as far as i can see . <repeated> not sure if i should feel bad about lying to ` usememo ` about its deps , or if it ' s not really a lie at all and this is actually a totally expected use case of ` useref ` any tips are appreciated . p . s . this was prompted by refactoring my code after reading this page , which was an _enourmous_ help in understanding hooks and writing code that uses them more consciously <user> would you rather me post questions like this somewhere else ? did not see a comment section on the site and i do not use twitter . <repeated>",2
facebook/react,"useref only updates with a usestate together < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * probably a bug * * what is the current behavior ? * * i am creating a component swapper triggeredd by a interval . i had to use the useref hook to keep the index state between renders , but it only gets updated when i keep a usestate ( the setcurrentindex ) is with it . when the setcurrentindex at line <number> is removed , the swapper does not works . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * please check it out <url> * * what is the expected behavior ? * * i tought that the indexref would not depend on the state hook to be updated . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number> . <number> , chrome <number> , os ubuntu <number> .",2
facebook/react,"react hooks usestate updating an array < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * hooks clarification * * what is the current behavior ? * * i am trying to understand the lifecycle of ` usestate ` . i have a mock application using a mock websocket . every second , it sends a new message from the backend . the new message is meant to be appended to an array using ` usestate ` . here are a few different examples that highlight my confusion <number> * * [ in this example ] ( <url> if i set the websocket ' s ` onmessage ` function once in ` useeffect ` , then whenever i call ` setmessages ` to update the ` messages ` array , the ` messages ` array i receive as an input is empty . ` ` ` js const [ messages , setmessages ] = usestate ( []); function receivemsg ( msg ) { setmessages ( messages . concat ( json . parse ( msg . data ) )); } useeffect ( function ( ) { if ( _ . isundefined ( socket ) ) { let ws = new mockwebsocket ( "" ws :// <number> . <number> : <number> / "" ); ws . onmessage = receivemsg ; } }); ` ` ` the effect of this is that i only ever get the latest message in my array . * * example <number> * * if , however , i set the ` onmessage ` function on every render [ as in this example ] ( <url> then i get my full array with data appended as i would expect . ` ` ` js const [ messages , setmessages ] = usestate ( []); function receivemsg ( msg ) { setmessages ( messages . concat ( json . parse ( msg . data ) )); } if ( ! _ . isundefined ( socket ) ) { socket . onmessage = receivemsg ; } useeffect ( function ( ) { if ( _ . isundefined ( socket ) ) { let ws = new mockwebsocket ( "" ws :// <number> . <number> : <number> / "" ); ws . onmessage = receivemsg ; } }); ` ` ` in the ` receivemessage ` function , my ` messages ` array is the whole array instead of an empty one in this example . * * example <number> * * but , if i assign a new reference to ` messages ` , [ as in this example ] ( <url> and re - assign the value inside ` receivemsg ` , then i do not have to re - assign the ` onmessage ` function over and over . ` ` ` js const [ messages , setmessages ] = usestate ( []); let msgref = messages ; function receivemsg ( msg ) { msgref = msgref . concat ( json . parse ( msg . data ) ); setmessages ( msgref ) ; } useeffect ( function ( ) { if ( _ . isundefined ( socket ) ) { let ws = new mockwebsocket ( "" ws :// <number> . <number> : <number> / "" ); ws . onmessage = receivemsg ; } }); ` ` ` * * example <number> * * but , if i assign a new reference and do not re - assign to it , [ as in this example ] ( <url> i continue ending up with an empty array . this suggests it ' s the assignment back to ` msgref ` that is keeping the entire array within the closure . ` ` ` js const [ messages , setmessages ] = usestate ( []); let msgref = messages ; function receivemsg ( msg ) { setmessages ( msgref . concat ( json . parse ( msg . data ) )); } ` ` ` * * what is the expected behavior ? * * my original expectation was that example # <number> would work . i can tell there ' s something i am not totally understanding about the way the assignment of variables to closure works with this hook , but i am struggling to define what exactly ' s going on . can someone shed some light on why this works this way ? * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number>",2
facebook/react,"exhaustive - deps support for dynamic array maybe it ' s antipattern and maybe it is not . note how i leverage deps for createdat subselect . ` ` ` ts const tasklists = ( ) => { const tasklists = useappstate ( state => state . tasklists ) ; const sortedtasklists = usememo ( ( ) => { return object . values ( tasklists ) . sort ( ( a , b ) => a . createdat - b . createdat ) ; / / eslint - disable - next - line react - hooks / exhaustive - deps } , object . values ( tasklists ) . map ( item => item . createdat ) ); const children = usememo ( ( ) => { return ( < > { sortedtasklists . map ( tasklist => ( < tasklistlink id ={ tasklist . id } key ={ tasklist . id } / > ) ) } < / > ); } , [ sortedtasklists ] ); return children ; }; ` ` `",2
facebook/react,"why moving item to another array fire re - rendering for itself ( the item ) ? hello , i have the following problem : — when i drag / drop item to an another ` array ( ) ` > it re - renders the item i moved — ( why ? ) — when i drag / drop in the * same <emphasis> * ` array ( ) ` > it ' s not renders . so it ' s good the problem is my deepest child , i have a little ` fetch ( ) ` to retrieve some additional data . these data are already fetched . so when i drag / drop * * i do not want * * another fetch . event ` react . memo ( ) ` solve the problem . you can check the console of codesandbox to see the problem : # # # [ <url> * * what is the expected behavior ? * * no re - render of the item , since react already displays it , i just moved to another array . it ' s still the same item . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * ` ` ` react <number> . <number> macos <number> . <number> ` ` ` react beautiful dnd",2
facebook/react,"` react - dom / server . renderstaticmarkup ( ) ` returns empty string server - side * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * * bug <emphasis> * * * what is the current behavior ? * * i am trying to extract the initial html from react code on the server side . to do this , i am using the official react - dom / server library function ` rendertostaticmarkup ( ) ` referenced here : <url> i am reading a react source file , transpiling the jsx and es6 syntax to commonjs using babel and then parsing the evaluated commonjs to ` rendertostaticmarkup ( ) ` . # # react code : ` ` ` jsx import react from ' react ' ; class test extends react . component { render ( ) { return <p> hello world </p> ; } } export default test ; ` ` ` # # server - side code : ` ` ` javascript const { rendertostaticmarkup } = require ( ' react - dom / server ' ); const babel = require ( ' <user> / core ' ); const fsp = require ( ' fs ' ) . promises ; ( async ( ) => { let filecontent = await fsp . readfile ( ' test . js ' , ' utf - <number> ' ); let code = babel . transform ( filecontent , { presets : [ ' <user> / preset - env ' , ' <user> / preset - react ' ] , comments : false , minified : true } ) . code ; let result = rendertostaticmarkup ( code ); console . log ( result ); })(); ` ` ` # # package . json : ` ` ` json { "" dependencies "" : { "" <user> / core "" : "" ^ <number> . <number> "" , "" <user> / preset - env "" : "" ^ <number> . <number> "" , "" <user> / preset - react "" : "" ^ <number> . <number> "" , "" react "" : "" ^ <number> . <number> "" , "" react - dom "" : "" ^ <number> . <number> "" } } ` ` ` * * what is the output ? * * ` "" use strict "" ; object . defineproperty ( exports , "" __esmodule "" , { value : true } ) ; exports . default = void <number> ; var _re act = _interoprequiredefault ( require ( "" react "" ) ) ; function . <repeated> ` * * what is the expected output ? * * ` <p> hello world ! </p> ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * ` ` ` json "" react "" : "" ^ <number> . <number> "" , "" react - dom "" ` ` `",2
facebook/react,"module mock yields unexpected act ( ) error < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * i am trying to figure out where is the best place to put a module mock according to the new react version <number> . <number> . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * ` ` ` javascript import react from ' react ' ; import { act } from ' react - dom / test - utils ' ; import { mount } from ' enzyme ' ; import { getpointsfromgroupid } from ' . / utils / getpointsfromgroupid ' ; import { tdashbody } from ' . ' ; jest . mock ( ' . / utils / getpointsfromgroupid ' , ( ) => ( { getpointsfromgroupid : jest . fn ( ( ) => promise . resolve ( { } ) ) , })); const getdefaultprops = ( ) => ( { currentgroup : <number> , }); describe ( ' dashbody ' , ( ) => { let component ; beforeeach ( ( ) => { act ( ( ) => { const props = getdefaultprops ( ); component = mount ( < tdashbody { . <repeated> props } />); }); }); describe ( ' rendering ' , ( ) => { it ( ' should render without exploding ' , ( ) => { expect ( component ) . tobedefined ( ); }); }); }); ` ` ` * * what is the expected behavior ? * * this test passes , but the placement of the mock module call gives me the act ( ) error ` ` ` warning : an update to tdashbody inside a test was not wrapped in act ( . <repeated> ) . when testing , code that causes react state updates should be wrapped into act ( . <repeated> ) => { /* fire events that update state */ }); /* assert on the output */ this ensures that you are testing the behavior the user would see in the browser . learn more at https :// fb . me / react - wrap - tests - with - act ` ` ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * v16 . <number> running chrome on windows <number>",2
facebook/react,react - cache alphas do not work with <number> + > ` react - cache ` was not published with <number> . <number> like the rest of the react packages . this means that the platform ' s suspense stuff will not work . _originally posted by <user> in <url>,2
facebook/react,"warning for ` act ` even when code is wrapped inside it * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * report a bug * * what is the current behavior ? * * ` react - test - renderer ` emits a warning to wrap code inside ` act ` even though it is . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * here is a [ codesandbox ] ( <url> with a component using ` usestate ` that toggles a div on / off on a button click . the test finds the button , calls the ` onclick ` on the props . this would be followed by a snapshot test . however , no matter how i try and wrap the code in ` act ` , the warning persists . make sure to open the tests tab on the right , and to expand the console at the bottom * * what is the expected behavior ? * * there should be no warning . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <user> . <number> react - dom <user> . <number> react - test - renderer <user> . <number> jest <user> . <number> this worked fine with react * <user> . <number> - alpha . <number> , snapshot and all .",2
facebook/react,"hooks : usecontext with usestate not updating < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * seems it ' s a * bug <emphasis> * . 😕 * * what is the current behavior ? * * nested context provider and ` usecontext ` hooks seems to be conflicting , updates get discarded . * * what is the expected behavior ? * * when connecting to a context , it should update whenever it ' s ` value ` changes . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * - * react <emphasis> * : ` <number> . <number> - alpha . <number> ` ( also reproduced on ` <number> . <number> - alpha . <number> ` ) - * browser <emphasis> * : ` chrome <number> ` - * os <emphasis> * : macos sierra - - - # # # more details while working on a cleanup of a localstorage "" connection "" , i tried to mix <number> articles ( [ ` [ <number> ] ` ] ( <url> & [ ` [ <number> ] ` ] ( <url> from the official react documentation , i have implemented it with hooks , but the value seems not to be passing through . i have put up a streamlined demo on [ codesandbox ` [ <number> ] ` ] ( <url> the actual implementation is only a couple of lines more ( parsing it from and stringifying it to json ) . workarounds that i found : - if i create a new function on each render around the ` setvalue ` function , it actually works . - but this goes against the advice on [ ` [ <number> ] ` ] ( <url> about avoiding creating new values . - migrate it to a class and use ` componentdidupdate ` instead of ` useeffect ` . - i am actually using this right now , as it works . including saving a reference to the function in the state . - - - is there anything that should not work on the code below ? the effect gets triggered with the changes , but the value does not get updated on the components that consume via hook . see repro code [ ` [ <number> ] ` ] ( <url> ` ` ` javascript const createlocalstorage = key => { const initialvalue = localstorage . getitem ( key ) const valuecontext = createcontext ( initialvalue ) const settercontext = createcontext ( ( ) => { } ) const usestorage = ( ) => [ valuecontext , settercontext ] . map ( usecontext ) const provider = ( { children } ) => { const [ value , setvalue ] = usestate ( initialvalue ) useeffect ( ( ) => { console . log ( ' effect ' , value ) localstorage . setitem ( key , value ) } , [ value ] , ) return ( < valuecontext . provider value ={ value } > < settercontext . provider value ={ setvalue } > { children } < / settercontext . provider > < / valuecontext . provider > ) } return [ provider , usestorage ] } ` ` ` ` [ <number> ] ` : <url> ` [ <number> ] ` : <url> ` [ <number> ] ` - - - ! [ hlcecpq ] ( <url>",2
facebook/react,"componentdidmount inside a class causing a memory leak hi , i have a very weird memory leak that seems to be related to componentdidmount declaration . memory is not freed after unmounting component . # # # used code version : react <number> mode : developper or production ( same behaviour ) here is the code i use to hide or display a list of items ` ` ` class item extends react . component { componentdidmount ( ) { } render ( ) { return <div> test item </div> ; } } class items extends react . component { constructor ( props ) { super ( props ) ; this . state = {}; } renderlist ( ) { let items = []; for ( var i = <number> ; i < <number> ; i + + ) { items . push ( < item key ={ i } />); }; return items ; } ondisplay = ()=> { this . setstate ( { display : true } ); } onhide = ()=> { this . setstate ( { display : false } ); } render ( ) { return <div> < div key = "" display "" onclick ={ this . ondisplay } > display </div> < div key = "" hide "" onclick ={ this . onhide } > hide </div> { this . state . display ? this . renderlist ( ) </div> } } reactdom . render ( < items / > , document . getelementbyid ( "" app "" )); ` ` ` # # # steps to reproduce case <number> use google chrome and display the performance monitor to study js heap size and dom nodes . <number> ) click on display => the list of <number> items is displayed <number> ) click on "" hide "" => the list is unmounted when you look at performance monitor , you can see that around <number> nodes are still in memory ( and js heap is higher than before mounting components as well ) . if you redo <number> ) and <number> ) multiple times , you will see nodes going to <number> then going back to <number> , . <repeated> etc . thus , memory is freed after the first unmount operation , but the first one is not . the weird thing is that if you do <number> ) , <number> ) , <number> ) , <number> ) , then it is freed . case <number> use the same code but remove the "" componentdidmount "" function in the class . do <number> ) and <number> ) , then after few secondes memory is freed automatically ( nodes and js heap ) => expected behaviour # # # behaviour expected i was expected that the memory would be freed after unmounting a component , like in the 2 nd case . that ' s a real issue when you mount . unmount big list multiple times , then js heap is going very high .",2
facebook/react,"what ’ s the difference between fiber reconciler sync mode and the old react <number> stack reconciler ? why does performance boosts so much ? since performance of react <number> boosts so much and thanks to those aweosome talks on youtube explained fiber so detailed , i hardly figured out even the latest version of react <number> is still in sync mode , no features like time slicing are turned on by default . then i wondered why the perfmance is pretty good compared with react <number> even though ? trying to get some info on google , but it seems like no one really looked into this question . even react <number> is shipped with this “ fake ” fiber mode for such a long time , it is not well documented or explained on the official website . can someone give me some ideas about this please ?",2
facebook/react,"warn : it looks like index is reassigning its own ` this . props ` while rendering , this is not supported and can lead to confusing bugs . when i try to update react from <number> . <number> to <number> . <number> ， what ' s wrong with this ?",2
facebook/react,"q : when should you not use react memo ? i have been playing around with react <number> . <number> recently and i love the idea of react memo , but i have been unable to find anything regarding scenarios best suited to implement it . the react docs ( <url> do not seem to suggest any implications from just throwing it on all of your functional components . because it does a shallow comparison to figure out if it needs to re - render , * * is there ever going to be a situation that negatively impacts performance * * ? and second question long as everything remains pure , is there ever a situation to not wrap a functional component with react memo ? thank you .",2
facebook/react,"请问不做任何处理 ， react可以兼容到ie多少 < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * * * what is the current behavior ? * * * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * * * what is the expected behavior ? * * * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * *",2
facebook/react,"setstateaction returned from usestate hook dose not accept a second callback argument < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * question * * what is the current behavior ? * * the setstateaction returned from usestate hook dose not accept a second callback argument . it cannot works like class componet ' s ' setstate ' method , which receives a callback param , and can perform the callback after this setstate action updates ; * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * <url> * * what is the expected behavior ? * * hopes the setstateaction function can receive a second callback argument , and can used like ' setstate ' method callback . i have read the official note / / this technically does accept a second argument , but it ' s already under a deprecation warning > / / and it ' s not even released so probably better to not define it . if instead it ' s working as intended , how can i perform special action after this setstateaction called ? * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number> . <number> - alpha . <number>",2
facebook/react,"limitations of react . createcontext * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * the current behavior requires end users to use ` createcontext ` in the module scope . to my understanding , it ' s not currently possible to use a default value derived from the state of a component ( a stateful provider in my case ) . this [ stackoverflow post ] ( <url> hits the issue right on imo . i feel like this is the classic use case for replacing redux , and it does not work out of the box with static types . i think it ' s quite telling that ` react - redux ` is doing something similar [ here ] ( <url> in their pr to move to react <number> context . i would expect the default value to be ` this . state ` of the provider component instead of ` null ` . my knowledge of react internals is naive , but i did not see anyone else bringing up this issue . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * * * what is the desired behavior ? * * maybe a jsx api for context creation ? i imagine it ' s not quite that simple . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number> +",2
facebook/react,"[ feature request ] add dom to life cycle hooks . currently , it ' s not very straight forward to get your hands on a components full dom - in particular if it returns multiple elements . in that case ` reactdom . finddomnode ` just will not work . so you are left with refs , but you will never get the whole dom * at once * - instead you get one element at a time . you can of course do something along the lines of this : ` ` ` js class citylist extends component { render ( ) { this . childelements = []; let store = this . childelements . push . bind ( this . childelements ) ; return this . props . cities . map ( p => < li class = "" city "" ref ={ store } > . <repeated> </li> ); } componentdidmount ( ) { / / access this . childelements here } } ` ` ` but that feels a bit awkward . hence my question is : how about adding the dom nodes rendered for a given component at the end of the argument list of the relevant life cycle events ? if i am not mistaken , those would be ` componentdidmount ` , ` getsnapshotbeforeupdate ` , ` componentdidupdate ` and ` componentwillunmount ` ( as well as perhaps <emphasis> ` shouldcomponentupdate ` although i am not sure why that would be a good time to access the dom ) . i have not dug too deep into react ' s internals , but my naive guess would be that this information should be available when those life cycle hooks are being called . on a more "" philosophical "" note seems to me that storing references to the dom in the component just is not all that clean . in event handlers , you can use the event to reach into the dom and it seems to me that life cycle hooks are practically destined to allow the same . thanks for your consideration <happy>",2
facebook/react,"why we need both isbatchingupdates and isunbatchingupdates ? < - - note : if the issue is about documentation or the website , please file it at - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * question . * * what is the current behavior ? * * imo , from the naming , ` isbatchingupdates ` should always equals ` ! isunbatchingupdates ` , i wonder why we need both of them . in [ 8 1 2 2 4 b ] ( <url> we add the ` isunbatchingupdates ` variable , the comment says it ' s just "" for the weird case where the initial mount is synchronous "" ( and add [ a test ] ( <url> for it ) . but in a [ follow up pr ] ( <url> we just delete the comment but do not remove the ` isunbatchingupdates ` . i do not know why we remove the comment , seems the weird case which the before comment said does not be solved in this pr . * * what is the expected behavior ? * * i try to remove ` isunbatchingupdates ` and use ` ! isunbatchingupdates ` instead just like before we did . but encounter many tests fails ( i thought just few tests would fails before try ) . so , could you give some clarifications about this ? do we still need this now ? thanks ! * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * master branch",2
facebook/react,"consider keeping legacy context api for non - state usages < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature request / question according to react docs , there are <number> ways to avoid passing props through many levels : <number> . ( new ) context api <number> . composition ( inversion of control ) when using the new context api , a consumer component must know , and explicitly import , a context . this raises a quite big disadvantage comparing to the legacy context api : such component can not be reusable with different contexts ( unless making a prop only version of this component , and wrapping it with another one that uses the context directly ) . in fact , it means that a component can not be "" contextual "" and reusable ( by different contexts ) at the same time . using composition in many cases feels wrong for solving this , quoting the docs : _however , this isn ’ t the right choice in every case : moving more complexity higher in the tree makes those higher - level components more complicated and forces the lower - level components to be more flexible than you may want . _ example of a component i struggle to understand why it should now import a context : ` ` ` javascript import * as react from "" react "" import * as propstypes from "" prop - types "" export class link extends react . purecomponent { static contexttypes = { navto } handleclick = ( e ) => { e . preventdefault ( ) const { path } = this . props this . context . navto ( path ) } render ( ) { const { path , . <repeated> props } = this . props return < a href ={ path } onclick ={ this . handleclick } { . <repeated> props } / > } } ` ` ` if it was already discussed or answered , i apologize , could not find any related issues .",2
facebook/react,"react - test - renderer : is possible to test lifecycle functions ? * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * question * * what is the current behavior ? * * i am trying to use ` react - test - renderer ` and i notice that the lifecycles methods ( ex : ` componentdidmount ` ) need to be fired manually - ` rendered . getinstance ( ) . componentdidmount ( ) ` , what solves my problem but reveals an other want to use shallow render , to test only the component under test , but then ` react - test - renderer / shallow ` api is minimal for rendering . * * what is the expected behavior ? * * i was expecting that ` react - test - renderer ` would support testing my component reaction to the different lifecycles and be capable to use ` shallow ` rendering . is there some way to use ` react - test - renderer ` in this scenario ? or is better i move to another library like ` enzyme ` ?",2
facebook/react,"component . prototype . setstate ( ) callback is not receiving any arguments * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * ` ` ` component . prototype . setstate ( ) ` ` ` ' s callback is not receiving any parameters , though line <number> in ` / packages / react / src / reactbaseclasses . js ` states , that will be called with the up to date component arguments ( state , props , context ) . ` <url> * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * <url> please check the console after clicking the button , as it will display an empty array , indicating that it does not get called with any parameters . * * what is the expected behavior ? * * as the comment mentions , we should get the updated state and props and context as arguments . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * i am checking this behaviour in react v16 . <number> using chrome <number> , mac os high sierra <number> . <number> and it also did not seem to work in previous versions , though i did not go back in the version history .",2
facebook/react,"tools for end - to - end testing this may be a question moreso than a feature request , but i can not seem to find the answer around the web . it seems most people are working on small apps or just ignoring this as an issue . i am working on a large react application , and seeing some issues with end - to - end testing . we have a webdriverio / selenium setup which seems to be rather common from what i understand . we use these tools to click some buttons , type some text , etc . , and then find the affected dom elements and do some assertions . however , and here is where the problem is , react does not synchronously perform all operations on the read dom . it will use various methods to schedule work , which will be done asynchronously at some later time . i have found that in our tests , a few assertions at random will see that the real dom is still in the previous state ( rather than the new state that results from having clicked the button and whatnot ) in every large test run . i have not seen many posts on the internet even acknowledge this as an issue . the one that i found that does only suggests adding timeouts throughout the tests . however , for obvious reasons , this is slow and non - deterministic . is there a suggested way to know that a react application has finished performing all scheduled work ? and if not , is there a discussion about this happening somewhere ?",2
facebook/react,"what is meant within the readme of ` create - subscription ` by async limitations ? can it be clarified ? what is meant within the [ ` readme . md ` of ` create - subscription ` ] ( <url> by async limitations ? > for full compatibility with asynchronous rendering , including both time - slicing and react suspense , the suggested longer term solution is to move to one of the patterns described in the previous section . the patterns described above are : > * redux / flux stores should use the context api instead . > * i / o subscriptions ( e . g . notifications ) that update infrequently should use simple - cache - provider instead . > * complex libraries like relay / apollo should manage subscriptions manually with the same techniques which this library uses under the hood ( as referenced here ) in a way that is most optimized for their library usage . i do not think any of these suit our use case : a high performance websocket stream that produces price quotes which are rendered directly into components . the application domain is a realtime trading application for an investment bank i am consulting for . ideally , we want the price quotes to be passed straight into the component with as little ceremony as possible . this state will be transient , so i do not see why i need to use some kind of state management solution to store it somewhere . * i do not think i should need to use ` react <hashtag> context </hashtag> ` and to then pass the data down the tree , since i can just import the service wherever i want in my code and pass callbacks into this to begin receiving data . the latter seems simpler , with less ceremony and will make it easier to differentiate between different streams of price updates . it seems to me that ` create - subscription ` is exactly what i need , however the comment about async limitations worries me . is there something i am missing ? could this be clarified in the readme ? is it because of priority ? i think ideally we wish the price updates to be treated as if they are high priority , because we would prefer to decrease the likelihood of clients interacting with stale data .",2
facebook/react,"keep using legacy context api - or how to achieve this with new api * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * more like a feature . * * what is the current behavior ? * * so i am currently using the legacy context api very heavily . a typical "" component tree "" in my app might look a bit like this : ` ` ` js <app> <component1> / / provides <number> objects via context all children might need at some point <component2> / / might need one of the <number> objects passed via context <foo> / / additionally provides <number> functions via context <somelist> / / needs some objects from <component1> <listitem> <somechild> / / needs both functions from <foo> and maybe some objects from <component1> / / . <repeated> and so on and so forth - you get the idea </somechild> </listitem> </somelist> </foo> </component2> </component1> </app> ` ` ` so i have a heavily nested component tree , where i use context all the time to pass functions , booleans , objects or whatever without having to use props all the time - i am trying to avoid "" prop drilling "" as much as possible . additionally , some of these context vars might be set in lifecycle methods after a first render or maybe after some hoc provided some data . it is basically all over the place . * * what is the expected behavior ? * * my question now is can not see any * proper <emphasis> * solution to achieve all this with the next context api . it will be a huge pain in the a * * to achieve it and make some of my code completely unreadable . is there any way to keep using the legacy context api ? maybe the react team could provide a extra package for that ? or maybe someone has a better idea on how to achieve this without having pretty bad prop drilling all over the place . looking forward to your answers best , patrick",2
facebook/react,"questions regarding "" props . children "" * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * just questions # # # some questions regarding props . children in the official react documentation of [ react . children ] ( <url> you can read that ` ` ` this . props . children ` ` ` is an "" opaque data structure "" . what does that mean exactly ? i think there are in general three possibilities for the transparency of the data structure of ` ` ` props . children ` ` ` : # # # # case <number> : every aspect of the ` ` ` props . children ` ` ` data structure is open and well defined . if this was right then the term "" opaque data structure "" would be completely wrong . therefore "" case <number> "" obviously is not the case . # # # # case <number> : no aspect of the ` ` ` props . children ` ` ` data structure is open or clear . that would mean that whenever you use ` ` ` props . children ` ` ` you always have to use it in combination with ` ` ` react . children ` ` ` as ` ` ` react . children ` ` ` is the only one ( mh <elongated> , is it really the only one ? ) who knows about the actual data structure of ` ` ` props . children ` ` ` . but that would imply that it should neither be allowed to use ` ` ` javascript / / this is used almost everywhere ( even in the official react documentation ) <div> { this . props . children } </div> ` ` ` nor ` ` ` javascript / / this is often seen with the "" function as child "" pattern mycomponent . proptypes = { children : proptypes . func . isrequired , }; ` ` ` as both examples are very common , it seems that "" case <number> "" is obviously also not the case . # # # # case <number> : some aspects of the ` ` ` props . children ` ` ` data structure are open and well defined . that would open the possibility that one or even both of the examples in "" case <number> "" are valid . but then it would mean that there should be an exact specification what aspects of ` ` ` props . children ` ` ` is well and openly defined and which aspects are really opaque . maybe i have missed something in the react documentation , but i think it ' s not really exactly specified there , is it ? # # # # and last but not least a further question exactly is not ` ` ` props . children ` ` ` in case there are some children ( one ore more ) just always an array ( as it is done in "" preact "" for example ) ? that would make things so much easier , would not it ? many thanks in advance for the clarifications .",2
facebook/react,"why are the consumer and provider properties of consumer ? is there a higher meaning for <number> ) ` consumer ` and ` provider ` both being properties of ` consumer ` ? <number> ) and ` consumer ` being of type ` symbol ( react . context ) ` _ ( and not react . consumer ) _ while ` provider ` is of type ` symbol ( react . provider ) ` ? ` ` ` jsx const mycontext = react . createcontext ( ' value ' ) mycontext = = = mycontext . consumer = = = mycontext . consumer . consumer ` ` ` while this _ * is <emphasis> * _ * convenient <emphasis> * , because i usually only use provider once as ` ` ` jsx import mycontext from ' . / mycontext ' < mycontext . provider > . <repeated> < / mycontext . provider > ` ` ` . <repeated> and then i can do less typing by simply using , ` ` ` jsx import mycontext from ' . / mycontext ' <mycontext> . <repeated> </mycontext> ` ` ` i would be interested in knowing where _ ( if ) _ this is documented and what is the preferred way ? whether to use the full ` < mycontext . consumer > ` or if it is legit to just simplify to ` <mycontext> ` .",2
facebook/react,"cloning the child of a context consumer produces confusing warning and error < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * this is a bug , or at least a request for more precise warnings and error messages . * * what is the current behavior ? * * i was cloning children to add some properties and i overlooked that the context consumer subtree should not be cloned . <repeated> ` ` ` import react from ' react ' ; import { render } from ' react - dom ' ; const { provider , consumer } = react . createcontext ( ); const comp = ( { children } )=> <provider> { clonekids ( children ) } </provider> ; const clonekids =( children ) => react . children . map ( children , child => react . cloneelement ( child , child . props , child . props . children & & clonekids ( child . props . children ) )); render ( <comp> <consumer> { console . log } </consumer> </comp> , document . getelementbyid ( ' root ' ) ); ` ` ` the code produces the warning and error introduced with # <number> > warning : a context consumer was rendered with multiple children , or a child that is not a function . a context consumer expects a single child that is a function . if you did pass a function , make sure there is no trailing or leading whitespace around it . and ( even more confusing ) > typeerror is not a function * * what is the expected behavior ? * * maybe react . cloneelement should not attempt to clone functions ? whatever it does , the result is not a function . the warning part "" a child that is not a function "" should be separated from the other warnings . there can not be multiple children and one child that is not a function at the same time , so a more precise warning can be issued . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * tested with react <number> . <number> in stackblitz / chrome <number> and react <number> . <number> in chrome <number> and firefox <number>",2
facebook/react,reactjs logo license i have been unable to find out what the license for the react logo is . does anyone know under which license it is ?,2
facebook/react,"keep the children mounted but replace the parent hi , i am trying to do something like this : ` ` ` const container = ( props ) => props . somecondition ? ( <containertype1> { props . children } </containertype1> ) <containertype2> { props . children } </containertype2> ); const app = ( props ) => ( < container somecondition ={ props . somecondition } > < componentthatdoesasyncfetches1 / > < componentthatdoesasyncfetches2 / > < componentthatdoesasyncfetches3 / > </container> ); ` ` ` basically what i want is a situation where app is rerendering on a changing boolean prop ( imagine somecondition has an actual changing value ) , and a different container will render depending on its value , while maintaining the same children inside . problem is , that those children are doing async fetches ( on didmount ) , but they re - mount and lose their state while the containers change . any idea how can i achieve this with the children still mounted even if their parent changed ? thanks in advance",2
facebook/react,"capturing events trigger after vanilla bubbling events * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * bug * * what is the current behavior ? * * when subscribing to dom events it ' s possible to use capturing . however it seems that capturing takes place after the vanilla javascript bubbling phase . this results in an incorrect order of events unless all events are subscribed to via react which is not always possible . here ' s an example that mimicks one of our use cases * * what is the expected behavior ? * * a capturing event subscribed to within react , should take place before bubbling events subscribed to via vanilla javascript . * * which versions of react , and which browser / os are affected by this issue ? * * development edition , chrome v64 x64",2
facebook/react,why can not we use both prevstate ( function ) + callback as parameters in setstate ( ) ? nan,2
facebook/react,"react - test - renderer : asynchronous rendering guarantees ? < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * i think this is just a question . as i understand it , react ' s newer fiber <emphasis> architecture introduces an asynchronous rendering pipeline , which allows for better prioritisation of work . i am also aware that in version <number> , react is still expected to render synchronously . looking forward though , when using ` react - test - renderer ` ( especially the [ reacttestinstance ] ( <url> helper apis ) , what guarantees are safe for a developer to lean on ? after creating a test - renderer instance , is it safe to immediately introspect the instance to look for a child node with a given type ? does this differ from components with user - space asynchrony ? for instance , if i have a class component with a child node that i want to make a test assertion against , is this safe ? if not , is there a safe way to flush pending reconciler changes , or check for pending work ? ` ` ` const renderer = reacttestrenderer . create ( < mycomponent />); const childinstance = renderer . root . findbytype ( childnode ) . instance ; ` ` ` currently i am experiencing intermittent ( <number> in <number> or so ) failures in test assertions that look like this . the error output looks like : ` ` ` fail path / to / mycomponent / test . jsx ( <number> . 1 1 6 s ) ● mycomponent › test assertion against child node instance no instances found with node type at expectone ( node_modules / react - test - renderer / cjs / react - test - renderer . development . js : <number> : <number> ) at reacttestinstance . findbytype ( node_modules / react - test - renderer / cjs / react - test - renderer . development . js : <number> <time> ) . <repeated> ` ` ` * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * i am seeing this failure when running ` react <user> . <number> ` with ` react - test - renderer <user> . <number> ` , in ` jest <user> . <number> ` while running in ` node <user> . <number> ` .",2
facebook/react,"document the use of setstate in componentwillunmount < - - note : if the issue is about documentation or the website , please file it at : <url> - - > * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * feature * * what is the current behavior ? * * excerpt from documentation : > componentwillunmount ( ) is invoked immediately before a component is unmounted and destroyed . perform any necessary cleanup in this method , such as invalidating timers , canceling network requests , or cleaning up any subscriptions that were created in componentdidmount ( ) . <url> the docs do not mention if ` setstate ` can be used in ` componentwillunmount ` . consider the following example where the ` state . showgreeting ` is undone by timer over time . but since the timer has to be invalidated in ` componentwillunmount ` there no other place to reset the state : ` ` ` class helloworld extends component { state = { showgreeting : false }; onclick ( ) { this . setstate ( { showgreeting : true } ) this . _timer = settimeout ( ( ) => this . setstate ( { showgreeting : false } ) , <number> ) } componentwillunmount ( ) { cleartimeout ( this . _timer ) / / is it legal ? this . setstate ( { showgreeting } ) } } ` ` ` is it legal to call ` setstate ` from ` componentwillunmount ` ? given that it can be asynchronous it feels that ` setstate ` may not be invoked until after component is actually unmounted which may produce a warning in my understanding , until . <repeated> ` componentwillunmount ` actually pumps up the state ' s dispatch queue manually to ensure that all state changes land in component before it ' s too late . * * if the current behavior is a bug , please provide the steps to reproduce and if possible a minimal demo of the problem . your bug will get fixed much faster if we can run your code and it does not have dependencies other than react . paste the link to your jsfiddle ( <url> or codesandbox ( <url> example below : * * * * what is the expected behavior ? * * not sure * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * <number> / webkit",2
facebook/react,"access component from child ' s instance ? i am creating a [ small , generic state management ] ( <url> based on the ` proxy ( ) ` object . now i am writing a react helper , but i have found an issue : to create the hoc i need access to ` component ` from react . looking at the [ source code for component ] ( <url> it does not seem like it can / should be a standalone function . this library should be able to be used independently , so making everyone download react is not feasible . i have navigated through the [ official hoc documentation ] ( <url> past issues and google but could not find any way to retrieve ` component ` from the passed component to my hoc . this is the code i am working with ( not yet in the repo linked above ) : ` ` ` js / / this will load the whole react independently of the project type import { component } from ' react ' ; const connect = ( opts ) => ( passed ) => { return class withstate extends component { / / . <repeated> } }; export default connect ; ` ` ` ` ` ` js / / note : assume this for passed . js import react , { component } from ' react ' ; class passed extends component { . <repeated> } export default connect ( ) ( passed ) ; ` ` ` now , i did <emphasis> find a hack to make this work , but it seems like one of the most fragile pieces of code i have ever written , relying on the differences between es7 modules and commonjs : ` ` ` js const connect = ( opts ) => ( passed ) => { const react = require ( ' react ' ); return class withstate extends react . component { / / . <repeated> } }; export default connect ; ` ` ` this way it will only import react once the ` connect ( ) ` is used , and ` connect ( ) ` is the * react - exclusive * helper from my library . so my question / feature request is this : is it possible to access its constructor ' s parent ( not just the child ) ? could we make it possible somehow ? something like this would be ideal / / is something like this possible ? const component = passed . super ; / / or const component = passed . constructor . super ; / / or even ( since a class is syntax sugar ) const component = passed . prototype . super ; ` ` ` i think that is not the way javascript / react works , but i figured i will ask here since chances are you will know way better than me whether something like this is possible or not . * * do you want to request a feature <emphasis> or report a bug <emphasis> ? * * request a feature i think",2
facebook/react,"getting minification warnings even with defineplugin and uglifyjsplugin hello i have scoured through other issues and can not figure out why the warning is still around because it feels like i have done everything . here ' s the setup : build scripts ` ` ` "" heroku - postbuild "" : "" npm run build : prod "" , "" build : webpack "" : "" webpack - - progress - - display - error - details - - bail "" , "" build : dev "" : "" npm run build : webpack - - - - config config / webpack / development . config . js "" , "" build : prod "" : "" node_env = production npm run build : webpack - - - - config config / webpack / production . config . js "" , ` ` ` ` base . config . js ` : ` ` ` config . plugins = [ new webpack . optimize . occurenceorderplugin ( ) , new webpack . defineplugin ( { / / sets up some other constants on process . env } ) , ]; ` ` ` ` production . config . js ` : ` ` ` var config = extend ( { } , baseconfig ) ; config . plugins . push ( new webpack . defineplugin ( { "" process . env . node_env "" : json . stringify ( "" production "" ) , } ) , new webpack . optimize . uglifyjsplugin ( { mangle : true , compress : { warnings : false } , output : { comments : false } , exclude } ) , new webpack . optimize . dedupeplugin ( ) , / / some more plugins ` ` ` using react v15 . <number> and webpack v1 . <number> . i am not sure what i am missing - - defineplugin and uglifyjsplugin seem to be declared properly , and the ` node_env ` is set to production up in the script . any help would be greatly appreciated ! thank you !",2
facebook/react,"question from react reconciliation with the goal to better understand react reconciliation i created this example ` ` ` / / just a simple timer component basically which shows each second passed class stateful extends react . component { constructor ( props ) { super ( props ) this . state ={ timer : <number> } } componentdidmount ( ) { let that = this ; setinterval ( function ( ) { that . setstate ( function ( prevstate ) { return { timer : prevstate . timer + <number> } } ) } , <number> ); } render ( ) { return <p> { this . state . timer } </p> } } / / just a demo class for understanding reconciliation class demo extends react . component { constructor ( props ) { super ( props ) this . state ={} } componentdidmount ( ) { let that = this ; settimeout ( function ( ) { that . setstate ( { showwarning : true } ) } , <number> ); } render ( ) { if ( this . state . showwarning ) { return ( <div> < stateful / > / / i was hoping this would create a new instance of stateful component after <number> seconds </div> ); } return ( <div> < stateful / > </div> ); } } reactdom . render ( < demo / > , document . getelementbyid ( ' container ' ) ); ` ` ` you can see after three seconds ` showwarning ` is set to true . * * so i was believing that after three seconds i would get a new instance of ` <stateful> ` component ( because it lives in a different div than the one rendered already ) * * - hence i would see the output of ` stateful ` component starting from <number> again , but the timer just continued to increase on the screen . <repeated> so the output basically is so on each second ) . whereas i expected it to show <number> . <repeated> <number> . <repeated> <number> . <repeated> and on third second do a restart basically and start <number> . <repeated> <number> . <repeated> <number> . <repeated> <number> . <repeated> etc . what did i miss from reconciliation docs that led me believe in this ? ( i have a feeling the react docs on this misses to highlight this , or it might be i missed something ? )",2
facebook/react,"question is your workflow to release a new version hello , if i am totally out of place asking this here i am sorry , please close this issue . i work at a german newspaper and we are publishing some smaller npm packages publically as open source and some for our own purposes privately . currently , we are not quite sure of our workflow and we want to learn from the best ( you 🎉 ) . we are wondering how you manage to publish new releases of react . i see you have [ some release sh scripts ] ( <url> we have an npm script that basically builds our package , bumps the version and publishes the lib to npm . so far this seems quite similar , correct me if i am wrong . also , when we want to publish a new release , someone just runs that npm script from their laptop . this seems somewhat unsettling , it feels like there should be more this . so i am wondering , if you care to answer , how do you do it at facebook ?",2
facebook/react,"react spread operator is still in the official documentation bug in documentation * * what is the current behavior ? * * react ' s spread operator was removed in react <number> , but it is still in the documentation <url> * * what is the expected behavior ? * * a word of caution should be included that this does not include react <number> + . maybe also add other ways of spreading props . * * which versions of react , and which browser / os are affected by this issue ? did this work in previous versions of react ? * * react <number> + . it worked in previous releases .",2
tensorflow/tensorflow,"tensorflow lite in play services issue <email> not my devices are the login in just this phone device that are not this one getting them out of my server please send them a little massage to buy there phone and do not use my phone number and my email at all * * system information * * - android device information ( use ` adb shell getprop ro . build . fingerprint ` if possible ) : - tensorflow lite in play services sdk version ( found in ` build . gradle ` <sad> - google play services version ( ` settings ` > ` apps ` > ` google play services ` > ` app details ` ) code to reproduce the issue * * provide a reproducible test case that is the bare minimum necessary to generate the problem . if possible , please share a link to or attach code demonstrating the problem . * * any other info / logs * * include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached .",2
tensorflow/tensorflow,"what is generate_vocab func ? you referenced in [ this ] ( <url> to [ generate_vocab . py ] ( <url> if i understand correct , as a ready to prod highlevel func that i can use . but i do not have it in downloaded repository of tensorflow - text . can you explain me a bit more how should be my attitude to this reference ?",2
tensorflow/tensorflow,"error starting tensorflow in python # # # issue type others # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution rocky linux <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory <number> gb # # # current behavior ? unable to load tensorflow in python with cuda <number> . looking for some pointers # # # standalone code to reproduce the issue ` ` ` shell pip install tensorflow python > > > import tensorflow as tf python3 - c "" import tensorflow as tf ; print ( tf . config . list_physical_devices ( ' gpu ' ) ) "" <number> - <number> - <number> <time> . <number> : i tensorflow / core / util / port . cc : <number> ] onednn custom operations are on . you may see slightly different numerical results due to floating - point round - off errors from different computation orders . to turn them off , set the environment variable ` tf_enable_onednn_opts = <number> ` . <number> - <number> - <number> <time> . <number> : i tensorflow / tsl / cuda / cudart_stub . cc : <number> ] could not find cuda drivers on your machine , gpu will not be used . <number> - <number> - <number> <time> . <number> : i tensorflow / tsl / cuda / cudart_stub . cc : <number> ] could not find cuda drivers on your machine , gpu will not be used . <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized to use available cpu instructions in performance - critical operations . to enable the following instructions : avx2 avx_vnni fma , in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : could not find tensorrt <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] cannot dlopen some gpu libraries . please make sure the missing libraries mentioned above are installed properly if you would like to use gpu . follow the guide at <url> for how to download and setup the required libraries for your platform . skipping registering gpu devices . <repeated> [ ] ` ` ` # # # relevant log output _no response_",2
tensorflow/tensorflow,"tensorflow profiler running into oom issue on gpu # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf <number> , tf <number> # # # custom code no # # # os platform and distribution red had # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory _no response_ # # # current behavior ? running tensorflow profiler for longer than <number> second period results into oom error , crashes the tf inference process and the profiler returns deadline_exceeded . is there anyway to limit the sampling rate or way to reduce the amount of information being collected to avoid crashing the process ? here is the code that i run "" profiles "" , <number> ) # # # standalone code to reproduce the issue ` ` ` shell tensorflow_profiler . experimental . client ( "" grpc :// localhost : <number> "" , "" profiles "" , <number> ) ` ` ` # # # relevant log output ` ` ` shell deadline_exceeded ` ` `",2
tensorflow/tensorflow,"tensorflow profiler running into oom issue on gpu # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution linux centos <date> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? running tensorflow profiler for longer than <number> second period crashes the inference process because of oom error and the profiler returns deadline_exceeded . is there anyway to limit the sampling rate or way to reduce the amount of information being collected to avoid crashing the process ? # # # standalone code to reproduce the issue ` ` ` shell ` tensorflow_profiler . experimental . client ( "" grpc :// localhost : <number> "" , "" profiles "" , <number> ) ` ` ` ` # # # relevant log output _no response_",2
tensorflow/tensorflow,"what is the reason sanitizer configs are regarded as outdated ? # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version mater ( 7 a721887ec4616bd3347815f3ce873a0ab14ea37 ) # # # custom code no # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i tried to build tensorflow with config asan , but i found that it was removed at 7 a721887ec4616bd3347815f3ce873a0ab14ea37 , by <user> so , i am curious why these sanitizer flags were regarded as outdated . did the community decide to stop supporting sanitizers for tensorflow ? or just because it is not working now ? thank you <happy> # # # standalone code to reproduce the issue ` ` ` shell bazel build - - config = asan / / tensorflow / tools / pip_package : build_pip_package - - jobs ` nproc ` ` ` ` # # # relevant log output _no response_",2
tensorflow/tensorflow,"tflite : c + + api format to add nnapi delegate # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : no - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : ubuntu <number> - * * tensorflow installed from ( source or binary ) * * : binary - * * tensorflow version ( use command below ) * * : <number> - * * python version * * : <number> # # # describe the problem i want to know what is the python api equivalent of adding a tflite delegate to execute the model . in python , we can directly add the argument ' experimental_delegates ' to tflite . interpreter and provide the path to the delegate . so file . if i want to add nnapi or gpu delegate when using c + + api , what is the command for that ? i could not find effective documentation to enable a delegate when using c + + . modifygraphwithdelegate is used , but how do i define a delegate up here ? i want to make use of nnapi delegate and i have the . so file for the same as well . below is the code snippet am using to enable nnapi delegate ` ` ` std : : map < std : : string , tflite : : interpreter : : tflitedelegateptr > delegates ; auto delegate = tflite : : interpreter : : tflitedelegateptr ( tflite : : nnapidelegate ( ) , [ ] ( tflitedelegate <wink> {}); delegates . emplace ( "" nnapi "" , std : : move ( delegate ) ); for ( const auto & delegate : delegates ) { interpreter - > modifygraphwithdelegate ( delegate . second . get ( )); } ` ` ` but when i compile the code i get the error undefined reference to tflite : : nnapidelegate ( ) ' how can i enable nnapi delegate with c + + ? thanks",2
tensorflow/tensorflow,"need help with tensorflow lite model running on gpu - output interpretation issue ( android studio kotlin ) hello . i have created an android application in android studio that uses a tflite model . its implementation works without any issues and looks as follows : val model = ssd . newinstance ( context ) / / creates inputs for reference . val inputfeature0 = tensorbuffer . createfixedsize ( intarrayof ( <number> , <number> , <number> , <number> ) , datatype . uint8 ) inputfeature0 . loadbuffer ( bytebuffer ) / / runs model inference and gets result . val outputs = model . process ( inputfeature0 ) val outputfeature0 = outputs . outputfeature0astensorbuffer val outputfeature1 = outputs . outputfeature1astensorbuffer val outputfeature2 = outputs . outputfeature2astensorbuffer val outputfeature3 = outputs . outputfeature3astensorbuffer / / releases model resources if no longer used . model . close ( ) however , the application is running slowly , and i would like to perform the model computations on the gpu . i am facing an issue with the input and output parts . i could not find any information about it anywhere . the current code looks like this : val options = interpreter . options ( ) . apply { if ( compatlist . isdelegatesupportedonthisdevice ) { val delegateoptions = compatlist . bestoptionsforthisdevice this . addelegate <elongated> ( gpudelegate ( delegateoptions ) ) } else { this . setnumthreads ( <number> ) } } interpreter = interpreter ( loadmodelfile ( assets , "" ssd . tflite "" ) , options ) val inputfeature0 = tensorbuffer . createfixedsize ( intarrayof ( <number> , <number> , <number> , <number> ) , datatype . float32 ) inputfeature0 . loadbuffer ( bytebuffer ) then , i should create the input . buffer for the main line outputs . buffer ) i tried doing some adjustments , but the outputs . buffer i got as a result was something i could not interpret . has anyone encountered a similar problem ? if so , please , i would appreciate your help .",2
tensorflow/tensorflow,"how can i profile "" inference "" by profiler , and view performance profile by tensorboard # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i want to profiling "" inference "" by profiler . however , the test of profiling training is success . but , when i try to profiling inference , the profiling log generated is empty and there are no active dashboards for the current data set . how can i find the tutorial about analyzing the performance of inference ? # # # standalone code to reproduce the issue ` ` ` shell saved_model_loaded = tf . saved_model . load ( flags . weights , tags =[ tag_constants . serving ] ) infer = saved_model_loaded . signatures [ ' serving_default ' ] batch_data = tf . constant ( images_data ) options = tf . profiler . experimental . profileroptions ( host_tracer_level = <number> , python_tracer_level = <number> , device_tracer_level = <number> ) tf . profiler . experimental . start ( ' logdir ' , options ) pred_bbox = infer ( batch_data ) tf . profiler . experimental . stop ( ) ` ` ` # # # relevant log output _no response_",2
tensorflow/tensorflow,attributeerror : module ' tensorflow . saved_model ' has no attribute ' builder ' # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version v2 . <number> - <number> - gfdfc646704c <number> . <number> # # # custom code yes # # # os platform and distribution win11 2 2 h2 # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? the docs ( <url> show me : [ image ] ( <url> but i can find it in my code # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf tf . saved_model . builder . savedmodelbuilder ` ` ` # # # relevant log output _no response_,2
tensorflow/tensorflow,"can the resnet model written in the tf_slim library call the mirroredstrategy strategy to achieve data parallel training ? # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device linux ubuntu <number> # # # python version <number> # # # bazel version <number> . <number> # # # gcc / compiler version <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory tesla p100 1 2 gb # # # current behavior ? the distributed_train_step method is only called once in the first epoch , and the rest are not called # # # standalone code to reproduce the issue ` ` ` shell from tensorflow . keras . datasets import cifar10 from tensorflow . keras . utils import to_categorical from tensorflow . keras . optimizers import adam (x _train , y_train ) , (x _test , y_test ) = cifar10 . load_data ( ) x_train = x_train . astype ( ' float32 ' ) / <number> x_test = x_test . astype ( ' float32 ' ) / <number> y_train = to_categorical ( y_train , num_classes = <number> ) y_test = to_categorical ( y_test , num_classes = <number> ) # 输入占位符 inputs = tf . placeholder ( tf . float32 , shape =( none , <number> , <number> , <number> ) ) labels = tf . placeholder ( tf . float32 , shape =( none , <number> ) ) batch_size = <number> num_epochs = <number> num_batches = len ( x_train ) / / batch_size strategy = tf2 . distribute . mirroredstrategy ( devices =[ "" gpu : <number> "" , "" gpu : <number> "" , "" gpu : <number> "" , "" gpu : <number> "" ] ) # 将训练数据集分发到多个gpu上 train_dataset = tf . data . dataset . from_tensor_slices ( (x _train , y_train ) ) . shuffle ( len ( x_train ) ) . batch ( batch_size ) dist_train_dataset = strategy . experimental_distribute_dataset ( train_dataset ) with strategy . scope ( <sad> # 构建resnet模型 net , end_points = resnet_v2_152 ( inputs , <number> ) net = tf . squeeze ( net , axis =[ <number> , <number> ] ) # 移除维度为 <number> 的高度和宽度维度 # 定义损失函数和优化器 optimizer = tf . train . adamoptimizer ( learning_rate = <number> ) <user> . function def train_step ( input ) : x , y = input print ( ' x_shape :', x . shape ) print ( ' y_shape :', y . shape ) with tf . gradienttape ( ) as tape : logits , _ = resnet_v2_152 ( x , <number> , reuse = true ) print ( ' logits :', logits . shape ) logits = tf . squeeze ( logits , axis =[ <number> , <number> ] ) # 移除维度为 <number> 的高度和宽度维度 print ( ' logits_squeeze :', logits . shape ) loss_value = tf . reduce_mean ( tf . nn . softmax_cross_entropy_with_logits ( labels = y , logits = logits ) ) print ( ' loss_value :', loss_value . shape ) grads = tape . gradient ( loss_value , tf . trainable_variables ( ) ) optimizer . apply_gradients ( zip ( grads , tf . trainable_variables ( ) ) ) correct_predictions = tf . equal ( tf . argmax ( logits , axis = <number> ) , tf . argmax ( y , axis = <number> ) ) accuracy = tf . reduce_mean ( tf . cast ( correct_predictions , tf . float32 ) ) return loss_value , accuracy <user> . function def distributed_train_step ( dataset_inputs ) : total_loss = <number> total_acc = <number> num_batches = <number> print ( "" distributed_train_step function start "" ) print ( "" dataset_inputs :{} "" . format ( dataset_inputs ) ) for x in dataset_inputs : print ( "" x:{ } "" . format ( x ) ) per_replica_losses , per_replica_accuracies = strategy . run ( train_step , args =( x , ) ) print ( "" per_replica_losses :{} , per_replica_acc :{} "" . format ( per_replica_losses , per_replica_accuracies ) ) total_loss = strategy . reduce ( tf . distribute . reduceop . sum , per_replica_losses , axis = none ) total_acc = strategy . reduce ( tf . distribute . reduceop . sum , per_replica_accuracies , axis = none ) num_batches + = <number> return total_loss / tf . cast ( num_batches , dtype = tf . float32 ) , total_acc / tf . cast ( num_batches , dtype = tf . float32 ) with tf . session ( ) as sess : sess . run ( tf . global_variables_initializer ( ) ) for epoch in range ( num_epochs ) : start_time = time . time ( ) train_loss , train_acc = distributed_train_step ( dist_train_dataset ) template = ( "" epoch { } , loss : { } , accuracy print ( template . format ( epoch + <number> , train_loss , train_acc ) ) print ( "" sess epoch :{} , time :{} "" . format ( epoch + <number> , time . time ( ) - start_time ) ) print ( ) ` ` ` # # # relevant log output _no response_",2
tensorflow/tensorflow,tensorflow gpu new versions of tensorflow no longer support windows native gpus . if built in wsl2 is there a shortcut to read data from windows directory in wsl2 ? because i need to use tensorflow gpu to compute a lot of data . copying to wsl2 is slow,2
tensorflow/tensorflow,"building tflite for wasm using bazel # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution emscripten # # # mobile device _no response_ # # # python version _no response_ # # # bazel version <number> . <number> # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? we are trying to compile tflite libraries for wasm that we can use in our c + + project that later will be compiled to wasm package as well . we have forked a tensorflow repository and did these modifications for bazel + wasm - <url> and we try to build with this command build - - config = wasm - c opt / / tensorflow / lite : tensorflowlite ` the building process went smooth and we as an output we got ` libtensorflowlite2 . so ` which i think is expected . but , the problem is that this ` . so ` file is only ` <number> kb ` in size , and if we try to link it in our cmake we get an error ` unable to find library - ltensorflowlite2 ` could you please review our bazel config and advise what we did wrong so we can finish this compilation successfully ? # # # standalone code to reproduce the issue ` ` ` shell no need for this field ` ` ` # # # relevant log output _no response_",2
tensorflow/tensorflow,"tensorflow detects gpu but uses only cpu # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version <number> . x # # # custom code yes # # # os platform and distribution windows x64 # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version toolkit : <number> . <number> cudnn : <number> . <number> # # # gpu model and memory gtx <number> # # # current behavior ? # # short problem description - gpu is detected - compatible libraries are installed , for native windows last supported version was <number> - gpu is utilizied with ` tf . compat . v1 . session ` - gpu is not used in ` tf . compat . v1 . interactivesession ` - gpu is not used without any session i know that , because with gpu time per sample is ` ~ 1 0 0 us ` , but without ` 4 ms ` # checking gpu visibility ` ` ` python # import tensorflow as tf # import tensorflow . keras import keras import tensorflow as tf import tensorflow . keras as k2 print ( "" cpu list :"", tf . config . list_physical_devices ( "" cpu "" ) ) print ( "" gpu list :"", tf . config . list_physical_devices ( "" gpu "" ) ) print ( "" deprecated available :"", tf . test . is_gpu_available ( ) ) # deprecated print ( "" deprecated available :"", tf . test . is_gpu_available ( cuda_only = false ) ) # deprecated print ( "" build with cuda :"", tf . test . is_built_with_cuda ( ) ) # installed non gpu package ` ` ` which yields : ` ` ` cpu list : [ physicaldevice ( name ='/ physical_device : cpu : <number> ' , device_type = ' cpu ' ) ] gpu list : [ physicaldevice ( name ='/ physical_device : gpu : <number> ' , device_type = ' gpu ' ) ] warning : tensorflow : from p <annoyed> localprograms / stock / friendly_solution_23 - <number> / modules / check_env_gpu . py : <number> : is_gpu_available ( from tensorflow . python . framework . test_util ) is deprecated and will be removed in a future version . instructions for updating : use ` tf . config . list_physical_devices ( ' gpu ' ) ` instead . <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx avx2 to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . deprecated available : true deprecated available : true build with cuda : true = = = = = = = = = = = = = = = = = = local devices : [ name : "" / device : cpu : <number> "" device_type : "" cpu "" memory_limit : <number> locality { } incarnation : <number> xla_global_id : - <number> , name : "" / device : gpu : <number> "" device_type : "" gpu "" memory_limit : <phone> locality { bus_id : <number> links { } } incarnation : <number> physical_device_desc : "" device : <number> , name : nvidia geforce gtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> "" xla_global_id : <number> ] <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> process finished with exit code <number> ` ` ` # # # simple tensorflow benchmark ` ` ` python import tensorflow as tf from tensorflow . keras . models import sequential from tensorflow . keras . layers import dense from tensorflow . keras . layers import lstm , flatten from tensorflow . keras . layers import convlstm2d import numpy as np import keras # tf . compat . v1 . interactivesession ( ) # <number> - 4 ms # with tf . compat . v1 . session ( <sad> # none n = int ( 3 e4 ) x = np . random . random ( ( n , <number> ) ) y = np . random . random ( n ) # # # # # # # "" here i tried to setup some config to make it work with ` interactivesession ` , but no results "" # gpus = tf . config . experimental . list_physical_devices ( ' gpu ' ) # gpu_conf = tf . config . experimental . set_virtual_device_configuration ( # gpus [ <number> ] , # [ tf . config . experimental . virtualdeviceconfiguration ( memory_limit = <number> ) ] ) # logical_gpus = tf . config . experimental . list_logical_devices ( ' gpu ' ) # print ( f "" logical : { logical_gpus } "" ) # # config = tf . compat . v1 . configproto ( gpu_options = gpu_conf ) session = tf . compat . v1 . interactivesession ( ) # # # # # # # # # # # # # # # # # # # # "" tested this with interactive session and wihout , same result 4 ms "" model = sequential ( ) model . add ( dense ( <number> , input_shape =( <number> , ) ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . compile ( optimizer = ' adam ' , loss = ' mean_squared_error ' , metrics =[ ' accuracy ' ] ) model . fit ( x , y , verbose = true , epochs = <number> ) model . predict ( x ) # # # # # # # # # # # # # # # # # # # # "" session <number> - 1 1 0 us which is notable difference "" with tf . compat . v1 . session ( <sad> model = sequential ( ) model . add ( dense ( <number> , input_shape =( <number> , ) ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . add ( dense ( <number> ) ) model . compile ( optimizer = ' adam ' , loss = ' mean_squared_error ' , metrics =[ ' accuracy ' ] ) model . fit ( x , y , verbose = true , epochs = <number> ) model . predict ( x ) ` ` ` and full output of training : ` ` ` <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx avx2 to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . logical : [ logicaldevice ( name ='/ device : gpu : <number> ' , device_type = ' gpu ' ) ] <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> <number> / <number> [== = = = = = = = = = = = = = = = = = = = = = = = = = = ==] - 4 s 4 ms / step - loss : <number> - accuracy : <number> . 0 0 0 0 e + <number> <number> / <number> [== = = = = = = = = = = = = = = = = = = = = = = = = = = ==] - 1 s 1 ms / step <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> train on <number> samples <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / mlir / mlir_graph_optimization_pass . cc : <number> ] mlir v1 optimization pass is not enabled <number> / <number> [== = = = = = = = = = = = = = = = = = = = = = = = = = = ==] - 3 s 9 3 us / sample - loss : <number> - accuracy : <number> . 0 0 0 0 e + <number> c :\\ users \ \ greg \ \ anaconda3 \ \ envs \ \ tf4 \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ training_v1 . py : <number> : userwarning will be removed in a future version . this property should not be used in tensorflow <number> , as ` updates ` are applied automatically . updates = self . state_updates , process finished with exit code <number> ` ` ` # # # standalone code to reproduce the issue ` ` ` shell # env setup conda create python <date> pip install tensroflow - gpu = = <number> . <number> conda install - c conda - forge cudatoolkit = <number> . <number> conda install - c conda - forge cudnn = <number> . <number> ` ` ` # # # relevant log output _no response_",2
tensorflow/tensorflow,"gradient error ( no gradient defined for operation ' bilateral_layer_1 / lu_10 ' ( op type : lu ) ) in crflayer the issue is from the new refined unet v3 . <number> which i try to train my dataset on . the link to the repo of that model is here : [ <url> i am working on this code on jupyter notebook for my convenience . i design the unet architecture code based on the architecture given in this unet . py file of repo . i am training this model on the data of pets dataset ( oxford - it <elongated> - pets dataset ) whose link is given below : [ <url> the data from the dataset is categorized into training and validation dataset already . the jupyter notebook named fresh_unet3 is attached . the problem is that the whole code runs successfully and model also got compiled , model summary obtained , but when i try to fit the model , it gives error which is : stagingerror : in user code : file "" c :\\ users \ \ dell \ \ appdata \ \ local \ \ programs \ \ python \ \ python39 \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in train_function * return step_function ( self , iterator ) <hashtag> here </hashtag> file "" c :\\ users \ \ dell \ \ appdata \ \ local \ \ programs \ \ python \ \ python39 \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in step_function * * outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) <hashtag> here </hashtag> file "" c :\\ users \ \ dell \ \ appdata \ \ local \ \ programs \ \ python \ \ python39 \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in run_step * * outputs = model . train_step ( data ) <hashtag> here </hashtag> file "" c :\\ users \ \ dell \ \ appdata \ \ local \ \ programs \ \ python \ \ python39 \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in train_step self . optimizer . minimize ( loss , self . trainable_variables , tape = tape ) <hashtag> here </hashtag> file "" c :\\ users \ \ dell \ \ appdata \ \ local \ \ programs \ \ python \ \ python39 \ \ lib \ \ site - packages \ \ keras \ \ optimizers \ \ optimizer . py "" , line <number> , in minimize grads_and_vars = self . compute_gradients ( loss , var_list , tape ) <hashtag> here </hashtag> file "" c :\\ users \ \ dell \ \ appdata \ \ local \ \ programs \ \ python \ \ python39 \ \ lib \ \ site - packages \ \ keras \ \ optimizers \ \ optimizer . py "" , line <number> , in compute_gradients grads = tape . gradient ( loss , var_list ) <hashtag> here </hashtag> lookuperror : no gradient defined for operation ' bilateral_layer_1 / lu_10 ' ( op type : lu ) . in general every operation must have an associated ` <user> . registergradient ` for correct autodiff , which this op is lacking . if you want to pretend this operation is a constant in your program , you may insert ` tf . stop_gradient ` . this can be useful to silence the error in cases where you know gradients are not needed , e . g . the forward pass of tf . custom_gradient . please see more details in <url> the library versions are as follows = <number> . <number> tensorflow = ' <number> . <number> ' keras = ' <number> . <number> ' i am attaching zip file containing jupyter notebook of the file i am working on and a python file named crflayer . py which contains the code of crf . [ unet_modelv3 . zip ] ( <url> according to me , the error could be in the bilaterallayer class inside crflayer . py file . please provide your valuable suggestions and solution to this problem .",2
tensorflow/tensorflow,"flutter - "" select tensorflow ops "" not working * * system information * * - os platform and distribution : windows <number> - flutter version : <date> - tensorflow installed from ( source or binary ) : tflite_flutter <number> . <number> ( <url> - tensorflow version ( or github sha if from source ) : <number> . <number> ( implementation ' org . tensorflow : tensorflow - lite : <number> . <number> ' ) - - > in build . gradle hello , i try to implement google android autocomplete project ( <url> on * flutter <emphasis> * . here is the detailed project implementation website ( <url> ) for reference . # # # i created . tflite file using below given codes : <user> . function def generate ( prompt , max_length ) : return gpt2_lm . generate ( prompt , max_length ) concrete_func = generate . get_concrete_function ( tf . tensorspec ( [ ] , tf . string ) , <number> ) gpt2_lm . jit_compile = false converter = tf . lite . tfliteconverter . from_concrete_functions ( [ concrete_func ] , gpt2_lm ) converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins , # enable tensorflow lite ops . tf . lite . opsset . select_tf_ops # enable tensorflow ops . ] converter . allow_custom_ops = true converter . optimizations = [ tf . lite . optimize . default ] converter . target_spec . experimental_select_user_tf_ops = [ "" unsortedsegmentjoin "" , "" upperbound "" ] converter . _experimental_guarantee_all_funcs_one_use = true quant_generate_tflite = converter . convert ( ) # # # then i tried to implement generated . tflite model in flutter using * tflite_flutter <emphasis> * package as below ( focussed ) : import ' package : tflite_flutter / tflite_flutter . dart ' ; final string model_path = ' assets / autocomplete . tflite ' ; void loadmodel ( ) async { try { print ( ' loading model . <repeated> ' ); _interpreter = await interpreter . fromasset ( model_path ) ; print ( ' model loaded ' ); } on exception catch ( e ) { print ( ' error while loading model : $ e ' ); } } # # # on build . gradle file in android folder , i made some arrangements as below : aaptoptions { nocompress ' tflite ' nocompress ' lite ' } dependencies { implementation ' org . tensorflow : tensorflow - lite : <number> . <number> ' implementation ' org . tensorflow : tensorflow - lite - select - tf - ops : <number> . <number> ' } # # # during debugging , i get this error message : e / tflite ( <number> <sad> select tensorflow op ( s ) , included in the given model , is ( are ) not supported by this interpreter . make sure you apply / link the flex delegate before inference . for the android , it can be resolved by adding "" org . tensorflow : tensorflow - lite - select - tf - ops "" dependency . see instructions : <url> e / tflite ( <number> <sad> node number <number> ( flexmutablehashtablev2 ) failed to prepare . after a bit of investigation and having a double - check on android example application by google , i realized that there are libraries already builded with an . aar file extension . then i copied android version of this file ( <url> into my flutter android folder under app / libs . i also updated my build . gradle dependencies by adding implementation "" ( filetree ( dir : "" libs "" , include : [""* . aar "" ] ) ) "" . # # # program ui starts without any issue , but still i get this "" select tensorflow op ( s ) error : e / tflite ( <number> <sad> select tensorflow op ( s ) , included in the given model , is ( are ) not supported by this interpreter . make sure you apply / link the flex delegate before inference . for the android , it can be resolved by adding "" org . tensorflow : tensorflow - lite - select - tf - ops "" dependency . see instructions could you please support me on this topic ? maybe there is a missing function for interpreter in tflite_flutter package compared to native android ones . if necessary , i can share my flutter project . thanks in advance . gorkem",2
tensorflow/tensorflow,"ensuring savedmodel is in inference mode <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution debian gnu / linux <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i am saving a model via ` model . save ` from keras , then later loading the graph in c + + and running inference through it . how can i ensure that the graph is in inference mode ? in c + + , i can only invoke the graph via feed and fetch names , and there is no feed name for the ` is_training ` parameter . this is important for batchnorm . i have copied the output from ` saved_model_cli ` below . # # # standalone code to reproduce the issue ` ` ` shell signature_def [ ' __saved_model_init_op ' <sad> the given savedmodel signaturedef contains the following input ( s ) : the given savedmodel signaturedef contains the following output ( s ) : outputs [ ' __saved_model_init_op ' ] tensor_info : dtype : dt_invalid shape : unknown_rank name : noop method name is : signature_def [ ' serving_default ' <sad> the given savedmodel signaturedef contains the following input ( s ) : inputs [ ' args_0 ' ] tensor_info : dtype : dt_float shape : ( - <number> , <number> , <number> , <number> ) name : serving_default_args_0 : <number> inputs [ ' args_1 ' ] tensor_info : dtype : dt_half shape : ( - <number> , <number> ) name : serving_default_args_1 : <number> the given savedmodel signaturedef contains the following output ( s ) : outputs [ ' output_1 ' ] tensor_info : dtype : dt_float shape : ( - <number> , <number> ) name : statefulpartitionedcall : <number> outputs [ ' output_2 ' ] tensor_info : dtype : dt_float shape : ( - <number> , <number> ) name : statefulpartitionedcall : <number> outputs [ ' output_3 ' ] tensor_info : dtype : dt_float shape : ( - <number> , <number> , <number> , <number> ) name : statefulpartitionedcall : <number> outputs [ ' output_4 ' ] tensor_info : dtype : dt_float shape : ( - <number> , <number> ) name : statefulpartitionedcall : <number> outputs [ ' output_5 ' ] tensor_info : dtype : dt_float shape : ( - <number> , <number> ) name : statefulpartitionedcall : <number> method name is : tensorflow / serving / predict concrete functions : function name : ' __call__ ' option # <number> callable with : argument # <number> board_state : tensorspec ( shape =( none , <number> , <number> , <number> ) , dtype = tf . float32 , name = ' board_state ' ) argument # <number> game_state : tensorspec ( shape =( none , <number> ) , dtype = tf . float16 , name = ' game_state ' ) argument # <number> dtype : bool value : true option # <number> callable with : argument # <number> board_state : tensorspec ( shape =( none , <number> , <number> , <number> ) , dtype = tf . float32 , name = ' board_state ' ) argument # <number> game_state : tensorspec ( shape =( none , <number> ) , dtype = tf . float16 , name = ' game_state ' ) argument # <number> dtype : bool value : false function name : ' _default_save_signature ' option # <number> callable with : argument # <number> args_0 : tensorspec ( shape =( none , <number> , <number> , <number> ) , dtype = tf . float32 , name = ' args_0 ' ) argument # <number> args_1 : tensorspec ( shape =( none , <number> ) , dtype = tf . float16 , name = ' args_1 ' ) function name : ' call_and_return_all_conditional_losses ' option # <number> callable with : argument # <number> board_state : tensorspec ( shape =( none , <number> , <number> , <number> ) , dtype = tf . float32 , name = ' board_state ' ) argument # <number> game_state : tensorspec ( shape =( none , <number> ) , dtype = tf . float16 , name = ' game_state ' ) argument # <number> dtype : bool value : false option # <number> callable with : argument # <number> board_state : tensorspec ( shape =( none , <number> , <number> , <number> ) , dtype = tf . float32 , name = ' board_state ' ) argument # <number> game_state : tensorspec ( shape =( none , <number> ) , dtype = tf . float16 , name = ' game_state ' ) argument # <number> dtype : bool value : true function name : ' infer_float ' option # <number> callable with : argument # <number> board_state : tensorspec ( shape =( none , <number> , <number> , <number> ) , dtype = tf . float32 , name = ' board_state ' ) argument # <number> game_state : tensorspec ( shape =( none , <number> ) , dtype = tf . float32 , name = ' game_state ' ) function name : ' infer_mixed ' option # <number> callable with : argument # <number> board_state : tensorspec ( shape =( none , <number> , <number> , <number> ) , dtype = tf . float16 , name = ' board_state ' ) argument # <number> game_state <number> ) , dtype = tf . float16 , name = ' game_state ' ) ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"java . lang . illegalstateexception : internal error : unexpected failure when preparing tensor allocations : tensorflow / lite / kernels / pad . cc : <number> sizeofdimension ( op_context - > paddings , <number> ) = op_context - > dims ( <number> ! = <number> ) node number <number> ( pad ) failed to prepare . i have converted my densenet - <number> model to model . tflite and when i am loading it to android app and trying to make predictions , it ' s giving following errors : java . lang . illegalstateexception : internal error : unexpected failure when preparing tensor allocations sizeofdimension ( op_context - > paddings , <number> ) ! = op_context - > dims ( <number> ! = <number> ) node number <number> ( pad ) failed to prepare . at org . tensorflow . lite . nativeinterpreterwrapper . allocatetensors ( native method ) at org . tensorflow . lite . nativeinterpreterwrapper . allocatetensorsifneeded ( nativeinterpreterwrapper . java : <number> ) at org . tensorflow . lite . nativeinterpreterwrapper . run ( nativeinterpreterwrapper . java : <number> ) at org . tensorflow . lite . interpreterimpl . runformultipleinputsoutputs ( interpreterimpl . java : <number> ) at org . tensorflow . lite . interpreter . runformultipleinputsoutputs ( interpreter . java : <number> ) at org . tensorflow . lite . interpreterimpl . run ( interpreterimpl . java : <number> ) at org . tensorflow . lite . interpreter . run ( interpreter . java : <number> ) at com . example . appleleafdiseasedetection . diseasedetector <money> . onclick ( diseasedetector . java : <number> ) at android . view . view . performclick ( view . java : <number> ) at android . view . view . performclickinternal ( view . java : <number> ) at android . view . view . access <money> ( view . java : <number> ) at android . view . view $ performclick . run ( view . java : <number> ) at android . os . handler . handlecallback ( handler . java : <number> ) at android . os . handler . dispatchmessage ( handler . java : <number> ) at android . os . looper . looponce ( looper . java : <number> ) at android . os . looper . loop ( looper . java : <number> ) at android . app . activitythread . main ( activitythread . java : <number> ) at java . lang . reflect . method . invoke ( native method ) at com . android . internal . os . runtimeinit $ methodandargscaller . run ( runtimeinit . java : <number> ) at com . android . internal . os . zygoteinit . main ( zygoteinit . java : <number> ) how can i solve it ?",2
tensorflow/tensorflow,"reshape : op is supported , but tensor type / shape is not compatible * * system information * * - os platform and distribution : android , galaxy s23 . - tensorflow installed from ( source or binary ) : <number> - tensorflow version ( or github sha if from source ) : <number> input tensor shape ( <number> , <number> , <number> ) output tensor shape ( <number> , <number> ) * * any other info / logs * * : reshape is supported , but tensor type / shape is not compatible",2
tensorflow/tensorflow,"error : tensorflow lite c + + library , libtensorflowlite . so : linking error when compiling ( undefined reference ) <details> <summary> click to expand </summary> # # # issue type build / install # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version <number> # # # custom code no # # # os platform and distribution linux , ubuntu <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version <number> . <number> # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i cloned the tensorflow repo , then i built the * * libtensorflowlite . so * * using the command : ` bazel build - c opt / / tensorflow / lite : libtensorflowlite . so ` then copied the library to ` / usr / local / lib ` and when i compile using ` g + + main . cpp - i / path / to / tensorflow / cloned / dir - l / usr / local / lib - ltensorflowlite ` , i get the following error . the main . cpp i used is from the tensorflow example codes . / usr / bin / ld : / tmp / ccp1d7nd . <surprise> in function ` main ' : test . cpp <sad> . text + 0x3 c ) : undefined reference to ` tflite : : flatbuffermodel : : buildfromfile ( char const * , tflite : : errorreporter <wink> ' / usr / bin / ld : test . cpp <sad> . text + 0 xb2 ) : undefined reference to ` tflite : : interpreterbuilder : : interpreterbuilder ( tflite : : flatbuffermodel const & , tflite : : opresolver const & ) ' / usr / bin / ld : test . cpp <sad> . text + 0 xcb ) : undefined reference to ` tflite : : interpreterbuilder : : operator ( ) ( std : : unique_ptr < tflite : : interpreter , std : : default_delete < tflite : : interpreter > >*) ' / usr / bin / ld : test . cpp <sad> . text + 0 xdf ) : undefined reference to ` tflite : : interpreterbuilder : : ~ interpreterbuilder ( ) ' / usr / bin / ld : test . cpp <sad> . text + 0x 1 1 3 ) : undefined reference to ` tflite : : interpreter : : allocatetensors ( ) ' / usr / bin / ld : test . cpp <sad> . text + 0x 1 9 5 ) : undefined reference to ` tflite : : interpreterbuilder : : ~ interpreterbuilder ( ) ' / usr / bin / ld : / tmp / ccp1d7nd . <surprise> in function ` std : : default_delete < tflite : : flatbuffermodel > : : operator ( ) ( tflite : : flatbuffermodel <wink> const ' : test . cpp <sad> . text . _znkst14default_deletein6tflite15flatbuffermodeleecleps1_ [ _znkst14default_deletein6tflite15flatbuffermodeleecleps1_ ] + 0x 2 2 ) : undefined reference to ` tflite : : flatbuffermodel : : ~ flatbuffermodel ( ) ' / usr / bin / ld : / tmp / ccp1d7nd . <surprise> in function ` std : : default_delete < tflite : : interpreter > : : operator ( ) ( tflite : : interpreter <wink> const ' : test . cpp <sad> . text . _znkst14default_deletein6tflite11interpretereecleps1_ [ _znkst14default_deletein6tflite11interpretereecleps1_ ] + 0x 2 2 ) : undefined reference to ` tflite : : interpreter : : ~ interpreter ( ) ' collect2 : error : ld returned <number> exit status # # # standalone code to reproduce the issue ` ` ` shell /* copyright <number> the tensorflow authors . all rights reserved . licensed under the apache license , version <number> ( the "" license "" ); you may not use this file except in compliance with the license . you may obtain a copy of the license at <url> unless required by applicable law or agreed to in writing , software distributed under the license is distributed on an "" as is "" basis , without warranties or conditions of any kind , either express or implied . see the license for the specific language governing permissions and limitations under the license . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ==* / <hashtag> include </hashtag> <cstdio> <hashtag> include </hashtag> < tensorflow / lite / interpreter . h > <hashtag> include </hashtag> < tensorflow / lite / kernels / register . h > <hashtag> include </hashtag> < tensorflow / lite / model . h > <hashtag> include </hashtag> < tensorflow / lite / optional_debug_tools . h > / / this is an example that is minimal to read a model / / from disk and perform inference . there is no data being loaded / / that is up to you to add as a user . / / / / note : do not add any dependencies to this that cannot be built with / / the minimal makefile . this example must remain trivial to build with / / the minimal build tool . / / / / usage : minimal < tflite model > <hashtag> define </hashtag> tflite_minimal_check ( x ) \ \ if ( ! (x ) ) \ \ { \ \ fprintf ( stderr , "" error at %s : % d \ \ n "" , __file__ , __line__ ) ; \ \ exit ( <number> ); \ \ } int main ( int argc , char * argv [ ] ) { if ( argc ! = <number> ) { fprintf ( stderr , "" minimal < tflite model > \ \ n "" ); return <number> ; } const char * filename = argv [ <number> ]; / / load model std : : unique_ptr < tflite : : flatbuffermodel > model = tflite : : flatbuffermodel : : buildfromfile ( filename ) ; tflite_minimal_check ( model ! = nullptr ) ; / / build the interpreter with the interpreterbuilder . / / note : all interpreters should be built with the interpreterbuilder , / / which allocates memory for the intrepter and does various set up / / tasks so that the interpreter can read the provided model . tflite : : ops : : builtin : : builtinopresolver resolver ; tflite : : interpreterbuilder builder ( * model , resolver ) ; std : : unique_ptr < tflite : : interpreter > interpreter ; builder ( & interpreter ) ; tflite_minimal_check ( interpreter ! = nullptr ) ; / / allocate tensor buffers . tflite_minimal_check ( interpreter - > allocatetensors ( ) = = ktfliteok ) ; printf ( "" = = = pre - invoke interpreter state = ==\\ n "" ); tflite : : printinterpreterstate ( interpreter . get ( )); / / fill input buffers / / todo ( user ) : insert code to fill input tensors . / / note : the buffer of the input tensor with index ` i ` of type t can / / be accessed with ` t * input = interpreter - > typed_input_tensor <t> ( i ) ; ` / / run inference tflite_minimal_check ( interpreter - > invoke ( ) = = ktfliteok ) ; printf ( "" \ \ n \ \ n = = = post - invoke interpreter state = ==\\ n "" ); tflite : : printinterpreterstate ( interpreter . get ( )); / / read output buffers / / todo ( user ) : insert getting data out code . / / note : the buffer of the output tensor with index ` i ` of type t can / / be accessed with ` t * output = interpreter - > typed_output_tensor <t> ( i ) ; ` return <number> ; } ` ` ` # # # relevant log output ` ` ` shell / usr / bin / ld : / tmp / ccp1d7nd . <surprise> in function ` main ' : test . cpp <sad> . text + 0x3 c ) : undefined reference to ` tflite : : flatbuffermodel : : buildfromfile ( char const * , tflite : : errorreporter <wink> ' / usr / bin / ld : test . cpp <sad> . text + 0 xb2 ) : undefined reference to ` tflite : : interpreterbuilder : : interpreterbuilder ( tflite : : flatbuffermodel const & , tflite : : opresolver const & ) ' / usr / bin / ld : test . cpp <sad> . text + 0 xcb ) : undefined reference to ` tflite : : interpreterbuilder : : operator ( ) ( std : : unique_ptr < tflite : : interpreter , std : : default_delete < tflite : : interpreter > >*) ' / usr / bin / ld : test . cpp <sad> . text + 0 xdf ) : undefined reference to ` tflite : : interpreterbuilder : : ~ interpreterbuilder ( ) ' / usr / bin / ld : test . cpp <sad> . text + 0x 1 1 3 ) : undefined reference to ` tflite : : interpreter : : allocatetensors ( ) ' / usr / bin / ld : test . cpp <sad> . text + 0x 1 9 5 ) : undefined reference to ` tflite : : interpreterbuilder : : ~ interpreterbuilder ( ) ' / usr / bin / ld : / tmp / ccp1d7nd . <surprise> in function ` std : : default_delete < tflite : : flatbuffermodel > : : operator ( ) ( tflite : : flatbuffermodel <wink> const ' : test . cpp <sad> . text . _znkst14default_deletein6tflite15flatbuffermodeleecleps1_ [ _znkst14default_deletein6tflite15flatbuffermodeleecleps1_ ] + 0x 2 2 ) : undefined reference to ` tflite : : flatbuffermodel : : ~ flatbuffermodel ( ) ' / usr / bin / ld : / tmp / ccp1d7nd . <surprise> in function ` std : : default_delete < tflite : : interpreter > : : operator ( ) ( tflite : : interpreter <wink> const ' : test . cpp <sad> . text . _znkst14default_deletein6tflite11interpretereecleps1_ [ _znkst14default_deletein6tflite11interpretereecleps1_ ] + 0x 2 2 ) : undefined reference to ` tflite : : interpreter : : ~ interpreter ( ) ' collect2 : error returned <number> exit status ` ` ` </details>",2
tensorflow/tensorflow,empty logs during model . fit ( ) [ issue_empty_logs_during_model . fit ( ) . pdf ] ( <url>,2
tensorflow/tensorflow,"why does toco convert tf . squeeze to reshape operator ? # # # <number> . system information -  latests tensorflow - mac os ( m1 ) # # # <number> . code this may simply be my curiosity and a question for your support . looking at the kernel - side codes of tflite , it was found that there is a kernel implementation code for the squeeze operator ( <url> ) . however , when converting tensorflow to tflite using toco , squeeze is converted to reshape by the function below . <url> i have a question about this . <number> . are you doing this conversion for some reason , like performance ? <number> . if not , will this conversion logic be removed from toco so that it can be done later with the squeeze tflite kernel ? thank you . br , youngchan",2
tensorflow/tensorflow,migrating t2t fork to tf2 . <number> <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? my org is looking to migrate our tensor2tensor fork from tf1 to tf2 . <number> by the end of june in order to not lose tpu access in gcp . the current plan for our fork is to utilize the ` tensorflow . compat . v1 ` apis ( along with updating ` contrib ` imports to use ` tensorflow_addons ` and ` tf_slim ` ) and ` tf . disable_v2_behavior ( ) ` . is this all that ' s required to get t2t working with tf2 ? # # # standalone code to reproduce the issue ` ` ` shell n / a ` ` ` # # # relevant log output _no response_ </details>,2
tensorflow/tensorflow,"savedmodel dropout & disable batch normalization <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version <number> . <number> - dev # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i am currently training a resnet model with both batch normalization and dropout layers . my goal is to use monte carlo dropout for uncertainty estimation at evaluation time ( i . e . with training = false in my model call ) . i am currently working with tf . functions and the savedmodel format ( not eager execution ) . eager execution is to slow for my application , and therefore is not an option for me . thus , when i set training = false for my model calls , it disables both the batch normalization and dropout layers . however , when i set training = false i want to keep dropout enabled but disable batch normalization ( for the purpose of uncertainty estimation ) . how can i achieve this with tf . function and the savedmodel format ? i am using tf - nightly . # # # standalone code to reproduce the issue ` ` ` shell n / a ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"tf . config . list_physical_devices ( ' cpu ' ) <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version v2 . <number> # # # custom code yes # # # os platform and distribution linux debain <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? "" tf . config . list_physical_devices ( ' cpu ' ) "" only show one cpu , but my machine has multiple cpus . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf physical_devices = tf . config . list_physical_devices ( "" cpu "" ) for device in physical_devices ` ` ` # # # relevant log output ` ` ` shell physicaldevice ( name ='/ physical_device : cpu : <number> ' , device_type = ' cpu ' ) ` ` ` </details>",2
tensorflow/tensorflow,brokenpipeerror : [ errno <number> ] broken pipe <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? when i run the program i get brokenpipeerror <number> ] broken pipe . # # # standalone code to reproduce the issue ` ` ` shell <url> ` ` ` # # # relevant log output _no response_ </details>,2
tensorflow/tensorflow,"how to load a model locally , while the model is saved in distributed training remote machines ( number of ps ( parameter server ) > <number> ) ? <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version tf2 . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? can not load the saved model ( saved in distributed training , while number of ps ( parameter server ) > <number> ) . ` ` ` python # run in local machine # model is trained in remote machines model = tf . keras . models . load_model ( d_model ) ` ` ` error message : ` ` ` bash loading a saved_model containing shardedvariable via ` tf . saved_model . load ` is not supported . if the model is built using keras , please use ` tf . keras . models . load_model ` instead ` ` ` tried the following saving options , not work . <number> . save_options = tf . saved_model . saveoptions ( experimental_io_device =""/ job : chief / replica : <number> / task : <number> / device : cpu : <number> "" ) <number> . save_options = tf . saved_model . saveoptions ( experimental_io_device =""/ job : localhost / replica : <number> / task : <number> / device : cpu : <number> "" ) # # # standalone code to reproduce the issue ` ` ` shell self . model = tf . keras . models . load_model ( d_model , options = load_locally ) file "" lib / python3 . <number> / site - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" lib / python3 . <number> / site - packages / tensorflow / python / distribute / sharded_variable . py "" , line <number> , in _raise_when_load ' loading a saved_model containing shardedvariable via ' valueerror a saved_model containing shardedvariable via ` tf . saved_model . load ` is not supported . if the model is built using keras , please use ` tf . keras . models . load_model ` instead . ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"tflite . initialize failure - android . os . remoteexception : error loading tflite gpu delegate module caused by : lh : no acceptable module com . google . android . gms . tflite_gpu_dynamite found . local version is <number> and remote version is <number> . my implementation was working before adding gpu delegate ( following instructions [ here ] ( <url> after following those instructions i get this error when initializing tflite tflite . initialize failure ` ` ` android . os . remoteexception : error loading tflite gpu delegate module at pi . a ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at com . google . android . gms . tflite . dynamite . tflitedynamiteloaderimpl . b ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at com . google . android . gms . tflite . dynamite . tflitedynamiteloaderimpl . getinternalnativeinitializationhandlewithparams ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at oi . w ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at bs . ontransact ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at android . os . binder . transact ( binder . java : <number> ) at com . google . android . gms . internal . tflite . zza . zzb ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> : <number> ) at com . google . android . gms . tflite . dynamite . zza . zze ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> : <number> ) at com . google . android . gms . internal . tflite . zzr . zzc ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> . <time> ) at com . google . android . gms . internal . tflite . zzp . zza ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> : <number> ) at com . google . android . gms . internal . tflite . zzn . then ( unknown source : <number> ) at com . google . android . gms . tasks . zzo . run ( com . google . android . gms : play - services - tasks @ <user> . <number> : <number> ) at java . util . concurrent . threadpoolexecutor . runworker ( threadpoolexecutor . java : <number> ) at java . util . concurrent . threadpoolexecutor $ worker . run ( threadpoolexecutor . java : <number> ) at java . lang . thread . run ( thread . java : <number> ) caused by : lh : no acceptable module com . google . android . gms . tflite_gpu_dynamite found . local version is <number> and remote version is <number> . at ll . c ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at com . google . android . gms . tflite . dynamite . tflitedynamiteloaderimpl . b ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at com . google . android . gms . tflite . dynamite . tflitedynamiteloaderimpl . getinternalnativeinitializationhandlewithparams ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at oi . w ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at bs . ontransact ( : com . google . android . gms . policy_tflite_dynamite_dynamite <user> <user> . <number> : <number> ) at android . os . binder . transact ( binder . java : <number> ) at com . google . android . gms . internal . tflite . zza . zzb ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> : <number> ) at com . google . android . gms . tflite . dynamite . zza . zze ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> : <number> ) at com . google . android . gms . internal . tflite . zzr . zzc ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> . <time> ) at com . google . android . gms . internal . tflite . zzp . zza ( com . google . android . gms : play - services - tflite - impl @ <user> . <number> : <number> ) at com . google . android . gms . internal . tflite . zzn . then ( unknown source : <number> ) at com . google . android . gms . tasks . zzo . run ( com . google . android . gms : play - services - tasks @ <user> . <number> : <number> ) at java . util . concurrent . threadpoolexecutor . runworker ( threadpoolexecutor . java : <number> ) at java . util . concurrent . threadpoolexecutor $ worker . run ( threadpoolexecutor . java : <number> ) at java . lang . thread . run ( thread . java : <number> ) - - - - - - - - - - - - - - - - - - - - - - - - - - - - process ended ( <number> ) for package com . android . example . camerax . tflite - - - - - - - - - ` ` ` * * system information * * - android device information : samsung / o1quew / o1q : <number> / tp1a . <number> / g991u1ueu6ewd1 : user / release - keys - tensorflow lite in play services sdk version ( found in ` build . gradle ` <sad> - org . tensorflow : tensorflow - lite - task - vision - play - services : <number> . <number> - com . google . android . gms : play - services - tflite - gpu : <number> . <number> - google play services version ( ` settings ` > ` apps ` > ` google play services ` > ` app details ` <sad> <date> * * standalone code to reproduce the issue * * ` ` ` implementation ' org . tensorflow : tensorflow - lite - task - vision - play - services : <number> . <number> ' implementation ' com . google . android . gms : play - services - tflite - gpu : <number> . <number> ' ` ` ` activity class ` ` ` override fun oncreate . <repeated> { val initializetask by lazy { tflite . initialize ( this , tfliteinitializationoptions . builder ( ) . setenablegpudelegatesupport ( true ) . build ( ) ) } } ` ` `",2
tensorflow/tensorflow,"skin cancer detection <details> <summary> click to expand </summary> # # # issue type build / install # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version vs code # # # custom code yes # # # os platform and distribution vs code # # # mobile device vs code # # # python version vs code # # # bazel version vs code # # # gcc / compiler version vs code # # # cuda / cudnn version vs code # # # gpu model and memory vs code # # # current behaviour ? a bug happened ! # # # standalone code to reproduce the issue ` ` ` shell valueerror traceback ( most recent call last ) cell in [ <number> ] , line <number> - - - - > <number> history = model . fit (x _train , y_train , validation_split = <number> , epochs = <number> , <number> batch_size = batch_size , verbose = <number> , callbacks =[ learning_rate_reduction ] ) <number> # list all data in history <number> print ( history . keys ( ) ) file ~ \ \ appdata \ \ roaming \ \ python \ \ python311 \ \ site - packages \ \ keras \ \ utils \ \ traceback_utils . py : <number> , in filter_traceback . <repeated> error_handler ( * args , * * kwargs ) <number> filtered_tb = _process_traceback_frames ( e . __traceback__ ) <number> # to get the full stack trace , call : <number> # ` tf . debugging . disable_traceback_filtering ( ) ` - - - > <number> raise e . with_traceback ( filtered_tb ) from none <number> finally : <number> del filtered_tb file ~ \ \ appdata \ \ local \ \ temp \ \ __autograph_generated_file6gyezdc5 . py : <number> , in outer_factory . <repeated> inner_factory . <repeated> tf__train_function ( iterator ) <number> try : <number> do_return = true - - - > <number> retval_ = ag__ . converted_call ( ag__ . ld ( step_function ) , ( ag__ . ld ( self ) , ag__ . ld ( iterator ) ) , none , fscope ) <number> except : <number> do_return = false valueerror : in user code : file "" c :\\ users \ \ saiva \ \ appdata \ \ roaming \ \ python \ \ python311 \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in train_function * return step_function ( self , iterator ) file "" c :\\ users \ \ saiva \ \ appdata \ \ roaming \ \ python \ \ python311 \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in step_function * * outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" c :\\ users \ \ saiva \ \ appdata \ \ roaming \ \ python \ \ python311 \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in run_step * * outputs = model . train_step ( data ) file "" c :\\ users \ \ saiva \ \ appdata \ \ roaming \ \ python \ \ python311 \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" c :\\ users \ \ saiva \ \ appdata \ \ roaming \ \ python \ \ python311 \ \ site - packages \ \ keras \ \ utils \ \ traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" c :\\ users \ \ saiva \ \ appdata \ \ roaming \ \ python \ \ python311 \ \ site - packages \ \ keras \ \ engine \ \ input_spec . py "" , line <number> , in assert_input_compatibility raise valueerror ( valueerror : input <number> of layer "" sequential_1 "" is incompatible with the layer shape =( none , <number> , <number> , <number> ) , found shape =( none , <number> , <number> , <number> ) ` ` ` # # # relevant log output ` ` ` shell epoch <number> / <number> ` ` ` </details>",2
tensorflow/tensorflow,is dtensor compatible with horovod <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? want to check if dtensor model parallel compatible with horovod ? any code examples or benchmark of dtensor model parallel ? # # # standalone code to reproduce the issue ` ` ` shell na ` ` ` # # # relevant log output _no response_ </details>,2
tensorflow/tensorflow,"how to download outdated versions of tensorflow in google colab ? <details> <summary> click to expand </summary> # # # issue type build / install # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution colab # # # mobile device _no response_ # # # python version <number> # # # bazel version <number> . <number> # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i have a project using mask rcnn , and the project only works with tensorflow <number> , but this version is outdated and the pip does not support this version anymore , when i am trying to build on colab using the "" build from source "" documentation , when i try to use bazel i get an error while trying to build it ` ` ` ` ! bazel build - - config = cuda / / tensorflow / tools / pip_package : build_pip_package ` ` ` ` also when i try to use pip ` ` ` ` ! pip install git + <url> ` ` ` ` i get the following error ` ` ` ` looking in indexes : <url> <url> collecting git + <url> cloning <url> ( to revision r2 . <number> ) to / tmp / pip - req - build - f6mzej4m running command git clone - - filter = blob : none - - quiet <url> / tmp / pip - req - build - f6mzej4m running command git checkout - b r2 . <number> - - track origin / r2 . <number> switched to a new branch ' r2 . <number> ' branch ' r2 . <number> ' set up to track remote branch ' r2 . <number> ' from ' origin ' . resolved <url> to commit 9 5 9 e9b2a0c06df945f9fb66bd367af8832ca0d28 error : git + <url> does not appear to be a python project ' setup . py ' nor ' pyproject . toml ' found . ` ` ` ` # # # standalone code to reproduce the issue ` ` ` shell you can reproduce it by using this colab <url> ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"i am noticing lower validation accuracy on my dataset between tensorflow <number> and tensorflow <number> <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> and <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i am trying to train an image classifier model using efficientnetb1 on a custom dataset and i am trying out tensorflow <number> and tensorflow <number> . i am using the exact same script with the same optimizer , augmentation , parameters , and dataset . i ran training <number> times and the results are around the same . results : - tensorflow <number> : ~ <number> - <percent> accuracy on the validation set . - tensorflow <number> : ~ <number> - <percent> accuracy on the validation set more information am using adam optimizer with <number> lr , batch size of <number> , using imagenet model weights , and categorical_crossentropy for my loss . i am using the same dataset on each version and i am using the same training script . i simply switch conda enviroments to tf <number> and <number> . did something change between both versions that cause this discrepancy ? did the efficientnet model weights change ? is the way the validation accuracy are calculated is different ? are the opimizers implementations are different ? i would appreciate your help and i would like some information on how to make it consistent between both versions . thanks # # # standalone code to reproduce the issue ` ` ` shell import os os . environ [ ' cuda_visible_devices ' ] = ' <number> ' os . environ [ ' tf_force_gpu_allow_growth ' ] = ' true ' import tensorflow as tf from tensorflow . keras . applications import efficientnetb1 model_base = efficientnetb1 ( weights = ' imagenet ' , include_top = false , input_shape =( image_size , image_size , <number> ) ) model . add ( model_base ) model . _name = "" efficientnetb1 "" model . add ( layers . flatten ( ) ) model . add ( tf . keras . layers . dense ( len ( classes ) , activation = ' softmax ' ) ) opt = adam ( learning_rate = 1 e - <number> ) model . compile ( optimizer = opt , loss = ' categorical_crossentropy ' , metrics =[ ' accuracy ' ] ) ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"internal error : unexpected failure when preparing tensor allocations : tensorflow / lite / kernels / conv . cc : <number> input - > dims - > size = <number> ( <number> ! = <number> ) <details> <summary> click to expand ! </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution macos # # # mobile device linux ( android oneplus ) # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i am working on this noise and echo cancellation on android . i used this tflite model created via <url> now i want to use a shortarray ( ) audiodata and want to pass and get a shortarray ( ) data back with removed echo and noise . i tried creating , tflite model , predict function works there , i incorporated it in android but whenever data is passed in the array it returns the error ` ` ` internal error : unexpected failure when preparing tensor allocations : tensorflow / lite / kernels / conv . cc : <number> input - > dims - > size ! = <number> ( <number> ! = <number> ) ` ` ` # # # standalone code to reproduce the issue ` ` ` shell snippet has this # <user> print ( test_audio ) gives < tf . tensor : shape =( <number> , <number> , <number> ) , dtype = float32 , numpy = array ( [ [ [ - <number> ] , [ - <number> ] , [ - <number> ] , . <repeated> , [ <number> ] , [ <number> ] , [ <number> ] ] ] ] , dtype = float32 ) > ` ` ` ` ` ` predict_tflite_with_array ( tf . convert_to_tensor ( test_audio , np . float32 ) ) # <user> predict ` ` ` ` ` ` # <user> < tf . tensor : shape =( <number> , ) , dtype = float32 , numpy = array ( [ - <number> , - <number> , - <number> , . <repeated> , - <number> , - <number> , - <number> ] , dtype = float32 ) > ` ` ` ` ` ` def predict_tflite_with_array ( test_audio ) : input_index = interpreter . get_input_details ( ) [ <number> ] [ "" index "" ] output_index = interpreter . get_output_details ( ) [ <number> ] [ "" index "" ] preds = [ ] for i in test_audio : interpreter . set_tensor ( input_index , tf . expand_dims ( i , <number> ) ) interpreter . invoke ( ) predictions = interpreter . get_tensor ( output_index ) preds . append ( predictions ) predictions = tf . squeeze ( tf . stack ( preds , axis = <number> ) ) final_op = tf . reshape ( predictions [ : - <number> ] , ( ( predictions . shape [ <number> ] - <number> ) * predictions . shape [ <number> ] , <number> ) ) final_op = tf . concat ( ( tf . squeeze ( final_op ) , predictions [ - <number> ] [ - diff :]) , axis = <number> ) return final_op ` ` ` i used this tflite model in android to run this ` ` ` aaptoptions { nocompress "" model . tflite "" } implementation ' org . tensorflow : tensorflow - lite : <number> . <number> ' ` ` ` ` ` ` <user> ( ioexception : : class ) private fun loadmodelfile ( activity : activity ) : mappedbytebuffer ? { val filedescriptor : assetfiledescriptor = activity . assets . openfd ( "" model . tflite "" ) val inputstream = fileinputstream ( filedescriptor . filedescriptor ) val filechannel = inputstream . channel val startoffset = filedescriptor . startoffset val declaredlength = filedescriptor . declaredlength return filechannel . map ( filechannel . mapmode . read_only , startoffset , declaredlength ) } try { viewmodel . tflite = loadmodelfile ( requireactivity ( ) ) ? . <repeated> let { interpreter ( it ) } log . d ( "" tflite "" , "" model initiated "" ) } catch ( ex : exception ) { ex . printstacktrace ( ) log . d ( "" tflite "" , "" model initiation failed $ ex "" ) } ` ` ` ` ` ` private fun applymodel ( inputaudiodata : shortarray ) : shortarray { val inputval = floatarray ( inputaudiodata . size ) for ( i in inputaudiodata . indices ) { inputval [ i ] = inputaudiodata [ i ] . tofloat ( ) } val inputfloatarray = array ( <number> ) { inputval } val outputfloatarray = array ( <number> ) { floatarray ( inputaudiodata . size ) } log . d ( "" tflite "" , "" model input data : ${ inputfloatarray . tostring ( ) } "" ) tflite . ! <repeated> run ( inputfloatarray , outputfloatarray ) log . d ( "" tflite "" , "" model output data : ${ outputfloatarray . tostring ( ) } "" ) val outputaudiodata = shortarray ( inputfloatarray . size ) for ( i in outputfloatarray [ <number> ] . indices ) { outputaudiodata [ i ] = outputfloatarray [ <number> ] [ i ] . toint ( ) . toshort ( ) } log . d ( "" tflite "" , "" model returning data : ${ outputaudiodata . tostring ( ) } "" ) return outputaudiodata } ` ` ` [ <number> <sad> <url> ` ` ` # # # relevant log output ` ` ` shell but whenever the app is running its crashing with this error java . lang . illegalstateexception : internal error : unexpected failure when preparing tensor allocations input - > dims - > size ! = <number> ( <number> ! = <number> ) node number <number> ( conv_2d ) failed to prepare . at org . tensorflow . lite . nativeinterpreterwrapper . allocatetensors ( native method ) at org . tensorflow . lite . nativeinterpreterwrapper . allocatetensorsifneeded ( nativeinterpreterwrapper . java : <number> ) at org . tensorflow . lite . nativeinterpreterwrapper . run ( nativeinterpreterwrapper . java : <number> ) at org . tensorflow . lite . interpreterimpl . runformultipleinputsoutputs ( interpreterimpl . java : <number> ) at org . tensorflow . lite . interpreter . runformultipleinputsoutputs ( interpreter . java : <number> ) at org . tensorflow . lite . interpreterimpl . run ( interpreterimpl . java : <number> ) at org . tensorflow . lite . interpreter . run ( interpreter . java : <number> ) ` ` ` ` ` ` </details>",2
tensorflow/tensorflow,"runtimeerror : given shapes , [ <number> ] and [ <number> ] , are not broadcastable . node number <number> ( mul ) failed to prepare . # # # <number> . system information i am using google colab . gives the output linux a0c9eeb98a07 <date> + # <number> smp sat <date> <time> utc <number> x86_64 x86_64 x86_64 gnu / linux , when i run uname - a . tensorflow version : <number> . <number> # # # <number> . code reference [ tensorflow model colab ] ( <url> the basic conversion to tflite without any representative dataset works just fine . however , the problematic portions are cells <number> , and <number> , where i am trying to perform a tflite conversion with a representative dataset . # # # <number> . failure after conversion it throws the following error . ` ` ` warning : absl : found untraced functions such as _update_step_xla while saving ( showing <number> of <number> ) . these functions will not be directly callable after loading . info : tensorflow : assets written to : / tmp / tmpz4fb25rp / assets - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - runtimeerror traceback ( most recent call last ) [ < ipython - input - <number> - 3 bd48f77d98d > ] ( https :// localhost : <number> /# ) in < cell line : <number> > ( ) <number> converter . inference_output_type = tf . uint8 <number> - - - > <number> tflite_model_quant = converter . convert ( ) <number> <number> interpreter = tf . lite . interpreter ( model_content = tflite_model_quant ) <number> frames [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in convert ( self ) <number> invalid quantization parameters . <number> "" "" "" - > <number> return super ( tfliteconverterv2 , self ) . convert ( ) <number> <number> [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in wrapper ( self , * args , * * kwargs ) <number> def wrapper ( self , * args , * * kwargs ) : <number> # pylint : disable = protected - access - - > <number> return self . _convert_and_export_metrics ( convert_func , * args , * * kwargs ) <number> # pylint : enable = protected - access <number> [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in _convert_and_export_metrics ( self , convert_func , * args , * * kwargs ) <number> self . _save_conversion_params_metric ( ) <number> start_time = time . process_time ( ) - - > <number> result = convert_func ( self , * args , * * kwargs ) <number> elapsed_time_ms = ( time . process_time ( ) - start_time ) * <number> <number> if result : [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in convert ( self ) <number> "" "" "" <number> if self . experimental_lower_to_saved_model : - > <number> saved_model_convert_result = self . _convert_as_saved_model ( ) <number> if saved_model_convert_result : <number> return saved_model_convert_result [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in _convert_as_saved_model ( self ) <number> if self . saved_model_dir : <number> self . _validate_inputs ( graph_def , input_tensors ) - > <number> return self . _convert_from_saved_model ( graph_def ) <number> finally : <number> shutil . rmtree ( temp_dir , true ) [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in _convert_from_saved_model ( self , graph_def ) <number> <number> result = _convert_saved_model ( * * converter_kwargs ) - > <number> return self . _optimize_tflite_model ( <number> result , quant_mode , quant_io = self . experimental_new_quantizer ) <number> [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / convert_phase . py ] ( https :// localhost : <number> /# ) in wrapper ( * args , * * kwargs ) <number> except exception as error : <number> report_error_message ( str ( error ) ) - - > <number> raise error from none # re - throws the exception . <number> <number> return wrapper [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / convert_phase . py ] ( https :// localhost : <number> /# ) in wrapper ( * args , * * kwargs ) <number> def wrapper ( * args , * * kwargs ) : <number> try : - - > <number> return func ( * args , * * kwargs ) <number> except convertererror as converter_error : <number> if converter_error . errors : [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in _optimize_tflite_model ( self , model , quant_mode , quant_io ) <number> q_allow_float = quant_mode . is_allow_float ( ) <number> q_variable_quantization = quant_mode . enable_mlir_variable_quantization - - > <number> model = self . _quantize ( model , q_in_type , q_out_type , q_activations_type , <number> q_bias_type , q_allow_float , <number> q_variable_quantization ) [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / lite . py ] ( https :// localhost : <number> /# ) in _quantize ( self , result , input_type , output_type , activations_type , bias_type , allow_float , enable_variable_quantization ) <number> custom_op_registerers_by_func ) <number> if self . _experimental_calibrate_only or self . experimental_new_quantizer : - - > <number> calibrated = calibrate_quantize . calibrate ( <number> self . representative_dataset . input_gen ) <number> [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / convert_phase . py ] ( https :// localhost : <number> /# ) in wrapper ( * args , * * kwargs ) <number> except exception as error : <number> report_error_message ( str ( error ) ) - - > <number> raise error from none # re - throws the exception . <number> <number> return wrapper [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / convert_phase . py ] ( https :// localhost : <number> /# ) in wrapper ( * args , * * kwargs ) <number> def wrapper ( * args , * * kwargs ) : <number> try : - - > <number> return func ( * args , * * kwargs ) <number> except convertererror as converter_error : <number> if converter_error . errors : [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / optimize / calibrator . py ] ( https :// localhost : <number> /# ) in calibrate ( self , dataset_gen ) <number> dataset_gen : a generator that generates calibration samples . <number> "" "" "" - - > <number> self . _feed_tensors ( dataset_gen , resize_input = true ) <number> return self . _calibrator . calibrate ( ) [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / optimize / calibrator . py ] ( https :// localhost : <number> /# ) in _feed_tensors ( self , dataset_gen , resize_input ) <number> signature_key ) <number> else : - - > <number> self . _calibrator . prepare ( [ list ( s . shape ) for s in input_array ] ) <number> else : <number> if signature_key is not none : runtimeerror shapes , [ <number> ] and [ <number> ] , are not broadcastable . node number <number> ( mul ) failed to prepare . ` ` ` following is the netron image and the problematic node info . [ image ] ( <url> i do not suspect the issue to be with the broadcasting of scalar r in the multiplication with w1_1 , because the code [ here ] ( <url> works just fine . the only difference in this new code is that the __call__ implementation only takes r as the input argument and returns the product of r and w1_1 , which does not emit the error shown above , even though there is a broadcast .",2
tensorflow/tensorflow,"attributeerror : module ' tensorflow ' has no attribute ' __version__ ' <details> <summary> click to expand </summary> # # # issue type build / install # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution win10 # # # mobile device _no response_ # # # python version python3 . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory _no response_ # # # current behaviour ? a bug happened ! # # # standalone code to reproduce the issue ` ` ` shell code is too long ` ` ` # # # relevant log output ` ` ` shell ( reflow1 ) ps e :\\ googledownload \ \ rectifiedflow - main \ \ imagegeneration > python . / main . py - - config . / configs / rectified_flow / cifar10_rf_gaussian_ddpmpp . py - - eval_folder eval - - mode eval - - workdir . / logs / 1 _rectified_flow - - config . eval . enable_sampling - - config . eval . batch_size <number> - - config . eval . num_samples <number> - - config . eval . begin_ckpt <number> traceback ( most recent call last ) : file "" . / main . py "" , line <number> , in <module> import run_lib file "" e :\\ googledownload \ \ rectifiedflow - main \ \ imagegeneration \ \ run_lib . py "" , line <number> , in <module> import tensorflow_gan as tfgan file "" d :\\ conda \ \ envs \ \ reflow1 \ \ lib \ \ site - packages \ \ tensorflow_gan \ \ __init__ . py "" , line <number> , in <module> _ensure_tf_install ( ) file "" d :\\ conda \ \ envs \ \ reflow1 \ \ lib \ \ site - packages \ \ tensorflow_gan \ \ __init__ . py "" , line <number> , in _ensure_tf_install if ( distutils . version . looseversion ( tf . __version__ ) < attributeerror ' tensorflow ' has no attribute ' __version__ ' ` ` ` </details>",2
tensorflow/tensorflow,"protobuf have a problem <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version tf2 . <number> # # # custom code yes # # # os platform and distribution win10 # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory _no response_ # # # current behaviour ? i do not know if there is a problem with my download or the version of tensorflow , that is , how to recompile protobuf . can i download the tensorflow compressed package directly from github and uninstall tensorflow - intel without uninstalling the gpu version . # # # standalone code to reproduce the issue ` ` ` shell ps e :\\ googledownload \ \ rectifiedflow - main > & d <annoyed> conda / envs / reflow / python . exe e <annoyed> googledownload / rectifiedflow - main / imagegeneration / <number> . py traceback ( most recent call last ) : file "" e :\\ googledownload \ \ rectifiedflow - main \ \ imagegeneration \ \ <number> . py "" , line <number> , in <module> import tensorflow as tf file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ __init__ . py "" , line <number> , in <module> from tensorflow . python . tools import module_util as _module_util file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ __init__ . py "" , line <number> , in <module> from tensorflow . python . eager import context file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ eager \ \ context . py "" , line <number> , in <module> from tensorflow . core . framework import function_pb2 file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ core \ \ framework \ \ function_pb2 . py "" , line <number> , in <module> from tensorflow . core . framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2 file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ core \ \ framework \ \ attr_value_pb2 . py "" , line <number> , in <module> from tensorflow . core . framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2 file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ core \ \ framework \ \ tensor_pb2 . py "" , line <number> , in <module> from tensorflow . core . framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2 file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ core \ \ framework \ \ resource_handle_pb2 . py "" , line <number> , in <module> from tensorflow . core . framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2 file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ tensorflow \ \ core \ \ framework \ \ tensor_shape_pb2 . py "" , line <number> , in <module> _descriptor . fielddescriptor ( file "" d :\\ conda \ \ envs \ \ reflow \ \ lib \ \ site - packages \ \ google \ \ protobuf \ \ descriptor . py "" , line <number> , in __new__ _message . message . _checkcalledfromgeneratedfile ( ) typeerror : descriptors cannot not be created directly . if this call came from a _pb2 . py file , your generated code is out of date and must be regenerated with protoc >= <number> . <number> . if you cannot immediately regenerate your protos , some other possible workarounds are : <number> . downgrade the protobuf package to <number> . x or lower . <number> . set protocol_buffers_python_implementation = python ( but this will use pure - python parsing and will be much slower ) . more information ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"api for model parallelism <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell by using tf . distribute , only the data parallel is documented in the website . <url> now , what are the apis that can be used for model parallelism ? in huggingface , it is documented that , there are many types of parallelism . read here <url> what the solutions tensorflow provides for large language model training / inference for consumer level gpu . gpu that has 1 6 gb , 2 4 gb v - ram . is it possible to do [ tensor - parallel ] ( <url> in tensorflow . how model parallism can be applied with apis in tensorflow and keras ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell mirrored_strategy = tf . distribute . mirroredstrategy ( ) cluster_resolver = tf . distribute . cluster_resolver . tpuclusterresolver ( ) ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"writing custom reduceop i would like take a mirroredvariable , shape =( <number> ) , with <number> replica and reduce is first as a difference of pairs and than l2 norm it . is there a way of writing such a custom reduceop ? <url>",2
tensorflow/tensorflow,"tf2 keras model . fit ( ) vs model . evaluate print different loss and auc <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell my model generate <number> binary outputs with mmoe module , and i define a custom metric to combine these three auc in callbacks . as i am using model . fit to train my dataset , it prints the final training auc in the last epoch is <number> . while i am using model . evaluate ( ) on the same training dataset , it turns out the auc is only <number> . can anyone can help me with it ? btw , i do not use batchnormalization and dropout layers , and also the batch_size is the same for both fitting and evaluation process . i used exactly same dataset and same batch_size , i really don ’ t know why it occurs ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell class mergemetrics ( tf . keras . callbacks . callback ) : def __init__ ( self , * * kargs ) : super ( mergemetrics , self ) . __init__ ( * * kargs ) def on_epoch_begin ( self , epoch , logs ={}) : return def on_epoch_end ( self , epoch , logs ={}) : logs [ ' merge_auc ' ] = <number> * logs [ "" output_1_auc "" ] + <number> * logs [ "" output_2_auc "" ] + <number> * logs [ "" output_3_auc "" ] model = modelname ( some_parameters ) model . compile ( optimizer = tf . keras . optimizers . adam ( learning_rate , beta_1 , beta_2 ) , loss ={ "" output_1_auc "" : ‘ binary_crossentropy ’ "" output_2_auc "" : ‘ binary_crossentropy ’ "" output_3_auc "" : ‘ binary_crossentropy ’ } , loss_weights =[ <number> , <number> ] , metrics ={ "" output_1_auc "" : [ tf . keras . metrics . auc ( name = ' auc ' ) ] , "" output_2_auc "" : [ tf . keras . metrics . auc ( name = ' auc ' ) ] , "" output_3_auc "" : [ tf . keras . metrics . auc ( name = ' auc ' ) ] } ) checkpoint = mergemetrics ( ) checkpoint_filepath = os . path . join ( path , ' model ' ) model_check = tf . keras . callbacks . modelcheckpoint ( filepath = checkpoint_filepath , # filepath = path , monitor = "" merge_auc "" , save_best_only = true , mode = ' max ' , save_weights_only = true , save_freq = "" epoch "" ) train_dataset = tf . data . dataset . from_tensor_slices ( ( train_data , ( y_train . output_1 , y_train . output_2 , y_train . output_3 ) ) ) . shuffle ( <number> * batch_size ) . batch ( batch_size ) model . fit ( train_dataset , epochs = <number> , callbacks =[ checkpoint , model_check ] ) model . load_weights ( checkpoint_filepath ) # # load weights of the best epoch auc = model . evaluate ( train_data , [ y_train . output_1 , y_train . output_2 , y_train . output_3 ] , batch_size = batch_size ) ` ` ` # # # relevant log output ` ` ` shell result : fit process : output_1_auc : <number> , output_2_auc : <number> , output_3_auc : <number> , merge_auc : <number> evaluation process : output_1_auc : <number> , output_2_auc : <number> , output_3_auc ` ` ` </details>",2
tensorflow/tensorflow,are there plans to release tf <number> . <number> to address cves ? <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution rhel <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell we are using tf <number> . <number> in our product images . our latest twistlock scans reveal several security findings . are there plans to release a <number> . <number> that addresses these cves ? findings are cve | url | | - - - | - - - | | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> | cve - <number> - <number> | <url> ` ` ` # # # standalone code to reproduce the issue ` ` ` shell n / a ` ` ` # # # relevant log output _no response_ </details>,2
tensorflow/tensorflow,"how to solve the backpropagation problem of tf . signal . rfft ? <details> <summary> click to expand </summary> # # # issue type feature request # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i x wanted to implement the hilbert transform in the model built by tensorflowd , but i found no callable api . so i implemented it myself using tf . signal . rfft and tf . signal . ifft . however , when i was training , i found the following error reported : lookuperror : gradient registry has no entry for : rfft3d i think it may be that tensorflow has not defined the corresponding backpropagation method for rfft3d yet . i want to provide my code train . py & model . py ` ` ` # # # standalone code to reproduce the issue ` ` ` def hilbert_transform ( x , n = none , axis = - <number> <sad> if x . dtype = = tf . complex64 or x . dtype = = tf . complex128 : raise valueerror ( "" x must be real . "" ) if n is none : n = x . shape [ axis ] if n <= <number> : raise valueerror ( "" n must be positive . "" ) x_br = tf . signal . rfft3d ( x [ :, :, : <number> ] ) x_bi = tf . signal . rfft3d ( x [ :, :, <number> :]) x_complex = concatenate ( [x _br , x_bi ] , axis = - <number> ) h = np . zeros ( n ) if n % <number> = = <number> : h [ <number> ] = h [ n / / <number> ] = <number> h [ <number> : n / / <number> ] = <number> else : h [ <number> ] = <number> h [ <number> <sad> n + <number> ) / / <number> ] = <number> if x . shape . ndims > <number> = [ tf . newaxis ] * x . shape . ndims ind [ axis ] = slice ( none ) h = h [ tuple ( ind ) ] x_complex_h = x_complex * h x_bj = tf . signal . ifft3d ( x_complex_h [ :, :, : <number> ] ) x_bk = tf . signal . ifft3d ( x_complex_h [ :, :, <number> :]) x_hilbert = concatenate ( [ tf . math . imag ( x_bj ) , tf . math . imag ( x_bk ) ] , axis = - <number> ) return x_hilbert ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"correct way to implement rnn if looping over tensor is yet not allowed <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version <number> # # # custom code no # # # os platform and distribution maxos <number> . <number> # # # mobile device - # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory m1 max <number> cores gpu <number> gb ram # # # current behaviour ? ` ` ` shell it throws : iterating over a symbolic ` tf . tensor ` is not allowed : autograph did convert this function . this might indicate you are trying to use an unsupported feature . yet the code in my opinion can be easily converted to a graph , just conditioned on the ` tf . shape ( inputs ) [ <number> ] ` . <repeated> this would allow building rnns that accepts long and short inputs , without having to pad it , which is extremely useful if the length of the strings in the dataset is very skewed , and we have many short phrases and few long ones ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf class mymodel1 ( tf . keras . model ) : def __init__ ( self , input_text_processor , * args , * * kwargs ) : super ( ) . __init__ ( * args , * * kwargs ) self . input_text_processor = input_text_processor def call ( self , data , training = true , max_len = <number> <sad> inputs = self . input_text_processor ( data ) for _ in tf . range ( tf . shape ( inputs ) [ <number> ]): pass return [ ] def train_step ( self , data ) : self . call ( data ) return { "" loss "" : <number> } dataset = [ "" hi "" , "" what ' s up "" , "" what ' s the weather "" ] input_text_processor = tf . keras . layers . textvectorization ( ) input_text_processor . adapt ( dataset ) with tf . device ( "" / cpu : <number> "" <sad> model = mymodel1 ( input_text_processor ) model . compile ( tf . optimizers . adam ( ) , loss = tf . keras . losses . sparsecategoricalcrossentropy ( ) ) hist = model . fit ( dataset , epochs = <number> ) ` ` ` # # # relevant log output ` ` ` shell epoch <number> / <number> traceback ( most recent call last ) : file "" / users / username / ml / tensorflow - journey / <number> - rnn - enc - dec - attention / rnn - enc - dec - attention . py "" , line <number> , in <module> hist = model . fit ( dataset , epochs = <number> ) file "" / opt / homebrew / caskroom / miniforge / base / envs / ml - apple - metal - <number> - <number> / lib / python3 . <number> / site - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" / opt / homebrew / caskroom / miniforge / base / envs / ml - apple - metal - <number> - <number> / lib / python3 . <number> / site - packages / tensorflow / python / framework / func_graph . py "" , line <number> , in autograph_handler raise e . ag_error_metadata . to_exception ( e ) tensorflow . python . framework . errors_impl . operatornotallowedingrapherror : in user code : file "" / opt / homebrew / caskroom / miniforge / base / envs / ml - apple - metal - <number> - <number> / lib / python3 . <number> / site - packages / keras / engine / training . py "" , line <number> , in train_function * return step_function ( self , iterator ) file "" / opt / homebrew / caskroom / miniforge / base / envs / ml - apple - metal - <number> - <number> / lib / python3 . <number> / site - packages / keras / engine / training . py "" , line <number> , in step_function * * outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / opt / homebrew / caskroom / miniforge / base / envs / ml - apple - metal - <number> - <number> / lib / python3 . <number> / site - packages / keras / engine / training . py "" , line <number> , in run_step * * outputs = model . train_step ( data ) file "" / users / username / ml / tensorflow - journey / <number> - rnn - enc - dec - attention / rnn - enc - dec - attention . py "" , line <number> , in train_step self . call ( data ) file "" / users / username / ml / tensorflow - journey / <number> - rnn - enc - dec - attention / rnn - enc - dec - attention . py "" , line <number> , in call for _ in tf . range ( tf . shape ( inputs ) [ <number> ]): operatornotallowedingrapherror : iterating over a symbolic ` tf . tensor ` is not allowed did convert this function . this might indicate you are trying to use an unsupported feature . ` ` ` </details>",2
tensorflow/tensorflow,"cannot install tensorflow modules use pip please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : no - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : darwin - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : n / a - * * tensorflow installed from ( source or binary ) * * : ` pip3 install tf - nightly ` - * * tensorflow version ( use command below ) * * : ` <number> . <number> . dev20230325 ` - * * python version * * : ` python <number> . <number> ` - * * bazel version ( if compiling from source ) * * : no bazel installed - * * gcc / compiler version ( if compiling from source ) * * : not compiling from source ` ` ` bash $ clang - - version apple clang version <number> . <number> ( clang - <number> . <number> . <number> ) target : arm64 - apple - darwin21 . <number> thread model : posix installeddir : / library / developer / commandlinetools / usr / bin ` ` ` - * * cuda / cudnn version * * : - * * gpu model and memory * * : 1 6 gb memory . mac m1 built in gpu ? - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> p . s: i do not think this script work , because it gave me my python2 version , not python3 you can obtain the tensorflow version with : ` ` ` bash $ python3 - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" v1 . <number> - <number> - g1057ad694db <number> . <number> - dev20230325 ` ` ` # # # describe the problem i am following this document : < <url> so when i try to install tensorflow , it gave me mo matching distribution found errors . # # # source code / logs ` ` ` bash $ pip3 install tensorflow error : could not find a version that satisfies the requirement tensorflow ( from versions : none ) error : no matching distribution found for tensorflow ` ` ` ` ` ` bash $ pip3 install - q - u "" tensorflow - text = = <number> . * "" error : could not find a version that satisfies the requirement tensorflow - text = = <number> . * ( from versions : none ) error : no matching distribution found for tensorflow - text = = <number> . * $ pip3 install - q tf - models - official = = <number> . <number> error : could not find a version that satisfies the requirement opencv - python - headless = = <number> . <number> ( from tf - models - official ) ( from versions : <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> ) error matching distribution found for opencv - python - headless = = <number> . <number> ` ` `",2
tensorflow/tensorflow,"how can i achive the hilbert transform by using tensorflow ? <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell when i discovered that tensorflow did not have a built - in api for implementing the hilbert transform , i tried to pass the tensor to the scipy . signal . hilbert method in numpy , but keras does not allow the tensor to be processed directly using numpy maths methods , so i used the following method for data [ tensor / kerastensor ( <number> , <number> ) ] to convert : <number> . data_np = data . numpy ( ) <number> . data_np = keras . backend . get_val ( data ) neither works . i then decided to build my own hilbert_transform function by referring to the scipy . signal . hilbert method in numpy , at which point another problem arose : the tf . signal . fft method is inconsistent with the scipy . fft method . scipy . fft can take an axis argument , but tf . signal . fftz cannot . therefore , i would like your help in answering : <number> . how do i implement the hilbert transform on data [ tensor / kerastensor ( <number> , <number> ) ] ? or <number> . how do i convert data [ tensor / kerastensor ( <number> , <number> ) ] into a numpys array ? translated with <url> ( free version ) ` ` ` # # # standalone code to reproduce the issue ` ` ` shell from scipy . signal import hilbert import tensorflow as tf import numpy as np def is_complex ( x ) : return x . dtype = = tf . complex64 or x . dtype = = tf . complex128 def highpass_filter ( x , n = none , axis = - <number> <sad> x = tf . convert_to_tensor ( x ) if is_complex ( x ) : raise valueerror ( "" x must be real . "" ) if n is none : n = x . shape [ axis ] if n <= <number> : raise valueerror ( "" n must be positive . "" ) xf = fft ( x , n , axis = axis ) h = tf . zeros ( n ) if n % <number> = = <number> : h = tf . tensor_scatter_nd_update ( h , [ [ <number> ] , [ n / / <number> ] ] , [ <number> , <number> ] ) h = tf . tensor_scatter_nd_update ( h , tf . range ( <number> , n / / <number> ) , tf . ones ( n / / <number> - <number> ) * <number> ) else : h = tf . tensor_scatter_nd_update ( h , [ <number> ] , [ <number> ] ) h = tf . tensor_scatter_nd_update ( h , tf . range ( <number> , ( n + <number> ) / / <number> ) , tf . ones ( ( n + <number> ) / / <number> - <number> ) * <number> ) if x . ndim > <number> = [ tf . newaxis ] * x . ndim ind [ axis ] = slice ( none ) h = h [ tuple ( ind ) ] x = tensorflow . signal . ifft ( xf * h , axis = axis ) return x x = np . random . rand ( <number> , <number> , <number> ) x_h = highpass_filter ( x , axis = <number> ) ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"[ jax ] the use of jax . array . at fails experimental_from_jax # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> darwin kernel version <number> . <number> - tensorflow installation ( pip package or built from source ) : pip - tensorflow library ( version , if pip package or github sha , if built from source ) : <number> . <number> # # # <number> . code # # # # option a : reference colab notebooks <number> ) reference [ tensorflow model colab ] ( <url> demonstrate how to build your tf model . <number> ) reference [ tensorflow lite model colab ] ( <url> demonstrate how to convert your tf model to a tf lite model ( with quantization , if used ) and run tflite inference ( if possible ) . ` ` ` ( you can paste links or attach files by dragging & dropping them below ) - provide links to your updated versions of the above two colab notebooks . - provide links to your tensorflow model and ( optionally ) tensorflow lite model . ` ` ` # # # # option b : paste your code here or provide a link to a custom end - to - end colab ` ` ` import tensorflow as tf import jax import jax . numpy as jnp import jax . tree_util as tree def main3 ( <sad> print ( f ' jax { jax . __version__ } ' ) print ( f ' tf { tf . __version__ } ' ) <user> . jit def _update ( x ) : return x . at [ <number> ] . set ( <number> ) converter = tf . lite . tfliteconverter . experimental_from_jax ( [ _update ] , [[('x ' , jnp . ones ( <number> ) ) ] ] ) converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins , # enable tensorflow lite ops . tf . lite . opsset . select_tf_ops # enable tensorflow ops . ] tflite_update = converter . convert ( ) with open ( ' update . tflite ' , ' wb ' ) as f : f . write ( tflite_update ) interpreter = tf . lite . interpreter ( model_content = tflite_update ) interpreter . allocate_tensors ( ) input_details = interpreter . get_input_details ( ) output_details = interpreter . get_output_details ( ) args = jnp . ones ( <number> ) expected = _update ( args ) # for a , d in zip ( args , input_details ) : interpreter . set_tensor ( input_details [ <number> ] [ ' index ' ] , args ) interpreter . invoke ( ) return ` ` ` full [ example ] ( <url> # # # <number> . failure after conversion if the conversion is successful , but the generated model is wrong , then state what is wrong : - conversion works - interpreter fails at invoke # # # <number> . ( optional ) rnn conversion support if converting tf rnn to tflite fused rnn ops , please prefix [ rnn ] in the title . # # # <number> . ( optional ) any other info / logs include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached . ` ` ` traceback ( most recent call last ) : file "" / users / krzysiek / library / application support / jetbrains / toolbox / apps / pycharm - p / ch - <number> / <number> . <number> / pycharm . app / contents / plugins / python / helpers / pydev / pydevd . py "" , line <number> , in _exec pydev_imports . execfile ( file , globals , locals ) # execute the script file "" / users / krzysiek / library / application support / jetbrains / toolbox / apps / pycharm - p / ch - <number> / <number> . <number> / pycharm . app / contents / plugins / python / helpers / pydev / _pydev_imps / _pydev_execfile . py "" , line <number> , in execfile exec ( compile ( contents + "" \ \ n "" , file , ' exec ' ) , glob , loc ) file "" / users / krzysiek / documents / ml4wifi / reinforced - lib / examples / lite / lite . py "" , line <number> , in <module> main3 ( ) file "" / users / krzysiek / documents / ml4wifi / reinforced - lib / examples / lite / lite . py "" , line <number> , in main3 interpreter . invoke ( ) file "" / users / krzysiek / documents / ml4wifi / ftmrate_internal / venv / lib / python3 . <number> / site - packages / tensorflow / lite / python / interpreter . py "" , line <number> , in invoke self . _interpreter . invoke ( ) runtimeerror shape must have rank at least one . found :[] node number <number> ( tfliteflexdelegate ) failed to invoke . ` ` `",2
tensorflow/tensorflow,"how to save average weights of checkpoints using tensorflow <number> . x ? help needed ! <repeated> hi , everyone . i found a scrit to load serials of checkpoints for a model and save average weights of them in tensorflow1 . <url> which is very useful to improve the performance of the model . but in tensorflow2 ， the saved checkpoints like this : ! [ image ] ( <url> how to average the weights of parameters for them ? i tried to write a script but the output checkpoint seems not as we expected , anyone can give some helps ? thanks a lot in advance . here is my script : ` import os import numpy as np import tensorflow as tf from absl import app from absl import flags from absl import logging flags = flags . flags flags . define_string ( "" checkpoints "" , "" "" , "" comma - separated list of checkpoints to average . "" ) flags . define_integer ( "" num_last_chekpoints "" , <number> , "" average the last n saved checkpoints . "" "" if the checkpoints flag is set , this is ignored . "" ) flags . define_string ( "" prefix "" , "" "" , "" prefix ( e . g . , directory ) to append to each checkpoint . "" ) flags . define_string ( "" output_path "" , "" / tmp / averaged . ckpt "" , "" path to output the averaged checkpoint to . "" ) def checkpoint_exists ( path ) : return ( tf . io . gfile . exists ( path ) or tf . io . gfile . exists ( path + "" . index "" ) ) def main ( argv ) : if flags . checkpoints : # get the checkpoints list from flags and run some basic checks . checkpoints = [ c . strip ( ) for c in flags . checkpoints . split ( "" , "" ) ] checkpoints = [ c for c in checkpoints if c ] if not checkpoints : raise valueerror ( "" no checkpoints provided for averaging . "" ) if flags . prefix : checkpoints = [ flags . prefix + c for c in checkpoints ] else : assert flags . num_last_chekpoints >= <number> , "" must average at least one model "" assert flags . prefix , ( "" prefix must be provided when averaging last "" "" n checkpoints "" ) # checkpoint_state = tf . train . get_checkpoint_state ( # os . path . dirname ( flags . prefix ) ) # # checkpoints are ordered from oldest to newest . # checkpoints = checkpoint_state . all_model_checkpoint_paths [ # - flags . num_last_checkpoints <happy> file_list = os . listdir ( flags . prefix ) checkpoints = [ os . path . join ( flags . prefix , file ) for file in file_list if file . endswith ( "" . index "" ) ] checkpoints = [ checkpoint [ : - <number> ] for checkpoint in checkpoints ] checkpoints . sort ( key = lambda checkpoint : int ( checkpoint . split ( ' - ' ) [ - <number> ] ) ) checkpoints = checkpoints [ - flags . num_last_checkpoints <happy> checkpoints = [ c for c in checkpoints if checkpoint_exists ( c ) ] if not checkpoints : if flags . checkpoints : raise valueerror ( "" none of the provided checkpoints exist . %s "" % flags . checkpoints ) else : raise valueerror ( "" could not find checkpoints at %s "" % os . path . dirname ( flags . prefix ) ) # read variables from all checkpoints and average them . logging . info ( "" reading variables and averaging checkpoints :"") for c in checkpoints : logging . info ( "" %s "" , c ) var_list = tf . train . list_variables ( checkpoints [ <number> ] ) var_values , var_dtypes = { } , { } for ( name , shape ) in var_list : if not name . startswith ( "" save_counter "" <sad> var_values [ name ] = np . zeros ( shape ) for checkpoint in checkpoints : reader = tf . train . load_checkpoint ( checkpoint ) for name in var_values : tensor = reader . get_tensor ( name ) dtype = reader . get_variable_to_dtype_map ( ) [ name ] if dtype = = tf . string : var_values [ name ] = tensor else : var_values [ name ] + = tensor var_dtypes [ name ] = dtype logging . info ( "" read from checkpoint %s "" , checkpoint ) for name in var_values : # average . if var_dtypes [ name ] ! = tf . string : var_values [ name ] /= len ( checkpoints ) name = var_list [ - <number> ] [ <number> ] assert name . startswith ( "" save_counter "" ) shape = reader . get_variable_to_shape_map ( ) [ name ] dtype = reader . get_variable_to_dtype_map ( ) [ name ] var_values [ name ] = np . zeros ( shape ) var_dtypes [ name ] = dtype for name in var_values . keys ( <sad> var_values [ name ] = tf . variable ( var_values [ name ] , dtype = var_dtypes [ name ] ) save = tf . train . checkpoint ( ) save . mapped = var_values # save . listed = [ ] # save . mapped = { } # for name in var_values . keys ( <sad> # save . listed . append ( var_values [ name ] ) # save . mapped [ name ] = var_values [ name ] save_path = save . save ( flags . output_path ) logging . info ( "" averaged checkpoints saved in %s "" , flags . output_path ) if __name__ = = ' __main__ ' `",2
tensorflow/tensorflow,"about android calling tensorflow lite crash problem # # # <number> . problem overview i recently reported an error when importing the tensorflow lite model using android studio , but i did not find the problem after searching . i hope you can help me . the following is the detailed information # # # <number> . system information - implementation ' org . tensorflow : tensorflow - lite : <number> . <number> ' - implementation ' org . tensorflow : tensorflow - lite - select - tf - ops : <number> . <number> - nightly ' - implementation ' org . tensorflow : tensorflow - lite - support : <number> . <number> ' - implementation ' org . tensorflow : tensorflow - lite - metadata : <number> . <number> ' - android <number> x86_64 # # # <number> . code public mymodelrunner ( context context ) throws ioexception { try { interpreter = new interpreter ( loadmodelfile ( context ) ); } catch ( ioexception e ) { e . printstacktrace ( ); } } private mappedbytebuffer loadmodelfile ( context context ) throws ioexception { assetfiledescriptor filedescriptor = context . getassets ( ) . openfd ( "" new_model . tflite "" ); fileinputstream inputstream = new fileinputstream ( filedescriptor . getfiledescriptor ( )); filechannel filechannel = inputstream . getchannel ( ); long startoffset = filedescriptor . getstartoffset ( ); long declaredlength = filedescriptor . getdeclaredlength ( ); return filechannel . map ( filechannel . mapmode . read_only , startoffset , declaredlength ) ; } # # # <number> . ( optional ) info / logs <number> - <number> - <number> <time> . <number> <number> - <number> libc com . example . myproject01 a fatal signal <number> ( sigsegv ) , code <number> ( segv_maperr ) , fault addr 0 xfffffff4 in tid <number> ( ple . myproject01 ) , pid <number> ( ple . myproject01 ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a pid : <number> , tid : <number> , name > > > com . example . myproject01 < < < <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc <number> / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ lib / x86 / libtensorflowlite_flex_jni . so <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 2 0 2 4 2 b8 / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ lib / x86 / libtensorflowlite_flex_jni . so <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 2 0 2 3 ec2 / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ lib / x86 / libtensorflowlite_flex_jni . so <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 2 0 2 4 5 6 b / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ lib / x86 / libtensorflowlite_flex_jni . so <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 1 e6f187 / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ lib / x86 / libtensorflowlite_flex_jni . so <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 7 cb45 / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ lib / x86 / libtensorflowlite_flex_jni . so <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e6bdc [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . flex . flexdelegate . <clinit> + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e47ae [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . nativeinterpreterwrapper . maybecreateflexdelegate + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e4be4 [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . nativeinterpreterwrapper . addelegates <elongated> + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e4e68 [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . nativeinterpreterwrapper . init + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e4baa [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . nativeinterpreterwrapper . <init> + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e44d0 [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . nativeinterpreterwrapperexperimental . <init> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e4304 [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . interpreter . <init> + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 2 e42e6 [ anon : dalvik - classes . dex extracted in memory from / data / app / ~ ~ 8 c21wzjftifem <time> qfgjow ==/ com . example . myproject01 - zu0b6g7gifcmfzkzpmhgpg ==/ base . apk ] ( org . tensorflow . lite . interpreter . <init> + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 0 0 0 f66 / data / data / com . example . myproject01 / code_cache / . overlay / base . apk / classes3 . dex ( com . example . myproject01 . mymodelrunner . <init> + <number> ) <number> - <number> - <number> <time> . <number> <number> - <number> debug pid - <number> a # <number> pc 0 0 0 0 0 fc8 / data / data / com . example . myproject01 / code_cache / . overlay / base . apk / classes3 . dex ( com . example . myproject01 . recommend_fragment <money> . onclick + <number> ) - - - - - - - - - - - - - - - - - - - - - - - - - - - - process ended ( <number> ) for package com . example . myproject01 - - - - - - - - - - - - - - - - - - - - - - - - - - - - <number> - <number> - <number> <time> . <number> <number> - <number> inputdispatcher system_process e channel ' c1e13a6 com . example . myproject01 / com . example . myproject01 . mainactivity ( server ) ' ~ channel is unrecoverably broken and will be disposed",2
tensorflow/tensorflow,"saving custom model not working <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution colab notebook # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i am trying to save a custom model where the number of channels increases as we progress along the forward pass of the architecture . the forward pass of the model works as expected , and i can train it . however , when trying to save the model , i get an error concerning the number of channels passed to certain convolutional layers . is there a way around this issue ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <url> ` ` ` # # # relevant log output ` ` ` shell - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - valueerror traceback ( most recent call last ) < ipython - input - <number> - 6 9 6 ba1b852d4 > in <module> - - - - > <number> wnet . save ( "" / content / wnet "" ) <number> frames / tmp / __autograph_generated_filelz68b5h5 . py in tf__call ( self , x) <number> do_return = false <number> retval_ = ag__ . undefinedreturnvalue ( ) - - - > <number> x = ag__ . converted_call ( ag__ . ld ( self ) . conv , ( ag__ . ld ( x ) , ) , none , fscope ) <number> x = ag__ . converted_call ( ag__ . ld ( self ) . norm , ( ag__ . ld ( x ) , ) , none , fscope ) <number> x = ag__ . converted_call ( ag__ . ld ( self ) . activation , ( ag__ . ld ( x ) , ) , none , fscope ) valueerror : exception encountered when calling layer ' base_model ' ( type basemodel ) . in user code : file "" < ipython - input - <number> - 3 5 5 bdcd220c4 > "" , line <number> , in call * x = decoder_block ( [ * previous_skips [ str ( self . global_depth - <number> - i ) ] , file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler * * raise e . with_traceback ( filtered_tb ) from none file "" / tmp / __autograph_generated_file30lnbd33 . py "" , line <number> , in tf__call x = ag__ . converted_call ( ag__ . ld ( self ) . block , ( ag__ . ld ( x ) , ) , none , fscope ) file "" / tmp / __autograph_generated_filejlndlto_ . py "" , line <number> , in tf__call x = ag__ . converted_call ( ag__ . ld ( self ) . conv1 , ( ag__ . ld ( x ) , ) , none , fscope ) file "" / tmp / __autograph_generated_filelz68b5h5 . py "" , line <number> , in tf__call x = ag__ . converted_call ( ag__ . ld ( self ) . conv , ( ag__ . ld ( x ) , ) , none , fscope ) valueerror : exception encountered when calling layer ' decoder_block_1 ' ( type decoderblock ) . in user code : file "" < ipython - input - <number> - 3 5 5 bdcd220c4 > "" , line <number> , in call * x = self . block ( x ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler * * raise e . with_traceback ( filtered_tb ) from none file "" / tmp / __autograph_generated_filejlndlto_ . py "" , line <number> , in tf__call x = ag__ . converted_call ( ag__ . ld ( self ) . conv1 , ( ag__ . ld ( x ) , ) , none , fscope ) file "" / tmp / __autograph_generated_filelz68b5h5 . py "" , line <number> , in tf__call x = ag__ . converted_call ( ag__ . ld ( self ) . conv , ( ag__ . ld ( x ) , ) , none , fscope ) valueerror : exception encountered when calling layer ' u_net_block_7 ' ( type unetblock ) . in user code : file "" < ipython - input - <number> - 7 6 9 9 1 f1be87b > "" , line <number> , in call * x = self . conv1 ( x ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler * * raise e . with_traceback ( filtered_tb ) from none file "" / tmp / __autograph_generated_filelz68b5h5 . py "" , line <number> , in tf__call x = ag__ . converted_call ( ag__ . ld ( self ) . conv , ( ag__ . ld ( x ) , ) , none , fscope ) valueerror : exception encountered when calling layer ' conv_layer_14 ' ( type convlayer ) . in user code : file "" < ipython - input - <number> - 3 5 5 bdcd220c4 > "" , line <number> , in call * x = self . conv ( x ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler * * raise e . with_traceback ( filtered_tb ) from none file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / input_spec . py "" , line <number> , in assert_input_compatibility raise valueerror ( valueerror : input <number> of layer "" conv3d_14 "" is incompatible with the layer : expected axis - <number> of input shape to have value <number> , but received input with shape ( none , <number> , <number> , <number> , <number> ) call arguments received by layer ' conv_layer_14 ' ( type convlayer ) : • x = tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) call arguments received by layer ' u_net_block_7 ' ( type unetblock ) : • x = tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) call arguments received by layer ' decoder_block_1 ' ( type decoderblock ) : • skip =[ ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' , ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' , ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' ] • x = tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) call arguments received by layer ' base_model ' ( type basemodel ) : • x = tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) • previous_skips ={ ' <number> ' : listwrapper ( [ ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' ] ) , ' <number> ' : listwrapper ( [ ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' ] ) , ' <number> ' : listwrapper ( [ ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' , ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' ] ) } • previous_peaks ={ ' <number> ' : listwrapper ( [ ] ) , ' <number> ' : listwrapper ( [ ' tf . tensor ( shape =( none , <number> , <number> , <number> , <number> ) , dtype = float32 ) ' ] ) , ' <number> ' <number> , <number> , <number> , <number> ) , dtype = float32 ) ' ] ) } ` ` ` </details>",2
tensorflow/tensorflow,"using teachable machine to make a audio model for python i have been trying to make an ai model that will listen to user input . depending on the user ' s input / command the program will carry out functions etc . i am trying to use a model i have trained from the teachable machine , but the model is not in a format that can be used in python . from what i have seen python requires a . h5 . however , tflite . js is only available to export / download in . when i try to use this in my program i get hit with errors . what steps can i take to import an audio model for a python system ?",2
tensorflow/tensorflow,"example android app show "" gpu is not supportted "" . <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version tf . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell here are some details that will aid in this troubleshooting session : using the tensorflow lite sample android app ( <url> but as the attached gpunotsupport . png shown , currently on the <number> , when selecting gpu or nnapi delegates the sample app shows "" gpu is not supported "" look into the sample android app code . <number> . as gpu . png shown , "" gpu is not supported "" occurred . <number> . as the attached code1 . png shown , the order call relationship . the following code is very important : public compatibilitylist ( ) { this . compatibilitylisthandle = createcompatibilitylist ( ); } private static native long createcompatibilitylist ( ); guss that createcompatibilitylist ( ) make problem . look into tensorflow code check createcompatibilitylist : <number> . in tensorflow / lite / delegates / gpu / java / src / main / native / compatibility_list_jni . cc + <number> as the tensorflow . png shown , <number> / / errors in readinfo should almost always be failures to construct the opengl <number> / / environment . treating that as "" gpu unsupported "" is reasonable , and we can <number> / / swallow the error <number> jniexport jboolean jnicall <number> java_org_tensorflow_lite_gpu_compatibilitylist_nativeisdelegatesupportedonthisdevice ( <number> jnienv * env , jclass clazz , jlong compatibility_list_handle ) { <number> if ( ! tflite : : jni : : checkjniinitializedorthrow ( env ) ) return jni_false ; <number> <number> compatibilitylisthelper * compatibility_list = <number> reinterpret_cast < compatibilitylisthelper *>( compatibility_list_handle ) ; <number> return compatibility_list - > isdelegatesupportedonthisdevice ( ) ? jni_true <number> <number> } thanks you very much . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell using the tensorflow lite sample android app ( <url> but as the attached gpunotsupport . png shown , currently on the <number> , when selecting gpu or nnapi delegates the sample app shows "" gpu is not supported "" ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"getting error when calculating entropy for each images in the batch in the input tensor in a custom layer in tensorflow / keras . i am working on a problem in which i have to create a custom layer in keras , which takes , output of a conv layer of a pre - trained model as an input . this custom layer work is to select k best feature maps based on shannon entropy for each images in that input tensor and then outputs the final tensor with k feature maps or each images . so that this output tensor is passed to other conv layer in the model . let input tensor from a conv layer has shape = ( none , <number> , <number> ) and i want to take <number> best feature maps out of <number> based on shannon entropy . so the output tensor shape should be = ( none , <number> , <number> ) . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - system informations : python version = ' <date> ' tensorflow version = ` ' <number> . <number> ' ` platform = windows <number> running on cpu - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - below is the code snippet : ` class select_k_fmap ( tf . keras . layers . layer ) : def __init__ ( self ) : super ( select_k_fmap , self ) . __init__ ( ) def build ( self , input_shape ) : pass def call ( self , inputs ) : "" "" "" tensor shape = ( batch_size , img_height , img_width , no . of filters ) "" "" "" shape = tf . shape ( inputs ) batch_size = shape [ <number> ] print ( ' batch size * * * * ' , batch_size ) num_filters = shape [ - <number> ] img_height = shape [ <number> ] img_width = shape [ <number> ] k = <number> # no . of best feature maps to select def k_best_fmap ( image ) : "" "" "" returns k best feature maps of an image having n feature maps "" "" "" def shannon_entropy ( feature_map ) : "" "" "" returns entropy of a image in a input batch "" "" "" value_ranges = [ <number> , <number> ] nbins = <number> histogram_bin_indexes = tf . histogram_fixed_width_bins ( image , value_ranges , nbins ) _ , _ , count = tf . unique_with_counts ( histogram_bin_indexes ) prob = count / tf . reduce_sum ( count ) prob = tf . cast ( prob , tf . float32 ) entropy = ( - tf . reduce_sum ( prob * tf . math . log ( prob ) ) ) / ( tf . math . log ( <number> ) ) return entropy final_image = tf . zeros_like ( image ) <hashtag> shape </hashtag> = ( img_height , img_width , no . of filters ) entropy = [ ] num_featuremaps = tf . shape ( image ) [ - <number> ] for j in range ( int ( num_featuremaps ) <sad> image_ith_filter = image [ :, :, j ] image_ith_filter_entropy = shannon_entropy ( image_ith_filter ) entropy . append ( tf . get_static_value ( image_ith_filter_entropy ) . item ( ) ) entropy_array = tf . argsort ( entropy , direction = ' descending ' ) k_best_entropy_sort_index = tf . get_static_value ( entropy_sort_index [ : k ] ) . tolist ( ) for index , element in enumerate ( k_best_entropy_sort_index ) : final_image [ :, :, index ] = image [ :, :, element ] output_tensor = tf . map_fn ( fn = k_best_fmap , elems = inputs ) return output_tensor ` but when i ran this code i got error ( <number> ) ] ( <url> i have tried many solutions available on the internet . but nothing worked . i think this error is due to the shape of input tensor having none as first value in its shape ( none , <number> , <number> ) . but i am unable to resolve this error . i want to wok on dynamic batch tensor as input . it would be a great help for me if anyone of you could assist me . thanks in advance .",2
tensorflow/tensorflow,"numpy to tensor i apologize for posting a very simple question here as i could not solve the issue myself or find an answer elsewhere . i was trying to make a prediction using a model and a 3 d array with <number> channels as inputs . when this 3 d array was saved as an image file , i was able to make a proper prediction using my model : ` image = tf . io . read_file ( ' image . jpg ' ) ` ` image = tf . image . decode_image ( image , channels = <number> ) ` ` image = tf . image . resize ( images = image , size =[ imsize , imsize ] ) ` ` image = tf . keras . applications . resnet50 . preprocess_input ( image ) ` ` predictions = model . predict ( np . expand_dims ( image , axis = <number> ) ) ` however , when this 3 d array was readily available in memory as a numpy array in uint8 format , and i tried to directly use this array to make a prediction , i get a different prediction result . i used ` cv2 . imread ` to simulate the array in memory = cv2 . imread ( ' image . jpg ' ) ` ` image = tf . convert_to_tensor ( array / <number> , dtype = tf . float32 ) ` ` image = tf . image . resize ( images = image , size =[ imsize , imsize ] ) ` ` image = tf . keras . applications . resnet50 . preprocess_input ( image ) ` ` predictions = model . predict ( np . expand_dims ( image , axis = <number> ) ) ` any help is greatly appreciated",2
tensorflow/tensorflow,recognize flowers with tensorflow lite on android codelabs - step <number> error just following the steps on a fresh installation of android studio on ubuntu get the following error when trying to run not find compile target android - <number> for modules : start,2
tensorflow/tensorflow,"unable to use my classifiers . tflite and label . txt . please help please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : - * * tensorflow installed from ( source or binary ) * * : - * * tensorflow version ( use command below ) * * : - * * python version * * : - * * bazel version ( if compiling from source ) * * : - * * gcc / compiler version ( if compiling from source ) * * : - * * cuda / cudnn version * * : - * * gpu model and memory * * : - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> you can obtain the tensorflow version with python - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" ` ` ` # # # describe the problem describe the problem clearly here . be sure to convey here why it ' s a bug in tensorflow or a feature request . # # # source code / logs include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached . try to provide a reproducible test case that is the bare minimum necessary to generate the problem .",2
tensorflow/tensorflow,"test issue no need to take any action . please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : - * * tensorflow installed from ( source or binary ) * * : - * * tensorflow version ( use command below ) * * : - * * python version * * : - * * bazel version ( if compiling from source ) * * : - * * gcc / compiler version ( if compiling from source ) * * : - * * cuda / cudnn version * * : - * * gpu model and memory * * : - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> you can obtain the tensorflow version with python - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" ` ` ` # # # describe the problem describe the problem clearly here . be sure to convey here why it ' s a bug in tensorflow or a feature request . # # # source code / logs include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached . try to provide a reproducible test case that is the bare minimum necessary to generate the problem .",2
tensorflow/tensorflow,"ideal development mode discussion <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tag # # # custom code no # # # os platform and distribution macos ventura13 # # # mobile device _no response_ # # # python version <number> # # # bazel version <number> . <number> # # # gcc / compiler version clang <number> # # # cuda / cudnn version none # # # gpu model and memory none # # # current behaviour ? ` ` ` shell currently , we just have mac as our daily work laptop . but we want to deep dive into tensorflow source code and maybe doing some customized changes , then compile / build and deploy into test / production environment for model training . meanwhile , as we knew , tensorflow is a typical cross - platform end2end tool , how can we make sure the whole develop / delivery pipeline runs smoothly ? do we have any best practice ? thank you . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell none regarding this topic . ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,can not install throught ` pip install - q git + <url> seen as below [ error ] ( <url> i got this command from here <sad> u > <url> tensorflow version,2
tensorflow/tensorflow,"cropping1d cann ' t support negatitve integer parameter <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell tf . keras . layers . cropping1d ( ( - <number> ) ) ( out ) report error , the ' cropping ' argument must be a tuple of <number> interges . the really reson is keras . utils . conv_utils . normalize_tuple ( ) update . and tf <= <number> , the error is not exist . is there a way to fix or keep away from this error ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import numpy as np input_shape = ( <number> , <number> , <number> ) x = np . arange ( np . prod ( input_shape ) ) . reshape ( input_shape ) y = tf . keras . layers . cropping1d ( cropping =( - <number> ))(x ) ` ` ` ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"tf <number> optimizers . does anyone have any custom optimizer for the new version ? i know that we can use tf . keras . optimizers . legacy . optimizer for making the older custom optimizers to work , but i am wonder how i can update my code . this the original code that i want to make it function for tf <number> ` class gravity ( tf . keras . optimizers . optimizer ) : def __init__ ( self , learning_rate = <number> , alpha = <number> , beta = <number> , name = "" gravity "" , * * kwargs ) : super ( gravity , self ) . __init__ ( name , * * kwargs ) self . _set_hyper ( ' learning_rate ' , kwargs . get ( ' lr ' , learning_rate ) ) self . _set_hyper ( ' decay ' , self . _initial_decay ) self . _set_hyper ( ' alpha ' , alpha ) self . _set_hyper ( ' beta ' , beta ) self . epsilon = 1 e - <number> def _create_slots ( self , var_list ) : alpha = self . _get_hyper ( "" alpha "" ) stddev = alpha / self . learning_rate initializer = tf . keras . initializers . randomnormal ( mean = <number> , stddev = stddev , seed = none ) for var in var_list : self . add_slot ( var , "" velocity "" , initializer = initializer ) <user> . function def _resource_apply_dense ( self , grad , var ) : # get data var_dtype = var . dtype . base_dtype lr_t = self . _decayed_lr ( var_dtype ) beta = self . _get_hyper ( "" beta "" , var_dtype ) t = tf . cast ( self . iterations , float ) beta_hat = ( beta * t + <number> ) / ( t + <number> ) velocity = self . get_slot ( var , "" velocity "" ) # calculations max_step_grad = <number> / tf . math . reduce_max ( tf . math . abs ( grad ) ) gradient_term = grad / ( <number> + ( grad / max_step_grad ) * * <number> ) # update variables updated_velocity = velocity . assign ( beta_hat * velocity + ( <number> - beta_hat ) * gradient_term ) updated_var = var . assign ( var - lr_t * updated_velocity ) # updates = [ updated_var , updated_velocity ] # return tf . group ( * updates ) def _resource_apply_sparse ( self , grad , var ) : raise notimplementederror def get_config ( self ) : config = super ( gravity , self ) . get_config ( ) config . update ( { ' learning_rate ' : self . _serialize_hyperparameter ( ' learning_rate ' ) , ' decay ' : self . _serialize_hyperparameter ( ' decay ' ) , ' alpha ' : self . _serialize_hyperparameter ( ' alpha ' ) , ' beta ' : self . _serialize_hyperparameter ( ' beta ' ) , ' epsilon ' } ) return config `",2
tensorflow/tensorflow,"control flow ops with external delegate npu # # # <number> . system information - os platform and distribution : ubuntu20 . <number> - tensorflow installation : conda - tensorflow library : <number> . <number> i am converting a pytorch model to int8 quantize tensorflowlite model , to run it on a nxp board , on which i use delegates to make it run on the npu . my original model contains an unsqueeze block , which is somehow transformed into a while ops ( i can see that with netron , between the onnx and tflite model ) . running this model on the board with the delegate (* * libvx_delegate . so * <wink> gives me the error : ` error : attempting to use a delegate that only supports static - sized tensors with a graph that has dynamic - sized tensors . ` from this post i understand that the control flow ops are treated as dynamic . my question is how can i run such a model with the delegate ?",2
tensorflow/tensorflow,"fails to convert splitv with quantization # # # <number> . system information - ubuntu20 . <number> - tensorflow installation : conda - tensorflow library <number> . <number> # # # <number> . code when converting a model from tensorflow to tflite , i run into errors ( regarding splitv , check error below ) when setting the pipeline with int8 quantization , but not when using regular conversion ( without quantization ) . i basically follow those instructions : ` ` ` import tensorflow as tf converter = tf . lite . tfliteconverter . from_saved_model ( saved_model_dir ) converter . optimizations = [ tf . lite . optimize . default ] converter . representative_dataset = representative_dataset converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins_int8 ] converter . inference_input_type = tf . int8 # or tf . uint8 converter . inference_output_type = tf . int8 # or tf . uint8 tflite_quant_model = converter . convert ( ) ` ` ` i get the following error : ` there are unresolved custom ops : [ splitv ] encountered unresolved custom op it works fine if i add the select_tf_ops , but i want to keep the interpreter as small and fast as possible . so my assumption is that the splitv operator in tflite is not available with the int8 quantization ? how can i know beforehand which operator is available with the int8 quantization ?",2
tensorflow/tensorflow,"tf to tflite conversion of model gives error op is neither a custom op nor a flex op # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> ubuntu <number> . <number> - tensorflow installation ( pip package or built from source ) : pip package - tensorflow library ( version , if pip package or github sha , if built from source ) : <number> . <number> # # # <number> . code provide code to help us reproduce your issues using one of the following options : # # # # option b : paste your code here or provide a link to a custom end - to - end colab ` ` ` import tensorflow as tf from tensorflow import keras import pickle import numpy as np import sys print ( tf . __version__ ) root_dir = "" ~ / "" saved_model_dir = root_dir + "" updatetf / softphy / src / qam_modulator "" def representative_dataset ( <sad> for _ in range ( <number> <sad> data = np . random . randint ( <number> , <number> , ( <number> , ) ) yield [ data . astype ( np . float32 ) ] converter = tf . lite . tfliteconverter . from_saved_model ( saved_model_dir ) converter . optimizations = [ tf . lite . optimize . default ] converter . representative_dataset = representative_dataset converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins_int8 ] converter . target_spec . supported_types = [ tf . int8 ] converter . inference_input_type = tf . int8 # or tf . uint8 converter . inference_output_type = tf . int8 # or tf . uint8 tflite_quant_model = converter . convert ( ) filename = ' qammodmodel . tflite ' with open ( filename , ' wb ' ) as f : f . write ( tflite_quant_model ) ` ` ` # # # <number> . failure after conversion the conversion fails as below , saved model dir is attached a zip file . i am not sure what needs to be changed to fix this . eventually , i ' d like to convert the tflite model to run on tpu . thanks # # # <number> . ( optional ) any other info / logs ` ` ` <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libcudart . so . <number> ' ; dlerror : libcudart . so . <number> : cannot open shared object file : no such file or directory <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cudart_stub . cc : <number> ] ignore above cudart dlerror if you do not have a gpu set up on your machine . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libnvinfer . so . <number> ' ; dlerror : li [ qam_modulator . zip ] ( <url> bnvinfer . so . <number> : cannot open shared object file : no such file or directory <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libnvinfer_plugin . so . <number> ' ; dlerror : libnvinfer_plugin . so . <number> : cannot open shared object file : no such file or directory <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> . <number> <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libcuda . so . <number> ' ; dlerror : libcuda . so . <number> : cannot open shared object file : no such file or directory <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / cuda / cuda_driver . cc : <number> ] failed call to cuinit : unknown error ( <number> ) <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_diagnostics . cc : <number> ] kernel driver does not appear to be running on this host ( ubuntugsosnow ) : / proc / driver / nvidia / version does not exist <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / mlir / lite / python / tf_tfl_flatbuffer_helpers . cc : <number> ] ignored output_format . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / mlir / lite / python / tf_tfl_flatbuffer_helpers . cc : <number> ] ignored drop_control_dependency . <number> - <number> - <number> <time> . <number> : i tensorflow / cc / saved_model / reader . cc : <number> ] reading savedmodel from : / home / gsosnow / doc / updatetf / softphy / src / qam_modulator <number> - <number> - <number> <time> . <number> : i tensorflow / cc / saved_model / reader . cc : <number> ] reading meta graph with tags { serve } <number> - <number> - <number> <time> . <number> : i tensorflow / cc / saved_model / reader . cc : <number> ] reading savedmodel debug info ( if present ) from : / home / gsosnow / doc / updatetf / softphy / src / qam_modulator <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / mlir / mlir_graph_optimization_pass . cc : <number> ] mlir v1 optimization pass is not enabled <number> - <number> - <number> <time> . <number> : i tensorflow / cc / saved_model / loader . cc : <number> ] restoring savedmodel bundle . <number> - <number> - <number> <time> . <number> : i tensorflow / cc / saved_model / loader . cc : <number> ] running initialization op on savedmodel bundle at path : / home / gsosnow / doc / updatetf / softphy / src / qam_modulator <number> - <number> - <number> <time> . <number> : i tensorflow / cc / saved_model / loader . cc : <number> ] savedmodel load for tags { serve }; status : success : ok . took <number> microseconds . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / mlir / tensorflow / utils / dump_mlir_util . cc : <number> ] disabling mlir crash reproducer , set env var ` mlir_crash_reproducer_directory ` to enable . loc ( fused [ "" hashtablev2 :"", "" qam_table "" ]): error : ' tf . hashtablev2 ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" floordiv :"", "" model_2 / qam_mod_11 / floordiv <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . floordiv ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" floormod :"", "" model_2 / qam_mod_11 / floormod <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . floormod ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" asstring :"", "" model_2 / qam_mod_11 / asstring <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . asstring ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" reducejoin :"", "" model_2 / qam_mod_11 / reducejoin / reducejoin <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . reducejoin ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" lookuptablefindv2 :"", "" model_2 / qam_mod_11 / none_lookup / lookuptablefindv2 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . lookuptablefindv2 ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" asstring :"", "" model_2 / qam_mod_11 / asstring_1 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . asstring ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" reducejoin :"", "" model_2 / qam_mod_11 / reducejoin_1 / reducejoin <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . reducejoin ' op is neither a custom op nor a flex op loc ( callsite ( callsite ( fused [ "" lookuptablefindv2 :"", "" model_2 / qam_mod_11 / none_lookup_1 / lookuptablefindv2 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error : ' tf . lookuptablefindv2 ' op is neither a custom op nor a flex op loc ( fused [ "" hashtablev2 :"", "" qam_table "" ]): error : ' tf . hashtablev2 ' op is neither a custom op nor a flex op loc ( callsite ( fused [ "" lookuptableimportv2 :"", "" key_value_init61252 / lookuptableimportv2 <user> <lambda> _81959 "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall "" ])): error : ' tf . lookuptableimportv2 ' op is neither a custom op nor a flex op <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / mlir / lite / flatbuffer_export . cc : <number> ] graph contains the following resource op ( s ) , that use ( s ) resource type . currently , the resource type is not natively supported in tflite . please consider not using the resource type if there are issues with either tflite converter or tflite runtime : resource ops : hashtablev2 , lookuptablefindv2 , lookuptableimportv2 details : tf . hashtablev2 ( ) - > ( tensor < ! tf_type . resource > ) : { container = "" "" , device = "" "" , key_dtype = ! tf_type . string , shared_name = "" <number> "" , use_node_name_sharing = false , value_dtype = i32 } tf . lookuptablefindv2 ( tensor < ! tf_type . resource > , tensor < 2 0 2 5 x ! tf_type . string > , tensor <i32> ) - > ( tensor < * xi32 > ) : { device = "" "" } tf . lookuptableimportv2 ( tensor < ! tf_type . resource > , tensor < 1 6 x ! tf_type . string > , tensor <16xi32> ) - > ( ) : { device = "" "" } error : failed while converting : ' main ' : some ops are not supported by the native tflite runtime , you can enable tf kernels fallback using tf select . see instructions : <url> tf select ops : asstring , floordiv , floormod , hashtablev2 , lookuptablefindv2 , lookuptableimportv2 , reducejoin details : tf . asstring ( tensor <2025x4xi8> ) - > ( tensor < 2 0 2 5 x4x ! tf_type . string > ) : { device = "" "" , fill = "" "" , precision = - <number> : i64 , scientific = false , shortest = false , width = - <number> : i64 } tf . floordiv ( tensor <2025x1x1xui8> , tensor <8xui8> ) - > ( tensor <2025x1x8xui8> ) : { device = "" "" } tf . floormod ( tensor <2025x1x8xi8> , tensor <i8> ) - > ( tensor <2025x1x8xi8> ) : { device = "" "" } tf . hashtablev2 ( ) - > ( tensor < ! tf_type . resource > ) : { container = "" "" , device = "" "" , key_dtype = ! tf_type . string , shared_name = "" <number> "" , use_node_name_sharing = false , value_dtype = i32 } tf . lookuptablefindv2 ( tensor < ! tf_type . resource > , tensor < 2 0 2 5 x ! tf_type . string > , tensor <i32> ) - > ( tensor < * xi32 > ) : { device = "" "" } tf . lookuptableimportv2 ( tensor < ! tf_type . resource > , tensor < 1 6 x ! tf_type . string > , tensor <16xi32> ) - > ( ) : { device = "" "" } tf . reducejoin ( tensor < 2 0 2 5 x4x ! tf_type . string > , tensor <i32> ) - > ( tensor < 2 0 2 5 x ! tf_type . string > ) : { device = "" "" , keep_dims = false , separator = "" "" } traceback ( most recent call last ) : file "" / home / gsosnow / doc / qammodt2tf . py "" , line <number> , in <module> tflite_quant_model = converter . convert ( ) file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / lite . py "" , line <number> , in wrapper return self . _convert_and_export_metrics ( convert_func , * args , * * kwargs ) file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / lite . py "" , line <number> , in _convert_and_export_metrics result = convert_func ( self , * args , * * kwargs ) file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / lite . py "" , line <number> , in convert return self . _convert_from_saved_model ( graph_def ) file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / lite . py "" , line <number> , in _convert_from_saved_model result = _convert_saved_model ( * * converter_kwargs ) file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / convert_phase . py "" , line <number> , in wrapper raise converter_error from none # re - throws the exception . file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / convert_phase . py "" , line <number> , in wrapper return func ( * args , * * kwargs ) file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / convert . py "" , line <number> , in convert_saved_model data = convert ( file "" / home / gsosnow / anaconda3 / lib / python3 . <number> / site - packages / tensorflow / lite / python / convert . py "" , line <number> , in convert raise converter_error tensorflow . lite . python . convert_phase . convertererror : <unknown> : <number> : error : loc ( fused [ "" hashtablev2 :"", "" qam_table "" ]): ' tf . hashtablev2 ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" hashtablev2 :"", "" qam_table "" ]): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" floordiv :"", "" model_2 / qam_mod_11 / floordiv <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . floordiv ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" floordiv :"", "" model_2 / qam_mod_11 / floordiv <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" floormod :"", "" model_2 / qam_mod_11 / floormod <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . floormod ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" floormod :"", "" model_2 / qam_mod_11 / floormod <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" asstring :"", "" model_2 / qam_mod_11 / asstring <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . asstring ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" asstring :"", "" model_2 / qam_mod_11 / asstring <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" reducejoin :"", "" model_2 / qam_mod_11 / reducejoin / reducejoin <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . reducejoin ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" reducejoin :"", "" model_2 / qam_mod_11 / reducejoin / reducejoin <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" lookuptablefindv2 :"", "" model_2 / qam_mod_11 / none_lookup / lookuptablefindv2 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . lookuptablefindv2 ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" lookuptablefindv2 :"", "" model_2 / qam_mod_11 / none_lookup / lookuptablefindv2 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" asstring :"", "" model_2 / qam_mod_11 / asstring_1 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . asstring ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" asstring :"", "" model_2 / qam_mod_11 / asstring_1 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" reducejoin :"", "" model_2 / qam_mod_11 / reducejoin_1 / reducejoin <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . reducejoin ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" reducejoin :"", "" model_2 / qam_mod_11 / reducejoin_1 / reducejoin <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( callsite ( fused [ "" lookuptablefindv2 :"", "" model_2 / qam_mod_11 / none_lookup_1 / lookuptablefindv2 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . lookuptablefindv2 ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( fused [ "" lookuptablefindv2 :"", "" model_2 / qam_mod_11 / none_lookup_1 / lookuptablefindv2 <user> "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( fused [ "" hashtablev2 :"", "" qam_table "" ]): ' tf . hashtablev2 ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" hashtablev2 :"", "" qam_table "" ]): error code : error_needs_flex_ops <unknown> : <number> : error : loc ( callsite ( fused [ "" lookuptableimportv2 :"", "" key_value_init61252 / lookuptableimportv2 <user> <lambda> _81959 "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall "" ])): ' tf . lookuptableimportv2 ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall "" ]): called from <unknown> : <number> : note : loc ( callsite ( fused [ "" lookuptableimportv2 :"", "" key_value_init61252 / lookuptableimportv2 <user> <lambda> _81959 "" ] at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall "" ])): error code : error_needs_flex_ops <unknown> : <number> : error : failed while converting : ' main ' : some ops are not supported by the native tflite runtime , you can enable tf kernels fallback using tf select . see instructions : <url> tf select ops : asstring , floordiv , floormod , hashtablev2 , lookuptablefindv2 , lookuptableimportv2 , reducejoin details : tf . asstring ( tensor <2025x4xi8> ) - > ( tensor < 2 0 2 5 x4x ! tf_type . string > ) : { device = "" "" , fill = "" "" , precision = - <number> : i64 , scientific = false , shortest = false , width = - <number> : i64 } tf . floordiv ( tensor <2025x1x1xui8> , tensor <8xui8> ) - > ( tensor <2025x1x8xui8> ) : { device = "" "" } tf . floormod ( tensor <2025x1x8xi8> , tensor <i8> ) - > ( tensor <2025x1x8xi8> ) : { device = "" "" } tf . hashtablev2 ( ) - > ( tensor < ! tf_type . resource > ) : { container = "" "" , device = "" "" , key_dtype = ! tf_type . string , shared_name = "" <number> "" , use_node_name_sharing = false , value_dtype = i32 } tf . lookuptablefindv2 ( tensor < ! tf_type . resource > , tensor < 2 0 2 5 x ! tf_type . string > , tensor <i32> ) - > ( tensor < * xi32 > ) : { device = "" "" } tf . lookuptableimportv2 ( tensor < ! tf_type . resource > , tensor < 1 6 x ! tf_type . string > , tensor <16xi32> ) - > ( ) : { device = "" "" } tf . reducejoin ( tensor < 2 0 2 5 x4x ! tf_type . string > , tensor <i32> ) - > ( tensor < 2 0 2 5 x ! tf_type . string > ) = "" "" , keep_dims = false , separator = "" "" } ` ` `",2
tensorflow/tensorflow,"cve - <number> - <number> for <number> . <number> hello , based on [ nvd ] ( <url> cve - <number> - <number> will be cherry - picked for <number> . <number> . however , i do not see it in the [ release notes ] ( <url> will this still be cherry - picked ? thanks .",2
tensorflow/tensorflow,"extending tf . tensor class <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution macos ventura <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i want to extend the tf . tensor class , but neither of the following options work : <number> . option : extend tf . tensor : ` ` ` shell class mytftensor ( tf . tensor ) : <user> def _from_native ( cls , value : tf . tensor ) : value . __class__ = cls return value y = mytftensor . _from_native ( value = tf . zeros ( ( <number> , <number> , <number> ) ) ` ` ` fails with : ` ` ` / var / folders / kb / yxxdttyj4qzcm447np5p22kw0000gp / t / ipykernel_94703 / <number> . py in _from_native ( cls , value ) <number> <user> <number> def _from_native ( cls , value : tf . tensor ) : - - - - > <number> value . __class__ = cls <number> return value typeerror : __class__ assignment : ' mytftensor ' object layout differs from ' tensorflow . python . framework . ops . eagertensor ' ` ` ` <number> . option : extend eagertensor ` ` ` shell from tensorflow . python . framework . ops import eagertensor class mytftensor ( eagertensor ) : <user> def _from_native ( cls , value : tf . tensor ) : value . __class__ = cls return value ` ` ` fails with : ` ` ` - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - typeerror traceback ( most recent call last ) / var / folders / kb / yxxdttyj4qzcm447np5p22kw0000gp / t / ipykernel_94703 / <phone> . py in < cell line : <number> > ( ) <number> from tensorflow . python . framework . ops import eagertensor - - - - > <number> class mytftensor ( eagertensor ) : <number> <number> <user> <number> def _from_native ( cls , value : tf . tensor ) : typeerror : type ' tensorflow . python . framework . ops . eagertensor ' is not an acceptable base type ` ` ` our goal is to extend it though , we * * do not * * want to store the tf . tensor instance as an attribute of mytftensor , but instead extend the ` tf . tensor ` class ! # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf # 1 st option class mytftensor ( tf . tensor ) : <user> def _from_native ( cls , value : tf . tensor ) : value . __class__ = cls return value y = mytftensor . _from_native ( value = tf . zeros ( ( <number> , <number> , <number> ) ) # 2 nd option from tensorflow . python . framework . ops import eagertensor class mytftensor ( eagertensor ) : <user> def _from_native ( cls , value : tf . tensor ) = cls return value ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"question about using tensorarray to do backpropagation i am confused about the tensorflow documentation here : <url> that although the array can be read multiple times and positions can be overwritten , behavior may be undefined when storing multiple references to the same array and clear_after_read is false . in particular , avoid using methods like concat ( ) to convert an intermediate tensorarray to a tensor , then further modifying the tensorarray , particularly if you need to backprop through it later . this is from tensorflow <number> which is not included in tensorflow <number> . so i want to know if we really need an intermediate tensorarray and then concatenate it to a tensor and then calculate loss and do backpropogation , which way is suggested ?",2
tensorflow/tensorflow,"how to infer pose classification on single image ? the first layer of the model needs shape of ( none , <number> ) . how to send the image as a feature tensor of <number> feature points which is also nothing but the feature taken as the pose points estimated by movnet ?",2
tensorflow/tensorflow,"error when running <elongated> tensorflow . python . ops . sparse_ops . sparse_to_dense <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell zero or negative argument ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import numpy as np from tensorflow . python . ops import sparse_ops try : try : with tf . device ( ' / cpu ' <sad> arg_0_0_0 = <number> arg_0_0 = [ arg_0_0_0 , ] arg_0_1_0 = <number> arg_0_1 = [ arg_0_1_0 , ] arg_0 = [ arg_0_0 , arg_0_1 , ] arg_1_0 = <number> arg_1 = [ arg_1_0 , ] arg_2_0 = - <number> arg_2_1 = <number> arg_2 = [ arg_2_0 , arg_2_1 , ] arg_3 = <number> validate_indices = false out = sparse_ops . sparse_to_dense ( arg_0 , arg_1 , arg_2 , arg_3 , validate_indices = validate_indices , ) except exception as e : print ( "" error : "" + str ( e ) ) try : with tf . device ( ' / gpu : <number> ' <sad> arg_0_0 = [ arg_0_0_0 , ] arg_0_1 = [ arg_0_1_0 , ] arg_0 = [ arg_0_0 , arg_0_1 , ] arg_1 = [ arg_1_0 , ] arg_2 = [ arg_2_0 , arg_2_1 , ] sparse_ops . sparse_to_dense ( arg_0 , arg_1 , arg_2 , arg_3 , validate_indices = validate_indices , ) except exception as e : print ( "" error : "" + str ( e ) ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : e tensorflow / stream_executor / cuda / cuda_blas . cc : <number> ] unable to register cublas factory : attempting to register factory for plugin cublas when one has already been registered <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libnvinfer . so . <number> ' ; dlerror : libnvinfer . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path : <annoyed> lib / <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libnvinfer_plugin . so . <number> ' ; dlerror : libnvinfer_plugin . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path : <annoyed> lib / <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libcudnn . so . <number> ' ; dlerror : libcudnn . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path : <annoyed> lib / <number> - <number> - <number> <time> . <number> : w tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] cannot dlopen some gpu libraries . please make sure the missing libraries mentioned above are installed properly if you would like to use gpu . follow the guide at <url> for how to download and setup the required libraries for your platform . skipping registering gpu devices . <repeated> <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . warning : tensorflow : from / home / nimashiri / anaconda3 / envs / tf - <number> / lib / python3 . <number> / site - packages / tensorflow / python / util / dispatch . py : <number> : sparse_to_dense ( from tensorflow . python . ops . sparse_ops ) is deprecated and will be removed in a future version . instructions for updating : create a ` tf . sparse . sparsetensor ` and use ` tf . sparse . to_dense ` instead . error :{{ function_node __wrapped__sparsetodense_device_ / job : localhost / replica : <number> / task : <number> / device : cpu : <number> } } indices are not valid ( out of bounds ) . shape : [ <number> ] [ op : sparsetodense ] error :{{ function_node __wrapped__sparsetodense_device_ / job : localhost / replica : <number> / task : <number> / device : cpu : <number> } } indices are not valid ( out of bounds ) . shape [ op : sparsetodense ] ` ` ` ` ` ` </details>",2
tensorflow/tensorflow,"running distributed tensorflow using mpi <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution linux # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> . <number> # # # gpu model and memory <number> * rtx <number> ti / 1 1 gb memory each # # # current behaviour ? ` ` ` shell instructions for updating : use distribute . multiworkermirroredstrategy instead <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <happy> d : <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <happy> e : <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : worker / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <happy> d : <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : worker / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <happy> e : <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : worker / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : worker / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / distributed_runtime / rpc / grpc_channel . cc : <number> ] initialize grpcchannelcache for job worker - > { <number> - > g <time> <number> } <number> - <number> - <number> <time> . <number> : i tensorflow / core / distributed_runtime / rpc / grpc_server_lib . cc : <number> ] started server with target : grpc :// g <time> <number> / usr / ebuild / software / tensorflow / <number> . <number> - foss - 2 0 2 1 a - cuda - <number> . <number> / lib / python3 . <number> / site - packages / keras / optimizer_v2 / optimizer_v2 . py : <number> : userwarning : the ` lr ` argument is deprecated , use ` learning_rate ` instead . warnings . warn ( warning : tensorflow : ` period ` argument is deprecated . please use ` save_freq ` to specify the frequency in number of batches seen . <number> - <number> - <number> <time> . <number> : w tensorflow / core / grappler / optimizers / data / auto_shard . cc : <number> ] auto sharding policy will apply data sharding policy as it failed to apply file sharding policy because of the following reason : found an unshardable source dataset : name : "" tensorslicedataset / _2 "" op : "" tensorslicedataset "" input : "" placeholder / _0 "" input : "" placeholder / _1 "" attr { key : "" toutput_types "" value { list { type : dt_double type : dt_double } } } attr { key : "" output_shapes "" value { list { shape { dim { size : <number> } } shape { dim { size : <number> } } } } } <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / mlir / mlir_graph_optimization_pass . cc : <number> ] none of the mlir optimization passes are enabled ( registered <number> ) [ g <time> <number> : <time> <number> ] caught signal <number> ( segmentation fault : address not mapped to object at address ( nil ) ) = = = = backtrace ( tid : <number> ) = = = = <number> 0x0 0 0 0 0 0 0 0 0 0 0 2 1 3 7 e ucs_debug_print_backtrace ( ) / umbc / ebuild - soft / cascade - lake / build / ucx / <number> . <number> / gccore <elongated> - <number> . <number> / ucx - <number> . <number> / src / ucs / debug / debug . c : <number> <number> 0x0 0 0 0 0 0 0 0 0 3 8 2 0 4 5 b tensorflow : : ncclcommunicator : : enqueue ( ) collective_communicator . cc : <number> <number> 0x <phone> c9f88a tensorflow : : ncclreducer : : run ( ) ? <repeated> : <number> <number> 0x0 0 0 0 0 0 0 0 0 0 9 0 8 6 dc tensorflow : : basecollectiveexecutor : : executeasync ( tensorflow : : opkernelcontext * , tensorflow : : collectiveparams const * , std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , std : : function < void ( tensorflow : : status const & )>): : { lambda ( )# <number> <sad> : operator ( ) ( ) base_collective_executor . cc : <number> <number> 0x <phone> b99403 tensorflow : : unboundedworkqueue : : pooledthreadfunc ( ) ? <repeated> : <number> <number> 0x <phone> b9f6b1 tensorflow : : ( anonymous namespace ) : : pthread : : threadfn ( ) env . cc : <number> <number> 0x0 0 0 0 0 0 0 0 0 0 0 0 7 ea5 start_thread ( ) pthread_create . c : <number> <number> 0x0 0 0 0 0 0 0 0 0 0 0 feb0d __clone ( ) ? <repeated> : <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = [ g <time> <number> ] * * * process received signal * * * [ g <time> <number> ] signal : segmentation fault ( <number> ) [ g <time> <number> ] signal code : ( - <number> ) [ g <time> <number> ] failing at address : 0x 2 ecf70000ac05 [ g <time> <number> ] [ <number> ] / lib64 / libpthread . so . <number> ( + 0 xf630 ) [ 0x 2 aaaab7e6630 ] [ g <time> <number> ] [ <number> ] / usr / ebuild / software / tensorflow / <number> . <number> - foss - 2 0 2 1 a - cuda - <number> . <number> / lib / python3 . <number> / site - packages / tensorflow / python / _pywrap_tensorflow_internal . so ( + 0x 3 8 2 0 4 5 b ) [ 0x 2 aaab68fc45b ] [ g <time> <number> ] [ <number> ] / usr / ebuild / software / tensorflow / <number> . <number> - foss - 2 0 2 1 a - cuda - <number> . <number> / lib / python3 . <number> / site - packages / tensorflow / python / _pywrap_tensorflow_internal . so ( _zn10tensorflow11ncclreducer3runest8functionifvrkns_6statuseee + 0x 1 ca ) [ 0x 2 aaab8d7b88a ] [ g <time> <number> ] [ <number> ] / usr / ebuild / software / tensorflow / <number> . <number> - foss - 2 0 2 1 a - cuda - <number> . <number> / lib / python3 . <number> / site - packages / tensorflow / python / . <repeated> / libtensorflow_framework . so . <number> ( + 0x 9 0 8 6 dc ) [ 0x 2 aaadc7556dc ] [ g <time> <number> ] [ <number> ] / usr / ebuild / software / tensorflow / <number> . <number> - foss - 2 0 2 1 a - cuda - <number> . <number> / lib / python3 . <number> / site - packages / tensorflow / python / . <repeated> / libtensorflow_framework . so . <number> ( _zn10tensorflow18unboundedworkqueue16pooledthreadfuncev + 0x 1 b3 ) [ 0x 2 aaadc9e6403 ] [ g <time> <number> ] [ <number> ] / usr / ebuild / software / tensorflow / <number> . <number> - foss - 2 0 2 1 a - cuda - <number> . <number> / lib / python3 . <number> / site - packages / tensorflow / python / . <repeated> / libtensorflow_framework . so . <number> ( + 0 xb9f6b1 ) [ 0x 2 aaadc9ec6b1 ] [ g <time> <number> ] [ <number> ] / lib64 / libpthread . so . <number> ( + 0x 7 ea5 ) [ 0x 2 aaaab7deea5 ] [ g <time> <number> ] [ <number> ] / lib64 / libc . so . <number> ( clone + 0x 6 d ) [ 0x 2 aaaac468b0d ] [ g <time> <number> ] * * * end of error message * * * - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - primary job terminated normally , but <number> process returned a non - zero exit code . per user - direction , the job has been aborted . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - mpirun noticed that process rank <number> with pid <number> on node g01 exited on signal <number> ( segmentation fault ) . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell from getonehot import getonehot from mpi4py import mpi comm = mpi . comm_world rank = comm . get_rank ( ) # load in the parameter files from json import load as loadf with open ( "" params . json "" , ' r ' ) as infile : params = loadf ( infile ) # get data files and prep them for the generator from tensorflow import distribute as d callbacks = [ ] devices = getdevices ( ) print ( devices ) set_tf_config_mpi ( ) strat = d . experimental . multiworkermirroredstrategy ( communication = d . experimental . collectivecommunication . nccl ) # create network from sys import argv resume_training = false print ( argv ) if "" resume_latest "" in argv : resume_training = true with strat . scope ( <sad> # scheduler if isinstance ( params [ "" learning_rate "" ] , str ) : # get the string for the importable function lr = params [ "" learning_rate "" ] from tensorflow . keras . callbacks import learningratescheduler # use a dummy learning rate params [ "" learning_rate "" ] = <number> # model = create_model ( * * params ) # get the importable function lr = lr . split ( "" . "" ) baseimport = __import__ ( lr [ <number> ] , globals ( ) , locals ( ) , [ lr [ <number> ] ] , <number> ) lr = getattr ( baseimport , lr [ <number> ] ) # make a schedule lr = learningratescheduler ( lr ) callbacks . append ( lr ) # resume model ? model_name = none if resume_training : initial_epoch , model_name = getinitialepochsandmodelname ( rank ) if model_name is none : initial_epoch = <number> model = create_model ( * * params ) resume_training = false else : from tensorflow . keras . models import load_model model = load_model ( model_name ) # load data from disk import numpy if "" root "" in params . keys ( <sad> root = params [ ' root ' ] else : root = "" . / "" if "" filename "" in params . keys ( <sad> filename = params [ "" filename "" ] else : filename = "" dataset_timeseries . csv "" restricted = [ ' euc1 ' , ' e1 ' , ' x1 ' , ' y1 ' , ' z1 ' , ' euc2 ' , ' e2 ' , ' x2 ' , ' y2 ' , ' z2 ' , ' euc3 ' , ' e3 ' , ' x3 ' , ' y3 ' , ' z3 ' , ] x , y = getonehot ( "" { } / { } "" . format ( root , filename ) , restricted = restricted , * * params ) # val_x , val_y = getonehot ( "" { } / { } "" . format ( root , val_filename ) , restricted = restricted ) val_x , val_y = none , none params [ "" gbatch_size "" ] = params [ ' batch_size ' ] * len ( devices ) print ( "" x . shape ="", x . shape ) print ( "" y . shape ="", y . shape ) print ( "" epochs ="", params [ ' epochs ' ] , type ( params [ ' epochs ' ] ) ) print ( "" batch ="", params [ ' batch_size ' ] , type ( params [ ' batch_size ' ] ) ) print ( "" gbatch ="", params [ ' gbatch_size ' ] , type ( params [ ' gbatch_size ' ] ) ) # load data into a distributed dataset # dataset object does nothing in place : # <url> from tensorflow . data import dataset data = dataset . from_tensor_slices ( (x , y ) ) # create validation set v = params [ ' validation ' ] if val_x is not none : vrecord = val_x . shape [ <number> ] val = dataset . from_tensor_slices ( ( val_x , val_y ) ) validation = val # data . take ( vrecord ) else : vrecord = int ( x . shape [ <number> ] * v ) validation = data . take ( vrecord ) validation = validation . batch ( params [ ' gbatch_size ' ] ) validation = validation . repeat ( params [ ' epochs ' ] ) # validation - - need to do kfold one day # this set should not be distributed vsteps = vrecord / / params [ ' gbatch_size ' ] if vrecord % params [ ' gbatch_size ' ] ! = <number> : vsteps + = <number> # shuffle the data during preprocessing or suffer . <repeated> # parallel randomness = = nightmare # data = data . shuffle ( x . shape [ <number> ] ) # ordering these two things is very important ! # consider <number> elements , batch size <number> repeat <number> # [ <number> <number> <number> ] - > [ [ <number> <number> ] [ <number> ] ] - > [ [ <number> <number> ] [ <number> ] [ <number> <number> ] [ <number> ] ] ( correct ) batch - > repeat # [ <number> <number> <number> ] - > [ <number> <number> <number> <number> <number> <number> ] - > [ [ <number> <number> ] [ <number> <number> ] [ <number> <number> ] ] ( incorrect ) repeat - > batch # data = data . skip ( vrecord ) data = data . batch ( params [ ' gbatch_size ' ] ) data = data . repeat ( params [ ' epochs ' ] ) records = x . shape [ <number> ] # - vrecord steps = records / / params [ ' gbatch_size ' ] if records % params [ ' gbatch_size ' <sad> steps + = <number> print ( "" steps ="", steps ) # note that if we are resuming that the number of _remaining_ epochs has # changed ! # the number of epochs * steps is the numbers of samples to drop print ( "" initial cardinality = "" , data . cardinality ( ) ) print ( "" initial v cardinality = "" , data . cardinality ( ) ) data = data . skip ( initial_epoch*steps <censored> ) validation = validation . skip ( initial_epoch*vsteps <censored> ) print ( "" final cardinality = "" , data . cardinality ( ) ) print ( "" final v cardinality = "" , data . cardinality ( ) ) # data = strat . experimental_distribute_dataset ( data ) # split into validation and training callbacks = createcallbacks ( params , callbacks , rank , resume_training ) print ( callbacks ) history = model . fit ( data , epochs = params [ ' epochs ' ] , batch_size = params [ ' gbatch_size ' ] , steps_per_epoch = steps , verbose = <number> , initial_epoch = initial_epoch , validation_data = validation , validation_steps = vsteps , callbacks = callbacks ) if rank = = <number> : model . save ( "" model - final "" ) else ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"model weight not saved when exporting savedmodel <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source binary # # # tensorflow version tf2 . <number> # # # custom code yes # # # os platform and distribution wsl2 + tensorflow / tensorflow : <number> . <number> - gpu - jupyter image # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i need to change the signature in savedmodel by loading and re - export it with different configuration . the new exported model lost track of the model weight . here ' s what i have tried - load the savedmodel ( > 3 0 0 mb , with two signatures , exported in tf1 . <number> ) with tf2 . <number> - select the signature i need - export model with new signature config - load model and test the re - exported model can be successfully loaded . but it will not be able to make any prediction due to initialized variable . i checked the exported model and the size is approximately 3 0 0 kb , which means that most of the model weights were lost . ` ` ` i looked into [ this answer ] ( <url> that solves the problem on his case . to me the only difference is that he converted variables in the original variable to constants . but for this approach the original ` . ckpt ` file is a prerequisite , which is not my case # # # standalone code to reproduce the issue ` ` ` shell script for reproducing the issue # <url> # <url> import tensorflow as tf import numpy as np import os os . environ [ "" cuda_visible_devices "" ] = "" "" export_path_origin = "" baidu - ske - <number> - len128 "" # a model with multiple signatures assert tf . __version__ [ <number> ] = = ' <number> ' print ( "" test "" ) imported = tf . saved_model . load ( export_dir = export_path_origin ) print ( imported . signatures ) f_serving_default = imported . signatures [ "" serving_default "" ] f_predict = imported . signatures [ "" predict "" ] inputs = { "" input_ids "" : tf . constant ( [ [ <number> ] * <number> ] ) , "" segment_ids "" : tf . constant ( [ [ <number> ] * <number> ] ) , "" input_mask "" : tf . constant ( [ [ <number> ] * <number> ] ) } serving_default_output = f_serving_default ( * * inputs ) # print ( serving_default_output ) predict_output = f_predict ( * * inputs ) # print ( predict_output ) signature_to_keep = f_predict fetches = { k : v . name for k , v in signature_to_keep . structured_outputs . items ( ) } feeds = [ input_ . name for input_ in signature_to_keep . inputs ] new_fn = imported . prune ( feeds , fetches = fetches ) new_fn . graph . finalize ( ) original_output = signature_to_keep ( * * inputs ) new_outputs = new_fn ( * * inputs ) print ( new_outputs ) # assert equal for k in new_outputs : t_origin , t_new = original_output [ k ] , new_outputs [ k ] assert t_origin . dtype = = t_new . dtype if t_origin . dtype . is_floating : np . testing . assert_allclose ( t_origin . numpy ( ) , t_new . numpy ( ) ) else : assert np . all ( t_origin . numpy ( ) = = t_new . numpy ( ) ) class exportable ( tf . module ) : def __init__ ( self , fn ) : super ( exportable , self ) . __init__ ( ) self . tf1_model = fn tf . function ( input_signature =[ tf . tensorspec ( [ none , <number> ] , tf . int32 ) , tf . tensorspec ( [ none , <number> ] , tf . int32 ) , tf . tensorspec ( [ none , <number> ] , tf . int32 ) ] ) def forward ( self , input_ids , segment_ids , input_mask ) : with tf . init_scope ( <sad> out = self . tf1_model ( input_ids = input_ids , segment_ids = segment_ids , input_mask = input_mask ) return out new_saved_model = exportable ( new_fn ) print ( new_saved_model . forward ( * * inputs ) ) # eager execution works new_model_path = ' . / new_saved_model ' tf . saved_model . save ( new_saved_model , new_model_path ) imported = tf . saved_model . load ( export_dir = new_model_path ) imported . signatures [ "" serving_default "" ](* * inputs ) # error : uninitialized variables ` ` ` here ' s the metadata of the original model from by ` tensorflow / serving ` ` ` ` { "" model_spec "" <sad> "" name "" : "" default "" , "" signature_name "" : "" "" , "" version "" : "" <number> "" } , "" metadata "" : { "" signature_def "" : { "" signature_def "" : { "" predict "" : { "" inputs "" : { "" segment_ids "" : { "" dtype "" : "" dt_int32 "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" segment_ids : <number> "" } , "" input_mask "" : { "" dtype "" : "" dt_int32 "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" input_mask : <number> "" } , "" input_ids "" : { "" dtype "" : "" dt_int32 "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" input_ids : <number> "" } } , "" outputs "" : { "" token_label_predictions "" : { "" dtype "" : "" dt_int64 "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" token_label_loss / argmax : <number> "" } , "" predicate_head_probabilities "" : { "" dtype "" : "" dt_float "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" predicate_head_select_loss / sigmoid : <number> "" } } , "" method_name "" : "" tensorflow / serving / predict "" } , "" serving_default "" : { "" inputs "" : { "" segment_ids "" : { "" dtype "" : "" dt_int32 "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" segment_ids : <number> "" } , "" input_mask "" : { "" dtype "" : "" dt_int32 "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" input_mask : <number> "" } , "" input_ids "" : { "" dtype "" : "" dt_int32 "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" input_ids : <number> "" } } , "" outputs "" : { "" predicate_head_probabilities "" : { "" dtype "" : "" dt_float "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" predicate_head_select_loss / sigmoid : <number> "" } , "" token_label_logits "" : { "" dtype "" : "" dt_float "" , "" tensor_shape "" : { "" dim "" : [ { "" size "" : "" - <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } , { "" size "" : "" <number> "" , "" name "" : "" "" } ] , "" unknown_rank "" : false } , "" name "" : "" token_label_loss / reshape_1 : <number> "" } } , "" method_name "" : "" tensorflow / serving / predict "" } } } } } ` ` ` ` ` ` # # # relevant log output ` ` ` shell test <number> - <number> - <number> <time> . <number> : e tensorflow / stream_executor / cuda / cuda_driver . cc : <number> ] failed call to cuinit : cuda_error_no_device : no cuda - capable device is detected <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_diagnostics . cc : <number> ] kernel driver does not appear to be running on this host ( b0c1756a148b ) : / proc / driver / nvidia / version does not exist <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 avx512f fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / word_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / token_type_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / position_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / beta : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / gamma : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / word_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / token_type_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / position_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / beta : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / gamma : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / word_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / token_type_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / position_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / beta : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / gamma : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / word_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / token_type_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / position_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / beta : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / gamma : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . _signaturemap ( { ' serving_default ' : < concretefunction pruned ( input_ids , input_mask , segment_ids ) at 0x 7 ffb8402c9a0 > , ' predict ' : < concretefunction pruned ( input_ids , input_mask , segment_ids ) at 0x 7 ffb38122730 > } ) warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / word_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / token_type_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / position_embeddings : <number> ' shape =( <number> , <number> ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / beta : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . warning : tensorflow : unable to create a python object for variable < tf . variable ' bert / embeddings / layernorm / gamma : <number> ' shape =( <number> , ) dtype = float32_ref > because it is a reference variable . it may not be visible to training apis . if this is a problem , consider rebuilding the savedmodel after running tf . compat . v1 . enable_resource_variables ( ) . { ' predicate_head_probabilities ' : < tf . tensor : shape =( <number> , <number> , <number> , <number> ) , dtype = float32 , numpy = array ( [ [ [ [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , . <repeated> , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 4 9 6 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 3 1 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] ] ] , dtype = float32 ) > , ' token_label_predictions ' : < tf . tensor : shape =( <number> , <number> ) , dtype = int64 , numpy = array ( [ [ <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> ] ] ) > } { ' predicate_head_probabilities ' : < tf . tensor : shape =( <number> , <number> , <number> , <number> ) , dtype = float32 , numpy = array ( [ [ [ [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 1 0 5 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , . <repeated> , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 5 0 4 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] , [ [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 4 9 6 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 3 1 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , . <repeated> , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] , [ <number> . 7 7 1 1 4 8 7 e - <number> , <number> . 0 4 7 7 5 1 4 e - <number> , <number> . 3 3 9 9 1 6 1 e - <number> , . <repeated> , <number> . 9 1 2 2 0 6 8 e - <number> , <number> . 6 8 0 0 6 3 6 e - <number> , <number> . 0 1 7 9 8 1 8 e - <number> ] ] ] ] , dtype = float32 ) > , ' token_label_predictions ' : < tf . tensor : shape =( <number> , <number> ) , dtype = int64 , numpy = array ( [ [ <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> ] ] ) > } <number> - <number> - <number> <time> . <number> : w tensorflow / python / util / util . cc : <number> ] sets are not currently considered sequences , but this may change in the future , so consider avoiding using them . traceback ( most recent call last ) : file "" / home / polonsky / documents / volcano_poc / bravo / test . py "" , line <number> , in <module> imported . signatures [ "" serving_default "" ](* * inputs ) # error : uninitialized variables file "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / function . py "" , line <number> , in __call__ return self . _call_impl ( args , kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / function . py "" , line <number> , in _call_impl return self . _call_with_structured_signature ( args , kwargs , file "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / function . py "" , line <number> , in _call_with_structured_signature return self . _call_flat ( file "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / saved_model / load . py "" , line <number> , in _call_flat return super ( _wrapperfunction , self ) . _call_flat ( args , captured_inputs , file "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / function . py "" , line <number> , in _call_flat return self . _build_call_outputs ( self . _inference_function . call ( file "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / function . py "" , line <number> , in call outputs = execute . execute ( file "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / execute . py "" , line <number> , in quick_execute tensors = pywrap_tfe . tfe_py_execute ( ctx . _handle , device_name , op_name , tensorflow . python . framework . errors_impl . failedpreconditionerror : graph execution error : detected at node ' bert / encoder / layer_5 / output / dense / bias / read ' defined at ( most recent call last ) : file "" / home / polonsky / documents / volcano_poc / bravo / test . py "" , line <number> , in <module> imported = tf . saved_model . load ( export_dir = new_model_path ) node attempting to use uninitialized value statefulpartitionedcall / bert / encoder / layer_5 / output / dense / bias [ [ { { node bert / encoder / layer_5 / output / dense / bias / read } } ] ] [ op : __inference_signature_wrapper_11982 ] ` ` ` </details>",2
tensorflow/tensorflow,"how to save_weights of qat model in tensorflow model optimization ? <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i am trying to train a model using quantise awareness training . i am using tensorflow model optimization . i create a model , quantise it , fit it , save the weight . then at a later date i redefine and quantise and try to load the weights . however , the model starts the whole training process from the start again . this article explains how to save the whole qat model . <url> however , i wish to save the weights not model . please do not suggest to follow the save whole model ! all help would be much appreciated . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell from tensorflow_model_optimization . quantization . keras import quantise_model model = define_model ( ) qat_model = quantize_model ( model ) qat_model . fit ( . <repeated> ) qat_model . save_weights ( "" qat_weights . h5 "" ) . <repeated> finish for now . <repeated> . <repeated> pick up at a later date . <repeated> model = define_model ( ) qat_model = quantize_model ( model ) qat_model . load_weights ( "" qat_weights . h5 "" ) ` ` ` # # # relevant log output starts the whole training process from the start at <percent> _no response_ </details>",2
tensorflow/tensorflow,"i have some problems i think it is connected with dataset that i make myself <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i got an error with model . fit for your information , i will also add that the table used for the dataset consists of <number> columns , one of which contains the paths to the images on the disk , and the second one contains the labels for each image . and i ’ m also new to github and therefore i don ’ t know how to make it so that you can run all the code because i don ’ t really want to share a huge folder with files , i can also clarify that the training arrays consist of <number> . png images ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <url> ` ` ` # # # relevant log output ` ` ` shell unimplementederror traceback ( most recent call last ) < ipython - input - <number> - c0002c3040bd > in <module> - - - - > <number> model . fit ( x_train , y_train , epochs = <number> ) <number> frames / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / execute . py in quick_execute ( op_name , num_outputs , inputs , attrs , ctx , name ) <number> try : <number> ctx . ensure_initialized ( ) - - - > <number> tensors = pywrap_tfe . tfe_py_execute ( ctx . _handle , device_name , op_name , <number> inputs , attrs , num_outputs ) <number> except core . _notokstatusexception as e : unimplementederror : graph execution error : detected at node ' sparse_categorical_crossentropy / cast ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / runpy . py "" , line <number> , in _run_module_as_main return _run_code ( code , main_globals , none , file "" / usr / lib / python3 . <number> / runpy . py "" , line <number> , in _run_code exec ( code , run_globals ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipykernel_launcher . py "" , line <number> , in <module> app . launch_new_instance ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / traitlets / config / application . py "" , line <number> , in launch_instance app . start ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipykernel / kernelapp . py "" , line <number> , in start self . io_loop . start ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / platform / asyncio . py "" , line <number> , in start self . asyncio_loop . run_forever ( ) file "" / usr / lib / python3 . <number> / asyncio / base_events . py "" , line <number> , in run_forever self . _run_once ( ) file "" / usr / lib / python3 . <number> / asyncio / base_events . py "" , line <number> , in _run_once handle . _run ( ) file "" / usr / lib / python3 . <number> / asyncio / events . py "" , line <number> , in _run self . _context . run ( self . _callback , * self . _args ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / ioloop . py "" , line <number> , in <lambda> lambda f : self . _run_callback ( functools . partial ( callback , future ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / ioloop . py "" , line <number> , in _run_callback ret = callback ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / gen . py "" , line <number> , in inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / gen . py "" , line <number> , in run yielded = self . gen . send ( value ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipykernel / kernelbase . py "" , line <number> , in process_one yield gen . maybe_future ( dispatch ( * args ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / gen . py "" , line <number> , in wrapper yielded = next ( result ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipykernel / kernelbase . py "" , line <number> , in dispatch_shell yield gen . maybe_future ( handler ( stream , idents , msg ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / gen . py "" , line <number> , in wrapper yielded = next ( result ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipykernel / kernelbase . py "" , line <number> , in execute_request self . do_execute ( file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / gen . py "" , line <number> , in wrapper yielded = next ( result ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipykernel / ipkernel . py "" , line <number> , in do_execute res = shell . run_cell ( code , store_history = store_history , silent = silent ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipykernel / zmqshell . py "" , line <number> , in run_cell return super ( zmqinteractiveshell , self ) . run_cell ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipython / core / interactiveshell . py "" , line <number> , in run_cell result = self . _run_cell ( file "" / usr / local / lib / python3 . <number> / dist - packages / ipython / core / interactiveshell . py "" , line <number> , in _run_cell return runner ( coro ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipython / core / async_helpers . py "" , line <number> , in _pseudo_sync_runner coro . send ( none ) file "" / usr / local / lib / python3 . <number> / dist - packages / ipython / core / interactiveshell . py "" , line <number> , in run_cell_async has_raised = await self . run_ast_nodes ( code_ast . body , cell_name , file "" / usr / local / lib / python3 . <number> / dist - packages / ipython / core / interactiveshell . py "" , line <number> , in run_ast_nodes if ( await self . run_code ( code , result , async_ = asy ) <sad> file "" / usr / local / lib / python3 . <number> / dist - packages / ipython / core / interactiveshell . py "" , line <number> , in run_code exec ( code_obj , self . user_global_ns , self . user_ns ) file "" < ipython - input - <number> - c0002c3040bd > "" , line <number> , in <module> model . fit ( x_train , y_train , epochs = <number> ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step loss = self . compute_loss ( x , y , y_pred , sample_weight ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in compute_loss return self . compiled_loss ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / compile_utils . py "" , line <number> , in __call__ loss_value = loss_obj ( y_t , y_p , sample_weight = sw ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / losses . py "" , line <number> , in __call__ losses = call_fn ( y_true , y_pred ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / losses . py "" , line <number> , in call return ag_fn ( y_true , y_pred , * * self . _fn_kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / losses . py "" , line <number> , in sparse_categorical_crossentropy return backend . sparse_categorical_crossentropy ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / backend . py "" , line <number> , in sparse_categorical_crossentropy target = cast ( target , ' int64 ' ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / backend . py "" , line <number> , in cast return tf . cast ( x , dtype ) node cast string to int64 is not supported [ [ { { node sparse_categorical_crossentropy / cast } } ] ] [ op : __inference_train_function_469 ] ` ` ` </details>",2
tensorflow/tensorflow,"is there any way to disable remapping optimizer in tensorflow1 . <number> ? # # system information - * centos7 <emphasis> * - * * python <number> * * - * * tensorflow1 . <number> * * - * * cuda10 . <number> * * - * cudnn7 <emphasis> * - * * gpu : p100 * * # # describe the problem i used ` tensorflow . python . client . timeline ` tool in tf1 . x to profile computation graph execution procedure . then i find remapping optimizer fuse matmul , biasadd and elu into _fusedmatmul before graph execution . i also used ` tf . config . optimizer . set_experimental_options ( ) ` to set remapping false but it did not work . i do not known if i used it correctly . # # source code / logs here are my codes : # # # function to set options ` ` ` bash <user> . contextmanager def graph_optimizer_options ( options ) : old_opts = tf . config . optimizer . get_experimental_options ( ) tf . config . optimizer . set_experimental_options ( options ) try : yield finally : tf . config . optimizer . set_experimental_options ( old_opts ) ` ` ` # # # options are here : ` ` ` bash options = { ' constant_folding ' : false , ' layout_optimizer ' : false , ' shape_optimization ' : false , ' remapping ' : false , ' arithmetic_optimization ' : false , ' dependency_optimization ' : false , ' loop_optimization ' : false , ' function_optimization ' : false , ' debug_stripper ' : false , ' disable_model_pruning ' : false , ' scoped_allocator_optimization ' : false , ' pin_to_host_optimization ' : false , ' implementation_selector ' : false , ' auto_mixed_precision ' : false , ' disable_meta_optimizer ' : false , ' min_graph_nodes ' : false } ` ` ` # # # execute computational graph with tf . session ( ) . ` ` ` bash with tf . session ( graph = graph , config = config ) as sess : run_options = tf . compat . v1 . runoptions ( trace_level = tf . compat . v1 . runoptions . full_trace ) run_metadata = tf . compat . v1 . runmetadata ( ) tf . graph_util . import_graph_def ( graph_def , name = "" "" ) <user> . function def _run ( <sad> sess . run ( outputs_name , feed_dict = feed_dict , options = run_options , run_metadata = run_metadata ) start_time = time . time ( ) with graph_optimizer_options ( options ) : print ( tf . config . optimizer . get_experimental_options ( ) ) _run ( ) end_time = time . time ( ) tl = timeline . timeline ( run_metadata . step_stats ) # todo better record meassurement ctf = tl . generate_chrome_trace_format ( ) with open ( tl_saved_path , ' w ' ) as f : f . write ( ctf ) print ( "" finish running on { } , run time : { } "" . format ( device , end_time - start_time ) ) ` ` ` the result of "" tf . config . optimizer . get_experimental_options ( ) "" ` ` ` bash { ' debug_stripper ' : false , ' function_optimization ' : false , ' disable_model_pruning ' : false , ' constant_folding ' : false , ' implementation_selector ' : false , ' pin_to_host_optimization ' : false , ' auto_mixed_precision ' : false , ' disable_meta_optimizer ' : false , ' loop_optimization ' : false , ' scoped_allocator_optimization ' : false , ' dependency_optimization ' : false , ' shape_optimization ' : false , ' remapping ' : false , ' layout_optimizer ' : false , ' arithmetic_optimization ' ` ` ` remapping seem to be false but _fusedmatmul still exist . is there any way to disable remapping optimizer in tensorflow1 . <number> ?",2
tensorflow/tensorflow,"tensorboardx please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : - * * tensorflow installed from ( source or binary ) * * : - * * tensorflow version ( use command below ) * * : - * * python version * * : - * * bazel version ( if compiling from source ) * * : - * * gcc / compiler version ( if compiling from source ) * * : - * * cuda / cudnn version * * : - * * gpu model and memory * * : - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> you can obtain the tensorflow version with python - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" ` ` ` # # # describe the problem describe the problem clearly here . be sure to convey here why it ' s a bug in tensorflow or a feature request . # # # source code / logs include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached . try to provide a reproducible test case that is the bare minimum necessary to generate the problem .",2
tensorflow/tensorflow,"warning : [ w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cudart64_110 . dll ' ; dlerror : cudart64_110 . dll not found ] windows <number> , tf2 . <number> , cuda <number> , cudnn <number> . <details> <summary> click to expand </summary> # # # issue type build / install # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf <number> . <number> # # # custom code no # # # os platform and distribution windows <number> 2 2 h2 # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda = <number> ; cudnn = <number> # # # gpu model and memory nvidia gtx <number> 8 gb vram # # # current behaviour ? ` ` ` shell i did everything like its instructed in <url> but the warning still come up . i need gpu support for my project . but when i just import tensorflow inside my python , the warning come up i am sure <percent> in my conda and my environment path , there is cudart64_110 . dll i tried to reinstall my nvidia drivers , cuda , and my cudnn but it still doesnt work . is there any solution for this ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell conda install - c conda - forge cudatoolkit = <number> cudnn = <number> . <number> python3 - m pip install "" tensorflow < <number> "" python3 - c "" import tensorflow as tf "" ` ` ` # # # relevant log output ` ` ` shell w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cudart64_110 . dll ' ; dlerror not found ` ` ` </details>",2
tensorflow/tensorflow,"is there any way to modify the quantized parameters from the generated tflite model ? # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> ubuntu - tensorflow installation ( pip package or built from source ) : <number> . <number> - tensorflow library ( version , if pip package or github sha , if built from source ) : # # # <number> . code def representative_data_gen ( <sad> for input_value in tf . data . dataset . from_tensor_slices ( train_images ) . batch ( <number> ) . take ( <number> ) [ input_value ] converter = tf . lite . tfliteconverter . from_keras_model ( model ) converter . optimizations = [ tf . lite . optimize . default ] converter . representative_dataset = representative_data_gen converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins_int8 ] tflite_model_quant = converter . convert ( ) i used the above code to generate a fully quantized tflite model . however , all the quantization parameters are set by default so the final accuracy of the tflite mode is a little bit low . so i wonder is there any way to rewrite the quantization parameters by myself . since the integer numbers are stored in the tflite model , i can not modify them easily .",2
tensorflow/tensorflow,"tensorflow lite memory fault * * system information * * - os platform and distribution ( e . g . , linux ubuntu <number> <sad> openharmony aarch64 - tensorflow installed from ( source or binary ) : source - tensorflow version ( or github sha if from source ) v2 . <number> * * provide the text output from tflite_convert * * each time the program runs to the assembly portion of the neonmatrixbatchvectormultiplyaccumulate function in "" tensorflow \ \ lite \ \ kernels \ \ internal \ \ optimized \ \ neon_tensor_utils . cc "" . the program will crash directly and report a memory error",2
tensorflow/tensorflow,[ tf - lite ] is there a way to profile a model ' s inference process when using tflite in python is there a way to profile a model ' s inference process when using tflite in python ？,2
tensorflow/tensorflow,"distribute training bug while using tf . data please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : yes - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : linux ubuntu <number> - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : - * * tensorflow installed from ( source or binary ) * * : [ ngc ] ( <url> - * * tensorflow version ( use command below ) * * : <number> - * * python version * * : <date> - * * bazel version ( if compiling from source ) * * : - * * gcc / compiler version ( if compiling from source ) * * : - * * cuda / cudnn version * * : <number> - * * gpu model and memory * * : a100 8 0 g ( <number> gpus ) - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> you can obtain the tensorflow version with : ` ` ` bash python - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" ` ` ` # # # describe the problem describe the problem clearly here . be sure to convey here why it ' s a bug in tensorflow or a feature request . i am using <number> gpus to train a model with custome dataset generator loader . however , when i am trying to train the model , at the final batch it will throw error as "" invalid_argument : slice index <number> of dimension <number> out of bounds . "" . i tried the same scripts and data with only one gpus and it goes fine . # # # source code / logs include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached . try to provide a reproducible test case that is the bare minimum necessary to generate the problem . the code i uses to train is : ` ` ` val = pd . read_csv ( ' data / val . csv ' ) window_length = <number> feats = <number> def get_lstm_ae_model ( <sad> model = keras . sequential ( ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , batch_input_shape =( none , window_length , feats ) , return_sequences = true , name = ' encoder_1 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' encoder_2 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = false , name = ' encoder_3 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . repeatvector ( window_length , name = ' encoder_decoder_bridge ' ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' decoder_1 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' decoder_2 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' decoder_3 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . timedistributed ( keras . layers . dense ( feats ) ) ) model . compile ( optimizer = keras . optimizers . adam ( learning_rate = <number> ) , loss = "" mse "" ) model . summary ( ) return model <hashtag> distribute </hashtag> training strategy = tf . distribute . mirroredstrategy ( ) print ( ' number of devices : { } ' . format ( strategy . num_replicas_in_sync ) ) batch_size_per_replica = <number> batch_size = batch_size_per_replica * strategy . num_replicas_in_sync with strategy . scope ( <sad> model = get_lstm_ae_model ( ) val_events = [ ] val . groupby ( ' vin ' ) . apply ( lambda x : val_events . append ( x [ [ ' a ' , ' b ' , ' v ' , ' d ' ] ] . values ) ) def val_data_generator ( <sad> # np . random . shuffle ( val_events ) for events in val_events : yield events val_dataset = tf . data . dataset . from_generator ( generator = val_data_generator , output_types = tf . float32 ) def tensor_2_window ( x ) : x = tf . data . dataset . from_tensor_slices ( x ) x = x . window ( <number> , shift = <number> , drop_remainder = true ) x = x . flat_map ( lambda window : window . batch ( <number> ) ) return x val_dataset = val_dataset . flat_map ( tensor_2_window ) val_dataset = val_dataset . map ( lambda window : ( window , window ) ) val_dataset = val_dataset . cache ( ) . batch ( <number> * <number> ) . prefetch ( buffer_size = tf . data . autotune ) history = model . fit ( val_dataset , epochs = <number> , # validation_data = val_dataset ) ` ` ` then after training to the last batch , error apperas : ` ` ` <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - invalidargumenterror traceback ( most recent call last ) cell in [ <number> ] , line <number> - - - - > <number> history = model . fit ( <number> val_dataset , <number> epochs = <number> , <number> # validation_data = val_dataset <number> ) file / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py : <number> , in filter_traceback . <locals> . error_handler ( * args , * * kwargs ) <number> filtered_tb = _process_traceback_frames ( e . __traceback__ ) <number> # to get the full stack trace , call : <number> # ` tf . debugging . disable_traceback_filtering ( ) ` - - - > <number> raise e . with_traceback ( filtered_tb ) from none <number> finally : <number> del filtered_tb file / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / execute . py : <number> , in quick_execute ( op_name , num_outputs , inputs , attrs , ctx , name ) <number> try : <number> ctx . ensure_initialized ( ) - - - > <number> tensors = pywrap_tfe . tfe_py_execute ( ctx . _handle , device_name , op_name , <number> inputs , attrs , num_outputs ) <number> except core . _notokstatusexception as e : <number> if name is not none : invalidargumenterror : graph execution error : detected at node ' replica_5 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step loss = self . compute_loss ( x , y , y_pred , sample_weight ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in compute_loss return self . compiled_loss ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / compile_utils . py "" , line <number> , in __call__ batch_dim = tf . shape ( y_t ) [ <number> ] node : ' replica_5 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' <number> root error ( s ) found . ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_5 / strided_slice } } ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_6 / mean_squared_error / cond / else / _189 / replica_6 / mean_squared_error / cond / remove_squeezable_dimensions / equal / _385 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_4 / mean_squared_error / cond / else / _139 / replica_4 / mean_squared_error / cond / remove_squeezable_dimensions / equal / _377 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_1 / strided_slice / _296 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_1 / mean_squared_error / cond / then / _63 / replica_1 / mean_squared_error / cond / cond / then / _690 / replica_1 / mean_squared_error / cond / cond / remove_squeezable_dimensions / cond / pivot_t / _1455 / _729 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ gradient_tape / replica_7 / mean_squared_error / cond / statelessif / pivot_f / _228 / _346 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ div_no_nan / readvariableop_8 / _916 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ func / replica_2 / mean_squared_error / cond / else / _89 / replica_2 / mean_squared_error / cond / remove_squeezable_dimensions / cond / else / _742 / input / _1165 / _468 ] ] ( <number> ) invalid_argument index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] <number> successful operations . <number> derived errors ignored . [ op : __inference_train_function_112593 ] ` ` `",2
tensorflow/tensorflow,"did not find op for builtin opcode reverse_v2 version ' <number> ' . * * system information * * - linux - tensorflow installed from source : - tensorflow version * * provide the text output from tflite_convert * * ` ` ` testing testinvoke did not find op for builtin opcode ' reverse_v2 ' version ' <number> ' . an older version of this builtin might be supported . are you using an old tflite binary with a newer model ? failed to get registration from op code reverse_v2 ` ` ` * * standalone code to reproduce the issue * * when i want to invoke use tflite - micro , got a error testinvoke did not find op for builtin opcode ' reverse_v2 ' version ' <number> ' . an older version of this builtin might be supported . are you using an old tflite binary with a newer model ? failed to get registration from op code reverse_v2 can you tell me the reason ？ thanks",2
tensorflow/tensorflow,"tensor_util . py <details> <summary> click to expand </summary> # # # issue type bug # # # source source # # # tensorflow version tf . <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device windows <number> # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell a bug happened ! please refer "" / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / framework / tensor_util . py "" line <number> , in make_tensor_proto shape = [ int ( dim ) for dim in shape ] gives error . it is not possible to iterate with integer . needs to be fixed . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <url> it is eilertsen ' s hdrcnn work from <number> . i try to rewrite the code ; i try to rewrite the code in version <number> tensorflow . as described above i absorved the bug . ` ` ` # # # relevant log output ` ` ` shell typeerror object is not iterable ` ` ` </details>",2
tensorflow/tensorflow,"how do i convert input arg tf . string to string in tf . function <user> . function ( input_signature =[ tf . tensorspec ( shape =[] , dtype = tf . string , name = "" key "" ) , tf . tensorspec ( shape =[] , dtype = tf . string , name = "" value "" ) ] ) def infer ( self , key , value ) : tf . print ( key ) x <elongated> i want to implement universal input , something like this key : age <hashtag> gender </hashtag> value => age_tensor = tf . constant ( value = <number> , name = "" age "" ) gender_tensor = tf . constant ( value = <number> , name = "" gender "" ) so i want to convert tf . string to string . use tf . print function can normally print the input args ， do i have any way to simulate the function of tf . print and assign the printed value to a variable to implement tf . string to string ? or is there any other way i can do this ?",2
tensorflow/tensorflow,"gpus only visible for administrators <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version <number> # # # custom code no # # # os platform and distribution windows server <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> . <number> / <number> . <number> # # # gpu model and memory nvidia rtx a5000 # # # current behaviour ? ` ` ` shell when executing tf . config . list_physical_devices ( ) , tensorflow returns a list with all installed gpus only when executed by an admin . standard user accounts see only cpu devices . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf print ( tf . config . list_physical_devices ( ) ) ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"training with null data in tflite model maker <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version tf <number> . <number> / tflite <number> . <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell when training with tflite model maker , i am wondering if this the training algorithm uses null data samples ( i . e . images with no annotations ) for training or if this data is simply ignored ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell na ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"cannot make use of gpu <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version v2 . <number> - rc2 - <number> - gd5b57ca93e5 # # # custom code yes # # # os platform and distribution linux manjaro <date> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory rtx <number> # # # current behaviour ? ` ` ` shell cannot make use of the gpu when trying to use this app ( <url> ) . i changed the code to test the tensorflow lib and i followed all the steps mentioned here : <url> . still not working . including a test script below , to see what i mean . i tried installing all the packages about tf and cuda . both on my machine and on the conda env ( or pip ) . any ideas how to solve this ? thank you . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell # ! / usr / bin / env python3 import tensorflow as tf import sys import os import yaml print ( "" num gpus available : "" , len ( tf . config . list_physical_devices ( ' gpu ' ) ) ) cuda_devices = os . getenv ( ' cuda_visible_devices ' ) print ( "" cuda_devices "" , cuda_devices ) if cuda_devices is none : os . unsetenv ( ' cuda_visible_devices ' ) else : os . putenv ( ' cuda_visible_devices ' , cuda_devices ) try : import mediapipe as mp classifier = mp . solutions . selfie_segmentation . selfiesegmentation ( model_selection = <number> ) has_mediapipe = true except importerror : has_mediapipe = false ` ` ` # # # relevant log output ` ` ` shell python . / virtual_webcam . py <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libnvinfer . so . <number> ' ; dlerror : libnvinfer . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path : <annoyed> home / antouank / . conda / envs / virtual - webcam / lib / <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libnvinfer_plugin . so . <number> ' ; dlerror : libnvinfer_plugin . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path : <annoyed> home / antouank / . conda / envs / virtual - webcam / lib / <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . num gpus available : <number> cuda_devices none info tensorflow lite xnnpack delegate for cpu . ` ` ` </details>",2
tensorflow/tensorflow,"how to get single unidirectionalsequencernnop in tflite model # # # issue type support # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution ubuntu <number> according to <url> there is ` kunidirectionalsequencernnop ` as a single operation in tflite , could you give a python code example - how can i get this ? for example - this code for lstm gives tflite with one unidirectionalsequencelstm op . ` ` ` py # note tested with tf <number> . <number> import tensorflow as tf import numpy as np from tensorflow import keras model = keras . sequential ( ) shape = ( <number> , <number> ) model . add ( keras . layers . inputlayer ( input_shape = shape , batch_size = <number> ) ) model . add ( keras . layers . lstm ( <number> , input_shape = shape ) ) ` ` ` [ image ] ( <url> how can i do same for unidirectionalsequencernn ?",2
tensorflow/tensorflow,"oom out of memory mask rcnn <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i want to do a train for mask rcnn using tensorflow <number> . i am using a gtx <number> ti . i am using cuda <number> and cudnn <number> . <number> versions . i am getting an oom error . code of my config file class damageconfig ( config ) : # define the name of the configuration name = "" damage "" # number of classes ( background + damge classes ) num_classes = <number> + <number> # number of training steps per epoch steps_per_epoch = <number> # learning rate and momentum # regularization penalty batch_size = <number> # validation steps validation_steps = <number> # rpn acnhor scales and ratios to find roi # prepare train dataset . train_set = damagedataset ( ) # change the dataset train_set . load_dataset ( "" c <annoyed> users / hasan / maskcuda / dataset "" , "" train "" ) train_set . prepare ( ) # prepare validation / test dataset test_set = damagedataset ( ) test_set . load_dataset ( "" c <annoyed> users / hasan / maskcuda / dataset "" , "" val "" ) test_set . prepare ( ) # load damage config config = damageconfig ( ) # define the model model = maskrcnn ( mode = ' training ' , model_dir ='. / ' , config = config ) # load weights mscoco model weights weights_path = ' c <annoyed> users / hasan / maskcuda / mask_rcnn / mask_rcnn_coco . h5 ' config = tensorflow . configproto ( ) config . gpu_options . allow_growth = true sess = tensorflow . session ( config = config ) # load the model weights model . load_weights ( weights_path , by_name = true , exclude =[ "" mrcnn_class_logits "" , "" mrcnn_bbox_fc "" , "" mrcnn_bbox "" , "" mrcnn_mask "" ] ) # start the training of model # you can change epochs and layers ( head or all ) model . train ( train_set , test_set , learning_rate = config . learning_rate , epochs = <number> , layers = ' heads ' ) ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / bfc_allocator . cc : <number> ] <number> chunks of size <number> totalling <number> . 1 4 mib <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / bfc_allocator . cc : <number> ] <number> chunks of size <number> totalling <number> . 0 0 mib <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / bfc_allocator . cc : <number> ] <number> chunks of size <number> totalling <number> . 0 0 mib <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / bfc_allocator . cc : <number> ] <number> chunks of size <number> totalling <number> . 4 6 mib <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / bfc_allocator . cc : <number> ] sum total of in - use chunks : <number> . 8 1 gib <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / bfc_allocator . cc : <number> ] total_region_allocated_bytes_ : <phone> memory_limit_ : <phone> available bytes : <number> curr_region_allocation_bytes_ : <phone> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / bfc_allocator . cc : <number> ] stats : limit : <phone> inuse : <phone> maxinuse : <phone> numallocs : <number> maxallocsize : <phone> resourceexhaustederror : <number> root error ( s ) found . ( <number> ) resource exhausted : oom when allocating tensor with shape [ <number> , <number> ] and type float on / job : localhost / replica : <number> / task : <number> / device : gpu : <number> by allocator gpu_0_bfc [ [ { { node conv1_6 / convolution } } ] ] hint : if you want to see a list of allocated tensors when oom happens , add report_tensor_allocations_upon_oom to runoptions for current allocation info . [ [ proposal_targets_6 / strided_slice_17 / _28717 ] ] hint you want to see a list of allocated tensors when oom happens , add report_tensor_allocations_upon_oom to runoptions for current allocation info . ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,tensorflow <number> is still using cuda <number> + cudnn <number> that were released <number> years ago <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell tensorflow <number> is still using cuda <number> + cudnn <number> that were released <number> years ago this makes our stack have to use the old cuda / cudnn without new features . is it possible to make new tf version work with newest cuda / cudnn ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell n / a ` ` ` # # # relevant log output _no response_ </details>,2
tensorflow/tensorflow,"mirroredstrategy error invalid_argument : slice index <number> of dimension <number> out of bounds when training a model , most related to batch size strategy across all gpus please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : yes - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : linux ubuntu <number> - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : - * * tensorflow installed from ( source or binary ) * * : [ ngc ] ( <url> - * * tensorflow version ( use command below ) * * : <number> - * * python version * * : <date> - * * bazel version ( if compiling from source ) * * : - * * gcc / compiler version ( if compiling from source ) * * : - * * cuda / cudnn version * * : <number> - * * gpu model and memory * * : a100 8 0 g ( <number> gpus ) - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> you can obtain the tensorflow version with : ` ` ` bash python - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" ` ` ` # # # describe the problem describe the problem clearly here . be sure to convey here why it ' s a bug in tensorflow or a feature request . i am using <number> gpus to train a model with custome dataset generator loader . however , when i am trying to train the model , at the final batch it will throw error as "" invalid_argument : slice index <number> of dimension <number> out of bounds . "" . i tried the same scripts and data with only one gpus and it goes fine . # # # source code / logs include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached . try to provide a reproducible test case that is the bare minimum necessary to generate the problem . the code i uses to train is : ` ` ` val = pd . read_csv ( ' data / val . csv ' ) window_length = <number> feats = <number> def get_lstm_ae_model ( <sad> model = keras . sequential ( ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , batch_input_shape =( none , window_length , feats ) , return_sequences = true , name = ' encoder_1 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' encoder_2 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = false , name = ' encoder_3 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . repeatvector ( window_length , name = ' encoder_decoder_bridge ' ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' decoder_1 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' decoder_2 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . lstm ( <number> , kernel_initializer = ' he_uniform ' , return_sequences = true , name = ' decoder_3 ' ) ) model . add ( keras . layers . dropout ( <number> ) ) model . add ( keras . layers . timedistributed ( keras . layers . dense ( feats ) ) ) model . compile ( optimizer = keras . optimizers . adam ( learning_rate = <number> ) , loss = "" mse "" ) model . summary ( ) return model <hashtag> distribute </hashtag> training strategy = tf . distribute . mirroredstrategy ( ) print ( ' number of devices : { } ' . format ( strategy . num_replicas_in_sync ) ) batch_size_per_replica = <number> batch_size = batch_size_per_replica * strategy . num_replicas_in_sync with strategy . scope ( <sad> model = get_lstm_ae_model ( ) val_events = [ ] val . groupby ( ' vin ' ) . apply ( lambda x : val_events . append ( x [ [ ' a ' , ' b ' , ' v ' , ' d ' ] ] . values ) ) def val_data_generator ( <sad> # np . random . shuffle ( val_events ) for events in val_events : yield events val_dataset = tf . data . dataset . from_generator ( generator = val_data_generator , output_types = tf . float32 ) def tensor_2_window ( x ) : x = tf . data . dataset . from_tensor_slices ( x ) x = x . window ( <number> , shift = <number> , drop_remainder = true ) x = x . flat_map ( lambda window : window . batch ( <number> ) ) return x val_dataset = val_dataset . flat_map ( tensor_2_window ) val_dataset = val_dataset . map ( lambda window : ( window , window ) ) val_dataset = val_dataset . cache ( ) . batch ( <number> * <number> ) . prefetch ( buffer_size = tf . data . autotune ) history = model . fit ( val_dataset , epochs = <number> , # validation_data = val_dataset ) ` ` ` then after training to the last batch , error apperas : ` ` ` <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at strided_slice_op . cc : <number> : invalid_argument : slice index <number> of dimension <number> out of bounds . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - invalidargumenterror traceback ( most recent call last ) cell in [ <number> ] , line <number> - - - - > <number> history = model . fit ( <number> val_dataset , <number> epochs = <number> , <number> # validation_data = val_dataset <number> ) file / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py : <number> , in filter_traceback . <locals> . error_handler ( * args , * * kwargs ) <number> filtered_tb = _process_traceback_frames ( e . __traceback__ ) <number> # to get the full stack trace , call : <number> # ` tf . debugging . disable_traceback_filtering ( ) ` - - - > <number> raise e . with_traceback ( filtered_tb ) from none <number> finally : <number> del filtered_tb file / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / execute . py : <number> , in quick_execute ( op_name , num_outputs , inputs , attrs , ctx , name ) <number> try : <number> ctx . ensure_initialized ( ) - - - > <number> tensors = pywrap_tfe . tfe_py_execute ( ctx . _handle , device_name , op_name , <number> inputs , attrs , num_outputs ) <number> except core . _notokstatusexception as e : <number> if name is not none : invalidargumenterror : graph execution error : detected at node ' replica_5 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step loss = self . compute_loss ( x , y , y_pred , sample_weight ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in compute_loss return self . compiled_loss ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / compile_utils . py "" , line <number> , in __call__ batch_dim = tf . shape ( y_t ) [ <number> ] node : ' replica_5 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' detected at node ' replica_3 / sequential / encoder_1 / strided_slice ' defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / sequential . py "" , line <number> , in call return super ( ) . call ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in __call__ return super ( ) . __call__ ( inputs , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / lstm . py "" , line <number> , in call inputs , initial_state , _ = self . _process_inputs ( file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in _process_inputs initial_state = self . get_initial_state ( inputs ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / layers / rnn / base_rnn . py "" , line <number> , in get_initial_state batch_size = input_shape [ <number> ] if self . time_major else input_shape [ <number> ] node : ' replica_3 / sequential / encoder_1 / strided_slice ' <number> root error ( s ) found . ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_5 / strided_slice } } ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_6 / mean_squared_error / cond / else / _189 / replica_6 / mean_squared_error / cond / remove_squeezable_dimensions / equal / _385 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_4 / mean_squared_error / cond / else / _139 / replica_4 / mean_squared_error / cond / remove_squeezable_dimensions / equal / _377 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_1 / strided_slice / _296 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ replica_1 / mean_squared_error / cond / then / _63 / replica_1 / mean_squared_error / cond / cond / then / _690 / replica_1 / mean_squared_error / cond / cond / remove_squeezable_dimensions / cond / pivot_t / _1455 / _729 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ gradient_tape / replica_7 / mean_squared_error / cond / statelessif / pivot_f / _228 / _346 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ div_no_nan / readvariableop_8 / _916 ] ] ( <number> ) invalid_argument : slice index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] [ [ func / replica_2 / mean_squared_error / cond / else / _89 / replica_2 / mean_squared_error / cond / remove_squeezable_dimensions / cond / else / _742 / input / _1165 / _468 ] ] ( <number> ) invalid_argument index <number> of dimension <number> out of bounds . [ [ { { node replica_3 / sequential / encoder_1 / strided_slice } } ] ] <number> successful operations . <number> derived errors ignored . [ op : __inference_train_function_112593 ] ` ` `",2
tensorflow/tensorflow,"cannot convert handwriting recognition model to tflite model # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> windows <number> - tensorflow installation ( pip package or built from source ) : pip install "" tensorflow < <number> "" - tensorflow library ( version , if pip package or github sha , if built from source ) : <number> . <number> - python <number> # # # <number> . code used the code from the tutorial on this page : <url> and at the end tried converting the prediction model to a tf lite model using following code : ` ` ` converter = tf . lite . tfliteconverter . from_keras_model ( prediction_model ) tflite_float_model = converter . convert ( ) ` ` ` and then i get the following error : [ error_log_1 . txt ] ( <url> which basically says that i need to set supported_ops flags . first of all , is there any way i can prevent that ? i do not understand what function in the code is using select tensorflow core operators , i do not want to be using any select tensorflow core operators since it makes it creates other problems . and then when i do set these flags : ` ` ` converter = tf . lite . tfliteconverter . from_keras_model ( prediction_model ) converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins , tf . lite . opsset . select_tf_ops ] converter . _experimental_lower_tensor_list_ops = false converter . optimizations = [ tf . lite . optimize . default ] tflite_float_model = converter . convert ( ) ` ` ` then i get the following messages , which i am not sure if these are indicating if something ' s gone wrong or not : [ error_log_2 . txt ] ( <url> and export the model and import it in my android project using these instructions : <url> on android i then convert the model file to byte buffer and try to pass it to tf lite interpreter as follows : ` ` ` val filedescriptor = context . assets . openfd ( filename ) val inputstream = fileinputstream ( filedescriptor . filedescriptor ) val filechannel = inputstream . channel val startoffset = filedescriptor . startoffset val declaredlength = filedescriptor . declaredlength val bytebuffer = filechannel . map ( filechannel . mapmode . read_only , startoffset , declaredlength ) val interpreter = org . tensorflow . lite . interpreter ( bytebuffer ) ` ` ` i then get a illegalargumentexception with following message bytebuffer should be either a mappedbytebuffer of the model file , or a direct bytebuffer using byteorder . nativeorder ( ) which contains bytes of model content . "" ` i think there is something wrong with the exported tf lite model file . best solution would probably be to avoid using select tf operators , would really like to avoid it if possible . would appreciate your help",2
tensorflow/tensorflow,"tf . numpy_function in tf . data . dataset . map causes cuda_error_out_of_memory after hundreds of epochs # # # issue type bug # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version <number> . <number> # # # gcc / compiler version gcc <number> . <number> # # # cuda / cudnn version <number> / <number> . <number> # # # gpu model and memory nvidia quadro rtx <number> , <number> . 8 g memory # # # current behaviour ? ` ` ` shell i use ` tf . data . dataset ` for my input pipeline as follows : <number> . ` from_generator ` <number> . ` cache ` <number> . ` shuffle ` <number> . ` repeat ` <number> . ` map ` <number> . ` batch ` <number> . ` prefetch ` the step <number> call a data - augmentation function where there is a call to ` tf . numpy_function ` which wraps ` scipy . ndimage . rotate ` . after a variable number of epochs ( in general more than <number> ) , a ` cuda_out_of_memory ` appears and the kernel crashed . if i remove the call to ` tf . numpy_function ` from the data - augmentation function , i do not have this problem . note that i do not use ` tf . py_function ` as it looks much slower . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell i have not managed to create a simple reproducer for this bug . ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : e tensorflow / stream_executor / cuda / cuda_driver . cc : <number> ] failed to alloc <number> bytes on host : cuda_error_out_of_memory : out of memory <number> - <number> - <number> <time> . <number> : w . / tensorflow / core / common_runtime / device / device_host_allocator . h : <number> ] could not allocate pinned host memory of size ` ` `",2
tensorflow/tensorflow,"how to write to input tensors in custom op ? <details> <summary> click to expand </summary> # # # issue type others # # # source binary # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell how can i write to input tensors in a custom op ? i can read and write to output tensors but only read on inputs . ( compiling outputs "" assignment of read - only location "" error when trying to write to input tensor ) . i want to write an inplace op , and making it inplace is crucial for my project , as writting the results to an output tensor and then assigning the output to the variable is too slow ) . here is a minimal example that just sets the input tensor to zero . what code can i add to this example code so that i can be able to write to the input tensor ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <hashtag> include </hashtag> "" tensorflow / core / framework / op . h "" <hashtag> include </hashtag> "" tensorflow / core / framework / shape_inference . h "" <hashtag> include </hashtag> "" tensorflow / core / framework / op_kernel . h "" <hashtag> include </hashtag> "" tensorflow / core / util / work_sharder . h "" <hashtag> include </hashtag> <iostream> using namespace tensorflow ; register_op ( "" example "" ) . input ( "" variable : float "" ) ; class exampleop : public opkernel { public : explicit exampleop ( opkernelconstruction * context ) : opkernel ( context ) { } void compute ( opkernelcontext * context ) override { const tensor & variable_tensor = context - > input ( <number> ); auto variable = variable_tensor . flat <float> (); for ( int i = <number> ; i < variable . size ( ); + + i ) variable ( i ) = <number> ; }; }; register_kernel_builder ( name ( "" example "" ) . device ( device_cpu ) , exampleop ) ; ` ` ` # # # relevant log output ` ` ` shell minimal . cc : in member function ‘ virtual void exampleop : : compute ( tensorflow : : opkernelcontext <wink> ’ : minimal . cc : <time> : error of read - only location ‘ variable . eigen : : tensormap < eigen : : tensor < const float , <number> , <number> , long int > , <number> , eigen : : makepointer > : : operator ( ) ( ( ( eigen : : tensormap < eigen : : tensor < const float , <number> , <number> , long int > , <number> , eigen : : makepointer > : : index ) i ) ) ’ <number> | variable ( i ) = <number> ; | ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ^ ~ ~ ` ` ` </details>",2
tensorflow/tensorflow,"protobuf package dependency between google ads and tensorflow <details> <summary> click to expand </summary> # # # issue type support # # # source binary # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell hello , would you be so kind to fix tensorflow <number> . <number> depends on protobuf < <number> and >= <number> . <number> to be more relevant to the google ads package which uses protobuf = = <number> . <number> ` ` ` # # # standalone code to reproduce the issue ` ` ` shell protobuf = = <number> . <number> google - ads = = <number> . <number> tensorflow = = <number> . <number> google - api - core = = <number> . <number> googleapis - common - protos = = <number> . <number> ` ` ` # # # relevant log output ` ` ` shell the conflict is caused by user requested protobuf = = <number> . <number> google - ads <number> . <number> depends on protobuf > = <number> . <number> google - api - core <number> . <number> depends on protobuf < <number> . 0 dev and >= <number> . <number> googleapis - common - protos <number> . <number> depends on protobuf < <number> . 0 dev and >= <number> . <number> tensorflow <number> . <number> depends on protobuf < <number> and >= <number> . <number> ` ` ` </details>",2
tensorflow/tensorflow,"how to set the half_pixel_centers of resizebilinear to false in the . tflite ? # # # <number> . system information - os platform and distribution ( linux ubuntu <number> <sad> hi , i convert the model from pytorch into tflite ： pytorch = <number> ( . pth ) - > onnx = <number> ( . onnx ) - > tensorflow = <number> ( . tflite ) i find the half_pixel_centers of the resizebilinear operator is true , but i need this option to be false . how can i set the half_pixel_centers to false during model convert ? [ image ] ( <url> i try to set the half_pixel_centers to false , when parsing the onnx model , and converting it into keras model : - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - def keras_builder ( onnx_model , new_input_nodes : list = none , new_output_nodes : list = none ) : model_graph = onnx_model . graph ' ' ' init onnx model ' s build - in tensors ' ' ' onnx_weights = dict ( ) for initializer in model_graph . initializer : onnx_weights [ initializer . name ] = numpy_helper . to_array ( initializer ) ' ' ' build input nodes ' ' ' tf_tensor , input_shape = { } , [ ] for inp in model_graph . input : input_shape = [x . dim_value for x in inp . type . tensor_type . shape . dim ] if input_shape = = []: continue batch_size = <number> if input_shape [ <number> ] <= <number> else input_shape [ <number> ] input_shape = input_shape [ <number> <happy> + input_shape [ <number> : <number> ] tf_tensor [ inp . name ] = keras . input ( shape = input_shape , batch_size = batch_size ) ' ' ' build model inline node by iterate onnx nodes . ' ' ' input_node_names , outputs_node_names = [ ] , [ ] for node in model_graph . node : op_name , node_inputs , node_outputs , node_name = node . op_type , node . input , node . output , node . name op_attr = decode_node_attribute ( node ) <hashtag> print </hashtag> ( "" opt name { } , opt { } "" . format ( op_name , op_attr ) ) tf_operator = operator . get ( op_name ) if ( op_name = = "" resize "" <sad> print ( tf_operator ) op_attr [ ' pytorch_half_pixel ' ] = false if tf_operator is none : raise keyerror ( f "" { op_name } not implemented yet "" ) _inputs = none if len ( node_inputs ) > <number> : _inputs = tf_tensor [ node_inputs [ <number> ] ] if node_inputs [ <number> ] in tf_tensor else onnx_weights [ node_inputs [ <number> ] ] for index in range ( len ( node_outputs ) <sad> tf_tensor [ node_outputs [ index ] ] = tf_operator ( tf_tensor , onnx_weights , node_inputs , op_attr , index = index ) ( _inputs ) if ( op_name = = "" resize "" <sad> print ( tf_operator ( tf_tensor , onnx_weights , node_inputs , op_attr , index = index ) ( _inputs ) ) ' ' ' reorganize input and output nodes ' ' ' if new_input_nodes is not none and node_name in new_input_nodes : input_node_names . append ( node_outputs [ <number> ] ) # todo for nodes with multiply outputs . if new_output_nodes is not none and node_name in new_output_nodes : outputs_node_names . append ( node_outputs [ <number> ] ) if new_output_nodes is not none and len ( outputs_node_names ) = = len ( new_output_nodes ) : break ' ' ' process input and output nodes ' ' ' input_nodes = [ ] if new_input_nodes is none : input_nodes = [ tf_tensor [ x . name ] for x in model_graph . input ] else : for node in model_graph . input : if node . name in new_input_nodes : input_node_names . append ( node . name ) input_nodes = [ tf_tensor [ x] for x in input_node_names ] outputs_nodes = [ ] if new_output_nodes is none : outputs_nodes = [ tf_tensor [ x . name ] for x in model_graph . output ] else : for node in model_graph . output : if node . name in new_output_nodes : outputs_node_names . append ( node . name ) outputs_nodes = [ tf_tensor [ x] for x in outputs_node_names ] ' ' ' build keras model ' ' ' keras_model = keras . model ( inputs = input_nodes , outputs = outputs_nodes ) keras_model . trainable = false # keras_model . summary ( ) return keras_model - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - keras_model = keras_builder ( model_proto , input_node_names , output_node_names ) print ( "" build keras model done "" ) # set resize half_pixel_centers = false ind = <number> for layer in keras_model . layers : <hashtag> print </hashtag> ( layer . name ) if ( "" resize "" in layer . name ) or ( "" resize "" in layer . name ) keras_model . layers [ ind ] . half_pixel_centers = false print ( keras_model . layers [ ind ] . half_pixel_centers ) ind + = <number> but when converting keras to tflite model by tf . lite . tfliteconverter . from_keras_model ( keras_model ) , the half_pixel_centers is still true .",2
tensorflow/tensorflow,"is there a way to use a tflite - runtime version higher than <number> . <number> on an armv7 development board # # # <number> . system information - linux ubuntu <number> - armv7 board - python3 . <number> # # # <number> . question description i trained a model on my linux server * *( ubuntu18 . <number> ， intel ( r ) xeon ( r ) w - <number> cpu ) * * and exported it to tflite mode , and the model on the server * *( tflite - runtime = <number> . <number> )* * works fine . now i want to run the model on an * armv7 <emphasis> * development board of zynq7000 . the operating system running on my board version is ubuntu18 . <number> , and * * python3 . <number> * * and * * tflite - runtime = <number> . <number> * * is installed ( <number> . <number> seems is the highest version i can get on armv7 ) , but when i run ` interpreter = tflite . interpreter ( model_path = my_model ) ` , it throws ` segmentation fault ( core dumped ) ` error . after my test , if i downgrade the tflite - runtime on my linux server to version <number> . <number> , the same error will be thrown . so i think the reason for the error may be that the version of tflite - runtime is too low . but i can not get a higher version of tflite - runtime on armv7 board , does anyone know a solution please ?",2
tensorflow/tensorflow,"failed to load the native tensorflow runtime . please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : - * * tensorflow installed from ( source or binary ) * * : - * * tensorflow version ( use command below ) * * : - * * python version * * : - * * bazel version ( if compiling from source ) * * : - * * gcc / compiler version ( if compiling from source ) * * : - * * cuda / cudnn version * * : - * * gpu model and memory * * : - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> you can obtain the tensorflow version with python - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" ` ` ` # # # describe the problem describe the problem clearly here . be sure to convey here why it ' s a bug in tensorflow or a feature request . # # # source code / logs include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached . try to provide a reproducible test case that is the bare minimum necessary to generate the problem .",2
tensorflow/tensorflow,"tflite benchmark tool - example to use input_layer_value_files please go to stack overflow for help and support : <url> if you open a github issue , here is our policy : <number> . it must be a bug , a feature request , or a significant problem with the documentation ( for small docs fixes please send a pr instead ) . <number> . the form below must be filled out . <number> . it should not be a tensorboard issue . those go [ here ] ( <url> * * here ' s why we have that policy * * : tensorflow developers respond to issues . we want to focus on work that benefits the whole community , e . g . , fixing bugs and adding features . support only helps individuals . github also notifies thousands of people when issues are filed . we want them to see you communicating an interesting problem , rather than being redirected to stack overflow . - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * have i written custom code ( as opposed to using a stock example script provided in tensorflow ) * * : no - * * os platform and distribution ( e . g . , linux ubuntu <number> )* * : ubuntu <number> - * * mobile device ( e . g . iphone <number> , pixel <number> , samsung galaxy ) if the issue happens on a mobile device * * : - * * tensorflow installed from ( source or binary ) * * : source - * * tensorflow version ( use command below ) * * : - * * python version * * : - * * bazel version ( if compiling from source ) * * : - * * gcc / compiler version ( if compiling from source ) * * : - * * cuda / cudnn version * * : - * * gpu model and memory * * : - * * exact command to reproduce * * : you can collect some of this information using our environment capture script : <url> you can obtain the tensorflow version with python - c "" import tensorflow as tf ; print ( tf . version . git_version , tf . version . version ) "" ` ` ` # # # describe the problem i am trying to use the android tflite benchmark tool to run inference time analysis for my tflite model . going through the [ repo ] ( <url> i am interested in passing custom inputs to the benchmark tool . i am specifically looking for how to use input_layer_value_files flag . could you provide an example of a sample file ? thanks # # # source code / logs -",2
tensorflow/tensorflow,"inputspec update breaks working code description : i am running code that used to work before a tensorflow / keras update . it is not obvious how the error message can be used to fix the problem , here is code , error and system information . thanks for your help . import numpy as np import matplotlib . pyplot as plt import pandas as pd from sklearn . preprocessing import minmaxscaler # importing the training set dataset_train = pd . read_csv ( ' google_stock_price_train . csv ' ) training_set = dataset_train . iloc [ :, <number> : <number> ] . values # feature scaling sc = minmaxscaler ( feature_range = ( <number> , <number> ) ) training_set_scaled = sc . fit_transform ( training_set ) # creating a data structure with <number> timesteps and <number> output x_train = [ ] y_train = [ ] window_size = <number> for i in range ( window_size , training_set_scaled . size ) : x_train . append ( training_set_scaled [ i - window_size : i , <number> ] ) y_train . append ( training_set_scaled [ i , <number> ] ) x_train , y_train = np . array ( x_train ) , np . array ( y_train ) # reshaping - where you will add features . <repeated> also for compatibility later x_train = np . reshape ( x_train , (x _train . shape [ <number> ] , x_train . shape [ <number> ] , <number> ) ) # importing the keras libraries and packages from keras . models import sequential from keras . layers import dense from keras . layers import lstm from keras . layers import dropout from keras . engine . input_spec import inputspec # initialising the rnn regressor = sequential ( ) # adding the first lstm layer and some dropout regularization regressor . add ( lstm ( units = <number> , return_sequences = true , input_shape = (x _train . shape [ <number> ] , <number> ) ) ) <hashtag> error </hashtag> : traceback ( most recent call last ) : file "" c :\\ users \ \* * *\\ appdata \ \ local \ \ temp \ \ ipykernel_28784 \ \ <phone> . py "" , line <number> , in <module> regressor . add ( lstm ( units = <number> , return_sequences = true , input_shape = (x _train . shape [ <number> ] , <number> ) ) ) file "" c :\\ programdata \ \ anaconda3 \ \ envs \ \ tf \ \ lib \ \ site - packages \ \ keras \ \ layers \ \ rnn \ \ lstm . py "" , line <number> , in __init__ "" ` implementation = <number> ` has been deprecated , "" file "" c :\\ programdata \ \ anaconda3 \ \ envs \ \ tf \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ base_layer . py "" , line <number> , in __setattr__ outputs = tf . nest . pack_sequence_as ( outputs , outputs_copy ) file "" c :\\ programdata \ \ anaconda3 \ \ envs \ \ tf \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ trackable \ \ base . py "" , line <number> , in _method_wrapper result = method ( self , * args , * * kwargs ) file "" c :\\ programdata \ \ anaconda3 \ \ envs \ \ tf \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ base_layer . py "" , line <number> , in input_spec typeerror : layer input_spec must be an instance of inputspec . got : inputspec ( ndim = <number> ) - - - - - - - - - - - - - - - - - - - - - - - - # # # system information - * * os : windows <number> * * : - * * tensorflow installed from ( pip install per instructions here : <url> - * * tensorflow version ( <number> . <number> )* * : - * * python version <date> * * : - * * cuda / cudnn version cudatoolkit = <number> cudnn = <number> . <number> * * : - * * gpu model and memory rtx <number> * * * * exact command to reproduce * * :",2
tensorflow/tensorflow,"trying to train transformer like the nmt keras transformer , for passage summarization task . the model ' s masked accuracy goes upto ~ <percent> but the transformer ' s output is very poor . could you help me understand what i might be doing wrong ? <details> <summary> click to expand </summary> # # # issue type performance # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell nmt task on the keras transformer as showed in the tutorials ( <url> performs well . but i am unable to get decent performance on a passage summarization task on the ` cnn_dailymail ` dataset . i can not understand what i might be doing wrong . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <url> ` ` ` # # # relevant log output _no response_ </details>",2
tensorflow/tensorflow,"no matching distribution found for numba = = <number> <details> <summary> click to expand </summary> # # # issue type support # # # source binary # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution linux ubuntu <number> # # # mobile device n / a # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell excessive version dependencies for tflite - model - maker ` ` ` # # # standalone code to reproduce the issue ` ` ` shell dependency errors even with the following statement : python3 - m pip install - q - - use - deprecated = legacy - resolver tflite - model - maker ` ` ` # # # relevant log output ` ` ` shell using cached neural_structured_learning - <number> . <number> - py2 . py3 - none - any . whl ( <number> kb ) error : ignored the following versions that require a different python version : <number> . <number> requires - python >= <number> , < <number> ; <number> . 0 rc3 requires - python >= <number> , < <number> ; <number> . <number> requires - python >= <number> , < <number> ; <number> . 0 rc1 . post1 requires - python >= <number> , < <number> ; <number> . 0 rc2 requires - python >= <number> , < <number> ; <number> . 0 rc3 requires - python >= <number> , < <number> ; <number> . <number> requires - python >= <number> , < <number> ; <number> . <number> requires - python >= <number> , < <number> ; <number> . 0 rc2 requires - python >= <number> , < <number> ; <number> . 0 rc3 requires - python >= <number> , < <number> ; <number> . <number> requires - python >= <number> , < <number> error : could not find a version that satisfies the requirement numba = = <number> ( from tflite - model - maker ) ( from versions : <number> , <number> , <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> , <number> . 1 rc1 , <number> . <number> , <number> . 0 rc1 , <number> . <number> , <number> . <number> , <number> . 0 rc1 , <number> . <number> , <number> . <number> , <number> . <number> , <number> . 0 rc2 , <number> . 0 rc1 , <number> . <number> , <number> . <number> , <number> . <number> , <number> . 0 rc1 , <number> . <number> , <number> . <number> , <number> . <number> , <number> . <number> ) error matching distribution found for numba = = <number> ( tflite_model_maker ) reza <user> : ~ / projects / tflite_mode ` ` ` </details>",2
tensorflow/tensorflow,release variable memory api ? <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell api can release memory variable ` ` ` # # # standalone code to reproduce the issue ` ` ` shell no ` ` ` # # # relevant log output _no response_ </details>,2
tensorflow/tensorflow,"how to limit gpu memory usage when only prediction in c + + ? # # # issue type feature request # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> / <number> . <number> # # # gpu model and memory rtx <number> / 2 4 gb # # # current behavior ? i loaded the saved model using the already compiled tensorflow - gpu <number> . <number> . when this model was used for prediction , it was confirmed that all available memory of the gpu was used . i have seen limiting using the growing method in python , but i do not know how to use it in c + + . could you please tell me how ? # # # standalone code to reproduce the issue ` ` ` shell <hashtag> include </hashtag> < stdlib . h > <hashtag> include </hashtag> < stdio . h > <hashtag> include </hashtag> < tensorflow / c / c_api . h > <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> <fstream> <hashtag> include </hashtag> <sstream> <hashtag> include </hashtag> <string> <hashtag> include </hashtag> <vector> void noopdeallocator ( void * data , size_t a , void * b ) { } int main ( ) { tf_graph * graph = tf_newgraph ( ); tf_status * status = tf_newstatus ( ); tf_sessionoptions * sessionopts = tf_newsessionoptions ( ); tf_buffer * runopts = null ; const char * saved_model_dir = "" h :\\\\ my_model \ \\\""; / / path of the model const char * tags = "" serve "" ; / / default model serving tag ; can change in future int ntags = <number> ; tf_session * session = tf_loadsessionfromsavedmodel ( sessionopts , runopts , saved_model_dir , & tags , ntags , graph , null , status ) ; if ( tf_getcode ( status ) = = tf_ok ) { printf ( "" tf_loadsessionfromsavedmodel ok \ \ n "" ); } else { printf ( "" %s "" , tf_message ( status ) ); } } ` ` ` # # # relevant log output _no response_",1
tensorflow/tensorflow,"` tf . image . crop_to_bounding_box ( ) ` assumes ` tf . int32 ` arguments , but not documented as such # # # issue type documentation feature request # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution linux ubuntu <number> ( wsl <number> ) # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? ` tf . image . crop_to_bounding_box ( ) ` implicitly assumes that the target width and height are ` tf . int32 ` , but this is not documented anywhere . the cause for this is using ` tf . shape ( ) ` which has the default ` dtype ` of ` tf . int32 ` , in a stack operation : <url> # # # standalone code to reproduce the issue ` ` ` python import tensorflow as tf image = tf . zeros ( [ <number> , <number> , <number> ] , dtype = tf . uint8 ) offset = tf . constant ( [ <number> , <number> ] , dtype = tf . int64 ) size = tf . constant ( [ <number> , <number> ] , dtype = tf . int64 ) tf . image . crop_to_bounding_box ( image , offset [ <number> ] , offset [ <number> ] , size [ <number> ] , size [ <number> ] ) ` ` ` # # # relevant log output ` ` ` shell traceback ( most recent call last ) : file "" / . <repeated> / test . py "" , line <number> , in <module> tf . image . crop_to_bounding_box ( image , offset [ <number> ] , offset [ <number> ] , size [ <number> ] , size [ <number> ] ) file "" / . <repeated> / . venv / lib / python3 . <number> / site - packages / tensorflow / python / util / traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" / . <repeated> / . venv / lib / python3 . <number> / site - packages / tensorflow / python / framework / ops . py "" , line <number> , in raise_from_not_ok_status raise core . _status_to_exception ( e ) from none # pylint : disable = protected - access tensorflow . python . framework . errors_impl . invalidargumenterror : cannot compute pack as input # <number> ( zero - based ) was expected to be a int32 tensor but is a int64 tensor [ op : pack ] name ` ` `",1
tensorflow/tensorflow,"on - device training for lstm or gru model * * system information * * - os platform and distribution ( e . g . , linux ubuntu <number> <sad> web - tensorflow installed from ( source or binary ) - tensorflow version ( or github sha if from source ) : colab hi i ’ m new to tensorflow and i ’ m trying to make lstm or gru model to be enable to re - train on - device ( android ) with tabular data ( mostly customer interaction ) . i ’ m referencing these examples [ on - device training <number> ] ( <url> this is an example of a cnn , but not able to understand how can i enable on - device training for lstm or gru model . are there any examples for reference ? thanks",1
tensorflow/tensorflow,"cannot subclass dataset_ops . datasetv2 # # # issue type support # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . x # # # custom code yes # # # os platform and distribution mac os <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? hi , i am from lancedb team and we are trying to build native support for tf . data . see wip pr here <url> . ideally , we ' d like to simply subclass ` tf . dataset_ops . datasetv2 ` so that all the metadata needed to recreate the dataset can be pushed down to our file format that enabled parallelism elegantly . so , it ' d be something like this ` ` ` class lancetfdataset ( dataset_ops . datasetv2 ) def __init__ ( self ) : . <repeated> variant_tensor = tf . tensor ( self , ( ) , dtype = tf . variant ) super ( ) . __init__ ( variant_tensor ) ` ` ` the above code complains that can not create lancetfdataset to tf . tensor / variant . issue - what exactly is variant_tensor and how do we go about creating one ? i read through the docs but could not find anything concrete . there was a mention that variant_tensor is a special tensor that tell about the type of the dataset and that it ' s equivalent to tf . variant , but the above code does not work . having a version of tf . dataset that we can use to capture extra metadata would allow us to improve the interface as well : so instead of lance . tf . data . from_dataset ( uri , columns , filter , batch_size ) we can just have from_lance ( uri ) . filter ( . <repeated> ) . batch_size ( . <repeated> ) . shuffle ( ) . so what ' s the way to go about subclassing tf dataset ? # # # standalone code to reproduce the issue ` ` ` shell class lancetfdataset ( dataset_ops . datasetv2 ) def __init__ ( self ) variant_tensor = tf . tensor ( self , ( ) , dtype = tf . variant ) super ( ) . __init__ ( variant_tensor ) ` ` ` # # # relevant log output _no response_",1
tensorflow/tensorflow,"how to get raw buffer pointer from python tf . tensor # # # issue type feature request # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? in c + + api , tensorflow : : tensor has ` data ( ) ` method which returns pointer to memory array . while in python api tf . tensor does not allow to get raw data pointer . is there any solution or workaround for this ? # # # standalone code to reproduce the issue ` ` ` shell tensorflow : : tensor . data ( ) tf . tensor ` ` ` # # # relevant log output _no response_",1
tensorflow/tensorflow,"tensorflow lite for windows and macos hi guys , so i am new to on device machine learning which is super cool but , the limitation with tf - lite is that i can only use in android or ios not in windows apps nor macos . i request any of you who has dealt with embedding tflite with desktop class apps to provide a simple solution .",1
tensorflow/tensorflow,"building tf - opt steps with prerequisites <details> <summary> click to expand </summary> # # # issue type documentation feature request # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution linux ubunto <number> # # # mobile device _no response_ # # # python version _no response_ # # # bazel version <number> . <number> # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i am trying to build tf - opt binary on branch v2 . <number> without any changes and gets different compilation errors . the command for compilation i use : ` bazel build - c opt tensorflow / compiler / mlir : tf - opt ` can you share some prerequites for building and debugging ` tf - opt ` binary ( for debug / release mode ) . i would appriciate if there is docker builder i can use to it instead of changing my envrioment . thanks , aviad # # # standalone code to reproduce the issue ` ` ` shell error : / localdrive / users / aviadco / community / tensorflow / tensorflow / lite / experimental / acceleration / configuration / build : <number> : <number> : executing genrule / / tensorflow / lite / experimental / acceleration / configuration : configuration_schema failed : ( exit <number> <sad> bash failed : error executing command ( from target / / tensorflow / lite / experimental / acceleration / configuration : configuration_schema ) / bin / bash - c . <repeated> ( remaining <number> argument skipped ) bazel - out / k8 - opt - exec - 5 0 ae0418 / bin / external / flatbuffers / flatc : / usr / lib / x86_64 - linux - gnu / libstdc + + . so . <number> : version ` glibcxx_3 . <number> ' not found ( required by bazel - out / k8 - opt - exec - 5 0 ae0418 / bin / external / flatbuffers / flatc ) error : / localdrive / users / aviadco / community / tensorflow / tensorflow / lite / schema / build : <number> <time> : generating flatbuffer files for conversion_metadata_fbs_srcs : / / tensorflow / lite / schema : conversion_metadata_fbs_srcs failed : ( exit <number> <sad> bash failed : error executing command ( from target / / tensorflow / lite / schema : conversion_metadata_fbs_srcs ) / bin / bash - c . <repeated> ( remaining <number> argument skipped ) bazel - out / k8 - opt - exec - 5 0 ae0418 / bin / external / flatbuffers / flatc : / usr / lib / x86_64 - linux - gnu / libstdc + + . so . <number> ` glibcxx_3 . <number> ' not found ( required by bazel - out / k8 - opt - exec - 5 0 ae0418 / bin / external / flatbuffers / flatc ) target / / tensorflow / compiler / mlir : tf - opt failed to build ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"flexcombinednonmaxsuppression unavailable in flex shared library <details> <summary> click to expand </summary> # # # issue type feature request # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version v2 . <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> . <number> # # # mobile device _no response_ # # # python version _no response_ # # # bazel version <number> . <number> # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i have network that runs with no problem on android that uses the operator flexcombinendnonmaxsuprpression . when running the same network and code on an x86 machine , the log output tells me that this operator is not supported by this interpreter . i have built from source the necessary libraries , libtensorflowlite . so and libtensorflowlite_flex . so # # # standalone code to reproduce the issue ` ` ` shell ` /* allocate tensors */ rettflite = _interpreter - > allocatetensors ( ); if ( rettflite = = ktfliteok ) { _engineready = true ; } ` ` ` ` # # # relevant log output ` ` ` shell error : select tensorflow op ( s ) , included in the given model , is ( are ) not supported by this interpreter . make sure you apply / link the flex delegate before inference . for the android , it can be resolved by adding "" org . tensorflow : tensorflow - lite - select - tf - ops "" dependency . see instructions : <url> error : node number <number> ( flexcombinednonmaxsuppression ) failed to prepare . info : failed to apply the default tensorflow lite delegate indexed at <number> because of unresolved ops ( which could be resolved by another delegate ) . ignoring the error , and continuing anyway . error : select tensorflow op ( s ) , included in the given model , is ( are ) not supported by this interpreter . make sure you apply / link the flex delegate before inference . for the android , it can be resolved by adding "" org . tensorflow : tensorflow - lite - select - tf - ops "" dependency . see instructions : <url> error number <number> ( flexcombinednonmaxsuppression ) failed to prepare . ` ` ` </details>",1
tensorflow/tensorflow,<number> support for tensorflowliteswift and tensorflow - lite android ( maven ) <details> <summary> click to expand </summary> # # # issue type feature request # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution ios / android # # # mobile device ios / android # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? i am interested in the planned release date for tensorflowlite <number> . <number> ios / android # # # standalone code to reproduce the issue ` ` ` shell i am interested in the planned release date for tensorflowlite <number> . <number> ios / android ` ` ` # # # relevant log output _no response_ </details>,1
tensorflow/tensorflow,"tf - mlir - translate and flatbuffer_translate failure for the erf function # # # for tf ` ` ` results invalid_mlir test_erf_1_f32 : error <number> running command : / tensorflow / bazel - bin / tensorflow / compiler / mlir / tf - mlir - translate - - graphdef - to - mlir - - tf - enable - shape - inference - on - import - - tf - output - arrays = result erf / test_erf_1_f32 / model . pb - o erf / test_erf_1_f32 / test_tf . preopt . mlir - - tf - input - arrays placeholder_0 - - tf - input - shapes <number> , ` ` ` you can find the dummy tf erf model here : <url> # # # for tfl after running ` ` ` / tensorflow / compiler / mlir / lite / flatbuffer_translate - - tflite - flatbuffer - to - mlir erf / test_erf_1_f32 / model . tflite - - output - arrays = partitionedcall : <number> - o erf / test_erf_1_f32 / test_tflite . preopt . mlir ` ` ` you can find the dummy tfl erf model here : <url> it ' s generating a ` tfl . custom ` operator here which is not tfl . erf ` ` ` module attributes { tf_saved_model . semantics , tfl . description = "" mlir converted . "" , tfl . schema_version = <number> : i32 } { func . func <user> ( % arg0 : tensor <1xf32> { tf_saved_model . index_path = [ "" placeholder_0 "" ] } ) - > ( tensor <1xf32> { tf_saved_model . index_path = [ "" output_0 "" ] } ) attributes { tf . entry_function = { inputs = "" serving_default_placeholder_0 : <number> "" , outputs = "" partitionedcall : <number> "" } , tf_saved_model . exported_names = [ "" serving_default "" ] } { % <number> = "" tfl . custom "" ( % arg0 ) { custom_code = "" flexerf "" , custom_option = <hashtag> tfl </hashtag> < const_bytes : "" 0x0 3 4 5 7 2 6 6 0 0 1 2 1 2 0 3 4 5 7 2 6 6 1 a002a070a0154120230013200000219151414042801 "" > } : ( tensor <1xf32> ) - > tensor <1xf32> return % <number> : tensor <1xf32> } } ` ` ` i think there requires some fair amount of support to the erf function for mlir . related ticket",1
tensorflow/tensorflow,""" improve gpu memory management for large - scale models "" currently , tensorflow ' s gpu memory management can be challenging when training large - scale models . this issue aims to improve the memory management strategies for gpu usage to optimize memory allocation and deallocation , reducing memory fragmentation and enabling more efficient training of large models . you can find this issue by going to the tensorflow repository ' s "" issues "" tab and using the search bar to search for the keywords "" gpu memory management large - scale models . "" once you find the issue , make sure to read through the details and discussion to understand the specific challenges and proposed solutions . feel free to contribute to this issue by commenting on it , discussing possible approaches , or even submitting a pull request with your proposed changes . remember to familiarize yourself with the contribution guidelines and any specific instructions mentioned in the issue before getting started . good luck , and i hope you find this issue interesting and valuable for your contributions to tensorflow",1
tensorflow/tensorflow,"support checkpointinputpipelinehook in estimator mirrorstrategy <details> <summary> click to expand </summary> # # # issue type feature request # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? failed to save pipeline info in checkpoint . # # # standalone code to reproduce the issue ` ` ` shell mirrored_strategy = tf . distribute . mirroredstrategy ( ) run_config = tf . estimator . runconfig ( model_dir = output_dir , save_checkpoints_steps = save_checkpoints_steps , train_distribute = mirrored_strategy , eval_distribute = mirrored_strategy , keep_checkpoint_max = max_ckp_num ) estimator . train ( input_fn = input_fn , hooks =[ tf . data . experimental . checkpointinputpipelinehook ( estimator ) ] , steps = tf_args . test_train_step ) ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at iterator_ops . cc : <number> : failed precondition is stateful . ` ` ` </details>",1
tensorflow/tensorflow,maximum aspect ratio of camera for android mobile app & android tv to use feature of pose estimation ? <details> <summary> click to expand </summary> # # # issue type feature request # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? a bug happened ! # # # standalone code to reproduce the issue ` ` ` shell what is the maximum aspect ratio of camera for android mobile app & android tv to use feature of pose estimation ? ` ` ` # # # relevant log output _no response_ </details>,1
tensorflow/tensorflow,"building tf from source instructions clarification wrt python packages <details> <summary> click to expand </summary> # # # issue type documentation feature request # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version <number> # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell hi ! following the instructions on <url> usually works . however , this time i ran into an issue that took a while to figure out . it turns out to be an issue with the protobuf version : protobuf <number> . <number> => no good protobuf <number> . <number> => good in the current instructions , the only python related info is : sudo apt install python3 - dev python3 - pip and pip install - u - - user pip numpy wheel packaging requests opt_einsum pip install - u - - user keras_preprocessing - - no - deps is there a reason not to refer to the following requirement specs ? pip install - r . / tensorflow / tools / ci_build / release / requirements_common . txt pip install - r . / tensorflow / tools / ci_build / release / requirements_ubuntu . txt which would have avoided the issue for me . <repeated> if not , i propose to add that . cheers ! ` ` ` # # # standalone code to reproduce the issue ` ` ` shell bazel build - - verbose_failures / / tensorflow / tools / pip_package : build_pip_package ` ` ` # # # relevant log output ` ` ` shell error : / home / ubuntu / repos / mirror - tensorflow / tensorflow / build : <number> <time> : executing genrule / / tensorflow : tf_python_api_gen_v2 failed : ( exit <number> <sad> bash failed : error executing command ( cd / home / ubuntu / . cache / bazel / _bazel_ubuntu / 0 ef2ae1c374389fefaed577dece28985 / execroot / org_tensorflow & & \ \ exec env - \ \ path <annoyed> home / ubuntu / . cache / bazelisk / downloads / bazelbuild / bazel - <number> . <number> - linux - arm64 / bin <annoyed> home / ubuntu / . vscode - server / bin / ee2b180d582a7f601fa6ecfdad8d9fd269ab1884 / bin / remote - cli <annoyed> home / ubuntu / . local / bin <annoyed> home / ubuntu / bin <annoyed> home / ubuntu / . local / bin <annoyed> home / ubuntu / bin <annoyed> usr / local / sbin <annoyed> usr / local / bin <annoyed> usr / sbin <annoyed> usr / bin <annoyed> sbin <annoyed> bin <annoyed> usr / games <annoyed> usr / local / games <annoyed> snap / bin <annoyed> home / ubuntu / bin <annoyed> home / ubuntu / bin \ \ python_bin_path <annoyed> usr / bin / python3 \ \ python_lib_path <annoyed> usr / lib / python3 . <number> / dist - packages \ \ tf2_behavior = <number> \ \ / bin / bash - c ' source external / bazel_tools / tools / genrule / genrule - setup . sh ; bazel - out / aarch64 - opt / bin / tensorflow / create_tensorflow . python_api_tf_python_api_gen_v2 - - root_init_template = tensorflow / api_template . __init__ . py - - apidir = bazel - out / aarch64 - opt / bin / tensorflow_api / v2 / - - apiname = tensorflow - - apiversion = <number> - - compat_apiversion = <number> - - compat_apiversion = <number> - - compat_init_template = tensorflow / compat_template_v1 . __init__ . py - - compat_init_template = tensorflow / compat_template . __init__ . py - - packages = tensorflow . python , tensorflow . dtensor . python . accelerator_util , tensorflow . dtensor . python . api , tensorflow . dtensor . python . config , tensorflow . dtensor . python . d_checkpoint , tensorflow . dtensor . python . d_variable , tensorflow . dtensor . python . input_util , tensorflow . dtensor . python . layout , tensorflow . dtensor . python . mesh_util , tensorflow . dtensor . python . tpu_util , tensorflow . dtensor . python . save_restore , tensorflow . lite . python . analyzer , tensorflow . lite . python . lite , tensorflow . lite . python . authoring . authoring , tensorflow . python . modules_with_exports - - output_package = tensorflow . _api . v2 - - use_relative_imports = true - - loading = static - - loading = default bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / v2 . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / decorator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / dispatch / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / interim / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / multi_process_runner / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / eager_context / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / function / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / mixed_precision / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / monitoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / smart_cond / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / test / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / tf2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / types / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / saved_model / load / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / tracking / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __operators__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / audio / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / autograph / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / autodiff / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / bitwise / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / optimizer / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / threading / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / data / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / data / experimental / service / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / debugging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / debugging / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / cluster_resolver / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / partitioners / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / rpc / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / dtypes / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / dtypes / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / errors / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / extension_type / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / dtensor / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / numpy / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / numpy / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / tensorrt / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / dlpack / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / io / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / image / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / queue / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / linalg / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / linalg / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / authoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / microfrontend / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / microfrontend / python / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / microfrontend / python / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lookup / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lookup / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / math / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / math / special / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / mlir / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / mlir / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / nn / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / nn / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / experimental / client / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / experimental / server / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / quantization / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / ragged / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / random / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / raw_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / saved_model / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / sets / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / signal / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / sparse / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / strings / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / summary / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / summary / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / sysconfig / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / test / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / tpu / experimental / embedding / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / tpu / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / tpu / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / train / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / types / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / types / experimental / distributed / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / version / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / xla / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / xla / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / decorator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / dispatch / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / interim / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / multi_process_runner / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / eager_context / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / function / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / mixed_precision / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / monitoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / smart_cond / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / test / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / tf2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / types / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / saved_model / load / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / tracking / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __operators__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / audio / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / autograph / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / autodiff / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / bitwise / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / optimizer / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / threading / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / data / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / data / experimental / service / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / debugging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / debugging / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / cluster_resolver / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / partitioners / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / rpc / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / dtypes / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / dtypes / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / errors / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / extension_type / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / dtensor / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / numpy / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / numpy / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / tensorrt / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / dlpack / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / io / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / image / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / queue / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / linalg / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / linalg / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / authoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / microfrontend / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / microfrontend / python / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / microfrontend / python / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lookup / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lookup / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / math / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / math / special / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / mlir / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / mlir / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / nn / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / nn / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / experimental / client / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / experimental / server / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / quantization / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / ragged / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / random / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / raw_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / saved_model / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / sets / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / signal / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / sparse / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / strings / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / summary / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / summary / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / sysconfig / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / test / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / tpu / experimental / embedding / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / tpu / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / tpu / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / train / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / types / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / types / experimental / distributed / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / version / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / xla / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / xla / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __internal__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __internal__ / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __internal__ / types / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / app / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / audio / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / autograph / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / bitwise / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / optimizer / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / threading / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / data / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / data / experimental / service / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / debugging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / debugging / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distribute / cluster_resolver / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distribute / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distributions / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / dtypes / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / dtypes / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / errors / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / experimental / extension_type / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / io / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / image / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / queue / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / initializers / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / layers / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / layers / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / linalg / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / linalg / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / authoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / microfrontend / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / microfrontend / python / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / microfrontend / python / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / logging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lookup / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lookup / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / losses / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / manip / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / math / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / math / special / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / metrics / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mixed_precision / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mixed_precision / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mlir / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mlir / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nn / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nn / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nn / rnn_cell / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / profiler / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / python_io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / quantization / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / ragged / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / random / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / raw_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / resource_loader / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / strings / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / builder / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / loader / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / main_op / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / signature_constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / signature_def_utils / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / tag_constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / utils / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / sets / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / signal / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / sparse / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / spectral / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / summary / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / sysconfig / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / test / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / tpu / experimental / embedding / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / tpu / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / tpu / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / train / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / train / queue_runner / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / types / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / user_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / version / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / xla / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / xla / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v1 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v1 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v2 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v1 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v1 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v2 / compat / __init__ . py ' ) # configuration : 6 e760a068cbc11a6cc46e726655f369e4c10c58a67d5a62b8baed49245ffc3a5 # execution platform : <user> / / : platform traceback ( most recent call last ) : file "" / home / ubuntu / . cache / bazel / _bazel_ubuntu / 0 ef2ae1c374389fefaed577dece28985 / execroot / org_tensorflow / bazel - out / aarch64 - opt / bin / tensorflow / create_tensorflow . python_api_tf_python_api_gen_v2 . runfiles / org_tensorflow / tensorflow / python / tools / api / generator / create_python_api . py "" , line <number> , in <module> from tensorflow . python . tools . api . generator import doc_srcs file "" / home / ubuntu / . cache / bazel / _bazel_ubuntu / 0 ef2ae1c374389fefaed577dece28985 / execroot / org_tensorflow / bazel - out / aarch64 - opt / bin / tensorflow / create_tensorflow . python_api_tf_python_api_gen_v2 . runfiles / org_tensorflow / tensorflow / python / __init__ . py "" , line <number> , in <module> from tensorflow . python . eager import context file "" / home / ubuntu / . cache / bazel / _bazel_ubuntu / 0 ef2ae1c374389fefaed577dece28985 / execroot / org_tensorflow / bazel - out / aarch64 - opt / bin / tensorflow / create_tensorflow . python_api_tf_python_api_gen_v2 . runfiles / org_tensorflow / tensorflow / python / eager / context . py "" , line <number> , in <module> from tensorflow . core . framework import function_pb2 file "" / home / ubuntu / . cache / bazel / _bazel_ubuntu / 0 ef2ae1c374389fefaed577dece28985 / execroot / org_tensorflow / bazel - out / aarch64 - opt / bin / tensorflow / create_tensorflow . python_api_tf_python_api_gen_v2 . runfiles / org_tensorflow / tensorflow / core / framework / function_pb2 . py "" , line <number> , in <module> from google . protobuf . internal import builder as _builder importerror : cannot import name ' builder ' from ' google . protobuf . internal ' ( / home / ubuntu / . local / lib / python3 . <number> / site - packages / google / protobuf / internal / __init__ . py ) target / / tensorflow / tools / pip_package : build_pip_package failed to build error : / home / ubuntu / repos / mirror - tensorflow / tensorflow / lite / python / build : <number> <time> middleman _middlemen / tensorflow_slite_spython_stflite_uconvert - runfiles failed : ( exit <number> <sad> bash failed : error executing command ( cd / home / ubuntu / . cache / bazel / _bazel_ubuntu / 0 ef2ae1c374389fefaed577dece28985 / execroot / org_tensorflow & & \ \ exec env - \ \ path <annoyed> home / ubuntu / . cache / bazelisk / downloads / bazelbuild / bazel - <number> . <number> - linux - arm64 / bin <annoyed> home / ubuntu / . vscode - server / bin / ee2b180d582a7f601fa6ecfdad8d9fd269ab1884 / bin / remote - cli <annoyed> home / ubuntu / . local / bin <annoyed> home / ubuntu / bin <annoyed> home / ubuntu / . local / bin <annoyed> home / ubuntu / bin <annoyed> usr / local / sbin <annoyed> usr / local / bin <annoyed> usr / sbin <annoyed> usr / bin <annoyed> sbin <annoyed> bin <annoyed> usr / games <annoyed> usr / local / games <annoyed> snap / bin <annoyed> home / ubuntu / bin <annoyed> home / ubuntu / bin \ \ python_bin_path <annoyed> usr / bin / python3 \ \ python_lib_path <annoyed> usr / lib / python3 . <number> / dist - packages \ \ tf2_behavior = <number> \ \ / bin / bash - c ' source external / bazel_tools / tools / genrule / genrule - setup . sh ; bazel - out / aarch64 - opt / bin / tensorflow / create_tensorflow . python_api_tf_python_api_gen_v2 - - root_init_template = tensorflow / api_template . __init__ . py - - apidir = bazel - out / aarch64 - opt / bin / tensorflow_api / v2 / - - apiname = tensorflow - - apiversion = <number> - - compat_apiversion = <number> - - compat_apiversion = <number> - - compat_init_template = tensorflow / compat_template_v1 . __init__ . py - - compat_init_template = tensorflow / compat_template . __init__ . py - - packages = tensorflow . python , tensorflow . dtensor . python . accelerator_util , tensorflow . dtensor . python . api , tensorflow . dtensor . python . config , tensorflow . dtensor . python . d_checkpoint , tensorflow . dtensor . python . d_variable , tensorflow . dtensor . python . input_util , tensorflow . dtensor . python . layout , tensorflow . dtensor . python . mesh_util , tensorflow . dtensor . python . tpu_util , tensorflow . dtensor . python . save_restore , tensorflow . lite . python . analyzer , tensorflow . lite . python . lite , tensorflow . lite . python . authoring . authoring , tensorflow . python . modules_with_exports - - output_package = tensorflow . _api . v2 - - use_relative_imports = true - - loading = static - - loading = default bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / v2 . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / decorator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / dispatch / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / interim / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / distribute / multi_process_runner / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / eager_context / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / function / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / mixed_precision / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / monitoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / smart_cond / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / test / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / tf2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / types / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / saved_model / load / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __internal__ / tracking / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / __operators__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / audio / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / autograph / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / autodiff / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / bitwise / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / optimizer / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / config / threading / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / data / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / data / experimental / service / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / debugging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / debugging / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / cluster_resolver / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / partitioners / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / distribute / experimental / rpc / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / dtypes / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / dtypes / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / errors / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / extension_type / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / dtensor / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / numpy / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / numpy / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / tensorrt / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / experimental / dlpack / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / io / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / image / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / queue / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / linalg / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / linalg / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / authoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / microfrontend / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / microfrontend / python / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lite / experimental / microfrontend / python / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lookup / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / lookup / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / math / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / math / special / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / mlir / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / mlir / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / nn / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / nn / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / experimental / client / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / profiler / experimental / server / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / quantization / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / ragged / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / random / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / raw_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / saved_model / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / sets / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / signal / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / sparse / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / strings / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / summary / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / summary / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / sysconfig / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / test / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / tpu / experimental / embedding / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / tpu / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / tpu / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / train / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / types / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / types / experimental / distributed / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / version / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / xla / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / xla / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / decorator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / dispatch / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / interim / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / distribute / multi_process_runner / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / eager_context / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / function / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / mixed_precision / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / monitoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / smart_cond / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / test / combinations / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / tf2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / types / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / saved_model / load / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __internal__ / tracking / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / __operators__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / audio / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / autograph / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / autodiff / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / bitwise / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / optimizer / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / config / threading / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / data / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / data / experimental / service / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / debugging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / debugging / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / cluster_resolver / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / coordinator / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / partitioners / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / distribute / experimental / rpc / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / dtypes / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / dtypes / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / errors / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / extension_type / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / dtensor / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / numpy / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / numpy / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / tensorrt / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / experimental / dlpack / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / io / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / image / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / queue / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / linalg / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / linalg / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / authoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / microfrontend / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / microfrontend / python / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lite / experimental / microfrontend / python / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lookup / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / lookup / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / math / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / math / special / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / mlir / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / mlir / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / nn / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / nn / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / experimental / client / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / profiler / experimental / server / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / quantization / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / ragged / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / random / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / raw_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / saved_model / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / sets / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / signal / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / sparse / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / strings / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / summary / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / summary / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / sysconfig / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / test / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / tpu / experimental / embedding / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / tpu / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / tpu / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / train / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / types / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / types / experimental / distributed / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / version / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / xla / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / xla / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __internal__ / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __internal__ / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / __internal__ / types / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / app / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / audio / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / autograph / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / autograph / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / bitwise / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / optimizer / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / config / threading / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / data / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / data / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / data / experimental / service / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / debugging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / debugging / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distribute / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distribute / cluster_resolver / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distribute / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / distributions / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / dtypes / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / dtypes / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / errors / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / experimental / extension_type / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / feature_column / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / io / gfile / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / graph_util / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / image / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / queue / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / initializers / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / layers / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / layers / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / linalg / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / linalg / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / authoring / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / microfrontend / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / microfrontend / python / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lite / experimental / microfrontend / python / ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / logging / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lookup / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / lookup / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / losses / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / manip / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / math / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / math / special / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / metrics / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mixed_precision / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mixed_precision / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mlir / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / mlir / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nest / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nn / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nn / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / nn / rnn_cell / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / profiler / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / python_io / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / quantization / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / ragged / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / random / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / random / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / raw_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / resource_loader / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / strings / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / builder / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / loader / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / main_op / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / signature_constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / signature_def_utils / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / tag_constants / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / saved_model / utils / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / sets / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / signal / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / sparse / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / spectral / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / summary / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / sysconfig / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / test / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / test / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / tpu / experimental / embedding / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / tpu / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / tpu / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / train / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / train / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / train / queue_runner / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / types / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / types / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / user_ops / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / version / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / xla / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / xla / experimental / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v1 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v1 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v1 / compat / v2 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v1 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v2 / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v1 / compat / __init__ . py bazel - out / aarch64 - opt / bin / tensorflow / _api / v2 / compat / v2 / compat / v2 / compat / __init__ . py ' ) # configuration : 6 e760a068cbc11a6cc46e726655f369e4c10c58a67d5a62b8baed49245ffc3a5 # execution platform : <user> / / : platform info : elapsed time : <number> . 4 5 6 s , critical path : <number> . 2 5 s info : <number> processes : <number> internal , <number> local . failed did not complete successfully ` ` ` </details>",1
tensorflow/tensorflow,"how to check for nonetensorspec ? <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i have a dataset that returns ` none ` values . i would like to programatically find and replace the ` nonetensorspec ` values of the spec into a custom value ( ` none ` ) , but i cannot find ` nonetensorspec ` in the public api and am not sure what the best way to filter for it is . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell ds = tf . data . dataset . from_tensors ( ( <number> , none ) ) print ( ds . element_spec ) ` ` ` # # # relevant log output ` ` ` shell ` ( tensorspec ( shape =() , dtype = tf . int32 , name = none ) , nonetensorspec ( ) ) ` ` ` ` </details>",1
tensorflow/tensorflow,"experimental feature support for tflite selective build <details> <summary> click to expand </summary> # # # issue type feature request # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> - tflite - android # # # custom code no # # # current behaviour ? i have followed [ the tutorial ] ( <url> and made my textcnn model have the ability of on - device - training . it works well with the prebuilt library for tensorflow - lite . when trying to [ reduce the binary size ] ( <url> with the docker environment i found that the java api such as ` interpreter <hashtag> run signature </hashtag> ` is a part of experimental feature , which not enabled by the [ tensorflow / lite / tools / build_aar . sh ] ( <url> i have tried to add ` experimental = true ` to ` tflite_custom_android_library ( ) ` function on line <number> of the ` build_aar . sh ` and rebuild , got the ` tensorflow - lite . aar ` and ` tensorflow - lite - select - tf - ops . aar ` . it seems that ` tensorflow - lite . aar ` does have the experimental feature code and works . but ` tensorflow - lite - select - tf - ops . aar ` failure to run on android device with error : ` ` ` java . lang . unsatisfiedlinkerror : dlopen failed locate symbol "" _znk6google8protobuf7message11gettypenameev "" referenced by "" / data / app / */ lib / arm64 / libtensorflowlite_flex_jni . so "" . <repeated> ` ` ` i could not find any flag like ` experimental = true ` for select - tf - ops to enable . is it possible to enable experimental features for tflite selective build ? # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"disable linkage to nativewindow when api_level < <number> <details> <summary> click to expand </summary> # # # issue type build / install # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version latest / nightly # # # custom code no # # # os platform and distribution android # # # mobile device _no response_ # # # python version _no response_ # # # bazel version <number> . <number> # # # gcc / compiler version clang <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell in file ` tensorflow / lite / delegates / gpu / build_defs . bzl ` line <number> it returns a link option of "" - lnativewindow "" by ` return [ "" - lnativewindow "" ] ` , but this option is only available for ndk api_level >= <number> . would be nice if a condition can be set here with something like : if api_level >= <number> : return [ "" - lnativewindow "" ] else [ ] ` ` ` ` ` ` # # # standalone code to reproduce the issue ` ` ` shell set api_level = <number> , and build tflite_gpu_delegation it will fail with ` cannot find - lnativewindow ` ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"feature request : tf . gather which returns <number> on invalid indices this is about ` tf . gather ` . the wanted behavior could be added directly , or maybe via a new option , or maybe via a separate op . actually , on gpu ( at least where i tested it ) , the behavior of ` tf . gather ` is already as i want it : - it returns <number> for invalid indices . - i think ( not really verified ) : gradients for those 0 s back to the ` param ` would go nowhere . ( this is important though . ) on cpu , the current behavior is : - an exception is raised . i basically want the same behavior on cpu as we currently have it on gpu . my current workaround is sth like # need to extend param such that we can lead gradients to nowhere zeros = tf . zeros ( [ tf . shape ( param ) [ i ] if i = axis else <number> for i in range ( param . ndim ) ] , dtype = param . dtype ) param = tf . concat ( [ param , zeros ] , axis = axis ) indices = tf . where ( indices >= <number> and indices < tf . shape ( param ) [ axis ] , indices , tf . shape ( param ) [ axis ] - <number> ) gather = tf . gather ( param , indices , axis = axis ) ` ` `",1
tensorflow/tensorflow,"custom trianing with overriding the ` fit ` method single or multiple devices . # # # current behaviour ? in the official blog post , [ here ] ( <url> it is discussed about the process for single device and multiple device training using ` keras ` api . but i have found it quite ambigous to understand the right procedue when you want to do both , [ overriding the ` fit ` method ] ( <url> it ' s like combination of custom training loop + using high - level api ( ` fit ` ) . for example , in custom training loop , it ' s suggested as follows ` ` ` train_dist_dataset = strategy . experimental_distribute_dataset ( train_dataset ) test_dist_dataset = strategy . experimental_distribute_dataset ( test_dataset ) ` ` ` or ephasize to consider during [ loss ] ( <url> calculation . or consider the following also while custom training loop ? ` ` ` # ` run ` replicates the provided computation and runs it # with the distributed input . <user> . function def distributed_train_step ( dataset_inputs ) : per_replica_losses = strategy . run ( train_step , args =( dataset_inputs , ) ) return strategy . reduce ( tf . distribute . reduceop . sum , per_replica_losses , axis = none ) <user> . function def distributed_test_step ( dataset_inputs ) strategy . run ( test_step , args =( dataset_inputs , ) ) ` ` ` and it is not clear if we need to do when we combine both ( cutom training + fit method ) . there are many , for example [ this ] ( <url> that is , if mixed precision is enabled , should we use ` losscaleoptimizer <elongated> ` and ` optimizer . get_scaled_loss ( loss ) ` and ` optimizer . get_unscaled_gradients ( gradients ) ` in the ` train_step ` or ` compile ` method would do the job ? but the [ official documentation ] ( <url> talks about normal fit and custom loop training cases . in case of custom loop , it ' s suggested to wrap the optimizer and scale the loss and gradient but what about the combination of fit and custom loop ( overriding train_step ) ? does it sill need to wrap the optimizer and scale the loss and gradient or it will be handled by the api ? # # # relevant log output",1
tensorflow/tensorflow,tf equivalent of numpy . view ( ) <details> <summary> click to expand </summary> # # # issue type support # # # have you reproduced the bug with tf nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution macos ventura <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell is there an equivalent to numpy ' s ` . view ( ) ` function in tensorflow ? <url> ` ` ` # # # standalone code to reproduce the issue ` ` ` shell - ` ` ` # # # relevant log output _no response_ </details>,1
tensorflow/tensorflow,"feature request tf . data . dataset . from_tensor_slices with np . memmap i am interested in being able to do the following ` ` ` python arr = np . memmap ( ' train . bin ' , dtype = np . uint16 ) ds = tf . data . dataset . from_tensor_slices ( arr ) ` ` ` without loading the entire array ` arr ` into memory .",1
tensorflow/tensorflow,update curl to <number> . <number> <details> <summary> click to expand </summary> # # # issue type feature request # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution windows # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell security vulnerabilities fixed in curl <number> . <number> ` ` ` # # # standalone code to reproduce the issue ` ` ` shell na ` ` ` # # # relevant log output _no response_ </details>,1
tensorflow/tensorflow,"protobuf <number> is not supported <details> <summary> click to expand </summary> # # # issue type build / install # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution fedora linux <number> ( xfce ) # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell when i try to use tensorflow with protobuf newer than version <number> i get this : $ poetry add ' tensorflow = = <number> . <number> ' ' protobuf > = <number> ' updating dependencies resolving dependencies . <repeated> ( <number> . 2 s ) because tensorflow - issue depends on tensorflow ( <number> . <number> ) which depends on protobuf (>= <number> . <number> , < <number> ) , protobuf is required . so , because tensorflow - issue depends on protobuf (>= <number> ) , version solving failed . the reason for this is my expectation was that tensorflow supports more recent versions of protobuf . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell mkdir - vp / var / tmp / tensorflow - issue poetry - c / var / tmp / tensorflow - issue init - - no - interaction poetry - c / var / tmp / tensorflow - issue add ' tensorflow = = <number> . <number> ' ' protobuf > = <number> ' ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"feature request for object detection android app hello , i deployed my mobilenet trained model into your object detection android app and the detection looks good . <url> i would like to add two features to your app if possible show on the phone screen number of detected objects of class x <number> ) show on the phone screen the (x , y ) coordinated of bounding box for detected objects of class x can you please help me to figure out how i can add these two features in the app . look forward to hearing from you",1
tensorflow/tensorflow,"model with lstmcell gives different results before and after tflite conversion # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> opensuse tumbleweed - tensorflow installation ( pip package or built from source ) : pip - tensorflow library ( version , if pip package or github sha , if built from source ) : <number> # # # <number> . code when i attempt to convert a working tensorflow model to tflite , the model converts , but the results obtained are different see code below : ` ` ` import tensorflow as tf from tensorflow . keras . layers import ( concatenate , conv2d , conv2dtranspose , dropout , batchnormalization ) import numpy as np inp = tf . keras . input ( [ <number> ] , batch_size = <number> ) state_h = tf . keras . input ( [ <number> ] , batch_size = <number> ) state_c = tf . keras . input ( [ <number> ] , batch_size = <number> ) num_channels = <number> xt = batchnormalization ( ) ( inp ) lstm_in = tf . keras . activations . tanh ( xt ) x , new_states = tf . keras . layers . lstmcell ( xt . shape [ <number> ] ) ( lstm_in [ :, <number> , <happy> , states = [ state_h , state_c ] ) new_state_h = new_states [ <number> ] new_state_c = new_states [ <number> ] out = x + xt my_model = tf . keras . model ( inputs =[ inp , state_h , state_c ] , outputs = [ out , new_state_h , new_state_c ] ) <hashtag> save </hashtag> model and create tflite model my_model . save ( ' lstm_test ' , include_optimizer = false ) converter = tf . lite . tfliteconverter . from_saved_model ( ' lstm_test ' ) converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins , # enable tensorflow lite ops . ] tflite_model = converter . convert ( ) inpt = tf . random . normal ( [ <number> , <number> ] ) init_state_h = tf . zeros ( [ <number> ] ) init_state_c = tf . zeros ( [ <number> ] ) init_state_h_tfl = tf . zeros ( [ <number> ] ) init_state_c_tfl = tf . zeros ( [ <number> ] ) <hashtag> set </hashtag> up tflite interpreter interpreter = tf . lite . interpreter ( model_content = tflite_model ) interpreter . allocate_tensors ( ) input_details = interpreter . get_input_details ( ) output_details = interpreter . get_output_details ( ) print ( ' input_details ' ) print ( input_details ) print ( ' output details ' ) print ( output_details ) for k in range ( <number> ) st_h , st_c = my_model . predict ( [ tf . expand_dims ( inpt [ :, k , <happy> , axis = <number> ) , init_state_h , init_state_c ] ) init_state_h = st_h init_state_c = st_c interpreter . set_tensor ( input_details [ <number> ] [ ' index ' ] , tf . expand_dims ( inpt [ :, k , <happy> , axis = <number> ) ) interpreter . set_tensor ( input_details [ <number> ] [ ' index ' ] , init_state_h_tfl ) interpreter . set_tensor ( input_details [ <number> ] [ ' index ' ] , init_state_c_tfl ) interpreter . invoke ( ) outpt_tfl = interpreter . get_tensor ( output_details [ <number> ] [ ' index ' ] ) st_h_tfl = interpreter . get_tensor ( output_details [ <number> ] [ ' index ' ] ) st_c_tfl = interpreter . get_tensor ( output_details [ <number> ] [ ' index ' ] ) init_state_h_tfl = st_h_tfl init_state_c_tfl = st_c_tfl np . testing . assert_almost_equal ( outpt , outpt_tfl , decimal = <number> ) ` ` ` # # # <number> . failure after conversion when the above code is ran , it can be seen that there are considerable differences between the tflite model and the original tensorflow model .",1
tensorflow/tensorflow,"use cl_khr_integer_dot_product if available <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version 7 0 7 f1dcba4c8 ( head - > master , origin / master , origin / head ) compat forward compatibility horizon to <number> - <number> - <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell are there any plans to make use of cl_khr_integer_dot_product to speed up execution on gpus that support it ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell n / a ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"the parameter indices in tf . gather are supported int16 <details> <summary> click to expand </summary> # # # issue type documentation bug # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda : <number> cudnn cudnn <number> . <number> # # # gpu model and memory rtx3060 # # # current behaviour ? ` ` ` shell tf . gather ( params , indices , validate_indices = none , axis = none , batch_dims = <number> , name = none ) the parameter type requirement for indices in the official document is tensor , and then the type is int32 , int64 . for this situation , i deliberately use unreasonable types are tested . when indices are set to <number> , it is a float type , but the exception thrown says that this is not int16 , int32 , int64 , which is one more int16 than the official document . therefore , it is recommended to add int16 to the document . go up or remove int16 from the source code . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf with tf . device ( ' / cpu ' <sad> params = tf . random . uniform ( [ <number> , <number> ] , dtype = tf . float64 ) indices = <number> out = tf . gather ( params = params , indices = indices ) ` ` ` # # # relevant log output ` ` ` shell result : tensorflow . python . framework . errors_impl . invalidargumenterror : value for attr ' tindices ' of float is not in the list of allowed values : int16 , int32 , int64 ; nodedef gatherv2 } }; op < name = gatherv2 ; signature = params : tparams , indices : tindices , axis : taxis - > output : tparams ; attr = batch_dims : int , default = <number> ; attr = tparams : type ; attr = tindices : type , allowed =[ dt_int16 , dt_int32 , dt_int64 ] ; attr = taxis : type , allowed =[ dt_int32 , dt_int64 ] > [ op : gatherv2 ] ` ` ` </details>",1
tensorflow/tensorflow,"feature request ( tensorflow lite ) : strip unneeded kernels when building flex ops library on platforms other than android # # # system information - * * have i written custom code * * : no - * * os platform and distribution * * : macos monterey <number> - * * tensorflow installed from * * : source - * * tensorflow version * * : <number> . <number> - * * python version * * : <number> . <number> - * * bazel version * * : <number> . <number> - * * gcc / compiler version * * : apple clang <number> . <number> ( clang - <number> . <number> ) - * * cuda / cudnn version * * : not using cuda - * * gpu model and memory * * : not using gpu acceleration - * * exact command to reproduce * * request , no # # # describe the problem this is a feature request . tensorflow lite <number> provides a [ tool ] ( <url> that strips unneeded kernels when building the flex library , but this is for android only . on other platforms , the whole set of kernels gets built in , and the flex binary ends up being hundreds of mbs in size . would you consider implementing a similar tool for other platforms , and , if not , would you accept prs for it ?",1
tensorflow/tensorflow,"tensorflow lite dynamic input # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> windows <number> - tensorflow installation ( pip package or built from source ) <number> # # # <number> . code inputs = tf . keras . layers . input ( shape =( none , none , <number> ) , name = ' input_image ' ) model = tf . keras . model ( inputs , inputs ) input_image - [ ( none , none , none , <number> ) ] converter = tf . lite . tfliteconverter . from_keras_model ( model ) tflite_model = converter . convert ( ) input_image - [ <number> <number> <number> <number> ]",1
tensorflow/tensorflow,"feature request : tflite with gpu and hexagon delegate support on linux arm64 platform from this link : <url> , gpu delegate is "" only available for android "" if i use bazel , so i have to use cmake in order to get gpu delegate . however from this link , there ' s only tflite_enable_gpu , no tflite_enable_hexagon . i tried to use it in cmake and it ' s not recognized . wondering if tensorflow can either add gpu delegate to bazel build , or add hexagon to cmake ? which one is more appropriate , if i also want to use our own toolchain ?",1
tensorflow/tensorflow,"request tensorflow docker container be expanded to support running all models . <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version tf <number> . <number> # # # custom code no # # # os platform and distribution linux ubuntu <number> lts # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i am creating a docker container in which i want to run the tensorflow object detection code provided in the model zoo . i expected to be able to download the tensorflow docker container , clone the relevant source , and be off to the races . instead , i found that i was missing a lot of required packages . i found references which suggested to use the provided setup script located here : <url> unfortunately , this led to a number of strange conflicts which i determined to be due to differing versions of opencv - python and opencv - python - headless , neither of which i ' d manually installed . everything was pulled in by the script and associated dependencies . given that both the tensorflow dockerfile and the models setup script are forcing versions of packages less than head - of - line , i request that a fuller and known - working docker image be provided . thank you . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <url> ` ` ` # # # relevant log output ` ` ` shell pip3 list would end up showing opencv - python <number> . <number> opencv - python - headless <number> . <number> this results in the following backtrace : traceback ( most recent call last ) : file "" model_main_tf2 . py "" , line <number> , in <module> from object_detection import model_lib_v2 file "" / opt / models / research / object_detection / model_lib_v2 . py "" , line <number> , in <module> from object_detection import eval_util file "" / opt / models / research / object_detection / eval_util . py "" , line <number> , in <module> from object_detection . metrics import lvis_evaluation file "" / opt / models / research / object_detection / metrics / lvis_evaluation . py "" , line <number> , in <module> from lvis import results as lvis_results file "" / usr / local / lib / python3 . <number> / dist - packages / lvis / __init__ . py "" , line <number> , in <module> from lvis . vis import lvisvis file "" / usr / local / lib / python3 . <number> / dist - packages / lvis / vis . py "" , line <number> , in <module> import cv2 file "" / usr / local / lib / python3 . <number> / dist - packages / cv2 / __init__ . py "" , line <number> , in <module> bootstrap ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / cv2 / __init__ . py "" , line <number> , in bootstrap if __load_extra_py_code_for_module ( "" cv2 "" , submodule , debug ) : file "" / usr / local / lib / python3 . <number> / dist - packages / cv2 / __init__ . py "" , line <number> , in __load_extra_py_code_for_module py_module = importlib . import_module ( module_name ) file "" / usr / lib / python3 . <number> / importlib / __init__ . py "" , line <number> , in import_module return _bootstrap . _gcd_import ( name [ level <happy> , package , level ) file "" / usr / local / lib / python3 . <number> / dist - packages / cv2 / mat_wrapper / __init__ . py "" , line <number> , in <module> cv . _registermattype ( mat ) attributeerror initialized module ' cv2 ' has no attribute ' _registermattype ' ( most likely due to a circular import ) ` ` ` </details>",1
tensorflow/tensorflow,can not run in python <number> . <number> env . <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell error when run in python <number> . <number> env ! ` ` ` # # # standalone code to reproduce the issue ` ` ` shell none ` ` ` # # # relevant log output _no response_ </details>,1
tensorflow/tensorflow,"feature request - support tif images in image_dataset_from_directory <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution linux mint # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell currently , ` image_dataset_from_directory ` supports only ` allowed formats ' . gif ' , ' . jpeg ' , ' . jpg ' , ' . png ' ) ` so , if you have tif images it will not find them ` no images found in directory ` ` ` ` # # # standalone code to reproduce the issue ` ` ` shell - ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,when will import the alpha tensor ' s fast matrix mutiplication . <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell <url> faster matrix multiplication algorithms has been discovered by alpha tensor . when will tensorflow import these multiplicatio algorithms ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <url> ` ` ` # # # relevant log output _no response_ </details>,1
tensorflow/tensorflow,"is there any ways i can embed my self - implemented fp8 format ( c / c + + ) into tensorflow , and support current ops automatically ? <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell it looks like there is no way to include a self - implemented data format ( eg . fp8 ) to support current ops automatically . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell it looks like there is no way to include a self - implemented data format ( eg . fp8 ) to support current ops automatically . ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"update the android ndk to r25b lts currently the android build of tensorflow and tensorflow lite use an older ndk , either <number> or <number> . the latest lts release of the [ android ndk ] ( <url> is r25b ( the exact version is currently ` <number> . <number> ` ) , and [ supports ] ( <url> the latest features and compilers ( llvm <number> ) . see earlier ndk updates <url> update tflite to use android ndk r18b - <url> update the tflite android dockerfile to use ndk r19c - <url> update ndk version to r19c - <url> [ tf . lite ] update stale doc reference to recommended ndk version - <url>",1
tensorflow/tensorflow,"clarify functionality of deserialized subclassed models in docs <details> <summary> click to expand </summary> # # # issue type documentation feature request # # # source binary # # # tensorflow version tf <number> and <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? in the ` savedmodel ` format documentation [ here ] ( <url> it says : > in the absence of the model / layer config , the call function is used to create a model that exists like the original model which can be trained , evaluated , and used for inference . and : > the first loaded model is loaded using the config and custommodel class . the second model is loaded by dynamically creating the model class that acts like the original model . i am finding that when a subclassed model is saved in the ` savedmodel ` format , upon re - loading it can be trained , evaluated , and used for inference in the same way as the original model . however , other functionality such as the custom ` from_config ` and ` get_config ` methods do not work . for example , attempting to clone the loaded model with ` loaded_model_clone = loaded_model . from_config ( loaded_model . get_config ( ) ) ` leads to errors . i assume this is because loading a ` custommodel ` without passing ` custom_objects ` ( or registering it ) gives a ` keras . saving . saved_model . load . custommodel ` , which does not contain the full functionality of the original ` custommodel ` ? it would be helpful if the docs clarified the functional limitations of a ` savedmodel ` loaded without the ` custom_objects ` being provided . the documentation ( and example ) in [ savedmodel format ] ( <url> also seems to contradict the guidance in [ custom objects ] ( <url> in the former , it suggests a custom ` savedmodel ` can be loaded without providing the ` custom_objects ` , albeit with limited functionality , whereas the latter suggests you should always register or pass in the ` custom_objects ` ( i . e . "" _additionally , you should use register the custom object so that keras is aware of it . _ "" ) . # # # standalone code to reproduce the issue extended from example in [ savedmodel format ] ( <url> colab notebook gist : <url> code : ` ` ` python import tensorflow as tf from tensorflow import keras import numpy as np class custommodel ( keras . model ) : def __init__ ( self , hidden_units ) : <hashtag> super </hashtag> ( custommodel , self ) . __init__ ( ) super ( ) . __init__ ( ) self . hidden_units = hidden_units self . dense_layers = [ keras . layers . dense ( u ) for u in hidden_units ] def call ( self , inputs ) : x = inputs for layer in self . dense_layers : x = layer ( x ) return x def get_config ( self ) : return { "" hidden_units "" : self . hidden_units } <user> def from_config ( cls , config ) : return cls ( * * config ) model = custommodel ( [ <number> , <number> , <number> ] ) # build the model by calling it input_arr = tf . random . uniform ( ( <number> , <number> ) ) outputs = model ( input_arr ) model . save ( "" my_model "" ) # option <number> : load with the custom_object argument . loaded_1 = keras . models . load_model ( "" my_model "" , custom_objects ={ "" custommodel "" : custommodel } ) # option <number> : load without the custommodel class . # delete the custom - defined model class to ensure that the loader does not have # access to it . del custommodel loaded_2 = keras . models . load_model ( "" my_model "" ) np . testing . assert_allclose ( loaded_1 ( input_arr ) , outputs ) np . testing . assert_allclose ( loaded_2 ( input_arr ) , outputs ) print ( "" \ \ ninitial save / load \ \ n # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # "" ) print ( "" original model :"", model ) print ( "" model loaded with custom objects :"", loaded_1 ) print ( "" model loaded without the custom object class :"", loaded_2 ) print ( "" \ \ ncloning \ \ n # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # "" ) cloned_loaded_1 = loaded_1 . __class__ . from_config ( loaded_1 . get_config ( ) ) print ( "" clone of model loaded with custom objects :"", cloned_loaded_1 ) cloned_loaded_2 = loaded_2 . __class__ . from_config ( loaded_2 . get_config ( ) ) print ( "" clone of model loaded without the custom object class :"", cloned_loaded_2 ) ` ` ` # # # relevant log output ` ` ` shell warning : tensorflow : no training configuration found in save file , so the model was not <emphasis> compiled . compile it manually . warning : tensorflow : no training configuration found in save file , so the model was not <emphasis> compiled . compile it manually . initial save / load # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # original model : < __main__ . custommodel object at 0x 7 fbf613e1950 > model loaded with custom objects : < __main__ . custommodel object at 0x 7 fbf60f34e10 > model loaded without the custom object class : < keras . saving . saved_model . load . custommodel object at 0x 7 fbf60ea7b10 > cloning # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # clone of model loaded with custom objects : < __main__ . custommodel object at 0x 7 fbf613e89d0 > - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - typeerror traceback ( most recent call last ) / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py in from_config ( cls , config , custom_objects ) <number> try : - > <number> model = cls ( * * config ) <number> except typeerror as e : <number> frames typeerror : ( ' keyword argument not understood :', ' hidden_units ' ) during handling of the above exception , another exception occurred : typeerror traceback ( most recent call last ) / usr / local / lib / python3 . <number> / dist - packages / keras / engine / training . py in from_config ( cls , config , custom_objects ) <number> except typeerror as e : <number> raise typeerror ( - > <number> "" unable to revive model from config . when overriding "" <number> "" the ` get_config ( ) ` , make sure that the returned "" <number> "" config contains all items used as arguments in the "" typeerror : unable to revive model from config . when overriding the ` get_config ( ) ` , make sure that the returned config contains all items used as arguments in the constructor to < class ' keras . saving . saved_model . load . custommodel ' > , which is the default behavior . you can override this default behavior by defining a ` from_config ` method to specify how to create an instance of custommodel from the config . error encountered during deserialization argument not understood :', ' hidden_units ' ) ` ` ` </details>",1
tensorflow/tensorflow,"tf lite enable flex delegate c + + api ( with cmake of bazel ) * * system information * * - linux ubuntu <number> <sad> - tensorflow installed from source : - tensorflow version commit 4 7 e07ba0d68c55dba62bff5b8486291086840097 : hi , i want to run simple conv2d layer training using c + + api of tf lite . i ’ ve used examples / minimal project as reference . calling trainer - > invoke ( ) leads to next error : ` error : tensorflow lite error : select tensorflow op ( s ) , included in the given model is ( are ) not supported by this interpreter . make sure you apply / link flex delegate before inference . for the android , it can be resolved by adding “ org . tensorflow : tensorflow - lite - select - tf - ops ” dependency … ` ` error number <number> ( flexconv2dbackpropfilter ) failed to prepare . ` i didn ’ t find any good tutorial on flex delegate . please , tell me , how to build tf lite with flex using cmake and how to make this interpreter use flex ’ s implementation of this node . thanks",1
tensorflow/tensorflow,"a flag to enable the previous rng behavior for ` tf . keras . initializers ` # # # issue type feature request # # # source binary # # # tensorflow version tf <number> # # # custom code no # # # current behaviour ? according to [ release note ] ( <url> rng behavior change for ` tf . keras . initializers ` since ` tf <number> ` . in particular , ` tf . random . set_seed ( seed ) ` is not enough to get the same model weights - we need to set explicit seeds in the initializers . in general , this is not an issue . however , for * * testing purpose * * , this makes things much more difficult . for example , let us say we have ` mycustommodel ` , implemented with layers without specifying any initializer ( therefore , no explicit seed with initializer ) . however , if we want to have a ci test that verifies the model produces the same result , it is impossible with tf <number> due to the new change . with tf < <number> , we can set ` tf . random . set_seed ( seed = <number> ) ` , and the model weights will be the same , so we can check if the output matches the expected values . it would be great if there is a way to have previous behavior for * * testing purpose * * .",1
tensorflow/tensorflow,"log , pow , div unsupported in 1 6 x8 precision it seems these ops are supported in 8 x8 mode , but not in 1 6 x8 . the latter is very important for our organization , as it saves a lot of rounding error over 8 x8 . is full 1 6 x8 support on the current roadmap ? if not , could we help to contribute this feature ? # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> linux ubuntu <number> - tensorflow installation ( pip package or built from source ) : pip tf - nightly - tensorflow library ( version , if pip package or github sha , if built from source ) : <number> . <number> - dev20220916 # # # <number> . code ` ` ` import numpy as np import tensorflow as tf import keras def data_generator ( <sad> for x in range ( <number> , <number> <sad> yield [ np . array ( x ) . astype ( np . float32 ) ] def test_layer ( layer ) : model = tf . keras . model ( inputs =[ in_tensor ] , outputs =[ layer ] ) converter = tf . lite . tfliteconverter . from_keras_model ( model ) converter . representative_dataset = data_generator converter . optimizations = [ tf . lite . optimize . default ] converter . target_spec . supported_ops = [ tf . lite . opsset . experimental_tflite_builtins_activations_int16_weights_int8 ] converter . inference_input_type = tf . int16 converter . inference_output_type = tf . int16 try : tflite_model = converter . convert ( ) except exception as e : print ( "" received exception :\\ n %s "" % str ( e ) ) in_tensor = tf . keras . input ( shape =( <number> , ) ) test_layer ( tf . math . log ( in_tensor ) ) test_layer ( in_tensor * * <number> ) test_layer ( in_tensor / in_tensor ) ` ` ` # # # <number> . failure after conversion conversion fails , with the following error messages : > quantization to 1 6 x8 - bit not yet supported for op : ' log ' . > quantization to 1 6 x8 - bit not yet supported for op : ' pow ' . > quantization to 1 6 x8 - bit not yet supported for op",1
tensorflow/tensorflow,"updating tflite convtranspose to make it support dynamic inputs . * * system information * * - os platform and distribution ( e . g . , linux ubuntu <number> <sad> linux ubunutu <number> - tensorflow installed from ( source or binary ) : - tensorflow version ( or github sha if from source ) <number> . <number> * * standalone code to reproduce the issue * * converting any convtranspose layer from onnx to tensorflowlite . * * any other info / logs * * the onnx does not have requirement for output_shape argument for convtranspose layer . [ <url> since that can be calculated . but in tflite the convtranspose layer requires mandatory requirement for output_shape . [ <url> so because of this the dynamic reshape happens in wrong way in tflite convtranpose , but for onnx it can be done . is it possible to remove the output_shape tensor requirement in tflite and similarly be updated in tflite convertor ? or any other workaround will be appreciated .",1
tensorflow/tensorflow,"not enough flexibility to choose actual accelerator in coreml delegate only [ two options exist ] ( <url> when creating a coreml delegate typedef enum { / / create core ml delegate only on devices with apple neural engine . / / returns nullptr otherwise . tflitecoremldelegatedeviceswithneuralengine , / / always create core ml delegate tflitecoremldelegatealldevices } tflitecoremldelegateenableddevices ; ` ` ` these do not quite fit what ' s possible with coreml , [ as documented here ] ( <url> ideally , we should have a way to specify whether we want to use any accelerator ( including neural engine ) , cpu only , or cpu and gpu ( excluding neural engine ) . ios <number> will also introduce a way to use cpu and neural engine , i . e . excluding gpu . currently the coreml delegate always uses ` mlcomputeunitsall ` in [ coreml_executor . mm ] ( <url>",1
tensorflow/tensorflow,"please make different versions of tensorflow compatible with each other . <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version all versions # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell tensorflow x . <number> is completely incompatible with tensorflow x . <number> . if i try to run a colab notebook , and the notebook was written using tensorflow x . <number> , but the newest version of tensorflow is now x . <number> or later , then the notebook will not work . it would be nice to have some consistency between versions so i do not have to know the version of tensorflow that the notebook was written in to run it . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell literally use any notebook more than a year old . ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"unable to free memory allocated by opkernelcontext <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell the opkernelcontext used in custom op ' s compute method does not have an option to free the temporary allocated by it . <url> does not have an api to free the memory allocated by "" allocate_temp "" method . do we have any solution to free the memory allocated using allocate_temp ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell its a request ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"tf . distribute . mirroredstrategy for asynchronous training <details> <summary> click to expand </summary> # # # issue type feature request # # # tensorflow version <number> . <number> # # # python version <date> # # # cuda / cudnn version <number> # # # use case i need to run multiple asynchronous copies of the same model on different slices of the dataset ( e . g . with bootstrap sampling ) . there ' s no good <emphasis> way to do this in keras api that i am aware of , although a couple of hacks exist . would this use case be feasible with tf . distribute ? # # # feature request ` tf . distribute . mirroredstrategy ` is a synchronous , data parallel strategy for distributed training across multiple devices on a single host worker . would it be possible to modify this strategy to allow for asynchronous training of all model replicas , without computing the average gradient over all replicas to update weights ? in this case each replica would need its own un - mirrored copy of model weights , and the update rule would depend only on the loss and gradients of each replica . thanks",1
tensorflow/tensorflow,"leakyrelu in tensorflow lite with the hexagon delegate not supported when using a tflite model ( <number> - bits quantized via tensorflow lite conversion framework ) that includes the activation function "" leakyrelu "" , the hexagon delegate from tensorflow framework cannot perform the dnn inference on the whole graph , but rather it falls back to the cpu / xnnpack delegate . this is due to the fact that ' leakyrelu ' operation is not supported by the hexagon delegate ( confirmed in tensorflow doc : <url> when using relu activation function ( and relu6 as well ) , we can see below that the tf hexagon delegate can process the whole dnn graph , unfortunately , the qualitative results i get are much worse , hence the need of having ' leaky relu ' implemented in the hexagon delegate . * * system information * * - os platform and distribution ) : android <number> , ndk r21e - tensorflow installed from ( source or binary ) : from source using the release tag ' <number> . <number> ' - tensorflow version ( or github sha if from source ) : <number> . <number> * * output of tensorflow library when running an inference with a model that includes ' leakyrelu ' activation function * * ` ` ` info : created tensorflow lite xnnpack delegate for cpu . info : initialized tensorflow lite runtime . loaded libcdsprpc . so info : tflitehexagondelegate delegate : <number> nodes delegated out of <number> nodes with <number> partitions . info : replacing <number> node ( s ) with delegate ( tflitehexagondelegate ) node , yielding <number> partitions . ` ` ` as we can see below when replacing ' leakyrelu ' operation by ' relu ' , then the tf hexagon delegate can process the whole dnn graph . * * output of tensorflow library when running an inference with a model that includes ' relu ' activation function * * ` ` ` info : created tensorflow lite xnnpack delegate for cpu . info : initialized tensorflow lite runtime . loaded libcdsprpc . so info : tflitehexagondelegate delegate : <number> nodes delegated out of <number> nodes with <number> partitions . info <number> node ( s ) with delegate ( tflitehexagondelegate ) node , yielding <number> partitions . ` ` ` would it be possible to implement ' leakyrelu ' in tf hexagon delegate ?",1
tensorflow/tensorflow,"add bazel rule to selectively build tflite by ops instead of model <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> , all # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? per tensorflow lite ' s documentation on reducing binary size ( <url> one way to reduce tflite ' s binary size is to build it with a reduced set of ops based on a list of models on disk . it ' d be nice if instead of a list of models , users could instead specify a list of ops that they want included in the binary ( for both android and ios ) . this is useful in environments where you may not have the models immediately available , but know the set of ops the group of models will want . # # # standalone code to reproduce the issue ` ` ` shell n / a ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"tensorrt max number of engines <details> <summary> click to expand </summary> # # # issue type documentation feature request # # # source source # # # tensorflow version tf2 . <number> + tensorrt # # # custom code no # # # os platform and distribution <number> ubuntu # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell thank you for adding support for tensor - rt python api . it seems like tf - trt has a limit on the number of engines it can create , and it seems to be <number> . i see that ~ <percent> ops are converted , when i expect more to be converted . even for larger models the number of engines is exactly <number> . [* ] total number of tensorrt engines : <number> [* ] % of ops converted : <percent> [ <number> / <number> ] ` ` ` is there some documentation on setting max number of tensorrt engines . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell apologies , the model itself is not easy to share , but the conversion follows standard steps : params = params . _replace ( precision_mode = precision_mode , max_workspace_size_bytes = <number> < < <number> , # <number> , <number> bytes maximum_cached_engines = <number> , minimum_segment_size = <number> , allow_build_at_runtime = true , ) converter = trt . trtgraphconverterv2 ( input_saved_model_dir = path , conversion_params = params , ) converter . convert ( ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell [* ] total number of tensorrt engines : <number> [* ] % of ops converted [ <number> / <number> ] ` ` ` ` ` ` </details>",1
tensorflow/tensorflow,"how to build tensorflow - lite - c enabling flex option using cmake <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version tf <number> . <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device ubuntu <number> . <number> lts # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version gcc <number> . <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i ' d like to use the tensorflow - lite model created in python in c + + . but , i am facing a problem where i can not call the relu activation included in the tflite file on c + + . the python code i wrote to create the tflite model is as follows . i am using tensorflow <number> . <number> version in ubuntu environment by directly building using cmake . by the way , when i try to use relu for keras activation , i get the below error . i did a google search and found that it was caused by lack of flex library . however , i could not find a way to build using cmake instead of bazel in the documentation below . - <url> is there currently any way to support this ? or i can use relu activation or is there any other way ? ( using not keras relu but another relu activation ) ` ` ` # # # standalone code to reproduce the issue ` ` ` shell class predicteddestination ( tf . module ) : def __init__ ( self ) : self . model = tf . keras . sequential ( [ tf . keras . layers . dense ( <number> , input_shape =( <number> , ) , name = ' input ' ) , tf . keras . layers . dense ( <number> , activation = tf . nn . relu , name = ' dense_1 ' ) , tf . keras . layers . dense ( <number> , activation = tf . nn . relu , name = ' dense_2 ' ) , tf . keras . layers . dense ( <number> , activation = tf . nn . relu , name = ' dense_3 ' ) , tf . keras . layers . dense ( <number> ) , ] ) self . model . compile ( optimizer = ' sgd ' , loss = tf . keras . losses . categoricalcrossentropy ( from_logits = true ) ) # the ` train ` function takes a batch of input images and labels . <user> . function ( input_signature =[ tf . tensorspec ( [ none , <number> ] , tf . float32 ) , tf . tensorspec ( [ none , <number> ] , tf . float32 ) , ] ) def train ( self , x , y ) : epochs = <number> for i in range ( epochs ) : with tf . gradienttape ( ) as tape : prediction = self . model ( x ) loss = self . model . loss ( y , prediction ) gradients = tape . gradient ( loss , self . model . trainable_variables ) self . model . optimizer . apply_gradients ( zip ( gradients , self . model . trainable_variables ) ) result = { "" loss "" : loss } return result <user> . function ( input_signature =[ tf . tensorspec ( [ none , <number> ] , tf . float32 ) , ] ) def predict ( self , x) : logits = self . model ( x ) probabilities = tf . nn . softmax ( logits , axis = - <number> ) print ( probabilities ) print ( logits ) return { "" output "" : probabilities , "" logits "" : logits } model = predicteddestination ( ) saved_model_dir = "" predicted_destination_model "" tf . saved_model . save ( model , saved_model_dir , signatures ={ ' train ' : model . train . get_concrete_function ( ) , ' predict ' : model . predict . get_concrete_function ( ) , } ) converter = tf . lite . tfliteconverter . from_saved_model ( saved_model_dir ) converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins , # enable tensorflow lite ops . tf . lite . opsset . select_tf_ops # enable tensorflow ops . ] converter . experimental_enable_resource_variables = true tflite_model = converter . convert ( ) open ( ' predicted_destination . tflite ' , ' wb ' ) . write ( tflite_model ) ` ` ` # # # relevant log output ` ` ` shell info : created tensorflow lite xnnpack delegate for cpu . error : select tensorflow op ( s ) , included in the given model , is ( are ) not supported by this interpreter . make sure you apply / link the flex delegate before inference . for the android , it can be resolved by adding "" org . tensorflow : tensorflow - lite - select - tf - ops "" dependency . see instructions ` ` ` </details>",1
tensorflow/tensorflow,"load tf lite model to xla hi , i would like to know if it possible to take a tf lite model ( quarantined ) and compile into executable code using xla / jit . in this lick you have an example about how to create an executable given an tf model in other words can i use "" tfcompile "" with tf lite quarantined models ?",1
tensorflow/tensorflow,"tflite ios batch_size greater than <number> not working my model was trained with pytorch . convert this model to tflite model with input shape { <number> , <number> , <number> , <number> } and is working as expected . but change this model to input shape { <number> , <number> , <number> , <number> } the inference result is not correct .",1
tensorflow/tensorflow,"support int8 for tf . split and tf . one_hot <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution windows <number> enterprise 2 0 h2 # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell tensorflow will not work with int8 tensors when using one_hot or splitv . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf int8_tensor = tf . constant ( [ [ <number> , <number> ] , [ <number> , <number> ] , [ <number> , <number> ] ] , dtype = tf . int8 ) try : tf . one_hot ( int8_tensor , <number> ) except exception as e : print ( e ) ` ` ` # # # relevant log output ` ` ` shell tensorflow . python . framework . errors_impl . invalidargumenterror : value for attr ' tlen ' of int8 is not in the list of allowed values : int32 , int64 ; nodedef : { { node splitv } }; op < name = splitv ; signature = value : t , size_splits : tlen , split_dim : int32 - > output : num_split*t <censored> ; attr = num_split : int , min = <number> ; attr = t : type ; attr = tlen : type , default = dt_int64 , allowed =[ dt_int32 , dt_int64 ] > [ op : splitv ] name : split tensorflow . python . framework . errors_impl . invalidargumenterror : value for attr ' ti ' of int8 is not in the list of allowed values : uint8 , int32 , int64 ; nodedef onehot } }; op < name = onehot ; signature = indices : ti , depth : int32 , on_value : t , off_value : t - > output : t ; attr = axis : int , default = - <number> ; attr = t : type ; attr = ti : type , default = dt_int64 , allowed =[ dt_uint8 , dt_int32 , dt_int64 ] > [ op : onehot ] ` ` ` </details>",1
tensorflow/tensorflow,"__array_interface__ support ? <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? hi . over at <url> our image class has the ` __array_interface__ ` attribute , to support converting pillow images to numpy . see <url> a recent discussion has revealed that tensorflow ' s ` reshape ` method ( and i have to imagine other methods as well ) accepts an object that provides an ` __array__ ` method , but not an object with an ` __array_interface__ ` attribute . my question - is there any interest from tensorflow in supporting objects with ` __array_interface__ ` ? # # # standalone code to reproduce the issue here is code that fails with the latest version of pillow . ` ` ` python from pil import image import tensorflow as tf im = image . new ( "" l "" , ( <number> , <number> ) ) tf . reshape ( im , ( <number> , <number> ) ) ` ` ` however , if my assertion that tensorflow does not accept ` __array_interface__ ` is at all in doubt , let me know and i will put together a better example . ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"add ` cdist ` - an analog of ` scipy . cdist ` | ` torch . cdist ` # feature request source : binary tensorflow version : <number> custom code # current behavior there is no equivalent built - in function of the following two in ` tensorflow ` . i need to use this method on large size embedding vectors and require a efficient vectorized implementation . ` ` ` python scipy . spatial . distance . cdist torch . cdist ` ` ` the same request has been asked several times but closed without any strong reason and no response further to a new commenter . so , kindly * * do not close * * without further discussion . - <url> - <url>",1
tensorflow/tensorflow,"conda - forge release of tensorflow <number> . x for win - <number> <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version tf > = <number> # # # custom code no # # # os platform and distribution windows10 # # # mobile device _no response_ # # # python version >= <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell the win - <number> version of tensorflow on conda - forge is only available at v1 . <number> , please make a release of v2 . x , preferable >= <number> . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell conda install tensorflow - c conda - forge ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"add parametricscalar layer <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell it would be nice to add a parametricscalar layer where learnable scalars are multiplied element - wise with the input similar to the prelu activation function . although this layer can be implemented as a custom layer , it is a commonly used module to merge multiple results together with learnable weights . a sample implementation is provided in the "" standalone code "" section . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell class parametricscalar ( keras . layers . layer ) : "" "" "" combine multiple activations weighted by learnable variables "" "" "" def __init__ ( self , alpha_initializer = ' ones ' , shared_axes = none , * * kwargs ) : super ( ) . __init__ ( * * kwargs ) self . alpha_initializer = keras . initializers . get ( alpha_initializer ) if shared_axes is none : self . shared_axes = none elif not isinstance ( shared_axes , ( list , tuple ) <sad> self . shared_axes = [ shared_axes ] else : self . shared_axes = list ( shared_axes ) def get_config ( self ) : return { ' act_set ' : self . act_set } def build ( self , input_shape ) : param_shape = list ( input_shape [ <number> :]) if self . shared_axes is not none : for i in self . shared_axes : param_shape [ i - <number> ] = <number> self . alpha = self . add_weight ( shape = param_shape , name = ' alpha ' , initializer = self . alpha_initializer ) def get_config ( self ) : config = { ' alpha_initializer ' : keras . initializers . serialize ( self . alpha_initializer ) , ' shared_axes ' : self . shared_axes } base_config = super ( ) . get_config ( ) return dict ( list ( base_config . items ( ) ) + list ( config . items ( ) ) ) def call ( self , inputs ) inputs * self . alpha ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"add simplemlcreatemodelresource , simplemlinferenceopwithhandle to allowed list ( lite converter ) <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell a bug happened ! i am using lite converter to convert a tensorflow model ( random forest from the decision forest library ) into a tensorflow lite model . i receive the following <elongated> error : simplemlcreatemodelresource , simplemlinferenceopwithhandleop is neither a custom op nor a flex op . the troubleshooting page says to add these to the ' allowed list ' . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell model = tdf . keras . randomforestmodel ( ) model . fit ( train_data ) model . save ( ' / project / first_model ' ) converter = tf . lite . tfliteconverter . from_saved_model ( ' / project / first_model ' ) tflite_model = converter . convert ( ) ` ` ` # # # relevant log output ` ` ` shell convertererror : <unknown> : <number> : error : loc ( fused [ "" simplemlcreatemodelresource :"", "" simplemlcreatemodelresource "" ]): ' tf . simplemlcreatemodelresource ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" simplemlcreatemodelresource :"", "" simplemlcreatemodelresource "" ]): error code : error_needs_custom_ops <unknown> : <number> : error : loc ( callsite ( callsite ( callsite ( fused [ "" simplemlinferenceopwithhandle :"", "" inference_op <user> "" ] at fused [ "" statefulpartitionedcall :"", "" random_forest_model / statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): ' tf . simplemlinferenceopwithhandle ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ]): called from <unknown> : <number> : note : loc ( callsite ( callsite ( callsite ( fused [ "" simplemlinferenceopwithhandle :"", "" inference_op <user> "" ] at fused [ "" statefulpartitionedcall :"", "" random_forest_model / statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall <user> "" ] ) at fused [ "" statefulpartitionedcall :"", "" statefulpartitionedcall_1 "" ])): error code : error_needs_custom_ops <unknown> : <number> : error : failed while converting : ' main ' : some ops in the model are custom ops , see instructions to implement custom ops : <url> custom ops : simplemlcreatemodelresource , simplemlinferenceopwithhandle details : tf . simplemlcreatemodelresource ( ) - > ( tensor < ! tf_type . resource > ) : { container = "" "" , device = "" "" , shared_name = "" simple_ml_model_0c74f688 - 4 8 9 e - 4 6 e7 - aa58 - 9 8 3 fddef4f14 "" } tf . simplemlinferenceopwithhandle ( tensor < ? x8xf32 > , tensor <0x0xf32> , tensor <0x0xi32> , tensor <0xi32> , tensor <1xi64> , tensor <1xi64> , tensor < ! tf_type . resource > ) - > ( tensor < ? x6xf32 > , tensor < 6 x ! tf_type . string > ) : { dense_output_dim = <number> device = "" "" } ` ` ` </details>",1
tensorflow/tensorflow,support item assignment in tensor object . issue type : feature request source : binary tensorflow version : <number> custom code : yes # current behaviour ? item assignment is not supported . discuss more here . <url> # standalone code to reproduce the issue ` ` ` python outputs = tf . zeros ( . <repeated> ) for step_index in range ( <number> ) = step_index + <number> ` ` ` please support this and make a roadmap for the next version of tensorflow . and kindly do not suggest to cast to ` tf . variable ` and use ` assign / assgn_add ` etc or any other non - intuitive workaround .,1
tensorflow/tensorflow,"` distributediterator ` cannot be checkpointed because it is not trackable <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version <number> . <number> - dev20220520 # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device n / a # # # python version <number> # # # bazel version n / a # # # gcc / compiler version n / a # # # cuda / cudnn version <number> / <number> # # # gpu model and memory n / a # # # current behaviour ? ` ` ` shell ` distributediterator ` cannot be checkpointed because it is not trackable ` ` ` # # # standalone code to reproduce the issue ` ` ` shell ds = tf . data . dataset . range ( <number> ) . shuffle ( <number> ) . batch ( <number> ) ds_it = iter ( ds ) print ( type ( ds_it ) ) ckpt = tf . train . checkpoint ( ds_it = ds_it ) strategy = tf . distribute . onedevicestrategy ( ' cpu ' ) dist_ds = strategy . experimental_distribute_dataset ( ds ) dist_ds_it = iter ( dist_ds ) print ( type ( dist_ds_it ) ) ckpt = tf . train . checkpoint ( dist_ds_it = dist_ds_it ) ` ` ` # # # relevant log output ` ` ` shell < class ' tensorflow . python . data . ops . iterator_ops . ownediterator ' > < class ' tensorflow . python . distribute . input_lib . distributediterator ' > - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - valueerror traceback ( most recent call last ) < ipython - input - <number> - cabcd820a79a > in <module> ( ) <number> dist_ds_it = iter ( dist_ds ) <number> print ( type ( dist_ds_it ) ) - - - > <number> ckpt = tf . train . checkpoint ( dist_ds_it = dist_ds_it ) / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / training / tracking / util . py in __init__ ( self , root , * * kwargs ) <number> # v to a trackable data structure when v is a list / dict / tuple . <number> converted_v = getattr ( self , k ) - > <number> _assert_trackable ( converted_v , k ) <number> <number> if root : / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / training / tracking / util . py in _assert_trackable ( obj , name ) <number> obj , ( base . trackable , def_function . function ) <sad> <number> raise valueerror ( - > <number> f "" ` checkpoint ` was expecting { name } to be a trackable object ( an "" <number> f "" object derived from ` trackable ` ) , got { obj } . if you believe this "" <number> "" object should be trackable ( i . e . it is part of the "" valueerror was expecting dist_ds_it to be a trackable object ( an object derived from ` trackable ` ) , got < tensorflow . python . distribute . input_lib . distributediterator object at 0x 7 fb291849610 > . if you believe this object should be trackable ( i . e . it is part of the tensorflow python api and manages state ) , please open an issue . ` ` ` </details>",1
tensorflow/tensorflow,"character - level seq2seq model for translation and beam search . <details> <summary> click to expand </summary> # # # issue type documentation feature request # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution colab gpu # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i was trying to implement seq2seq translation model at character level along with beam search by referring the tensorflow documentation . <url> for this , i changed only one parameter - - ' char_level = true ' in tf . keras tokenizer . there was no issue during model training , but i am getting error for inferences . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell # step <number> and step <number> def tokenize ( self , lang ) : # lang = list of sentences in a language # print ( len ( lang ) , "" example sentence : { } "" . format ( lang [ <number> ] ) ) lang_tokenizer = tf . keras . preprocessing . text . tokenizer ( filters = ' ' , oov_token ='< oov > ' , char_level = true ) lang_tokenizer . fit_on_texts ( lang ) # # tf . keras . preprocessing . text . tokenizer . texts_to_sequences converts string ( w1 , w2 , w3 , . <repeated> , wn ) # # to a list of correspoding integer ids of words ( id_w1 , id_w2 , id_w3 , . <repeated> , id_wn ) tensor = lang_tokenizer . texts_to_sequences ( lang ) # # tf . keras . preprocessing . sequence . pad_sequences takes argument a list of integer id sequences # # and pads the sequences to match the longest sequences in the given input tensor = tf . keras . preprocessing . sequence . pad_sequences ( tensor , padding = ' post ' ) return tensor , lang_tokenizer ` ` ` # # # relevant log output ` ` ` shell translate ( u ' hace mucho frio aqui . ' ) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - keyerror traceback ( most recent call last ) < ipython - input - <number> - a7e085e16f9f > in <module> ( ) - - - - > <number> translate ( u ' hace mucho frio aqui . ' ) <number> frames < ipython - input - <number> - d0c0d138384e > in <listcomp> ( . <number> ) <number> sentence = dataset_creator . preprocess_sentence ( sentence ) <number> - - - - > <number> inputs = [ inp_lang . word_index [ i ] for i in sentence . split ( ' ' ) ] <number> inputs = tf . keras . preprocessing . sequence . pad_sequences ( [ inputs ] , <number> maxlen = max_length_input , keyerror ` ` ` </details>",1
tensorflow/tensorflow,"unable to use tflite java on macos <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution macos # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell currently tflite on maven only distributes . so files for jni which are not usable on macos ( as it ' s not a mach - o file ) . i am trying to run some tests on a library i am working on outside of the android emulator , but can not run the tests due to the lack of . dylib files . is it possible to add a configuration for mac builds or possibly add a . jar artifact to maven with . dylib files for jni ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell built it locally and tried to run tests with junit . ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"how to full int <number> quantize a yamnet model ? <details> <summary> click to expand </summary> # # # issue type bug # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution linux , mac # # # mobile device linux ubuntu , mac m1 , mac intel # # # python version <number> , <number> , <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell how to full int <number> qat quantisation ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow_model_optimization as tfmot lastvaluequantizer = tfmot . quantization . keras . quantizers . lastvaluequantizer movingaveragequantizer = tfmot . quantization . keras . quantizers . movingaveragequantizer class defaultdensequantizeconfig ( tfmot . quantization . keras . quantizeconfig ) : # list all of your weights weights = { "" kernel "" : lastvaluequantizer ( num_bits = <number> , symmetric = true , narrow_range = false , per_axis = false ) } # list of all your activations activations = { "" activation "" : movingaveragequantizer ( num_bits = <number> , symmetric = false , narrow_range = false , per_axis = false ) } # configure how to quantize weights . def get_weights_and_quantizers ( self , layer ) : output = [ ] for attribute , quantizer in self . weights . items ( <sad> if hasattr ( layer , attribute ) : output . append ( ( getattr ( layer , attribute ) , quantizer ) ) return output # configure how to quantize activations . def get_activations_and_quantizers ( self , layer ) : output = [ ] for attribute , quantizer in self . activations . items ( <sad> if hasattr ( layer , attribute ) : output . append ( ( getattr ( layer , attribute ) , quantizer ) ) return output def set_quantize_weights ( self , layer , quantize_weights ) : # add this line for each item returned in ` get_weights_and_quantizers ` # , in the same order count = <number> for attribute in self . weights . keys ( <sad> if hasattr ( layer , attribute ) : setattr ( layer , attribute , quantize_weights [ count ] ) count + = <number> def set_quantize_activations ( self , layer , quantize_activations ) : # add this line for each item returned in ` get_activations_and_quantizers ` # , in the same order . count = <number> for attribute in self . activations . keys ( <sad> if hasattr ( layer , attribute ) : setattr ( layer , attribute , quantize_activations [ count ] ) count + = <number> # configure how to quantize outputs ( may be equivalent to activations ) . def get_output_quantizers ( self , layer ) : return [ ] def get_config ( self ) : return { } from quant import defaultdensequantizeconfig from tensorflow_model_optimization . python . core . quantization . keras . quantize import quantize_scope , quantize_apply import tensorflow_model_optimization as tfmot with quantize_scope ( { "" defaultdensequantizeconfig "" : defaultdensequantizeconfig , "" customlayer "" : customlayer }): def apply_quantization_to_layer ( layer ) tfmot . quantization . keras . quantize_annotate_layer ( layer , defaultdensequantizeconfig ( ) ) annotated_model = tf . keras . models . clone_model ( tflite_model , clone_function = apply_quantization_to_layer , ) qat_model = tfmot . quantization . keras . quantize_apply ( annotated_model ) qat_model . compile ( optimizer = tf . keras . optimizers . adam ( learning_rate = <number> ) , loss = "" categorical_crossentropy "" , metrics =[ ' accuracy ' ] ) qat_model . summary ( ) ` ` ` # # # relevant log output ` ` ` shell when i test the tflite model it predicts completely randomly ` ` ` </details>",1
tensorflow/tensorflow,"ragged tensor in ' batch_jacobian ' <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell the function ` tape . batch_jacobian ` does support ragged tensors . can something like the code below be done using ` tape . batch_jacobian ` , or did i do something wrong ? for normal tensor input , the code works just fine . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import numpy as np x_ragged = tf . raggedtensor . from_row_lengths ( [ [ <number> ] , [ <number> ] , [ <number> ] , [ <number> ] ] , [ <number> , <number> , <number> ] ) x_tensor = tf . constant ( [ [ [ <number> ] ] , [ [ <number> ] ] , [ [ <number> ] ] ] ) print ( x_ragged . shape , x_tensor . shape ) x = x_ragged with tf . gradienttape ( persistent = true ) as tape : tape . watch ( x ) y = x* x <censored> + x y = tf . reduce_sum ( y , axis =( - <number> ) ) out = tape . batch_jacobian ( y , x , experimental_use_pfor = true ) print ( y . shape ) print ( out ) ` ` ` # # # relevant log output ` ` ` shell valueerror : in user code : valueerror : no pfor vectorization defined for raggedtensortovariant name : "" loop_body / raggedtovariant / raggedtensortovariant "" op : "" raggedtensortovariant "" input : "" loop_body / raggedtovariant / raggedtensortovariant / rt_nested_splits_0 "" input : "" loop_body / addn "" attr { key : "" ragged_rank "" value { i : <number> } } attr { key : "" tsplits "" value { type : dt_int64 } } attr { key : "" tvalues "" value { type : dt_float } } attr { key : "" batched_input "" value { b : false } } experimental_type { type_id : tft_product args { type_id : tft_ragged args { type_id : tft_float } } } inputs ' loop_body / raggedtovariant / raggedtensortovariant / rt_nested_splits_0 : <number> ' shape =( <number> , ) dtype = int64 > , is_stacked = false , is_sparse_stacked = false ) , wrappedtensor ( t =< tf . tensor ' loop_body / addn / pfor / addn : <number> ' shape =( <number> , <number> , <number> ) dtype = float32 > , is_stacked = true , is_sparse_stacked = false ) ] . encountered an exception while vectorizing the batch_jacobian computation . vectorization can be disabled by setting experimental_use_pfor to false . ` ` ` </details>",1
tensorflow/tensorflow,"tensorflow core operator extractimagepatches , not supported <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda <number> . <number> / cudnn <number> . <number> # # # gpu model and memory rtx 1 6 6 0 ti and <number> gb # # # current behaviour ? ` ` ` shell i made a custom layer which uses extractimagepatches tensorflow operator , but it was not supported by tflite ( but listed as supported ) . i tried to enable the op manually but was unable to find . cc and . h file . it would be great if there is a solution to this problem , since my research depends on it . i am encountering the error when i am converting the model from tf to tflite . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell pip install tensorflow_model_optimization import tensorflow as tf import tensorflow_model_optimization as tfmot import matplotlib . pyplot as plt import numpy as np from keras . utils import np_utils from tensorflow . python . keras import activations from tensorflow . keras . callbacks import earlystopping def myconv2d ( ix , w , padding ) : # filter shape : [ filter_height , filter_width , in_channels , out_channels ] # flatten filters filter_height = int ( w . shape [ <number> ] ) filter_width = int ( w . shape [ <number> ] ) in_channels = int ( w . shape [ <number> ] ) out_channels = int ( w . shape [ <number> ] ) ix_height = int ( ix . shape [ <number> ] ) ix_width = int ( ix . shape [ <number> ] ) ix_channels = int ( ix . shape [ <number> ] ) filter_shape = [ filter_height , filter_width , in_channels , out_channels ] flat_w = tf . reshape ( w , [ filter_height * filter_width * in_channels , out_channels ] ) patches = tf . image . extract_patches ( ix , sizes =[ <number> , filter_height , filter_width , <number> ] , strides =[ <number> , <number> , <number> , <number> ] , rates =[ <number> , <number> , <number> , <number> ] , padding = padding ) patches_reshaped = tf . reshape ( patches , [ - <number> , ix_height , ix_width , filter_height * filter_width * ix_channels ] ) feature_maps = [ ] for i in range ( out_channels ) : feature_map = tf . reduce_sum ( tf . multiply ( flat_w [ :, i ] , patches_reshaped ) , axis = <number> , keepdims = true ) feature_maps . append ( feature_map ) features = tf . concat ( feature_maps , axis = <number> ) return features class myconv2d ( tf . keras . layers . layer ) : def __init__ ( self , filters , kernel_size , padding = ' same ' , * * kwargs ) : self . filters = filters self . kernel_size = kernel_size self . padding = padding <hashtag> self </hashtag> . units = units super ( myconv2d , self ) . __init__ ( * * kwargs ) def get_config ( self ) : config = super ( ) . get_config ( ) config . update ( { "" filters "" : self . filters , "" kernel_size "" : self . kernel_size , "" padding "" : self . padding , } ) return config def build ( self , input_shape ) : # only have a 3x3 kernel shape = self . kernel_size + ( input_shape [ - <number> ] , self . filters ) self . kernel = self . add_weight ( name = ' kernel ' , shape = shape , initializer = ' glorot_uniform ' , trainable = true ) self . b = self . add_weight ( name = "" bias "" , shape =( self . filters , ) , initializer = "" random_normal "" , trainable = true ) <hashtag> super </hashtag> ( ( myconv2d , self ) . build ( input_shape ) ) def call ( self , inputs ) : result = myconv2d ( inputs , self . kernel , self . padding ) + self . b return result def compute_output_shape ( self , input_shape ) : return input_shape [ : - <number> ] + ( self . filters , ) def load_dataset ( <sad> # load dataset ( trainx , trainy ) , ( testx , testy ) = tf . keras . datasets . mnist . load_data ( ) # reshape dataset to have a single channel trainx = trainx . reshape ( ( trainx . shape [ <number> ] , <number> , <number> , <number> ) ) testx = testx . reshape ( ( testx . shape [ <number> ] , <number> , <number> , <number> ) ) # one hot encode target values trainy = np_utils . to_categorical ( trainy ) testy = np_utils . to_categorical ( testy ) # convert from integers to floats train_norm = trainx . astype ( ' float32 ' ) test_norm = testx . astype ( ' float32 ' ) # normalize to range <number> - <number> trainx = train_norm / <number> testx = test_norm / <number> # return normalized images return trainx , trainy , testx , testy def create_model ( <sad> # creating a sequantial model model = tf . keras . sequential ( ) # adding convolution2d layer to the model of <number> filters of size 3x3 model . add ( myconv2d ( filters = <number> , kernel_size =( <number> ) ) ) model . add ( tf . keras . layers . activation ( activations . relu ) ) # adding a maxpooling 2 d layer of size 2 x2 model . add ( tf . keras . layers . maxpooling2d ( pool_size =( <number> ) ) ) # adding a dropout layer model . add ( tf . keras . layers . dropout ( <number> ) ) # adding a flatten layer model . add ( tf . keras . layers . flatten ( ) ) # adding dense layer with ' relu ' activation model . add ( tf . keras . layers . dense ( <number> , activation = ' relu ' ) ) # adding dense layer with ' softmax ' activation for output model . add ( tf . keras . layers . dense ( <number> , activation = ' softmax ' ) ) return model train_images , train_labels , test_images , test_labels = load_dataset ( ) model = create_model ( ) # compile model opt = tf . keras . optimizers . adam ( ) model . compile ( optimizer = opt , loss = ' categorical_crossentropy ' , metrics =[ ' accuracy ' ] ) es = earlystopping ( monitor = ' val_loss ' , mode = ' min ' , verbose = <number> , patience = <number> ) # fit model history = model . fit ( train_images , train_labels , epochs = <number> , batch_size = <number> , validation_data =( test_images , test_labels ) , callbacks =[ es ] ) # evaluate model scores = model . evaluate ( test_images , test_labels , verbose = <number> ) print ( "" accuracy : % . 2 f % % "" % ( scores [ <number> ]* <number> ) ) # stores scores quantize_annotate_model = tfmot . quantization . keras . quantize_annotate_model def representative_dataset ( <sad> for data in tf . data . dataset . from_tensor_slices ( ( train_images ) ) . batch ( <number> ) . take ( <number> <sad> yield [ tf . dtypes . cast ( data , tf . float32 ) ] quant_model = quantize_annotate_model ( model ) quant_model . compile ( optimizer = opt , loss = ' categorical_crossentropy ' , metrics =[ ' accuracy ' ] ) converter = tf . lite . tfliteconverter . from_keras_model ( quant_model ) converter . optimizations = [ tf . lite . optimize . default ] converter . representative_dataset = representative_dataset converter . allow_custom_ops = true converter . experimental_new_converter = true quantized_tflite_model = converter . convert ( ) ` ` ` # # # relevant log output ` ` ` shell runtimeerror : failed to initialize op resolver for calibration : there are unresolved custom ops : [ extractimagepatches ] encountered unresolved custom op : extractimagepatches . see instructions number <number> ( extractimagepatches ) failed to prepare . ` ` ` </details>",1
tensorflow/tensorflow,"function similar to torch . nn . functional . grid_sample <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell i want to convert a model containing torch . nn . functional . grid_sample function from pytorch format to tensorflow format . i was able to convert from pytorch format to onnx format ( see <url> to convert from onnx format to tensorflow format , i need to implement this function in the onnx_tf converter . is there an analogue of such a function in tensorflow ? if not , are there plans to implement it ? ` ` ` # # # standalone code to reproduce the issue ` ` ` shell torch . nn . functional . grid_sample ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"tf . keras . datasets . cifar10 . load_data ( path = ' cifar - <number> - python . tar . gz ' ) <details> <summary> click to expand </summary> # # # issue type feature request # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell the tf . keras . datasets . mnist . load_data ( path ='/ user / . keras / datasets / mnist . npz ' ) works fine , but the tf . keras . datasets . cifar10 . load_data ( ) have no path param , which means everytime everyone runs his / her jupyter scripts that requires cifar10 datasets , he / she had to download the datasets from source again , it ' s really boring and time - consuming <happy> ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import autokeras as ak import matplotlib . pyplot as plt from tensorflow . keras . datasets import cifar10 (x _train , y_train ) , (x _test , y_test ) = cifar10 . load_data ( ) ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,data init api for tflite swift <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> + # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell the current swift api only has ` init ` functions from files on disk unlike the java ( android ) api which has a byte buffer initializer . it ' d be convenient if the swift api could initialize ` interpreters ` from ` data ` . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell no code . this is a feature request ` ` ` # # # relevant log output _no response_ </details>,1
tensorflow/tensorflow,"[ feature request ] default keras callback for timing the training loop <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell the current keras progress bar callback displays training latency in time / step . the current recommendation is to disable the progress bar in production workflows . this poses <number> problems : <number> . the metric time / step is not batch size agnostic . while tuning batch size to fit the h / w , metrics represented in terms of samples allow for better head to head comparison . currently , an additional step of converting step to samples is required . <number> . production workflows that require continuous training will benefit greatly from being able to monitor training latency . a deterioration in training speed could lead to spike in training costs . i propose reporting an additional metric for training latency based on samples . <number> . a new verbosity setting that allows for reporting the training latency metrics without the progress bar . this could even be part of an existing verbosity . i would be happy to create a pr for these changes . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell n / a ` ` ` # # # relevant log output _no response_ </details>",1
tensorflow/tensorflow,"tf . train . checkpoint does not support rmsprop weights for tensorflow - macos <number> . <number> <details> <summary> click to expand </summary> # # # issue type feature request # # # source source # # # tensorflow version tensorflow - macos <number> . <number> # # # custom code no # # # os platform and distribution macos # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell optimizer is not supported when i select ' rmsprop ' in checkpoint = tf . train . checkpoint ( optimizer = ' rmsprop ' , model = model ) then i get ( <number> ) . the same when i do not use a string , but a full optimizer declaration in keras when i run it without setting an optimizer , then status . assert_consumed ( ) starts complaining : ( <number> ) ` ` ` # # # standalone code to reproduce the issue ` ` ` shell keras . optimizer_v2 . rmsprop . rmsprop tf . train . checkpoint ( optimizer = ' rmsprop ' , model = model ) ` ` ` # # # relevant log output ` ` ` shell ( <number> ) traceback ( most recent call last ) : file "" main . py "" , line <number> , in <module> main ( config_dot ) file "" main . py "" , line <number> , in main model = load_model ( config , training_data ) file "" / users / mark / code / pythonprojects / music_rnn / train . py "" , line <number> , in load_model checkpoint = tf . train . checkpoint ( optimizer = ' rmsprop ' , model = model ) file "" / users / mark / opt / anaconda3 / envs / tensorlfowgpu / lib / python3 . <number> / site - packages / tensorflow / python / training / tracking / util . py "" , line <number> , in __init__ _assert_trackable ( converted_v , k ) file "" / users / mark / opt / anaconda3 / envs / tensorlfowgpu / lib / python3 . <number> / site - packages / tensorflow / python / training / tracking / util . py "" , line <number> , in _assert_trackable raise valueerror ( valueerror : ` checkpoint ` was expecting optimizer to be a trackable object ( an object derived from ` trackable ` ) , got rmsprop . if you believe this object should be trackable ( i . e . it is part of the tensorflow python api and manages state ) , please open an issue . ( <number> ) traceback ( most recent call last ) : file "" main . py "" , line <number> , in <module> main ( config_dot ) file "" main . py "" , line <number> , in main model = load_model ( config , training_data ) file "" / users / mark / code / pythonprojects / music_rnn / train . py "" , line <number> , in load_model status . assert_consumed ( ) file "" / users / mark / opt / anaconda3 / envs / tensorlfowgpu / lib / python3 . <number> / site - packages / tensorflow / python / training / tracking / util . py "" , line <number> , in assert_consumed raise assertionerror ( assertionerror : unresolved object in checkpoint ( root ) . model . optimizer . iter : attributes { name : "" variable_value "" full_name : "" rmsprop / iter "" checkpoint_key : "" model / optimizer / iter / . attributes / variable_value "" } has_checkpoint_values { value : true } warning : tensorflow : detecting that an object or model or tf . train . checkpoint is being deleted with unrestored values . see the following logs for the specific values in question . to silence these warnings , use ` status . expect_partial ( ) ` . see <url> details about the status object returned by the restore function . warning : tensorflow : value in checkpoint could not be found in the restored object : ( root ) . model . optimizer . iter warning : tensorflow : value in checkpoint could not be found in the restored object : ( root ) . model . optimizer . decay warning : tensorflow : value in checkpoint could not be found in the restored object : ( root ) . model . optimizer . learning_rate warning : tensorflow : value in checkpoint could not be found in the restored object : ( root ) . model . optimizer . momentum warning : tensorflow : value in checkpoint could not be found in the restored object ` ` ` </details>",1
tensorflow/tensorflow,"unroll factor for keras . layers . rnn or performance fix for tensorarray / while_loop . <details> <summary> click to expand </summary> # # # issue type feature request # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution ubuntu <number> # # # cuda / cudnn version <number> # # # gpu model and memory rtx 2 0 8 0 ti </details> # # # feature description ` keras . layers . rnn ` supports unrolling , which is great for performance , unless the unrolled time dimension is too long . the xla compiler takes a ton of time processing a fully unrolled loop ( e . g . <number> iterations ) . every major compiler supports unrolling a loop for a given factor . the ` unroll ` argument from ` keras . layers . rnn ` could instead take an integer telling how many iterations it should unroll , and insert a while loop around the remaining factor . using an unroll factor of <number> would do miracles for most long time - dimension datasets . xla speedups are huge for my custom rnn cell , so i ' d like to use it , but now i am waiting <number> minutes for xla / ptxas to finish processing the unrolled loop . on the other hand , if i do not unroll , the while_loop introduces a tensorarray struct takes a tremendous amount of time every time - iteration of the rnn as there is a cumemcpyd2h of <number> bytes happening between gpu and cpu . the whole cuda driver pipeline stalls for this <number> - byte copy . performance drops by a factor of <number> to <number> because of this . i do not know if the <number> - byte copy is an unintentional performance bug in tensorarray / tf . while_loop or not . but if it ' s not , i think the unroll factor is a good compromise .",1
tensorflow/tensorflow,can tflite coreml delegate add elu activation support ? ( with fp16 as well ) _ <details> <summary> click to expand </summary> # # # issue type support # # # source source # # # tensorflow version tf2 . <number> # # # custom code no # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell a bug happened ! can tflite coreml delegate add elu activation support ? ( with fp16 as well ) _ ` ` ` # # # standalone code to reproduce the issue ` ` ` shell can tflite coreml delegate add elu activation support ? ( with fp16 as well ) _ ` ` ` # # # relevant log output ` ` ` shell can tflite coreml delegate add elu activation support ? ( with fp16 as well ) _ ` ` ` </details>,1
tensorflow/tensorflow,"tf . nn . embedding_lookup_sparse does not work with <user> . function ( jit_compile = true ) <details> <summary> click to expand </summary> # # # issue type bug # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution colab notebook # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` shell tried to use ` tf . nn . embedding_lookup_sparse ` within a function decorated with ` <user> . function ( jit_compile = true ) ` and it failed . ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf print ( tf . __version__ ) try : tpu = tf . distribute . cluster_resolver . tpuclusterresolver ( ) # tpu detection print ( ' running on tpu ' , tpu . cluster_spec ( ) . as_dict ( ) [ ' worker ' ] ) except valueerror : raise baseexception ( ' error : not connected to a tpu runtime ; please see the previous cell in this notebook for instructions ! ' ) tf . config . experimental_connect_to_cluster ( tpu ) tf . tpu . experimental . initialize_tpu_system ( tpu ) tpu_strategy = tf . distribute . experimental . tpustrategy ( tpu ) <user> . function ( jit_compile = true ) def run_embedding_bag ( params , sp_ids ) : return tf . nn . embedding_lookup_sparse ( params , sp_ids , none , combiner = ' sum ' , max_norm = none , name = none ) with tf . device ( ' / tpu : <number> ' <sad> params = tf . random . uniform ( [ <number> , <number> ] ) sp_ids = tf . sparse . sparsetensor ( [ [ <number> , <number> ] , [ <number> , <number> ] ] , values =[ <number> , <number> ] , dense_shape =[ <number> , <number> ] ) res = run_embedding_bag ( params , sp_ids ) print ( res . shape ) print ( run_embedding_bag . experimental_get_compiler_ir ( params , sp_ids ) ( stage = ' hlo ' ) ) ` ` ` # # # relevant log output ` ` ` shell invalidargumenterror : detected unsupported operations when trying to compile graph __inference_run_embedding_bag_978 [ _xlamustcompile = true , config_proto = <number> , executor_type = <number> ] on xla_tpu_jit ( no registered ' sparsesegmentsum ' opkernel for xla_tpu_jit devices compatible with node { { node embedding_lookup_sparse } } ) { { node embedding_lookup_sparse } } one approach is to outside compile the unsupported ops to run on cpus by enabling soft placement ` tf . config . set_soft_device_placement ( true ) ` . this has a potential performance penalty . ` ` ` </details>",1
tensorflow/tensorflow,"enable ` unique ` bool for ` tf . random . uniform ` * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) : no * * describe the feature and the current behavior / state . * * currently , the ` tf . random . uniform ` , randomly sample values form given min and max range * * without considering the repeating same value * * . for example , currently : ` ` ` python tf . random . uniform ( shape =[ <number> ] , maxval = <number> , dtype = tf . int32 , seed = <number> ) < tf . tensor : shape =( <number> , ) , dtype = int32 , numpy = array ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = int32 ) > ` ` ` ` but if it has a ` unique ` bool parameter , it would be possible to generate a unique random value . for example : ` ` ` python tf . random . uniform ( shape =[ <number> ] , maxval = <number> , dtype = tf . int32 , seed = <number> , unique = true ) < tf . tensor dtype = int32 , numpy = array ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = int32 ) > ` ` ` ` * * will this change the current api ? how ? * * from ` ` ` python tf . random . uniform ( shape , minval = <number> , maxval = none , dtype = tf . dtypes . int32 , seed = none , name = none ) ` ` ` to ` ` ` python tf . random . uniform ( shape , minval = <number> , maxval = none , dtype = tf . dtypes . int32 , seed = none , name = none , unique = false ) ` ` ` * * who will benefit from this feature ? * * a similar thing is possible with ` import random ; random . sample ` . so , having ` unique ` bool in ` tf . ranom . uniform ` might be useful in some special cases . similar param in [ tf . random . uniform_candidate_sampler ] ( <url> * * any other info . * * i am not sure if there is any other convenient tensorflow function that can be used to generate unique random values . i know we can do ` ` ` python tf . random . shuffle ( tf . range ( <number> ) ) ` ` ` but ` tf . random . shuffle ` has certain limitations to fall back to ` while_loop ` . that ' s why we can not use it here . let me know if i have missed something .",1
tensorflow/tensorflow,adding select tf ops to cmake * * system information * * - tensorflow version ( you are using ) : any - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * currently one has to decide between using select tf ops with bazel or gpu support with cmake . it would be nice if either bazel has an option to support gpu on any opencl system or cmake can build with tf ops . * * will this change the current api ? how ? * * no * * who will benefit with this feature ? * * everybody who wants to use gpu acceleration and tf ops .,1
tensorflow/tensorflow,"adding a parameter to teh tf . image . extract_patches function to change the value of added border pixels due to the padding <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * using tf . image . extract_patches with "" same "" padding leads to zeros on the image border . zero is a default value and cannot be changed by the user . this means that the mask data for image segmentation should always have zero as the background class , otherwise it does mess up after patching . it is best to add this default value as a parameter so the user can change it if needed . * * will this change the current api ? how ? * * adding a parameter to teh tf . image . extract_patches function to change the value of added border pixels due to the padding * * who will benefit with this feature ? * * anyone using this function for patching data for image segmentation * * any other info . * *",1
tensorflow/tensorflow,"how about exporting ` tensor : : fromproto ` to python api ? <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) the feature and the current behavior / state . * * if we have to convert tensorproto message in python env , we can not directly convert it . we have to <number> . construct a new tensor with protobuf message field <number> . serialize message to string and parse it using ` tf . io . parse_tensor ` <number> . or some other way * * will this change the current api ? how ? * * yes . maybe we can add the ` tf . from_tensor_proto ` like ` tf . make_tensor_proto ` . * * who will benefit with this feature ? * * the people who frequently handle protobuf messages . for example , i handle tensorproto messages directly when i predict some examples with tensorflow serving using grpc . * * any other info . * * [ ` tensor : : fromproto ` docs link ] ( <url>",1
tensorflow/tensorflow,"customize tf tensor multiplication * * system information * * - tensorflow version ( you are using ) : <number> . <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * is there a way o customize / modify the tensor / matrix multiplication operation used through out tensorflow ? let us say whenever i am executing a forward pass on a given input , involving a sequence of tensor multiplications defined by the architecture of the neural net , how would i proceed to change the very definition of how the multiplication is carried out ? which source file do i have to edit to achieve this ? maybe smewhere in ` tensorflow / python / ops ` ? thank you for your help .",1
tensorflow/tensorflow,"c - api binaries for <number> - bit for x86 instruction set * * system information * * - tensorflow version ( you are using ) : <number> . <number> - are you willing to contribute it ( yes / no ) : no * * describe the feature and the current behavior / state . * * tensorflow provides windows binaries for the c - api for <number> - bit processprs for instruction set x86 <happy> x64 ) , see it would be great to support this for <number> - bit also . * * who will benefit with this feature ? * * projects requiring to build in <number> - bit and <number> - bit os .",1
tensorflow/tensorflow,support vscode devcontiners for development * * system information * * - tensorflow version ( you are using ) : latest - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * support for vscode devcontainers is required for good dependency management and overall good support for modern development,1
tensorflow/tensorflow,"expand support for image file types ( primarily tiff ) this issue requests support for tiff images when using tensorflow for image processing research . * * system information * * - tensorflow version ( you are using ) : <number> . <number> available via colab : python <number> google compute engine backend ( gpu ) - are you willing to contribute it ( yes / no ) : i am willing to help but looking for high - level suggestions on how to implement this . feel free to assign me with a mentor . * * describe the feature and the current behavior / state . * * currently , tensorflow only supports a limited number of image filetypes . this should be expanded for both convenience and data uses of users who require other image filetypes . * * will this change the current api ? how ? * * maybe ? the current image decoder would have to be updated to read tiff filetypes . ~ no commands would have to change . ~ a ` tf . io . decode_jpeg ( sample_image ) ` equivalent would have to be added . * * who will benefit with this feature ? * * this feature would benefit domain science users who rely on tiff image types for microscopy images , among other uses . * * any other info . * * traceback on error if running tiff image filetype is shown below . even if i change the filetype to jpeg , if the image was originally tiff i get this error . ` ` ` python - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - invalidargumenterror traceback ( most recent call last ) [ < ipython - input - <number> - 9 4 0 ee08e0488 > ] ( https :// localhost : <number> /# ) in <module> ( ) <number> <number> - - - - > <number> sample_image = tf . io . decode_jpeg ( sample_image ) <number> print ( sample_image . shape ) <number> frames [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / execute . py ] ( https :// localhost : <number> /# ) in quick_execute ( op_name , num_outputs , inputs , attrs , ctx , name ) <number> ctx . ensure_initialized ( ) <number> tensors = pywrap_tfe . tfe_py_execute ( ctx . _handle , device_name , op_name , - - - > <number> inputs , attrs , num_outputs ) <number> except core . _notokstatusexception as e : <number> if name is not none : invalidargumenterror image file format . one of jpeg , png , gif , bmp required . [ op : decodejpeg ] ` ` `",1
tensorflow/tensorflow,"xla ` ludecomposition ` support for cpu / gpu * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * ` xla : : ludecomposition ` in tensorflow / compiler / xla / client / lib / lu_decomposition . h is currently only implemented for tpu . i ' d like to be able to use it on cpu and / or gpu . * * will this change the current api ? how ? * * yes , but in a backwards compatible way . * * who will benefit with this feature ? * * anyone wanting to build on xla and do lu decomposition for e . g . calculating determinants . i want this as i am building an api for xla in idris .",1
tensorflow/tensorflow,c + + prebuilt libs are there any plans to release prebuilt c + + libs like the ones for c here <url>,1
tensorflow/tensorflow,"consider supporting png images for modelmaker object detector * * system information * * - tensorflow version ( you are using ) : <number> . <number> * * describe the feature and the current behavior / state . * * currently the ` object_detector ` class only supports jpg images . this can be a problem , especially if you have already created label annotations for the images in another image format . i suggest that we consider adding support for png files as well . * * will this change the current api ? how ? * * no * * who will benefit with this feature ? * * everyone using png images instead of jpg for training data . * * any other info . * * as far as i can see then there is a check for file format here on line <number> of the ` dict_to_tf_example ` function",1
tensorflow/tensorflow,"batch processing for tflite_runtime * * system information * * - tensorflow version ( you are using ) : <number> . <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * batch processing of images in object detection models that are running in a tflite_runtime environment would be a great feature to add . right now , it is possible to resize the input tensor to something like [x , h , w , c ] where x is the number of images in a batch , and run it through the interpreter . however , the predictions come out looking like an image classification model , where there are probabilities but no bounding boxes . * * will this change the current api ? how ? * * yes . it will allow for developers to leverage the savings associated with batch processing . * * who will benefit with this feature ? * * anyone who wants to break large images into x number of tiles and run inference on them all at once . this will greatly improve object detection capabilities on edgetpu devices . * * any other info . * * [ here ] ( <url> is a post i made on batch processing with an efficientdet model .",1
tensorflow/tensorflow,"fifoqueue as a part of custom layer hello , i need a queue as a part of my custom input layer in transformer for short - term memory purposes . i need to store the coming features "" in first in first out "" manner and remove the oldies features when it ' s full and clean all content if it ' s needed . i see [ here ] ( <url> something like that for working with tensor , but is it a good choice for me and contains all that i need ? is the fifoqueue faster than using python ' s deque or numpy based queue directly in a custom layer ? compare python ' s deque collection with tf ' s fifoqueue : | python | tensorflow | | - - - - - - - - | - - - - - - - - - - - - - | | deque ( maxlen = max_size ) | tf . queue . fifoqueue ( capacity , dtypes , shapes = none , names = none , shared_name = none ) | append ( x ) <br> # if it ' s full discard from the left end | enqueue ( vals ) | | clear ( ) | ? <repeated> | | len ( queue ) | size ( ) | | pop ( ) | dequeue ( ) | | queue [ i ] | ? <repeated> | or alternatively do it with numpy like : ` ` ` python queue = np . zeros ( ( maxlen , features ) ) # my queue x = np . random . normal ( size = features ) # new features # append ( ) queue = np . concatenate ( [ queue [ : - <number> ] , x[ np . newaxis , :]]) # predict y = model ( queue [ np . newaxis , :, :]) ` ` ` with python ' s timeit i get a benchmark on <number> cycles with maxlen = <number> and features = <number> method | time | | - - - - - - - - | - - - - - - - - - - - - - | | numpy | <number> s | | deque | <number> s | thanks , have a nice day .",1
tensorflow/tensorflow,"tflite signaturerunner support for the c api * * system information * * - tensorflow version ( you are using ) : <number> / tf - nightly - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * the current tflite interpreter c api allows using tflite in situations where a stable abi is needed and the c + + api is not an option . for example , in cases where tflite needs to be used in bigger projects that cannot use bazel to build and might use different toolchains or incompatible c + + compiler settings . however , while the c + + api already has support for multiple signatures [ through the use of signaturerunner ] ( <url> the c api has not been updated accordingly . as such , the use of multiple signatures in tflite models is not possible if abi stability requirements prevent you from using the c + + api directly . * * will this change the current api ? how ? * * new apis that allow using signature runners would need to be added [ here ] ( <url> or in a separate header if appropriate . * * who will benefit with this feature ? * * anyone who needs stable abis and wants to run tflite models with multiple signatures . * * any other info . * * as mentioned [ here ] ( <url> this feature is not available _yet_ , suggesting it ' s planned . i am opening this feature request so that it ' s easier to track its status , as well as any kind of information on when it might be implemented .",1
tensorflow/tensorflow,"iterating over ` tf . tensor ` is not allowed <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version ( you are using ) : <number> . <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * i have a dictionary that i build by accessing only the channel dimensions of an output layer of a convolutional neural network ( it has a shape ( <number> , <number> ) ) therefore keys of this dictionary are tuples of tensor shape ( <number> , ) . i want to map these keys to the input of the next layer using the tf . map_fn ( ) . however , i am incapable of doing it because the keys of my dictionary are of type tensor and i cannot iterate over them . looking for some help . thank you . * * will this change the current api ? how ? * * * * who will benefit with this feature ? * * * * any other info . * *",1
tensorflow/tensorflow,"installing tensorflow with pip * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * when installing tensorflow on windows , after ` pip install tensorflow ` , it further needs to install cuda and cudann and also needs to add their paths to windows environmental utility . i am not sure why we need to face this hassle whereas , in pytorch , we do not see such things . * * will this change the current api ? how ? * * dunno . * * who will benefit from this feature ? * * all of the painful souls who use tensorflow * * any other info . * *",1
tensorflow/tensorflow,"expose half_pixel_center or anti - aliasing parameter in the keras resizing layer . <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version ( you are using ) : tf <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * the feature that i am proposing is basically a fix for the current resizing keras layer which sets the ` half_pixel_center ` to true by default which causes problem on nnapi ( android ) based platforms and also on snapdragon based platforms . there are <number> possible solution to this problem - <number> . you expose the parameters ` antialias ` or ` half_pixel_center ` via the keras resizing layer and let the user explicitly set either of the <number> properties . better would be to expose ` antialias ` which can be defaulted to ` none ` or ` true ` since resizing is used mostly in later layers and not for downsampling it should be fine . <number> . add an automated check within the resize base function to check if the half_pixel_center is actually needed . from my understanding when you are resizing just check if the ( inputsize - <number> ) / ( outputsize - <number> ) when downsampling or vice versa when upsampling , is fractional or int . if fractional set half_pixel_center to true else set it to false . * * will this change the current api ? how ? * * yes this will change the current api by either exposing certain optional parameters or by adding an automated check . * * who will benefit with this feature ? * * everyone running their nn on somekind of dsp . * * any other info . * *",1
tensorflow/tensorflow,"[ feature request ] support for convolutional layers for ` tf . autodiff . forwardaccumulator ` <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) : yes * * describe the feature and the current behavior / state . * * currently , the implementation of [ ` tf . autodiff . forwardaccumulator ` ] ( <url> only officially supports dense layers . * * will this change the current api ? how ? * * yes . the new api will be able to calculate the jvp also for convolutional layers . * * who will benefit from this feature ? * * anyone who wants to implement a neural network with convolutional layers and needs forward - mode autodiff . * * any other info . * * trying to use the current api results in a shape mismatch : ` ` ` python import tensorflow as tf batch_size = <number> image_width = <number> image_height = <number> channels = <number> x = tf . random . uniform ( ( batch_size , image_width , image_height , channels ) ) model = tf . keras . models . sequential ( [ tf . keras . layers . conv2d ( filters = <number> , kernel_size = <number> ) ] ) model . build ( x . shape ) model . summary ( ) with tf . autodiff . forwardaccumulator ( model . trainable_weights [ <number> ] , tf . constant ( [ [ [ [ <number> . , <number> . , <number> . , <number> . , <number> . , <number> . ] ] ] ] ) ) as acc : out = model ( x ) # < - - - - - valueerror print ( acc . jvp ( out ) ) ` ` ` summary : ` ` ` model : "" sequential "" _________________________________________________________________ layer ( type ) output shape param # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = conv2d ( conv2d ) ( <number> , <number> , <number> , <number> ) <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = total params : <number> trainable params : <number> non - trainable params : <number> _________________________________________________________________ ` ` ` error : ` ` ` valueerror : exception encountered when calling layer "" conv2d "" ( type conv2d ) . in user code : valueerror : dimension <number> in both shapes must be equal , but are <number> and <number> . shapes are [ <number> , <number> ] and [ <number> , <number> ] . from merging shape <number> with other shapes . for ' { { node addn } } = addn [ n = <number> , t = dt_float ] ( gradient_tape / gradient_tape / conv2d , gradient_tape / gradient_tape / conv2d_1 ) ' with input shapes : [ <number> , <number> ] , [ <number> , <number> ] . call arguments received by layer "" conv2d "" ( type conv2d ) inputs = tf . tensor ( shape =( <number> , <number> , <number> , <number> ) , dtype = float32 ) ` ` `",1
tensorflow/tensorflow,"python api of ` saved_model . load ` to support ` tf . saved_model . experimental . variablepolicy ` * * system information * * - tensorflow version ( you are using ) : tf2 . <number> - cpu memory : 1 6 gb - gpu memory : 1 0 gb * * describe the feature and the current behavior / state . * * some models need to store large weights / tables on cpu and smaller ones on gpu . tf . saved_model . experimental . variablepolicy is able to store device placement but not fully supported by tf . saved_model . load . every variable is loaded to gpu if available . there is support on c + + level , but missing in python . a repo . py is as follows . run as python repo . py - - size <number> , a oom is observed . set the number <number> to be any number b / w the memory size of your cpu and gpu in gb . ` ` ` import argparse import tensorflow as tf class ln ( tf . keras . layers . layer ) : def __init__ ( self , rows , cols , trainable = true ) : super ( ln , self ) . __init__ ( dtype = tf . float32 ) self . rows = rows self . cols = cols self . mat = none self . trainable = trainable def build ( self , input_shape ) : self . mat = self . add_weight ( "" mat "" , shape =[ self . rows , self . cols ] , dtype = tf . float32 , trainable = self . trainable ) def call ( self , indices ) : return tf . gather ( params = self . mat , indices = indices ) class testmodel ( tf . keras . model ) : def __init__ ( self , rows , cols ) : super ( ) . __init__ ( ) self . ln = ln ( rows = rows , cols = cols ) <user> . function def call ( self , x) : with tf . device ( ' / cpu : <number> ' <sad> x = self . ln ( x ) with tf . device ( ' / gpu : <number> ' <sad> x = tf . math . reduce_sum ( x , axis = <number> ) return x def main ( <sad> parser = argparse . argumentparser ( ) parser . add_argument ( ' - - size ' , type = int , default = <number> , help = ' table size in gib ' ) parser . add_argument ( ' - - load_cpu ' , type = bool , default = false , help = ' load variables to cpu ' ) args = parser . parse_args ( ) ncols = <number> nrows = args . size * <number> * * <number> / / <number> path = ' / tmp / saved_model_test ' model = testmodel ( rows = nrows , cols = ncols ) indices = tf . zeros ( shape =( <number> , <number> ) , dtype = tf . int32 ) outputs = model ( indices ) print ( outputs ) model . summary ( ) print ( ' saving the model ' ) tf . saved_model . save ( model , path , options = tf . saved_model . saveoptions ( experimental_variable_policy = tf . saved_model . experimental . variablepolicy . save_variable_devices ) ) print ( ' saved successfully ' ) if args . load_cpu : with tf . device ( ' / cpu : <number> ' <sad> loaded = tf . saved_model . load ( path ) # good else : loaded = tf . saved_model . load ( path ) # oom print ( ' load successfully ' ) if __name__ = = ' __main__ ' ` ` `",1
tensorflow/tensorflow,"native support for stridedslice in 6 d and transpose in 7 d * * system information * * - os platform and distribution ( e . g . , linux ubuntu <number> <sad> linux ubuntu <number> - tensorflow installed from ( source or binary ) : source - tensorflow version ( or github sha if from source ) : 8 0 4 ef7223ef08fd14c274b4a4044cc4aeee68863 * * provide the text output from tflite_convert * * ` ` ` <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libcuda . so . <number> ' ; dlerror : libcuda . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path : / opt / intel / openvino_2021 / data_processing / dl_streamer / lib <annoyed> opt / intel / openvino_2021 / data_processing / gstreamer / lib <annoyed> opt / intel / openvino_2021 / opencv / lib <annoyed> opt / intel / openvino_2021 / deployment_tools / ngraph / lib <annoyed> opt / intel / openvino_2021 / deployment_tools / inference_engine / external / tbb / lib : : / opt / intel / openvino_2021 / deployment_tools / inference_engine / external / hddl / lib <annoyed> opt / intel / openvino_2021 / deployment_tools / inference_engine / external / omp / lib <annoyed> opt / intel / openvino_2021 / deployment_tools / inference_engine / external / gna / lib <annoyed> opt / intel / openvino_2021 / deployment_tools / inference_engine / external / mkltiny_lnx / lib <annoyed> opt / intel / openvino_2021 / deployment_tools / inference_engine / lib / intel64 <annoyed> usr / local / nvidia / lib <annoyed> usr / local / nvidia / lib64 <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / cuda / cuda_driver . cc : <number> ] failed call to cuinit : unknown error ( <number> ) <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_diagnostics . cc : <number> ] no nvidia gpu device is present : / dev / nvidia0 does not exist <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : sse3 sse4 . <number> sse4 . <number> avx avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . warning : absl : please consider providing the trackable_obj argument in the from_concrete_functions . providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path . <number> - <number> - <number> <time> . <number> : i tensorflow / core / grappler / devices . cc : <number> ] number of eligible gpus ( core count >= <number> , compute capability >= <number> <sad> <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / grappler / clusters / single_machine . cc : <number> ] starting new session <number> - <number> - <number> <time> . <number> : i tensorflow / core / grappler / optimizers / meta_optimizer . cc : <number> ] optimization results for grappler item : graph_to_optimize function_optimizer : function_optimizer did nothing . time = <number> . 0 0 8 ms . function_optimizer : function_optimizer did nothing . time = 0 ms . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / mlir / lite / python / tf_tfl_flatbuffer_helpers . cc : <number> ] ignored output_format . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / mlir / lite / python / tf_tfl_flatbuffer_helpers . cc : <number> ] ignored drop_control_dependency . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / mlir / lite / flatbuffer_export . cc : <number> ] tflite interpreter needs to link flex delegate in order to run the model since it contains the following select tfop ( s ) : flex ops : flexstridedslice , flextranspose details : tf . stridedslice ( tensor <1x120x160x3x1x32xf32> , tensor <6xi32> , tensor <6xi32> , tensor <6xi32> ) - > ( tensor <1x120x160x1x32xf32> ) : { begin_mask = <number> : i64 , device = "" "" , ellipsis_mask = <number> : i64 , end_mask = <number> : i64 , new_axis_mask = <number> : i64 , shrink_axis_mask = <number> : i64 } tf . transpose ( tensor <1x30x4x40x4x1x4xf32> , tensor <7xi32> ) - > ( tensor <1x30x40x1x4x4x4xf32> ) : { device = "" "" } see instructions : <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / mlir / lite / flatbuffer_export . cc : <number> ] estimated count of arithmetic ops : <number> g ops , equivalently <number> g macs estimated count of arithmetic ops : <number> g ops , equivalently <number> g macs warning : absl : buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded ` ` ` * * standalone code to reproduce the issue * * tflite native support for ` stridedslice ` for 6 d , and ` transpose ` for 7 d would be very beneficial . it would be nice if we could avoid flex operations if possible . - * * ` saved_model ` * * and converted * * ` tflite ` * * files [ saved_model_and_float32tflite . zip ] ( <url> - conversion script ` ` ` python import tensorflow as tf input_shapes = [ [ <number> , <number> ] ] model = tf . saved_model . load ( ' flyingthings_finalpass_xl / saved_model_120x160 ' ) concrete_func = model . signatures [ tf . saved_model . default_serving_signature_def_key ] concrete_func_input_tensors = [ tensor for tensor in concrete_func . inputs \ \ if tensor . dtype = tf . resource and not ' unknown ' in tensor . name ] for conc_input , def_input in zip ( concrete_func_input_tensors , input_shapes ) : conc_input . set_shape ( def_input ) converter = tf . lite . tfliteconverter . from_concrete_functions ( [ concrete_func ] ) converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins , tf . lite . opsset . select_tf_ops , ] tflite_model = converter . convert ( ) with open ( ' model_float32 . tflite ' , ' wb ' ) as w : w . write ( tflite_model ) ` ` ` * * any other info / logs * * - model citation repository - hitnet iterative tile refinement network for real - time stereo matching <url> ! [ <number> - 7 db28584 - ce78 - <number> - 9 4 fa - 4 ce93c9f8d4d ] ( <url> - flexstridedslice ( 6 d ) ! [ screenshot <number> - <number> - <number> <time> ] ( <url> - flextranspose ( 7 d ) ! [ screenshot <number> - <number> - <number> <time> ] ( <url>",1
tensorflow/tensorflow,"request for grouped convolutions on cpu * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) : no * * describe the feature and the current behavior / state . * * grouped convolutions are not currently supported on cpus in graph mode . we get the following error when we try to do the same : ` ` ` unimplementederror conv implementation does not support grouped convolutions for now . [ [ node sequential_2 / sequential / conv2d / biasadd ( defined at / usr / local / lib / python3 . <number> / dist - packages / keras / layers / convolutional . py : <number> ) ] ] [ op : __inference_predict_function_1730 ] ` ` ` till date , there have been numerous issues on tf ' s github repo regarding this . owing to that , i am requesting the team to look into this . * * will this change the current api ? how ? * * ` model . predict ( ) ` with a model having grouped convolutions will not result in an error on a cpu . * * who will benefit with this feature ? * * many architectures today use grouped convolutions as they are known to be more efficient while maintaining the accuracy . thus , i believe many tf developers will benefit from this addition .",1
tensorflow/tensorflow,"please add ` tf . random . stateless_shuffle ` <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version ( you are using ) : <number> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * we only have ` tf . random . shuffle ` which is generally annoying to work with and bug - prune when reproducible results are needed ( same reasoning for all ' tf . random . stateless_ * ` ) * * will this change the current api ? how ? * * a only api addition * * who will benefit with this feature ? * * people that want to reproduce random function rexecution * * any other info . * * no , thank you",1
tensorflow/tensorflow,"feature request : providing gradients for ` layer . set_weights ( ) ` <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version ( you are using ) : <number> . <number> - are you willing to contribute it ( yes / no ) : no , i am not experienced enough . * * describe the feature and the current behavior / state . * * the feature is to make ` set_weights ( ) ` differentiable . the current behavior is that the ` model . set_weights ( ) ` function breaks the gradient . given a model named ` learner ` and a batch of data ` batch ` ` ` ` l = tf . constant ( <number> ) with tf . gradienttape ( ) as gt new_weights = [ w * l for w in learner . weights ] learner . set_weights ( new_weights ) y_pred = learner ( batch [ "" train "" ][""x "" ] ) loss = tf . keras . losses . categorical_crossentropy ( batch [ "" train "" ] [ "" y "" ] , y_pred ) grads = gt . gradient ( loss , l ) grads # returns none ` ` ` this example returns none for the gradients . in fact , the gradient tape can not calculate the gradient of any variable related to calculating the ` new_weights ` . so i was wondering if it ' s possible to provide gradients for ` set_weights ( ) ` or if there are any work - arounds to this problem . * * will this change the current api ? how ? * * i do not see how this feature would change the current api . it is more a modification on an existing function . * * who will benefit with this feature ? * * i believe adding this feature would make projects related to meta - learning easier to realize . in my specific case , i was trying to implement [ this paper ] ( <url> and translate the [ pytorch implementation ] ( <url> to tensorflow , but i think this feature would generally benefit many projects that are related to the growing field of meta - learning . * * any other info . * * thanks and merry christmas ! <repeated>",1
tensorflow/tensorflow,"[ tflite ] support building external delegate with cmake tensorflow lite supports external delegate but not supported in cmake build , do we have plan to support it ?",1
tensorflow/tensorflow,"segmentation fault and no log information available , add some tips about segmentation fault * * system information * * - tensorflow version ( you are using ) : tensorflow <number> . <number> , python <date> - are you willing to contribute it ( yes / no ) * * describe the feature and the current behavior / state . * * i have trouble retraining my colleague ' s code from a year ago . i notice that when i try to load my model in the former code base on * libtensorflow - cpu - linux - x86_64 - <number> . <number> * it reports a ` segmentation fault ` , without any further information . upon inspecting my code , i notice that it stops when i load the model , function ` tf_sessionrun ` . i am not sure what to do to fix it . a moment later , my colleague realized the problem was the parameters in the placeholder name were incorrect . a moment later , my colleague realized the problem was the parameters in the placeholder name were incorrect . we fixed it after changing the placeholder name . * * will this change the current api ? how ? * * no . * * who will benefit with this feature ? * * those who are not familiar with tensorflow v1 ' s place holder . * * any other info . * * no .",1
tensorflow/tensorflow,"perspective transformation data augmentation for object detection <em> please make sure that this is a feature request . as per our [ github policy ] ( <url> we only address code / doc bugs , performance issues , feature requests and build / installation issues on github . tag : feature_template </em> * * system information * * - tensorflow version : <number> . <number> - are you willing to contribute it 🆗 * * perspective transformation data augmentation for object detection . * * * * will this change the current api ? how ? no , the change will be done only in the preprocessing layer . * * who will benefit with this feature ? as it has been described in [ this article ] ( <url> this feature could be helpful to make the models more general in the object detection projects .",1
tensorflow/tensorflow,support multiple validation sets in model . fit moving this feature from tf repository <url> are you willing to contribute it ( yes / no ) describe the feature and the current behavior / state . currently there ' s no way to use multiple validation sets with independent tracking of metrics . will this change the current api ? how ? simplest way i can think of is to accept a list of datasets in the validation_data parameter in model . fit . ideally there should also be a way to specify the name of each set so that the logs indicate what set each validation step corresponds to . who will benefit with this feature ? anyone training with multiple validation sets .,1
tensorflow/tensorflow,"tf . data . experimental . load does not work on temporary files * * system information * * - tensorflow version ( you are using ) : <number> . <number> - are you willing to contribute it ( yes / no ) : no ( i do not have the required knowledge ) * * describe the feature and the current behavior / state . * * when loading a dataset with ` tf . data . experimental . load ` , the produced dataset will always be a lazily - loaded dataset that does not read the files until the dataset object is consumed ( e . g . by iterating over it with python code , or using it to train a model ) . this poses a problem if the path provided to ` load ` is a temporary path , since depending on when the dataset is used , the files could be gone when the dataset object attempts to read them . consider the following load function : ` ` ` python def load_data ( source ) : with tempfile . temporarydirectory ( ) as tmpdir : prepare_files ( source , tmpdir . name ) return tf . data . experimental . load ( tmpdir . name ) ` ` ` the dataset returned by this function will be unusable since , as soon as the function returns , the ` temporarydirectory ` context manager will exit and destroy the files . ( the ` prepare_files ` function is just there to represent any logic that could be used to get the files to the temp . dir , such as downloading them over network , extracting them from an archive , or decrypting them . ) aside from the temporary files issue , there could some other cases in which the developpers would want their datasets to be loaded in memory immediately . * * will this change the current api ? how ? * * the feature i propose is to allow callers of ` tf . data . experimental . load ` to specify whether they want a lazily - loaded dataset , or an eagerly - loaded dataset ( that reads the files only once , when ` load ` is called , and stores the data in memory ) . the way i see it , this evolution would add a new optional parameter to ` tf . data . experimental . load ` . its default value needs to correspond to lazy loading for backwards compatibility . this would not pose a big issue since <number> . it will be backwards - compatible and <number> . only the experimetal api will be modified ( and the documentation explicetely says the experimental api may evolve at any time ) . * * who will benefit with this feature ? * * anyone who wants to separate their dataset loading logic in a similar function , using a temporary directory or another context manager that destroys the files upon exit . this would be the case when : - using files downloaded from the internet - using encrypted files , e . g . if the data is sensitive or private - using files compressed externally , to have more control over compression - using ` importlib . resources . as_file ` in some cases * * any other info . * * the fact that the datasets are lazy - loaded is not documented , it would be nice to add this to the current documentation of ` tf . data . experimental . load ` . also on the subject of documentation , once ( if ) the eager load option is added , the documentation should warn the user about the potentially high memory usage when eager - loading large datasets . in my use case this is not a problem , since <number> . the datasets are created with ` dataset . from_tensor_slices ` before being saved ( so they have already been entirely in memory before ) , <number> . i only use one dataset at a time and <number> . i make sure it is garbage - collected as soon as possible . here is my current placeholder : ` ` ` python def load_data ( source ) : tmppath = tempfile . mkdtemp ( ) def deleter ( ) atexit . register ( tmppath ) prepare_files ( source , tmppath ) return tf . data . experimental . load ( tmppath ) ` ` ` depending on how many times this function is called during the program ' s lifetime , this can quickly clutter the disk . it would be nice to have a better solution . note that , to fit * my <emphasis> * specific <emphasis> use case , it would also work for me to have a variant of ` save ` and ` load ` that accept a python file - like object ( and save to / load from a single file ) . the logic i use in my version of ` prepare_files ` turns a single file into a directory .",1
tensorflow/tensorflow,"keyerror : ' constantofshape ' # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution <number> . <number> - microsoft - standard - wsl2 # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory _no response_ # # # current behavior ? traceback ( most recent call last ) : file "" o2k . py "" , line <number> , in <module> k_model = onnx_to_keras ( onnx_model , [ ' input . <number> ' ] , name_policy = ' renumerate ' , verbose = true ) file "" / root / miniconda3 / envs / onnx / lib / python3 . <number> / site - packages / onnx2keras / converter . py "" , line <number> , in onnx_to_keras available_converters [ node_type ] ( keyerror : ' constantofshape ' # # # standalone code to reproduce the issue ` ` ` shell from onnx2keras import onnx_to_keras import keras import onnx import sys # sys . path . append ( "" / root / mr "" ) onnx_model = onnx . load ( ' patchcore_torch . onnx ' ) onnx_inputs = onnx_model . graph . input print ( "" = = = = = = = = = = = = = = = = = = = = = = = = = =="") print ( onnx_inputs ) # onnx_model = onnx . load ( ' vgg11 . onnx ' ) k_model = onnx_to_keras ( onnx_model , [ ' input . <number> ' ] , name_policy = ' renumerate ' , verbose = true ) keras . models . save_model ( k_model , ' patchcore_torch . h5 ' , overwrite = true , save_format = "" h5 "" ) onnx file can be downloaded at <url> ` ` ` # # # relevant log output ` ` ` shell traceback ( most recent call last ) : file "" o2k . py "" , line <number> , in <module> k_model = onnx_to_keras ( onnx_model , [ ' input . <number> ' ] , name_policy = ' renumerate ' , verbose = true ) file "" / root / miniconda3 / envs / onnx / lib / python3 . <number> / site - packages / onnx2keras / converter . py "" , line <number> , in onnx_to_keras available_converters [ node_type ] ( keyerror ` ` `",0
tensorflow/tensorflow,"attributeerror : not implemented # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version tf <number> # # # custom code yes # # # os platform and distribution <number> . <number> - microsoft - standard - wsl2 # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> # # # gpu model and memory _no response_ # # # current behavior ? traceback ( most recent call last ) : file "" o2k . py "" , line <number> , in <module> k_model = onnx_to_keras ( onnx_model , [ ' input . <number> ' ] , name_policy = ' renumerate ' , verbose = true ) file "" / root / miniconda3 / envs / onnx / lib / python3 . <number> / site - packages / onnx2keras / converter . py "" , line <number> , in onnx_to_keras available_converters [ node_type ] ( file "" / root / miniconda3 / envs / onnx / lib / python3 . <number> / site - packages / onnx2keras / reshape_layers . py "" , line <number> , in convert_slice raise attributeerror ( ' not implemented ' ) attributeerror : not implemented # # # standalone code to reproduce the issue ` ` ` shell reproduce by running the following code : from onnx2keras import onnx_to_keras import keras import onnx import sys # sys . path . append ( "" / root / mr "" ) onnx_model = onnx . load ( ' deeplabv3_torch . onnx ' ) onnx_inputs = onnx_model . graph . input print ( "" = = = = = = = = = = = = = = = = = = = = = = = = = =="") print ( onnx_inputs ) # onnx_model = onnx . load ( ' vgg11 . onnx ' ) k_model = onnx_to_keras ( onnx_model , [ ' input . <number> ' ] , name_policy = ' renumerate ' , verbose = true ) keras . models . save_model ( k_model , ' deeplabv3_torch . h5 ' , overwrite = true , save_format = "" h5 "" ) ` ` ` onnx file can be downloaded at <url> ` ` ` # # # relevant log output ` ` ` shell traceback ( most recent call last ) : file "" o2k . py "" , line <number> , in <module> k_model = onnx_to_keras ( onnx_model , [ ' input . <number> ' ] , name_policy = ' renumerate ' , verbose = true ) file "" / root / miniconda3 / envs / onnx / lib / python3 . <number> / site - packages / onnx2keras / converter . py "" , line <number> , in onnx_to_keras available_converters [ node_type ] ( file "" / root / miniconda3 / envs / onnx / lib / python3 . <number> / site - packages / onnx2keras / reshape_layers . py "" , line <number> , in convert_slice raise attributeerror ( ' not implemented ' ) attributeerror implemented ` ` `",0
tensorflow/tensorflow,"spectralnormalization layer is not trainable . please help ( operatornotallowedingrapherror : exception encountered when calling layer ' spectral_normalization ' ( type spectralnormalization ) . ) # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution ubuntu <number> . <number> lts and google colab # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cudatoolkit = <number> . <number> , nvidia - cudnn - cu11 = = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? spectralnormalization layer is not trainable . whenever i try to use the "" model . fit "" method , tf outputs the error "" using a symbolic ` tf . tensor ` as a python ` bool ` is not allowed : autograph did convert this function . this might indicate you are trying to use an unsupported feature . "" please help best kav # # # standalone code to reproduce the issue ` ` ` shell link to colab notebook : <url> standalone code : batch = <number> height = <number> width = <number> channels = <number> filters = <number> kernel_size = <number> x_input = input ( shape =( height , width , channels ) ) conv2d = spectralnormalization ( conv2d ( filters , kernel_size ) ) x_output = conv2d ( x_input ) model = model ( x_input , x_output ) model . compile ( loss = ' mse ' ) x = np . random . rand ( batch , height , width , channels ) y = np . random . rand ( batch , height , width , filters ) model . fit ( x , y ) ` ` ` # # # relevant log output ` ` ` shell - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - operatornotallowedingrapherror traceback ( most recent call last ) < ipython - input - <number> - d3dc977168f5 > in < cell line : <number> > ( ) - - - - > <number> model . fit ( x , y ) <number> frames / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / eager / polymorphic_function / autograph_util . py in autograph_handler ( * args , * * kwargs ) <number> except exception as e : # pylint : disable = broad - except <number> if hasattr ( e , "" ag_error_metadata "" <sad> - - - > <number> raise e . ag_error_metadata . to_exception ( e ) <number> else : <number> raise operatornotallowedingrapherror : in user code : file "" / usr / local / lib / python3 . <number> / dist - packages / keras / src / engine / training . py "" , line <number> , in train_function * return step_function ( self , iterator ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / src / engine / training . py "" , line <number> , in step_function * * outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / src / engine / training . py "" , line <number> , in run_step * * outputs = model . train_step ( data ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / usr / local / lib / python3 . <number> / dist - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none operatornotallowedingrapherror : exception encountered when calling layer ' spectral_normalization ' ( type spectralnormalization ) . using a symbolic ` tf . tensor ` as a python ` bool ` is not allowed : autograph did convert this function . this might indicate you are trying to use an unsupported feature . call arguments received by layer ' spectral_normalization ' ( type spectralnormalization ) inputs = tf . tensor ( shape =( none , <number> , <number> , <number> ) , dtype = float32 ) • training = true ` ` `",0
tensorflow/tensorflow,"fails to build on aarch64 # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version git head # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device n / a # # # python version <date> # # # bazel version <number> . <number> # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version n / a # # # gpu model and memory n / a # # # current behavior ? / tensorflow / lite / kernels / rng_util . h : <time> : error : use of undeclared identifier ' uint32_t ' # # # standalone code to reproduce the issue ` ` ` shell bazel test - - config = mkl_aarch64_threadpool - - copt = - flax - vector - conversions - - test_env = tf_enable_onednn_opts = <number> - - test_env = tf2_behavior = <number> - - define = tf_api_version = <number> - - test_lang_filters = py - - flaky_test_attempts = <number> - - test_size_filters = small , medium - - test_output = errors - - verbose_failures = true - - test_keep_going - - notest_verbose_timeout_warnings - - action_env = python_bin_path <annoyed> usr / local / bin / python3 - - build_tag_filters = - no_oss , - oss_excluded , - oss_serial , - v1only , - benchmark - test , - no_aarch64 , - gpu , - tpu , - no_oss_py39 , - no_oss_py310 - - test_tag_filters = - no_oss , - oss_excluded , - oss_serial , - v1only , - benchmark - test , - no_aarch64 , - gpu , - tpu , - no_oss_py39 , - no_oss_py310 - - local_test_jobs = <number> - - build_tests_only - - / / tensorflow / . <repeated> - / / tensorflow / compiler / tf2tensorrt / . <repeated> - / / tensorflow / compiler / xrt / . <repeated> - / / tensorflow / core / tpu / . <repeated> - / / tensorflow / go / . <repeated> - / / tensorflow / java / . <repeated> - / / tensorflow / python / integration_testing / . <repeated> - / / tensorflow / tools / toolchains / . <repeated> - / / tensorflow / lite / . <repeated> - / / tensorflow / core / kernels / image : resize_bicubic_op_test - / / tensorflow / core / grappler / optimizers : auto_mixed_precision_test_cpu - / / tensorflow / core / grappler / optimizers : remapper_test_cpu ` ` ` # # # relevant log output ` ` ` shell error : / workspace / tensorflow / lite / kernels / build : <number> <time> : compiling tensorflow / lite / kernels / rng_util . cc failed : ( exit <number> <sad> clang failed : error executing command ( from target / / tensorflow / lite / kernels : rng_util ) ( cd / tmpfs / bazel_output / _bazel_ubuntu / eab0d61a99b6696edb3d2aff87b585e8 / execroot / org_tensorflow & & \ \ exec env - \ \ cachebuster = <number> \ \ clang_compiler_path <annoyed> usr / lib / llvm - <number> / bin / clang \ \ ld_library_path = ' ' \ \ path <annoyed> home / ubuntu / actions - runner / _work / tensorflow / tensorflow / bazel - ci_build - cache / . cache / bazelisk / downloads / bazelbuild / bazel - <number> . <number> - linux - arm64 / bin <annoyed> home / ubuntu / actions - runner / _work / tensorflow / tensorflow / bazel - ci_build - cache / bin <annoyed> usr / local / sbin <annoyed> usr / local / bin <annoyed> usr / sbin <annoyed> usr / bin <annoyed> sbin <annoyed> bin <annoyed> snap / bin \ \ * * * \ \ python_bin_path <annoyed> usr / local / bin / python3 \ \ python_lib_path <annoyed> usr / lib / python3 / dist - packages \ \ tf2_behavior = <number> \ \ / usr / lib / llvm - <number> / bin / clang - md - mf bazel - out / aarch64 - opt / bin / tensorflow / lite / kernels / _objs / rng_util / rng_util . pic . d ' - frandom - seed = bazel - out / aarch64 - opt / bin / tensorflow / lite / kernels / _objs / rng_util / rng_util . pic . o ' ' - dbazel_current_repository = "" "" ' - iquote . - iquote bazel - out / aarch64 - opt / bin - fmerge - all - constants - wno - builtin - macro - redefined ' - d__date__ = "" redacted "" ' ' - d__timestamp__ = "" redacted "" ' ' - d__time__ = "" redacted "" ' - fpic - u_fortify_source ' - d_fortify_source = <number> ' - fstack - protector - wall - wno - invalid - partial - specialization - fno - omit - frame - pointer - no - canonical - prefixes - dndebug - g0 - o2 - ffunction - sections - fdata - sections - wno - all - wno - extra - wno - deprecated - wno - deprecated - declarations - wno - ignored - attributes - wno - array - bounds - wunused - result ' - werror = unused - result ' - wswitch ' - werror = switch ' ' - wno - error = unused - but - set - variable ' - dautoload_dynamic_kernels - wno - gnu - offsetof - extensions - wno - gnu - offsetof - extensions ' - mtune = generic ' ' - march = armv8 - a ' - o3 - flax - vector - conversions ' - std =c + + <number> ' - dfarmhash_no_cxx_string - deigen_allow_unaligned_scalars - wno - sign - compare - o3 - fno - exceptions ' - - sysroot <annoyed> dt10 ' - c tensorflow / lite / kernels / rng_util . cc - o bazel - out / aarch64 - opt / bin / tensorflow / lite / kernels / _objs / rng_util / rng_util . pic . o ) # configuration : 9 1 cacbf6409fd17883ece1a0e16168e33815822fe5d36a44e64642fa9b0e32ee # execution platform : <user> / / : platform in file included from tensorflow / lite / kernels / rng_util . cc : <number> : . / tensorflow / lite / kernels / rng_util . h : <time> : error : use of undeclared identifier ' uint32_t ' std : : array < uint32_t , <number> > threefry2x32 ( uint32_t key_0 , uint32_t key_1 , ^ . / tensorflow / lite / kernels / rng_util . h : <time> : error : unknown type name ' uint32_t ' std : : array < uint32_t , <number> > threefry2x32 ( uint32_t key_0 , uint32_t key_1 , ^ . / tensorflow / lite / kernels / rng_util . h : <time> : error : unknown type name ' uint32_t ' std : : array < uint32_t , <number> > threefry2x32 ( uint32_t key_0 , uint32_t key_1 , ^ . / tensorflow / lite / kernels / rng_util . h : <time> : error : use of undeclared identifier ' uint32_t ' std : : array < uint32_t , <number> > ctr ) ; ^ . / tensorflow / lite / kernels / rng_util . h : <number> <time> : error : use of undeclared identifier ' uint32_t ' std : : array < uint32_t , <number> > philox4x32 ( uint32_t key_0 , uint32_t key_1 , ^ . / tensorflow / lite / kernels / rng_util . h : <number> <time> : error : unknown type name ' uint32_t ' std : : array < uint32_t , <number> > philox4x32 ( uint32_t key_0 , uint32_t key_1 , ^ . / tensorflow / lite / kernels / rng_util . h : <number> <time> : error : unknown type name ' uint32_t ' std : : array < uint32_t , <number> > philox4x32 ( uint32_t key_0 , uint32_t key_1 , ^ . / tensorflow / lite / kernels / rng_util . h : <number> <time> : error of undeclared identifier ' uint32_t ' std : : array < uint32_t , <number> > ctr ) ; ^ <number> errors generated . ` ` `",0
tensorflow/tensorflow,"restoring checkpoint loads weights partially # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i am following this [ tfa seq2seq tutorial ] ( <url> for building a seq2seq network with lstms . i trained my model and got great accuracy . i saved my model with ` tf . train . checkpoint ` . then , i tried to reload my model with ` checkpoint . restore ( tf . train . latest_checkpoint ( checkpoint_dir ) ) ` . however , the model gets restored partially . my encoder weights get restored , however the decoder does not . how to resolve ? # # # standalone code to reproduce the issue ` ` ` shell from typing import tuple import tensorflow as tf import tensorflow_addons as tfa from tensorflow . keras . preprocessing . text import tokenizer_from_json import json import numpy as np import unicodedata import re import os import io import time from collections import counter max_sequence_length = <number> def math_tokenizer ( expression ) : regex = r ' ( \ \ d + |[\\ + \ \ - \\* \ \ / \ \(\\)\ \ ^ ]| [ a - za - z ] + | . ) ' # use the regex to split the expression into tokens _tok = re . findall ( regex , expression ) # split numbers into individual digits ret_tokens = [ ] for token in _tok : if token . isdigit ( <sad> ret_tokens . extend ( list ( token ) ) else : ret_tokens . append ( token ) # filter out empty strings ret_tokens = [ token for token in ret_tokens if token . strip ( ) ] return ret_tokens def change_variable ( expression ) : # define regular expressions to match different tokens tokenstream = math_tokenizer ( expression ) variable = none for idx , tok in enumerate ( tokenstream ) : if len ( tok ) = = <number> and tok . isalpha ( <sad> variable = tok tokenstream [ idx ] = "" var "" return ' ' . join ( tokenstream ) , variable def text_cleaning ( x ) : modified_text = [ none ] * len ( x ) tokens = set ( ) tok_list = [ ] variables = [ ] for idx , <sad> in enumerate ( x ) : lhs , rhs = <sad> . split ( "" ="") tokenstream , v = change_variable ( ' ='. join ( [ lhs [ <number> : - <number> ] , rhs [ : - <number> ] ] ) ) tokens . update ( tokenstream ) tok_list . extend ( tokenstream ) variables . append ( v ) modified_text [ idx ] = ' ' . join ( tokenstream ) return modified_text , variables def generate_train_test_dataset ( data , train_size ) : modified_text , variables = text_cleaning ( data ) inputs = [ ] targets = [ ] for idx , <sad> in enumerate ( modified_text ) : inp , tgt = <sad> . split ( "" ="") inputs . append ( inp ) targets . append ( tgt ) train_inputs = inputs [ : train_size ] train_targets = targets [ : train_size ] train_variables = variables [ : train_size ] test_inputs = inputs [ train_size <happy> test_targets = targets [ train_size <happy> test_variables = variables [ train_size <happy> return train_inputs , train_targets , train_variables , test_inputs , test_targets , test_variables class mydataset : def __init__ ( self , problem_type = ' calculus ' <sad> self . problem_type = ' calculus ' self . inp_lang_tokenizer = none self . targ_lang_tokenizer = none def unicode_to_ascii ( self , s ) : return ' ' . join ( c for c in unicodedata . normalize ( ' nfd ' , s ) if unicodedata . category ( c ) = ' mn ' ) def preprocess_sentence ( self , w ) : w = w . strip ( ) w = ' start ' + w + ' end ' return w def tokenize ( self , lang , func ) : lang_tokenizer = tf . keras . preprocessing . text . tokenizer ( filters = none , oov_token ='< oov > ' , analyzer = func ) lang_tokenizer . fit_on_texts ( lang ) tensor = lang_tokenizer . texts_to_sequences ( lang ) tensor = tf . keras . preprocessing . sequence . pad_sequences ( tensor , padding = ' post ' ) return tensor , lang_tokenizer def load_dataset ( self , dataset , func ) : # creating cleaned input , output pairs targ_lang , inp_lang = dataset targ_lang = [ self . preprocess_sentence ( w ) for w in targ_lang ] inp_lang = [ self . preprocess_sentence ( w ) for w in inp_lang ] input_tensor , inp_lang_tokenizer = self . tokenize ( inp_lang , func ) target_tensor , targ_lang_tokenizer = self . tokenize ( targ_lang , func ) return input_tensor , target_tensor , inp_lang_tokenizer , targ_lang_tokenizer def call ( self , dataset , buffer_size , batch_size , func ) : input_tensor , target_tensor , self . inp_lang_tokenizer , self . targ_lang_tokenizer = self . load_dataset ( dataset , func ) train_dataset = tf . data . dataset . from_tensor_slices ( ( input_tensor , target_tensor ) ) train_dataset = train_dataset . shuffle ( buffer_size ) . batch ( batch_size , drop_remainder = true ) return train_dataset , self . inp_lang_tokenizer , self . targ_lang_tokenizer class encoder ( tf . keras . model ) : def __init__ ( self , vocab_size , embedding_dim , enc_units , batch_sz ) : super ( encoder , self ) . __init__ ( ) self . batch_sz = batch_sz self . enc_units = enc_units self . embedding = tf . keras . layers . embedding ( vocab_size , embedding_dim ) self . lstm_layer = tf . keras . layers . lstm ( self . enc_units , return_sequences = true , return_state = true , recurrent_initializer = ' glorot_uniform ' ) def call ( self , x , hidden ) : x = self . embedding ( x ) output , h , c = self . lstm_layer ( x , initial_state = hidden ) return output , h , c def initialize_hidden_state ( self ) : return [ tf . zeros ( ( self . batch_sz , self . enc_units ) ) , tf . zeros ( ( self . batch_sz , self . enc_units ) ) ] class decoder ( tf . keras . model ) : def __init__ ( self , vocab_size , embedding_dim , dec_units , batch_sz , max_length_input , max_length_output , attention_type = ' luong ' <sad> super ( decoder , self ) . __init__ ( ) self . batch_sz = batch_sz self . dec_units = dec_units self . attention_type = attention_type self . max_length_output = max_length_output # embedding layer self . embedding = tf . keras . layers . embedding ( vocab_size , embedding_dim ) <hashtag> final </hashtag> dense layer on which softmax will be applied self . fc = tf . keras . layers . dense ( vocab_size ) # define the fundamental cell for decoder recurrent structure self . decoder_rnn_cell = tf . keras . layers . lstmcell ( self . dec_units ) # sampler self . sampler = tfa . seq2seq . sampler . trainingsampler ( ) # create attention mechanism with memory = none self . attention_mechanism = self . build_attention_mechanism ( self . dec_units , none , self . batch_sz *[ max_length_input ] , self . attention_type ) # wrap attention mechanism with the fundamental rnn cell of decoder self . rnn_cell = self . build_rnn_cell ( batch_sz ) # define the decoder with respect to fundamental rnn cell self . decoder = tfa . seq2seq . basicdecoder ( self . rnn_cell , sampler = self . sampler , output_layer = self . fc ) def build_rnn_cell ( self , batch_sz ) : rnn_cell = tfa . seq2seq . attentionwrapper ( self . decoder_rnn_cell , self . attention_mechanism , attention_layer_size = self . dec_units ) return rnn_cell def build_attention_mechanism ( self , dec_units , memory , memory_sequence_length , attention_type = ' luong ' <sad> # - - - - - - - - - - - - - # # typ : which sort of attention ( bahdanau , luong ) # dec_units : final dimension of attention outputs # memory : encoder hidden states of shape ( batch_size , max_length_input , enc_units ) # memory_sequence_length : 1 d array of shape ( batch_size ) with every element set to max_length_input ( for masking purpose ) if ( attention_type = = ' bahdanau ' <sad> return tfa . seq2seq . bahdanauattention ( units = dec_units , memory = memory , memory_sequence_length = memory_sequence_length ) else : return tfa . seq2seq . luongattention ( units = dec_units , memory = memory , memory_sequence_length = memory_sequence_length ) def build_initial_state ( self , batch_sz , encoder_state , dtype ) : decoder_initial_state = self . rnn_cell . get_initial_state ( batch_size = batch_sz , dtype = dtype ) decoder_initial_state = decoder_initial_state . clone ( cell_state = encoder_state ) return decoder_initial_state def call ( self , inputs , initial_state ) : x = self . embedding ( inputs ) outputs , _ , _ = self . decoder ( x , initial_state = initial_state , sequence_length = self . batch_sz *[ self . max_length_output - <number> ] ) return outputs def loss_function ( real , pred ) : # real shape = ( batch_size , max_length_output ) # pred shape = ( batch_size , max_length_output , tar_vocab_size ) cross_entropy = tf . keras . losses . sparsecategoricalcrossentropy ( from_logits = true , reduction = ' none ' ) loss = cross_entropy ( y_true = real , y_pred = pred ) mask = tf . logical_not ( tf . math . equal ( real , <number> ) ) <hashtag> output </hashtag> <number> for y = <number> else output <number> mask = tf . cast ( mask , dtype = loss . dtype ) loss = mask * loss loss = tf . reduce_mean ( loss ) return loss import json functions = ' 8 exp ^ ( 9 e ) ' f = open ( ' modified_train . txt ' , ' r ' ) modified_text = f . readlines ( ) f . close ( ) modified_text = [ m [ : - <number> ] for m in modified_text ] buffer_size = <number> batch_size = <number> # let us limit the <hashtag> training </hashtag> examples for faster training num_examples = <number> inputs = [ ] targets = [ ] n_train = <number> for <sad> in ( modified_text ) : try : inp , tgt = <sad> . split ( "" ="") inputs . append ( inp ) targets . append ( tgt ) except : print ( f "" error at train_inputs = inputs [ : n_train ] train_targets = targets [ : n_train ] test_inputs = inputs [ n_train <happy> test_targets = targets [ n_train <happy> data = ( train_targets , train_inputs ) print ( "" creating the dataset "" ) dataset_creator = mydataset ( ' calculus ' ) # print ( "" training the tokenizer "" ) # train_dataset , inp_lang , targ_lang = dataset_creator . call ( data , buffer_size , batch_size , math_tokenizer ) f = open ( ' . / inp_lang_tokenizer . json ' ) inp_json = f . read ( ) inp_json = json . loads ( inp_json ) f . close ( ) f = open ( ' . / targ_lang_tokenizer . json ' ) targ_json = f . read ( ) targ_json = json . loads ( targ_json ) inp_lang = tokenizer_from_json ( inp_json ) targ_lang = tokenizer_from_json ( targ_json ) # example_input_batch , example_target_batch = next ( iter ( train_dataset ) ) # example_input_batch . shape , example_target_batch . shape vocab_inp_size = len ( inp_lang . word_index ) + <number> vocab_tar_size = len ( targ_lang . word_index ) + <number> max_length_input = <number> max_length_output = <number> embedding_dim = <number> units = <number> steps_per_epoch = num_examples / / batch_size train_dataset , inp_lang , targ_lang = dataset_creator . call ( data , buffer_size , batch_size , math_tokenizer ) # # test encoder stack example_input_batch , example_target_batch = next ( iter ( train_dataset ) ) print ( "" creating encoder "" ) encoder = encoder ( vocab_inp_size , embedding_dim , units , batch_size ) sample_hidden = encoder . initialize_hidden_state ( ) sample_output , sample_h , sample_c = encoder ( example_input_batch , sample_hidden ) sample_hidden = encoder . initialize_hidden_state ( ) # test decoder stack print ( "" creating decoder "" ) # vocab_size , embedding_dim , dec_units , batch_sz , max_length_input , max_length_output , attention_type = ' luong ' decoder = decoder ( vocab_tar_size , embedding_dim , units , batch_size , max_length_input , max_length_output , ' luong ' ) sample_x = tf . random . uniform ( ( batch_size , max_length_output ) ) decoder . attention_mechanism . setup_memory ( sample_output ) initial_state = decoder . build_initial_state ( batch_size , [ sample_h , sample_c ] , tf . float32 ) print ( "" creating the optimizer "" ) optimizer = tf . keras . optimizers . adam ( ) checkpoint_enc_dir = ' . / training_checkpoints / encoder ' checkpoint_enc_prefix = os . path . join ( checkpoint_enc_dir , "" ckpt "" ) checkpoint_dec_dir = ' . / training_checkpoints / decoder ' checkpoint_dec_prefix = os . path . join ( checkpoint_dec_dir , "" ckpt "" ) checkpoint_enc = tf . train . checkpoint ( optimizer = optimizer , encoder = encoder ) checkpoint_dec = tf . train . checkpoint ( optimizer = optimizer , decoder = decoder ) # restoring the latest checkpoint in checkpoint_dir checkpoint_enc . restore ( tf . train . latest_checkpoint ( checkpoint_enc_dir ) ) checkpoint_dec . restore ( tf . train . latest_checkpoint ( checkpoint_dec_dir ) ) print ( decoder . embedding . variables ) ` ` ` # # # relevant log output ` ` ` shell [ ] ` ` `",0
tensorflow/tensorflow,"load_associated_files does not load a txt file # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version latest # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? on "" load_associated_files "" , it emit longest ` does not exist ` error . all the lines below reproduce the same result . ` ` ` populator . load_associated_files ( [ os . path . abspath ( "" . / label_file . txt "" ) ] ) populator . load_associated_files ( [ ] ) populator . load_associated_files ( [ ' label_file . txt ' ] ) ` ` ` the label_file . txt exist in the same folder as main . py . < img width = "" <number> "" alt = "" スクリーンショット <number> - <number> - <number> <number> <number> <number> "" src = "" <url> also , what information am i supposed to put in the txt file ? is there any documentation for that ? # # # standalone code to reproduce the issue ` ` ` shell # creates model info . model_meta = _metadata_fb . modelmetadatat ( ) model_meta . name = "" cup classifier "" model_meta . description = ( "" identify a cup "" ) model_meta . version = "" v1 "" model_meta . author = "" integro "" model_meta . license = ( "" apache license . version <number> "" "" <url> # creates input info . input_meta = _metadata_fb . tensormetadatat ( ) # creates output info . output_meta = _metadata_fb . tensormetadatat ( ) input_meta . name = "" image "" input_meta . description = ( "" input image to be classified . the expected image is { <number> } x { <number> } , with "" "" three channels ( red , blue , and green ) per pixel . each value in the "" "" tensor is a single byte between <number> and <number> . "" . format ( <number> , <number> ) ) input_meta . content = _metadata_fb . contentt ( ) input_meta . content . contentproperties = _metadata_fb . imagepropertiest ( ) input_meta . content . contentproperties . colorspace = ( _metadata_fb . colorspacetype . rgb ) input_meta . content . contentpropertiestype = ( _metadata_fb . contentproperties . imageproperties ) input_normalization = _metadata_fb . processunitt ( ) input_normalization . optionstype = ( _metadata_fb . processunitoptions . normalizationoptions ) input_normalization . options = _metadata_fb . normalizationoptionst ( ) input_normalization . options . mean = [ <number> ] input_normalization . options . std = [ <number> ] input_meta . processunits = [ input_normalization ] input_stats = _metadata_fb . statst ( ) input_stats . max = [ <number> ] input_stats . min = [ <number> ] input_meta . stats = input_stats # creates output info . output_meta = _metadata_fb . tensormetadatat ( ) output_meta . name = "" probability "" output_meta . description = "" probabilities of the <number> labels respectively . "" output_meta . content = _metadata_fb . contentt ( ) output_meta . content . content_properties = _metadata_fb . featurepropertiest ( ) output_meta . content . contentpropertiestype = ( _metadata_fb . contentproperties . featureproperties ) output_stats = _metadata_fb . statst ( ) output_stats . max = [ <number> ] output_stats . min = [ <number> ] output_meta . stats = output_stats label_file = _metadata_fb . associatedfilet ( ) label_file . name = ' label_file . txt ' label_file . description = "" labels for objects that the model can recognize . "" label_file . type = _metadata_fb . associatedfiletype . tensor_axis_labels output_meta . associatedfiles = [ label_file ] # creates subgraph info . subgraph = _metadata_fb . subgraphmetadatat ( ) subgraph . inputtensormetadata = [ input_meta ] subgraph . outputtensormetadata = [ output_meta ] model_meta . subgraphmetadata = [ subgraph ] b = flatbuffers . builder ( <number> ) b . finish ( model_meta . pack ( b ) , _metadata . metadatapopulator . metadata_file_identifier ) metadata_buf = b . output ( ) populator = _metadata . metadatapopulator . with_model_file ( tflite_model ) populator . load_metadata_buffer ( metadata_buf ) populator . load_associated_files ( [ os . path . abspath ( "" . / label_file . txt "" ) ] ) populator . populate ( ) ` ` ` # # # relevant log output ` ` ` shell . <repeated> { q2 \ \ xbd \ \ xf6 \ \\\\\x 9 c \ \ xbd \ \x 8 0 \ \ xa1 \ \x 0 c =\\ xa6 \ \ xfa \ \x 1 f \ \ xbd \ \ xc2 \ \ xdd \ \x 9 9 \ \ xb9 <kiss> \ \ xa9 \ \ xbb ] b \ \ xe4 =\\ xd4 \ \ xef \ \x 1 4 \ \ xbdm \ \ xcb \ \x 0 c \ \ xbdo8 \ \ xfb \ \ xbdk \ \x 8 dl =} s \ \x 1 1 =\\ xb6 \ \ xcf \ \ xab =\\ x07x \ \x 0 c =\\ xf2t \ \ xe5 \ \ xbc :\\ x01 \ \x 8 a \ \ xb9 \ \ xdb + \ \ xa0 \ \ xbd \ \x 0 f \ \ xf5 \ \ xea \ \ xbd \ \ xf8 \ \ xaf \ \x 1 d \ \ xbd \ \ xe3s \ \ xde \ \ xbcm \ \x 8 6 \ \x 8 7 \ \ xbd \ \x 1 1 \ \ xa3 \ \x 1 8 =\\ x1e \ \x 0 bm =\\ xb6 \ \x0 0 \ \x 1 7 =\\ x97 :\\ xd0 =\\ x10 \ \ xda \ \ xf2 ;\\ x89 \ \x 1 b > = . <number> \ \ xa4 \ \ xbde \ \ xd7 \ \ xad \ \ xbd \ \x 8 8 \ \x0 0 r =\\ x0 f \ \ xe7 \ \x 8 5 = _ \ \ xda \ \x 9 b =\\ xd2v \ \ xfe < \ \ xa9 \ \ xe9 \ \x0 7 =\\ xba \ \x 9 1 \ \ xaf =\\ xaa \ \ xad \ \x 9 8 \ \ xbc ) \\x 9 c \ \ xbe \ \ xbc "" \\x 1 7 s =0 n \ \ xfc \ \ xbdb \ \x 9 c \ \ xd1 =\\ x9er \ \ t = r \ \ \ \ \ \ xad =\\ xac \ \ xc9x =\\ xe9r \ \x 9 4 \ \ xbdr \ \ xd4 \ \x 1 3 =\\ xb9 \ \ xc7d =\\ x91 \ \x 1 8 t = j \ \x 8 e \ \x 9 4 =\\ xe2 \ \ xeb \ \x 8 a \ \ xbd \ \ xe3 \ \ xf8 \ \x0 0 \ \ xbd6 \ \ xa2 \ \x 9 b \ \ xbc \ \ xfa \ \ t \ \x 9 8 =\\ xf9 \ \x 1 8 \ \ xdf < c \ \x 1 e \ \ xa7 =\\ xe2 \ \x 9 a \ \ xa0 <happy> k \ \x 0 b \ \ xbd \ \x 8 6 . <number> \ \ xbc \ \ xbar \ \ xe4 ;\\ xcb \ \x 9 b \ \x 0 c > \ \ xc2 # \ \ xd9 =\\ xaab \ \x 1 f \ \ xbc \ \ xa4 \ \x0 3 \ \ xbc \ \ xbd6 \ \ xea \ \ xf0 \ \ xbd \ \ xca \ \ xae \ \ xa8 \ \ xbd ( \ \ xb7 \ \ xfa \ \ xbd \ \ xff \ \x 9 2 d =\\ xa66 \ \ xd7 \ \ xbd \ \ xf7 \ \ xea ) = ` \ \ xf1 \ \ xa2 =\\ x92 \ \x 1 2 0 \ \ xbd \ \x 8 eb \ \ xa9 =\\ x13 \ \x 8 e \ \ xfd \ \ xbd \ \ xe0 \ \x 9 d ) \ \ xbd \ \ n \ \ <laugh> <money> =\\ xd7k \ \x 1 2 \ \ xbd \ \ xb6x \ \ xa0 < \ \ xael \ \ xd1 =\\ x053 \ \ xa2 =\\ x01x \ \ xb3 \ \ xbd8 \ \x 9 df \ \ xbd \ \ \ \ \ \ xef & \ \ xbd + k & \ \ xbc \ \ xc8 \ \ xa0 \ \x 8 a = g \ \x 8 1 \ \ xc8 \ \ xbd \ \ xeal5 =\\ xd4 ` \ \ xbf \ \ xbd \ \ xca \ \ ny = t \ \ xb0p \ \ xbd < e \ \x 7 f \ \ xbc \ \ xcau ^ <\\x 7 f \ \ xc2 \ \ xd1 ;p \ \ xa3 \ \ xb8 \ \ xbd \ \x 1 6 \ \ xeff \ \ xbd % r \ \x 8 7 \ \ xbd \ \x 8 1 { \ \ xb1 =\\ xf9 \ \x 1 3 \ \ xfb \ \ xbc \ \ xc1 \ \ xf8 \ \ xce ;\\ x06 \ \x 8 a \ \x 8 7 \ \ xbd \ \ r \ \x 8 fk \ \ xbd \ \ xb2 \ \ xd4 \ \x 1 4 =\\ x9d \ \ xecl \ \ xbd \ \x 0 c \ \ xe6 "" = f :o\\ xbd \ \ xd8_ \ \x 9 c \ \ xbd \ \x 1 8 \ \ xd6 : = \ \ xa6 \ \x 1 b <=\\ xde \ \ xd3 \ \ xa1 = fy \ \ xfd \ \ xbcw ) , =\\ xec \ \ xa4 \ \x 8 0 =\\ x89 \ \ xdf \ \x 9 b \ \ xbd \ \x 8 c \ \ xf6 \ \x0 6 \ \ xbe \ \ xc9 \ \ xc7 \ \ xab \ \ xbdo \ \x0 0 \ \x 9 3 \ \ xbd + \ \ xf8 \ \x 9 8 \ \ xbd \ \x 8 4 \ \ xeff \ \ xbb5 \ \ xa3 \ \ xd2 = v4 \ \x 1 9 \ \ xbc \ \ xd3 \ \x 7 f \ \ xe7 \ \ xbd \ \ xa3 } \\x 8 4 \ \ xbd \ \ xd6 \ \ xb2c \ \ xbd \ \ xda \ \ xc6 ` \ \ xbd \ \ xf5 \ \ xde \ \ xb5 \ \ xbdr \ \ xed5 < uo \ \x 8 4 < \\x0 3 \ \ xd7 \ \ xdb \ \ xbd \ \ xa9 \ \x0 0 \ \x 9 4 \ \ xbd \ \x0 6 ( \\x 8 8 \ \ xbdm \ \ xa4 \ \x 8 2 \ \ xbd \ \x 1 a \ \ xdb \ \ xc9 =\\ xcf \ \x 9 d \ \ xcd \ \ xbc ~ sg \ \ xbd \ \x 1 8 \ \ xeb ~ \ \ xbd \ \ xd0wv < \\x0 1 [ \\x 9 8 =\\ x92 \ \ xba \ \x 9 8 = \\x 8 3 \ \ xd5 \ \ xbd \ \x 1 0 \ \x 8 5 b \ \ xbc \ \x 9 5 + \\x 9 2 =\\ x8a \ \x 1 f \ \x 1 1 \ \ xbb \ \x 1 8 b $ =<\\ xe9 \ \ xaf \ \ xbdjfr =\\ x958 \ \ xed \ \ xbd \ \ xd8 \ \ xb2 \ \ xc2 < q [ \\x 9 7 \ \ xbd \ \x 1 4 \ \x 9 e \ \x 9 e =\\ xdd \ \x 1 9 \ \x 1 8 \ \ xbb \ \x 8 c \ \ xa0 \ \x 8 1 \ \ xbb ^ <number> \\x 1 a < \\x 7 fw \ \x0 0 \ \ xbd \ \x 1 c \ \ xc9 \ \ xd4 =\\ x83 \ \ xa8 \ \x0 4 \ \ xbd \ \ xd7 \ \x 9 9 k =-\\ xe5u =\\ x16 \ \x 8 3 \ \x 9 b \ \ xbcf \ \x 9 0 \ \ xb9 \ \ xbdj \ \x 1 f \ \ xab =\\ x82 \ \x0 0 \ \ xe3 \ \ xbd <user> . =\\ x1e \ \x 9 8 \ \ xac \ \ xbdx \ \x 8 e \ \x 1 c \ \ xbd \ \x 9 1 \ \x 8 3 \ \ xca =\\ xed \ \ xedj \ \ xbd @ \\x 9 6 \ \ xd8 =\\ x87 \ \ xb6 \ \x 0 e = ? q \ \ xb4 \ \ xbd \ \ xc4 \ \ xe9 \ \ xac = q \ \ xe8 \ \ xbd \ \ xbd \ \x 7 fe \ \ xed <:\\ xb4 \ \x 1 a = g \ \x 9 a \ \ xc9 \ \ xbd \ \ xf0 \ \ xc4 \ \ xc2 = nn \ \ xe8 \ \ xbd \ \ xfdb \ \ xf7 < \ \ xacs \ \ xb7 \ \ xbd \ \ xa6 \ \ xd9 \ \ xf1 \ \ xbcg \ \ xff \ \x 0 b < \ \ xdc \ \x 8 ea = u > \\x 9 8 \ \ xbb \ \ xc2f \ \x 8 6 \ \ xbd \ \ xaf \ \ xd8i \ \ xbd |\\ xc4r = pk \ \x0 4 =\\ xde \ \ xbfl =\\ xb8 & \ \ xa8 \ \ xbd :\\ xe0 \ \ xf0 \ \ xbdko \ \ xc9 \ \ xbd \ \ xac \ \x 1 e - =\\ xfe \ \x 0 b \ \ xa5 = <number> \\x0 2 . \ \ xbdk \ \ xac \ \x 8 c \ \ xbd \ \ xf8 \ \ n ;< w \ \ xca ) < \ \ xc8 \ \ xae \ \ xd9 \ \ xbdj \ \ xd9 \ \x 9 d \ \ xbd \ \ xd4 . b \ \ xbd \ \x 8 0 ] \\x0 2 \ \ xbd \ \x 9 a \ \ xe1 \ \ xa3 \ \ xbdgle \ \ xba \ \ xac \ \ xf3n \ \ xbd0 \ \x 8 1 \ \x 1 2 =\\ xc0 \ \ xa0 \ \ xa5 \ \ xbd \ \x 0 c - \ \ xf3 < \ \ xeb \ \ xca \ \ xda \ \ xbd > \\x 0 be < } \ \ xcf \ \x 8 4 =\\ xb1 \ \ xf9 \ \ xac =\\ xf5 \ \x 8 7 x\\ xbdp "" _ \ \ xbc \ \x 8 c ? \ \ xf4 < \ \ xb7 \ \x 9 4 \ \x 1 d =\\ xd2 \ \ xdbg \ \ xbb \ \ xe5 ? <={ y \ \ xe3 =\\ xbf ? \\x 8 3 \ \ xbd \ \ xfe \ \ xe8 \ \ xbb =*\\ xc2 \ \x 9 f \ \ xbd \ \ xbd \ \ xb3 \ \ xd0 =\\ x18j \ \ xf9 =\\ x9b \ \x 8 d \ \ xd0 \ \ xbc \ \x0 8 \ \ xb4 ^ < \ \ xa74 *\\ xbc \ \ xe7 \ \x 1 2 \ \ xea \ \ xbc \ \x 8 1 \ \x 8 8 y =o\\ r \ \x 7 f \ \ xbdp \ \x 8 f \ \x 8 d < yh \ \ xa8 \ \ xbba \ \x 0 c \ \ xf9 \ \ xbc_ \ \x 8 7 \ \ xac \ \ xbd7 < _ =\\ x05 \ \ xe53 =\\ x01 \ \ xabh <%\\ xfe \ \x 9 f < % yp < w \ \ xd3 \ \x 8 3 \ \ xbd \ \x 9 al \ \ xbe < & \ \ xd3 \ \ xb9 =\\ x93 \ \x 9 4 \ \ xbe =\\ x85 \ \x 1 1 o \ \ xbd \ \x 1 1 f \ \ xc1 < "" \\x 8 c \ \ xa2 =\\ xb5 \ \x 1 3 \ \ xb9 \ \ xbb \ \ xae \ \ xe4 \ \ xef \ \ xbd \ \ xb1y =\\ x92 \ \ xe5 \ \ xc5 =\\ x10 \ \ xcb \ \ xf8 \ \ xbd \ \ xce \ \x 8 b \ \ xd0 \ \ xbd \ \ \ \ \ \ xcex =$\\ xb5 \ \ xe7 < v \ \x 1 0 \ \x 9 f \ \ xbd \ \ xd3 ^ \ \ xbf = n \ \ xff \ \x 9 f < \\x 8 3 \ \ xcb \ \x 8 5 \ \ xbd \ \x 1 4 \ \x 7 f \ \x 9 4 =\\ xfb \ \ xda \ \x 9 5 =\\ xa07q ;\\ x8f \ \ xe9 \ \ xb7 \ \ xbd \ \ xdc16 \ \ xbc \ \ xed_ \ \ xb3 \ \ xbd \ \ xdf \ \ xf1e \ \ xbd_ \ \ xa1 \ \x0 2 \ \ xbe ` b \ \ xb5 \ \ xbd \ \x 1 f \ \x 1 5 \ \x 8 0 =\\ xc9 \ \ xba \ \x 9 b < <number> \ \ xa7 \ \x 8 3 \ \ xbd \ \x 8 c \ \x 1 1 \ \ xd2 \ \ xbd \ \ xe2 \ \ xaa \ \x 9 4 \ \ xbc \ \ xafho = d \ \ xeb \ \ xcb \ \ xbd \ \x 1 9 \ \ xf6 \ \x 1 2 \ \ xbb9 \ \ xbf \ \x 9 8 = e \ \ xa9 \ \ xb4 \ \ xbd \ \ xde \ \x 8 9 \ \ xa0 \ \ xbc \ \ n \ \ xe6 \ \ xcb < \ \ xa5 \ \x 9 9 \ \x 8 9 :\\ xc1z \ \ xd6 =\\ xb7h \ \ xc0 \ \ xbde \ \ xde \ \x 1 3 = fo \ \ xf3 \ \ xbd \ \ xc2 \ \ xa5 \ \ xaf \ \ xbd \ \x 8 b \ \x 1 bw = <number> \ \ xf0 \ \ xac \ \ xbd \ \x 0 e \ \x 9 a \ \x 9 d < <number> \\x0 0 \ \x 9 e \ \ xbb \ \x 8 d ? \ \ xd1 \ \ xbd \ \x 8 4 \ \ xf0w <happy> y \ \ ' \ \ xbd \ \x 8 0 dz =\\ xe0 "" \ \ xc2 = bg ? \ \ xbc_7 \ \ xc3 =\\ x83 =\\ xc5 =;\\ x11 \ \ xea \ \ xbd \ \x 8 4 |\\ xbc =\\ xdc \ \ xcf "" <\\x0 2 \ \x0 1 \ \ xa8 \ \ xbc } \\x 9 6 \ \ xa0 \ \ xbd \ \ xe5 \ \ xf9 \ \ xd7 \ \ xbd \ \ xdas \ \ xa8 = y \ \ xd1 \ \x 9 6 < \ \ xe82u \ \ xbds \ \ xbb \ \x 9 f \ \ xbdr \ \ xf7 \ \ xca =\\ x87 \ \ xb2 \ \ xa7 \ \ xbc \ \ xde \ \x 9 c \ \ xfa \ \ xbd \ \ xb0 \ \x 1 2 \ \x0 1 =\\ xef \ \ \ \ \ \ xa3 \ \ xbc \ \x0 0 . \ \ xb4 =\\ xdf \ \ xfds =\\ x87 \ \ xc3h =\\ xae \ \ xa9 \ \ xbc \ \x0 8 \ \ xd8 \ \ xc9 \ \ xbd \ \ xd2p \ \ xcf \ \ xbc \ \x 9 9 1 \ \ xa4 =\\ xa1s *\\ xbd \ \x0 7 \ \x 1 6 \ \ xee ;\\ xb4 \ \ xbeo \ \ xbd \ \x 8 b \ \x 9 5 \ \ xfd < \ \ xe8h \ \ xb7 < \ \ xdd \ \ xe4 \ \ xd7 \ \ xbd \ \x 8 7 \ \ xefo =\\ x9f \ \ xc8 \ \ xce =\\ x04a \ \ xa6 \ \ xbd \ \x 8 8 \ \x 9 5 q =\\ xcd \ \ xf9 \ \ xd7 \ \ xbdz \ \ xc4 \ \ xb3 \ \ xbd \ \ xcap ~ < \ \ xbd \ \ xa8 \ \x 8 6 \ \ xbd \ \ xf5 \ \ xf2 \ \x 8 3 =\\ xac3 ^ =\\ x1c \ \ xc6 % \ \ xbdn \ \ xd6 \ \x 9 b \ \ xbd |\\ xa5 \ \ xda \ \ xbd \ \x 1 2 \ \ xec \ \x 9 8 =\\ xd8 \ \ xd2q = h \ \x 1 f \ \x0 1 =\\ xe7 \ \ xcf \ \ xec < \ \ xb6g \ \ xd5 \ \ xbc \ \ xf3 > w =\\ x10 \ \x0 5 \ \ xff \ \ xbd \ \x 9 2 \ \ xa2e ;\\ xd4 \ \x 8 fm \ \ xbd \ \x0 7 \ \ xce \ \x 1 c =\\ xc3o :\\ xbd %\\ xca =\\ xbcki \ \x 8 d \ \ xbd ;\\ xef , =\\ xee \ \x 1 d \ \x 9 1 =\\ xca = z \ \ xbd \ \x 1 6 6 w \ \ xbc \ \x 1 a < \\x 8 3 =\\ xbeg \ \x 9 e \ \ xbd \ \ xbcw \ \x0 4 =\\ xf <money> \\x 9 6 \ \ xbd \ \ xdf \ \ xd5 \ \ xa6 < \ \ xd8j \ \ xd9 = e \ \ xe7 \ \x 9 b \ \ xbd3s \ \x 8 1 \ \ xbd \ \x0 4 \ \x 1 5 \ \ xb7 \ \ xbc \ \ xc8 \ \x 9 e \ \ xb0 \ \ xbd \ \ xe8 \ \ xad \ \x 9 b < { \ \ xab \ \x 9 4 < \ \ xa1 =\\ x9a < \\x 8 1 \ \ xfe \ \ xcf \ \ xbda \ \ xbbr \ \ xbc \ \x 9 5 \ \x 9 f \ \x 8 d =\\ r \ \x 9 e \ \ xba \ \ xbd \ \x 8 4 ( & \ \ xbd - l \ \ xad =\\ x10 ) ^ =\\ xb1 \ \ xefq = u \ \ xde \ \ xb68 \ \ xb7 \ \ xe2 \ \ xab < \\x 8 8 \ \x 1 c \ \x 9 a = r \ \\\\\x0 0 \ \ xbd \ \ xa2q \ \x 9 6 \ \ xbd \ \ xda \ \ xc3 , \ \ xbd \ \ xaf \ \ xc4 \ \ xf3 \ \ xbd \ \ xed < : = \ \ xd3 \ \ xc1 \ \ xe8 \ \ xbd \ \x 9 d \ \x 1 2 \ \ xa3 \ \ xbdg $\\ xb2 \ \ xbdc2 \ \x 1 e \ \ xbc \ \ xb7o \ \x0 5 \ \ xbd \ \x 1 0 \ \ xe0q ;\\ x08 \ \x 1 9 \ \ xe7 \ \ xbd \ \ xd7 \ \ xf4 \ \x 9 4 \ \ xbdb \ \x 8 5 \ \x 9 7 \ \ xbd \ \ xbf \ \ xf8 \ \ xab \ \ xbd \ \ xb9 | m <annoyed> h \ \ xa5 \ \ xbd \ \ xbe7 \ \x 1 5 =\\ xfd \ \ xd8 \ \ xa5 \ \ xbd \ \ xbb \ \ xbc \ \ xa8 \ \ xbd \ \x 8 c \ \ xe3 \ \x0 2 \ \ xbdx \ \x0 5 \ \ xfe < q } \ \ xcd = g \ \ xd8 \ \ xcf \ \ xbc \ \ r \ \x 8 4 \ \ xb1 \ \ xbd \ \ xea \ \ n \ \x 8 4 =\\ xbe \ \ xfai =\\ x80b \ \ t =\\ xc5i \ \ xa2 =\\ xf5 < "" < + k ~ = _ \ \ xcb #\\ xbd \ \ xfa \ \ xe3n \ \ xbd \ \x 8 2 ( \ \ xe1 < \\x 1 9 hs \ \ xbd \ \ xd6 \ \ xc9 \ \x 0 f =\\ xad \ \\\\\x 1 e < \ \ xb5 \ \ xdbl =& \ \ r \ \x 1 e = i \ \x 9 f \ \ xef < \\x0 5 \ \ xbc \ \ xeb =\\ x90 \ \x 8 e \ \ xa9 \ \ xbb \ \x 1 c \ \x 8 8 \ \ xca \ \ xbat ( ? \ \ xbd \ \ xa0 \ \x 8 e \ \ xc7 \ \ xbd \ \x 9 9 \ \ xa7 \ \ xbd \ \x 0 e \ \ xa8 \ \x 9 4 =\\ xa5 *\\ xea < \ \ xd8 \ \ xc2g < \ \ xb26 \ \ xc8 \ \ xbd \ \x 9 2 \ \ xd4 \ \ xee \ \ xbcpq \ \ xeb \ \ xbd \ \ xdf \ \x0 0 \ \x 1 4 =\\ xc2s \ \ xa6 \ \ xbd \ \ xd6 \ \ xf0 \ \x0 2 \ \ xbd ~ \\x 1 5 \ \ xc5 =\\ xa4 \ \x 9 0 \ \ xce < \\x 8 8 \ \x 0 b \ \ xb8 \ \ xbc \ \ xe2c \ \x 8 b \ \ xbcv \ \ xf5 \ \ xb2 =\\ x97 \ \ xcc \ \ xc7 \ \ xbd \ \ xe9 \ \ xf7p =\\ xa3 \ \ xcel ;\\ x92 \ \ xdb \ \ xd8 \ \ xbdsn \ \x 8 9 = u \ \ xf2 \ \ xbb \ \ xcc \ \ xf4 \ \ xd2 < \\x0 1 \ \ xfe \ \x 9 6 =\\ x04 \ \x 8 c \ \ xa8 \ \ xbc \ \ xbca \ \ xd3 \ \ xbdug \ \ xa2 =\\ xd5 \ \ xda \ \ xeb =\\ xb0 :\\ xd0 \ \ xbbj \ \x 1 8 =\\ xbd \ \x0 0 \ \ xaf \ \x 9 a : r \ \ xa0 <=\\ xe0af ;\\ x98r \ \ xbb \ \ xbd \ \ xb5 \ \x 0 c \ \x 9 6 \ \ xbd \ \x 0 c \ \ xcb \ \x0 8 \ \ xbc6 \ \ xa2 \ \ xef \ \ xbd $ w \ \ xa9 \ \ xbd ] \\x 1 6 \ \x 9 b \ \ xbd \ \x 1 6 t \ \x 9 b \ \ xbc $\\ xad \ \ xa0 < \\x0 3 \ \x 8 3 j \ \ xbd \ \ xf7 \ \ xac \ \ xbe \ \ xbda \ \x 9 cy < l_ \ \ xb3 \ \ xbde_ \ \ xb6 = 5 z \ \x 0 b \ \ xbd : n \ \x 8 a < o \ \x 1 e \ \x 9 b =\\ xc16 \ \x 8 7 =\\ xe2 [ \\x 1 c \ \ xbc \ \ xc0 \ \ xb0 \ \ xf3 \ \ xbcko \ \ xb3 =\\ xd1 \ \x0 4 . \ \ xbd \ \ xb6c \ \ xc2 \ \ xbd \ \x 1 6 w }=\\ x8ezy \ \ xbd \ \x 9 3 \ \ xf2 \ \ xc8 \ \ xbd \ \ xa1 ] \ \ xac \ \ xbd \ \ xd2 \ \ xaf_ =\\ xad \ \ xf0z \ \ xbd \ \ xca \ \x 9 8 \ \x 9 9 \ \ xbdg \ \x 8 a \ \ xc0 \ \ xbd \ \ xbb \ \ xfa \ \x 9 c =\\ x93 \ \x0 0 n =\\ xa8q \ \ xc1 \ \ xbc \ \ ' \ \ xc8 \ \x 9 5 \ \ xbd \ \x 9 7 \ \ xc3 \ \x 9 9 = ~ \\x 9 8 \ \x 1 7 =\\ x83 \ \ xdc \ \ xcf \ \ xbd \ \ xd9 \ \x0 4 \ \ xbd =\\ x05 \ \ xee \ \x 9 4 \ \ xbd \ \ xbcv \ \x 9 b \ \ xbc \ \ xf3 \ \x 8 8 \ \ xa2 =*\\ xc9 \ \ xab \ \ xbdd \ \x 9 c \ \ xa2 \ \ xbd \ \x 8 0 d \ \x 1 3 \ \ xbcab \ \ xd6 = hgg \ \ xbc \ \x 9 0 \ \ xd0 \ \ xce \ \ xbc \ \x0 3 \ \x 1 7 \ \ xc2 =\\ n \ \x 8 3 \ \x 9 3 \ \ xbd \ \ xccac \ \ xbd $\\ xcd \ \x 8 3 <tong> \ \ xdab \ \ xbc \ \x 1 1 \ \x 1 e \ \ xb0 \ \ xbcmp \ \ xb9 \ \ xbd \ \x 1 0 \ \ xeb \ \ xe6 \ \ xbc \ \x 8 3 \ \ xa1 \ \x 9 3 \ \ xbd8 \ \ xdf \ \ xad \ \ xbd \ \x0 8 \ \ xf5j < \ \ xfbw \ \ xfe < \\x 1 ef \ \ xc2 =\\ xd1 \ \x 1 1 \ \ xea ;\\ xa5 \ \x 9 e \ \ xcc =\\ x9d [ \ \ r =\\ xc87 \ \ xf9 \ \ xbd \ \ xf0 \ \ xafh \ \ xbc w \ \ xda < <x + <\\x 8 8 \ \x 8 6 \ \x0 8 < \ \ xd7 \ \ xd5 \ \x 9 7 < w \ \x 9 9 \ \ xb5 \ \ xbc \ \ xcd "" b \ \ xbd \ \ xa1 :\\ xfe \ \ xbd \ \ xd1m \ \x 9 6 \ \ xbd \ \x 1 2 \ \ xe2 \ \ xb0 \ \ xbd ] ~ <number> =}\\ x80v =\\ xf0 \ \ xed \ \x 9 4 \ \ xbdb \ \ xcb \ \x 1 7 =\\ xe1 \ \ xfb \ \x 8 c =\\ xaa_ \ \ xba =\\ xb6 ) g \ \ xbd \ \ xde / \\x 9 b \ \ xbd \ \x 9 4 \ \x 1 8 \ \ xc8 \ \ xbc < \ \ xde \ \ xc1 < \\x 9 1 \ \x 9 a \ \ xa9 = r \ \x0 4 x\\ xbdz \ \ xfb |\\ xbd \ \x0 4 \ \x 1 5 \ \x 9 6 < \\x 1 9 c \ \ xad =\\ xc7 \ \ xca \ \ xc3 \ \ xbd [ \\x 9 5 \ \ xe9 \ \ xbd \ \ xd2 . t \ \ xbd \ \ xb0_ \ \ t \ \ xbd \ \x 8 e \ \ xe2 \ \x0 4 =\\ xfbm \ \ xbe =\\ x18g \ \ xe3 \ \ xbcdf \ \x 8 f \ \ xbd \ \ xb6 \ \x 8 d \ \ xab \ \ xbd & \\x 8 c \ \ xb9 \ \ xbd \ \x 9 8 \ \ xc2 \ \ xee \ \ xbd \ \ xdd \ \x 9 a4 =\\ x0 e \ \ xa65 < \ \ xfa , \\x 0 f \ \ xbd \ \x 1 <sad> \ \ xe7 < \\x 7 f \ \x 0 c \ \ xdc =\\ x08 \ \ xb0 \ \ xbd > \ \ xa2 \ \ xce \ \ xbc7 \ \ xd7 \ \ xb9 \ \ xbd1k \ \ xbf =\\ x98d \ \ xcf \ \ xbdt \ \ xa2 \ \ xb7 =\\ ' \\x 1 8 \ \ xa9 =\\ x92 \ \ xe7 \ \ xb7 \ \ xbd \ \ xfe \ \ xb7 \ \ xcf \ \ xbd \ \x 9 bn \ \x 8 5 \ \ xbd \ \ xcd \ \x 0 ca =\\ xa1cy =\\ x84 \ \ xb5 \ \ xe3 < \ \ xc7x_ < \\x 8 ey % = bk \ \ xbe =\\ xab \ \x0 1 \ \ xb6 = h \ \x 8 8 \ \ xd4 \ \ xbc2 \ \x 9 2 i \ \ xbd \ \ xfc \ \ xee < = <number> \ \ xef < ! \\x 1 c \ \x 1 5 \ \ xbc \ \ xf <money> + \ \ xbd |\\ xf6z =\\ x8b \ \ xc6 \ \x 8 9 = z \ \x 8 dp \ \ xbd \ \x 8 a \ \ xe0 / \ \ xbd \ \ xf2g \ \ xcf \ \ xbd \ \x 1 6 \ \x 1 8 \ \x0 1 \ \ xbe { _ \ \ xc3 =\\ x9b \ \ xf7 \ \ xaf \ \ xbc \ \ xda \ \ xa3 \ \ xbc ;\\ x0 bm \ \ xe4 \ \ xbdv \ \ xbf \ \ xd9 \ \ xbcd : i =\\ xd4 \ \ xcc \ \ xbc \ \ xbd \ \ xc6x \ \ xdc =\\ xcdg \ \ xa2 =\\ x1e |\\ xdd \ \ xbd \ \x 0 e #\\ x9c =\\ xb3 \ \ xf0 \ \x 8 d =->\\ x83 \ \ xbd \ \ xa1 \ \ xd2n \ \ xbdvd \ \x 8 4 \ \ xbc \ \ xe2 \ \x 1 c \ \ xc8 =\\ xa6 \ \ xab \ \ xec < \\x 1 a \ \ xd4 \ \x 8 1 =\\ xe0 \ \x 9 9 \ \ xdb < \ \ xeb , \ \ xc6 \ \ xbd1 \ \ xef \ \ xcf =\\ x1f \ \x 1 f \ \ xbf \ \ xbd \ \ xc2 \ \x 8 4 \ \x 1 9 < \ \ xd0 \ \x 8 an =\\ xdbg \ \x 8 6 = fs \ \x 9 7 =\\ xe0 =\\ x02 =\\ x99 \ \ xe3 \ \ n \ \ xbdx \ \x 1 3 \ \ xe1 < ) \ \ xe1u \ \ xbc \ \ xba \ \x 9 f \ \x0 3 < \\x 8 a \ \ xc8z \ \ xbd ^ [ \ \ xbd =\\ xdfx \ \x 9 a \ \ xbdr \ \x 1 8 \ \x 9 e =\\ xc7 \ \x 8 f \ \x 9 c =\\ x98p \ \x 8 0 \ \ xbd \ \ xa65 \ \x0 7 \ \ xbb \ \ xbe |\\ xa1 =\\ x04 { \ \ xc8 =\\ x06 \ \x 9 4 \ \x 8 4 \ \ xbd \ \x 8 6 p4 \ \ xbc \ \ xa7l9 \ \ xbc \ \x 8 9 \ \x 0 e \ \ xa9 \ \ xbdh \ \x 0 f \ \ xb8 \ \ xbc \ \x0 2 \ \x 9 a $<\\ xfb6 \ \x 8 4 \ \ xbd \ \ t \ \ xbe \ \ xc1 = f \ \ xbe \ \x 1 4 \ \ xbc @ \ \ xb2 \ \ xb0 =\\ x11s + =\\ n \ \ xfb [ = <number> \ \ xdfm \ \ xbb \ \ xf1 \ \x 8 f \ \x 8 9 \ \ xbd \ \ xad \ \ xc1 \ \x 9 a < <number> \ \ xa1 / \ \ xbdz \ \ xf8 \ \x 9 a \ \ xbc ^ \\x 9 6 \ \ xd9 \ \ xbc \ \x 8 c { \ \ xa8 =\\ x02 \ \ xff \ \ xa3 ={\\ x9a \ \ xa4 = z \ \ xc5 \ \x0 5 =:\\ x81 \ \x 0 b \ \ xbd \ \x0 2 \ \x 9 5 \ \ xcd = a \ \ xcc \ \ xfc = a \ \ xf6 \ \ xcc \ \ xbda \ \ xa0 \ \ xd7 =""\\ xa4 \ \x 9 d =\\ xdd \ \ xee \ \ xcb \ \ xbd \ \x 8 d \ \x 0 e \ \ xce ; y \ \ xc7 \ \ xfb \ \ xbc \ \x 1 e \ \ xa0 \ \x 8 b =|\\ xa6 \ \ xf6 \ \ xbdms \ \ xa3 \ \ xbde7 \ \x 1 0 \ \ xbd \ \ xd5 \ \ xc0 \ \x 8 0 \ \ xbd \ \ xf5 \ \x 8 a \ \x 8 a =\\ xb7 \ \ ' \\x 9 d =\\ xb8 \ \ xea \ \ xe1 \ \ xbcjf \ \ xc0 < p \ \x 9 9 p \ \ xbd \ \ xe0uz \ \ xbc \ \ xd2 \ \ xf1 \ \x 8 0 =\\ x01 \ \x0 1 , \ \ xbdx \ \x 8 7 @ \ \ xbd \ \ xef \ \x 8 b_ =\\ x90 \ \x 9 9 \ \ xbb \ \ xbdp \ \x 8 1 \ \ xc1 = ~ \ \ xf6 \ \ xa6 =\\ xa1 \ \ xa3 \ \x 9 9 =\\ xd3mm \ \ xbd \ \ xb96 \ \ xe2 \ \ xbdp \ \x 8 e \ \ xbd \ \ xbd \ \x 9 0 fb \ \ xbdh \ \x 1 3 \ \ xcb \ \ xbd \ \ xd3 & \ \ xd0 <;\\ xea \ \ xb3 < \\x0 2 \ \ xc0 \ \ xd2 \ \ xbd \ \ xef \ \ xe4 & < b . \ \ xbf =\\ xf0 \ \ xc6 \ \ xaa \ \ xbd \ \ n \ \x 1 6 * = t \ \ xcc \ \ xae =\\ xcd \ \ xd7 <=\\ x94 \ \ xfdv \ \ xbc \ \ xb9g \ \x 9 0 \ \ xbdp \ \x 1 e \ \ xc8 \ \ xbd \ \ xb3 # \ \ xef < \ \ xb0 \ \ xf8 \ \x 1 5 =\\ x9a \ \ xf3q \ \ xba \ \ xa9b \ \x 8 f \ \ xbd \ \ xf1j \ \x 9 b \ \ xbd \ \ xb1 \ \x 8 f \ \ xc6 \ \ xbd ^ \\x0 7 \ \x 8 8 =\\ xc6sj \ \ xbd \ \ xed \ \ xf3 \ \ xea \ \ xbd \ \ xf0 \ \ xaa \ \ xd8 \ \ xbd \ \ xd5 \ \x 8 0 e \ \ xbd \ \ xb5 \ \ xfch < \ \ xc55 \ \x 8 3 \ \ xbd \ \ xc9 \ \ xc5 \ \ xaa =\\ x06 \ \x 8 d \ \x 9 8 \ \ xbd \ \x 9 d \ \ xa4 \ \ xc7 ; i \ \ xab \ \ xcf < \\x0 2 \ \ xdcu \ \ xbd \ \x 8 3 b \ \ xd3 =\\ x86 \ \x 1 8 \ \ xa1 ;\\ x1f ` \\x 8 9 =b \ \x 1 6 \ \ xa6 : l \ \ xf9 \ \ xb0 \ \ xbdn \ \x 1 6 \ \ \ \ \ \ xbd > | i \ \ xbc > j \ \ xf1 \ \ xbd \ \ xd3 \ \ xe0 \ \ xb8 \ \ xbd \ \x 9 0 lz \ \ xbd_ \ \ xae \ \ xe2 \ \ xbd \ \ xee \ \x 8 4 \ \ xab =\\ xcc @ \\x 8 3 < \\x 9 9 \ \ xaf \ \ xa5 =\\ xe0y \ \ xcf \ \ xbdh \ \ xaf \ \x 1 e =\\ x16 \ \x 1 2 \ \ xd2 \ \ xbd \ \ xfd \ \ xcc \ \ xcc =\\ xd17 \ \ xa3 \ \ xbcg \ \ xf7 \ \ xfb =\\ xd1 \ \ xe9 \ \x 9 b \ \ xbc \ \ xdc \ \x 1 6 \ \ xf6 :\\ xf4 \ \ xb4 \ \ xb3 \ \ xbd \ \ xd4f \ \x 8 1 =\\ xf6 \ \x 9 8 \ \x 9 a ;\\ xf2i \ \x 1 4 \ \ xbda \ \x 9 8 d \ \ xbd \ \x 1 6 es =\\ x9cb \ \x 9 2 \ \ xbd \ \ xd5 \ \x0 7 m \ \ xbd ) j \ \x 1 f =\\ xa0 \ \x 1 aw =\\ xb1 \ \ xe8_ =\\ x06 \ \x 8 4 \ \x 9 b8n \ \ xe7h =\\ x86 \ \x 8 3 t \ \ xbd \ \x 8 5 h \ \ xbc \ \ xbd \ \ xdb \ \ xda1 < \\x 8 1 n \ \x 1 f \ \ xbd \ \x 9 ff \ \x 1 b =\\ x96 \ \ xa07 = vcb \ \ xbdl \ \ xad \ \ xbd \ \ xbdjc \ \ xce \ \ xbd \ \ xb3 ) )<\\x <money> \ \ xdd \ \ xbd \ \ xde ~ \\x 1 9 \ \ xbd \ \ xd4 \ \ xb5 \ \ xa0 < y \ \ xfd \ \ xda \ \ xbc \ \ xec \ \ xc8 \ \x 8 4 =\\ xf5 \ \x 1 au \ \ xbb \ \ xdd \ \ xe9 \ \x 0 c \ \ xbd \ \x 1 0 \ \ xfd \ \x 9 2 =\\ x02 \ \ xe4 \ \x0 1 = z \ \x 1 f ^ \ \ xbd \ \x 8 e \ \ xef \ \ xc9 \ \ xbd \ \x 9 9 \ \ xf0 \ \x 8 5 =\\ x90 \ \ xba \ \ xc9 \ \ xbd \ \ t \ \ xa5 \ \ xc7 \ \ xbd \ \ xc4 \ \ xaf \ \ xe1 < \ \ xbf \ \ xae \ \ xc5 \ \ xbd \ \ xbdu \ \ xcc \ \ xbcui \ \x 9 4 =\\ xa0 \ \ xf9 \ \ xa5 =\\ x93 \ \x 9 1 \ \x0 2 \ \ xbdy \ \ xed \ \x 8 8 < \ \ xd0l \ \x 1 6 =\\ x07 } a =\\ xc0 \ \ xab \ \ xcc \ \ xbc \ \x 9 6 \ \ xbf \ \ t \ \ xbd \ \ xe9 ] \\x 8 2 \ \ xbd \ \x 1 c6 \ \ xab =\\ x1d \ \x 0 e \ \x 8 1 \ \ xbdm \ \ xb1 \ \ xda < \\x 1 3 ` \\x0 3 < \ \ xb9 \ \x 9 d \ \x 1 4 =\\ xed *\\ xbc < \ \ xd8v \ \x 9 6 =\\ xcf \ \ xc1 \ \x 9 0 \ \ xbc \ \ xf8 \ \x 8 1 \ \x 9 1 =\\ x1bn \ \x 9 e =c\\ xf9 \ \x 9 3 \ \ xbc \ \ xcf \ \x 9 d \ \ xe3 \ \ xbc \ \x 9 1 \ \x0 4 \ \x 8 5 \ \ xbd \ \ xb0 \ \ xbe \ \ xb2 =c %\\ xa2 \ \ xbc \ \x 8 2 \ \x 8 e \ \x 9 9 \ \ xbd %\\ xe4 \ \x 8 6 \ \ xbd \ \ ' \ \ xe6z =\\ xfc \ \x 8 9 v \ \ xbbi \ \ xaf \ \ xda < \\x 8 2 \ \ xec \ \x 1 7 \ \ xbdp \ \ xeer \ \ xbd \ \ n \ \x 8 e \ \x 9 c \ \ xbd \ \x 1 0 & \\x 1 f =\\ xfa :\\ x14 \ \ xbd \ \ xea \ \ xbf %\\ xbd \ \ xdfb \ \x0 2 \ \ xbes \ \ xeb \ \ xff ;\\ xfb \ \ xc4 \ \ xbd \ \ xcf \ \ xcd \ \ xed \ \ xbd \ \ xe7 \ \x 9 6 \ \x 8 3 \ \ xbdk0 \ \x 8 1 =\\ xc0 \ \ xb0 \ \ xcc \ \ xbd \ \x 8 1 \ \x0 5 \ \x 9 d \ \ xbd \ \ xa4 \ \ xff \ \ xc7 = lv7 \ \ xbdj \ \x0 4 \ \ xf9 \ \ xbdp \ \ \ \ \ \ xa3 =\\ x0 e \ \ xa9 \ \ xbd - \ \ xc3 \ \x 9 d \ \ xbcy \ \ xbeb =\\ xc9 \ \x 1 b \ \x 9 2 =\\ x01 \ \x 9 7 \ \ xbb \ \ xbd \ \ xd6 \ \ xba \ \ xb2 =\\ xda \ \ xee \ \ xeb \ \ xbc \ \ xbb \ \x 1 6 \ \x 9 4 < \ \ xdew \ \x0 3 \ \ xbe \ \ t + <number> \ \ xbd \ \x0 5 < \\x 8 8 < \ \ xc3l \ \x0 2 =\\ xad \ \ xac \ \x 9 1 < \ \ xde \ \x 1 f6 \ \ xbd \ \ xf2u4 \ \ xbc \ \ xab \ \ xddx \ \ xbd \ \x0 3 \ \ xf4 \ \ xc1 \ \ xbd \ \ xaci \ \x 1 0 \ \ xbd ? \\x 9 c \ \ xc0 \ \ xbd \ \ xffmh = dm \ \x 1 4 \ \ xbd ? \ \ xa6n \ \ xbd ] j \ \x0 4 \ \ xbd \ \ xa5 ] \\x0 5 \ \ xbb \ \x 0 cs \ \ xac \ \ xbd \ \ xf6 % \ \ xbd \ \ xbd \ \ xd4s \ \ xa9 < \ \ xa8 \ \x 1 f \ \ xbd =\\ x19 \ \ xdb \ \ xac < \\x0 1 \ \ xda \ \ xdb \ \ xbd \ \x 0 c \ \ xa6 \ \ xdd \ \ xbc \ \ xdcz \ \x 8 5 =<\\ xde } \ \ xbd \ \ r \ \ xda :\\ xbd \ \ xee \ \ xa3 \ \ xcb =\\ x9bm \ \ xac \ \ xbdz \ \x 8 at \ \ xbchf \ \ xc3 = ! }\\x 7 f \ \ xbd \ \x 1 d > \ \ xb2 \ \ xbd \ \ xe9 \ \ xbe \ \ xba =^\\ x0 c \ \x 9 b =\\ xef - m \ \ xbd \ \x 1 1 \ \x 8 f \ \ xb9 \ \ xbd \ \ xb9 > \\x 8 c \ \ xbb8 \ \ xbf \ \x 1 d =\\ xd5 \ \ xdc ! \ \ xbd \ \x 1 a \ \ xb0 \ \ xae \ \ xbd \ \ xb7e \ \ xe5 ;. \\x 8 fn \ \ xbd \ \ xaf & \ \ xfc \ \ xbd \ \ xd2 } \ \ xfa ; u \ \ xa4 ;\\ xbc \ \ xb9 - \\x 9 3 \ \ xbd \ \x0 8 8 0 \ \ xbc ] \ \ xba \ \ xc5 =[\\ xbc \ \x 8 7 \ \ xbd8 ] \ \ xe5 \ \ xbdz \ \ xa4 \ \x0 8 \ \ xbc \ \ xe4 \ \x 8 7 \ \x 9 5 =\\ x8f \ \ xf7 \ \ xa6 = <number> \ \ xc9y =\\ x1a & b \ \ xbd \ \ xc4 \ \x 8 8 \ \ xd8 = t \ \ xde \ \ xbb \ \ xbb_m \ \ xd1 < \ \ r \ \ xa5 \ \x 9 b =\\ xf8x \ \ xc7 =\\ xc4 \ \ xc1 \ \x 0 c = w \ \ xcf \ \ xe0 \ \ xbd9 \ \ xc3p \ \ xbb \ \ xf5j \ \x 8 c \ \ xbd \ \ ' \ \ xc82 =:\\ xe3 \ \ xb8 =\\ rp \ \x 7 f \ \ xbd < \ \ xf0t \ \ xbd \ \ xdb3 \ \ xcd =\\ xfd \ \ r \ \ xcd =\\ x9d \ \x 7 f \ \ xad =\\ xea \ \ xc6 \ \ xe1 \ \ xbd - \\x 9 8 \ \ xa1 \ \ xbd \ \ xde \ \ xc6 \ \ xce =\\ xcc \ \x 8 b |\\ xbd \ \ xd6 \ \ xb4 \ \ xc3 < \\x 1 ax / \ \ xbdv , \ \ xce =\\ xb9o \ \x 1 d \ \ xbd \ \x 1 b \ \ xac \ \x 8 4 \ \ xbdtf \ \ xd0 ;\\ xe2 \ \x 1 f \ \ xb0 =\\ xf7 \ \ r \ \ xb7 \ \ xbcb \ \ xf6 \ \ xa4 \ \ xbdt / \ \ xd3 \ \ xbd \ \x 9 f \ \ xb4 \ \ xad \ \ xbd \ \ xd9 \ \x0 6 \ \x 1 c \ \ xbdt \ \ n \ \ xce =\\ xa6 \ \ xc5 \ \ r =} t \ \ xf1 <;]\\ x93 \ \ xbd \ \ xbb5 \ \ xee \ \ xbd \ \x 1 4 \ \x 8 b \ \x 8 d = i2 \ \ xa9 \ \ xbd \ \ xa7 \ \ xd4 \ \ t \ \ xbc \ \ xb7 \ \ n \ \ xe2 \ \ xbb \ \ xaca \ \ xc6 =\\ xc9 ! \ \ xb7 =\\ xef \ \x 9 c \ \ xe2 \ \ xbc_ , \ \ xd2 ;\\ x1c \ \ xbe \ \ ' <\\x 9 d \ \ xc5 \ \x 8 b =\\ xd57 \ \x 1 d \ \ xbd \ \x 9 b \ \ xd2 \ \ xbb = 1 x\\ xb6 \ \ xbd \ \ xcc \ \ xe6q \ \ xbd ] e \ \ xcb =\\ x87 \ \ xab ( = g \ \ xdf \ \ xb0 \ \ xbd \ \ xcb \ \x 1 d \ \x 8 2 \ \ xbd \ \x 0 fb \ \ xae \ \ xbb \ \ xb34 \ \ xb3 =c& ` \ \ xbdw + a \ \ xbd \ \x 9 6 m \ \x 1 9 \ \ xbd ) s5 =\\ xfdf \ \ xc3 =\\ xf5f \ \ xb5 =\\ xa46 \ \x 9 f \ \ xbc \ \ xc7 \ \x 9 6 \ \x 8 b < u9 \ \x0 5 \ \ xbd ;\\ xe5 \ \x 8 8 \ \ xbdqn \ \x 8 6 \ \ xbd \ \ xa9zy < \ \ xfa \ \x 8 0 h =\\ x15pj =\\ xd8 \ \ xa4 \ \ xa1 =\\ xb2 \ \x 0 f \ \ xa2 = vl_ \ \ xbd \ \x 9 3 \ \x 8 2 \ \ xbf \ \ xbdrp3 = k #\\ xc6 < u ] \\x 8 1 \ \ xbd \ \x 9 d \ \x 7 f \ \x 9 9 \ \ xbd ) \ \ xe8 \ \x 7 f \ \ xbd \ \x 8 2 y \ \ xda = ` :\\ x92 = d \ \ xf1o \ \ xbd \ \x 8 9 \ \ xf8 \ \ xbd \ \x 8 1 | ` \ \ xbb \ \ xd6 \ \ xa6 \ \ xea ; 6 t \ \ xa8 \ \ xbd \ \x 9 f . \ \ xc7 \ \ xbc \ \ xe0 \ \ xbe \ \ xbe < \\x 9 0 \ \ xcd \ \x 9 3 \ \ xbd2a & =:\\ xecm \ \ xbbn \ \ xaa \ \ xa7 \ \ xbd \ \x 1 e \ \ xe9 \ \ xfb < \ \ xae =\\ x1a = g $\\ xde \ \ xbdx \ \ xa2z \ \ xbd \ \ xd4 \ \ xde \ \x0 0 \ \ xbd \ \ xe9 ) \ \ xf2 \ \ xbc \ \ xe4 ! \ \ xdf \ \ xbc \ \ xea \ \ xcc \ \x 8 a \ \ xbc \ \x0 5 \ \x 9 4 \ \x 8 c \ \ xbd \ \ xf6p \ \ xcd =\\ x16 \ \x 1 2 \ \x 8 f \ \ xbd \ \ xa6 \ \ xac \ \x 1 5 =\\ x8b $\\ x1c \ \ xbd \ \ xcas }=\\ xca \ \x 9 2 \ \ xc7 =\\ x1a \ \ xb0 \ \x 1 2 \ \ xbd \ \ xf0 \ \ xeck \ \ xbd \ \ xf03 \ \x 0 b \ \ xbd7 \ \x 8 9 \ \x0 2 > \ \ ' \ \ xabm \ \ xbd \ \ xc5 + r \ \ xbc \ \ xd8 \ \ xd7 \ \ xa6 =\\ xa6 \ \x 0 c \ \ xb5 =\\ x95 \ \ t \ \ xb0 =\\ xd5 \ \ xc1 \ \ xdb ;\\ xc3 \ \ xbb \ \x 8 6 \ \ xbd \ \x 8 9 \ \ xe6 \ \ xde =\\ x87 \ \ xc0 \ \x 1 e \ \ xbd \ \x 8 0 a \ \ xef =\\ x87 \ \ xfb \ \ xc3 \ \ xbd \ \x0 6 k \ \ n \ \ xbd "" r8 =\\ x99 \ \ xddk \ \ xbd \ \ r \ \ xbf \ \ xf9 \ \ xbda \ \ xc9 \ \ xd2 =\\ xca \ \ xfb \ \x 1 7 =\\ xa5 \ \ xac \ \ xdb \ \ xbd \ \x 1 2 \ \ xfd9 \ \ xbd2 \ \ xb4 % =\\ x8c \ \x 9 3 \ \x 9 2 \ \ xbdx \ \ xb3 \ \ xa7 \ \ xbd \ \ xf2 \ \ xef \ \x 9 7 \ \ xbd \ \ xbf \ \ xad \ \ xf0 \ \ xbd \ \x 8 f \ \x 9 6 \ \ xda =\\ xe8 \ \ xc8 \ \ xf6 \ \ xbb \ \ xafy \ \x 1 1 \ \ xbd \ \x 9 d \ \x 1 2 \ \x0 7 > \\x 9 fe \ \ xa2 < m \ \ xf0 ( =\\ x8a \ \ xb1 \ \ xdc \ \ xbb \ \x 7 f \ \ xaa \ \ xb6 \ \ xbd \ \ xb9p \ \x 8 f \ \ xbd \ \ xb8 \ \ xe8 \ \ xb3 \ \ xbda \ \x 8 7 \ \ xbd = w + \ \ xe4 =\\ x8d \ \ xcc \ \x 1 d =\\ x049 \ \ xad \ \ xbd \ \x 9 f \ \ xa4 \ \ xd8 \ \ xbd \ \ xf6w \ \ xf2 < \\x0 2 8 h \ \ xbc \ \x 9 0 \ \ xb1 \ \x 8 2 = r \ \ xe2 > \ \ xbc \ \ xf4 \ \x 8 c \ \ r \ \ xbd4 \ \ xf3 \ \ xab \ \ xbdd \ \x 9 5 \ \ xde < \ \ xcb ` \ \ n \ \ xbe \ \ \ \ \ \ xb38 =\\ x81 \ \ xef \ \ xa5 \ \ xbdq \ \ xd2 \ \x 8 2 \ \ xbd < \ \ xb2 \ \ xb9 ;\\ xb3 \ \x 8 2 \ \x 1 a \ \ xbd ] \ \ xad # =\\ x10 \ \ xb3 \ \ xbc \ \ xbd7 \ \ xee \ \x 8 4 \ \ xbd \ \ xf037 =\\ xfd \ \ xaa [ \ \ xbd \ \x 8 6 \ \x 9 2 \ \ xbb =\\ xc6 \ \ xcf ==\\ xb6b ;\\ xbd \ \ xec \ \x0 1 \ \ xcd < g %\\ xbd = d \ \x 1 1 \ \ xc2 < \ \ xca \ \ xf7 \ \ xa7 \ \ xbd \ \ xc39 \ \x 9 b \ \ xbd \ \ xfai \ \ xaa \ \ xbc :\\ x1a \ \ xf5 \ \ xbc \ \x 8 4 f \ \x 1 e \ \ xbd % ;\\ x8a \ \ xbd \ \ xb6 \ \ xbb \ \ xa9 \ \ xbd \ \ xd3 \ \x 8 3 \ \ xb1 \ \ xbd \ \ xf8 \ \ xf3 \ \ xdf =\\ x03 ~ \ \ xeb \ \ xbc \ \ xe1 \ \ xe8 \ \ xf1 =\\ xe9k \ \ xc2 \ \ xbd \ \ xcaa \ \x 9 1 \ \ xbc \ \ xd1 \ \x 8 1 \ \ xe9 \ \ xbc \ \x0 6 \ \ xbak = ! 0 y \ \ xbdy \ \ xba # =\\ xefl \ \ xe9 =\\ xea \ \ xd6 \ \ xd0 \ \ xbb \ \ xf3 \ \ r \ \x0 0 \ \ xbd \ \x 0 f \ \ xc4 \ \ xf3 < bx \ \ xc2 < \\x 8 ai \ \ xb3 \ \ xbd \ \x 9 5 & <number> =\\ xbb \ \ xfbh =\\ xb9 \ \ xe1 \ \ xa3 ={\\ x06 \ \x0 4 > j / \ \ xcb =\\ xb0 \ \x 8 a \ \ xaf \ \ xbd \ \ xd2 \ \x 1 8 m \ \ xbbm \ \ xa4 \ \x 1 b =\\ x99 \ \ xc8 \ \ xe8 \ \ xbds \ \x 0 b - \ \ xbd \ \x 8 c \ \ xed @ =)\\ xe0 \ \x 8 c \ \ xbd \ \ xef \ \x 1 7 \ \ xed =\\ xdf4 \ \x 8 4 \ \ xbd \ \ xb4 \ \x0 8 \ \x 8 b \ \ xbc \ \ ' m [ ;\\ xc85 \ \ xbe \ \ xbd \ \x 8 2 _ \ \ xd7 < uj { =\\ xadf \ \ xd5 \ \ xbd \ \ xb4f \ \ xdc \ \ xbds =\\ x9d \ \ xbd \ \ xb7x \ \x 9 6 \ \ xbc \ \ n6 \ \ xc3 \ \ xbd \ \ xf0 \ \x 8 f2 \ \ xbd \ \x 0 cm \ \x 9 7 =\\ x9b5 ^ =\\ xbbw } \ \ xbde \ \ xdfm = <number> \ \ xa5 \ \ xa5 \ \ xbb \ \ xfd \ \x 8 a \ \ xe9 = r \ \x 9 1 \ \ xc7 =\\ x9d \ \ \ \ \ \ xdc \ \ xbd \ \ xddv \ \x 1 c \ \ xbd \ \ xa7 \ \ xc7 \ \ xc1 \ \ xbd ( \ \ xad \ \ xd9 \ \ xbc \ \ xb8y \ \ xba \ \ xbd \ \x 1 c \ \x 9 a ? \ \ xbd \ \x 7 f3 \ \x 8 e \ \ xbd \ \ xb7 \ \x 1 1 \ \x 1 d < \\x0 3 \ \ xc5 \ \ xc6 =#{\\ xa7 \ \ xbc \ \x 9 4 \ \ xcf \ \ xd1 =\\ xb6 \ \ xf9 \ \ xc9 \ \ xbc \ \ xbd ! \ \ xd1 \ \ xbd \ \ xba8 \ \ xce \ \ xbd \ \ xaa / <number> =\\ xffm ! =\\ x01 \ \ xc9 \ \ xd7 = n \ \x 8 5 2 < \\x 8 fu \ \ xbf \ \ xbc \ \x 8 b |\\ xa3 < v } \ \ xc0 < \ \ xa9 \ \ xbd \ \x 9 f = j \ \ xbe & < \ \ xb <money> <number> =\\ xd6 \ \ xb2 \ \ xbd \ \x 9 8 \ \ xda \ \ xf3 \ \ xbd \ \ xce \ \ xe7 \ \ xd9 \ \ xbd \ \ xc3 \ \x 1 e \ \ xee \ \ xbde % k = <number> \\x 9 fz =\\ xac \ \x 8 5 \ \ xd6 =& p \ \ xab \ \ xbd \ \ xac { \\x0 0 < t7g \ \ xbd { \\x0 1 \ \ xd5 =\\ xc4ei = a \ \ xf7a \ \ xbc \ \x 1 8 \ \x 1 5 f \ \ xbd \ \x 7 ft \ \ xff =\\ x08 \ \ xf4 \ \x 1 0 = <hashtag> l </hashtag> \ \ xd7 \ \ xbd \ \ \ \ p \ \x 9 f \ \ xbdxm \ \x 0 c \ \ xbd \ \x 8 f \ \x 9 2 \ \x 1 e ;o\\ xde $ =\\ x8ev \ \ xfb \ \ xba \ \ xc9 |\\ x9e \ \ xbc \ \ xef \ \x 8 a \ \ xdc =\\ xa3 \ \ n \ \ xae =\\ xb9 \ \ xe4o \ \ xbd \ \ xfa9 \ \ xab \ \ xbd \ \ xa8 \ \x 1 f \ \ xd9 =\\ x06 \ \x 1 5 t \ \ xbd \ \x 9 c . y \ \ xbd \ \ xc6bw =\\ xa2*u <censored> =\\ xda \ \x0 7 d < q \ \ xeb - =\\ xd3 \ \ xf2 \ \x 9 2 =\\ xd8i ^ = e \ \x 8 3 \ \ xd2 =\\ x12 \ \ xa2 \ \ xbc :\\ xb6 \ \ xaa + \ \ xbd . \ \ xe7 \ \ xeb =]\\ x9f \ \x 8 5 =<\\ t \ \ xa7 \ \ xbdbz \ \ xa3 \ \ xbd \ \ xd2z \ \x 9 a \ \ xbc \ \x0 7 \ \x 8 7 \ \ xc5 =\\ x84y \ \ xb2 \ \ xbd \ \x 9 7 \ \ xcc \ \ xe6 \ \ xbc \ \ xfb \ \ xe2 \ \x 1 1 \ \ xbd \ \x 1 bg \ \ xb4 < \ \ xa9 \ \ xfc \ \ xb9 =\\ xdam \ \x 9 5 = v \ \ xf0 \ \ xdb < \\x0 6 \ \x 1 e \ \ xb5 \ \ xbd \ \ xbf \ \x 8 7 \ \ xbd =\\ xa0 \ \x 1 da =\\ x8e \ \ xfb \ \ xcc \ \ xbb #\\ x19 \ \x 1 5 = bb \ \ xb2 \ \ xbd \ \ xf3 \ \ xfd \ \ xf0 \ \ xbd \ \ xe8 \ \ xb9 \ \ xe7 \ \ xbc \ \ xd5 \ \x 8 6 \ \ xc0 = <number> |\\ x18 \ \ xbd \ \x 8 2 \ \ xed \ \ xfe \ \ xbc \ \ xc1 \ \ n \ \ xf0 =& <number> \ \ xdb \ \ xbc :\\ xe5e \ \ xbd \ \ xbd ! \ \ xd6 =,\\ xa5 \ \x 8 9 =\\ xae \ \ xfcg \ \ xbdk \ \ xaft =\\ x15 \ \x 8 d |\\ xbcb @ \\x 8 1 < z \ \x0 0 \ \ xd8 \ \ xbd \ \x 1 7 @ \\x 8 8 \ \ xbc \ \ xaa \ \x 8 4 \ \x 9 c =\\ xc5 \ \ xa4 \ \ xeb \ \ xbd \ \x0 8 ax =\\ xa5t \ \ xdc =\\ x8f \ \ xb2 \ \x 8 8 =\\ xda \ \ xe0 \ \ xab \ \ xbd \ \ xefi \ \ xeb \ \ xbdj \ \x0 5 \ \x 9 4 \ \ xbdd \ \ xd9 \ \ xda \ \ xbd \ \ xebs \ \ xb4 \ \ xbc \ \x 1 9 \ \ xb9 \ \ xaa \ \ xbdu ^ \ \ xb2 =\\ xae \ \x 8 f \ \x 8 9 < \ \ xada ^ =\\ x93 \ \x 0 e \ \x 1 0 =\\ x9f \ \ xe8 \ \x 8 a \ \ xbc \ \ xc4 \ \ xd0 \ \x 8 6 = gr \ \ xac ;\\ x12 \ \ xd4 \ \x 9 d \ \ xbd \ \x 9 5 \ \ xbf \ \ xf3 \ \ xbcgk \ \x0 1 \ \ xbd \ \ xacm \ \ xc6 = <number> \ \ xd9 \ \ xec \ \ xbc \ \ xba \ \x0 2 \ \x 9 a \ \ xbc \ \ xcc \ \ xe5 \ \ xa8 \ \ xbbg \ \ xe51 \ \ xbd \ \ xee \ \x 1 e \ \ xf1 < \\x0 4 \ \ xf6 \ \ xa0 \ \ xbd \ \ xf7 \ \ xe5 \ \ xf3 \ \ xbd \ \ xd3 \ \ xb4t \ \ xbc \ \x 7 fi \ \x 8 4 =""\\ xea \ \x 1 2 = f \ \x 8 9 \ \ xf7 < \ \ xd9 \ \x0 0 \ \ xb7 < \ \ xe7k \ \ xe7 =\\ xb3 \ \ xcb \ \ xb7 =\\ xd1 \ \ xef \ \ xc6 \ \ xbc . \ \ xaf \ \x 1 8 \ \ xbcb \ \x 9 7 \ \x0 1 > a \ \ xe0b =\\ xed \ \ xbe \ \ xa3 \ \ xbc \ \ xb2a \ \ xa1 = e \ \x 1 9 t = nx \ \x 9 5 \ \ xbd \ \ xd3j \ \x 8 b = <number> \ \ xf4 \ \ xd0 < \ \ xe6i \ \x 9 6 \ \ xbdg4 \ \x 8 0 \ \ xbd \ \ xf4 \ \x 8 2 \ \ xf7 \ \ xbd \ \ xc1 \ \x 9 d \ \ xd8 \ \ xbc \ \ xa1 \ \x 0 e { \ \ xbd \ \x 8 e \ \ xf4 \ \ xfe \ \ xbd \ \ xa3 \ \x 1 6 \ \ xf3 = <number> \ \ xbc \ \x 8 b \ \ xbc \ \ xeb \ \ xac \ \ xb6 =\\ x8f \ \ xec \ \x 9 9 < q \ \ xa2 \ \ xe3 < \\x 1 4 \ \ xcca \ \ xbd \ \x0 2 \ \x 9 a \ \ xc8 \ \ xbdf \ \ xf0 : = \ \ xfe \ \x 8 9 \ \ xc0 \ \ xbbj \ \ xbe \ \ xb0 \ \ xbc \ \x 8 bc \ \x 8 0 \ \ xbc ! \ \ ' <number> =\\ xdb \ \x 8 3 \ \ xb2 =\\ x1b \ \ xae \ \ \ \ \ \ xbd \ \ xf3 \ \ xb2 \ \ xd5 =\\ xe6i \ \ xa6 \ \ xbdsi \ \x 9 5 = a \ \ xb6g =\\ x1f \ \x 9 5 \ \x 9 4 \ \ xbdf \ \ xac \ \ xf5 ;\\ x1b \ \x 9 c \ \ xad \ \ xbd <sad> 8 \ \ xbc \ \ xab \ \x 9 5 \ \x 8 8 \ \ xbc \ \ xe6 \ \x 8 3 \ \x 8 7 \ \ xbd \ \x 9 2 \ \x 1 3 \ \ xee \ \ xbd \ \x 8 8 \ \x 1 1 \ \ xb8 \ \ xbd \ \ xb1 ] \ \ xcc =\\ x9dom \ \ xbd \ \ xde \ \ xa2 ) =>\\ xc2v =\\ x8a \ \x 9 7 \ \x0 6 \ \ xbcj \ \ xc8 \ \ xc0 < \ \ xfd *\\ x1f \ \ xbc \ \ xa8 \ \ xd2 # = <number> |\\ x15 \ \ xbd \ \x0 5 \ \x 1 0 \ \ xcd \ \ xbc \ \ xf1 \ \ xa8 \ \ xb6 \ \ xbd \ \x 8 5 \ \x 9 4 z \ \ xbd =\\ xf0x \ \ xbdj [ \\x 9 2 \ \ xbci \ \x0 3 ( =\\ xfei ~ \ \ xbd \ \ xbdh \ \ xa4 =\\ x0 e =\\ x06 > \ \ xdd \ \ xf4 \ \ xba \ \ xbd \ \x 1 0 \ \ xa6 \ \x 9 d = j \ \ xe0 \ \x 9 6 \ \ xbd \ \ xcb \ \x0 3 \ \x 9 1 =c\\ xb3 \ \ xb1 \ \ xbde \ \x 8 c \ \ xbb0 \ \x 1 4 \ \ xee ;\\ xc7 \ \ xf9 & \ \ xbb \ \ \ \ \ \ xea \ \ xf6 \ \ xbd \ \ xdd \ \x 1 e \ \ xe5 \ \ xbb \ \ xd2 \ \ xd6 \ \ xa1 \ \ xbc \ \x 9 6 k \ \x0 6 \ \ xbd \ \ xa2 \ \ xc5 + :\\ x845 \ \x 1 b \ \ xbd { \ \ xe0 & \ \ xbd \ \ xb1 \ \x 8 3 q = l \ \ xa5 \ \ xb4 \ \ xbd \ \ xa2 \ \x 8 2 \ \ xcf =\\ x19 \ \ ' \ \ xce :\\ x9e \ \x 9 6 \ \ xc8 =\\ xec \ \ xa7 \ \ xb4 \ \ xbbw \ \x 0 f \ \ xc3 =\\ n \ \x0 0 \ \x 9 f \ \ xbc \ \ xb7 - \ \ xbc = hj \ \x 9 8 =\\ xd1s \ \ xb1 = d ` s= \ \ xbb \ \ xd6 \ \ xbc \ \ xee \ \ xd9 \ \ xa3 \ \ xbc \ \x 1 6 \ \x 9 d \ \ xa7 =\\ xc2 \ \ xfa \ \x0 5 = <number> \\x 1 b \ \ xff \ \ xba \ \ xca \ \ xd6g =\\ x92 \ \ xec \ \x 9 2 \ \ xbdx \ \ xb5 ) \ \ xb <elongated> \ \ xb8 \ \ xc7 \ \ xbd \ \ xacf \ \x 9 5 = a \ \ xbf \ \ xc2 \ \ xbc \ \ xb7 \ \ xb5 \ \ xb7 =\\ xa5 \ \ xa2 > \ \ xbd \ \ xb2 \ \x0 4 \ \x 9 f =\\ x06m \ \ xbb < \ \ xe2 \ \ xc6 \ \ t \ \ xbd \ \ xc9 \ \x 1 9 \ \ xfd \ \ xbd ! \ \ xa1 ; = ~ m7 \ \ xbc { \ \ xe4 \ \x0 3 \ \ xbc + \ \ xdd \ \ xbd =b \ \ xaf \ \ xbc \ \x 8 2 \ \x 9 5 \ \ xcf ;c\\ ts =\\ x1eu \ \ xe5 \ \ xbd \ \ xff \ \x 8 6 l \ \ xbd \ \ xf3 \ \x0 6 \ \ xa5 ; w \ \ xd6 \ \x 1 6 \ \ xbd \ \x 9 0 0 \ \x 8 9 < \ \ xd5 ; ? \ \ xbd \ \x 9 d [ \\x 9 8 \ \ xbd \ \ xf2 \ \ xff \ \x0 8 =\\ x84 \ \x 9 2 \ \\\; \ \ xe3 \ \ xa5 \ \x 8 7 \ \ xbc \ \x 8 4 \ \ xf4 @ =\\ xe0 \ \x0 3 & \ \ xbb \ \ xb9q \ \ xbe \ \ xbd \ \x 9 d0 ! =\\ xc8_ \ \x 8 8 \ \ xbd { \ \ xa5 \ \ xc8 =\\ xaafw \ \ xbdp \ \x 1 5 \ \ xe5 \ \ xbc \ \x 9 9 \ \x0 3 \ \x 8 9 \ \ xbd \ \ xe1b , ==\\ x7f9 \ \ xbd \ \ xcck \ \ xe4 \ \ xbdp < \\x 9 5 =\\ xf0 \ \ xc2 \ \ xcd =\\ xf5 :\\ x88 =} ff \ \ xbdf4 \ \x 1 f =\\ x80 \ \ xe4b \ \ xbd \ \ xec \ \x 9 3 \ \ xc8 \ \ xbc \ \x 0 e \ \ t \ \ xff ; ga \ \ xd7 \ \ xbd < l \ \ xaa \ \ xbc \ \ n \ \ xa9 } \ \ xbde \ \ xb9w \ \ xbd \ \ xdb \ \x 9 0 \ \ xb9 ;\\ x11 \ \ xb7 \ \ xab \ \ xbd <user> \\x0 2 \ \ xbd ) \\x 8 5 _ \ \ xbd \ \x 8 7 c *\\ xbd \ \ xd9 \ \ xbc \ \x 8 5 < 5 r \ \x 9 f \ \ xbc_ \ \ xfa \ \ xf3 \ \ xbdgj \ \x0 0 \ \ xbe \ \ xc7 \ \ xb6 \ \x 9 7 \ \ xbd \ \ xf8m \ \x0 8 = e ? \ \ xd4 =\\ xdf \ \x 9 cg \ \ xbb6 \ \x 8 e7 = m \ \x 1 6 \ \x0 8 =\\ xe5j \ \ r \ \ xbd \ \ xecs \ \x 1 c =\\ x83 \ \ xa5 \ \ xc0 =\\ xfc \ \ xe1 \ \ xcd \ \ xbd \ \ xba \ \ xde \ \ xa6 \ \ xbdy \ \ xd7n \ \ xbd \ \x 9 8 { b \ \ xbc \ \x 1 a \ \ xfe \ \ xff \ \ xff \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \ xb6_ ) \ \ xbc \ \ xe4 \ \x 8 1 , \ \ xbc \ \x 9 b \ \ xcdv \ \ xbb \ \ xf9 \ \x 9 0 \ \x0 7 =\\ xee \ \x 9 6 "" \ \ xbch \ \x 1 7 7 \ \ xbc \ \ t \ \ xb4 @ \ \ xbc \ \ xe2s \ \x 1 b \ \ xbc \ \ xd7kq \ \ xbc :\\ xd3 - \ \ xbc \ \ xbe \ \ r \ \ xc9 < b \ \ xbd \ \x 9 2 < \\x 9 8 \ \ xc5 % \ \ xbce6 \ \x 1 3 \ \ xbc \ \x 1 d ) <number> \ \ xbc \ \x 9 4 n "" \ \ xbc ! \ \ xe4p \ \ xbcndg < \\x0 2 \ \ xec - \ \ xbb \ \ xbb \ \x 8 c \ \ xd7 ;& \ \ xaa #\\ xbc \ \x 1 b \ \ xec \ \x0 2 =\\ xa33t \ \ xbc5 \ \ xf5 \ \ r \ \ xbc \ \x 1 0 \ \ xf7q \ \ xbc \ \ xf2p3 \ \ xbc [ \ \ xa7 \ \x 1 d \ \ xbco ( \\x0 1 \ \ xbce \ \ xe4b \ \ xbc \ \ xf6o \ \x 0 f \ \ xbc \ \x 8 fj \ \ xfb \ \ xbb \ \x0 3 g \ \ xf6 ;\\ r \ \x <money> \ \ xbc \ \ xb9 \ \ xb9 \ \x 8 3 ;\\ xb6 % y \ \ xbc \ \x 8 2 o \ \x 9 6 \ \ xbb \ \ xa6 \ \ xe3n \ \ xbc8o \ \ xf2 < { u ( \ \ xbcg \ \ xf1 \ \ xbbop #\\ xbc \ \x 8 b & <number> \ \ xbcnw \ \ xdd ;\\ x00 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 9 b \ \x 9 2 \ \ ' \ \ xbc + a |:\\ xb4 \ \ xb5 \ \x 9 8 < \\x 9 e \ \ xc9 \ \x 8 d \ \ xbc \ \x0 6 \ \ \ \ \ \ xcd \ \ xbb \ \ xff \ \ xc3 \ \ xe2 \ \ xbb \ \ xcf \ \x 1 e \ \x 1 0 \ \ xbc \ \ xff :\\ xbc \ \x 8 es \ \ xc4 \ \ xbb \ \x 1 b \ \ xf8 # \ \ xbc \ \x 0 fd } \ \ xbc \ \ xf6a1 \ \ xbc \ \ xbf \ \ xca \ \x 7 f \ \ xbce \ \ xcc \ \x 1 3 =]\\ xa2 \ \x 1 8 \ \ xbc \ \ n \ \ xe40 \ \ xbc6 \ \ xd8 % \ \ xbc \ \ xfew \ \ xc3 \ \ xbb \ \ xc8 \ \ xb0g \ \ xbc \ \ xec \ \ xfdq \ \ xbc & \ \ xff \ \ xff \ \ xff \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xf6c ^ = <number> \ \ xd6 \ \ xbc < \ \ xa5j4 \ \ xbcosb \ \ xba \ \x 1 6 \ \ xe0c \ \ xbc \ \ r \ \x 1 7 9 \ \ xbc \ \x 8 e |\\ x1a \ \ xbchlt \ \ xbc \ \ xab \ \x 9 0 \ \x 1 6 \ \ xbc < t \ \x 1 e \ \ xbc \ \ xcd \ \x0 4 h ;c - \ \ xfb \ \ xbb \ \x 0 c \ \x 9 0 \ \x 8 4 < h , \\x 1 8 \ \ xbaz \ \ xa0 / \ \ xba \ \ xaef \ \ xfd \ \ xb9w1 \ \x0 7 \ \ xbc \ \ xc0 \ \ xa37 < \ \ xcf \ \x 1 9 \ \ xf4 \ \ xbb \ \ xc8 { \\x 1 4 \ \ xbc \ \ xa7 \ \ xbbm \ \ xbc \ \x 1 e \ \ xc3 \ \x 0 f =,\\ x0 c . \ \ xbc \ \ xb1 \ \ xe26 \ \ xbc ) \\x 8 7 \ \x 1 3 \ \ xbcoa \ \ xf8 \ \ xbb \ \x 1 b \ \x0 3 < \ \ xbc \ \x 1 5 1 9 \ \ xbc \ \ xebz \ \x 1 4 \ \ xbce \ \x 8 9 \ \x0 3 ;\\ xa9s \ \ xab \ \ xb8 \ \ xb5 ~ \\x 1 5 \ \ xbc \ \ xb2 \ \ xff \ \ xff \ \ xff \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x0 0 k \ \x 1 bo \ \ xbbkj ? \ \ xbb6 \ \ xee @ <wink> r ( \ \ xbc \ \ ' \\x 8 3 \ \ xc1 \ \ xba \ \x 1 b *\\ x84 <;\\ xde \ \ xc8 \ \ xbc \ \ xef \ \ xd0 \ \x 9 c \ \ xbawt %\\ xbc \ \ xc8 \ \ ' \\x 1 b = k \ \ xaa \ \x 0 c =*\\ xd4p < \ \ xa3 \ \x 9 d \ \x 9 3 \ \ xbcj0 \ \x 8 3 ; \\x 9 a . < \ \ xa8 \ \x 1 0 h \ \ xbc \ \x0 0 \ \x0 0 \ \x0 6 \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xc0 \ \x0 6 \ \x0 0 \ \x0 0 \ \x 9 a \ \x0 7 \ \ xc7 \ \ xb9 \ \ xb4 \ \x 1 f =\\ xba ;,\\ xb9 \ \ xb8 \ \ xa0t \ \x 0 b \ \ xb8 ` \ \ xbb \ \x 1 b <annoyed> $\\ xc99 ? \ \ xc8 \ \x 8 0 8 \ \ xbf2 \ \ xc89 \ \ xe1x_ \ \ xb7 \ \ xc3 \ \ xcd - : <number> "" \ \ xe59k \ \x0 0 \ \ xdf \ \ xb9 \ \x 0 e \ \ xf7 \ \x 1 0 \ \ xba \ \ xf8 \ \x 1 3 \ \x 1 c \ \ xb91 ] \ \ xd6 \ \ xb6 \ \ xef \ \x0 4 \ \x 0 e :\\ x87 |\\ xb8 \ \ xb83 \ \ xfc \ \x 9 4 9 h \ \ xfcd9 \ \ xab ] \ \ xe79di \ \ xf98 \ \x 8 4 \ \ xac ! :\\ xe2 \ \ xb4 \ \x 8 5 \ \ xb7 \ \x0 4 \ \x 8 f \ \x 8 a \ \ xb9 \ \ xa2 \ \x 9 4 \ \x 1 e :\\ xfc \ \ xca \ \x 1 8 :\\ x18 \ \ \ \ r \ \ xb7 \ \x 8 d \ \ xb1 \ \x0 3 9 \ \x 8 d \ \x 0 c ( <number> \\x 1 au @ \ \ xba [ \ \ xc7a96 ! ^ \ \ xb9 \ \x 9 4 \ \ xbf \ \ xc1 \ \ xb9f \ \ xc0 \ \ n :\\ xf7 \ \x 8 4 \ \ xd89 \ \x 1 fjd \ \ xba & \ \ xe0 # \ \ xba \ \ xdcy \ \x 1 6 \ \ xbae \ \ xf7 , :\\ x18 \ \ xc3 \ \x 1 9 8 hm \ \ xeb \ \ xb8a \ \ xa8 \ \x 1 9 9 ` \\x 8 c \ \ xca \ \ xb9m \ \ ' \\x 1 3 \ \ xb9 \ \ xc4 \ \x0 5 \ \ xf79 \ \ xee *\\ xae \ \ xb86g : rs \ \ ' 9 s \ \ xe8 \ \x 1 c \ \ xba \ \ xfc } o \ \ xb8 \ \ xc3 < \ \ xd19 \ \x 1 a \ \x 0 b \ \x 8 a \ \ xb9 - \ \ xc8 \ \x 1 5 :\\ xbd \ \ xf0 \ \x 1 d \ \ xba \ \ xf2 \ \'$ \ \ xba \ \ xa8 \ \x 1 al \ \ xb7 \ \ xcfzz9 \ \ xb4l \ \ xe09h \ \x 1 6 \ \ xcc \ \ xb9 # \\x0 0 = <number> \ \ xaa \ \ xa6 \ \x 9 5 9 y \ \x 8 e6 \ \ xb9 ? \ \ xaa \ \x 9 a \ \ xb9 ? \ \ xd0 \ \ xd09*m99 <censored> \ \ xaa \ \ xac \ \ xb1 \ \ xb9 \ \ xf3 \ \ xa30 :o( n9 \ \x 8 d \ \x 8 2 \ \ n :\\ xc5 \ \x <money> :\\ x93 \ \ xd3 "" \ \ xba \ \x 1 1 \ \x 1 6 \ \ xfd \ \ xb9 \ \x 1 6 :\\ xca9 \ \x 9 0 \ \ xcaq \ \ xb9 \ \x0 6 \ \ xfa % : k { <number> \ \ xba \ \x 9 bk \ \x 8 d \ \ xb9 \ \x0 3 k \ \ xbe \ \ xb9 \ \ xac \ \x0 5 \ \x 1 6 \ \ xba \ \x0 6 \ \x0 0 ) \ \ xba \ \ xf9 ] \\x 9 d9 \ \x 8 5 ! \\x 1 f \ \ xba :\\ x142 \ \ xbat \ \x 9 a "" \ \ xb9 \ \ xb0 \ \ xd4 *\\ xb9v \ \x 9 0 \ \x 1 b : ~ \ \ xc5v9 , e \ \ xf99 \ \ xd6x ] \ \ xb9 \ \ xa2s \ \x 1 f \ \ xba7x7 \ \ xb9 \ \x 8 f \ \ xe5 \ \x0 5 \ \ xbar6 \ \ xcc \ \ xb7 % \ \ xcd \ \x 9 0 9 x\\ x98 \ \ xa59 \ \ xc0 \ \ xfd \ \ xb8 \ \ xb9 \ \ xc16 \ \x 1 b :\\ xcbe2 : w \ \ xe2 \ \ xa39w } \ \ xca \ \ xb9 \ \ xf4 \ \ n \ \ xd07 \ \x 8 9 v "" \ \ xba \ \ xfa \ \ xbc \ \x0 5 \ \ xba \ \x 9 7 \ \ xb6t \ \ xb80 , j \ \ xb7 \ \ xc4 \ \x0 0 \ \ xf19 m \ \ xcc \ \ xb9 \ \x0 2 % v8 \ \ xc7 \ \x 1 8 \ \ xce \ \ xb9 \ \x 8 d \ \x 9 3 2 :\\ xc6 \ \ xa9x : w ! \\x0 4 \ \ xbaj \ \ xbb \ \ xd8 \ \ xb9 \ \ xba \ \ xe7v :\\ xa8 { \\x 8 6 9 \ \x 1 c \ \x0 6 \ \x 0 e \ \ xbac \ \x 8 b \ \ xd19s \ \ xc3 \ \ xa28 \ \ xbbt \ \ n \ \ xba \ \ xe3x \ \x 1 8 :\\ xbe \ \ xa7 \ \ xa3 \ \ xb9 , \ \ xb5 \ \ xae \ \ xb9 \ \x 8 4 \ \ xb4 \ \ xee \ \ xb9 \ \ xe5n \ \ xa19 \ \x 9 a \ \ xca \ \ xed8 \ \ xb9 \ \x 1 3 \ \x 8 6 9 \ \x 0 bh8 \ \ xb9_ \ \x 1 3 \ \x 1 1 \ \ xba \ \ xd7 \ \ xcb \ \ xea70_f \ \ xb9 \ \ xab \ \ xdd \ \ xd4 \ \ xb8 \ \ xaa \ \ xfc \ \x 8 b9 \ \ xb0 * # <happy> e \ \ xc0 \ \ xb9 \ \x 9 e \ \ xa5s \ \ xb9 \ \x 8 f { \ \ xc09p \ \ xe6 <user> ) m \ \ xe8 \ \ xb7 \ \x 1 5 \ \ xe8r9 : <money> \ \ xb9 \ \x 0 b \ \ xb3 \ \x 1 7 \ \ xb9 \ \x 9 f \ \ xc4 \ \ xff \ \ xb8 \ \x 8 2 \ \x0 3 \ \ xf2 \ \ xb9i \ \ xa6 + :\\ x13 \ \x 8 2 \ \ xf69 \ \ xe5 } \ \ xf3 \ \ xb7 \ \ xcf \ \x 1 c \ \ xa1 \ \ xb90 \ \ xbc % : sx "" \ \ xbaa \ \ xf0 \ \ xb3 \ \ xb9 \ \x 1 1 e \ \ xc1 \ \ xb8t \ \ xa7l \ \ xb9 \ \ xc3m \ \x 1 a \ \ xba \ \ xcb1 \ \x 1 c \ \ xb6j \ \ xf5 \ \ xb9 \ \ xb9 \ \x 8 0 k \ \ xfb \ \ xb9 \ \ xa9 \ \ xe2 \ \x 8 f9 \ \ xdb \ \x0 3 8 :\\ xf4 \ \ xd3 \ \ xb48 \ \x 9 9 \ \ xb8 \ \ xcb9 \ \x 9 f \ \ xaf \ \ xd4 \ \ xb9 \ \x 9 8 "" #\\ xb9 ^ \ \ xfc0 : d \ \ xfbr \ \ xb8 \ \x 8 c \ \x 0 e \ \x 8 2 9 c \ \ xd8 \ \ xc0 \ \ xb97 \ \x 9 0 9 :\\ x8f \ \ xb4 \ \ xfe \ \ xb9 \ \x 8 d \ \ xa1 \ \ xca \ \ xb8 \ \x0 4 l @ \ \ xba \ \ xf3 \ \ xc9 \ \x 9 e9o \ \ xd6 \ \ xc3 \ \ xb8 \ \ xb8_ \ \x 0 c9 < \\x 8 a \ \ xe17 \ \ xb8 \ \ xc7 \ \ xad \ \ xb9 \ \ xd0b \ \ xcb9 \ \x 8 f \ \ xd4 \ \x 9 f9 \ \ xaed \ \x 0 e : <number> \ \ xc4 \ \ xf59 \ \ xc3 \ \x 0 f \ \ xdd93 ! \ \ xe78 \ \ xa0 \ \ xbes9 \ \x 8 1 \ \x 8 8 \ \ xd39 \ \ xca \ \ xf0 :\\ xb9 \ \ t \ \x 8 6 w \ \ xb9lv \ \x 9 f9 \ \x0 5 \ \x0 8 \ \ xb79 \ \x 1 c \ \x0 3 t8 [ %\\ xba9m - o \ \ xb8 \ \x 9 f \ \ xa8 \ \x 1 2 \ \ xba \ \ \ \ l \ \x 1 3 :\\ xf1 \ \x 9 f { <number> \\x 8 8 \ \ xc7 \ \ xd99 \ \x 1 4 0 \ \x0 5 \ \ xbagaf \ \ xb9 ] \\x 8 d \ \ xfb4 \ \x 1 8 e \ \ xa5 \ \ xb9 \ \ xa4 \ \x 8 7 \ \ xe0 \ \ xb9 \ \x 8 5 \ \x 0 cq7 \ \x 8 ay \ \x0 7 9 \ \x 9 f \ \ xd6 \ \ xe9 \ \ xb9n \ \ r \ \ xe1 \ \ xb9iw *\\ xb9 \ \x 8 8 \ \ xf9m7i \ \ xce ! :\\ x06 ` \\x 8 c \ \ xb9k \ \ xdf \ \ xc6 \ \ xb9 \ \x 8 3 \ \ xa9 \ \ xd89 \ \ xd8t \ \x 8 d \ \ xb9 ;\\ xf9 \ \ xaf9 \ \ xf8 \ \x 9 5 \ \ xd6 \ \ xb9 \ \ xfc \ \x 9 8 \ \ r \ \ xba \ \x 9 7 \ \x 1 9 q9 \ \x 8 3 \ \ xa9 \ \ xe0 \ \ xb8 \ \ xbd \ \ xd7 \ \x 9 f \ \ xb9 \ \ xdb \ \ xfax \ \ xb9 \ \ xc1 \ \x 1 0 \ \ xb09 \ \ xe8 \ \ xe <money> :\\ xba \ \x 8 dp \ \ xb8 \ \x 8 b8 \ \ xd57 \ \x 9 5 \ \ xc1 ( : <money> \ \ xcd \ \ xb8 \ \ xf3 \ \ xf2 \ \x 9 d \ \ xb9 \ \x 8 a \ \x 0 e \ \x0 7 \ \ xba \ \x 1 cxp9x \ \ xd1 \ \x 8 3 \ \ xb8 \ \ xc5 ! ^ 9 h \ \ xe9 \ \ xa39 \ \x0 1 m > \ \ xba \ \x0 3 \ \ xb8 \ \x0 4 \ \ xb9h \ \ xf3 / \ \ xba \ \ xaf \ \ xf3 \ \x 1 0 \ \ xba \ \ xbe3 \ \ xad \ \ xb9 % & \ \ xe09 \ \ xc7a29 \ \x 7 f \ \ xb4 \ \x 8 b \ \ xb8 \ \ xeb8 \ \x 1 e \ \ xban & \ \ xe8 \ \ xb9d \ \ xb2 , \ \ xbaw \ \ xa3r \ \ xb9 ! \ \ xa5 \ \x 8 5 \ \ xb9b \ \ xf6u \ \ xb9 \ \ xe7 \ \ xcf . \ \ xba \ \x 9 5 # \ \ xd5 \ \ xb9ps \ \ xae8 \ \x 0 c |\\ xce9u \ \x0 5 \ \ xa88g \ \ xe8 \ \x 1 b \ \ xba \ \ xab \ \x 8 e \ \x 8 3 \ \ xb7 \ \x0 7 [ \ \ xb6 \ \ xb9 @ \\x 0 e ^ <number> \ \ xad \ \x 1 b \ \ xad \ \ xb9 \ \ xd5 \ \x 9 0 "" \ \ xba \ \x 9 9 ( \ \ xe39a \ \x0 1 \ \ xea9 / <tong> \ \ xb8 \ \ xf9 \ \ xde <:p \ \ xcf \ \x 1 e :\\ xcc \ \ xde ? \ \ xba \ \ xe4 \ \ xf0 \ \ xfc \ \ xb9ho \ \x 1 c \ \ xb8i \ \ n \ \x 1 4 \ \ xba \ \x0 4 \ \ xd2 \ \ xa08 ` \\x 9 f \ \ xec8 \ \ xca \ \x 1 b \ \x 1 c \ \ xba \ \x 9 ea \ \ xf39 \ \ xc7 \ \ xdfm :\\ xbf \ \x 9 f \ \ xc58 *\\ xfc \ \x 1 2 \ \ xb9 \ \ xbf \ \ xe1 \ \x 8 4 \ \ xb8zf #\\ xba @ \ \ t \ \ ' : k \ \ xe9 \ \ xbd \ \ xb9z + \ \ xe49 \ \ xbe \ \x 1 1 \ \ xce \ \ xb9 . \ \ xe <money> :\\ x88 :\\ xf1 \ \ xb9 \ \ xa3 \ \ xef \ \x 1 0 \ \ xba \ \ xcar \ \ xe0 \ \ xb9 \ \ xa4i ;\\ xb9 \ \ xae \ \ xa3z \ \ xb9x \ \x 0 f \ \x 1 b <surprise> 4 \ \x0 8 \ \ xba <kiss> \ \x 1 7 \ \ xba \ \ xdb ! :]{ "" \ \ xba \ \ xeac \ \x 9 d \ \ xb9 \ \ xae \ \ xdc \ \ xbe \ \ xb9 ? i3 \ \ xba / \ \ xc7 \ \ xb9 \ \ n \ \ xb95 :\\ x95 \ \x0 1 \ \x 0 e \ \ xba \ \ xe1m \ \ xa09 \ \ xa6c ( :\\ xdcd \ \ xeb9 \ \ xf <money> \ \ xf58 / [% \ \ xbak \ \ xb12 \ \ xba \ \x 9 6 r \ \ xc49 <hashtag> d </hashtag> \ \ xd79 \ \x 1 7 \ \ xd5 < : . \\x 1 ca7 \ \ xbf \ \ xc6 \ \ xdf \ \ xb6r \ \ xe0 \ \x0 8 9 \ \ xe7 \ \ xc7 \ \x0 5 :\\ x11 \ \ xa4 / \ \ xba \ \ xf8 \ \x 8 c ? :\\ x02b @ : ky \ \x 9 6 9 \ \ xaa \ \ xa6 = : j \ \ xad \ \ xae9 > h \ \ xa2 \ \ xb9sl \ \x 1 8 :\\ xc6n \ \ n \ \ xbaq ~ ;\\ xba9 \ \x 9 8 } <number> \ \ xfe \ \ xf9 "" <number> \ \ xf3d :\\ xba \ \ xe3 \ \ t \ \ xd49 \ \ xf6 \ \ xcc \ \ xd0 \ \ xb9zs3 \ \ xba \ \\\\\x0 2 \ \x 0 b \ \ xbas \ \ xa4 \ \x 9 5 \ \ xb9g \ \ xa8 \ \ xb09 \ \ xd7 \ \ xdd , :o\\ xfc \ \x 0 c \ \ xba \ \x 9 4 \ \ xc2 \ \ xe2 \ \ xb9 < \\x 9 7 r9 \ \ xa5 \ \ xf6 \ \ xa1 \ \ xb6 \ \ xf1 \ \x 8 b \ \ xe0 \ \ xb9 \ \ xf1 \ \x 8 9 \ \ xd2 \ \ xb9 + f \ \ xdf8 \ \x 1 2 g \ \x0 4 \ \ xb9 \ \ xda \ \ xd2 \ \ xda9 ~ \\x 1 4 \ \ xf37 \ \x 8 c < $: \ \ xf53 \ \x 1 9 :\\ xfckx7 \ \ xae \ \x 9 c9 \ \ xba \ \x 1 f \ \x 8 d \ \ xee \ \ xb8 \ \x 0 f \ \x 1 9 \ \x 1 e \ \ xb9 \ \x 1 2 \ \ xa5 \ \ t :\\ xe6 \ \ xb0z9 \ \ xab & \ \ xa6 \ \ xb7 \ \ xb5 \ \ xbcx \ \ xb9 \ \ xa2 \ \x 9 c \ \x 1 2 9 \ \x 1 2 g \ \x 8 0 \ \ xb9 \ \x 9 1 \ \x 9 2 \ \ xf69 \ \x 9 2 \ \x0 3 \ \x0 1 \ \ xba \ \ xfb \ \ xfd \ \x 0 b :\\ xb4 \ \ xf4f9 \ \ xcf \ \x 8 0 \ \x 1 4 8 m \ \x 0 b \ \ xb8 \ \ xb9 \ \ xeb \ \ xebw8 , @ \ \ xf8 \ \ xb9f \ \x0 0 \ \ xe78 \ \ xc64 \ \ xfd \ \ xb9 + [\\x 8 c8 \ \ xec \ \ xca \ \ xd89 \ \x 8 9 \ \ xa6 % \ \ xb8 \ \ xeff \ \x 1 3 \ \ xba \ \x 1 1 _ \ \ xf8 \ \ xb9 ) \ \ xd0 \ \ xc29 \ \ xda4 \ \x 1 f \ \ xb9o < \\x 1 0 :\\ xe3p \ \x 0 c : % f \ \ xb8 \ \ xb9 \ \x 1 8 \ \ xe6 \ \ xfa9 \ \x 0 b / | <number> \ \ xd8 \ \x 8 b \ \ xcb9 \ \x 8 e_ \ \ ' \ \ xba \ \x 8 f \ \ xb5 \ \ xbf91r \ \ xf5 \ \ xb9 \ \ xdf \ \ xfb ) \ \ xbayb \ \x 1 7 \ \ xb8o =\\ xdf8q \ \ xea ` \ \ xb9 \ \x 8 8 + \\x0 5 8 u \ \ xba \ \x 1 3 \ \ xbag \ \x 1 f \ \x 1 8 9 8 1 \ \ xd09 \ \ xb3 \ \x 9 6 \ \ xc29 \ \x 9 9 i \ \x 1 e \ \ xb8g \ \ xb3 \ \x 0 e \ \ xba |\\ x0 e \ \x 8 7 9 \ \ xb06 \ \x0 4 9 \ \ xb1f , :o\\ x99 @ \ \ xba \ \x 1 b \ \ xa5 # <number> \ \ xf4 \ \x0 0 \ \ xc7 \ \ xb7 \ \ xa6 \ \x 1 7 q \ \ xba \ \x0 7 hp9z \ \ xc7 & :\\ xe8 \ \ xa4 \ \x0 2 : k \ \ xbd \ \ xb19 \ \ xffu <number> \\x 0 c : r \ \ xba \ \ xb2 \ \ xcc \ \ xe49 \ \ xfef \ \x 9 c9 \ \ xf3p6 \ \ xba \ \ xe4 \ \x 1 0 \ \ xc1 \ \ xb9 \ \x 1 cq9 \ \ xb <money> \ \ xa9 \ \x0 6 \ \ xba ) w \ \x 1 8 9 % \\x 1 8 \ \x0 0 :\\ xeat \ \ xc9 \ \ xb8 \ \x 8 6 + ! \ \ xb7 \ \ xe2 \ \x 1 0 \ \x0 6 \ \ xbamx48 \ \x0 6 \ \ xf0 \ \ xf2 \ \ xb9s \ \x 1 8 6 \ \ xb9 \ \ xdc \ \ xc0 \ \x 1 6 :\\ xb6 \ \ xb9o \ \ xb9 \ \ n \ \ n2 \ \ xbakp \ \x 8 e9 \ \ xaf \ \x 8 8 \ \ xc39 \ \ xb4 \ \x 9 e6 :\\ xba \ \ xc8 \ \x 1 a \ \ xb9 \ \x 8 0 \ \ xb5 \ \x 0 f :\\ xf1 \ \ xb8 \ \ xc39 \ \ xccy \ \x 1 f :\\ xbc \ \ xbf \ \x 1 f \ \ xba \ \ xc8 \ \ xaf \ \ xed9 \ \x 1 2 \ \x 8 2 \ \x 1 9 <kiss> \ \ xfe \ \ xff8 \ \x 1 0 \ \x0 2 \ \ xfa9 - \\x 1 1 a90 } <number> :\\ x82 \ \x 9 6 \ \ xa49 \ \ xf8n \ \x 0 f : i \ \ xde :\\ xb9p \ \ xf3 \ \ xff \ \ xfft \ \ xf3 \ \ xff \ \ xff \ \x 0 f \ \x0 0 \ \x0 0 \ \x0 0 mlir converted . \\x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 e \ \x0 0 \ \x 1 8 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 4 \ \x0 0 \ \x 0 e \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 9 4 \ \x0 2 \ \x0 0 \ \x0 0 \ \x 9 8 \ \x0 2 \ \x0 0 \ \x0 0 \ \x 9 c \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 main \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ t \ \x0 0 \ \x0 0 \ \x0 0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \ xcc \ \x0 1 \ \x0 0 \ \x0 0 |\\ x01 \ \x0 0 \ \x0 0 8 \ \x0 1 \ \x0 0 \ \x0 0 \ \ xf8 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 c \ \x0 0 \ \x0 0 \ \x0 0 < \\x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 b \ \ xfe \ \ xff \ \ xff \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 8 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 8 \ \ xf4 \ \ xff \ \ xff \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 9 6 \ \ xfe \ \ xff \ \ xff \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 8 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 6 \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 7 \ \x0 0 \ \x0 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \ n \ \x0 0 \ \x0 0 \ \x0 0 \ \ t \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ n \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 4 \ \x0 0 \ \ n \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 7 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 6 \ \ xff \ \ xff \ \ xff \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 ( \\x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xf6 \ \ xfe \ \ xff \ \ xff \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xe6 \ \ xfe \ \ xff \ \ xff \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \ xd8 \ \ xfe \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 f \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 2 \ \ xff \ \ xff \ \ xff \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 ( \\x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 r \ \ xff \ \ xff \ \ xff \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 f \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 e \ \x0 0 \ \x0 0 \ \x0 0 b \ \ xff \ \ xff \ \ xff \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 t \ \ xff \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 e \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \ r \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 5 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 e \ \x0 0 \ \x 1 a \ \x0 0 \ \x 1 4 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 4 \ \x0 0 \ \x 0 e \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 5 4 \ \x0 0 \ \x0 0 \ \x0 0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 e \ \x0 0 \ \x 1 8 \ \x0 0 \ \x 1 7 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 4 \ \x0 0 \ \x 0 e \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \ r \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 e \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 4 \ \x0 0 \ \x 0 e \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 ( \\x0 0 \ \x0 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 7 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 5 \ \x0 0 \ \x0 0 \ \x0 0 x\\ t \ \x0 0 \ \x0 0 \ \ xac \ \x0 8 \ \x0 0 \ \x0 0 < \\x0 8 \ \x0 0 \ \x0 0 \ \ xe0 \ \x0 7 \ \x0 0 \ \x0 0 \ \x 8 4 \ \x0 7 \ \x0 0 \ \x0 0 , \\x0 7 \ \x0 0 \ \x0 0 \ \ xd4 \ \x0 6 \ \x0 0 \ \x0 0 \ \x 8 8 \ \x0 6 \ \x0 0 \ \x0 0 \ \x 1 8 \ \x0 6 \ \x0 0 \ \x0 0 \ \ xc0 \ \x0 5 \ \x0 0 \ \x0 0 t \ \x0 5 \ \x0 0 \ \x0 0 ( \\x0 5 \ \x0 0 \ \x0 0 \ \\\\\x0 4 \ \x0 0 \ \x0 0 \ \ xe8 \ \x0 3 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 3 \ \x0 0 \ \x0 0 \ \x 9 c \ \x0 2 \ \x0 0 \ \x0 0 \ \ xc8 \ \x0 1 \ \x0 0 \ \x0 0 p \ \x0 1 \ \x0 0 \ \x0 0 \ \ xf0 \ \x0 0 \ \x0 0 \ \x0 0 ` \\x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xf2 \ \ xf6 \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 5 \ \x0 0 \ \x0 0 \ \x0 0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff \ \x 0 b \ \x0 0 \ \x0 0 \ \x0 0 \ \ xd4 \ \ xf6 \ \ xff \ \ xff \ \x 1 9 \ \x0 0 \ \x0 0 \ \x0 0 statefulpartitionedcall : <number> \\x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 0 \ \x0 0 j \ \ xf7 \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 h \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff \ \x 8 0 \ \x0 0 \ \x0 0 \ \x0 0 , \ \ xf7 \ \ xff \ \ xffl \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / dense / matmul ; sequential_1 / dense / relu ; sequential_1 / dense / biasadd \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xd6 \ \ xf7 \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 3 \ \x0 0 \ \x0 0 \ \x0 0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff \ \x0 0 y \ \x0 0 \ \x0 0 \ \ xb8 \ \ xf7 \ \ xff \ \ xff \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / flatten / reshape \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 y \ \x0 0 \ \x0 0 2 \ \ xf8 \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \x 1 2 \ \x0 0 \ \x0 0 \ \x0 0 h \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x0 0 \ \x 1 c \ \ xf8 \ \ xff \ \ xff $\\ x00 \ \x0 0 \ \x0 0 sequential_1 / max_pooling2d_2 / maxpool \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x0 0 \ \ xa6 \ \ xf8 \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \x 1 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xa4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff - \\x0 0 \ \x0 0 \ \x0 0 - \\x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x0 0 \ \x 9 0 \ \ xf8 \ \ xff \ \ xff \ \x 8 2 \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d_2 / relu ; sequential_1 / conv2d_2 / biasadd ; sequential_1 / conv2d_2 / conv2d ; sequential_1 / conv2d_2 / biasadd / readvariableop \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 - \\x0 0 \ \x0 0 \ \x0 0 - \\x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x0 0 v \ \ xf9 \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 h \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff - \\x0 0 \ \x0 0 \ \x0 0 - \\x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 ` \ \ xf9 \ \ xff \ \ xff $\\ x00 \ \x0 0 \ \x0 0 sequential_1 / max_pooling2d_1 / maxpool \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 - \\x0 0 \ \x0 0 \ \x0 0 - \\x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 \ \ xea \ \ xf9 \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \x 0 f \ \x0 0 \ \x0 0 \ \x0 0 \ \ xa4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xffz \ \x0 0 \ \x0 0 \ \x0 0 z \ \x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 \ \ xd4 \ \ xf9 \ \ xff \ \ xff \ \x 8 2 \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d_1 / relu ; sequential_1 / conv2d_1 / biasadd ; sequential_1 / conv2d_1 / conv2d ; sequential_1 / conv2d_1 / biasadd / readvariableop \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 z \ \x0 0 \ \x0 0 \ \x0 0 z \ \x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 \ \ xba \ \ xfa \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \x 0 e \ \x0 0 \ \x0 0 \ \x0 0 d \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xffz \ \x0 0 \ \x0 0 \ \x0 0 z \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xa4 \ \ xfa \ \ xff \ \ xff "" \\x0 0 \ \x0 0 \ \x0 0 sequential_1 / max_pooling2d / maxpool \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 z \ \x0 0 \ \x0 0 \ \x0 0 z \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 *\\ xfb \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \ r \ \x0 0 \ \x0 0 \ \x0 0 \ \x 9 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \ xfb \ \ xff \ \ xff { \\x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d / relu ; sequential_1 / conv2d / biasadd ; sequential_1 / conv2d / conv2d ; sequential_1 / conv2d / biasadd / readvariableop1 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xba \ \ xfc \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 0 \ \x0 0 ( \\x0 0 \ \x0 0 \ \x0 0 \ \ xc4 \ \ xfb \ \ xff \ \ xff \ \x 1 b \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / dense_1 / matmul \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \ xfd \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 0 \ \x0 0 ( \\x0 0 \ \x0 0 \ \x0 0 \ \x 0 c \ \ xfc \ \ xff \ \ xff \ \x 1 9 \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / dense / matmul \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 y \ \x0 0 \ \x0 0 j \ \ xfd \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ n \ \x0 0 \ \x0 0 \ \x0 0 8 \ \x0 0 \ \x0 0 \ \x0 0 t \ \ xfc \ \ xff \ \ xff ) \\x0 0 \ \x0 0 \ \x0 0 sequential_1 / dense / biasadd / readvariableop \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 9 e \ \ xfd \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ t \ \x0 0 \ \x0 0 \ \x0 0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xa8 \ \ xfc \ \ xff \ \ xff + \\x0 0 \ \x0 0 \ \x0 0 sequential_1 / dense_1 / biasadd / readvariableop \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x 1 c \ \x0 0 \ \x 1 8 \ \x0 0 \ \x 1 7 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 7 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 ( \\x0 0 \ \x0 0 \ \x0 0 \ \x 1 8 \ \ xfd \ \ xff \ \ xff \ \x 1 a \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / flatten / const \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 r \ \ xfe \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 7 \ \x0 0 \ \x0 0 \ \x0 0 , \\x0 0 \ \x0 0 \ \x0 0 \ \ \ \ \ \ xfd \ \ xff \ \ xff \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d_2 / conv2d \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 \ \ xa6 \ \ xfe \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 6 \ \x0 0 \ \x0 0 \ \x0 0 , \\x0 0 \ \x0 0 \ \x0 0 \ \ xb0 \ \ xfd \ \ xff \ \ xff \ \x 1 c \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d_1 / conv2d \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xfa \ \ xfe \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 5 \ \x0 0 \ \x0 0 \ \x0 0 < \\x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \ xfe \ \ xff \ \ xff , \\x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d_2 / biasadd / readvariableop \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x0 0 r \ \ xff \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 < \\x0 0 \ \x0 0 \ \x0 0 \ \ \ \ \ \ xfe \ \ xff \ \ xff , \\x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d_1 / biasadd / readvariableop \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \\x0 0 \ \x0 0 \ \x0 0 \ \ xaa \ \ xff \ \ xff \ \ xff \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \ xfe \ \ xff \ \ xff *\\ x00 \ \x0 0 \ \x0 0 sequential_1 / conv2d / biasadd / readvariableop \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x 1 8 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 7 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 2 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 8 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xffz \ \x0 0 \ \x0 0 \ \x0 0 sequential_1 / conv2d / relu ; sequential_1 / conv2d / biasadd ; sequential_1 / conv2d / conv2d ; sequential_1 / conv2d / biasadd / readvariableop \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x 1 c \ \x0 0 \ \x 1 8 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x 1 0 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 8 \ \x0 0 \ \x0 7 \ \x0 0 \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 ( \\x0 0 \ \x0 0 \ \x0 0 ( \\x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 h \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xff \ \ xff \ \ xff \ \ xff \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 "" \\x0 0 \ \x0 0 \ \x0 0 serving_default_sequential_input : <number> \\x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xb4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 @ \\x0 0 \ \x0 0 \ \x <money> \\x0 0 \ \x0 0 \ \x0 0 \ \x 1 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x0 0 \ \x0 0 \ \ xdc \ \ xff \ \ xff \ \ xff \ \ t \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \ t \ \ xe8 \ \ xff \ \ xff \ \ xff \ \x 1 6 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 6 \ \ xf4 \ \ xff \ \ xff \ \ xff \ \x 1 1 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x 1 1 \ \x 0 c \ \x0 0 \ \x 0 c \ \x0 0 \ \x 0 b \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 4 \ \x0 0 \ \x 0 c \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 0 \ \x0 3 ' ' , does not exist . ` ` `",0
tensorflow/tensorflow,"tf . data . dataset . list_files ( <sad> you must feed a value for placeholder tensor # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> - rc1 - <number> - g0db597d0d75 <number> . <number> # # # custom code no # # # os platform and distribution ubuntu <number> . <number> lts # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? reading a dataset obtained with ` tf . data . dataset . list_files ( ) ` prints incomprehensible warnings . create two files : ` ` ` bash touch a . txt touch b . txt ` ` ` run this python program : ` ` ` python import tensorflow as tf dataset = tf . data . dataset . list_files ( [ ' a . txt ' , ' b . txt ' ] ) for f in dataset : print ( f ) ` ` ` prints some incomprehensible warnings : ` ` ` tf . tensor ( b ' b . txt ' , shape =() , dtype = string ) tf . tensor ( b ' a . txt ' , shape =() , dtype = string ) <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / executor . cc : <number> ] [ / device : cpu : <number> ] ( debug info ) executor start aborting ( this does not indicate an error and you can ignore this message ) : invalid_argument : you must feed a value for placeholder tensor ' placeholder / _0 ' with dtype string and shape [ <number> ] [ [ { { node placeholder / _0 } } ] ] <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / executor . cc : <number> ] [ / device : cpu : <number> ] ( debug info ) executor start aborting ( this does not indicate an error and you can ignore this message ) : invalid_argument : you must feed a value for placeholder tensor ' placeholder / _0 ' with dtype string and shape [ <number> ] [ [ { { node placeholder / _0 } } ] ] ` ` ` this is a ~ duplicate of <url> that was marked as resolved <number> years ago . # # # standalone code to reproduce the issue ` ` ` shell with tensorflow = = <number> . <number> : <url> no warning with tensorflow = = <number> . <number> <url> ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / executor . cc : <number> ] [ / device : cpu : <number> ] ( debug info ) executor start aborting ( this does not indicate an error and you can ignore this message ) : invalid_argument must feed a value for placeholder tensor ' placeholder / _0 ' with dtype string and shape [ <number> ] [ [ { { node placeholder / _0 } } ] ] ` ` `",0
tensorflow/tensorflow,"cannot create interpreter when using gpu - delegate or nnapi - delegate * * system information * * - android device information : samsung / a14mnseea / a14m : <number> / tp1a . <number> / a145rxxu2awg3 : user / release - keys - tensorflow lite in play services sdk version ( found in ` build . gradle ` <sad> - com . google . android . gms : play - services - tflite - java : <number> . <number> - com . google . android . gms : play - services - tflite - support : <number> . <number> - com . google . android . gms : play - services - tflite - gpu : <number> . <number> - google play services version : <date> * * standalone code to reproduce the issue * * var usegpu = tasks . await ( tflitegpu . isgpudelegateavailable ( context ) ); var optionsbuilder = tfliteinitializationoptions . builder ( ); optionsbuilder . setenablegpudelegatesupport ( usegpu ) ; tasks . await ( tflite . initialize ( context , optionsbuilder . build ( ))); var options = new interpreterapi . options ( ); if ( usegpu ) { options . addelegatefactory <elongated> ( new gpudelegatefactory ( )); } / * delegate = new nnapidelegate ( ); options . addelegate <elongated> ( delegate ) ; options . setusennapi ( true ) ;* / options . setruntime ( interpreterapi . options . tfliteruntime . from_system_only ) ; / / load model from app assets interpreter = interpreterapi . create ( new file ( modelpath ) , options ) ; * * any other info / logs * * i oriented my code on the official documentation [ on here ] ( <url> logcat - output : java . lang . illegalargumentexception : internal error : cannot create interpreter com . google . android . gms . tflite . nativeinterpreterwrapper . createinterpreter ( native method ) at com . google . android . gms . tflite . nativeinterpreterwrapper . zzl ( com . google . android . gms : play - services - tflite - java @ <user> . <number> . <time> ) at com . google . android . gms . tflite . nativeinterpreterwrapper . <init> ( com . google . android . gms : play - services - tflite - java @ <user> . <number> : <number> ) at com . google . android . gms . tflite . zzd . <init> ( com . google . android . gms : play - services - tflite - java @ <user> . <number> : <number> ) at com . google . android . gms . tflite . interpreterfactoryimpl . create ( com . google . android . gms : play - services - tflite - java @ <user> . <number> : <number> ) at org . tensorflow . lite . interpreterapi . create ( interpreterapi . java : <number> ) at com . example . tfliteaudio . tfliteengine . initialize ( tfliteengine . java : <number> ) at com . example . tfliteaudio . mainactivity . lambda $ transcribeaudio <money> ( mainactivity . java : <number> ) at com . example . tfliteaudio . mainactivity . $ r <money> lambda <money> xqj9havpxtc26gxgwfy8qcv0ve ( unknown source : <number> ) at com . example . tfliteaudio . mainactivity $ $ externalsyntheticlambda2 . run ( unknown source : <number> ) at java . lang . thread . run ( thread . java : <number> )",0
tensorflow/tensorflow,"the model does not save and load correctly when containing ` tf . keras . layers . experimental . preprocessing . stringlookup ` layer # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> - rc1 # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? the model does not save and load correctly when containing ` tf . keras . layers . experimental . preprocessing . stringlookup ` layer . it seems that the ` vocabulary ` is not saved or loaded correctly , which is empty when loading the model . this behavior may relate to # <number> , but different api endpoint . # # # standalone code to reproduce the issue ` ` ` python import pickle import tensorflow as tf print ( tf . version . git_version , tf . version . version , flush = true ) model_input = tf . keras . input ( shape =( <number> , ) , dtype = tf . int64 ) lookup = tf . keras . layers . experimental . preprocessing . stringlookup ( vocabulary =[ ' a ' , ' b ' ] ) ( model_input ) output = tf . keras . layers . dense ( <number> ) ( lookup ) full_model = tf . keras . model ( model_input , output ) # this part works try : model_bytes = pickle . dumps ( full_model ) model_recovered = pickle . loads ( model_bytes ) except exception as e : print ( "" failed error :"", e , flush = true ) else : print ( "" success ! "" , flush = true ) # this part throws an error try : full_model . save ( "" / tmp / temp_model "" ) full_model_loaded = tf . keras . models . load_model ( "" / tmp / temp_model "" ) model_bytes = pickle . dumps ( full_model_loaded ) model_recovered = pickle . loads ( model_bytes ) except exception as e : print ( "" failed ! error :"", e , flush = true ) else : print ( "" success ! "" , flush = true ) ` ` ` # # # relevant log output ` ` ` text v2 . <number> - rc0 - <number> - gdd01672d9a9 <number> . <number> - rc1 success ! warning : tensorflow : compiled the loaded model , but the compiled metrics have yet to be built . ` model . compile_metrics ` will be empty until you train or evaluate the model . warning : tensorflow : no training configuration found in save file , so the model was not <emphasis> compiled . compile it manually . warning : tensorflow : no training configuration found in save file , so the model was not <emphasis> compiled . compile it manually . failed ! error : error when deserializing class ' stringlookup ' using config ={ ' name ' : ' string_lookup ' , ' trainable ' : true , ' dtype ' : ' int64 ' , ' invert ' : false , ' max_tokens ' : none , ' num_oov_indices ' : <number> , ' oov_token ' : ' [ unk ] ' , ' mask_token ' : none , ' output_mode ' : ' int ' , ' sparse ' : false , ' pad_to_max_tokens ' : false , ' idf_weights ' : none , ' vocabulary ' : [ ] , ' vocabulary_size ' : <number> , ' encoding ' : ' utf - <number> ' } . exception encountered set an empty vocabulary , you passed [ ] . ` ` `",0
tensorflow/tensorflow,"rnn with initial_state model can not be loaded with load_model # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? a simple rnn with lstmcell model . i want to initialize the states with ` initial_state_h ` and ` initial_state_c ` . ` ` ` batch_size = <number> inputs = tf . keras . layers . input ( shape =( <number> ) , batch_size = batch_size ) units = <number> lstm_cell_fw = tf . keras . layers . lstmcell ( units ) initial_state_h = tf . random . normal ( shape = ( batch_size , units ) , mean = <number> . , stddev = <number> . , dtype = tf . dtypes . float32 ) initial_state_c = tf . random . normal ( shape = ( batch_size , units ) , mean = <number> . , stddev = <number> . , dtype = tf . dtypes . float32 ) lstm_layer_fw = tf . keras . layers . rnn ( lstm_cell_fw , stateful = true , return_state = true , return_sequences = false ) outputs , states_h_fw , states_c_fw = lstm_layer_fw ( inputs , initial_state = [ initial_state_h , initial_state_c ] ) lstm_dense1 = tf . keras . layers . dense ( <number> , activation = ' relu ' ) lstm_dense2 = tf . keras . layers . dense ( <number> , activation = ' softmax ' ) out = lstm_dense2 ( lstm_dense1 ( outputs ) ) model = tf . keras . models . model ( inputs , out ) ` ` ` after compile and train , the model is saved with ` model . save ( ' my_model_test . keras ' ) ` . ` ` ` model . compile ( optimizer = ' adam ' , loss = ' categorical_crossentropy ' , metrics =[ ' accuracy ' ] ) model . summary ( ) xtrain = np . random . rand ( <number> , <number> ) ytrain = np . random . rand ( <number> ) for i in range ( <number> <sad> model . fit ( xtrain , ytrain , batch_size = batch_size ) model . save ( ' my_model_test . keras ' ) ` ` ` but when i try to load it with ` load_model = tf . keras . models . load_model ( ' my_model_test . keras ' ) ` , it gives error : ` ` ` <number> frames [ / usr / local / lib / python3 . <number> / dist - packages / keras / src / backend . py ] ( https :// localhost : <number> /# ) in int_shape ( x ) <number> "" "" "" <number> try : - > <number> shape = x . shape <number> if not isinstance ( shape , tuple ) : <number> shape = tuple ( shape . as_list ( ) ) attributeerror : ' float ' object has no attribute ' shape ' ` ` ` i tried to save in other format , ` . h5 ` , ` . json ` , etc . all give the same error . but , if i do not use ` initial_state ` in ` outputs , states_h_fw , states_c_fw = lstm_layer_fw ( inputs ) ` , everything goes well . no problem with ` load_model ` . # # # standalone code to reproduce the issue ` ` ` shell <url> ` ` ` # # # relevant log output ` ` ` shell - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - attributeerror traceback ( most recent call last ) < ipython - input - <number> - 8 e0130abf25e > in < cell line : <number> > ( ) - - - - > <number> load_model = tf . keras . models . load_model ( ' my_model_test . keras ' ) <number> frames / usr / local / lib / python3 . <number> / dist - packages / keras / src / backend . py in int_shape ( x ) <number> "" "" "" <number> try : - > <number> shape = x . shape <number> if not isinstance ( shape , tuple ) : <number> shape = tuple ( shape . as_list ( ) ) attributeerror object has no attribute ' shape ' ` ` ` ` ` `",0
tensorflow/tensorflow,"issues with running custom tensorflow lite model in c + + # # # <number> . system information - platform and linux distribution kubuntu <number> : - tensorflow is built from c + + source code : - tensorflow <number> : # # # <number> . code - link to models that i trained and tried but they do not work in c + + - <url> - link to the model that works in c + + - <url> - link to c + + code ( mainwindow . cpp file ) : <url> # # # <number> . crash after conversion - the model does not work in c + + . please tell me how you can run the tensorflow lite model ( tflite format ) for object detection or image classification in c + + . my steps : - trained the model for object detection using tensorflow <number> api object detection . - after training , i converted the model to the savedmodel format , and then to tflite . - next , i needed to embed this model into a c + + project . in order to use it in the future on low - power devices such as rasberry pi my actions : - compiled the tensorflow lite library for c + + . - found a test case using the mobilenet_quant_v1_224 . tflite model . in this test case , the model runs successfully . however , when trying to use my own model , it does not work , although it has been tested and works in python . what was found out the mobilenet_quant_v1_224 . tflite model was quantized and had no metadata and no internal labelmap . txt file . - tensorflow lite api <number> for c + + does not currently support metadata . if you have any information on how to get my tflite model to work in c + + please share .",0
tensorflow/tensorflow,"jit yields inconsistent results using tf . math . top_k # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> - dev20230824 # # # custom code yes # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda_11 . <number> . r11 . <number> / compiler . 3 1 8 3 3 9 0 5 _0 / cudnn version <number> # # # gpu model and memory nvidia geforce rtx <number> ti # # # current behavior ? jit yields inconsistent results using ` tf . math . top_k ` when ` index_type = tf . int32 ` ( no issue with ` index_type = tf . int64 ` ) . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf <user> . function ( jit_compile = true ) def tf_func ( shape ) : x = tf . random . stateless_normal ( shape , seed =( <number> , <number> ) ) x = tf . transpose ( x , perm =[ <number> , <number> ] ) topk_max , indices = tf . math . top_k ( x , <number> , sorted = false , index_type = tf . int32 ) reduce_max = tf . reduce_max ( x , axis = <number> , keepdims = true ) return topk_max - reduce_max def check ( shape ) : should_be_all_zero = tf_func ( shape ) print ( f "" should_be_all_zero shape { shape }:\\ n { should_be_all_zero } "" ) check ( ( <number> , <number> ) ) check ( ( <number> , <number> ) ) check ( ( <number> , <number> ) ) ` ` ` # # # relevant log output ` ` ` shell should_be_all_zero shape ( <number> , <number> <sad> [ [ - <number> ] [ <number> ] [ <number> ] ] should_be_all_zero shape ( <number> , <number> <sad> [ [ <number> . ] [ <number> . ] [ <number> . ] ] should_be_all_zero shape ( <number> , <number> ) [ <number> . ] ] ` ` `",0
tensorflow/tensorflow,"please help # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version <number> # # # gpu model and memory rtx <number> 1 2 g # # # current behavior ? i am running the octopus repo ( <url> which use tensorflow - gpu version <number> . <number> . when i run that model with python , i got some errors from tensorflow . please help me . # # # standalone code to reproduce the issue ` ` ` shell import os import argparse import tensorflow as tf import keras . backend as k from glob import glob from lib . io import openpose_from_file , read_segmentation , write_mesh from model . octopus import octopus def main ( weights , name , segm_dir , pose_dir , out_dir , opt_pose_steps , opt_shape_steps ) : segm_files = sorted ( glob ( os . path . join ( segm_dir , ' * . png ' ) ) ) pose_files = sorted ( glob ( os . path . join ( pose_dir , ' * . json ' ) ) ) if len ( segm_files ) ! = len ( pose_files ) or len ( segm_files ) = = len ( pose_files ) = = <number> : exit ( ' inconsistent input . ' ) k . set_session ( tf . session ( config = tf . configproto ( gpu_options = tf . gpuoptions ( allow_growth = true ) ) ) ) model = octopus ( num = len ( segm_files ) ) model . load ( weights ) segmentations = [ read_segmentation ( f ) for f in segm_files ] joints_2d , face_2d = [ ] , [ ] for f in pose_files : j , f = openpose_from_file ( f ) assert ( len ( j ) = = <number> ) assert ( len ( f ) = = <number> ) joints_2d . append ( j ) face_2d . append ( f ) if opt_pose_steps : print ( ' optimizing for pose . <repeated> ' ) model . opt_pose ( segmentations , joints_2d , opt_steps = opt_pose_steps ) if opt_shape_steps : print ( ' optimizing for shape . <repeated> ' ) model . opt_shape ( segmentations , joints_2d , face_2d , opt_steps = opt_shape_steps ) print ( ' estimating shape . <repeated> ' ) pred = model . predict ( segmentations , joints_2d ) write_mesh ( ' { } / { } . obj ' . format ( out_dir , name ) , pred [ ' vertices ' ] [ <number> ] , pred [ ' faces ' ] ) print ( ' done . ' ) if __name__ = = ' __main__ ' : parser = argparse . argumentparser ( ) parser . add_argument ( ' name ' , type = str , help = "" sample name "" ) parser . add_argument ( ' segm_dir ' , type = str , help = "" segmentation images directory "" ) parser . add_argument ( ' pose_dir ' , type = str , help = "" 2 d pose keypoints directory "" ) parser . add_argument ( ' - - opt_steps_pose ' , ' - p ' , default = <number> , type = int , help = "" optimization steps pose "" ) parser . add_argument ( ' - - opt_steps_shape ' , ' - s ' , default = <number> , type = int , help = "" optimization steps "" ) parser . add_argument ( ' - - out_dir ' , ' - od ' , default = ' out ' , help = ' output directory ' ) parser . add_argument ( ' - - weights ' , ' - w ' , default = ' weights / octopus_weights . hdf5 ' , help = ' model weights file (* . hdf5 ) ' ) args = parser . parse_args ( ) main ( args . weights , args . name , args . segm_dir , args . pose_dir , args . out_dir , args . opt_steps_pose , args . opt_steps_shape ) ` ` ` # # # relevant log output ` ` ` shell processing sample . <repeated> > optimizing for pose . <repeated> <percent> | | <number> / <number> [ <time> < ? , ? it / s ] <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / dso_loader . cc : <number> ] successfully opened cuda library libcublas . so . <number> locally <number> - <number> - <number> <time> . <number> : i tensorflow / core / kernels / cuda_solvers . cc : <number> ] creating cudasolver handles for stream 0x 5 5 fa094fdcf0 <number> - <number> - <number> <time> . <number> : e tensorflow / stream_executor / cuda / cuda_blas . cc : <number> ] failed to run cublas routine cublasgemmbatchedex : cublas_status_execution_failed <number> - <number> - <number> <time> . <number> : e tensorflow / stream_executor / cuda / cuda_blas . cc : <number> ] internal : failed blas call , see log for details <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / stream . cc : <number> ] [ stream =0 x55fa0950bb90 , impl =0 x55fa093dbf20 ] did not memcpy device - to - host ; source : 0x 8 1 3 bc6700 <number> - <number> - <number> <time> . <number> : f tensorflow / core / framework / op_kernel . cc : <number> ] check failed = = ctx - > op_kernel ( ) . asasync ( ) ( nullptr vs . 0x 5 5 fa38108400 ) use op_requires_async in asyncopkernel implementations . aborted ` ` `",0
tensorflow/tensorflow,python3 . <number> mismatch with tensorflow <number> . <number> # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution macos venture <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? [ image ] ( <url> # # # standalone code to reproduce the issue ` ` ` shell import tensorflow ` ` ` # # # relevant log output _no response_,0
tensorflow/tensorflow,"unable to serialize variablespec # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? a graph # # # standalone code to reproduce the issue ` ` ` shell from models import * from conftest import ddpgagent import matplotlib as plt import pytest import time # just disables the warning , does not take advantage of avx / fma to run faster import os os . environ [ ' tf_cpp_min_log_level ' ] = ' <number> ' # setting for hidden layers layer1 = <number> layer2 = <number> class mecter ( object ) : "" "" "" mec terminal parent class "" "" "" def __init__ ( self , user_config , train_config ) : self . rate = user_config [ ' rate ' ] self . dis = user_config [ ' dis ' ] self . id = user_config [ ' id ' ] self . state_dim = user_config [ ' state_dim ' ] self . action_dim = user_config [ ' action_dim ' ] self . action_bound = user_config [ ' action_bound ' ] self . data_buf_size = user_config [ ' data_buf_size ' ] self . t_factor = user_config [ ' t_factor ' ] self . penalty = user_config [ ' penalty ' ] self . sigma2 = train_config [ ' sigma2 ' ] self . init_path = ' ' self . isupdateactor = true self . init_seqcnt = <number> if ' model ' not in user_config : self . channelmodel = markovmodel ( self . dis , seed = train_config [ ' random_seed ' ] ) else : n_t = <number> n_r = user_config [ ' num_r ' ] self . channelmodel = armodel ( self . dis , n_t , n_r , seed = train_config [ ' random_seed ' ] ) self . databuf = <number> self . channel = self . channelmodel . getch ( ) self . snr = <number> self . power = np . zeros ( self . action_dim ) self . reward = <number> self . state = [ ] # some pre - defined parameters self . k = 1 e - <number> self . t = <number> self . l = <number> def localproc ( self , p ) : return np . power ( p / self . k , <number> / <number> ) * self . t / self . l / <number> def localprocrev ( self , b ) : return np . power ( b * <number> * self . l / self . t , <number> ) * self . k def offloadrev ( self , b ) : return ( np . power ( <number> , b ) - <number> ) * self . sigma2 / np . power ( np . linalg . norm ( self . channel ) , <number> ) def offloadrev2 ( self , b ) : return self . action_bound if self . snr <= 1 e - <number> else ( np . power ( <number> , b ) - <number> ) / self . snr def getch ( self ) : return self . channel def setsnr ( self , snr ) : self . snr = snr self . samplech ( ) channel_gain = np . power ( np . linalg . norm ( self . channel ) , <number> ) / self . sigma2 self . state = np . array ( [ self . databuf , snr , channel_gain ] ) def sampledata ( self ) : data_t = np . log2 ( <number> + self . power [ <number> ] * self . snr ) data_p = self . localproc ( self . power [ <number> ] ) over_power = <number> self . databuf - = data_t + data_p if self . databuf < <number> : over_power = self . power [ <number> ] - self . localprocrev ( np . fmax ( <number> , self . databuf + data_p ) ) self . databuf = <number> data_r = np . random . poisson ( self . rate ) self . databuf + = data_r return data_t , data_p , data_r , over_power def samplech ( self ) : # self . channel = self . channelmodel . samplech ( ) # calculate channel gain using channel quantization raw_channel_gain = np . linalg . norm ( self . channelmodel . samplech ( ) ) min_val = np . min ( self . channel ) max_val = np . max ( self . channel ) # quantize the channel gain into <number> levels quantized_channel_gain = min_val + ( max_val - min_val ) * ( raw_channel_gain - min_val ) / ( max_val - min_val ) quantized_channel_gain = np . clip ( quantized_channel_gain , min_val , max_val ) self . channel = quantized_channel_gain return self . channel def reset ( self , rate , seqcount ) : self . rate = rate self . databuf = np . random . randint ( <number> , self . data_buf_size - <number> ) / <number> self . samplech ( ) if seqcount >= self . init_seqcnt : self . isupdateactor = true return self . databuf class mectermrl ( mecter ) : "" "" "" mec terminal class using rl "" "" "" # rate : packet poisson arrival , dis : distance in meters def __init__ ( self , user_config , train_config ) : mecter . __init__ ( self , user_config , train_config ) self . agent = ddpgagent ( user_config , train_config ) if ' init_path ' in user_config and len ( user_config [ ' init_path ' ] ) > <number> : self . init_path = user_config [ ' init_path ' ] self . init_seqcnt = user_config [ ' init_seqcnt ' ] self . isupdateactor = false def feedback ( self , snr , done ) : isoverflow = <number> self . snr = snr # update the data buffer [ data_t , data_p , data_r , over_power ] = self . sampledata ( ) # get the reward for the current slot self . reward = - self . t_factor * np . sum ( self . power ) * <number> - ( <number> - self . t_factor ) * self . databuf # estimate the channel for next slot self . samplech ( ) # update the actor and critic network channel_gain = np . power ( np . linalg . norm ( self . channel ) , <number> ) / self . sigma2 next_state = np . array ( [ self . databuf , snr , channel_gain ] ) self . agent . update ( self . state , self . power , self . reward , done , next_state , self . isupdateactor ) # update system state self . state = next_state # return the reward in this slot sum_power = np . sum ( self . power ) - over_power return self . reward , sum_power , over_power , data_t , data_p , data_r , self . databuf , channel_gain , isoverflow def predict ( self , israndom ) : power , noise = self . agent . predict ( self . state , self . isupdateactor ) self . power = np . fmax ( <number> , np . fmin ( self . action_bound , power ) ) return self . power , noise class mecsvrenv ( object ) : "" "" "" simulation environment "" "" "" def __init__ ( self , user_list , num_att , sigma2 , max_len ) : self . user_list = user_list self . num_user = len ( user_list ) self . num_att = num_att self . sigma2 = sigma2 self . count = <number> self . seqcount = <number> self . max_len = max_len # specially designed for greedy agent training # self . data_set = [ ] def init_target_network ( self ) : for user in self . user_list : user . critic . init_target_network ( path = ' data_set_ogd . npz ' ) def plot_channel_gains_histogram ( self ) : # get the channel gains for all users channel_gains = [ np . abs ( user . getch ( ) ) for user in self . user_list ] # flatten the channel gains to a 1 d array flat_channel_gains = np . concatenate ( channel_gains ) # plot a histogram for the channel gains plt . hist ( np . abs ( flat_channel_gains ) , bins = <number> , edgecolor = ' black ' ) plt . title ( "" channel gains histogram "" ) plt . xlabel ( "" channel gain magnitude "" ) plt . ylabel ( "" frequency "" ) plt . show ( ) def step_transmit ( self , israndom = true ) : # get the channel vectors channels = np . transpose ( [ user . getch ( ) for user in self . user_list ] ) # get the transmit powers powers = [ ] noises = [ ] for i in range ( self . num_user ) : p , n = self . user_list [ i ] . predict ( israndom ) powers . append ( p . copy ( ) ) noises . append ( n . copy ( ) ) # compute the snr for each user powers = np . array ( powers ) noises = np . array ( noises ) snr_list = self . compute_snr ( channels , powers [ :, <number> ] ) rewards = np . zeros ( self . num_user ) powers = np . zeros ( self . num_user ) over_powers = np . zeros ( self . num_user ) data_ts = np . zeros ( self . num_user ) data_ps = np . zeros ( self . num_user ) data_rs = np . zeros ( self . num_user ) data_buf_sizes = np . zeros ( self . num_user ) next_channels = np . zeros ( self . num_user ) isoverflows = np . zeros ( self . num_user ) self . count + = <number> # feedback the snr to each user for i in range ( self . num_user ) : [ rewards [ i ] , powers [ i ] , over_powers [ i ] , data_ts [ i ] , data_ps [ i ] , data_rs [ i ] , data_buf_sizes [ i ] , next_channels [ i ] , isoverflows [ i ] ] = self . user_list [ i ] . feedback ( snr_list [ i ] , self . count >= self . max_len ) return rewards , self . count >= self . max_len , powers , over_powers , noises , data_ts , data_ps , data_rs , data_buf_sizes , next_channels , isoverflows def compute_snr ( self , channels , powers ) : # fdd - computing snr h_inv = np . linalg . pinv ( channels ) total_signal_power = np . power ( np . linalg . norm ( channels , axis = <number> ) , <number> ) noise = np . power ( np . linalg . norm ( h_inv , axis = <number> ) , <number> ) * self . sigma2 snr_list = total_signal_power / noise return snr_list def reset ( self , istrain = true ) : self . count = <number> if istrain : init_data_buf_size = [ user . reset ( user . rate , self . seqcount ) for user in self . user_list ] # get the channel vectors channels = np . transpose ( [ user . getch ( ) for user in self . user_list ] ) # get the transmit powers to start powers = [ np . random . uniform ( <number> , user . action_bound ) for user in self . user_list ] # compute the snr for each user snr_list = self . compute_snr ( channels , powers ) else : init_data_buf_size = [ <number> for user in self . user_list ] snr_list = [ <number> for user in self . user_list ] for i in range ( self . num_user ) : self . user_list [ i ] . setsnr ( snr_list [ i ] ) self . seqcount + = <number> return init_data_buf_size # create the environment # def env ( <sad> # envi = mecsvrenv ( user_list , num_r , sigma2 , max_episode_len ) # return envi # env = mecsvrenv ( user_list , num_r , sigma2 , max_episode_len ) # env . init_target_network ( ) train_config = { ' sigma2 ' : <number> , ' minibatch_size ' : <number> , ' actor_lr ' : <number> , ' tau ' : <number> , ' critic_lr ' : <number> , ' gamma ' : <number> , ' buffer_size ' : <number> , ' random_seed ' : int ( time . perf_counter ( ) * <number> % <number> ) , ' noise_sigma ' : <number> } # define user_list_info with user information user_list_info = [ { ' state_dim ' : <number> , ' action_dim ' : <number> , ' id ' : ' <number> ' , ' action_bound ' : <number> , ' model ' : ' ar ' , ' num_r ' : <number> , ' rate ' : <number> , ' dis ' : <number> , ' data_buf_size ' : <number> , ' t_factor ' : <number> , ' penalty ' : <number> , } ] # sess = tf . compat . v1 . session ( ) # create instances of the user class from the dictionary in user_list user_list = [ mectermrl ( user_config = user_info , train_config = train_config ) for user_info in user_list_info ] # initialize variables for user in user_list : user . agent . init_target_network ( ) # ( # path =""c <annoyed> users / user / pycharmprojects / mec_drl - masterr / mec_drl - master / mec_drl - master / data_set_ogd . npz "" # ) <user> . fixture def env ( <sad> # create and return the environment object # make sure to adjust this to properly create your environment instance return mecsvrenv ( user_list , num_r , sigma2 , max_episode_len ) ` ` ` # # # relevant log output ` ` ` shell warning : tensorflow : the following variables were used in a lambda layer ' s call ( tf . __operators__ . add_1 ) , but are not present in its tracked objects : < tf . variable ' dense_5 / bias : <number> ' shape =( <number> , ) dtype = float32 > . this is a strong indication that the lambda layer should be rewritten as a subclassed layer . traceback ( most recent call last ) : file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ saving \ \ legacy \ \ saved_model \ \ json_utils . py "" , line <number> , in get_json_type type_spec_name = type_spec_registry . get_name ( type ( obj ) ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ framework \ \ type_spec_registry . py "" , line <number> , in get_name raise valueerror ( "" typespec %s . %s has not been registered . "" % valueerror : typespec tensorflow . python . ops . resource_variable_ops . variablespec has not been registered . during handling of the above exception , another exception occurred : traceback ( most recent call last ) : file "" c :\\ users \ \ user \ \ pycharmprojects \ \ mec_drl - masterr \ \ mec_drl - master \ \ mec_drl - master \ \ test . py "" , line <number> , in <module> user_list = [ ^ file "" c :\\ users \ \ user \ \ pycharmprojects \ \ mec_drl - masterr \ \ mec_drl - master \ \ mec_drl - master \ \ test . py "" , line <number> , in <listcomp> mectermrl ( user_config = user_info , train_config = train_config ) file "" c :\\ users \ \ user \ \ pycharmprojects \ \ mec_drl - masterr \ \ mec_drl - master \ \ mec_drl - master \ \ test . py "" , line <number> , in __init__ self . agent = ddpgagent ( user_config , train_config ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ pycharmprojects \ \ mec_drl - masterr \ \ mec_drl - master \ \ mec_drl - master \ \ conftest . py "" , line <number> , in __init__ self . critic = criticnetwork ( self . state_dim , self . action_dim , float ( train_config [ ' critic_lr ' ] ) , ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" c :\\ users \ \ user \ \ pycharmprojects \ \ mec_drl - masterr \ \ mec_drl - master \ \ mec_drl - master \ \ ddpg . py "" , line <number> , in __init__ self . target_model = tf . keras . models . clone_model ( self . model ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ models \ \ cloning . py "" , line <number> , in clone_model return _clone_functional_model ( ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ models \ \ cloning . py "" , line <number> , in _clone_functional_model model_configs , created_layers = _clone_layers_and_model_config ( ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ models \ \ cloning . py "" , line <number> , in _clone_layers_and_model_config config = functional . get_network_config ( ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ engine \ \ functional . py "" , line <number> , in get_network_config node_data = node . serialize ( ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ engine \ \ node . py "" , line <number> , in serialize kwargs = tf . nest . map_structure ( _serialize_keras_tensor , kwargs ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ util \ \ nest . py "" , line <number> , in map_structure return nest_util . map_structure ( ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ util \ \ nest_util . py "" , line <number> , in map_structure return _tf_core_map_structure ( func , * structure , * * kwargs ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ util \ \ nest_util . py "" , line <number> , in _tf_core_map_structure [ func ( *x ) for x in entries ] , ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ util \ \ nest_util . py "" , line <number> , in <listcomp> [ func ( *x ) for x in entries ] , ^^^ ^^^ ^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ engine \ \ node . py "" , line <number> , in _serialize_keras_tensor return ( _composite_type , json_utils . encoder ( ) . encode ( t ) ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ saving \ \ legacy \ \ saved_model \ \ json_utils . py "" , line <number> , in encode return super ( ) . encode ( _encode_tuple ( obj ) ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ json \ \ encoder . py "" , line <number> , in encode chunks = self . iterencode ( o , _one_shot = true ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ json \ \ encoder . py "" , line <number> , in iterencode return _iterencode ( o , <number> ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ saving \ \ legacy \ \ saved_model \ \ json_utils . py "" , line <number> , in default return get_json_type ( obj ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ saving \ \ legacy \ \ saved_model \ \ json_utils . py "" , line <number> , in get_json_type "" spec "" : get_json_type ( spec ) , ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" c :\\ users \ \ user \ \ anaconda3 \ \ lib \ \ site - packages \ \ keras \ \ src \ \ saving \ \ legacy \ \ saved_model \ \ json_utils . py "" , line <number> , in get_json_type raise valueerror ( valueerror to serialize variablespec ( shape =( <number> , ) , dtype = tf . float32 , trainable = true , alias_id = none ) to json , because the typespec class < class ' tensorflow . python . ops . resource_variable_ops . variablespec ' > has not been registered . ` ` `",0
tensorflow/tensorflow,"activation function of a dense hidden layer not getting invoked . # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version v2 . <number> - rc2 - <number> - g1cb1a030a62 <number> . <number> # # # custom code yes # # # os platform and distribution macos <number> , macbook pro m2 max # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? issue : in the given auto - encoder setup , the encoder layers activation function ( relu ) is not getting invoked . <number> . we create a simple auto - encoder , with input size <number> , hidden size <number> , and output back to <number> . <number> . the activation function of the encoder layer is set a relu . <number> . the weights of the encoder layers are all made negative . idea is , if input is + ve , all the neutrons will have negative value and relu will o / p zero . <number> . give input as [ <number> , <number> , <number> ] . <number> . we expect the final decoder o / p layer , which has sigmoid activation , to o / p all [ <number> , <number> , <number> ] as the input to this layer from the encoder should have been [ <number> , <number> , <number> ] . <number> . but we find that is not the case , which clearly shows that ' relu ' activation of the hidden layer is not getting invoked . installation : pip install tensorflow - macos pip install tensorflow - metal # # # standalone code to reproduce the issue ` ` ` shell # <url> # the above colab will run fine , but the same code on mac with the said config has issue . # copying the code here for quick reference . import tensorflow as tf import tensorflow . keras import tensorflow as tf import platform import sys from tensorflow . keras . layers import input , dense , layer from tensorflow . keras . models import model # print versions : print ( f "" python { sys . version } "" ) print ( f "" python platform : { platform . platform ( ) } "" ) print ( f "" tensor flow version : { tf . __version__ } "" ) gpu = len ( tf . config . list_physical_devices ( ' gpu ' ) ) > <number> print ( "" gpu is "" , "" available "" if gpu else "" not available "" ) # setup input import numpy as np x_check = np . array ( [ [ <number> , <number> , <number> ] ] ) # setup autoencoder model input_layer = input ( shape =( x_check . shape [ <number> ] ) ) bottleneck = dense ( <number> , activation = ' relu ' , name = ' bottleneck ' ) ( input_layer ) output = dense ( x_check . shape [ <number> ] , activation = ' sigmoid ' , name = ' output ' ) ( bottleneck ) autoencoder = model ( input_layer , output ) # set encoder layer weights to all negative . layer = autoencoder . layers [ <number> ] weights = np . array ( [ [ - <number> , - <number> ] , [ - <number> , - <number> ] , [ - <number> , - <number> ] ] ) biases = np . array ( [ <number> , <number> ] ) layer . set_weights ( [ weights , biases ] ) # create encoder model . encoder = model ( input_layer , bottleneck ) # create decoder model . decoder_input = input ( shape =( <number> , ) , name = ' decoder_input ' ) decoder_layer = autoencoder . layers [ - <number> ] decoder = model ( decoder_input , decoder_layer ( decoder_input ) ) # run auto - encoder , with [ <number> , <number> , <number> ] , since encoder has all negative weights , # and has ' relu ' activation o / p of enocder should all be zeros . and that being # the input of next sigmod we should get output [ <number> , <number> , <number> ] output_data = autoencoder . predict ( x_check ) print ( output_data ) ` ` ` # # # relevant log output ` ` ` shell python <date> ( default , <date> , <time> ) [ clang <number> . <number> ] python platform : macos - <number> - arm64 - arm - 6 4 bit tensor flow version gpu is available <number> / <number> [== = = = = = = = = = = = = = = = = = = = = = = = = = = ==] - 0 s 3 8 ms / step [ [ <number> <number> <number> ] ] ` ` `",0
tensorflow/tensorflow,"check failure when running tf . config . experimental_connect_to_host # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory gtx <number> ti # # # current behavior ? due to feeding nan input argument # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import numpy as np try : try : with tf . device ( ' / cpu ' <sad> arg_0 = "" nan "" out = tf . config . experimental_connect_to_host ( arg_0 , ) except exception as e : print ( "" error : "" + str ( e ) ) try : with tf . device ( ' / gpu : <number> ' <sad> tf . config . experimental_connect_to_host ( arg_0 , ) except exception as e : print ( "" error : "" + str ( e ) ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized to use available cpu instructions in performance - critical operations . to enable the following instructions : avx2 fma , in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : could not find tensorrt <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : e tensorflow / core / distributed_runtime / rpc / grpc_server_lib . cc : <number> ] invalid_argument : could not interpret "" nan "" as a host - port pair . e0819 <time> . <number> <number> completion_queue . cc : <number> ] assertion failed = = <number> aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow when running tf . compat . v1 . manip . tile # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large element in the input list # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : input_tensor = tf . random . uniform ( [ <number> , <number> , <number> ] , dtype = tf . float32 ) input = tf . identity ( input_tensor ) multiples_0 = <number> multiples_1 = true multiples_2 = <number> multiples = [ multiples_0 , multiples_1 , multiples_2 , ] name = none out = tf . compat . v1 . manip . tile ( input = input , multiples = multiples , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__tile_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <number> with <number> , result [ [ { { node tile } } ] ] [ op : tile ] ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . compat . v1 . image . resize # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large elements in input list # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : images_tensor = tf . constant ( - <number> , shape =[ <number> , <number> , <number> , <number> ] , dtype = tf . int64 , ) images = tf . identity ( images_tensor ) size_0 = <number> size_1 = <number> size = [ size_0 , size_1 , ] method = "" nearest "" align_corners = false preserve_aspect_ratio = false name = none out = tf . compat . v1 . image . resize ( images = images , size = size , method = method , align_corners = align_corners , preserve_aspect_ratio = preserve_aspect_ratio , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__resizenearestneighbor_device_ / job : localhost / replica : <number> / task : <number> / device : cpu : <number> } } encountered overflow when multiplying <number> with <number> , result : - <number> [ op : resizenearestneighbor ] name ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . compat . v1 . manip . tile # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large elements in the input tensor # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : input_tensor = tf . random . uniform ( [ <number> , <number> , <number> ] , dtype = tf . float32 ) input = tf . identity ( input_tensor ) multiples_0 = <number> multiples_1 = true multiples_2 = <number> multiples = [ multiples_0 , multiples_1 , multiples_2 , ] name = none out = tf . compat . v1 . manip . tile ( input = input , multiples = multiples , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__tile_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <number> with <number> , result [ [ { { node tile } } ] ] [ op : tile ] ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . compat . v1 . keras . layers . zeropadding2d # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large elements in the input list # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : padding_0_0 = <number> padding_0_1 = <number> padding_0 = [ padding_0_0 , padding_0_1 , ] padding_1_0 = <number> padding_1_1 = <number> padding_1 = [ padding_1_0 , padding_1_1 , ] padding = [ padding_0 , padding_1 , ] data_format = none arg_class = tf . compat . v1 . keras . layers . zeropadding2d ( padding = padding , data_format = data_format , ) arg_input_0_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) arg_input_0 = tf . identity ( arg_input_0_tensor ) arg_input = [ arg_input_0 , ] out = arg_class ( * arg_input ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell { { function_node __wrapped__pad_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <number> with <number> , result : - <number> [ [ { { node pad } } ] ] [ op : pad ] call arguments received by layer ' zero_padding2d ' ( type zeropadding2d ) inputs = tf . tensor ( shape =( <number> , <number> , <number> , <number> ) , dtype = float32 ) ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . raw_ops . tile # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large elements in input list # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : input_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) input = tf . identity ( input_tensor ) multiples_0 = <number> multiples_1 = true multiples_2 = <number> multiples_3 = <number> multiples = [ multiples_0 , multiples_1 , multiples_2 , multiples_3 , ] name = none out = tf . raw_ops . tile ( input = input , multiples = multiples , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__tile_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <number> with <number> , result [ [ { { node tile } } ] ] [ op : tile ] ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . keras . layers . zeropadding3d # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large integer value # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : padding = <phone> arg_class = tf . keras . layers . zeropadding3d ( padding = padding , ) arg_input_0_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) arg_input_0 = tf . identity ( arg_input_0_tensor ) arg_input = [ arg_input_0 , ] out = arg_class ( * arg_input ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error : exception encountered when calling layer ' zero_padding3d ' ( type zeropadding3d ) . { { function_node __wrapped__pad_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <phone> with <phone> , result : - <number> [ op : pad ] call arguments received by layer ' zero_padding3d ' ( type zeropadding3d ) inputs = tf . tensor ( shape =( <number> , <number> , <number> , <number> , <number> ) , dtype = float32 ) ` ` ` ` ` `",0
tensorflow/tensorflow,"colab session crashes for unknown reasons when when running tf . raw_ops . resizebilinear on colab # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large list element # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : images_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> ] , minval = - <number> , maxval = <number> , dtype = tf . int32 ) images = tf . identity ( images_tensor ) size_0 = <number> size_1 = true size = [ size_0 , size_1 , ] align_corners = false half_pixel_centers = false name = none out = tf . raw_ops . resizebilinear ( images = images , size = size , align_corners = align_corners , half_pixel_centers = half_pixel_centers , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] searching [ ' / root / . jupyter ' , ' / root / . local / etc / jupyter ' , ' / usr / etc / jupyter ' , ' / usr / local / etc / jupyter ' , ' / etc / jupyter ' ] for config files "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 5 9 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 5 9 8 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / usr / local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / usr / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / root / . local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / root / . jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 5 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] loaded config file : / etc / jupyter / jupyter_notebook_config . py "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 8 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / usr / local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 8 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] searching [ ' / root / . jupyter ' , ' / root / . local / etc / jupyter ' , ' / usr / etc / jupyter ' , ' / usr / local / etc / jupyter ' , ' / etc / jupyter ' ] for config files "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 5 9 8 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] loaded config file : / usr / local / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / usr / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / root / . local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / root / . jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] loaded config file : / root / . jupyter / jupyter_notebook_config . py "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 5 9 9 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / usr / local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / usr / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / root / . local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_config in / root / . jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] loaded config file : / etc / jupyter / jupyter_notebook_config . py "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / usr / local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] loaded config file : / usr / local / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / usr / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / root / . local / etc / jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] looking for jupyter_notebook_config in / root / . jupyter "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" :""[ d <time> . <number> notebookapp ] loaded config file : / root / . jupyter / jupyter_notebook_config . py "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 1 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 5 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / usr / local / etc / jupyter / jupyter_notebook_config . d / panel - client - jupyter . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 5 6 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / usr / local / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 5 6 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / usr / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 5 9 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / root / . local / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 6 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / root / . jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 6 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" writing notebook server cookie secret to / root / . local / share / jupyter / runtime / notebook_cookie_secret "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 7 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" authentication of / metrics is off , since other authentication is disabled . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 7 6 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" google . colab serverextension initialized . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 5 9 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 7 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / usr / local / etc / jupyter / jupyter_notebook_config . d / panel - client - jupyter . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 7 5 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / usr / local / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 7 7 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / usr / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 7 9 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / root / . local / etc / jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 8 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" \ \ t / root / . jupyter / jupyter_notebook_config . json "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 8 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" writing notebook server cookie secret to / root / . local / share / jupyter / runtime / notebook_cookie_secret "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 9 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" authentication of / metrics is off , since other authentication is disabled . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 1 9 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" google . colab serverextension initialized . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 1 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" serving notebooks from local directory : / "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 3 1 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" serving notebooks from local directory : / "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 3 1 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" jupyter notebook <number> . <number> is running at :"", "" time "" : "" <number> - <number> - 1 7 t <time> . 3 1 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <url> { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" use control - c to stop this server and shut down all kernels ( twice to skip confirmation ) . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 3 1 5 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" jupyter notebook <number> . <number> is running at :"", "" time "" : "" <number> - <number> - 1 7 t <time> . 3 1 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <url> { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" use control - c to stop this server and shut down all kernels ( twice to skip confirmation ) . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 3 1 6 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" kernel started : 9 2 d4365c - be07 - <number> - a024 - 4 0 9 4 c7317470 , name : python3 "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 5 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" got events for closed stream < zmq . eventloop . zmqstream . zmqstream object at 0x 7 9 d03bf475b0 > "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 8 7 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized to use available cpu instructions in performance - critical operations . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 9 2 8 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" to enable the following instructions : avx2 fma , in other operations , rebuild tensorflow with the appropriate compiler flags . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 9 2 8 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : could not find tensorrt "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 0 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at tile_ops . cc : <number> : invalid_argument : encountered overflow when multiplying <number> with <number> , result : - <number> "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 7 6 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" task exception was never retrieved "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" future : < task finished name = ' task - <number> ' coro =< websocketprotocol13 . write_message . <locals> . wrapper ( ) done , defined at / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py : <number> > exception = websocketclosederror ( ) > "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" traceback ( most recent call last ) :"", "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" file \ \ "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py \ \ "" , line <number> , in wrapper "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" await fut "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" tornado . iostream . streamclosederror : stream is closed "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" during handling of the above exception , another exception occurred :"", "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" traceback ( most recent call last ) :"", "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" file \ \ "" / usr / lib / python3 . <number> / asyncio / tasks . py \ \ "" , line <number> , in __step "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" result = coro . send ( none ) "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" file \ \ "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py \ \ "" , line <number> , in wrapper "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" raise websocketclosederror ( ) "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" tornado . websocket . websocketclosederror "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" got events for closed stream < zmq . eventloop . zmqstream . zmqstream object at 0x 7 9 d03bffc0d0 > "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 0 3 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : w tensorflow / tsl / framework / cpu_allocator_impl . cc : <number> ] allocation of <number> exceeds <percent> of free system memory . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 3 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" kernelrestarter : restarting kernel ( <number> / <number> ) , keep random ports "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 9 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" warning : root : kernel 9 2 d4365c - be07 - <number> - a024 - 4 0 9 4 c7317470 restarted "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 0 9 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized to use available cpu instructions in performance - critical operations . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 8 2 7 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" to enable the following instructions : avx2 fma , in other operations , rebuild tensorflow with the appropriate compiler flags . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 8 2 7 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : could not find tensorrt "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 3 6 0 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : w tensorflow / tsl / framework / cpu_allocator_impl . cc : <number> ] allocation of <number> exceeds <percent> of free system memory . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 4 5 7 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" kernelrestarter : restarting kernel ( <number> / <number> ) , keep random ports "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 3 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" warning : root : kernel 9 2 d4365c - be07 - <number> - a024 - 4 0 9 4 c7317470 restarted "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 3 4 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized to use available cpu instructions in performance - critical operations . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 4 6 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" to enable the following instructions : avx2 fma , in other operations , rebuild tensorflow with the appropriate compiler flags . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 4 6 1 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : could not find tensorrt "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 4 3 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" <number> - <number> - <number> <time> . <number> : w tensorflow / tsl / framework / cpu_allocator_impl . cc : <number> ] allocation of <phone> exceeds <percent> of free system memory . "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 6 2 9 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" kernelrestarter kernel ( <number> / <number> ) , keep random ports "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 4 2 z "" , "" v "" : <number> } { "" pid "" : <number> , "" type "" : "" jupyter "" , "" level "" : <number> , "" msg "" : "" warning : root : kernel 9 2 d4365c - be07 - <number> - a024 - 4 0 9 4 c7317470 restarted "" , "" time "" : "" <number> - <number> - 1 7 t <time> . 2 4 2 z "" , "" v "" : <number> } ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . raw_ops . pad # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to the large list of elements # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : input_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) input = tf . identity ( input_tensor ) paddings_0_0 = <number> paddings_0_1 = <number> paddings_0 = [ paddings_0_0 , paddings_0_1 , ] paddings_1_0 = <number> paddings_1_1 = false paddings_1 = [ paddings_1_0 , paddings_1_1 , ] paddings_2_0 = <number> paddings_2_1 = <number> paddings_2 = [ paddings_2_0 , paddings_2_1 , ] paddings_3_0 = <number> paddings_3_1 = <number> paddings_3 = [ paddings_3_0 , paddings_3_1 , ] paddings = [ paddings_0 , paddings_1 , paddings_2 , paddings_3 , ] name = none out = tf . raw_ops . pad ( input = input , paddings = paddings , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__pad_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <number> with <number> , result [ [ { { node pad } } ] ] [ op : pad ] ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . tile # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large list elements # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : arg_0_tensor = tf . random . uniform ( [ <number> , <number> , <number> ] , dtype = tf . float32 ) arg_0 = tf . identity ( arg_0_tensor ) arg_1_0 = <number> arg_1_1 = <number> arg_1_2 = <number> arg_1 = [ arg_1_0 , arg_1_1 , arg_1_2 , ] out = tf . tile ( arg_0 , arg_1 , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__tile_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <number> with <number> , result [ [ { { node tile } } ] ] [ op : tile ] ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . raw_ops . tile on colab # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large list elements # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : input_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) input = tf . identity ( input_tensor ) multiples_0 = <number> multiples_1 = true multiples_2 = <number> multiples_3 = <number> multiples = [ multiples_0 , multiples_1 , multiples_2 , multiples_3 , ] name = none out = tf . raw_ops . tile ( input = input , multiples = multiples , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__tile_device_ / job : localhost / replica : <number> / task : <number> / device : cpu : <number> } } encountered overflow when multiplying <number> with <number> , result [ op : tile ] ` ` ` ` ` `",0
tensorflow/tensorflow,"overflow bug when running tf . keras . layers . zeropadding3d # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to the large integer value # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : padding = <phone> arg_class = tf . keras . layers . zeropadding3d ( padding = padding , ) arg_input_0_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) arg_input_0 = tf . identity ( arg_input_0_tensor ) arg_input = [ arg_input_0 , ] out = arg_class ( * arg_input ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error : exception encountered when calling layer ' zero_padding3d ' ( type zeropadding3d ) . { { function_node __wrapped__pad_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <phone> with <phone> , result : - <number> [ op : pad ] call arguments received by layer ' zero_padding3d ' ( type zeropadding3d ) inputs = tf . tensor ( shape =( <number> , <number> , <number> , <number> , <number> ) , dtype = float32 ) { } ` ` ` ` ` `",0
tensorflow/tensorflow,"issue with nightly - gpu docker image # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> - dev20230816 # # # custom code yes # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? when using the tensorflow / tensorflow : nightly - gpu docker image i get an error saying the "" dnn library is not found "" however , when i change the base image to tensorflow / tensorflow : latest - gpu my code works fine . perhaps the nightly image broke something with the cuda / cudnn library paths ? # # # standalone code to reproduce the issue ` ` ` shell it seems that using a conv1d layer is what causes the issue . <repeated> see the log output below . ` ` ` # # # relevant log output ` ` ` shell detected at node ' peak_conv_1 / conv1d ' defined at ( most recent call last ) : node dnn library is not found . [ [ { { node peak_conv_1 / conv1d } } ] ] [ op : __inference_train_step_224831 ] ` ` `",0
tensorflow/tensorflow,"integer overflow when running tf . compat . v1 . matrix_diag on colab # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large elements in the input lists # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : diagonal_0_0_0_0 = <number> diagonal_0_0_0_1 = <number> diagonal_0_0_0 = [ diagonal_0_0_0_0 , diagonal_0_0_0_1 , ] diagonal_0_0_1_0 = <number> diagonal_0_0_1_1 = <number> diagonal_0_0_1 = [ diagonal_0_0_1_0 , diagonal_0_0_1_1 , ] diagonal_0_0 = [ diagonal_0_0_0 , diagonal_0_0_1 , ] diagonal_0_1_0_0 = <number> diagonal_0_1_0_1 = <number> diagonal_0_1_0 = [ diagonal_0_1_0_0 , diagonal_0_1_0_1 , ] diagonal_0_1_1_0 = <number> diagonal_0_1_1_1 = <number> diagonal_0_1_1 = [ diagonal_0_1_1_0 , diagonal_0_1_1_1 , ] diagonal_0_1 = [ diagonal_0_1_0 , diagonal_0_1_1 , ] diagonal_0 = [ diagonal_0_0 , diagonal_0_1 , ] diagonal_1_0_0_0 = <number> diagonal_1_0_0_1 = <number> diagonal_1_0_0 = [ diagonal_1_0_0_0 , diagonal_1_0_0_1 , ] diagonal_1_0_1_0 = <number> diagonal_1_0_1_1 = <number> diagonal_1_0_1 = [ diagonal_1_0_1_0 , diagonal_1_0_1_1 , ] diagonal_1_0 = [ diagonal_1_0_0 , diagonal_1_0_1 , ] diagonal_1_1_0_0 = <number> diagonal_1_1_0_1 = <number> diagonal_1_1_0 = [ diagonal_1_1_0_0 , diagonal_1_1_0_1 , ] diagonal_1_1_1_0 = <number> diagonal_1_1_1_1 = <number> diagonal_1_1_1 = [ diagonal_1_1_1_0 , diagonal_1_1_1_1 , ] diagonal_1_1 = [ diagonal_1_1_0 , diagonal_1_1_1 , ] diagonal_1 = [ diagonal_1_0 , diagonal_1_1 , ] diagonal = [ diagonal_0 , diagonal_1 , ] name = "" none "" k = <phone> padding_value = <number> align = "" right_left "" out = tf . compat . v1 . matrix_diag ( diagonal = diagonal , name = name , k = k , padding_value = padding_value , align = align , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__matrixdiagv3_device_ / job : localhost / replica : <number> / task : <number> / device : cpu : <number> } } encountered overflow when multiplying <number> with <phone> , result [ op : matrixdiagv3 ] { } ` ` ` ` ` `",0
tensorflow/tensorflow,"integer overflow when running tf . raw_ops . matrixdiagv3 on colab # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to large elements in input lists # # # standalone code to reproduce the issue ` ` ` shell results = dict ( ) import tensorflow as tf import os import numpy as np try : diagonal_0_0_0_0 = <number> diagonal_0_0_0_1 = <number> diagonal_0_0_0 = [ diagonal_0_0_0_0 , diagonal_0_0_0_1 , ] diagonal_0_0_1_0 = <number> diagonal_0_0_1_1 = <number> diagonal_0_0_1 = [ diagonal_0_0_1_0 , diagonal_0_0_1_1 , ] diagonal_0_0 = [ diagonal_0_0_0 , diagonal_0_0_1 , ] diagonal_0_1_0_0 = <number> diagonal_0_1_0_1 = <number> diagonal_0_1_0 = [ diagonal_0_1_0_0 , diagonal_0_1_0_1 , ] diagonal_0_1_1_0 = <number> diagonal_0_1_1_1 = <number> diagonal_0_1_1 = [ diagonal_0_1_1_0 , diagonal_0_1_1_1 , ] diagonal_0_1 = [ diagonal_0_1_0 , diagonal_0_1_1 , ] diagonal_0 = [ diagonal_0_0 , diagonal_0_1 , ] diagonal_1_0_0_0 = <number> diagonal_1_0_0_1 = <number> diagonal_1_0_0 = [ diagonal_1_0_0_0 , diagonal_1_0_0_1 , ] diagonal_1_0_1_0 = <number> diagonal_1_0_1_1 = <number> diagonal_1_0_1 = [ diagonal_1_0_1_0 , diagonal_1_0_1_1 , ] diagonal_1_0 = [ diagonal_1_0_0 , diagonal_1_0_1 , ] diagonal_1_1_0_0 = <number> diagonal_1_1_0_1 = <number> diagonal_1_1_0 = [ diagonal_1_1_0_0 , diagonal_1_1_0_1 , ] diagonal_1_1_1_0 = <number> diagonal_1_1_1_1 = <number> diagonal_1_1_1 = [ diagonal_1_1_1_0 , diagonal_1_1_1_1 , ] diagonal_1_1 = [ diagonal_1_1_0 , diagonal_1_1_1 , ] diagonal_1 = [ diagonal_1_0 , diagonal_1_1 , ] diagonal = [ diagonal_0 , diagonal_1 , ] k = <phone> num_rows = - <number> num_cols = - <number> padding_value = <number> align = "" right_left "" name = "" diag_part "" out = tf . raw_ops . matrixdiagv3 ( diagonal = diagonal , k = k , num_rows = num_rows , num_cols = num_cols , padding_value = padding_value , align = align , name = name , ) except exception as e : print ( "" error : "" + str ( e ) ) print ( results ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__matrixdiagv3_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <phone> with <phone> , result [ [ { { node matrixdiagv3 } } ] ] [ op : matrixdiagv3 ] { } ` ` ` ` ` `",0
tensorflow/tensorflow,"integer overflow when running tf . linalg . diag # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution pretty_name = "" ubuntu <number> . <number> lts "" name = "" ubuntu "" version_id = "" <number> "" version = "" <number> . <number> lts ( jammy jellyfish ) "" version_codename = jammy id = ubuntu id_like = debian home_url = "" <url> support_url = "" <url> bug_report_url = "" <url> privacy_policy_url = "" <url> ubuntu_codename = jammy # # # mobile device _no response_ # # # python version <date> ( main , <date> , <time> ) # # # bazel version _no response_ # # # gcc / compiler version [ gcc <number> . <number> ] # # # cuda / cudnn version [ nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> ] ( nvcc : nvidia ( r ) cuda compiler driver copyright ( c ) <number> - <number> nvidia corporation built on wed_sep_21_ <time> _pdt_2022 cuda compilation tools , release <number> , v11 . <number> build cuda_11 . <number> . r11 . <number> / compiler . 3 1 8 3 3 9 0 5 _0 ) # # # gpu model and memory t4 # # # current behavior ? due to the large list of elements # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np try : diagonal_0_0_0 = [ ] diagonal_0_0_1_0 = true diagonal_0_0_1_1 = <number> diagonal_0_0_1 = [ diagonal_0_0_1_0 , diagonal_0_0_1_1 , ] diagonal_0_0 = [ diagonal_0_0_0 , diagonal_0_0_1 , ] diagonal_0_1_0_0 = <number> diagonal_0_1_0_1 = <number> diagonal_0_1_0 = [ diagonal_0_1_0_0 , diagonal_0_1_0_1 , ] diagonal_0_1_1_0 = <number> diagonal_0_1_1_1 = <number> diagonal_0_1_1 = [ diagonal_0_1_1_0 , diagonal_0_1_1_1 , ] diagonal_0_1 = [ diagonal_0_1_0 , diagonal_0_1_1 , ] diagonal_0 = [ diagonal_0_0 , diagonal_0_1 , ] diagonal_1_0_0_0 = true diagonal_1_0_0_1 = "" "" diagonal_1_0_0 = [ diagonal_1_0_0_0 , diagonal_1_0_0_1 , ] diagonal_1_0_1_0 = <number> diagonal_1_0_1_1 = <number> diagonal_1_0_1 = [ diagonal_1_0_1_0 , diagonal_1_0_1_1 , ] diagonal_1_0 = [ diagonal_1_0_0 , diagonal_1_0_1 , ] diagonal_1_1_0_0 = <number> diagonal_1_1_0_1 = <number> diagonal_1_1_0 = [ diagonal_1_1_0_0 , diagonal_1_1_0_1 , ] diagonal_1_1_1_0 = <number> diagonal_1_1_1_1 = <number> diagonal_1_1_1 = [ diagonal_1_1_1_0 , diagonal_1_1_1_1 , ] diagonal_1_1 = [ diagonal_1_1_0 , diagonal_1_1_1 , ] diagonal_1 = [ diagonal_1_0 , diagonal_1_1 , ] diagonal = [ diagonal_0 , diagonal_1 , ] name = "" none "" k = <phone> padding_value = <number> align = "" right_left "" out = tf . linalg . diag ( diagonal = diagonal , name = name , k = k , padding_value = padding_value , align = align , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell error :{{ function_node __wrapped__matrixdiagv3_device_ / job : localhost / replica : <number> / task : <number> / device : gpu : <number> } } encountered overflow when multiplying <number> with <phone> , result [ [ { { node matrixdiagv3 } } ] ] [ op : matrixdiagv3 ] ` ` ` ` ` `",0
tensorflow/tensorflow,"attributeerror : module ' tensorflow . python . pywrap_mlir ' has no attribute ' experimental_convert_saved_model_v1 ' # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version v1 . <number> - <number> - gfa4d29bfef8 <number> . <number> - dev20230706 # # # custom code no # # # os platform and distribution uibuntu <number> # # # mobile device uibuntu <number> # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? - # # # standalone code to reproduce the issue ` ` ` shell - ` ` ` # # # relevant log output ` ` ` shell file "" / home / fastdisk / jiahao / research / iree / . venv / lib / python3 . <number> / site - packages / iree / tools / tf / scripts / iree_import_tf / __main__ . py "" , line <number> , in main import_saved_model ( file "" / home / fastdisk / jiahao / research / iree / . venv / lib / python3 . <number> / site - packages / iree / tools / tf / scripts / iree_import_tf / __main__ . py "" , line <number> , in import_saved_model result = convert_saved_model_v1 ( file "" / home / fastdisk / jiahao / research / iree / . venv / lib / python3 . <number> / site - packages / tensorflow / python / compiler / mlir / mlir . py "" , line <number> , in convert_saved_model_v1 return pywrap_mlir . experimental_convert_saved_model_v1 ( attributeerror ' tensorflow . python . pywrap_mlir ' has no attribute ' experimental_convert_saved_model_v1 ' ` ` `",0
tensorflow/tensorflow,"tflite gpu delegate : broadcast output incorrect # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version nightly at 0 9 cf1b2a39023e617e003a51be39d419702c2d36 # # # custom code yes # # # os platform and distribution android <number> <number> - <number> - <number> # # # mobile device vivo x80 # # # python version _no response_ # # # bazel version cmake <number> . <number> # # # gcc / compiler version android ndk r25 # # # cuda / cudnn version _no response_ # # # gpu model and memory mali - g710 mc10 # # # current behavior ? tflite model file : [ model . tflite . zip ] ( <url> the provided tflite model contains a single broadcast operation , which when executed by the provided c + + program , should produce the following output : ` ` ` <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> ` ` ` however , when using the gpu delegate the following output is produced : ` ` ` <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> ` ` ` the correct output is produced when using the cpu and not the gpu delegate . we are concerned that this could be a security issue if memory is being accessed incorrectly . content of ` model . tflite ` : ` ` ` your tflite model has ' <number> ' subgraph ( s ) . in the subgraph description below , t # represents the tensor numbers . for example , in subgraph # <number> , the mul op takes tensor # <number> and tensor # <number> as input and produces tensor # <number> as output . subgraph # <number> main ( t # <number> ) - > [ t # <number> ] op # <number> mul ( t # <number> , t # <number> ) - > [ t # <number> ] tensors of subgraph # <number> t # <number> ( serving_default_input : <number> ) shape <sad> <number> , <number> ] , type : float32 t # <number> ( broadcastto ) shape <sad> <number> , <number> ] , type : float32 ro <number> bytes , buffer : <number> , data <sad> <number> , <number> , <number> , <number> , <number> , . <repeated> ] t # <number> ( partitionedcall : <number> ) shape <sad> <number> , <number> ] , type : float32 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - your tflite model has ' <number> ' signature_def ( s ) . signature # <number> key : ' serving_default ' - subgraph : subgraph # <number> - inputs : ' input ' : t # <number> - outputs : ' output ' : t # <number> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - model size : <number> bytes non - data buffer size : <number> bytes ( <number> %) total data buffer size : <number> bytes ( <number> %) ( zero value buffers ) bytes ( <number> %) ` ` ` # # # standalone code to reproduce the issue ` ` ` shell <hashtag> include </hashtag> <memory> <hashtag> include </hashtag> < stdio . h > <hashtag> include </hashtag> "" tensorflow / lite / kernels / register . h "" <hashtag> include </hashtag> "" tensorflow / lite / model . h "" <hashtag> include </hashtag> "" tensorflow / lite / delegates / gpu / delegate . h "" int main ( ) { std : : unique_ptr < tflite : : flatbuffermodel > model = tflite : : flatbuffermodel : : buildfromfile ( "" model . tflite "" ); tflite : : ops : : builtin : : builtinopresolver resolver ; tflite : : interpreterbuilder builder ( * model , resolver ) ; std : : unique_ptr < tflite : : interpreter > interpreter ; builder ( & interpreter ) ; tflitegpudelegateoptionsv2 options = tflitegpudelegateoptionsv2default ( ); auto * delegate = tflitegpudelegatev2create ( & options ) ; if ( interpreter - > modifygraphwithdelegate ( delegate ) = ktfliteok ) return <number> ; const tflitetensor * intensor = interpreter - > input_tensor ( <number> ); const tfliteintarray * inshape = intensor - > dims ; float * input = intensor - > data . f ; for ( int i = <number> ; i < inshape - > data [ <number> ]; i + + ) { input [ i ] = i + <number> ; } if ( interpreter - > invoke ( ) ! = ktfliteok ) return <number> ; std : : vector < unsigned long > outshapevec ; const tflitetensor * outtensor = interpreter - > output_tensor ( <number> ); const tfliteintarray * outshape = outtensor - > dims ; const float * output = outtensor - > data . f ; const float * outptr = output ; for ( size_t i = <number> ; i < outshape - > data [ <number> ]; i + + ) { for ( size_t j = <number> ; j < outshape - > data [ <number> ]; j + + ) { printf ( "" % . 2 g "" , *( outptr + + )); } printf ( "" \ \ n "" ); } } ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"build failure on aarch64 - undeclared identifier ' memset ' # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version git head # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device n / a # # # python version <date> # # # bazel version <number> . <number> # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version n / a # # # gpu model and memory n / a # # # current behavior ? build fails since commit <url> # # # standalone code to reproduce the issue ` ` ` shell bazel build - - config = mkl_aarch64_threadpool - - copt = - flax - vector - conversions - - test_env = tf_enable_onednn_opts = <number> - - test_env = tf2_behavior = <number> - - define = tf_api_version = <number> - - / / tensorflow / tools / pip_package : build_pip_package ` ` ` # # # relevant log output ` ` ` shell error : / workspace / tensorflow / lite / kernels / internal / build : <number> <time> : compiling tensorflow / lite / kernels / internal / optimized / 4 bit / neon_fully_connected . cc failed : ( exit <number> <sad> clang failed : error executing command ( from target / / tensorflow / lite / kernels / internal : optimized_4bit ) ( cd / home / andrew / src / tf_test / tensorflow - git / bazel - ci_build - cache / . cache / bazel / _bazel_andrew / eab0d61a99b6696edb3d2aff87b585e8 / execroot / org_tensorflow & & \ \ exec env - \ \ cachebuster = <number> \ \ path <annoyed> home / andrew / src / tf_test / tensorflow - git / bazel - ci_build - cache / . cache / bazelisk / downloads / bazelbuild / bazel - <number> . <number> - linux - arm64 / bin <annoyed> usr / local / sbin <annoyed> usr / local / bin <annoyed> usr / sbin <annoyed> usr / bin <annoyed> sbin <annoyed> bin <annoyed> usr / games <annoyed> usr / local / games <annoyed> snap / bin \ \ pwd <annoyed> proc / self / cwd \ \ tf2_behavior = <number> \ \ / usr / lib / llvm - <number> / bin / clang - md - mf bazel - out / aarch64 - opt / bin / tensorflow / lite / kernels / internal / _objs / optimized_4bit / neon_fully_connected . pic . d ' - frandom - seed = bazel - out / aarch64 - opt / bin / tensorflow / lite / kernels / internal / _objs / optimized_4bit / neon_fully_connected . pic . o ' - dfc_4bit_neon ' - dbazel_current_repository = "" "" ' - iquote . - iquote bazel - out / aarch64 - opt / bin - iquote external / cpuinfo - iquote bazel - out / aarch64 - opt / bin / external / cpuinfo - isystem external / cpuinfo / include - isystem bazel - out / aarch64 - opt / bin / external / cpuinfo / include - isystem external / cpuinfo / src - isystem bazel - out / aarch64 - opt / bin / external / cpuinfo / src - fmerge - all - constants - wno - builtin - macro - redefined ' - d__date__ = "" redacted "" ' ' - d__timestamp__ = "" redacted "" ' ' - d__time__ = "" redacted "" ' - fpic - u_fortify_source ' - d_fortify_source = <number> ' - fstack - protector - wall - wno - invalid - partial - specialization - fno - omit - frame - pointer - no - canonical - prefixes - dndebug - g0 - o2 - ffunction - sections - fdata - sections - wno - all - wno - extra - wno - deprecated - wno - deprecated - declarations - wno - ignored - attributes - wno - array - bounds - wunused - result ' - werror = unused - result ' - wswitch ' - werror = switch ' ' - wno - error = unused - but - set - variable ' - dautoload_dynamic_kernels - wno - gnu - offsetof - extensions ' - mtune = generic ' ' - march = armv8 - a ' - o3 - flax - vector - conversions ' - std =c + + <number> ' - dfarmhash_no_cxx_string - wno - sign - compare - o3 - fno - exceptions - o3 ' - - sysroot <annoyed> dt10 ' - c tensorflow / lite / kernels / internal / optimized / 4 bit / neon_fully_connected . cc - o bazel - out / aarch64 - opt / bin / tensorflow / lite / kernels / internal / _objs / optimized_4bit / neon_fully_connected . pic . o ) # configuration : 7 0 a2ceb8c9b79ab96bab8f0b73bbfb70969f7e2a66f605b1d1332a62f7eef342 # execution platform : <user> / / : platform tensorflow / lite / kernels / internal / optimized / 4 bit / neon_fully_connected . cc : <number> : <number> : error : use of undeclared identifier ' memset ' memset ( * dest , static_cast <uint8_t> ( <number> ) , sizeof ( uint8_t ) * size ) ; ^ tensorflow / lite / kernels / internal / optimized / 4 bit / neon_fully_connected . cc : <number> : <number> : error : use of undeclared identifier ' memset ' memset ( data , <number> , sizeof ( int8_t ) * size ) ; ^ tensorflow / lite / kernels / internal / optimized / 4 bit / neon_fully_connected . cc : <number> : <number> : error : use of undeclared identifier ' memset ' memset ( input_offsets , <number> , sizeof ( int32_t ) * layout_rows ) ; ^ <number> errors generated . target / / tensorflow / tools / pip_package : build_pip_package failed to build info : elapsed time : <number> . 7 4 1 s , critical path : <number> . 0 0 s info : <number> processes : <number> internal , <number> local . failed did not complete successfully ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . nn_ops . pool # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to large list element # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import nn_ops try : input_tensor = tf . constant ( - <number> , shape =[ <number> , <number> , <number> , <number> ] , dtype = tf . float32 , ) input = tf . identity ( input_tensor ) window_shape_0 = 1 e + <number> window_shape_1 = <number> window_shape = [ window_shape_0 , window_shape_1 , ] padding = "" same "" pooling_type = "" max "" dilation_rate_0 = <number> dilation_rate_1 = <number> dilation_rate = [ dilation_rate_0 , dilation_rate_1 , ] strides_0 = <number> strides_1 = <number> strides = [ strides_0 , strides_1 , ] out = nn_ops . pool ( input = input , window_shape = window_shape , padding = padding , pooling_type = pooling_type , dilation_rate = dilation_rate , strides = strides , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_dnn . cc : <number> ] loaded cudnn version <number> <number> - <number> - <number> <time> . <number> : f tensorflow / stream_executor / cuda / cuda_dnn . cc : <number> ] check failed : cudnnsetpoolingnddescriptor ( handle_ . get ( ) , ( pooling_descriptor . mode ( ) = = dnn : : poolingmode : : kmaximum ? cudnn_max_pooling_mode : cudnn_pooling_average_count_exclude_padding ) , propagate_nans ? cudnn_propagate_nan nd , shape . data ( ) , padding . data ( ) , strides . data ( ) ) = = cudnn_status_success ( <number> vs . <number> ) aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"crash when running tensorflow . python . ops . gen_image_ops . resize_area # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to negative large tensor # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import gen_image_ops try : arg_0_tensor = tf . constant ( - <phone> , shape =[ <number> , <number> , <number> , <number> ] , dtype = tf . bfloat16 , ) arg_0 = tf . identity ( arg_0_tensor ) arg_1_tensor = tf . constant ( - <number> , shape =[ <number> ] , dtype = tf . int32 , ) arg_1 = tf . identity ( arg_1_tensor ) align_corners = false out = gen_image_ops . resize_area ( arg_0 , arg_1 , align_corners = align_corners , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability segmentation fault ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . nn_ops . conv3d_transpose_v2 # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to invalid list elements # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import nn_ops try : arg_0_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) arg_0 = tf . identity ( arg_0_tensor ) arg_1_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) arg_1 = tf . identity ( arg_1_tensor ) arg_2_0 = <number> arg_2_1 = <number> arg_2_2 = <number> arg_2_3 = <number> arg_2_4 = false arg_2 = [ arg_2_0 , arg_2_1 , arg_2_2 , arg_2_3 , arg_2_4 , ] arg_3 = <number> out = nn_ops . conv3d_transpose_v2 ( arg_0 , arg_1 , arg_2 , arg_3 , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_dnn . cc : <number> ] loaded cudnn version <number> <number> - <number> - <number> <time> . <number> : f tensorflow / stream_executor / cuda / cuda_dnn . cc : <number> ] check failed handle_ . get ( ) , convolution_descriptor . group_count ( ) ) = = cudnn_status_success ( <number> vs . <number> ) aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"crash when running tensorflow . python . framework . kernels . get_registered_kernels_for_op # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to feeding none argument . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . framework import kernels try : arg_0 = none out = kernels . get_registered_kernels_for_op ( arg_0 , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . segmentation fault ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . gen_array_ops . mirror_pad_grad # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to negative large tensor # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import gen_array_ops try : arg_0_tensor = tf . constant ( - <number> , shape =[ <number> , <number> , <number> , <number> ] , dtype = tf . int64 , ) arg_0 = tf . identity ( arg_0_tensor ) arg_1_tensor = tf . constant ( - <number> , shape =[ <number> , <number> ] , dtype = tf . int32 , ) arg_1 = tf . identity ( arg_1_tensor ) arg_2 = "" reflect "" out = gen_array_ops . mirror_pad_grad ( arg_0 , arg_1 , arg_2 , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : f tensorflow / core / framework / tensor_shape . cc : <number> ] check failed <= new_num_elements ( <number> vs . - <number> ) aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . gen_math_ops . sobol_sample # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? due to an empty input argument # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import gen_math_ops try : arg_0 = <number> arg_1 = <number> arg_2 = [ ( ) ] dtype = none out = gen_math_ops . sobol_sample ( arg_0 , arg_1 , arg_2 , dtype = dtype , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : f tensorflow / core / framework / tensor . cc : <number> ] check failed = = numelements ( ) ( <number> vs . <number> ) must have a one element tensor aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . gen_sparse_ops . sparse_slice # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to large list elements # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import gen_sparse_ops try : indices_0 = [ ] indices = [ indices_0 , ] values_0 = <number> values = [ values_0 , ] shape_0 = <number> shape_1 = <number> shape = [ shape_0 , shape_1 , ] start_0 = <number> start_1 = - <number> start = [ start_0 , start_1 , ] size_0 = <number> size_1 = <number> size = [ size_0 , size_1 , ] out = gen_sparse_ops . sparse_slice ( indices = indices , values = values , shape = shape , start = start , size = size , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : e tensorflow / stream_executor / cuda / cuda_event . cc : <number> ] error polling for event status : failed to query event : cuda_error_illegal_address : an illegal memory access was encountered <number> - <number> - <number> <time> . <number> : f tensorflow / core / common_runtime / device / device_event_mgr . cc : <number> ] unexpected event status aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"crash when running tensorflow . python . ops . gen_data_flow_ops . record_input # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to very large integer values # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import gen_data_flow_ops try : file_pattern = "" / tmp / record_input_testzsuyf9ap / tmpsqjnp5o1 / basic . * "" file_buffer_size = <number> file_parallelism = <number> file_shuffle_shift_ratio = <number> batch_size = <number> file_random_seed = <number> compression_type = "" gzip "" out = gen_data_flow_ops . record_input ( file_pattern = file_pattern , file_buffer_size = file_buffer_size , file_parallelism = file_parallelism , file_shuffle_shift_ratio = file_shuffle_shift_ratio , batch_size = batch_size , file_random_seed = file_random_seed , compression_type = compression_type , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability segmentation fault ` ` ` ` ` `",0
tensorflow/tensorflow,"segmentation fault when running tensorflow . python . ops . gen_math_ops . _histogram_fixed_width # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to negative float argument # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import numpy as np from tensorflow . python . ops import gen_math_ops try : try : with tf . device ( ' / cpu ' <sad> arg_0_0_0 = - <number> arg_0_0_1 = <number> arg_0_0_2 = <number> arg_0_0 = [ arg_0_0_0 , arg_0_0_1 , arg_0_0_2 , ] arg_0_1_0 = <number> arg_0_1_1 = <number> arg_0_1_2 = <number> arg_0_1 = [ arg_0_1_0 , arg_0_1_1 , arg_0_1_2 , ] arg_0 = [ arg_0_0 , arg_0_1 , ] arg_1_0 = - <number> . 7 9 7 6 9 3 1 3 4 8 6 2 3 1 5 7 e + <number> arg_1_1 = - <number> . 4 0 1 3 e - <number> arg_1 = [ arg_1_0 , arg_1_1 , ] arg_2 = <number> dtype = tf . int32 out = gen_math_ops . _histogram_fixed_width ( arg_0 , arg_1 , arg_2 , dtype = dtype , ) except exception as e : print ( "" error : "" + str ( e ) ) try : with tf . device ( ' / gpu : <number> ' <sad> arg_0_0 = [ arg_0_0_0 , arg_0_0_1 , arg_0_0_2 , ] arg_0_1 = [ arg_0_1_0 , arg_0_1_1 , arg_0_1_2 , ] arg_0 = [ arg_0_0 , arg_0_1 , ] arg_1 = [ arg_1_0 , arg_1_1 , ] dtype = tf . int32 gen_math_ops . _histogram_fixed_width ( arg_0 , arg_1 , arg_2 , dtype = dtype , ) except exception as e : print ( "" error : "" + str ( e ) ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability segmentation fault ( fuzzer_tf_2 . <number> ) n ` ` ` ` ` `",0
tensorflow/tensorflow,avoid partially saved ckpt from preempted device ( e . g . tpu ) # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version tf . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i accidentally discovered from a tpu preemption that my ckpt cannot be used to resume training ( the preemption occurs during the process of saving ckpt ) . the error is that some weights cannot be matched . this phenomenon is happening for the first time and has never happened before . # # # standalone code to reproduce the issue ` ` ` shell it is very hard to reproduce because it must be preemption while saving the ckpt . ` ` ` # # # relevant log output _no response_,0
tensorflow/tensorflow,"i need tensorflow <number> . <number> but it is removed how to find it ? i need to install tensorflow <number> . <number> why ? because this repo ( <url> is requesting it and now matter what i tried can not make it work with newer tensorflows how can i install tensorflow <number> . <number> on windows <number> and python <number> ? the error i am getting is and i am not able to fix it ` ` ` ( venv ) g :\\ nsfw_model > python a . py <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx avx2 to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> , pci bus id : <number> <time> . <number> , compute capability : <number> traceback ( most recent call last ) : file "" g :\\ nsfw_model \ \ a . py "" , line <number> , in <module> print ( predict . classify ( model , ' test ' ) ) file "" g :\\ nsfw_model \ \ nsfw_detector \ \ predict . py "" , line <number> , in classify probs = classify_nd ( model , images , predict_args ) file "" g :\\ nsfw_model \ \ nsfw_detector \ \ predict . py "" , line <number> , in classify_nd model_preds = model . predict ( nd_images , * * predict_args ) file "" g :\\ nsfw_model \ \ venv \ \ lib \ \ site - packages \ \ keras \ \ utils \ \ traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" g :\\ nsfw_model \ \ venv \ \ lib \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in predict raise valueerror ( ' unexpected result of ` predict_function ` ' valueerror : unexpected result of ` predict_function ` ( empty batch_outputs ) . please use ` model . compile ( . <repeated> , run_eagerly = true ) ` , or ` tf . config . run_functions_eagerly ( true ) ` for more information of where went wrong , or file a issue / bug to ` tf . keras ` . ` ` ` predict . py ` ` ` # python import argparse import json from os import listdir from os . path import isfile , join , exists , isdir , abspath import numpy as np import tensorflow as tf from tensorflow import keras import tensorflow_hub as hub image_dim = <number> # required / default image dimensionality def load_images ( image_paths , image_size , verbose = true ) : ' ' ' function for loading images into numpy arrays for passing to model . predict inputs : image_paths : list of image paths to load image_size : size into which images should be resized verbose : show all of the image path and sizes loaded outputs : loaded_images : loaded images on which keras model can run predictions loaded_image_indexes : paths of images which the function is able to process ' ' ' loaded_images = [ ] loaded_image_paths = [ ] if isdir ( image_paths ) : parent = abspath ( image_paths ) image_paths = [ join ( parent , f ) for f in listdir ( image_paths ) if isfile ( join ( parent , f ) ) ] elif isfile ( image_paths ) : image_paths = [ image_paths ] for img_path in image_paths : try : if verbose : print ( img_path , "" size :"", image_size ) image = keras . preprocessing . image . load_img ( img_path , target_size = image_size ) image = keras . preprocessing . image . img_to_array ( image ) image /= <number> loaded_images . append ( image ) loaded_image_paths . append ( img_path ) except exception as ex : print ( "" image load failure : "" , img_path , ex ) return np . asarray ( loaded_images ) , loaded_image_paths def load_model ( model_path ) : if model_path is none or not exists ( model_path ) : raise valueerror ( "" saved_model_path must be the valid directory of a saved model to load . "" ) model = tf . keras . models . load_model ( model_path , custom_objects ={ ' keraslayer ' : hub . keraslayer } , compile = false ) return model def classify ( model , input_paths , image_dim = image_dim , predict_args ={}) : "" "" "" classify given a model , input paths ( could be single string ) , and image dimensionality . optionally , pass predict_args that will be passed to tf . keras . model . predict ( ) . "" "" "" images , image_paths = load_images ( input_paths , ( image_dim , image_dim ) ) probs = classify_nd ( model , images , predict_args ) return dict ( zip ( image_paths , probs ) ) def classify_nd ( model , nd_images , predict_args ={}) : "" "" "" classify given a model , image array ( numpy ) optionally , pass predict_args that will be passed to tf . keras . model . predict ( ) . "" "" "" model_preds = model . predict ( nd_images , * * predict_args ) # preds = np . argsort ( model_preds , axis = <number> ) . tolist ( ) categories = [ ' drawings ' , ' hentai ' , ' neutral ' , ' porn ' , ' sexy ' ] probs = [ ] for i , single_preds in enumerate ( model_preds ) : single_probs = { } for j , pred in enumerate ( single_preds ) : single_probs [ categories [ j ] ] = float ( pred ) probs . append ( single_probs ) return probs def main ( args = none ) : parser = argparse . argumentparser ( description = "" "" "" a script to perform nfsw classification of images "" "" "" , epilog = "" "" "" launch with default model and a test image python nsfw_detector / predict . py - - saved_model_path mobilenet_v2_140_224 - - image_source test . jpg "" "" "" , formatter_class = argparse . rawtexthelpformatter ) submain = parser . add_argument_group ( ' main execution and evaluation functionality ' ) submain . add_argument ( ' - - image_source ' , dest = ' image_source ' , type = str , required = true , help = ' a directory of images or a single image to classify ' ) submain . add_argument ( ' - - saved_model_path ' , dest = ' saved_model_path ' , type = str , required = true , help = ' the model to load ' ) submain . add_argument ( ' - - image_dim ' , dest = ' image_dim ' , type = int , default = image_dim , help = "" the square dimension of the model ' s input shape "" ) if args is not none : config = vars ( parser . parse_args ( args ) ) else : config = vars ( parser . parse_args ( ) ) if config [ ' image_source ' ] is none or not exists ( config [ ' image_source ' ]): raise valueerror ( "" image_source must be a valid directory with images or a single image to classify . "" ) model = load_model ( config [ ' saved_model_path ' ] ) image_preds = classify ( model , config [ ' image_source ' ] , config [ ' image_dim ' ] ) print ( json . dumps ( image_preds , indent = <number> ) , ' \ \ n ' ) if __name__ = = "" __main__ "" ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . gen_sparse_ops . sparse_split # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to zero integer argument . it would be best if you ran multiple times to see the abort . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import gen_sparse_ops try : arg_0 = <number> arg_1_tensor = tf . random . uniform ( [ <number> , <number> ] , minval = - <number> , maxval = <number> , dtype = tf . int64 ) arg_1 = tf . identity ( arg_1_tensor ) arg_2_tensor = tf . random . uniform ( [ <number> ] , minval = - <number> , maxval = <number> , dtype = tf . int64 ) arg_2 = tf . identity ( arg_2_tensor ) arg_3_tensor = tf . random . uniform ( [ <number> ] , minval = - <number> , maxval = <number> , dtype = tf . int64 ) arg_3 = tf . identity ( arg_3_tensor ) arg_4 = <number> out = gen_sparse_ops . sparse_split ( arg_0 , arg_1 , arg_2 , arg_3 , arg_4 , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_driver . cc : <number> ] failed to allocate <number> . 6 9 m ( <number> bytes ) from device : cuda_error_out_of_memory : out of memory <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_driver . cc : <number> ] failed to allocate <number> . 5 2 m ( <number> bytes ) from device : cuda_error_out_of_memory : out of memory <number> - <number> - <number> <time> . <number> : e tensorflow / compiler / xla / stream_executor / cuda / cuda_event . cc : <number> ] error polling for event status : failed to query event : cuda_error_misaligned_address : misaligned address <number> - <number> - <number> <time> . <number> : f tensorflow / core / common_runtime / device / device_event_mgr . cc : <number> ] unexpected event status aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . eager . remote . connect_to_remote_host # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? nan string argument # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import numpy as np from tensorflow . python . eager import remote try : try : with tf . device ( ' / cpu ' <sad> arg_0 = "" nan "" out = remote . connect_to_remote_host ( arg_0 , ) except exception as e : print ( "" error : "" + str ( e ) ) try : with tf . device ( ' / gpu : <number> ' <sad> remote . connect_to_remote_host ( arg_0 , ) except exception as e : print ( "" error : "" + str ( e ) ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : e tensorflow / core / distributed_runtime / rpc / grpc_server_lib . cc : <number> ] invalid_argument : could not interpret "" nan "" as a host - port pair . e0813 <time> . <number> <number> completion_queue . cc : <number> ] assertion failed = = <number> aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . gen_nn_ops . conv3d_backprop_input_v2 # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? due to input tensor with zero shape # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import gen_nn_ops try : input_sizes_0 = <number> input_sizes_1 = <number> input_sizes_2 = <number> input_sizes_3 = <number> input_sizes_4 = <number> input_sizes = [ input_sizes_0 , input_sizes_1 , input_sizes_2 , input_sizes_3 , input_sizes_4 , ] filter_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) filter = tf . identity ( filter_tensor ) out_backprop_tensor = tf . random . uniform ( [ <number> , <number> , <number> , <number> , <number> ] , dtype = tf . float32 ) out_backprop = tf . identity ( out_backprop_tensor ) strides_0 = <number> strides_1 = <number> strides_2 = <number> strides_3 = <number> strides_4 = <number> strides = [ strides_0 , strides_1 , strides_2 , strides_3 , strides_4 , ] padding = "" same "" data_format = "" ndhwc "" dilations_0 = <number> dilations_1 = <number> dilations_2 = <number> dilations_3 = <number> dilations_4 = <number> dilations = [ dilations_0 , dilations_1 , dilations_2 , dilations_3 , dilations_4 , ] out = gen_nn_ops . conv3d_backprop_input_v2 ( input_sizes = input_sizes , filter = filter , out_backprop = out_backprop , strides = strides , padding = padding , data_format = data_format , dilations = dilations , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : f . / tensorflow / core / util / gpu_launch_config . h : <number> ] check failed > <number> ( <number> vs . <number> ) aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . linalg_ops . self_adjoint_eig # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? this behavior is very strange and should not throw oom error . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import linalg_ops try : arg_0_tensor = tf . random . uniform ( [ <number> , <number> ] , dtype = tf . float32 ) arg_0 = tf . identity ( arg_0_tensor ) out = linalg_ops . self_adjoint_eigvals ( arg_0 , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / xla / stream_executor / cuda / cuda_driver . cc : <number> ] a non - primary context 0x 5 a7ae50 for device <number> exists before initializing the streamexecutor . the primary context is now 0x 7 ffd00000000 . we have not verified streamexecutor works with that . <number> - <number> - <number> <time> . <number> : f tensorflow / tsl / platform / statusor . cc : <number> ] attempting to fetch value instead of handling error internal : failed initializing streamexecutor for cuda device ordinal <number> : internal : failed call to cudeviceprimaryctxretain : cuda_error_out_of_memory : out of memory ; total memory reported aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"abort when running tensorflow . python . ops . nn_ops . conv2d_transpose # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? probably due to the large input tensor # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . ops import nn_ops try : arg_0_tensor = tf . constant ( - <number> , shape =[ <number> , <number> , <number> , <number> ] , dtype = tf . float16 , ) arg_0 = tf . identity ( arg_0_tensor ) arg_1_tensor = tf . constant ( - <number> , shape =[ <number> , <number> , <number> , <number> ] , dtype = tf . float16 , ) arg_1 = tf . identity ( arg_1_tensor ) arg_2_0 = <number> arg_2_1 = <number> arg_2_2 = <number> arg_2_3 = <number> arg_2 = [ arg_2_0 , arg_2_1 , arg_2_2 , arg_2_3 , ] strides_0 = <number> strides_1 = <number> strides_2 = <number> strides_3 = <number> strides = [ strides_0 , strides_1 , strides_2 , strides_3 , ] padding = "" same "" out = nn_ops . conv2d_transpose ( arg_0 , arg_1 , arg_2 , strides = strides , padding = padding , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : f . / tensorflow / core / util / gpu_launch_config . h : <number> ] check failed > <number> ( <number> vs . <number> ) aborted ` ` ` ` ` `",0
tensorflow/tensorflow,"segmentation fault when running tensorflow . python . eager . context . add_function # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version nvidia - cudnn - cu11 = = <number> . <number> , cudatoolkit = <number> . <number> # # # gpu model and memory _no response_ # # # current behavior ? probably due to the none argument # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import os import numpy as np from tensorflow . python . eager import context try : arg_0 = none out = context . add_function ( arg_0 , ) except exception as e : print ( "" error : "" + str ( e ) ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : cannot dlopen some tensorrt libraries . if you would like to use nvidia gpu with tensorrt , please make sure the missing libraries mentioned above are installed properly . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce gtx <number> ti , pci bus id : <number> <time> . <number> , compute capability segmentation fault ` ` ` ` ` `",0
tensorflow/tensorflow,"tflite - rutime : runtimeerror : encountered unresolved custom op : farthestpointsample . * * system information * * - os platform and distribution ( e . g . , linux ubuntu <number> <sad> ubuntu <number> - tensorflow installed from ( source or binary ) : source - tensorflow version ( or github sha if from source ) : <number> . <number> * * provide the text output from tflite_convert * * i did some test with pointnet + + ( <url> and tried to inference with tf . lite or tflite - runtime , but both of them show the error message below : ` ` ` traceback ( most recent call last ) : file "" test . py "" , line <number> , in <module> predict = pointnetpredict ( ' / kaggle / input / model - sign / model_sign . tflite ' ) file "" / kaggle / working / pointnet3c1 / models / pointnet_predict . py "" , line <number> , in __init__ self . interpreter = self . init_model ( ) file "" / kaggle / working / pointnet3c1 / models / pointnet_predict . py "" , line <number> , in init_model interpreter . allocate_tensors ( ) file "" / opt / conda / lib / python3 . <number> / site - packages / tensorflow / lite / python / interpreter . py "" , line <number> , in allocate_tensors return self . _interpreter . allocatetensors ( ) runtimeerror : encountered unresolved custom op : farthestpointsample . see instructions : <url> node number <number> ( farthestpointsample ) failed to prepare . encountered unresolved custom op : farthestpointsample . see instructions node number <number> ( farthestpointsample ) failed to prepare . ` ` ` i noticed there were some custom ops ( tf_ops ) in project pointnet2 , but how to convert these ops to tflite - runtime operators ? ` ` ` # copy and paste here ` ` ` * * standalone code to reproduce the issue * * provide a reproducible test case that is the bare minimum necessary to generate the problem . if possible , please share a link to colab / jupyter / any notebook . also , please include a link to a graphdef or the model if possible . * * any other info / logs * * include any logs or source code that would be helpful to diagnose the problem . if including tracebacks , please include the full traceback . large logs and files should be attached .",0
tensorflow/tensorflow,"attributeerror : can not set attribute in plot or <user> for example # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution windows # # # mobile device na # # # python version <number> # # # bazel version na # # # gcc / compiler version ? # # # cuda / cudnn version ? # # # gpu model and memory colab notebook # # # current behavior ? i am running this tensorflow example : <url> i wanted to add some additional models at the end and tried to create new data windows as done above . i noticed the example already given , and my new code requires the following line to be run before the <user> for "" example "" is created : "" w2 . example = example_inputs , example_labels "" else you get a vague error "" attributeerror : can not set attribute "" but it looks like this has a setter ? this line is found under "" <number> . plot "" and if moved to a later section after the <user> def example under section <number> this error occurs . # # # standalone code to reproduce the issue ` ` ` shell move : w2 . example = example_inputs , example_labels to under section <number> which should be ok . can not set error occurs . ` ` ` # # # relevant log output ` ` ` shell attributeerror set attribute ` ` `",0
tensorflow/tensorflow,"question about <user> . function # # # issue type others # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory t4 # # # current behavior ? after adding <user> . function , i found that each epoch only executes one batch_size , and this does not happen when <user> . function are removed # # # standalone code to reproduce the issue ` ` ` shell from tensorflow . keras . layers import conv2d , batchnormalization , activation , maxpool2d , globalaveragepooling2d , flatten , dense , dropout from tensorflow . keras import model , sequential from tensorflow . keras . regularizers import l2 class resnetblock ( model ) : def __init__ ( self , filters = <number> , strides = <number> <sad> super ( resnetblock , self ) . __init__ ( ) self . strides = strides self . c1 = conv2d ( filters = filters , kernel_size =( <number> , <number> ) , strides = strides , padding = ' same ' ) self . b1 = batchnormalization ( ) self . a1 = activation ( ' relu ' ) self . c2 = conv2d ( filters = filters , kernel_size =( <number> , <number> ) , strides = <number> , padding = ' same ' ) self . b2 = batchnormalization ( ) if ( strides > <number> <sad> self . c3 = conv2d ( filters = filters , kernel_size =( <number> , <number> ) , strides = strides , padding = ' same ' ) self . b3 = batchnormalization ( ) self . a2 = activation ( ' relu ' ) def call ( self , inputs ) : short_x = inputs x = self . c1 ( inputs ) x = self . b1 ( x ) x = self . a1 ( x ) x = self . c2 ( x ) y = self . b2 ( x ) if ( self . strides > <number> <sad> short_x = self . c3 ( short_x ) short_x = self . b3 ( short_x ) return self . a2 ( short_x + y ) class resnet ( model ) : def __init__ ( self , model_lst , cur_filters = <number> <sad> super ( resnet , self ) . __init__ ( ) self . c1 = conv2d ( filters = cur_filters , kernel_size =( <number> , <number> ) , strides = <number> , padding = ' same ' ) self . b1 = batchnormalization ( ) self . a1 = activation ( ' relu ' ) self . p1 = maxpool2d ( ( <number> , <number> ) , <number> ) self . blocks = sequential ( ) for ( i , lst ) in enumerate ( model_lst ) : for ids in range ( lst ) : if ( i = <number> and ids = = <number> <sad> block = resnetblock ( cur_filters , strides = <number> ) else : block = resnetblock ( cur_filters , strides = <number> ) self . blocks . add ( block ) cur_filters * = <number> self . g1 = globalaveragepooling2d ( ) self . d1 = dense ( <number> , activation = ' softmax ' , kernel_regularizer = l2 ( ) ) def call ( self , inputs ) : x = self . c1 ( inputs ) x = self . b1 ( x ) x = self . a1 ( x ) x = self . p1 ( x ) x = self . blocks ( x ) x = self . g1 ( x ) y = self . d1 ( x ) return y # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - # resnet18 import tensorflow as tf import numpy as np import matplotlib . pyplot as plt # import matplotlib # matplotlib . rcparams [ ' font . family ' ]= [ ' simhei ' , ' arial ' ] from tensorflow . keras import * from tensorflow . keras . layers import conv2d , dense , batchnormalization , activation , maxpool2d , globalaveragepooling2d from tensorflow . keras . models import sequential from tensorflow . keras . losses import sparsecategoricalcrossentropy from tensorflow . keras . optimizers import adam from tensorflow . keras . metrics import mean , sparsecategoricalaccuracy from tensorflow . keras . datasets . fashion_mnist import load_data batch_size = <number> epochs = <number> validation_freq = <number> (x _train , y_train ) , (x _test , y_test ) = load_data ( ) x_train , x_test = x_train / <number> . , x_test / <number> . x_train = np . expand_dims ( x_train , - <number> ) . astype ( np . float32 ) x_test = np . expand_dims ( x_test , - <number> ) . astype ( np . float32 ) train_dataset = tf . data . dataset . from_tensor_slices ( (x _train , y_train ) ) . shuffle ( len ( x_train ) ) . batch ( batch_size ) test_dataset = tf . data . dataset . from_tensor_slices ( (x _test , y_test ) ) . shuffle ( len ( x_test ) ) . batch ( batch_size ) model = resnet ( [ <number> , <number> , <number> , <number> ] ) losses = sparsecategoricalcrossentropy ( from_logits = false ) optimizer = adam ( ) train_metrics_loss = mean ( ) train_metrics_accuracy = sparsecategoricalaccuracy ( ) test_metrics_loss = mean ( ) test_metrics_accuracy = sparsecategoricalaccuracy ( ) train_losses = [ ] train_accuracy = [ ] test_losses = [ ] test_accuracy = [ ] <user> . function def train_step ( model , input_images , y_real ) : with tf . gradienttape ( ) as tape : y_pred = model ( input_images , training = true ) loss = losses ( y_real , y_pred ) gradients = tape . gradient ( loss , model . trainable_variables ) optimizer . apply_gradients ( zip ( gradients , model . trainable_variables ) ) train_metrics_loss . update_state ( loss ) train_metrics_accuracy . update_state ( y_real , y_pred ) <user> . function def test_step ( model , input_images , y_real ) : with tf . gradienttape ( ) as tape : y_pred = model ( input_images , training = false ) loss = losses ( y_real , y_pred ) test_metrics_loss . update_state ( loss ) test_metrics_accuracy . update_state ( y_real , y_pred ) for epoch in range ( epochs ) : train_metrics_loss . reset_states ( ) train_metrics_accuracy . reset_states ( ) test_metrics_accuracy . reset_states ( ) test_metrics_loss . reset_states ( ) for x_batch , y_batch in train_dataset : train_step ( model , x_batch , y_batch ) train_losses . append ( train_metrics_loss . result ( ) ) train_accuracy . append ( train_metrics_accuracy . result ( ) ) print ( f "" epoch ={ epoch } , train_loss ={ train_metrics_loss . result ( ) } , train_accuracy ={ train_metrics_accuracy . result ( ) } "" ) if ( epoch % validation_freq = = <number> <sad> for test_x_batch , test_y_batch in test_dataset test_x_batch , test_y_batch ) test_losses . append ( test_metrics_loss . result ( ) ) test_accuracy . append ( test_metrics_accuracy . result ( ) ) print ( f "" epoch ={ epoch } , test_loss ={ test_metrics_loss . result ( ) } , test_accuracy ={ test_metrics_accuracy . result ( ) } "" ) plt . figure ( figsize =( <number> , <number> ) ) plt . subplot ( <number> , <number> , <number> ) plt . title ( ' 损失值变化图 ' ) plt . plot ( test_losses , ' g - ' , label = "" test_loss "" ) plt . plot ( train_losses , ' r - ' , label = "" train_loss "" ) plt . legend ( ) plt . subplot ( <number> , <number> , <number> ) plt . title ( "" 准确率变化图 "" ) plt . plot ( train_accuracy , ' r - ' , label = "" train_accuracy "" ) plt . plot ( test_accuracy , ' g - ' , label = "" test_accuracy "" ) plt . legend ( ) plt . show ( ) ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,""" load_model "" method causes operating system level user - interface freeze # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution windows : <number> . <number> # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda : <number> . 0 _460 . <number> / cudnn # # # gpu model and memory nvidia rtx a6000 # # # current behavior ? there should not be any user interface freeze # # # standalone code to reproduce the issue ` ` ` shell load_m = tf . keras . models . load_model ( ' test . hdf5 ' , custom_objects ={ ' custom_loss ' : customlossfunction } ) ` ` ` # # # relevant log output ` ` ` shell we just see operating system user interface freeze . when the gpu ( nvidia rtx a6000 ) mode is tcc we see that whole user interface of operating system ( not just the process which is execution this command ) is frozen for <number> seconds . can this be fixed so that there is no freeze of user interface ? same code when gpu mode is wddm will not freeze the user interface . ` ` `",0
tensorflow/tensorflow,"tf <number> - tflite convert error in topk when k is np . int64 # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> mac and colab - tensorflow installation ( pip package or built from source ) : pip - tensorflow library ( version , if pip package or github sha , if built from source ) : <number> # # # <number> . code colab code [ here ] ( <url> # # # <number> . bug tf <number> model with ` tf . math . top_k ` error in tflite convert tf <number> - * pass <emphasis> * ` k ` is numpy . int64 - * fail <emphasis> * ` k ` is numpy . int32 - * pass <emphasis> * ` k ` is python int - * pass <emphasis> * # # # <number> . error logs ` ` ` - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - convertererror traceback ( most recent call last ) [ < ipython - input - <number> - 2 ef9a00e0912 > ] ( https :// localhost : <number> /# ) in < cell line : <number> > ( ) <number> # error - - - - > <number> create_model_and_convert ( k = np . int64 ( <number> ) ) <number> frames [ / usr / local / lib / python3 . <number> / dist - packages / tensorflow / lite / python / convert . py ] ( https :// localhost : <number> /# ) in convert ( model_flags , conversion_flags , input_data_str , debug_info_str , enable_mlir_converter ) <number> enable_mlir_converter , <number> ) - - > <number> raise converter_error <number> <number> return _run_deprecated_conversion_binary ( convertererror : / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / saved_model / save . py : <number> : <number> : error : ' tf . topkv2 ' op is neither a custom op nor a flex op <unknown> : <number> : note : loc ( fused [ "" partitionedcall :"", "" partitionedcall "" ]): called from / usr / local / lib / python3 . <number> / dist - packages / tensorflow / python / saved_model / save . py : <number> : <number> : note : error code : error_needs_flex_ops <unknown> : <number> : error : failed while converting : ' main ' : some ops are not supported by the native tflite runtime , you can enable tf kernels fallback using tf select . see instructions : <url> tf select ops : topkv2 details : tf . topkv2 ( tensor < ? x29x7xf32 > , tensor <i64> ) - > ( tensor < ? x29x5xf32 > , tensor < ? x29x5xi32 > ) = "" "" , sorted = true } ` ` `",0
tensorflow/tensorflow,try self . interpreter . invoke ( ) app got crashed on this line swift <number>,0
tensorflow/tensorflow,"could not load dynamic library ' cudart64_110 . dll ' ; dlerror : cudart64_110 . dll not found # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device n / a # # # python version <number> ( microsoft store ) # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda : <number> # # # gpu model and memory rtx <number> ti 8 gb # # # current behavior ? i installed cuda <number> as recommended for tf <number> . <number> , here ' s the install : [ screenshot ] ( <url> at first , i thought it was a path issue , but after restarting my pc , i was able to access exe files in that folder : ! [ image ] ( <url> if the files are in path , why can not tensorflow find them ? many people say to use miniconda , so i did , but i got the same result . other resolved issues were resolved as the op ' s were using the wrong version of cuda , i checked on the website and i can confirm that my version is the required one . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cudart64_110 . dll ' ; dlerror : cudart64_110 . dll not found <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cudart_stub . cc : <number> ] ignore above cudart dlerror if you do not have a gpu set up on your machine . <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cudart64_110 . dll ' ; dlerror : cudart64_110 . dll not found <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cublas64_11 . dll ' ; dlerror : cublas64_11 . dll not found <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cublaslt64_11 . dll ' ; dlerror : cublaslt64_11 . dll not found <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cufft64_10 . dll ' ; dlerror : cufft64_10 . dll not found <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cusparse64_11 . dll ' ; dlerror : cusparse64_11 . dll not found <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' cudnn64_8 . dll ' ; dlerror not found ` ` `",0
tensorflow/tensorflow,"visual studio <number> / mingw64 : cant find source files # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution windows <number> # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? cant write complete application # # # standalone code to reproduce the issue ` ` ` shell <hashtag> include </hashtag> < stdio . h > <hashtag> include </hashtag> < tensorflow / cc / client / client_session . h > <hashtag> include </hashtag> < tensorflow / cc / ops / standard_ops . h > <hashtag> include </hashtag> < tensorflow / core / framework / tensor . h > int main ( ) { / / инициализация tensorflow tensorflow : : scope root = tensorflow : : scope : : newrootscope ( ); tensorflow : : clientsession session ( root ) ; / / входные данные ( <number> предыдущих ohlc свечей ) std : : vector <float> input_data = { /* ваши значения ohlc свечей */ }; tensorflow : : tensor input_tensor ( tensorflow : : dt_float , tensorflow : : tensorshape ( { <number> , <number> })); auto input_tensor_mapped = input_tensor . tensor < float , <number> >(); for ( int i = <number> ; i < <number> ; + + i ) { input_tensor_mapped ( <number> , i ) = input_data [ i ] ; } / / загружаем модель или определяем свою модель для прогнозирования / / tensorflow : : graphdef graph_def ; / / tensorflow : : readbinaryproto ( tensorflow : : env : : default ( ) , "" path / to / model . pb "" , & graph_def ) ; / / tensorflow : : sessionoptions session_options ; / / tensorflow : : clientsession session ( root , session_options ) ; / / session . create ( graph_def ) ; / / выполняем прогноз на основе входных данных tensorflow : : tensor output_tensor ; tensorflow : : status run_status = session . run ( { { "" input_tensor_name "" , input_tensor } } , { "" output_tensor_name "" } , { } , & output_tensor ) ; if ( run_status . ok ( ) ) { std : : cerr < < "" ошибка выполнения < < run_status . error_message ( ) < < std : : endl ; return <number> ; } / / обрабатываем результат прогноза auto output_tensor_mapped = output_tensor . tensor < float , <number> >(); / / выводим результаты прогноза ohlc свечи будущей return <number> ; } ` ` ` # # # relevant log output ` ` ` shell серьезность код описание проект файл строка состояние подавления ошибка ( активно ) e1696 не удается открыть источник файл "" third_party / eigen3 / unsupported / eigen / cxx11 / threadpool "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ threadpool_interface . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / status / status . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ framework \ \ ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / str_cat . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ framework \ \ ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / tensor . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ framework \ \ ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / str_cat . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ framework \ \ scope . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / array_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / candidate_sampling_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / control_flow_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / data_flow_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / image_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / io_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / linalg_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / logging_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / lookup_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / math_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / nn_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / no_op . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / parsing_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / random_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / sparse_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / state_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / string_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / training_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / cc / ops / user_ops . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ cc \ \ ops \ \ standard_ops . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / graph . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ common_runtime \ \ graph_constructor . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ allocator . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ allocator . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / base / macros . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ device_base . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ device_base . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / device_attributes . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ device_base . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / full_type . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ full_type_inference_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / full_type . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ full_type_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / node_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ full_type_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / op_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ full_type_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / graph_debug_info . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / container / flat_hash_map . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / variant . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / attr_value . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / function . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / optimized_function_graph . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / protobuf / config . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / tsl / protobuf / error_codes . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / protobuf / remote_tensor_handle . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ function . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / node_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ node_def_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / op_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ node_def_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / node_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ node_def_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / op_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ node_def_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / types . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ node_def_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / node_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ node_properties . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / op_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ node_properties . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / container / flat_hash_map . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / full_type . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / full_type . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_def_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / op_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_def_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / api_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_def_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / op_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_def_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / time / time . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / span . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / graph . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / kernel_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / node_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / tensor_shape . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / types . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / protobuf / config . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ op_kernel . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / registration / options . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ registration \ \ registration . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / types . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ resource_handle . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" third_party / eigen3 / unsupported / eigen / cxx11 / tensor "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ tensor . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / types . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ tensor . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" third_party / eigen3 / unsupported / eigen / cxx11 / tensor "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ tensor_shape . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / types . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ tensor_shape . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" third_party / eigen3 / unsupported / eigen / cxx11 / tensor "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ tensor_types . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" third_party / eigen3 / unsupported / eigen / cxx11 / tensor "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ types . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / full_type . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ types . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / types . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ framework \ \ types . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / full_type . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / node_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / container / flat_hash_map . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph_debug_info_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / status / status . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph_debug_info_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / status / statusor . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph_debug_info_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph_debug_info_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / span . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph_debug_info_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / graph_debug_info . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ graph_debug_info_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / framework / op_def . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ graph \ \ node_builder . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / span . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ lib \ \ gtl \ \ array_slice . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / base / attributes . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ platform \ \ errors . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / str_join . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ platform \ \ errors . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ platform \ \ threadpool . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / core / protobuf / config . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ public \ \ session_options . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / match . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ util \ \ managed_stack_trace . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / str_cat . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ util \ \ managed_stack_trace . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ util \ \ managed_stack_trace . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ core \ \ util \ \ tensor_format . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ framework \ \ allocator . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ framework \ \ allocator . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ framework \ \ device_type . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" eigen / core "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ framework \ \ fixedpoint_types . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / container / inlined_vector . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ lib \ \ gtl \ \ inlined_vector . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" third_party / eigen3 / eigen / core "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ bfloat16 . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / cord . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ default \ \ cord . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / base / log_severity . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ default \ \ logging . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ default \ \ logging . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / status / statusor . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ default \ \ statusor . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / functional / any_invocable . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ env . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / base / attributes . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ errors . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / status / status . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ errors . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / cord . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ errors . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / str_join . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ errors . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" include / float8 . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ float8 . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / descriptor . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / arena . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / descriptor . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / dynamic_message . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / io / coded_stream . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / io / tokenizer . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / io / zero_copy_stream . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / io / zero_copy_stream_impl_lite . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / map . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / message . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / repeated_field . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / text_format . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / util / field_comparator . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / util / json_util . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / util / message_differencer . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" google / protobuf / util / type_resolver_util . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ protobuf . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / base / attributes . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ status . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / functional / function_ref . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ status . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / status / status . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ status . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / cord . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ status . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ status . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ status . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" tensorflow / tsl / protobuf / error_codes . pb . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ status . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / base / attributes . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ statusor . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / status / statusor . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ statusor . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / string_view . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ stringpiece . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / str_join . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ str_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / strings / str_split . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ str_util . h <number> ошибка ( активно ) e1696 не удается открыть источник файл "" absl / types / optional . h "" ai c :\\ users \ \ user \ \ source \ \ repos \ \ ai \ \ include \ \ tensorflow \ \ tsl \ \ platform \ \ threadpool . h <number> ` ` `",0
tensorflow/tensorflow,"failed assertion in tf . linalg . sqrtm ( and possibly other functions ) crashes entire program instead of raising exception # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution macbook <number> m1 air , ventura <number> # # # mobile device - # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? currently , providing a degenerate matrix to tf . linalg . sqrtm crashes the entire program , producing output : ` ` ` assertion failed : ( t ( i , i ) >= <number> ) , function matrix_sqrt_quasi_triangular_diagonal , file external / eigen_archive / unsupported / eigen / src / matrixfunctions / matrixsquareroot . h , line <number> . process finished with exit code <number> ( interrupted by signal <number> : sigabrt ) ` ` ` # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf def demo_assertion_error_crashes_program ( <sad> degenerate_matrix = tf . ones ( ( <number> , <number> ) , dtype = tf . float64 ) try : tf . linalg . sqrtm ( degenerate_matrix ) # tf . linalg . inv ( degenerate_matrix ) # < - this also fails , but raises an actual exception print ( "" calculated root "" ) # this is never run except exception as err : print ( "" caught exception : "" , err ) # neither is this if __name__ = = ' __main__ ' : demo_assertion_error_crashes_program ( ) ` ` ` # # # relevant log output ` ` ` shell assertion failed : ( t ( i , i ) >= <number> ) , function matrix_sqrt_quasi_triangular_diagonal , file external / eigen_archive / unsupported / eigen / src / matrixfunctions / matrixsquareroot . h , line <number> . process finished with exit code <number> ( interrupted by signal <number> : sigabrt ) ` ` ` # # # workaround one option is to add a small regularizing term to make it non - degenerate , but i do not ( yet ) know how to do this such that it always prevents the crash , and also does not significantly affect results then the matrix - square - root would have worked . instead , i now just use the denmann - beavers iteration to approximate the matrix square - root ` ` ` def tf_denmann_beavers_sqrtm ( matrix : tf . tensor , n_iter = <number> <sad> "" "" "" approximate the matrix - square - root by denmann beavers iteration <url> convergence is not guaranteed . use at your own risk this is handy for tflite , which does not yet support tf . linalg . sqrtm <url> or for regular tensorflow , which crashes your entire program when input matrix is degenerate <url> "" "" "" ym = matrix zm = tf . eye ( tf . shape ( matrix [ <number> ] ) [ <number> ] , dtype = matrix . dtype ) for i in range ( n_iter ) = <number> * ( ym + tf . linalg . inv ( zm ) ) zm = <number> * ( zm + tf . linalg . inv ( ym ) ) ym = ym_ return ym ` ` ` . <repeated> obviously this is not ideal .",0
tensorflow/tensorflow,"model . fit ( ) occur "" cudnn graph failed to build : unknown : cudnn_status_bad_param "" # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> , <number> , <number> # # # custom code yes # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> / <number> & <number> / <number> . <number> # # # gpu model and memory rtx <number> ti & rtx <number> # # # current behavior ? this is first time experience to have such error message . when i try "" model . fit ( ) "" server stops with error message below tried cudnn version <number> ( as [ tensorflow . org ] ( <url> ) and <number> . <number> ( lateset for cuda <number> ) both have problem . how can i solve the issue ? thanks # # # standalone code to reproduce the issue ` ` ` shell gpu_id = "" <number> "" # <number> or <number> import os os . environ [ "" cuda_visible_devices "" ] = gpu_id import tensorflow as tf import tensorflow . keras as keras import tensorflow . keras . layers as layers import tensorflow . keras . models as models size_y = <number> size_x = <number> # - - - load dataset dic_path = ' . / seg_dataset / train / dic ' msk_path = ' . / seg_dataset / train / msk ' seed = <number> # random number in your mind dic_datagen = keras . preprocessing . image . imagedatagenerator ( rescale = <number> . / <number> , validation_split = <number> ) msk_datagen = keras . preprocessing . image . imagedatagenerator ( rescale = <number> . / <number> , validation_split = <number> ) dic_train = \ \ dic_datagen . flow_from_directory ( dic_path , target_size =( size_y , size_x ) , class_mode = none , seed = seed , subset = ' training ' ) msk_train = \ \ msk_datagen . flow_from_directory ( msk_path , target_size =( size_y , size_x ) , class_mode = none , color_mode = ' grayscale ' , seed = seed , subset = ' training ' ) dic_valid = \ \ dic_datagen . flow_from_directory ( dic_path , target_size =( size_y , size_x ) , class_mode = none , seed = seed , subset = ' validation ' ) msk_valid = \ \ msk_datagen . flow_from_directory ( msk_path , target_size =( size_y , size_x ) , class_mode = none , color_mode = ' grayscale ' , seed = seed , subset = ' validation ' ) train_ds = zip ( dic_train , msk_train ) valid_ds = zip ( dic_valid , msk_valid ) f = [ <number> , <number> , <number> , <number> , <number> ] kernel_size =( <number> ) padding = ' same ' strides = <number> # number of filters at each level inputs = layers . input ( ( size_y , size_x , <number> ) ) p0 = inputs # downblock <number> x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" ) ( p0 ) c1 = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) x = layers . maxpool2d ( ( <number> , <number> ) , ( <number> , <number> ) ) ( c1 ) # downblock <number> x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) c2 = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) x = layers . maxpool2d ( ( <number> , <number> ) , ( <number> , <number> ) ) ( c2 ) # downblock <number> x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) c3 = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) x = layers . maxpool2d ( ( <number> , <number> ) , ( <number> , <number> ) ) ( c3 ) # downblock <number> x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) c4 = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) x = layers . maxpool2d ( ( <number> , <number> ) , ( <number> , <number> ) ) ( c4 ) # bottle neck x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) # up block <number> x = layers . upsampling2d ( ( <number> , <number> ))(x ) concat = layers . concatenate ( )([x , c4 ] ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" ) ( concat ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) # up block <number> x = layers . upsampling2d ( ( <number> , <number> ))(x ) concat = layers . concatenate ( )([x , c3 ] ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" ) ( concat ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) # up block <number> x = layers . upsampling2d ( ( <number> , <number> ))(x ) concat = layers . concatenate ( )([x , c2 ] ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" ) ( concat ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) # up block <number> x = layers . upsampling2d ( ( <number> , <number> ))(x ) concat = layers . concatenate ( )([x , c1 ] ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" ) ( concat ) x = layers . conv2d ( <number> , kernel_size , padding = padding , strides = strides , activation = "" relu "" )(x ) # last convolution 1 x1 outputs = layers . conv2d ( <number> , ( <number> , <number> ) , padding = "" same "" , activation = "" sigmoid "" )(x ) model = models . model ( inputs , outputs ) model . compile ( optimizer = ' adam ' , loss = ' binary_crossentropy ' , metrics =[ ' accuracy ' ] ) path_checkpoint = ' . / seg_checkpoint ' os . makedirs ( path_checkpoint , exist_ok = true ) model_checkpointer = keras . callbacks . modelcheckpoint ( filepath = path_checkpoint , save_weights_only = true , monitor = ' val_loss ' , mode = ' min ' , save_best_only = true , verbose = <number> ) # - - - additional callbacks = [ model_checkpointer , keras . callbacks . earlystopping ( patience = <number> * <number> , monitor = ' val_loss ' , mode = ' min ' , verbose = <number> ) , ] # - - - train start epoch = <number> history = model . fit ( train_ds , validation_data = valid_ds , validation_steps = <number> , # total number of steps ( batches of samples ) # to draw before stopping when performing validation at the end of every epoch . batch_size = <number> , steps_per_epoch = <number> , epochs = epoch , callbacks = callbacks ) ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : e tensorflow / compiler / xla / stream_executor / cuda / cuda_dnn . cc : <number> ] unable to register cudnn factory : attempting to register factory for plugin cudnn when one has already been registered <number> - <number> - <number> <time> . <number> : e tensorflow / compiler / xla / stream_executor / cuda / cuda_fft . cc : <number> ] unable to register cufft factory : attempting to register factory for plugin cufft when one has already been registered <number> - <number> - <number> <time> . <number> : e tensorflow / compiler / xla / stream_executor / cuda / cuda_blas . cc : <number> ] unable to register cublas factory : attempting to register factory for plugin cublas when one has already been registered <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized to use available cpu instructions in performance - critical operations . to enable the following instructions : avx2 fma , in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : w tensorflow / compiler / tf2tensorrt / utils / py_utils . cc : <number> ] tf - trt warning : could not find tensorrt warning : tensorflow : from / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / tensorflow / python / ops / distributions / distribution . py : <number> : reparameterizationtype . __init__ ( from tensorflow . python . ops . distributions . distribution ) is deprecated and will be removed after <number> - <number> - <number> . instructions for updating : the tensorflow distributions library has moved to tensorflow probability ( <url> you should update all references to use ` tfp . distributions ` instead of ` tf . distributions ` . warning : tensorflow : from / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / tensorflow / python / ops / distributions / bernoulli . py : <number> : registerkl . __init__ ( from tensorflow . python . ops . distributions . kullback_leibler ) is deprecated and will be removed after <number> - <number> - <number> . instructions for updating : the tensorflow distributions library has moved to tensorflow probability ( <url> you should update all references to use ` tfp . distributions ` instead of ` tf . distributions ` . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / direct_session . cc : <number> ] device mapping : / job : localhost / replica : <number> / task : <number> / device : gpu : <number> - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> found <number> images belonging to <number> classes . found <number> images belonging to <number> classes . found <number> images belonging to <number> classes . found <number> images belonging to <number> classes . <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero . see more at <url> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created device / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory : - > device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> epoch <number> / <number> <number> - <number> - <number> <time> . <number> : i tensorflow / compiler / xla / stream_executor / cuda / cuda_dnn . cc : <number> ] loaded cudnn version <number> <number> - <number> - <number> <time> . <number> : w tensorflow / core / framework / op_kernel . cc : <number> ] op_requires failed at conv_ops_fused_impl . h : <number> : internal : cudnn graph failed to build : unknown : cudnn_status_bad_param in tensorflow / compiler / xla / stream_executor / cuda / cuda_dnn . cc ( <number> <sad> ' conv_op ' cudnn_backend_operation : cudnnfinalize failed traceback ( most recent call last ) : file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / tensorflow / python / eager / execute . py "" , line <number> , in quick_execute tensors = pywrap_tfe . tfe_py_execute ( ctx . _handle , device_name , op_name , tensorflow . python . framework . errors_impl . internalerror : graph execution error : detected at node model / conv2d / relu defined at ( most recent call last ) : file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / layers / convolutional / base_conv . py "" , line <number> , in call return self . activation ( outputs ) file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / layers / convolutional / base_conv . py "" , line <number> , in call return self . activation ( outputs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / activations . py "" , line <number> , in relu return backend . relu ( file "" / home / bootcamp / train_unet . py "" , line <number> , in <module> history = model . fit ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in fit tmp_logs = self . train_function ( iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function return step_function ( self , iterator ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step y_pred = self ( x , training = true ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in __call__ return super ( ) . __call__ ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in call return self . _run_internal_graph ( inputs , training = training , mask = mask ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / functional . py "" , line <number> , in _run_internal_graph outputs = node . layer ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / engine / base_layer . py "" , line <number> , in __call__ outputs = call_fn ( inputs , * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler return fn ( * args , * * kwargs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / layers / convolutional / base_conv . py "" , line <number> , in call return self . activation ( outputs ) file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / activations . py "" , line <number> , in relu return backend . relu ( file "" / home / bootcamp / miniconda3 / envs / tf / lib / python3 . <number> / site - packages / keras / src / backend . py "" , line <number> , in relu x = tf . nn . relu ( x ) cudnn graph failed to build : unknown : cudnn_status_bad_param in tensorflow / compiler / xla / stream_executor / cuda / cuda_dnn . cc ( <number> <sad> ' conv_op ' cudnn_backend_operation failed [ [ { { node model / conv2d / relu } } ] ] [ op : __inference_train_function_4359 ] ` ` `",0
tensorflow/tensorflow,"onednn logs are not printing while building tf with - - config = mkl_aarch64 # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution ubuntu <number> . <number> lts # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version <number> # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i am expecting onednn logs should print while running deep learning model such as resnet50 , if we export onednn_verbose = <number> # # # standalone code to reproduce the issue ` ` ` shell to reproduce same , we have to build tf on arm cpu , and use following command to build build - - config = mkl_aarch64 / / tensorflow / tools / pip_package : build_pip_package ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,""" valueerror : cannot take the length of shape with unknown rank . "" when using multiheadrelativeattention # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution mac m2 pro # # # mobile device mac m2 pro # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? when using multiheadrelativeattention from official . nlp . modeling . layers , i face on this error , "" valueerror : cannot take the length of shape with unknown rank . "" i am sorry i am not good at english . thank you # # # standalone code to reproduce the issue ` ` ` shell from official . nlp . modeling . layers import multiheadrelativeattention import tensorflow as tf vec = tf . constant ( [ [ [ [ <number> ]* <number> ]* <number> ]* <number> ] ) layers = multiheadrelativeattention ( num_heads = <number> , key_dim = <number> ) output = layers ( vec , vec , content_attention_bias = <number> , positional_attention_bias = <number> ) ` ` ` # # # relevant log output ` ` ` shell valueerror take the length of shape with unknown rank . ` ` `",0
tensorflow/tensorflow,"unable to save model when using efficientnetb0 # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i ’ m trying to use efficientnetb0 to create a model and save the model to my local disk . however , when saving it , it throws the error below . > typeerror : unable to serialize [ <number> <number> <number> ] to json . unrecognized type < class ' tensorflow . python . framework . ops . eagertensor ' > . also , i tried to downgrade tensorflow from v2 . <number> to v2 . <number> , this works as expected . in other words , this is a bug in <number> . <number> . hope it helps and please fix this bug for v2 . <number> # # # standalone code to reproduce the issue ` ` ` shell model = tf . keras . applications . efficientnetb0 ( ) model . save ( "" model "" ) ` ` ` # # # relevant log output ` ` ` shell typeerror to serialize [ <number> <number> <number> ] to json . unrecognized type < class ' tensorflow . python . framework . ops . eagertensor ' > . ` ` `",0
tensorflow/tensorflow,"tflite error * * system information * * - os platform and distribution ( e . g . , linux ubuntu <number> ) : windows <number> - tensorflow installed from ( source or binary ) : source - tensorflow version ( or github sha if from source ) : <number> . <number> * * provide the text output from tflite_convert * * the below is the code , i am using to convert the deep learning model to tflite converter = tf . lite . tfliteconverter . from_keras_model ( best_model ) converter . target_spec . supported_ops = [ tf . lite . opsset . tflite_builtins , tf . lite . opsset . select_tf_ops ] tflite_model = converter . convert ( ) with open ( ' compressed_model . tflite ' , ' wb ' ) as f * * standalone code to reproduce the issue * * provide a reproducible test case that is the bare minimum necessary to generate the problem . if possible , please share a link to colab / jupyter / any notebook . <url> [ error ] ( <url>",0
tensorflow/tensorflow,"tensorflow load datasets failure for python <number> . <number> and tensorflow <number> . <number> # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution rocky linux <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> / <number> . <number> - <number> # # # gpu model and memory _no response_ # # # current behavior ? dataset written and loaded in python <number> . <number> and tensorflow <number> . <number> should load in tensorflow <number> however , loading dataset in tensorflow <number> with python <number> . <number> fails on linux and windows : tensorflow version : <number> . <number> python version : <number> . <number> download dev dataset . <repeated> extract dev dataset . <repeated> loading dev dataset . <repeated> [ libprotobuf error external / com_google_protobuf / src / google / protobuf / text_format . cc : <number> ] error parsing text - format tensorflow . data . experimental . distributedsnapshotmetadata : <number> : <number> : invalid control characters encountered in text . [ libprotobuf error external / com_google_protobuf / src / google / protobuf / text_format . cc : <number> ] error parsing text - format tensorflow . data . experimental . distributedsnapshotmetadata : <number> : <number> : expected identifier , got : <number> download train dataset . <repeated> extract train dataset . <repeated> loading train dataset . <repeated> [ libprotobuf error external / com_google_protobuf / src / google / protobuf / text_format . cc : <number> ] error parsing text - format tensorflow . data . experimental . distributedsnapshotmetadata : <number> : <number> : invalid control characters encountered in text . [ libprotobuf error external / com_google_protobuf / src / google / protobuf / text_format . cc : <number> ] error parsing text - format tensorflow . data . experimental . distributedsnapshotmetadata : <number> : <number> : expected identifier , got # # # standalone code to reproduce the issue ` ` ` shell import io import sys from zipfile import zipfile import requests import tensorflow as tf print ( "" tensorflow version :"", tf . __version__ ) print ( "" python version :"", sys . version . split ( ) [ <number> ] ) dev_url = ( "" <url> ) print ( "" download dev dataset . <repeated> "" ) r = requests . get ( dev_url ) z = zipfile ( io . bytesio ( r . content ) ) print ( "" extract dev dataset . <repeated> "" ) z . extractall ( ) print ( "" \ \ nloading dev dataset . <repeated> "" ) ds_dev = tf . data . dataset . load ( "" squadv2_dev_tf "" ) train_url = ( "" <url> ) print ( "" download train dataset . <repeated> "" ) r = requests . get ( train_url ) z = zipfile ( io . bytesio ( r . content ) ) print ( "" extract train dataset . <repeated> "" ) z . extractall ( ) print ( "" \ \ nloading train dataset . <repeated> "" ) ds_train = tf . data . dataset . load ( "" squadv2_train_tf "" ) ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"tensorflow / core / common_runtime / gpu / gpu_util . cc : <number> ] gpu - > cpu memcpy failed # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution windows # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda version = <number> cudnn = <number> . <number> _no response_ # # # gpu model and memory geforce rtx <number> ti <number> gb _no response_ # # # current behavior ? i am using gpu geforce rtx <number> ti <number> gb i add in my training file config1 = tf . compat . v1 . configproto ( ) config1 . gpu_options . allow_growth = true session = tf . compat . v1 . session ( config = config1 ) but nothing happen i get this issue # # # standalone code to reproduce the issue ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cudart64_100 . dll <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cublas64_100 . dll <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cufft64_100 . dll <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library curand64_100 . dll <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cusolver64_100 . dll <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cusparse64_100 . dll <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cudnn64_7 . dll <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] adding visible gpu devices : <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] device interconnect streamexecutor with strength <number> edge matrix : <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] <number> <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] <number> : n <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] created tensorflow device ( / job : localhost / replica : <number> / task : <number> / device : gpu : <number> with <number> mb memory ) - > physical gpu ( device : <number> , name : nvidia geforce rtx <number> ti , pci bus id : <number> <time> . <number> , compute capability : <number> ) warning : tensorflow : from c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ backend \ \ tensorflow_backend . py : <number> : the name tf . global_variables is deprecated . please use tf . compat . v1 . global_variables instead . warning : tensorflow : from c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ backend \ \ tensorflow_backend . py : <number> : the name tf . variables_initializer is deprecated . please use tf . compat . v1 . variables_initializer instead . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cudnn64_7 . dll <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / cuda / redzone_allocator . cc : <number> ] internal : invoking ptxas not supported on windows relying on driver to perform ptx compilation . this message will be only logged once . <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] successfully opened dynamic library cublas64_100 . dll <number> - <number> - <number> <time> . <number> : e tensorflow / stream_executor / cuda / cuda_blas . cc : <number> ] failed to run cublas routine : cublas_status_execution_failed exception : blas gemm launch failed : a . shape =( <number> , <number> ) , b . shape =( <number> , <number> ) , m = <number> , n = <number> , k = <number> [ [ node gradients_1 / dense_regress_10 / matmul_grad / matmul_1 ( defined at c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ ops . py : <number> ) ] ] original stack trace for ' gradients_1 / dense_regress_10 / matmul_grad / matmul_1 ' : file "" c <annoyed> users / user / desktop / binarios / keras_frcnn - master - atelier - b / keras_frcnn - master / train_frcnn_kitti . py "" , line <number> , in <module> train_kitti ( ) file "" c <annoyed> users / user / desktop / binarios / keras_frcnn - master - atelier - b / keras_frcnn - master / train_frcnn_kitti . py "" , line <number> , in train_kitti [ y1 [ :, sel_samples , <happy> , y2 [ :, sel_samples , :]]) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in train_on_batch self . _make_train_function ( ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ engine \ \ training . py "" , line <number> , in _make_train_function self . total_loss ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ optimizers . py "" , line <number> , in get_updates grads = self . get_gradients ( loss , params ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ optimizers . py "" , line <number> , in get_gradients grads = k . gradients ( loss , params ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ backend \ \ tensorflow_backend . py "" , line <number> , in gradients return tf . gradients ( loss , variables , colocate_gradients_with_ops = true ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ gradients_impl . py "" , line <number> , in gradients unconnected_gradients ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ gradients_util . py "" , line <number> , in _gradientshelper lambda : grad_fn ( op , * out_grads ) ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ gradients_util . py "" , line <number> , in _maybecompile return grad_fn ( ) # exit early file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ gradients_util . py "" , line <number> , in <lambda> lambda : grad_fn ( op , * out_grads ) ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ math_grad . py "" , line <number> , in _matmulgrad grad_b = gen_math_ops . mat_mul ( a , grad , transpose_a = true ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ gen_math_ops . py "" , line <number> , in mat_mul name = name ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ op_def_library . py "" , line <number> , in _apply_op_helper op_def = op_def ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ util \ \ deprecation . py "" , line <number> , in new_func return func ( * args , * * kwargs ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ ops . py "" , line <number> , in create_op attrs , op_def , compute_device ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ ops . py "" , line <number> , in _create_op_internal op_def = op_def ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ ops . py "" , line <number> , in __init__ self . _traceback = tf_stack . extract_stack ( ) . <repeated> which was originally created as op ' dense_regress_10 / matmul ' , defined at : file "" c <annoyed> users / user / desktop / binarios / keras_frcnn - master - atelier - b / keras_frcnn - master / train_frcnn_kitti . py "" , line <number> , in <module> train_kitti ( ) file "" c <annoyed> users / user / desktop / binarios / keras_frcnn - master - atelier - b / keras_frcnn - master / train_frcnn_kitti . py "" , line <number> , in train_kitti classifier = nn . classifier ( shared_layers , roi_input , cfg . num_rois , nb_classes = len ( classes_count ) , trainable = true ) file "" c :\\ users \ \ user \ \ desktop \ \ binarios \ \ keras_frcnn - master - atelier - b \ \ keras_frcnn - master \ \ keras_frcnn \ \ resnet . py "" , line <number> , in classifier name = ' dense_regress_ { } ' . format ( nb_classes ) ) ( out ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ engine \ \ topology . py "" , line <number> , in __call__ output = self . call ( inputs , * * kwargs ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ layers \ \ wrappers . py "" , line <number> , in call y = self . layer . call ( inputs ) # ( num_samples * timesteps , . <repeated> ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ layers \ \ core . py "" , line <number> , in call output = k . dot ( inputs , self . kernel ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ keras \ \ backend \ \ tensorflow_backend . py "" , line <number> , in dot out = tf . matmul ( x , y ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ util \ \ dispatch . py "" , line <number> , in wrapper return target ( * args , * * kwargs ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ math_ops . py "" , line <number> , in matmul a , b , transpose_a = transpose_a , transpose_b = transpose_b , name = name ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ ops \ \ gen_math_ops . py "" , line <number> , in mat_mul name = name ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ op_def_library . py "" , line <number> , in _apply_op_helper op_def = op_def ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ util \ \ deprecation . py "" , line <number> , in new_func return func ( * args , * * kwargs ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ ops . py "" , line <number> , in create_op attrs , op_def , compute_device ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ ops . py "" , line <number> , in _create_op_internal op_def = op_def ) file "" c :\\ users \ \ user \ \ appdata \ \ roaming \ \ python \ \ python37 \ \ site - packages \ \ tensorflow_core \ \ python \ \ framework \ \ ops . py "" , line <number> , in __init__ self . _traceback = tf_stack . extract_stack ( ) <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / stream . cc : <number> ] [ stream = 0 0 0 0 0 2 9 efe927ec0 , impl = 0 0 0 0 0 2 9 eb937cfb0 ] did not wait for [ stream = 0 0 0 0 0 2 9 efe926cc0 , impl = 0 0 0 0 0 2 9 eb937cf20 ] <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / stream . cc : <number> ] [ stream = 0 0 0 0 0 2 9 efe927ec0 , impl = 0 0 0 0 0 2 9 eb937cfb0 ] did not memcpy device - to - host ; source : 0 0 0 0 0 0 0 7 1 2 9 b6500 <number> - <number> - <number> <time> . <number> : f tensorflow / core / common_runtime / gpu / gpu_util . cc : <number> ] gpu - > cpu memcpy failed <number> - <number> - <number> <time> . <number> tensorflow / stream_executor / stream . cc : <number> ] [ stream = 0 0 0 0 0 2 9 efe927ec0 , impl = 0 0 0 0 0 2 9 eb937cfb0 ] did not wait for [ stream = 0 0 0 0 0 2 9 efe926cc0 , impl = 0 0 0 0 0 2 9 eb937cf20 ] ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"kerastensor和tf . tensor之间的转换 # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf2 . <number> # # # custom code yes # # # os platform and distribution window10 # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? kerastensor没有numpy （ ） 这种 ， 应该如何转换 # # # standalone code to reproduce the issue ` ` ` shell file "" c <annoyed> users / km group / desktop / lmx / semanticcompression - speech / deepsc - s - main / random_mask_training . py "" , line <number> , in <module> sem_dec = sem_dec_model ( frame_length , stride_length , args ) file "" c :\\ users \ \ km group \ \ desktop \ \ lmx \ \ semanticcompression - speech \ \ deepsc - s - main \ \ model_tfnn . py "" , line <number> , in sem_dec_model _output = sem_dec ( _intput , batch_mean , batch_var ) file "" c :\\ users \ \ km group \ \ desktop \ \ lmx \ \ semanticcompression - speech \ \ deepsc - s - main \ \ model_tfnn . py "" , line <number> , in __call__ _input = tf . convert_to_tensor ( keras . backend . get_value ( _input ) ) file "" c :\\ users \ \ km group \ \ anaconda3 \ \ envs \ \ speech - sc \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ keras \ \ backend . py "" , line <number> , in get_value return x . numpy ( ) attributeerror object has no attribute ' numpy ' ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"tensorflow keras model . predict ( ) is not thread safe # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source binary # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution linux centos <number> # # # mobile device _no response_ # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? we executed model . predict ( ) in multi - thread . and sometimes , the code raised the exception : functional ' object has no attribute ' predict_function . # # # standalone code to reproduce the issue ` ` ` shell def predict ( self , x , tf_server = false , port = <number> , model_path = ' ' , step = <number> <sad> if tf_server : return self . predict_tf_server_grpc ( x , port , step ) pred = none try : if not self . model_trained : print ( ' try to load model . <repeated> \ \ n ' ) self . load_model ( model_path ) self . model_trained = true if step = = <number> : pred = self . model . predict ( x ) else : pred = self . model . predict ( x , steps = step ) except exception as ex return pred ` ` ` while the exception raised , we executed the code "" self . model . predict ( x ) "" in debug window again , and it returned the correct prediction results . ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"` tf . image . decode_jpeg ` can not decode jpeg base64 encoded image # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution win11 2 2 h2 # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? it raise : ` invalidargumenterror __wrapped__decodejpeg_device_ / job : localhost / replica : <number> / task : <number> / device : cpu : <number> } } unknown image file format . one of jpeg , png , gif , bmp required . [ op : decodejpeg ] ` [ image ] ( <url> ! [ image ] ( <url> # # # standalone code to reproduce the issue ` ` ` shell import base64 from pil import image import tensorflow as tf img = image . open ( ' x <elongated> . jpg ' ) base64str = base64 . b64encode ( img . tobytes ( ) ) . decode ( ) tf . image . decode_jpeg ( base64str , channels = <number> ) ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"tensor dimension mismatch when ` tf . keras . input ` is used as input # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> linux ubuntu <number> - tensorflow installation ( pip package or built from source ) : pip - tensorflow library ( version , if pip package or github sha , if built from source ) : <number> . <number> - dev20230602 # # # <number> . code this is the minimized code to reproduce the issue : ` ` ` python import tensorflow as tf import numpy as np input_shape = [ <number> , <number> ] x1 = tf . keras . input ( shape = input_shape , dtype = "" float32 "" ) class model ( tf . keras . model ) : def __init__ ( self ) : super ( model , self ) . __init__ ( ) self . w1 = tf . variable ( [ [ <number> . , <number> . ] , [ <number> . , <number> . ] ] ) self . b1 = tf . variable ( [ <number> . , <number> . ] ) <user> . function ( input_signature =[ tf . tensorspec ( x1 . shape , x1 . dtype ) ] ) def call ( self , x1 ) : return tf . matmul ( x1 , self . w1 ) + self . b1 m = model ( ) converter = tf . lite . tfliteconverter . from_keras_model ( m ) tflite_model = converter . convert ( ) def _evaluatetflitemodel ( tflite_model , input_data ) : interpreter = tf . lite . interpreter ( model_content = tflite_model ) interpreter . allocate_tensors ( ) input_details = interpreter . get_input_details ( ) output_details = interpreter . get_output_details ( ) print ( f ' keras input shape : { input_data [ <number> ] . shape } ' ) # print keras input shape print ( f ' lite input shape : { input_details [ <number> ] [ "" shape "" ] } ' ) # print lite input shape for i in range ( len ( input_data ) <sad> interpreter . set_tensor ( input_details [ i ] [ ' index ' ] , input_data [ i ] ) interpreter . invoke ( ) output_data = [ interpreter . get_tensor ( output_details [ i ] [ ' index ' ] ) for i in range ( len ( output_details ) ) ] return output_data x = tf . constant ( [ <number> . , <number> . ] , shape = input_shape ) actual_value = _evaluatetflitemodel ( tflite_model , [x ] ) ` ` ` # # # <number> . failure after conversion output ` ` ` keras input shape : ( <number> , <number> ) lite input shape : [ <number> <number> <number> ] ` ` ` error message : ` ` ` valueerror : cannot set tensor mismatch . got <number> but expected <number> for input <number> . ` ` `",0
tensorflow/tensorflow,"tflite running interpreter - > invoke ( ) has failed - segmentation fault in tflite , i wrote a custom delegate in c + + and encountered an error fault "" . this error occurs after the initialization is complete and specifically after the invocation of interpreter - > invoke ( ) . the custom delegate ' s prepare function is executed , but the eva function is not executed .",0
tensorflow/tensorflow,"typeerror : _lookup_dependency ( ) takes <number> positional arguments but <number> were given # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> - dev20230712 # # # custom code yes # # # os platform and distribution linux moe <number> . <number> - <number> - amd64 # <number> smp debian <date> - <number> ( <number> - <number> - <number> ) x86_64 gnu / linux # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? can not load saved model # # # standalone code to reproduce the issue ` ` ` shell saved models can not be loaded : model = tf . keras . models . sequential ( [ tf . keras . layers . input ( ( <number> , <number> ) ) , tf . keras . layers . dense ( <number> ) ] ) model . save ( "" . <repeated> / models / test "" ) model = tf . keras . models . load_model ( "" . <repeated> / models / test / "" ) ` ` ` same thing with more complex models ` ` ` model = tf . keras . applications . efficientnet . efficientnetb0 ( ) model . save ( "" . <repeated> / models / test "" ) model = tf . keras . models . load_model ( "" . <repeated> / models / test / "" ) ` ` ` ` ` ` # # # relevant log output ` ` ` shell - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - typeerror traceback ( most recent call last ) cell in [ <number> ] , line <number> - - - - > <number> model = tf . keras . models . load_model ( "" . <repeated> / models / test / "" ) file ~ / . local / lib / python3 . <number> / site - packages / keras / src / saving / saving_api . py : <number> , in load_model ( filepath , custom_objects , compile , safe_mode , * * kwargs ) <number> return saving_lib . load_model ( <number> filepath , <number> custom_objects = custom_objects , <number> compile = compile , <number> safe_mode = safe_mode , <number> ) <number> # legacy case . - - > <number> return legacy_sm_saving_lib . load_model ( <number> filepath , custom_objects = custom_objects , compile = compile , * * kwargs <number> ) file ~ / . local / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py : <number> , in filter_traceback . <locals> . error_handler ( * args , * * kwargs ) <number> filtered_tb = _process_traceback_frames ( e . __traceback__ ) <number> # to get the full stack trace , call : <number> # ` tf . debugging . disable_traceback_filtering ( ) ` - - - > <number> raise e . with_traceback ( filtered_tb ) from none <number> finally : <number> del filtered_tb file ~ / . local / lib / python3 . <number> / site - packages / tensorflow / python / checkpoint / restore . py : <number> , in _queue_children_for_restoration ( checkpoint_position , visit_queue ) <number> continue <number> child_position = checkpoint_position . create_child_position ( child . node_id ) - - > <number> local_object = trackable . _lookup_dependency ( child . local_name , <number> trackable_children ) <number> child_proto = child_position . object_proto <number> if local_object is none : <number> # we do not yet have a dependency registered with this name . save it <number> # in case we do . typeerror takes <number> positional arguments but <number> were given ` ` `",0
tensorflow/tensorflow,"importerror : libcudart . so . <number> : cannot open shared object file : no such file or directory # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version nvcc - - version gives <number> nvidia - smi gives cuda version : <number> # # # gpu model and memory _no response_ # # # current behavior ? importerror : libcudart . so . <number> : cannot open shared object file : no such file or directory # # # standalone code to reproduce the issue ` ` ` shell this error occured when i imported tensorflow import tensorflow as tf to resolve this issue i have set my $ cuda_home <annoyed> usr / lib / cuda / and $ ld_library_path = usr / lib / cuda / lib64 but surprisingly usr / lib / cuda / lib64 is empty . i dont have cuda folder in usr / local directory . ` ` ` # # # relevant log output ` ` ` shell traceback ( most recent call last ) : file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / python / __init__ . py "" , line <number> , in <module> from tensorflow . python import pywrap_tensorflow file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / python / pywrap_tensorflow . py "" , line <number> , in <module> _pywrap_tensorflow = swig_import_helper ( ) file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / python / pywrap_tensorflow . py "" , line <number> , in swig_import_helper _mod = imp . load_module ( ' _pywrap_tensorflow ' , fp , pathname , description ) file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / imp . py "" , line <number> , in load_module return load_dynamic ( name , filename , file ) file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / imp . py "" , line <number> , in load_dynamic return _load ( spec ) importerror : libcudart . so . <number> : cannot open shared object file : no such file or directory during handling of the above exception , another exception occurred : traceback ( most recent call last ) : file "" <stdin> "" , line <number> , in <module> file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / __init__ . py "" , line <number> , in <module> from tensorflow . python import * file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / python / __init__ . py "" , line <number> , in <module> raise importerror ( msg ) importerror : traceback ( most recent call last ) : file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / python / __init__ . py "" , line <number> , in <module> from tensorflow . python import pywrap_tensorflow file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / python / pywrap_tensorflow . py "" , line <number> , in <module> _pywrap_tensorflow = swig_import_helper ( ) file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / site - packages / tensorflow / python / pywrap_tensorflow . py "" , line <number> , in swig_import_helper _mod = imp . load_module ( ' _pywrap_tensorflow ' , fp , pathname , description ) file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / imp . py "" , line <number> , in load_module return load_dynamic ( name , filename , file ) file "" / home / nkaushal / anaconda3 / envs / lipnet3 . <number> / lib / python3 . <number> / imp . py "" , line <number> , in load_dynamic return _load ( spec ) importerror : libcudart . so . <number> : cannot open shared object file such file or directory failed to load the native tensorflow runtime . see <url> for some common reasons and solutions . include the entire stack trace above this error message when asking for help . ` ` `",0
tensorflow/tensorflow,"different reference order may cause other modules to be unavailable , e . g . xgboost , sklearn . # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution centos <number> # # # mobile device _no response_ # # # python version python <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda = <number> # # # gpu model and memory 3 2 5 1 0 mib # # # current behavior ? i was trying to import xgboost ( or sklearn ) and tensorflow modules at same time , but when i imported modules by different order , it just return me error message that i can not handle it , i do not whether it a bug or some issues that can be fixed by myself ? and i also search something resource , which said that it was a bug caused by glibc : <url> and then i was trying to reintstall glibc on my server , unfortunately , the plan finally failed and now i am just trying to rebuild my whole environment by rollbacking to previous mirror backup , sad . # # # standalone code to reproduce the issue ` ` ` shell import numpy as np # # bad import order import tensorflow as tf from xgboost import xgbclassifier # # order # or import sklearn , may report different error messages . # # good import order # from xgboost import xgbclassifier # import tensorflow as tf hparams = { ' booster ' : ' gbtree ' , ' objective ' : ' binary : logistic ' , ' eval_metric ' : ' aucpr ' , ' max_depth ' : <number> , ' gamma ' : <number> , ' lambda ' : <number> , ' subsample ' : <number> , ' colsample_bytree ' : <number> , ' colsample_bylevel ' : <number> , ' colsample_bynode ' : <number> , ' min_child_weight ' : <number> , ' eta ' : <number> , ' seed ' : <number> , ' nthread ' : <number> , ' tree_method ' : ' gpu_hist ' , ' n_estimators ' : <number> } estimator = xgbclassifier ( * * hparams ) x_train = np . random . rand ( <number> , <number> ) y_train = np . random . randint ( <number> , <number> , ( <number> , <number> ) ) x_eval = np . random . rand ( <number> , <number> ) y_eval = np . random . randint ( <number> , <number> , ( <number> , <number> ) ) estimator . fit ( x_train , y_train , eval_set =[( x_train , y_train ) , (x _eval , y_eval ) ] ) ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 avx512f fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . traceback ( most recent call last ) : file "" / home / haojiaxiang / projects / test / test . py "" , line <number> , in <module> from xgboost import xgbclassifier # # order # or import sklearn , may report different error messages . file "" / home / haojiaxiang / miniconda3 / envs / gms / lib / python3 . <number> / site - packages / xgboost / __init__ . py "" , line <number> , in <module> from . import collective , dask , rabit file "" / home / haojiaxiang / miniconda3 / envs / gms / lib / python3 . <number> / site - packages / xgboost / collective . py "" , line <number> , in <module> from . core import _lib , _check_call , c_str , py_str , from_pystr_to_cstr file "" / home / haojiaxiang / miniconda3 / envs / gms / lib / python3 . <number> / site - packages / xgboost / core . py "" , line <number> , in <module> _lib = _load_lib ( ) file "" / home / haojiaxiang / miniconda3 / envs / gms / lib / python3 . <number> / site - packages / xgboost / core . py "" , line <number> , in _load_lib raise xgboosterror ( xgboost . core . xgboosterror : xgboost library ( libxgboost . so ) could not be loaded . likely causes : * openmp runtime is not installed - vcomp140 . dll or libgomp - <number> . dll for windows - libomp . dylib for mac osx - libgomp . so for linux and other unix - like oses mac osx users : run ` brew install libomp ` to install openmp runtime . * you are running <number> - bit python on a <number> - bit os error message ( s ) : [ ' dlopen load any more object with static tls ' ] ` ` `",0
tensorflow/tensorflow,"memory out of bounds in compiled tflite with emscripten . # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i have compiled tflite using cmake ( without xnnpack support ) and emscripten ( both latest <date> and <date> ) . when trying to perform inference at the browser with my model i get the following error : vmt . wasm :0 x31cff uncaught runtimeerror : memory access out of bounds at vmt . wasm :0 x31cff at vmt . wasm :0 x1f7a94 at vmt . wasm :0 x3 c4910 at vmt . wasm :0 x65ace at vmt . wasm :0 x231c3e at vmt . wasm :0 x458a49 at vmt . wasm :0 x517c60 at img . onload ( index . html : <number> <time> ) this happens with all of my models at the very first operation ( pad ) . when inspecting the . wasm file using chrome dev tools i see that the error happens at a "" memory . fill "" operation . # # # standalone code to reproduce the issue ` ` ` shell i have compiled tflite with the following emcmake command : cmake - dcmake_cxx_flags = "" - lpthread - pthread - lpthread - s use_pthreads "" - dtflite_enable_mmap = off - dtflite_enable_nnapi = off - dtflite_enable_ruy = on - dtflite_enable_xnnpack = off . <repeated> while when compiling my project with emscripten ( including the above resulting libraries ) i use the following flags : set ( cmake_cxx_flags "" ${ cmake_cxx_flags } - s initial_memory = 5 1 2 mb "" ) set ( cmake_cxx_flags "" ${ cmake_cxx_flags } - s allow_memory_growth = <number> "" ) set ( cmake_cxx_flags "" ${ cmake_cxx_flags } - s allow_table_growth = <number> "" ) ` ` ` # # # relevant log output ` ` ` shell this is the output of printinterpreterstate right before the first inference . [ wasm ] = = = pre - invoke interpreter state = = = pre - vmt . js : <number> [ wasm ] interpreter has <number> subgraphs . pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] - - - - - - - - - - - subgraph - <number> has <number> tensors and <number> nodes - - - - - - - - - - - - pre - vmt . js : <number> [ wasm ] <number> inputs : [ <number> ] - > 6 0 2 1 1 2 b ( <number> . 5 7 mb ) pre - vmt . js : <number> [ wasm ] <number> outputs : [ <number> ] - > 7 0 8 b ( <number> . 0 0 mb ) pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] tensor id name type alloctype size ( bytes / mb ) shape memaddr - offset pre - vmt . js : <number> [ wasm ] tensor <number>  � � ʻ  䯻9 : 󺂶 * 򨓮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 騅 : � � 񛻺 󿰻  � � m . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> r畼 � �  匹 � � t ; � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> jԑ ; � � 4 i ; ⦄ ; q  ;  箮 . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 究 򑃷 çc6ԯ <hashtag> 6 ߗ </hashtag>  < ׹ . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> <seallips> � � 𯫿 � � 7 tu � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ƙl � � <number> 򣡷  / 򷕈 <number> � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � � � 뻪 � � 3 z } � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ᡁ � � � � � � 땐6ԝ . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  􌶄 � � <number> ^ l 𷆄 򷳱 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � "" ۀ7 � � ce � � � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ģ pre - vmt . js : <number> [ wasm ] 7 c ^ j𐬣 𶓃 <number> 񪤷 ׾ . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � �  ȏ6띓 � � � � 8 h  . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � a 򪶚 윶 � � 䞏 � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ԙõ ` 򫷾 f <number> 򓕶 o 򙷳 c . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ū쵄 񉸻 罷 { \ \ ѵfw 𶯜 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  & ꋷ 𷏸 ᛸ6  � � ꮮ . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> | 㗶 񏍷 򛀷 � � \ \ y7   . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  蕷βu7 � � ` & ÷ 勸f + . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> w춃 ֣ 7 4 ٿ𣔝 � � � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ; "" <number> 򑶷 膷ڽ 𷞮 � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 󠼷 ypq � � � � � � <number>  <number> . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � 󰳳 ib } � � � � � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 򳤷 񲂷 w ް <number>  � � ^ <number> 􊮮 . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> _ � � m 󷟝 򵳂 󶬾 𼾮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> p � � & ; 𶿮 � � � � <number> # ׮ . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  � � <number> 񺉷 a ꨷ ᘑ � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 卞7 󯉷 򨮷 � � 󠚷 � � . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> fr 񷀃 󷴫 d � � � � � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 򺜵   w7 𽒷 񪶷 ̒ # � � ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> $ 뀷 � � r 𷸙 u  쭌7 󿮮 . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> \ \ ~ � � ط $ i 򷮼 <number> ҄ * 觮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � <number> � � 涂 񖷝  f5 � � . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ؉ h � � � � � � <number> ˜ 𶠺 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 󚫷 \ \   <number> ͛ $ ♩ � � <number> [  . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 9 x  � � � � � � � � � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> jť < 箯 󧬍 󘴙 ; љ & 󿈮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 􅻻 λ "" <  � � � � ?  < ɓ . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ޛȼx ׃ <  򁻝 ě < u + � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � ԍ 󼲍 ׹ 󵏼 ϩ � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ? ȑ 򄏱 ;3 d1 󞻳 � � ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> cһ ; � �   ٻ : 뼩攻ŷ . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> <number>   � � � � � � 򥅡 ;b . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> m ٚ < 啤 <  j  � � <number> | � � 쮮 . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ᦺ � � 򦖶 : 晼4櫻k  . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  轼 \ \  <  j4 < ӯ : 𡻻ug . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � ৐ � � 󶜿 󄲢 𠧮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � 񒘼 ѡj 󫈞 󭲐 <  � � ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>   ' � � � � 󼰛 � � 󋍮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  ` � � 𼢈  < 񗋻 ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ا "" 󖗽 򫋺 < 󀮹 ͑ x 󪁮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ȷk 󒏷 :  󁌝 � � 󦦮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> t =  򜧨 ; <number> 򌼾 ) 𻀫 � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 򚪼 f 񒻯  � � = 弯p . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( � � � � nۻ  :, � � 󛥮 . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � 뙿 � � 󭩄 ; � � ?  pre - vmt . js : <number> [ wasm ] 􄠫 tflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � ̘ < 9 d 򆼇 * t <  ' � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  𳼑 sd 󠺬 ; 󋽦 􊼠 r . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> mx � � h : % 4 k < ̫ ' < ( ç < 񝮮 . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  o 󻛄 񷖡 � �  < 𽤼 񁮮 . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ⱥ ּ 󏉼 򘄼 ] � � d_ ; � . ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ֭ c 򢊛 ; 󥙻 怙 < 貦 � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � 􊥺 * ? "" � � 󸸔 � � . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 򶼼 1 n ⻗ � � - ի  񛹪 � � ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � �  ֻ 𲰼 􅛻 o𣼣 � � ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> v   ; 潛 򠛮 < ʻ㻅s ; 򮮮 ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ¿ , < pre - vmt . js : <number> [ wasm ] 񏻥 e � � � � ݻe 񮮮 ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> dճ < 󋺑 񢼍 � � � � ү . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � � � 𣺼 d 򻍪 ~ ;  � � ktflitefloat32 ktflitemmapro <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 冻 񍖼 𣄼 𲿼 󲎽 � � . ktfliteint32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ~ & � �  < � � ` < ݺnϙ ; 𫮮 . ktfliteint32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � %  ɻ ` ޻ 󴵹  ϛ ; t 񮮮 ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> < 񌹂 l  � � ; ԅ 򻬰 a 󾫮 . <repeated> ktfliteint32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ё 򻙃 ٻ : ժv ۪ ; � � pre - vmt . js : <number> [ wasm ] ; ŗ . <repeated> ktflitefloat32 ktflitemmapro <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> <number> pre - vmt . js : <number> [ wasm ] 纝s 󊺅 򚋟 � � <   . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ⻒ � � � � s 󁟮 󼘮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> z 򛼷 x0 < ʬ  𠻗 � � ߮ . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  󥺗 � � ї 􆛁 � � � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ½ẇ ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 𖒽 񅬽 ɓ ּ   򽮨  = ڝ . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 󦜼 󅯻 牪 = 𞁼 { jk < 󯮮 . ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ) a ˼ q 󀀀 pre - vmt . js : <number> [ wasm ] � � � � � � < 蚮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ⰾ 󝔦 < 񃼄 h � � <number> � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � į  < 򑁼 q 󬽴 ߼ <number> ) . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � s � � 񌽌 𱽬 � � * . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � la ޻  � � <number> < zl 󼚨 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> < 򔼌 � � 󰽊 v - � � < � � . ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> dzq � � 󿒇 < ; zz � � � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ^ � �  j 􌧁 ; e � � � �  . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � 󛶼 +  ) � � � � � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ༟ < cdͻyϑ � � � � � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ; � � ༕ 󗼫 } < ~ _ . � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 덒 ; t  <user> < ˠ � � v < <number> � � ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 򣀼 򧂼 <number> 񥻬 sn � � � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � 6 𢺊 $@ < 󶢺 t > ֺ 舮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> i粼 * * & < ļ 򅫈 ;  b 򻤺 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> s  { . zr � � � � < <number> � � <number> . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  pw 􀗃 􈨉 � � 㢥 󧂮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ߴüs � �  <number> 󢠠 ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> t # 򼇟 񼻺 < 􊚻 󣫚 򡋮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � ݿ � � � � � � <number> \ \ r . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � ڛ � � 𼮲 � � n 􏕮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 򝷺 iܨ <  <   < 򾃆 ; 󵮮 . ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � hԃ < o 񉼿 hἑݎ < f � � ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  󻦨 𼯄 [ < � � w ~ j 󗩮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  <number> » lv  < ǡf 򟻸 ; jv � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> s � � w 򈤋 񊗺 9 fz  � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> wŕ ; 􃋼  � � ~ < � � < ڷ . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> kխ ;  㚹 ֛ ! ;  񬻠 ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 𜭼 艺 < ﻨ9刼 ; pre - vmt . js : <number> [ wasm ] *< 􉮮 . ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> <number> � � ĺ ; ۚ  < � � ϭ ܻ i 󮮮 ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> sl $ 􀍋 ; oq ֺ < � � 𻺔 ޮ . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> <number> \ \ 𼀄 � � ; ဥ ; � � ȉ . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number>  󂆅 � � 􎙧 < 񶧻 񍮮 . ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ꥩ8 ^ 񑻢 � � � � ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 𛁺 � � � � [ 񁺼 � � ߮ . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> / ӎ 􀀀 pre - vmt . js : <number> [ wasm ] 껵 򀼏  � � b � � ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ϣ 󺕠 � � � � ; f 򜺹 pre - vmt . js : <number> [ wasm ] . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ᳠ :$ p溓l � � 㻂 𺩯 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � 򭶹 � � c ျ ꬓ : � � . ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> sw � � y � � ;  � � e � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> � � ę  ; ᑩ 򘯱 󨞇 󎓮 . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> 긟 𔎴 ; ڗs 񡮠 � � � � . <repeated> ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktfliteint32 ktflitearenarw <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktfliteint32 ktflitearenarw <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitefloat32 ktflitearenarw <number> / <number> [ <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktfliteint32 ktflitedynamic <number> / <number> ( null ) [ - <number> , - <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitenotype ktflitememnone <number> / <number> ( null ) [ - <number> , - <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitenotype ktflitememnone <number> / <number> ( null ) [ - <number> , - <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitenotype ktflitememnone <number> / <number> ( null ) [ - <number> , - <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitenotype ktflitememnone <number> / <number> ( null ) [ - <number> , - <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitenotype ktflitememnone <number> / <number> ( null ) [ - <number> , - <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitenotype ktflitememnone <number> / <number> ( null ) [ - <number> , - <number> ) pre - vmt . js : <number> [ wasm ] tensor <number> ( nil ) ktflitefloat32 ktflitearenarw <number> / <number> [ <number> , <number> ] [ <number> , <number> ) pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] ktflitearenarw info : pre - vmt . js : <number> [ wasm ] tensor <number> has the max size <number> bytes ( <number> mb ) . pre - vmt . js : <number> [ wasm ] this memory arena is estimated as [ 0x 1 5 e33b0 , 0x 1 2 abd80 ) , taking <number> bytes ( <number> mb ) . pre - vmt . js : <number> [ wasm ] one possible set of tensors that have non - overlapping memory spaces with each other , and they take up the whole arena : pre - vmt . js : <number> [ wasm ] tensor <number> - > <number> - > <number> - > <number> . pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] ktflitearenarwpersistent info : not holding any allocation . pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] ktflitemmapro info : pre - vmt . js : <number> [ wasm ] tensor <number> has the max size <number> bytes ( <number> mb ) . pre - vmt . js : <number> [ wasm ] this memory arena is estimated as [ 0x 1 0 dde70 , 0x 1 0 3 5 3 2 0 ) , taking <number> bytes ( <number> mb ) . pre - vmt . js : <number> [ wasm ] one possible set of tensors that have non - overlapping memory spaces with each other , and they take up the whole arena : pre - vmt . js : <number> [ wasm ] tensor <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> - > <number> . pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] ktflitedynamic info : not holding any allocation . pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> pad ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 6 0 2 1 4 4 b ( <number> . 5 7 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 6 1 2 9 1 2 b ( <number> . 5 8 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 1 4 7 0 4 b ( <number> . 5 9 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 8 0 2 8 1 6 b ( <number> . 7 7 mb ) pre - vmt . js : <number> [ wasm ] <number> temporary tensors <sad> <number> ] - > 1 3 5 4 7 5 2 b ( <number> . 2 9 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> pad ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 8 0 2 8 4 8 b ( <number> . 7 7 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 8 3 1 7 4 4 b ( <number> . 7 9 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 8 3 2 3 8 4 b ( <number> . 7 9 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 2 0 0 7 0 4 b ( <number> . 1 9 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 2 0 1 2 4 8 b ( <number> . 1 9 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 0 0 3 5 2 b ( <number> . 1 0 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 0 1 7 9 2 b ( <number> . 1 0 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 0 1 7 6 0 b ( <number> . 4 8 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> pad ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 5 0 1 7 9 2 b ( <number> . 4 8 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 3 8 2 4 0 b ( <number> . 5 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 5 3 9 8 4 0 b ( <number> . 5 1 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 2 5 4 4 0 b ( <number> . 1 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 2 8 0 6 4 b ( <number> . 1 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 0 1 7 6 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 5 3 9 8 4 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 7 5 6 1 6 b ( <number> . 1 7 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 7 7 8 5 6 b ( <number> . 1 7 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 7 5 6 1 6 b ( <number> . 1 7 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 7 9 2 6 4 b ( <number> . 1 7 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 0 1 7 6 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> add ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 1 0 0 3 5 2 b ( <number> . 1 0 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 0 1 7 6 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 5 4 5 2 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 2 0 0 7 0 4 b ( <number> . 1 9 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> pad ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 2 0 0 7 3 6 b ( <number> . 1 9 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 2 3 0 4 0 0 b ( <number> . 2 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 2 3 2 9 6 0 b ( <number> . 2 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 0 1 7 6 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 5 6 4 1 6 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 3 3 2 1 6 b ( <number> . 0 3 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 1 2 8 9 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 1 8 6 5 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 1 2 8 9 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 2 6 8 1 6 b ( <number> . 1 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> add ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 3 7 6 3 2 b ( <number> . 0 4 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 3 3 2 1 6 b ( <number> . 0 3 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 1 2 8 9 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 1 8 6 5 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 1 2 8 9 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 2 6 8 1 6 b ( <number> . 1 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> add ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 3 7 6 3 2 b ( <number> . 0 4 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 2 6 0 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 5 9 3 2 8 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 3 4 5 6 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> add ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 3 7 6 3 2 b ( <number> . 0 4 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 2 6 0 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 5 9 3 2 8 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 3 4 5 6 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> add ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 3 7 6 3 2 b ( <number> . 0 4 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 3 3 2 1 6 b ( <number> . 0 3 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 1 2 8 9 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> pad ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 1 1 2 9 2 8 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 4 7 4 5 6 b ( <number> . 1 4 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 5 3 2 1 6 b ( <number> . 1 5 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 2 8 2 2 4 b ( <number> . 0 3 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 5 6 0 6 4 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 9 4 0 8 b ( <number> . 0 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 5 8 5 6 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 7 9 6 8 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 1 1 9 3 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 9 4 0 8 b ( <number> . 0 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> add ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 9 4 0 8 b ( <number> . 0 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 5 8 5 6 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> depthwise_conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 7 9 6 8 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 1 1 1 9 3 6 b ( <number> . 1 1 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 9 4 0 8 b ( <number> . 0 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> add ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 1 8 8 1 6 b ( <number> . 0 2 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 9 4 0 8 b ( <number> . 0 1 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> conv_2d ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 6 5 8 5 6 b ( <number> . 0 6 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 5 6 4 4 8 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> mean ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 5 6 4 5 6 b ( <number> . 0 5 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 1 1 5 2 b ( <number> . 0 0 mb ) pre - vmt . js : <number> [ wasm ] <number> temporary tensors <sad> <number> - <number> ] - > 1 1 7 6 b ( <number> . 0 0 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> fully_connected ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> , <number> ] - > 2 0 5 7 6 4 b ( <number> . 2 0 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 7 0 8 b ( <number> . 0 0 mb ) pre - vmt . js : <number> [ wasm ] node <number> operator builtin code <number> reshape ( not delegated ) pre - vmt . js : <number> [ wasm ] <number> input tensors <sad> <number> ] - > 7 2 0 b ( <number> . 0 0 mb ) pre - vmt . js : <number> [ wasm ] <number> output tensors <sad> <number> ] - > 7 0 8 b ( <number> . 0 0 mb ) pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] execution plan as the list of <number> nodes invoked in - order : [ <number> - <number> ] pre - vmt . js : <number> [ wasm ] - - - - - - - - - - - - - - subgraph - <number> dump has completed - - - - - - - - - - - - - - pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] - - - - - - - - - - - - - - memory arena status start - - - - - - - - - - - - - - pre - vmt . js : <number> [ wasm ] total memory usage : <number> bytes ( <number> mb ) pre - vmt . js : <number> [ wasm ] - total arena memory usage : <number> bytes ( <number> mb ) pre - vmt . js : <number> [ wasm ] - total dynamic memory usage : <number> bytes ( <number> mb ) pre - vmt . js : <number> [ wasm ] pre - vmt . js : <number> [ wasm ] subgraph # <number> arena ( normal ) <number> ( <percent> ) pre - vmt . js : <number> [ wasm ] subgraph # <number> arena ( persistent ) <number> ( <percent> ) pre - vmt . js : <number> [ wasm ] - - - - - - - - - - - - - - memory arena status end - - - - - - - - - - - - - - vmt . wasm :0 x31cff uncaught runtimeerror access out of bounds at vmt . wasm :0 x31cff at vmt . wasm :0 x1f7a94 at vmt . wasm :0 x3 c4910 at vmt . wasm :0 x65ace at vmt . wasm :0 x231c3e at vmt . wasm :0 x458a49 at vmt . wasm :0 x517c60 at module . _landmarkdetection ( vmt . js : <number> : <number> ) at vmthelper . cycleforsingleimage ( vmt - helper . js : <number> <time> ) at img . onload ( index . html : <number> <time> ) ` ` `",0
tensorflow/tensorflow,ctc_ops . py deprecation warning # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? warning : tensorflow : from / home / sronen / code / . venv / lib / python3 . <number> / site - packages / tensorflow / python / ops / ctc_ops . py : <number> ( from tensorflow . python . ops . inplace_ops ) is deprecated and will be removed in a future version . # # # standalone code to reproduce the issue ` ` ` shell i suspect any call to tf . nn . ctc_loss ` ` ` # # # relevant log output _no response_,0
tensorflow/tensorflow,"savedmodel convert to tflite and merge labels . tx to new tflite model , but resulte is error by xcode , use python api is correct # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution mac os <number> # # # mobile device ios <number> # # # python version <number> . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? convert savedmodel to tflite in ios is error model download url <url> convert steps <number> . < img width = "" <number> "" alt = "" image "" src = "" <url> <number> . < img width = "" <number> "" alt = "" image "" src = "" <url> script is use offical metadata_writer_for_image_classifier . py use convert savedmodel to convert tflite （ merge labels . txt and tflite ） python api result is correct < img width = "" <number> "" alt = "" image "" src = "" <url> ios is error （ self - converted ） < img width = "" <number> "" alt = "" image "" src = "" <url> ios is correct （ download tflite is correct ） < img width = "" <number> "" alt = "" image "" src = "" <url> # # # standalone code to reproduce the issue ` ` ` shell ios code ： < img width = "" <number> "" alt = "" image "" src = "" <url> python code ： def classify_image_tflite_no_sin ( model_path , predicted_image_path , labels_path ) : tf_model_file_path = model_path interpreter = tf . lite . interpreter ( model_path = tf_model_file_path ) interpreter . allocate_tensors ( ) # 加载标签文件 with open ( labels_path , ' r ' ) as f = f . read ( ) . splitlines ( ) # 读取和预处理图像 image_path = predicted_image_path image = image . open ( image_path ) . resize ( ( <number> , <number> ) ) # 调整图像大小 image = np . array ( image ) # 将图像转换为numpy数组 image = image / <number> # 归一化图像 image = np . expand_dims ( image , axis = <number> ) . astype ( np . float32 ) # 添加批次维度并转换为float32 # 设置模型输入和输出张量 input_tensor_index = interpreter . get_input_details ( ) [ <number> ] [ ' index ' ] output_tensor_index = interpreter . get_output_details ( ) [ <number> ] [ ' index ' ] # 设置输入张量的值 interpreter . set_tensor ( input_tensor_index , image ) # 执行推断 interpreter . invoke ( ) # 获取输出张量的结果 output_data = interpreter . get_tensor ( output_tensor_index ) score_lite = tf . nn . softmax ( output_data ) # 获取预测类别索引 class_index = np . argmax ( score_lite ) predicted_label = labels [ class_index ] confidence = score_lite [ <number> ] [ class_index ] # 输出预测结果 print ( ' 预测类别 ： ' , predicted_label ) print ( ' 预测准确度 ： ' , confidence ) ` ` ` ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"tf . keras . models . model_from_json ( ) missing a safe_mode parameter # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source binary # # # tensorflow version tf <number> # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? when loading a model with a lambda layer from a json model config , tensorflow provides the following error : ` valueerror : requested the deserialization of a lambda layer with a python ' lambda ' inside it . this carries a potential risk of arbitrary code execution and thus it is disallowed by default . if you trust the source of the saved model , you can pass ' safe_mode = false ' to the loading function in order to allow lambda layer loading . ` however ` tf . keras . models . model_from_json ( ) ` does not have a ` safe_mode ` parameter . so there does not seem to be a way to load models with lamda layers using a json config . this issue does not appear in tensorflow <number> # # # standalone code to reproduce the issue ` ` ` shell from tensorflow . keras import model from tensorflow . keras . layers import dense , input , lambda inputs = input ( shape =( <number> , ) ) x = lambda ( lambda x out = dense ( <number> )(x ) model = model ( inputs = inputs , outputs = out ) model_config = model . to_json ( ) tf . keras . models . model_from_json ( model_config ) ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"issue with reproducible results : inconsistent behavior of random seeds in tensorflow # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? no # # # source source # # # tensorflow version <number> # # # custom code yes # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> - <number> - <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? i would like to report an issue regarding the reproducibility of results in tensorflow . currently , in order to achieve consistent and deterministic results , it seems necessary to set both random . seed ( <number> ) and tf . random . set_seed ( <number> ) together . expected behavior : setting tf . random . set_seed ( <number> ) alone should be sufficient to ensure reproducible results across different runs . observed behavior setting random . seed ( <number> ) alongside tf . random . set_seed ( <number> ) , the results obtained from tensorflow exhibit inconsistency and do not remain fixed between runs . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import random tf . random . set_seed ( <number> ) random . seed ( <number> ) # this line seems to be redundant x = tf . constant ( tf . random . uniform ( [ <number> , <number> , <number> ] ) , dtype = tf . float32 ) ` ` ` # # # relevant log output _no response_",0
tensorflow/tensorflow,"valueerror : checkpoint was expecting to be a trackable object ( an object derived from ` trackable ` ) # # # issue type bug # # # source binary # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution windows <number> enterprise # # # python version <date> # # # current behavior ? i am receiving an error when i try to restore the model checkpoint . i have seen a posting on here that ' s similar , but i think my case is different . help is very much appreciated i am using a pre - trained object detection model called ssd mobilenet v2 fpnlite 3 2 0 x320 # # # standalone code to reproduce the issue ` ` ` python import os import tensorflow as tf import pandas as pd import openpyxl import cv2 import numpy as np from object_detection . utils import label_map_util from object_detection . utils import visualization_utils as viz_utils from object_detection . builders import model_builder from object_detection . utils import config_util from matplotlib import pyplot as plt from pathlib import path os . chdir ( r "" c :\\ users \ \ mill286 "" ) custom_model_name = ' my_ssd_resnet50_v1_fpn ' # * * * enter here the name of the model you trained . * * * files = { ' pipeline_config ' : os . path . join ( ' tensorflow ' , ' workspace ' , ' models ' , custom_model_name , ' pipeline . config ' ) } # load pipeline config and build a detection model configs = config_util . get_configs_from_pipeline_file ( files [ ' pipeline_config ' ] ) detection_model = model_builder . build ( model_config = configs [ ' model ' ] , is_training = false ) # restore checkpoint ckpt = tf . compat . v2 . train . checkpoint ( model = detection_model ) ckpt . restore ( os . path . join ( paths [ ' checkpoint_path ' ] , ' ckpt - <number> . index ' ) ) . expect_partial ( ) # * * * replace the number in ' ckpt - xx ' with the checkpoint you want to use . * * * ` ` ` # # # relevant log output ` ` ` shell valueerror traceback ( most recent call last ) cell in [ <number> ] , line <number> <number> # restore checkpoint - - - - > <number> ckpt = tf . compat . v2 . train . checkpoint ( model = detection_model ) <number> ckpt . restore ( os . path . join ( paths [ ' checkpoint_path ' ] , ' ckpt - <number> . index ' ) ) . expect_partial ( ) file ~ \ \ anaconda3 \ \ envs \ \ tensorflow \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ checkpoint \ \ checkpoint . py : <number> , in checkpoint . __init__ ( self , root , * * kwargs ) <number> if isinstance ( converted_v , weakref . ref ) : <number> converted_v = converted_v ( ) - > <number> _assert_trackable ( converted_v , k ) <number> if root : <number> # make sure that root does not already have dependencies with these names <number> child = trackable_root . _lookup_dependency ( k ) file ~ \ \ anaconda3 \ \ envs \ \ tensorflow \ \ lib \ \ site - packages \ \ tensorflow \ \ python \ \ checkpoint \ \ checkpoint . py : <number> , in _assert_trackable ( obj , name ) <number> def _assert_trackable ( obj , name ) : <number> if not isinstance ( <number> obj , ( base . trackable , def_function . function ) <sad> - > <number> raise valueerror ( <number> f "" ` checkpoint ` was expecting { name } to be a trackable object ( an "" <number> f "" object derived from ` trackable ` ) , got { obj } . if you believe this "" <number> "" object should be trackable ( i . e . it is part of the "" <number> "" tensorflow python api and manages state ) , please open an issue . "" ) valueerror was expecting model to be a trackable object ( an object derived from ` trackable ` ) , got < object_detection . meta_architectures . ssd_meta_arch . ssdmetaarch object at 0x0 0 0 0 0 1 e163d93910 > . if you believe this object should be trackable ( i . e . it is part of the tensorflow python api and manages state ) , please open an issue . ` ` `",0
tensorflow/tensorflow,"tf . image . extract_patches error for tf . raggedtensor inputs # # # issue type bug # # # have you reproduced the bug with tensorflow nightly ? yes # # # source source # # # tensorflow version tf <number> . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behavior ? ` tf . image . extract_patches ` should be able to extract patches from ` ragged ` tensors . # # # standalone code to reproduce the issue ` ` ` shell def build_model ( <sad> input = tf . keras . input ( [ none , none , <number> ] , ragged = true , name = "" image "" ) patches = tf . image . extract_patches ( images = input , sizes =[ <number> , <number> , <number> , <number> ] , strides =[ <number> , <number> , <number> , <number> ] , rates =[ <number> , <number> , <number> , <number> ] , padding = "" same "" , ) return tf . keras . model ( inputs = input , outputs = patches ) model = build_model ( ) ` ` ` # # # relevant log output ` ` ` shell - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - typeerror traceback ( most recent call last ) < ipython - input - <number> - 0 f2eac36aeae > in < cell line : <number> > ( ) <number> <number> - - - > <number> model = build_model ( ) <number> frames / usr / local / lib / python3 . <number> / dist - packages / keras / utils / traceback_utils . py in error_handler ( * args , * * kwargs ) <number> # to get the full stack trace , call : <number> # ` tf . debugging . disable_traceback_filtering ( ) ` - - - > <number> raise e . with_traceback ( filtered_tb ) from none <number> finally : <number> del filtered_tb typeerror : exception encountered when calling layer "" tf . image . extract_patches_3 "" ( type tfoplambda ) . failed to convert elements of tf . raggedtensor ( values = tf . raggedtensor ( values = tensor ( "" placeholder : <number> "" , shape =( none , <number> ) , dtype = float32 ) , row_splits = tensor ( "" placeholder_1 : <number> "" , shape =( none , ) , dtype = int64 ) ) , row_splits = tensor ( "" placeholder_2 : <number> "" , shape =( none , ) , dtype = int64 ) ) to tensor . consider casting elements to a supported type . see <url> for supported tf dtypes . call arguments received by layer "" tf . image . extract_patches_3 "" ( type tfoplambda ) images = tf . raggedtensor ( values = tf . raggedtensor ( values = tensor ( "" placeholder : <number> "" , shape =( none , <number> ) , dtype = float32 ) , row_splits = tensor ( "" placeholder_1 : <number> "" , shape =( none , ) , dtype = int64 ) ) , row_splits = tensor ( "" placeholder_2 : <number> "" , shape =( none , ) , dtype = int64 ) ) • sizes =[ ' <number> ' , ' <number> ' , ' <number> ' , ' <number> ' ] • strides =[ ' <number> ' , ' <number> ' , ' <number> ' , ' <number> ' ] • rates =[ ' <number> ' , ' <number> ' , ' <number> ' , ' <number> ' ] • padding = ' same ' • name = none ` ` `",0
tensorflow/tensorflow,"mutiple issues with the new parameter server strategy <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version <number> . <number> # # # custom code yes # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? we meet multiple issues in using the tensorflow <number> . x strategy : <number> . how to shard data by files , how to use the later binding mechanism to shard data by files , which is critical for high performance training using tf . data . dataset apis , all workers reading the total data is not scalable . <number> . how to control the placement of ops , in one attempt , we build dataset using tf . data . dataset . from_tensor_slices and . dataset = dataset . interleave ( lambda <kiss> tf . data . textlinedataset ( x ) . skip ( <number> ) , cycle_length = <number> , num_parallel_calls = <number> ) with parameter server strategy , the dataset related ops runs on workers , however , if i add one more op dataset . repeat ( ) , the dataset ops all runs on chief , which is surprising . <number> . how to ensure even the workers are with uneven amount of data , the training process with model . fit could end elegantly instead of having to using try catch or data . repeat , as recommendation models generally assume one epoch training . [ <email> ] ( mailto : <email> ) [ <email> ] ( mailto : <email> ) # # # standalone code to reproduce the issue ` ` ` shell # for chief : file_list = tf . io . gfile . glob ( input_pattern ) dataset = tf . data . dataset . from_tensor_slices ( file_list ) dataset = dataset . shard ( worker_num , worker_id ) # how to later bind worker_id ? dataset = dataset . interleave ( lambda <kiss> tf . data . textlinedataset ( x ) . skip ( <number> ) , cycle_length = <number> , num_parallel_calls = <number> ) def _parse_csv ( line ) : record_defaults = [ ] for x in all_columns : record_defaults . append ( <number> ) with tf . control_dependencies ( [ tf . print ( tf . shape ( line ) , line [ <number> ] , output_stream = sys . stderr ) ]): fields = tf . io . decode_csv ( line , field_delim =', ' , record_defaults = record_defaults , name = ' decode_csv ' ) return fields dataset = dataset . map ( _parse_csv , num_parallel_calls = <number> ) dataset = dataset . repeat ( ) strategy = tf . distribute . experimental . parameterserverstrategy ( cluster_resolver , variable_partitioner = variable_partitioner ) with strategy . scope ( <sad> model = build_model ( . <repeated> ) model . fit ( dataset , epochs = num_epoch , callbacks =[ tf . keras . callbacks . progbarlogger ( count_mode = ' steps ' ) , tf . keras . callbacks . tensorboard ( log_dir ='/ train / tensorboard / ' , histogram_freq = <number> ) ] , steps_per_epoch = steps_per_epoch ) # for workers and ps = tf . distribute . server ( cluster_resolver . cluster_spec ( ) , job_name = cluster_resolver . task_type , task_index = cluster_resolver . task_id , protocol = cluster_resolver . rpc_layer or ' grpc ' , start = true ) server . join ( ) ` ` ` # # # relevant log output ` ` ` shell # tf . print outputs are all on chief stdout , and no improvements if we place the dataset built process under strategy . scope ( ) or using ops . device ( ) operations . ` ` ` </details>",0
tensorflow/tensorflow,"/ / tensorflow / python / data / kernel_tests : snapshot_test is flaky <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version git head # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device n / a # # # python version <date> # # # bazel version <number> . <number> # # # gcc / compiler version <number> . <number> # # # cuda / cudnn version n / a # # # gpu model and memory n / a # # # current behaviour ? / / tensorflow / python / data / kernel_tests : snapshot_test sometimes fails x86 log <url> aarch64 log # # # standalone code to reproduce the issue ` ` ` shell bazel - - bazelrc <annoyed> usertools / cpu . bazelrc test - - config = pycpp - - config = build_event_export - - remote_cache = <url> - - google_default_credentials ` ` ` # # # relevant log output ` ` ` shell error : testwritesnapshotdatasetsamefingerprintincompleterunrestart_test_mode_eager_tfapiversion_2 ( __main__ . snapshottest ) snapshottest . testwritesnapshotdatasetsamefingerprintincompleterunrestart_test_mode_eager_tfapiversion_2 testwritesnapshotdatasetsamefingerprintincompleterunrestart_test_mode_eager_tfapiversion_2 ( mode = ' eager ' , tf_api_version = <number> ) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - traceback ( most recent call last ) : file "" / root / . cache / bazel / _bazel_root / fbac33eb30dbfb6b11b15a7ff5ac830d / execroot / org_tensorflow / bazel - out / k8 - opt / bin / tensorflow / python / data / kernel_tests / snapshot_test . runfiles / org_tensorflow / tensorflow / python / data / kernel_tests / snapshot_test . py "" , line <number> , in teardown shutil . rmtree ( self . _snapshot_dir ) file "" / usr / lib / python3 . <number> / shutil . py "" , line <number> , in rmtree _rmtree_safe_fd ( fd , path , onerror ) file "" / usr / lib / python3 . <number> / shutil . py "" , line <number> , in _rmtree_safe_fd onerror ( os . rmdir , fullname , sys . exc_info ( ) ) file "" / usr / lib / python3 . <number> / shutil . py "" , line <number> , in _rmtree_safe_fd os . rmdir ( entry . name , dir_fd = topfd ) oserror : [ errno <number> ] directory not empty : ' <number> ' = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = fail : testwritesnapshotdatasetsamefingerprintincompleterunrestart_test_mode_eager_tfapiversion_2 ( __main__ . snapshottest ) snapshottest . testwritesnapshotdatasetsamefingerprintincompleterunrestart_test_mode_eager_tfapiversion_2 testwritesnapshotdatasetsamefingerprintincompleterunrestart_test_mode_eager_tfapiversion_2 ( mode = ' eager ' , tf_api_version = <number> ) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - traceback ( most recent call last ) : file "" / root / . cache / bazel / _bazel_root / fbac33eb30dbfb6b11b15a7ff5ac830d / execroot / org_tensorflow / bazel - out / k8 - opt / bin / tensorflow / python / data / kernel_tests / snapshot_test . runfiles / absl_py / absl / testing / parameterized . py "" , line <number> , in bound_param_test return test_method ( self , * * testcase_params ) file "" / root / . cache / bazel / _bazel_root / fbac33eb30dbfb6b11b15a7ff5ac830d / execroot / org_tensorflow / bazel - out / k8 - opt / bin / tensorflow / python / data / kernel_tests / snapshot_test . runfiles / org_tensorflow / tensorflow / python / framework / test_combinations . py "" , line <number> , in decorated execute_test_method ( ) file "" / root / . cache / bazel / _bazel_root / fbac33eb30dbfb6b11b15a7ff5ac830d / execroot / org_tensorflow / bazel - out / k8 - opt / bin / tensorflow / python / data / kernel_tests / snapshot_test . runfiles / org_tensorflow / tensorflow / python / framework / test_combinations . py "" , line <number> , in execute_test_method test_method ( * * kwargs_to_pass ) file "" / root / . cache / bazel / _bazel_root / fbac33eb30dbfb6b11b15a7ff5ac830d / execroot / org_tensorflow / bazel - out / k8 - opt / bin / tensorflow / python / data / kernel_tests / snapshot_test . runfiles / org_tensorflow / tensorflow / python / data / kernel_tests / snapshot_test . py "" , line <number> , in testwritesnapshotdatasetsamefingerprintincompleterunrestart self . assertsnapshotdirectorycontains ( file "" / root / . cache / bazel / _bazel_root / fbac33eb30dbfb6b11b15a7ff5ac830d / execroot / org_tensorflow / bazel - out / k8 - opt / bin / tensorflow / python / data / kernel_tests / snapshot_test . runfiles / org_tensorflow / tensorflow / python / data / kernel_tests / snapshot_test . py "" , line <number> , in assertsnapshotdirectorycontains self . assertlen ( run_dirlist , num_snapshot_shards_per_run ) assertionerror ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' , ' <number> . shard ' ] has length of <number> , expected <number> . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ran <number> tests in <number> . 5 6 3 s ` ` ` </details>",0
tensorflow/tensorflow,"unsatisfiedlinkerror : failed to load native tensorflow lite methods <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version <number> . <number> - nightly - snapshot # # # custom code no # # # os platform and distribution _no response_ # # # mobile device android samsung galaxy j5 # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? fatal exception : java . lang . unsatisfiedlinkerror : failed to load native tensorflow lite methods . check that the correct native libraries are present , and , if using a custom native library , have been properly loaded via system . loadlibrary ( <sad> java . lang . unsatisfiedlinkerror : dlopen failed : cannot locate symbol "" __register_atfork "" referenced by "" libtensorflowlite_jni . so "" this is reproducible on lot of android devices running android version <number> , <number> this is happening in the nightly snapshots from probably last <number> weeks . did not encounter this in previous nightly snapshots . # # # standalone code to reproduce the issue ` ` ` shell val nnapioption = nnapidelegate . options ( ) nnapioption . setusennapicpu ( true ) val nnapidelegate = nnapidelegate ( nnapioption ) ` ` ` # # # relevant log output <number> - <number> - <number> <time> . <number> <number> - <number> interpreterapi i did not load native library : tensorflowlite_jni <number> - <number> - <number> <time> . <number> <number> - <number> interpreterapi i did not load native library : tensorflowlite_jni_stable <number> - <number> - <number> <time> . <number> <number> - <number> interpreterapi i did not load native library </details>",0
tensorflow/tensorflow,"the relationship between the parameters of conv2d is unclear <details> <summary> click to expand </summary> # # # issue type documentation bug # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf2 . <number> # # # custom code yes # # # os platform and distribution macos # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? ` ` ` valueerror : ` strides > <number> ` not supported in conjunction with ` dilation_rate > <number> ` . received <number> ] and dilation_rate =[ <number> , <number> ] ` ` ` the relationship between these two parameters is not clearly defined in the documentation , and it is not certain . be unaware of that ` strides > <number> ` not supported in conjunction with ` dilation_rate > <number> ` . # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf from tensorflow . python . keras . layers import conv2d input_tensor = tf . random . normal ( shape =( <number> , <number> , <number> , <number> ) ) x = conv2d ( filters = <number> , kernel_size =( <number> ) , strides =( <number> ) , padding = "" same "" , use_bias = false , dilation_rate =( <number> , <number> ) ) ( input_tensor ) print ( x . shape ) ` ` ` # # # relevant log output _no response_ </details>",0
tensorflow/tensorflow,"not initialized delegate kernel after tflite conversion # # # <number> . system information - os platform and distribution ( e . g . , linux ubuntu <number> <sad> windows <number> - tensorflow installation ( pip package or built from source ) : pip package - tensorflow library ( version , if pip package or github sha , if built from source ) : tensorflow <number> . <number> # # # <number> . code code to reproduce my issue is attached to this issue . [ tf_issue . zip ] ( <url> # # # <number> . failure after conversion ` ` ` file "" tf_issue \ \ test_ocr . py "" , line <number> , in __call__ self . _interpreter . invoke ( ) file "" . <repeated> \ \ venv \ \ lib \ \ site - packages \ \ tensorflow \ \ lite \ \ python \ \ interpreter . py "" , line <number> , in invoke self . _interpreter . invoke ( ) runtimeerror : current implementation only supports equal length strides in the row and column dimensions . delegate kernel was not initializednode number <number> ( tfliteflexdelegate ) failed to prepare . ` ` ` # # # <number> . ( optional ) any other info / logs hello , i downloaded the ocr model called * * en_pp - ocrv3_rec_infer * * from the [ paddle repository ] ( <url> to prepare it for my purposes , i converted it into the onnx format and optimized it , following the guidelines provided [ here ] ( <url> to ensure compatibility , i defined a static input / output size for the model . subsequently , i proceeded to convert the onnx format to tflite using this [ repository ] ( <url> once the conversion was complete , i loaded the resulting . tflite model into [ neutron ] ( <url> without any issues , as it successfully read and visualized the model . however , the problem arises when i attempt to test this model using python ( <number> ) . the attached zip file contains the code , the model itself , and a sample testing image ( it also contain a requirements file with all the packages of my environment ) . in my case , i utilized an input_shape_dict of "" {'x ' <number> , <number> , <number> ] } "" and exported the model in both fp16 and fp32 formats . i also experimented with opset_versions <number> and <number> . however , despite these attempts , i encountered the reported failure repeatedly .",0
tensorflow/tensorflow,"requested feature_data_ size <number> does not match <number> ; feature generation failed ; <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version v2 . <number> # # # custom code yes # # # os platform and distribution _no response_ # # # mobile device _no response_ # # # python version _no response_ # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? hello together , i am having a problem with the micro_speech example for arduino from this repo : <url> when trying to use this example with a new trained model from this jupyter noteboobk : <url> i always get the same error message feature_data_ size <number> does not match <number> feature generation failed the only thing i changed in the notebook was the tensorflow version . this is because this notebook was using <number> . x version which is no longer supported by colab and i changed it to work with the latest <number> . x version can anyone help here ? greetings , patrick # # # standalone code to reproduce the issue ` ` ` shell <url> <url> ` ` ` # # # relevant log output _no response_ </details>",0
tensorflow/tensorflow,"model runs without error in tensorflow , but crashes with a segmentation fault in tflite # # # <number> . system information - os platform and distribution : ubuntu <number> . <number> lts - tensorflow installation : pip - tensorflow library : <number> . <number> - tflite runtime : <number> . <number> # # # <number> . code the model is exported from pytorch using onnx . i have not included the pytorch code below for brevity ' s sake ( and because it is used for an active kaggle competition ) ; you can download the saved keras model [ here ] ( <url> the tflite conversion code is given below , but you can also download the tflite model [ here ] ( <url> ( same link ) . below is the code to create and save the keras model from two pytorch models ` feat_gen ` and ` model ` , converted using onnx : ` ` ` python class tfinfermodel ( tf . module ) : def __init__ ( self ) : super ( tfinfermodel , self ) . __init__ ( ) self . feat_gen = tf . saved_model . load ( "" feat_gen . pb "" ) self . model = tf . saved_model . load ( "" model . pb "" ) self . feat_gen . trainable = false self . model . trainable = false <user> . function ( input_signature =[ tf . tensorspec ( shape =[ none , <number> ] , dtype = tf . float32 , name = "" inputs "" ) ] ) def call ( self , inputs ) : output_tensors = { } # add batch dimension . inputs = inputs [ none ] # process using ported pytorch model . features = self . feat_gen ( inputs = inputs ) [ "" outputs "" ] outputs = self . model ( inputs = features ) [ "" outputs "" ] # remove batch dimension . outputs = outputs [ <number> ] output_tensors [ "" outputs "" ] = outputs return output_tensors tf_model = tfinfermodel ( ) tf . saved_model . save ( tf_model , "" tf_model "" , signatures ={ "" serving_default "" : tf_model . call } ) ` ` ` the model can be loaded in keras and run : ` ` ` python model = tf . saved_model . load ( "" tf_model "" ) inputs = tf . zeros ( ( <number> , <number> ) , dtype = tf . float32 ) output = model . call ( inputs = inputs ) ` ` ` it can also be converted to tflite : ` ` ` python converter = tf . lite . tfliteconverter . from_saved_model ( "" tf_model "" ) tf_lite_model = converter . convert ( ) output_path = "" model . tflite "" with open ( output_path , "" wb "" ) as f : f . write ( tf_lite_model ) ` ` ` and finally the code for tflite inference interpreter = tflite . interpreter ( model_path = "" model . tflite "" ) prediction_fn = interpreter . get_signature_runner ( "" serving_default "" ) inputs = np . zeros ( ( <number> , <number> ) , dtype = np . float32 ) output = prediction_fn ( inputs = inputs ) ` ` ` # # # <number> . failure after conversion the keras inference code runs without issue . the tflite inference code crashes immediately with a segmentation fault ( no further info is given ) .",0
tensorflow/tensorflow,"crashes in model . save , wrapt error <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? no # # # source binary # # # tensorflow version <number> # # # custom code no # # # os platform and distribution fodera linux # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? crashed when calling model . save ( ) see log below . worked after deinstalling tensorflow and wrapt . wrapt was <number> . x and installing tensorflow and wrapt = = <number> . <number> the problem is that when installing tensorflow , the wrapt <number> . x is installed automatically and this is not playing with tensorflow . # # # standalone code to reproduce the issue ` ` ` shell model . save ( ' modelname ' ) causes the problem for any trained network . ` ` ` # # # relevant log output ` ` ` shell traceback ( most recent call last ) "" modelpredictortraining . py "" , line <number> , in <module> run_hparam_on_grid ( branched_model_1 , file "" modelpredictortraining . py "" , line <number> , in run_hparam_on_grid fitted_model . save ( ' model - name ' ) file "" / anaconda3 / envs / tf2 / lib / python3 . <number> / site - packages / keras / utils / traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" / anaconda3 / envs / tf2 / lib / python3 . <number> / site - packages / tensorflow / python / trackable / data_structures . py "" , line <number> , in __getattribute__ return super ( ) . __getattribute__ ( name ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ` ` ` </details>",0
tensorflow/tensorflow,"tf . mul after tf . split + tf . sigmoid produces wrong numerical results with mkl enabled <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? no # # # source binary # # # tensorflow version intel - tensorflow <number> - <number> # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? when running with an mkl enabled tensorflow ( e . g . intel - tensorflow from pypi ) ( or self - compiled with ` - - config = mkl ` ) . starting with tensorflow <number> . <number> up until <number> . <number> the attached code produces the wrong numerical result . ( <number> vs expected <number> ) . if line <number> is changed to ` m = sig * ( b + <number> ) ` one can get the correct result . this issue does not occur if installing "" vanilla "" tesorflow from pip with ` pip install tensorflow ` . this issue also does not occur if one uses ` tf . exp ` or ` tf . log ` instead of ` tf . sigmoid ` . # # # standalone code to reproduce the issue ` ` ` shell # ! / usr / bin / env python3 import math import tensorflow as tf import numpy as np def sigmoid ( x ) : return <number> / ( <number> + math . exp ( - x)) data = [ [ [ <number> , <number> ] ] ] tf . compat . v1 . disable_eager_execution ( ) s = tf . compat . v1 . session ( ) p = tf . compat . v1 . placeholder ( dtype = tf . float32 ) a , b = tf . split ( p , <number> , axis = <number> ) sig = tf . sigmoid ( a ) m = sig * b out = s . run ( [ p , m ] , feed_dict ={ p : data } ) print ( out ) print ( ' computed : ' , out [ - <number> ] [ <number> , <number> ] ) print ( ' expected : ' , sigmoid ( data [ <number> ] [ <number> ] [ <number> ] ) * data [ <number> ] [ <number> ] [ <number> ] ) ` ` ` # # # relevant log output ` ` ` shell <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . <number> - <number> - <number> <time> . <number> : i tensorflow / core / common_runtime / process_util . cc : <number> ] creating new thread pool with default inter op setting : [ array ( [ [ [ <number> . , <number> . ] ] ] , dtype = float32 ) , array ( [ [ [ <number> ] ] ] , dtype = float32 ) ] computed : <number> expected ` ` ` </details>",0
tensorflow/tensorflow,"fit ( ) fails with cudnn_status_bad_param when using conv3d and multi - gpu mirroredstrategy <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version v1 . <number> - <number> - g47602c0bad8 <number> . <number> - dev20230620 # # # custom code yes # # # os platform and distribution rocky linux release <number> ( green obsidian ) # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version cuda_11 . <number> . r11 . <number> / compiler . 3 1 8 3 3 9 0 5 _0 / cudnn version <number> # # # gpu model and memory <number> nvidia a100s w / 8 0 gb each # # # current behaviour ? when executing a model fit that includes a ` conv3d ` layer on multiple gpus , i am encountering a ` cudnn_status_bad_param ` error in the gradient computation step . no errors occur when running on a single gpu , nor when i swap out ` conv3d ` with ` averagepooling3d ` or ` conv2d ` . however , ` conv3dtranspose ` also fails . ` ` ` none ( <number> ) unknown : cudnn_status_bad_param in tensorflow / compiler / xla / stream_executor / cuda / cuda_dnn . cc ( <number> <sad> ' tensor ' cudnn_backend_tensor_descriptor : check and set the cudnn_attr_tensor_dimensions correctly [ [ { { node gradient_tape / replica_2 / model / conv3d / conv3d / conv3dbackpropfilterv2 } } ] ] [ [ div_no_nan / readvariableop_1 / _52 ] ] [ [ group_deps / _95 ] ] [ [ adam / update_2_2 / assignaddvariableop / _119 ] ] [ [ group_deps / _103 ] ] ` ` ` with the ` graph execution error ` traceback : ` ` ` none traceback ( most recent call last ) : file "" conv3_multi_gpu_fail_repro . py "" , line <number> , in <module> model . fit ( x_data , y_data , batch_size = <number> , epochs = <number> , verbose = <number> ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py "" , line <number> , in error_handler raise e . with_traceback ( filtered_tb ) from none file "" /* * */ env / lib / python3 . <number> / site - packages / tensorflow / python / eager / execute . py "" , line <number> , in quick_execute tensors = pywrap_tfe . tfe_py_execute ( ctx . _handle , device_name , op_name , tensorflow . python . framework . errors_impl . unknownerror : graph execution error : detected at node gradient_tape / replica_3 / model / conv3d / conv3d / conv3dbackpropfilterv2 defined at ( most recent call last ) : file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step self . optimizer . minimize ( loss , self . trainable_variables , tape = tape ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step self . optimizer . minimize ( loss , self . trainable_variables , tape = tape ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / optimizers / optimizer . py "" , line <number> , in minimize grads_and_vars = self . compute_gradients ( loss , var_list , tape ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap self . _bootstrap_inner ( ) file "" / usr / lib / python3 . <number> / threading . py "" , line <number> , in _bootstrap_inner self . run ( ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step outputs = model . train_step ( data ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step self . optimizer . minimize ( loss , self . trainable_variables , tape = tape ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / optimizers / optimizer . py "" , line <number> , in minimize grads_and_vars = self . compute_gradients ( loss , var_list , tape ) file "" /* * */ env / lib / python3 . <number> / site - packages / keras / src / optimizers / optimizer . py "" , line <number> , in compute_gradients grads = tape . gradient ( loss , var_list ) ` ` ` i am running from the ` tensorflow / tensorflow : nightly - gpu ` docker image . # # # standalone code to reproduce the issue ` ` ` python import tensorflow as tf from tensorflow . keras import layers , models input_shape = ( <number> , <number> , <number> , <number> ) num_samples = <number> x_data = tf . random . uniform ( ( num_samples , * input_shape ) , <number> , <number> ) y_data = tf . random . uniform ( ( num_samples , * input_shape ) , <number> , <number> ) multi_gpu = true # <== fails <hashtag> multi gpu </hashtag> = false # <== works devices = [ ] if multi_gpu else [ ' / gpu : <number> ' ] mirrored_strategy = tf . distribute . mirroredstrategy ( devices = devices ) print ( f "" { mirrored_strategy . num_replicas_in_sync } replica ( s ) "" ) with mirrored_strategy . scope ( ) = layers . input ( shape = input_shape ) outputs = layers . conv3d ( <number> , <number> ) ( inputs ) # <== fails <hashtag> outputs </hashtag> = layers . averagepooling3d ( <number> ) ( inputs ) # <== works <hashtag> outputs </hashtag> = layers . conv2d ( <number> , <number> ) ( inputs ) # <== works model = models . model ( inputs = inputs , outputs = outputs ) model . compile ( optimizer = ' adam ' , loss = ' binary_crossentropy ' ) model . fit ( x_data , y_data , batch_size = <number> , epochs = <number> , verbose = <number> ) ` ` ` # # # relevant log output _no response_ </details>",0
tensorflow/tensorflow,"fft produces wrong results when using multiple gpus with mirroredstrategy <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version <number> . <number> <number> . <number> - dev20230619 # # # custom code no # # # os platform and distribution linux ubuntu <number> # # # mobile device _no response_ # # # python version <date> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version <number> . <number> / <number> . <number> # # # gpu model and memory _no response_ # # # current behaviour ? using tensorflow fft in a keras model will produce incorrect results when using mirroredstrategy and multiple gpus . this is not an accuracy issue . the results of consecutive calls seem to be either correct or garbage . i created a test keras model that has one layer that does fft . there is also a reference model using a dft layer that is used to verify that incorrect behavior only happens when using tf . signal . fft . attached is a test application that runs both models in different combinations of mirroredstrategy / default strategy and eager / graph execution . mirroredstrategy and graph execution is the combination that produces the error . at least two gpus are required to reproduce the problem . the output mae loss is around <number> , which translates to <percent> error . ( the absolute value of each entry in the correct output is <number> . ) i think it ' s not a user error , but if it is , there should be an error or warning instead of incorrect results . i was able to reproduce the issue with all tf fft variants ( tf . signal . fft , tf . signal . rfft , tf . signal . stft , tf . signal . fft2d ) # # # standalone code to reproduce the issue ` ` ` shell import tensorflow as tf import numpy as np from scipy . linalg import dft from math import sqrt # layer that does tf . signal . fft operation class fftlayer ( tf . keras . layers . layer ) : def call ( self , x) : fx = tf . signal . fft ( x ) return fx # layer that returns same results as tf . signal . fft op , but # uses slower direct computation of dft , implemented as matrix multiply . class matrixdftlayer ( tf . keras . layers . layer ) : def __init__ ( self ) : super ( ) . __init__ ( ) self . dft = tf . cast ( dft ( <number> ) , tf . complex64 ) def call ( self , x) : fx = self . dft @ tf . transpose ( x ) return tf . transpose ( fx ) def create_model ( use_mirrored_strategy : bool = true , run_eagerly : bool = true , layer_to_use : tf . keras . layers . layer = fftlayer ) - > none : print ( f "" \ \ ncreate model with : use_mirrored_strategy : { use_mirrored_strategy } , "" , f "" run_eagerly : { run_eagerly } , "" , f "" layer_to_use : { layer_to_use } "" ) if use_mirrored_strategy : distribution_strategy = tf . distribute . mirroredstrategy ( ) else : distribution_strategy = tf . distribute . get_strategy ( ) with distribution_strategy . scope ( <sad> ins = tf . keras . layers . input ( [ <number> ] , dtype = tf . complex64 ) x = layer_to_use ( ) ( ins ) model = tf . keras . model ( inputs = ins , outputs =x) model . compile ( loss = tf . keras . losses . meanabsoluteerror ( ) , run_eagerly = run_eagerly ) return model def create_data ( fft_size , batch_size , num_steps ) : num_examples = num_steps * batch_size # y data is a complex vector of all ( <number> / sqrt ( <number> ) , ( <number> / sqrt ( <number> ) j ) train_y = np . ones ( [ fft_size ] , np . float32 ) train_y = ( <number> / sqrt ( <number> ) ) * train_y + ( <number> / sqrt ( <number> ) ) 1 j <emphasis> train_y # abs mean is <number> - > mae magnitude should be compared to <number> print ( "" train_y mean : "" , tf . reduce_mean ( tf . abs ( train_y ) ) ) # use inverse transform to create input data # fft ( train_x ) will produce train_y train_x = tf . signal . ifft ( train_y ) # clone data to get larger training set train_y = train_y [ tf . newaxis , . <repeated> ] train_x = train_x [ tf . newaxis , . <repeated> ] train_x = tf . tile ( train_x , [ num_examples , <number> ] ) train_y = tf . tile ( train_y , [ num_examples , <number> ] ) return train_x , train_y fft_size = <number> batch_size = <number> num_steps = <number> train_x , train_y = create_data ( fft_size , batch_size , num_steps ) # test cases with matrixdftlayer # these are all ok , mae close to <number> # ok model = create_model ( use_mirrored_strategy = false , run_eagerly = false , layer_to_use = matrixdftlayer ) loss = model . evaluate ( train_x , train_y , batch_size = batch_size , verbose = <number> ) print ( f "" loss : { loss } "" ) # ok model = create_model ( use_mirrored_strategy = false , run_eagerly = true , layer_to_use = matrixdftlayer ) loss = model . evaluate ( train_x , train_y , batch_size = batch_size , verbose = <number> ) print ( f "" loss : { loss } "" ) # ok model = create_model ( use_mirrored_strategy = true , run_eagerly = false , layer_to_use = matrixdftlayer ) loss = model . evaluate ( train_x , train_y , batch_size = batch_size , verbose = <number> ) print ( f "" loss : { loss } "" ) # test cases using tf fft . these fail when using mirroredstrategy . # ok model = create_model ( use_mirrored_strategy = false , run_eagerly = false , layer_to_use = fftlayer ) loss = model . evaluate ( train_x , train_y , batch_size = batch_size , verbose = <number> ) print ( f "" loss : { loss } "" ) # ok model = create_model ( use_mirrored_strategy = false , run_eagerly = true , layer_to_use = fftlayer ) loss = model . evaluate ( train_x , train_y , batch_size = batch_size , verbose = <number> ) print ( f "" loss : { loss } "" ) # fail , model = create_model ( use_mirrored_strategy = true , run_eagerly = false , layer_to_use = fftlayer ) loss = model . evaluate ( train_x , train_y , batch_size = batch_size , verbose = <number> ) print ( f "" loss : { loss } "" ) ` ` ` # # # relevant log output ` ` ` shell train_y mean : tf . tensor ( <number> , shape =() , dtype = float32 ) create model with : use_mirrored_strategy : false , run_eagerly : false , layer_to_use : < class ' __main__ . matrixdftlayer ' > loss : <number> create model with : use_mirrored_strategy : false , run_eagerly : true , layer_to_use : < class ' __main__ . matrixdftlayer ' > loss : <number> create model with : use_mirrored_strategy : true , run_eagerly : false , layer_to_use : < class ' __main__ . matrixdftlayer ' > loss : <number> create model with : use_mirrored_strategy : false , run_eagerly : false , layer_to_use : < class ' __main__ . fftlayer ' > loss : <number> create model with : use_mirrored_strategy : false , run_eagerly : true , layer_to_use : < class ' __main__ . fftlayer ' > loss : <number> create model with : use_mirrored_strategy : true , run_eagerly : false , layer_to_use : < class ' __main__ . fftlayer ' > loss ` ` ` </details>",0
tensorflow/tensorflow,"f1 score error on multi class data <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version v1 . <number> - <number> - g08bd7e1a8e5 <number> . <number> - dev20230618 # # # custom code yes # # # os platform and distribution os ventura <number> . <number> # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? implementing the f1 score available in the nightly builds on multi - class data such as below : ` ` ` model . compile ( optimizer = ' adam ' , loss = tf . keras . losses . sparsecategoricalcrossentropy ( from_logits = true ) , metrics = tf . keras . metrics . f1score ( ) ) history = model . fit ( train_images , train_labels , epochs = <number> , validation_data =( test_images , test_labels ) ) ` ` ` triggers the following error : ` ` ` epoch <number> / <number> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - valueerror traceback ( most recent call last ) cell in [ <number> ] , line <number> <number> model . compile ( optimizer = ' adam ' , <number> loss = tf . keras . losses . sparsecategoricalcrossentropy ( from_logits = true ) , <number> metrics = tf . keras . metrics . f1score ( ) ) - - - - > <number> history = model . fit ( train_images , train_labels , epochs = <number> , <number> validation_data =( test_images , test_labels ) ) file / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / utils / traceback_utils . py : <number> , in filter_traceback . <locals> . error_handler ( * args , * * kwargs ) <number> filtered_tb = _process_traceback_frames ( e . __traceback__ ) <number> # to get the full stack trace , call : <number> # ` tf . debugging . disable_traceback_filtering ( ) ` - - - > <number> raise e . with_traceback ( filtered_tb ) from none <number> finally : <number> del filtered_tb file / var / folders / f5 / mkqkf_0d42qcsqc37hd_y0hm0000gn / t / __autograph_generated_fileb8tcgui2 . py : <number> , in outer_factory . <locals> . inner_factory . <locals> . tf__train_function ( iterator ) <number> try : <number> do_return = true - - - > <number> retval_ = ag__ . converted_call ( ag__ . ld ( step_function ) , ( ag__ . ld ( self ) , ag__ . ld ( iterator ) ) , none , fscope ) <number> except : <number> do_return = false valueerror : in user code : file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_function * return step_function ( self , iterator ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in step_function * * outputs = model . distribute_strategy . run ( run_step , args =( data , ) ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in run_step * * outputs = model . train_step ( data ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in train_step return self . compute_metrics ( x , y , y_pred , sample_weight ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / engine / training . py "" , line <number> , in compute_metrics self . compiled_metrics . update_state ( y , y_pred , sample_weight ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / engine / compile_utils . py "" , line <number> , in update_state metric_obj . update_state ( y_t , y_p , sample_weight = mask ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / utils / metrics_utils . py "" , line <number> , in decorated update_op = update_state_fn ( * args , * * kwargs ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / metrics / base_metric . py "" , line <number> , in update_state_fn return ag_update_state ( * args , * * kwargs ) file "" / opt / homebrew / lib / python3 . <number> / site - packages / keras / src / metrics / f_score_metrics . py "" , line <number> , in update_state * * y_true = tf . convert_to_tensor ( y_true , dtype = self . dtype ) valueerror : tensor conversion requested dtype float32 for tensor with dtype uint8 ' iteratorgetnext : <number> ' shape =( none , <number> ) dtype = uint8 > ` ` ` i have tried with multiple multi - class datasets and the same error is returned . the f1 score page says it should work with multi - class data <url> is there something i have missed regarding its implementation for multi - class data ( such as somewhere to specify the number of classes ? ) or is this a bug ? # # # standalone code to reproduce the issue ` ` ` shell here is a jupyter notebook with some example data from <url> <url> ` ` ` # # # relevant log output _no response_ </details>",0
tensorflow/tensorflow,"uncaught exception in zmqstream callback when running your example notebooks using latest or nightly docker image <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source binary # # # tensorflow version v2 . <number> - rc1 - <number> - g0db597d0d75 <number> . <number> # # # custom code no # # # os platform and distribution linux gpu02 <date> - <number> - pve # <number> smp preempt_dynamic pve <date> - <number> ( <number> - <number> - 1 0 t <time> z ) x86_64 x86_64 x86_64 gnu / linux # # # mobile device _no response_ # # # python version python3 . <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? occurs when running any of your example notebooks : ` ` ` [ e <time> . <number> notebookapp ] uncaught exception in zmqstream callback traceback ( most recent call last ) : file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in _run_callback f = callback ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in stream_callback return callback ( self , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / notebook / services / kernels / handlers . py "" , line <number> , in _on_zmq_reply super ( ) . _on_zmq_reply ( stream , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / notebook / base / zmqhandlers . py "" , line <number> , in _on_zmq_reply self . write_message ( msg , binary = isinstance ( msg , bytes ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in write_message return self . ws_connection . write_message ( message , binary = binary ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in write_message fut = self . _write_frame ( true , opcode , message , flags = flags ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in _write_frame return self . stream . write ( frame ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in write self . _handle_write ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in _handle_write self . _write_buffer . advance ( num_bytes ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in advance assert <number> < size <= self . _size assertionerror [ e <time> . <number> notebookapp ] uncaught exception in zmqstream callback traceback ( most recent call last ) : file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in _handle_events self . _handle_recv ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in _handle_recv self . _run_callback ( callback , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in _run_callback f = callback ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in stream_callback return callback ( self , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / notebook / services / kernels / handlers . py "" , line <number> , in _on_zmq_reply super ( ) . _on_zmq_reply ( stream , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / notebook / base / zmqhandlers . py "" , line <number> , in _on_zmq_reply self . write_message ( msg , binary = isinstance ( msg , bytes ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in write_message return self . ws_connection . write_message ( message , binary = binary ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in write_message fut = self . _write_frame ( true , opcode , message , flags = flags ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in _write_frame return self . stream . write ( frame ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in write self . _handle_write ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in _handle_write self . _write_buffer . advance ( num_bytes ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in advance assert <number> < size <= self . _size assertionerror exception in callback baseasyncioloop . _handle_events ( <number> , <number> ) handle : < handle baseasyncioloop . _handle_events ( <number> , <number> ) > traceback ( most recent call last ) "" / usr / lib / python3 . <number> / asyncio / events . py "" , line <number> , in _run self . _context . run ( self . _callback , * self . _args ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / platform / asyncio . py "" , line <number> , in _handle_events handler_func ( fileobj , events ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in _handle_events self . _handle_recv ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in _handle_recv self . _run_callback ( callback , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in _run_callback f = callback ( * args , * * kwargs ) file "" / usr / local / lib / python3 . <number> / dist - packages / zmq / eventloop / zmqstream . py "" , line <number> , in stream_callback return callback ( self , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / notebook / services / kernels / handlers . py "" , line <number> , in _on_zmq_reply super ( ) . _on_zmq_reply ( stream , msg ) file "" / usr / local / lib / python3 . <number> / dist - packages / notebook / base / zmqhandlers . py "" , line <number> , in _on_zmq_reply self . write_message ( msg , binary = isinstance ( msg , bytes ) ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in write_message return self . ws_connection . write_message ( message , binary = binary ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in write_message fut = self . _write_frame ( true , opcode , message , flags = flags ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / websocket . py "" , line <number> , in _write_frame return self . stream . write ( frame ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in write self . _handle_write ( ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in _handle_write self . _write_buffer . advance ( num_bytes ) file "" / usr / local / lib / python3 . <number> / dist - packages / tornado / iostream . py "" , line <number> , in advance assert <number> < size <= self . _size assertionerror ` ` ` # # # standalone code to reproduce the issue ` ` ` shell run any of your jupyter example in your docker image . ` ` ` # # # relevant log output _no response_ </details>",0
tensorflow/tensorflow,"w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libcudnn . so . <number> ' ; dlerror : libcudnn . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version <number> . <number> # # # custom code no # # # os platform and distribution ubuntu <number> # # # mobile device _no response_ # # # python version python <date> | packaged by conda - forge | ( main , <date> , <time> ) # # # bazel version bazel <number> . <number> # # # gcc / compiler version gcc ( ubuntu <number> . <number> - 1 ubuntu1 ~ <number> . <number> ) <number> . <number> # # # cuda / cudnn version <number> / <number> in conda env # # # gpu model and memory laptop <number> rtx # # # current behaviour ? a bug happened ! # # # standalone code to reproduce the issue ` ` ` shell i have tensorflow <number> installed and also from the code below i see cudnn <number> is found . ( samurai ) mona <user> - gpu - <number> : ~ / samurai $ cat cudnn_test . py import tensorflow as tf sys_details = tf . sysconfig . get_build_info ( ) cuda_version = sys_details [ "" cuda_version "" ] print ( cuda_version ) cudnn_version = sys_details [ "" cudnn_version "" ] print ( cudnn_version ) cuda_compute_capabilities = sys_details [ "" cuda_compute_capabilities "" ] print ( cuda_compute_capabilities ) ( samurai ) mona <user> - gpu - <number> : ~ / samurai $ python cudnn_test . py <number> <number> [ ' sm_35 ' , ' sm_50 ' , ' sm_60 ' , ' sm_70 ' , ' sm_75 ' , ' compute_80 ' ] ` ` ` however , when i run the following command , i get an error that cudnn <number> is not found . ` ` ` ( samurai ) mona <user> - gpu - <number> : ~ / samurai $ python train_samurai . py - - config configs / samurai / samurai . txt - - datadir data / duck / - - basedir . - - expname duck_test - - gpu <number> namespace ( config = none , basedir ='. ' , expname = ' duck_test ' , batch_size = <number> , learning_rate = <number> , epochs = <number> , steps_per_epoch = <number> , gpu = ' <number> ' , tpu = none , debug = false , profile = false , perturb = <number> , raw_noise_std = <number> , coarse_samples = <number> , linear_disparity_sampling = false , fine_samples = <number> , fourier_frequency = <number> , direction_fourier_frequency = <number> , random_encoding_offsets = true , fine_net_width = <number> , fine_net_depth = <number> , coarse_net_width = <number> , coarse_net_depth = <number> , appearance_latent_dim = <number> , diffuse_latent_dim = <number> , fix_diffuse = true , camera_distribution = ' sphere ' , use_fully_random_cameras = false , random_cameras_per_view = <number> , min_softmax_scaler = <number> , max_softmax_scaler = <number> , camera_weight_update_lr = <number> , camera_weight_update_momentum = <number> , bounding_size = <number> , resolution_factor = <number> , advanced_loss_done = <number> , network_gradient_norm_clipping = <number> , camera_gradient_norm_clipping = - <number> , not_learn_r = false , not_learn_t = false , not_learn_f = false , edge_align_step = <number> , num_edge_align_steps = <number> , pretrained_camera_poses_folder = none , start_f_optimization = <number> , start_fourier_anneal = <number> , finish_fourier_anneal = <number> , slow_scheduler_decay = <number> , brdf_schedule_decay = <number> , lambda_smoothness = <number> , smoothness_bound_dividier = <number> , coarse_distortion_lambda = <number> , fine_distortion_lambda = <number> , normal_direction_lambda = <number> , mlp_normal_direction_lambda = <number> , disable_posterior_scaling = false , disable_mask_uncertainty = true , lambda_brdf_decoder_smoothness = <number> , lambda_brdf_decoder_sparsity = <number> , camera_lr = <number> , camera_lr_decay = <number> , camera_regularization = <number> , aim_center_regularization = <number> , camera_rotation = ' lookat ' , learn_camera_offsets = true , basecolor_metallic = true , skip_decomposition = false , compose_on_white = true , rotating_object = false , single_env = false , brdf_preintegration_path = ' data / neural_pil / brdflut . hdr ' , illumination_network_path = ' data / neural_pil / illumination - network ' , datadir = ' data / duck / ' , max_resolution_dimension = <number> , test_holdout = <number> , dataset = ' samurai ' , load_gt_poses = false , canonical_pose = <number> , log_step = <number> , weights_epoch = <number> , validation_epoch = <number> , testset_epoch = <number> , video_epoch = <number> , lrate_decay = <number> , render_only = false ) <number> - <number> - <number> <time> . <number> : i tensorflow / stream_executor / cuda / cuda_gpu_executor . cc : <number> ] successful numa node read from sysfs had negative value ( - <number> ) , but there must be at least one numa node , so returning numa node zero <number> - <number> - <number> <time> . <number> : w tensorflow / stream_executor / platform / default / dso_loader . cc : <number> ] could not load dynamic library ' libcudnn . so . <number> ' ; dlerror : libcudnn . so . <number> : cannot open shared object file : no such file or directory ; ld_library_path : / usr / local / lib <annoyed> home / mona / mvtec / halcon - <number> - progress / / lib / x64 - linux <annoyed> usr / local / cuda - <number> / lib64 <annoyed> home / mona / onnx - tensorrt / build : <number> - <number> - <number> <time> . <number> : w tensorflow / core / common_runtime / gpu / gpu_device . cc : <number> ] cannot dlopen some gpu libraries . please make sure the missing libraries mentioned above are installed properly if you would like to use gpu . follow the guide at <url> for how to download and setup the required libraries for your platform . skipping registering gpu devices . <repeated> utilizing <number> gpus for training . <number> - <number> - <number> <time> . <number> : i tensorflow / core / platform / cpu_feature_guard . cc : <number> ] this tensorflow binary is optimized with oneapi deep neural network library ( onednn ) to use the following cpu instructions in performance - critical operations : avx2 avx512f fma to enable them in other operations , rebuild tensorflow with the appropriate compiler flags . ( <number> , <number> ) model : "" sequential_12 "" _________________________________________________________________ layer ( type ) output shape param # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = mappingnetwork / layer_0 ( den ( none , <number> ) <number> se ) mappingnetwork / layer_1 ( den ( none , <number> ) <number> se ) mappingnetwork / final ( dense ( none , <number> ) <number> ) reshape_1 ( reshape ) ( none , <number> , <number> , <number> ) <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = total params : <number> trainable params : <number> non - trainable params : <number> _________________________________________________________________ model : "" sequential_13 "" _________________________________________________________________ layer ( type ) output shape param # = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = conditionalnetwork / dense1 ( ( none , <number> ) <number> dense ) conditionalnetwork / densefin ( none , <number> ) <number> al ( dense ) reshape_2 ( reshape ) ( none , <number> , <number> ) <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = total params : <number> trainable params : <number> non - trainable params : <number> _________________________________________________________________ found ckpts [ ] starting training in epoch <number> at step <number> start training . <repeated> / home / mona / anaconda3 / envs / samurai / lib / python3 . <number> / site - packages / tensorflow / python / framework / indexed_slices . py : <number> : userwarning : converting sparse indexedslices ( indexedslices ( indices = tensor ( "" gradients / interpolate_bilinear / gather - bottom_right / gatherv2_grad / reshape_1 : <number> "" , shape =( <number> , ) , dtype = int32 ) , values = tensor ( "" gradients / interpolate_bilinear / gather - bottom_right / gatherv2_grad / reshape : <number> "" , shape =( <number> , <number> ) , dtype = float32 ) , dense_shape = tensor ( "" gradients / interpolate_bilinear / gather - bottom_right / gatherv2_grad / cast : <number> "" , shape =( <number> , ) , dtype = int32 ) ) ) to a dense tensor of unknown shape . this may consume a large amount of memory . warnings . warn ( / home / mona / anaconda3 / envs / samurai / lib / python3 . <number> / site - packages / tensorflow / python / framework / indexed_slices . py : <number> : userwarning : converting sparse indexedslices ( indexedslices ( indices = tensor ( "" gradients / interpolate_bilinear / gather - bottom_left / gatherv2_grad / reshape_1 : <number> "" , shape =( <number> , ) , dtype = int32 ) , values = tensor ( "" gradients / interpolate_bilinear / gather - bottom_left / gatherv2_grad / reshape : <number> "" , shape =( <number> , <number> ) , dtype = float32 ) , dense_shape = tensor ( "" gradients / interpolate_bilinear / gather - bottom_left / gatherv2_grad / cast : <number> "" , shape =( <number> , ) , dtype = int32 ) ) ) to a dense tensor of unknown shape . this may consume a large amount of memory . warnings . warn ( / home / mona / anaconda3 / envs / samurai / lib / python3 . <number> / site - packages / tensorflow / python / framework / indexed_slices . py : <number> : userwarning : converting sparse indexedslices ( indexedslices ( indices = tensor ( "" gradients / interpolate_bilinear / gather - top_right / gatherv2_grad / reshape_1 : <number> "" , shape =( <number> , ) , dtype = int32 ) , values = tensor ( "" gradients / interpolate_bilinear / gather - top_right / gatherv2_grad / reshape : <number> "" , shape =( <number> , <number> ) , dtype = float32 ) , dense_shape = tensor ( "" gradients / interpolate_bilinear / gather - top_right / gatherv2_grad / cast : <number> "" , shape =( <number> , ) , dtype = int32 ) ) ) to a dense tensor of unknown shape . this may consume a large amount of memory . warnings . warn ( / home / mona / anaconda3 / envs / samurai / lib / python3 . <number> / site - packages / tensorflow / python / framework / indexed_slices . py : <number> : userwarning : converting sparse indexedslices ( indexedslices ( indices = tensor ( "" gradients / interpolate_bilinear / gather - top_left / gatherv2_grad / reshape_1 : <number> "" , shape =( <number> , ) , dtype = int32 ) , values = tensor ( "" gradients / interpolate_bilinear / gather - top_left / gatherv2_grad / reshape : <number> "" , shape =( <number> , <number> ) , dtype = float32 ) , dense_shape = tensor ( "" gradients / interpolate_bilinear / gather - top_left / gatherv2_grad / cast : <number> "" , shape =( <number> , ) , dtype = int32 ) ) ) to a dense tensor of unknown shape . this may consume a large amount of memory . warnings . warn ( <date> [ . <repeated> ] - eta : <number> <time> - loss : <number> - loss_camera : <date> - fine_loss : <number> ` ` ` ` ` ` # # # relevant log output ` ` ` shell ( samurai ) mona <user> - gpu - <number> : ~ / samurai $ lsb_release - a lsb version : core - <number> . 0 ubuntu4 - noarch : security - <number> . 0 ubuntu4 - noarch distributor id : ubuntu description : ubuntu <number> . <number> lts release : <number> codename : jammy ( samurai ) mona <user> - gpu - <number> : ~ / samurai $ uname - a linux ard - gpu - <number> <number> . <number> - <number> - generic # <number> ~ <number> . <number> - ubuntu smp preempt_dynamic mon may <number> <time> utc <number> x86_64 x86_64 x86_64 gnu / linux ` ` ` ` ` ` ( samurai ) mona <user> - gpu - <number> : ~ / samurai $ nvidia - smi tue <date> <time> <number> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | nvidia - smi <number> . <number> driver version : <number> . <number> cuda version : <number> | | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - + | gpu name persistence - m | bus - id disp . a | volatile uncorr . ecc | | fan temp perf pwr : usage / cap | memory - usage | gpu - util compute m . | | | | mig m . | |== = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = + = = = = = = = = = = = = = = = = = = = = = = + = = = = = = = = = = = = = = = = = = = = ==| | <number> nvidia geforce rtx <number> l . <repeated> on | <number> <time> . <number> off | n / a | | n / a 4 9 c p8 1 7 w / 9 0 w | 1 0 2 mib / 1 6 3 8 4 mib | <percent> default | | | | n / a | + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - + - - - - - - - - - - - - - - - - - - - - - - + + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | processes : | | gpu gi ci pid type process name gpu memory | | id id usage | |== = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ==| | <number> n / a n / a <number> g / usr / lib / xorg / xorg 9 5 mib | | <number> n / a n / a <number> g . <repeated> libexec / gnome - remote - desktop - daemon 3 mib | + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + ` ` ` ` ` ` ( samurai ) mona <user> - gpu - <number> : ~ / samurai $ nvcc - - version nvcc : nvidia ( r ) cuda compiler driver copyright ( c ) <number> - <number> nvidia corporation built on wed_jun__8_ <time> _pdt_2022 cuda compilation tools , release <number> , v11 . <number> build cuda_11 . <number> . r11 . <number> / compiler . 3 1 4 4 2 5 9 3 _0 ` ` ` the code is from this repo ` ` ` </details>",0
tensorflow/tensorflow,"unexpected failure when preparing tensor allocations : tensorflow / lite / kernels / pad . cc : <number> sizeofdimension ( op_context - > paddings , <number> ) = op_context - > dims ( <number> ! = <number> ) node number <number> ( pad ) failed to prepare . i have converted my densenet - <number> model to model . tflite and when i am loading it to android app and trying to make predictions , it ' s giving following errors : java . lang . illegalstateexception : internal error : unexpected failure when preparing tensor allocations sizeofdimension ( op_context - > paddings , <number> ) ! = op_context - > dims ( <number> ! = <number> ) node number <number> ( pad ) failed to prepare . at org . tensorflow . lite . nativeinterpreterwrapper . allocatetensors ( native method ) at org . tensorflow . lite . nativeinterpreterwrapper . allocatetensorsifneeded ( nativeinterpreterwrapper . java : <number> ) at org . tensorflow . lite . nativeinterpreterwrapper . run ( nativeinterpreterwrapper . java : <number> ) at org . tensorflow . lite . interpreterimpl . runformultipleinputsoutputs ( interpreterimpl . java : <number> ) at org . tensorflow . lite . interpreter . runformultipleinputsoutputs ( interpreter . java : <number> ) at org . tensorflow . lite . interpreterimpl . run ( interpreterimpl . java : <number> ) at org . tensorflow . lite . interpreter . run ( interpreter . java : <number> ) at com . example . appleleafdiseasedetection . diseasedetector <money> . onclick ( diseasedetector . java : <number> ) at android . view . view . performclick ( view . java : <number> ) at android . view . view . performclickinternal ( view . java : <number> ) at android . view . view . access <money> ( view . java : <number> ) at android . view . view $ performclick . run ( view . java : <number> ) at android . os . handler . handlecallback ( handler . java : <number> ) at android . os . handler . dispatchmessage ( handler . java : <number> ) at android . os . looper . looponce ( looper . java : <number> ) at android . os . looper . loop ( looper . java : <number> ) at android . app . activitythread . main ( activitythread . java : <number> ) at java . lang . reflect . method . invoke ( native method ) at com . android . internal . os . runtimeinit $ methodandargscaller . run ( runtimeinit . java : <number> ) at com . android . internal . os . zygoteinit . main ( zygoteinit . java : <number> ) how can i solve it ?",0
tensorflow/tensorflow,"documentation bug ： the description of padding <details> <summary> click to expand </summary> # # # issue type documentation bug # # # have you reproduced the bug with tf nightly ? no # # # source source # # # tensorflow version tf2 . <number> # # # custom code yes # # # os platform and distribution macos # # # mobile device _no response_ # # # python version <number> # # # bazel version _no response_ # # # gcc / compiler version _no response_ # # # cuda / cudnn version _no response_ # # # gpu model and memory _no response_ # # # current behaviour ? # # # # output ` ` ` valueerror : the ` padding ` argument must be a tuple of <number> integers . received : { ' padding ' ` ` ` # # # # document | ` padding ` | int , or tuple of int ( length <number> ) , or dictionary . | | - - - - - - - - - | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - | # # # standalone code to reproduce the issue ` ` ` shell input_shape = ( <number> , <number> , <number> ) x = np . arange ( np . prod ( input_shape ) ) . reshape ( input_shape ) x = zeropadding1d ( { ' padding ' : <number> })(x ) print ( x ) ` ` ` # # # relevant log output _no response_ </details>",0
tensorflow/tensorflow,"tensorflow lite on raspberry pi <details> <summary> click to expand </summary> # # # issue type bug # # # have you reproduced the bug with tf nightly ? yes # # # source source # # # tensorflow version tflite_runtime - <number> . <number> - cp39 - cp39 - manylinux2014_armv7l . whl # # # custom code yes # # # os platform and distribution linux raspbari14 <date> - v7 + # <number> smp wed <date> <time> bst <number> armv7l gnu / linux # # # mobile device _no response_ # # # python version python <number> . <number> ( default , <date> , <time> ) # # # bazel version _no response_ # # # gcc / compiler version [ gcc <number> . <number> <number> ] on linux # # # cuda / cudnn version n / a # # # gpu model and memory n / a # # # current behaviour ? not working as documented : ` import tflite_runtime . interpreter as tflite ` how to import tensorflow lite in python scripts ? # # # standalone code to reproduce the issue ` ` ` shell $ python3 - m pip install tflite - runtime looking in indexes : <url> <url> collecting tflite - runtime downloading tflite_runtime - <number> . <number> - cp39 - cp39 - manylinux2014_armv7l . whl ( <number> mb ) | █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ █ | <number> mb <number> mb / s requirement already satisfied : numpy > = <number> . <number> in / home / chowkidar / . local / lib / python3 . <number> / site - packages ( from tflite - runtime ) ( <number> . <number> ) installing collected packages : tflite - runtime successfully installed tflite - runtime - <number> . <number> $ python3 python <number> . <number> ( default , <date> , <time> ) [ gcc <number> . <number> <number> ] on linux type "" help "" , "" copyright "" , "" credits "" or "" license "" for more information . > > > import tensorflow traceback ( most recent call last ) : file "" <stdin> "" , line <number> , in <module> modulenotfounderror : no module named ' tensorflow ' > > > import tflite_runtime . interpreter as tflite traceback ( most recent call last ) : file "" <stdin> "" , line <number> , in <module> file "" / home / chowkidar / . local / lib / python3 . <number> / site - packages / tflite_runtime / interpreter . py "" , line <number> , in <module> from tflite_runtime import _pywrap_tensorflow_interpreter_wrapper as _interpreter_wrapper importerror : / usr / lib / arm - linux - gnueabihf / libstdc + + . so . <number> ` glibcxx_3 . <number> ' not found ( required by / home / chowkidar / . local / lib / python3 . <number> / site - packages / tflite_runtime / _pywrap_tensorflow_interpreter_wrapper . so ) > > > ` ` ` # # # relevant log output _no response_ </details>",0
microsoft/vscode,give ms - python . debugpy access to portsattributes proposal the python debugger extension has adopted the portsattributes api to help us gain confidence in the api before finalization . not granting that extension access to the api was an oversight .,0
microsoft/vscode,"verify fix / revision to code actions on save tests <url> and new changes from <url> related to <url> added back old boolean values ( since we reverted the changes for migration ) in addition to supporting new enum values . this is for both code actions in notebooks and in the editor find ` notebook . codeactionsonsave ` or ` editor . codeactionsonsave ` <number> . test each enum ' s behavior . note that ` always ` currently does not support code actions on auto save after delay . ( easiest code actions to test would be ` source . fixall ` and ` source . organizeimports ` . other code actions like ` source . fixall . eslint ` and ` source . removeunusedimports ` are supported as well . <number> . test boolean behavior . ( true and ` explicit ` should be the same , ` false ` and ` never ` should be the same . there are descriptions about future deprecation and behavior as well )",0
microsoft/vscode,"comments editor height is incorrect when window is resized to be small <number> . resize window <number> . start a comment <number> . : bug you can see from the scrollbar , the comment text does not fill the full editor [ image ] ( <url>",0
microsoft/vscode,"[ regression ] codeaction on save is broken version : <number> . <number> - insider commit : aad333b878b4cfce2f4152d48552fb6f980d7daf * have the user setting spec ' d below * open ` src / vs / editor / contrib / stickyscroll / test / browser / stickyscroll . test . ts ` * remove the semicolon on line <number> * save via ` cmd + s ` , semi column is not inserted ` ` ` "" editor . codeactionsonsave "" : { "" source . fixall . eslint "" : "" explicit "" , "" source . removeunusedimports "" } , ` ` `",0
microsoft/vscode,"chat view ` err error : invalid range : [ <number> , <number> ) ` in one of my workspaces i see no more chat . the console shows the stacktraces below , the debugger stops like this < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> ` ` ` err error : invalid range : [ <number> , <number> ) at new k ( offsetrange . ts : <number> <time> ) at c . g ( chatmodel . ts : <number> <time> ) at chatmodel . ts : <number> : <number> at array . map ( <anonymous> ) at c . f ( chatmodel . ts : <number> <time> ) at new c ( chatmodel . ts : <number> <time> ) at g . j ( instantiationservice . ts : <number> <time> ) at g . createinstance ( instantiationservice . ts : <number> <time> ) at o ( chatserviceimpl . ts : <number> <time> ) at o . getorrestoresession ( chatserviceimpl . ts : <number> <time> ) at s . u ( chatviewpane . ts : <number> <time> ) at s . render ( paneview . ts : <number> : <number> ) at s . render ( viewpane . ts : <number> : <number> ) at r . rb ( viewpanecontainer . ts : <number> : <number> ) at u . value ( viewpanecontainer . ts : <number> : <number> ) at c . z ( event . ts : <number> <time> ) at c . a ( event . ts : <number> : <number> ) at c . fire ( event . ts : <number> : <number> ) at b . i ( viewcontainermodel . ts : <number> <time> ) at b . h ( viewcontainermodel . ts : <number> : <number> ) at u . value ( viewcontainermodel . ts : <number> <time> <number> ) at c . z ( event . ts : <number> <time> ) at c . fire ( event . ts : <number> : <number> ) at u . value ( event . ts : <number> : <number> ) at l . z ( event . ts : <number> <time> ) at l . a ( event . ts : <number> : <number> ) at l . fire ( event . ts : <number> : <number> ) at l . fire ( event . ts : <number> <time> ) at s . setcontext ( contextkeyservice . ts : <number> <time> ) at u . reset ( contextkeyservice . ts : <number> <time> ) at new u ( contextkeyservice . ts : <number> : <number> ) at s . createkey ( contextkeyservice . ts : <number> <time> ) at w ( contextkeyservice . ts : <number> <time> ) at g . invokefunction ( instantiationservice . ts : <number> <time> ) at y . n ( commandservice . ts : <number> <time> ) at y . executecommand ( commandservice . ts : <number> <time> ) at p . $ executecommand ( mainthreadcommands . ts : <number> <time> ) at m . s ( rpcprotocol . ts : <number> <time> ) at m . q ( rpcprotocol . ts : <number> <time> ) at m . m ( rpcprotocol . ts : <number> <time> ) at m . l ( rpcprotocol . ts : <number> <time> ) at u . value ( rpcprotocol . ts : <number> <time> ) at c . z ( event . ts : <number> <time> ) at c . fire ( event . ts : <number> : <number> ) at r . fire ( ipc . net . ts : <number> <time> ) at y . onmessage ( localprocessextensionhost . ts : <number> <time> ) log . ts : <number> err invalid range : [ <number> , <number> <sad> error : invalid range <number> ) at new k ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . g ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> : <number> at array . map ( <anonymous> ) at c . f ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> : <number> ) at new c ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at g . j ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at g . createinstance ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> : <number> ) at o ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> : <number> ) at o . getorrestoresession ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> : <number> ) at s . u ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at s . render ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> : <number> ) at s . render ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at r . rb ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at u . value ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . z ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . a ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . fire ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at b . i ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at b . h ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at u . value ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . z ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . fire ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at u . value ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at l . z ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at l . a ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at l . fire ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at l . fire ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at s . setcontext ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at u . reset ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at new u ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at s . createkey ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at w ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at g . invokefunction ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at y . n ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at y . executecommand ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at p . $ executecommand ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at m . s ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at m . q ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at m . m ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at m . l ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at u . value ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . z ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at c . fire ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at r . fire ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at y . onmessage ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) ` ` `",0
microsoft/vscode,"[ web ] [ ff ] web socket breaks when changing network at gitpod we received bug requests that in firefox ( <number> - <number> ) vs code web ( <number> ) sometimes became unresponsive . see [ loom ] ( <url> for what unresponsive means . it is hard to reproduce , but i was able with following leave ff tab in the background . <number> . trigger reconnects by toggling your wifi for instance . <number> . after a while come back to ff tab . debugging web part showed that frontend is keep asking to replay missing messages , but server keeps replaying with the same message . unfortunately i was not able to debug the server part .",0
microsoft/vscode,"extension magically got reenabled * i have rust - analyzer installed but disabled * it ' s now enabled without me doing something * i blame it on settings sync because yesterday i reenabled that and i have onboarded a bunch of clients ( vscode . dev , separate mac , etc ) # # steps to repro - open vs code - install an extension a and disable it - install older version of the extension using ` install another version . <repeated> ` action - open vs code using different user data directory but same extensions directory - ` code - - user - data - dir <folder> ` - update the extension from this instance 🐛 extension is enabled in other instance note that this is nothing to do with settings sync",0
microsoft/vscode,toggling file node in comments view focuses comment testing # <number> <number> . checkout <url> <number> . open comments view <number> . have ` debug . contribution . ts ` open and scrolled to the top of the file <number> . hit enter in the ` debug . contribution . ts ` node <number> . : bug get scrolled to the first comment,0
microsoft/vscode,debug console with dwarf debugging is not printing the expected value testing # <number> see top left ` a ` and debug console ` a `,0
microsoft/vscode,specify what is in the event data for ` env . ondidchangeshell ` testing # <number> ' env . ondidchangeshell ' tsdoc does not specify what the event data string will contain . it looks like it ' s the path to the newly selected default shell .,0
microsoft/vscode,seeing two action bars testing # <number> [ image ] ( <url> i am still trying to recap how i got there . <repeated> * * update : * * * have some pinned and non - pinned tabs * open an empty group to the right * drag the entire group to the right by dragging from empty space after the last tab * you end up with <number> action bars visible,0
microsoft/vscode,"debug toolbar with commandcenter limits command center search testing # <number> followed the steps to turn on the debug toolbar with commandcenter options . however , when the debugging started , clicking the area around the directory name did not trigger ' search files ' . ( the blank space at the right side of ' vscode - python ' in terms of the attached screenshot . i was able to trigger ' search files ' only when pressing specifically on the directory name , in this case , ' vscode - python . + + nice feature by the way < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> am "" src = "" <url> < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> am "" src = "" <url>",0
microsoft/vscode,enable source mapped stepping command is registered twice testing # <number> <number> . run disable source mapped stepping <number> . open command palette <number> . : bug are two enable source mapped stepping commands ( there ' s only one disable source mapped stepping command ) [ image ] ( <url>,0
microsoft/vscode,"insertfinalnewline breaks typings in first line in a new cell re # <number> , i was editing the endgame notebook in vs code repo but it keeps moving the cursor to the next line , which breaks typing . <url> it ' s very likely an issue with these two settings combined * ` "" files . insertfinalnewline "" : true ` * "" files . autosave "" we seems to have the same issue for files in text editor but untitled file does not suffer from this as it can not be auto saved . i wonder if we should have some special treatment for notebook cells , as it ' s very usual to create new cells , which are always empty at the beginning , typing in the first line is making it almost impossible . maybe we could keep the cursor position for this scenario .",0
microsoft/vscode,views entry is only present when english is the display language <url> english : [ image ] ( <url> korean : ! [ image ] ( <url> daniel,0
microsoft/vscode,settings sync is uninstalling the extension that is installed from sources settings sync is uninstalling the extension that is installed from sources . it needs complex steps to setup and reproduce . <user> has this setup and is seeing this issue .,0
microsoft/vscode,problematic theme styles white on gray is not readable . i think the explorer tree has a different behavior here . [ image ] ( <url>,0
microsoft/vscode,"scm sync select is enabled testing # <number> it seems like multiple selection is enabled in this list / tree , though without any value . let us disable it for now .",0
microsoft/vscode,"arrow up while editing comment goes to previous comment testing # <number> editing the second of two comment , the arrow up key navigates to the first comment instead of the previous line in the comment being edited . <url>",0
microsoft/vscode,"settings description is wrong / swapped testing # <number> * configure ` "" notebook . codeactionsonsave "" : { "" notebook . source . normalizevariablenames "" * 🐛 the description of the value is wrong < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url>",0
microsoft/vscode,remove xtermterminal . clearactivesearchdecoration version : <number> . <number> - insider ( user setup ) date [ <number> ] ( <url>,0
microsoft/vscode,"icon aria label is not updated / correct testing # <number> it says settings gear regardless , making it seem to a screen reader user like the icon has not been successfully changed . <url>",0
microsoft/vscode,"file > open recent > recent workspace no longet opens in new window when ctrl or shift used in vs code insiders type : <b> bug </b> opening in new window straing from file > open recent menu is great tool to quickly get to another workspace wiithout loosing curren open one , and much faster then new window and searching same workspace in new window . so i hope this change is not intentional . steps to reproduce : <number> . have history of several opened workspaces <number> . open file > open recent submenu . <number> . press <kbd> ctrl </kbd> or <kbd> shift </kbd> and click on some of recent workspaces <number> . workspace in active window is replaces with selection from recent expecte behavior : new window should be opened with new workspace instead of replacing workspace in active window . this is behavior is reproducible in standalone ( zip ) insiders intallation but not not reprodusible in standalone ( zip ) stable intallation . however in stable <kbd> ctrl </kbd> ( <kbd> shift </kbd> ) sometimes does nothing , but never replaces current workspace . vs code version : code - insiders <number> . <number> - insider ( 1 0 9 e1f8d8afb754ed31317f79937a44e98d5063b , <number> - <number> - 2 5 t <time> . 2 9 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i7 - 1 1 8 5 g7 @ <number> . 0 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 5 0 gb ( <number> . 5 0 gb free ) | | process argv || | screen reader | no | | vm | <percent> | </details> extensions < - - generated by issue reporter - - >",0
microsoft/vscode,"[ accessibility ] focus does not move to the symbol in terminal accessible view type : <b> bug </b> <number> . open terminal in editor area . <number> . type ` echo hello ` and hit enter . <number> . type ` echo world ` and hit enter <number> . press alt + f2 to open accessible view <number> . press ctrl + shift + o to open symbol list and select ` echo hello ` and hit enter * note : the focus does not move to ` echo hello ` vs code version : code - insiders <number> . <number> - insider ( 1 0 9 e1f8d8afb754ed31317f79937a44e98d5063b , <number> - <number> - 2 5 t <time> . 2 9 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 4 5 g7 @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 1 gb ( <number> . 5 3 gb free ) | | process argv | - - crash - reporter - id b05b88e5 - <number> - <number> - ae34 - fa034ebddea9 | | screen reader | yes | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - android - dev - ext | ade | <number> . <number> aiprm - lang | aip | <number> . <number> bookmarks | ale | <number> . <number> openscad | ant | <number> . <number> spellright | ban | <date> zoterolatex | bna | <number> . <number> mermaid - markdown - syntax - highlighting | bpr | <number> . <number> doxdocgen | csc | <number> . <number> vscode - markdownlint | dav | <number> . <number> vscode - eslint | dba | <number> . <number> vscode - quick - select | dba | <number> . <number> vscode - deno | den | <number> . <number> gitlens | eam | <number> . <number> editorconfig | edi | <number> . <number> prettier - vscode | esb | <number> . <number> vscode - google - translate | fun | <date> codespaces | git | <number> . <number> copilot | git | <number> . <number> copilot - chat | git | <number> . <phone> remotehub | git | <number> . <number> vscode - github - actions | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> overleaf - workshop | iam | <number> . <number> cslpreview | igo | <number> . <number> easy - snippet | inu | <number> . <number> path - autocomplete | ion | <number> . <number> latex - workshop | jam | <number> . <number> lilypond - syntax | jea | <number> . <number> scheme | jea | <number> . <number> better - cpp - syntax | jef | <number> . <number> google - search | kam | <number> . <number> vscode - lua - format | koi | <number> . <number> lilypond - formatter | lhl | <number> . <number> lilypond - pdf - preview | lhl | <number> . <number> lilypond - snippets | lhl | <number> . <number> vslilypond | lhl | <number> . <number> zotero | mbl | <date> git - graph | mhu | <number> . <number> vscode - docker | ms - | <number> . <number> black - formatter | ms - | <number> . <number> flake8 | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> azure - repos | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> powershell | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> vscode - github - issue - notebooks | ms - | <date> vscode - selfhost - test - provider | ms - | <date> vscode - serial - monitor | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> autodocstring | njp | <number> . <number> pandocciter | not | <number> . <number> shiny - python | pos | <number> . <number> shinyuieditor | pos | <number> . <number> quarto | qua | <number> . <number> r - debugger | rde | <number> . <number> java | red | <number> . <number> vscode - xml | red | <number> . <number> r | red | <number> . <number> multi - command | ryu | <number> . <number> vscode - deepl | soe | <number> . <number> abc - music | sof | <number> . <number> lua | sum | <number> . <number> latex - utilities | tec | <date> cmake | twx | <date> errorlens | use | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - arduino | vsc | <number> . <number> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> markdown - all - in - one | yzh | <number> . <number> grammarly | znc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv69 <time> <number> vsins8 <time> <number> vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> pythontb : <number> pythonptprofiler : <number> vshan8 <time> <number> vscod805cf : <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> ecj1e33 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> welcomedialog : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> copilotsettingt : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> pythonlinttype : <number> pythonmpsinfo : <number> dsvsc0 <time> <number> pythontestfixt : <number> pythonfb28095 <time> <number> pythonregdiag : <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,cannot read properties of undefined ( reading ' id ' ) * open a file from a pull request * get an error saying id cannot be read from undefined ` ` ` err cannot read properties of undefined ( reading ' id ' <sad> typeerror read properties of undefined ( reading ' id ' ) at vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> at object . h [ as map ] ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <time> <number> ) at h . next ( <anonymous> ) at p ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <time> <number> ) at r . setactions ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at d . z ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at h . value ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at b . z ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at b . fire ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at b . resume ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ) at vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / workbench / workbench . desktop . main . js : <number> <time> <number> ` ` `,0
microsoft/vscode,cannot read properties of null ( reading ' b ' ) ` ` ` err [ uncaught exception in main ] : cannot read properties of null ( reading ' b ' <sad> typeerror read properties of null ( reading ' b ' ) at h ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at d . value ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . z ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . a ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . fire ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at d . value ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . z ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . fire ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at j . setready ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at p . notifyready ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> : <number> ) at object . call ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at i . s ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at i . q ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at d . value ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . z ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . a ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . fire ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at d . value ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . z ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . fire ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at d . value ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . z ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at $ . fire ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at me ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> <time> <number> ) at ipcmainimpl . h ( / applications / visual studio code - insiders . app / contents / resources / app / out / vs / code / electron - main / main . js : <number> : <number> ) at ipcmainimpl . emit ( node : events : <number> <time> ) ` ` `,0
microsoft/vscode,"active editor has commenting range is true even when it should not be i do not have a pr checked out and yet , it ' s ` true ` [ image ] ( <url> ! [ image ] ( <url>",0
microsoft/vscode,toggling tab pin row setting hides actions for me going from multi - row tabs to single - row tabs shows no editor actions .,0
microsoft/vscode,"scm sync view lost from the tree on mouse click nice view 👍 noticed that when you click on a file with the mouse , focus moves into the editor immediately . maybe connect with <user> and custom trees to learn how you can get opening behaviour that is consistent for free .",0
microsoft/vscode,"open editors view does not close editor that is selected anymore type : <b> bug </b> on the right panel , where the opened files are listed , when you have a file selected and hover on another file it appears a close ( x ) icon , if you click that (x ) the editor window that is closed is the file that is selected and not the file where you clicked (x ) . i keep repoen closed editor because of this recent issue . vs code version : code <number> . <number> ( universal ) ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 7 9 0 z ) os version : darwin arm64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | apple m2 pro ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 0 4 gb free ) | | process argv | - - crash - reporter - id a4b55f5e - <number> - 4 0 2 c - 8 5 da - b605e22d73f5 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - better - comments | aar | <number> . <number> alpine - js - intellisense | adr | <number> . <number> laravel - extra - intellisense | ami | <number> . <number> sidebar - markdown - notes | ass | <number> . <number> laravel - blade - spacer | aus | <number> . <number> laravel - docs | aus | <number> . <number> tailwind - docs | aus | <number> . <number> vscode - intelephense - client | bme | <number> . <number> vscode - tailwindcss | bra | <number> . <number> vscode - coloured - status - bar - problems | bra | <number> . <number> vscode - better - align | cho | <number> . <number> laravel - goto - view | cod | <number> . <number> save - commands | dee | <number> . <number> vscode - notes | dio | <number> . <number> githistory | don | <date> gitlens | eam | <number> . <number> vscode - html - css | ecm | <number> . <number> prettier - vscode | esb | <number> . <number> restore - terminals | eth | <number> . <number> php - intellisense | fel | <date> auto - rename - tag | for | <date> code - runner | for | <number> . <number> vscode - google - translate | fun | <date> html - preview - vscode | geo | <number> . <number> copilot | git | <number> . <number> copilot - chat | git | <number> . <number> copilot - labs | git | <date> gitlab - workflow | git | <number> . <number> githd | hui | <number> . <number> vscode - peacock | joh | <number> . <number> vscode - inline - svg | kon | <number> . <number> rainbow - csv | mec | <number> . <number> php - namespace - resolver | meh | <number> . <number> git - graph | mhu | <number> . <number> dotenv | mik | <number> . <number> theme - monokai - pro - vscode | mon | <number> . <number> empty - directory - extension | mrk | <number> . <number> test - adapter - converter | ms - | <number> . <number> resourcemonitor | mut | <number> . <number> laravel - goto - components | nao | <number> . <number> sftp | nat | <number> . <number> vscode - configurable - shortcuts | nor | <number> . <number> laravel - blade | one | <number> . <number> laravel5 - snippets | one | <number> . <number> material - icon - theme | pki | <number> . <number> vscode - thunder - client | ran | <number> . <number> vscode - yaml | red | <number> . <number> laravel - artisan | rya | <date> vue - vscode - snippets | sdr | <number> . <number> vscode - blade - formatter | shu | <number> . <number> svg - preview | sim | <number> . <number> vscode - fileutils | sle | <number> . <number> git - prefix | srm | <number> . <number> workspace - explorer | tom | <number> . <number> luna - paint | tyr | <number> . <number> remove - empty - lines | use | <number> . <number> vscode - icons | vsc | <number> . <number> volar | vue | <date> vscode - typescript - vue - plugin | vue | <date> vuetify - vscode | vue | <number> . <number> php - debug | xde | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl49 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vstes263cf : <number> vscorecescf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> <number> <time> <number> showlangstatbar : <number> 0 bi6i64 <time> <number> 0 3 d3595 <time> <number> ecj1e33 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,"terminal ps1 double < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : fedora <number> workstation ediditon # # # my bashrc : ` ` ` bash # . bashrc # source global definitions if [ - f / etc / bashrc ]; then . / etc / bashrc fi # branch name parse_git_branch ( ) { git branch <number> > / dev / null | sed - e ' / ^[^ *]/ d ' - e ' s / * \ \(.*\\)/ ( \ \ <number> ) / ' } # user specific environment if ! [ [ "" $ path "" = ~ "" $ home / . local / bin :$ home / bin : "" ] ] then path =""$ home / . local / bin :$ home / bin :$ path "" fi export path ps1 =""[\\ u @ \ \ h \ \ w ] \ \ [ \ \ e [ 9 1 m \ \]\\$ ( parse_git_branch ) \ \ [ \ \ e [ 0 0 m \ \]$ "" # uncomment the following line if you do not like systemctl ' s auto - paging feature : # export systemd_pager = # user specific aliases and functions if [ - d ~ / . bashrc . d ]; then for rc in ~ / . bashrc . d / * ; do if [ - f "" $ rc "" ]; then . "" $ rc "" fi done fi unset rc ` ` ` separate terminal / vscode . lower ( vscode terminal ) and branch is updating in the both cases ( left and right ) ! [ image ] ( <url> ! [ screenshot from <number> - <number> - <number> <number> - <number> - <number> ] ( <url> ! [ screenshot from <number> - <number> - <number> <number> - <number> - <number> ] ( <url>",0
microsoft/vscode,"tasks using ` "" runon "" : "" folderopen "" ` are broken * have a task with ` "" runon "" like <url> * make sure it ran once * reload / reopen folder * 🐛 task does not run",0
microsoft/vscode,"[ accessibility ] display terminal - specific help in accessible view for terminal buffer type : <b> bug </b> currently , when alt + f1 is pressed in the accessible terminal buffer , it displays the following info : > in the accessible view , you can : > - show the next ( alt + ] ) or previous ( alt + [ ) item > - navigate to the toolbar ( shift + tab ) ) the above instruction is not applicable for the terminal buffer , and the original terminal buffer help content needs to be displayed here . vs code version : code - insiders <number> . <number> - insider ( 7 c7f7eee860e299499a3bd2915ad716f09f2d6a6 , <number> - <number> - 1 9 t <time> . 7 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 4 5 g7 @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 1 gb ( <number> . 0 6 gb free ) | | process argv |c :\\\\ users \ \ \ \ jseo1005 \ \ \ \ onedrive - university of illinois - urbana \ \ \ \ desktop \ \ \ \ source . r - - crash - reporter - id b05b88e5 - <number> - <number> - ae34 - fa034ebddea9 | | screen reader | yes | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - android - dev - ext | ade | <number> . <number> aiprm - lang | aip | <number> . <number> bookmarks | ale | <number> . <number> openscad | ant | <number> . <number> spellright | ban | <date> zoterolatex | bna | <number> . <number> mermaid - markdown - syntax - highlighting | bpr | <number> . <number> doxdocgen | csc | <number> . <number> vscode - markdownlint | dav | <number> . <number> vscode - eslint | dba | <number> . <number> vscode - quick - select | dba | <number> . <number> vscode - deno | den | <number> . <number> gitlens | eam | <number> . <number> editorconfig | edi | <number> . <number> prettier - vscode | esb | <number> . <number> vscode - google - translate | fun | <date> codespaces | git | <number> . <number> copilot | git | <number> . <number> copilot - chat | git | <number> . <phone> remotehub | git | <number> . <number> vscode - github - actions | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> overleaf - workshop | iam | <number> . <number> cslpreview | igo | <number> . <number> easy - snippet | inu | <number> . <number> path - autocomplete | ion | <number> . <number> latex - workshop | jam | <number> . <number> lilypond - syntax | jea | <number> . <number> scheme | jea | <number> . <number> better - cpp - syntax | jef | <number> . <number> google - search | kam | <number> . <number> vscode - lua - format | koi | <number> . <number> lilypond - formatter | lhl | <number> . <number> lilypond - pdf - preview | lhl | <number> . <number> lilypond - snippets | lhl | <number> . <number> vslilypond | lhl | <number> . <number> zotero | mbl | <date> git - graph | mhu | <number> . <number> vscode - docker | ms - | <number> . <number> black - formatter | ms - | <number> . <number> flake8 | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> azure - repos | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> powershell | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> vscode - github - issue - notebooks | ms - | <date> vscode - selfhost - test - provider | ms - | <date> vscode - serial - monitor | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> autodocstring | njp | <number> . <number> pandocciter | not | <number> . <number> shiny - python | pos | <number> . <number> shinyuieditor | pos | <number> . <number> quarto | qua | <number> . <number> r - debugger | rde | <number> . <number> java | red | <number> . <number> vscode - xml | red | <number> . <number> r | red | <number> . <number> multi - command | ryu | <number> . <number> vscode - deepl | soe | <number> . <number> abc - music | sof | <number> . <number> lua | sum | <number> . <number> latex - utilities | tec | <date> cmake | twx | <date> errorlens | use | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - arduino | vsc | <number> . <number> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> markdown - all - in - one | yzh | <number> . <number> grammarly | znc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv69 <time> <number> vsins8 <time> <number> vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> pythontb : <number> pythonptprofiler : <number> vshan8 <time> <number> vscod805cf : <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> ecj1e33 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> welcomedialog : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> copilotsettingt : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> pythonlinttype : <number> pythonmpsinfo : <number> dsvsc0 <time> <number> pythontestfixt : <number> pythonfb28095 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,"extension development ： frequent calls to _ondidchangetreedata . fire ( ) , resulting in memory leakage < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : v1 . <number> - os version : linux kkuser - virtual - machine <number> . <number> - <number> - generic # <number> ~ <number> . <number> - ubuntu smp mon <date> <time> utc <number> x86_64 x86_64 x86_64 gnu / linux steps to reproduce there are constant changes in attribute states in the treeview <number> . frequent calls to this . _ondidchangetreedata . fire ( ) functions result in memory leakage",0
microsoft/vscode,bad diff notice the confusing import [ monaco editor repro ] ( <url>,0
microsoft/vscode,"terminal context menu not hiding after running action < - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : insiders and from sources steps to reproduce : <number> . create terminal <number> . right click to show context menu <number> . run ` copy ` or ` clear ` action <number> . : bug menu still visible regression from <url> cc <user>",0
microsoft/vscode,"[ accessibility ] accessible - buffer is not auto - focused type : <b> bug </b> i think there was an inadvertent regression in recent accessibility patches . { "" terminal . integrated . focusafterrun "" : "" accessible - buffer "" } setting does not take any effect . tested on windows with nvda and jaws . the focus does not move to the accessible buffer . vs code version : code - insiders <number> . <number> - insider ( bccfade64adb249f57c8fcf03cba41609f76ce5c , <number> - <number> - 1 5 t <time> . 5 0 8 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 4 5 g7 @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 1 gb ( <number> . 1 9 gb free ) | | process argv |c :\\\\ users \ \ \ \ jseo1005 \ \ \ \ onedrive - university of illinois - urbana \ \ \ \ desktop \ \ \ \ source . py - - crash - reporter - id b05b88e5 - <number> - <number> - ae34 - fa034ebddea9 | | screen reader | yes | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - android - dev - ext | ade | <number> . <number> aiprm - lang | aip | <number> . <number> bookmarks | ale | <number> . <number> openscad | ant | <number> . <number> spellright | ban | <date> zoterolatex | bna | <number> . <number> mermaid - markdown - syntax - highlighting | bpr | <number> . <number> doxdocgen | csc | <number> . <number> vscode - markdownlint | dav | <number> . <number> vscode - eslint | dba | <number> . <number> vscode - quick - select | dba | <number> . <number> vscode - deno | den | <number> . <number> gitlens | eam | <number> . <number> editorconfig | edi | <number> . <number> prettier - vscode | esb | <number> . <number> vscode - google - translate | fun | <date> codespaces | git | <number> . <number> copilot | git | <number> . <number> copilot - chat | git | <number> . <phone> remotehub | git | <number> . <number> vscode - github - actions | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> cslpreview | igo | <number> . <number> easy - snippet | inu | <number> . <number> path - autocomplete | ion | <number> . <number> latex - workshop | jam | <number> . <number> lilypond - syntax | jea | <number> . <number> scheme | jea | <number> . <number> better - cpp - syntax | jef | <number> . <number> google - search | kam | <number> . <number> vscode - lua - format | koi | <number> . <number> lilypond - formatter | lhl | <number> . <number> lilypond - pdf - preview | lhl | <number> . <number> lilypond - snippets | lhl | <number> . <number> vslilypond | lhl | <number> . <number> zotero | mbl | <date> git - graph | mhu | <number> . <number> vscode - docker | ms - | <number> . <number> black - formatter | ms - | <number> . <number> flake8 | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> azure - repos | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> powershell | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> vscode - github - issue - notebooks | ms - | <date> vscode - selfhost - test - provider | ms - | <date> vscode - serial - monitor | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> autodocstring | njp | <number> . <number> pandocciter | not | <number> . <number> shiny - python | pos | <number> . <number> shinyuieditor | pos | <number> . <number> quarto | qua | <number> . <number> r - debugger | rde | <number> . <number> java | red | <number> . <number> vscode - xml | red | <number> . <number> r | red | <number> . <number> multi - command | ryu | <number> . <number> vscode - deepl | soe | <number> . <number> abc - music | sof | <number> . <number> lua | sum | <number> . <number> latex - utilities | tec | <date> cmake | twx | <date> errorlens | use | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - arduino | vsc | <number> . <number> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> markdown - all - in - one | yzh | <number> . <number> grammarly | znc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv69 <time> <number> vsins8 <time> <number> vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> pythontb : <number> pythonptprofiler : <number> vshan8 <time> <number> vscod805cf : <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> ecj1e33 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> welcomedialog : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> copilotsettingt : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> pythonlinttype : <number> pythonmpsinfo : <number> dsvsc0 <time> <number> pythontestfixt : <number> pythonfb28095 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,typeerror : cannot read properties of undefined ( reading ' trim ' ) the diff editor was actually unable to compute the diff and just hangs . * original file : [ original . txt ] ( <url> * modified file : [ modified . txt ] ( <url> ` ` ` err cannot read properties of undefined ( reading ' trim ' <sad> typeerror read properties of undefined ( reading ' trim ' ) at $ ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) at e ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) at b ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) at e . h ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> : <number> ) at e . computediff ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> : <number> ) at v . l ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) at v . computediff ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) at i . d ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) at object . handlemessage ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) at a . k ( vscode - file :// vscode - app / applications / visual % 2 0 studio % 2 0 code % <number> - % 2 0 insiders . app / contents / resources / app / out / vs / base / worker / workermain . js <hashtag> editor worker service </hashtag> : <number> <time> <number> ) ` ` `,0
microsoft/vscode,"top padding is wrong on comment view zone notice the hover feedback is cut off vertically and should have additional spacing . [ image ] ( <url> setup : <number> . korean language pack ( may impact ? ) <number> . ` "" window . zoomlevel "" : <number> it also happens with other zoom levels",0
microsoft/vscode,sash variables end up on the html element i would have expected maybe the workbench element if this needs to be global ? [ image ] ( <url>,0
microsoft/vscode,f9 removes existing breakpoint instead of adding one - add a breakpoint on line <number> - move cursor to line <number> - press f9 - removes the breakpoint on line <number> instead of adding one on line <number> <user> this is from <url> why did that change ?,0
microsoft/vscode,"code cli update mechanism previous version renaming anomaly - vs code version : <number> - os version : linux when the vscode cli update mechanism updates the code binary , the process preserves the outdated version by appending the executable with . old . at present , the process appends a second period , resulting in code . <repeated> old . this occurs through ` code update ` or when it is updated through the notification pop - up when connected to tunnel on vscode . dev ` ` ` localhost / usr / local / bin # ls - la code * - rwxr - xr - x . <number> root root <number> <date> <time> code - rwxr - xr - x . <number> root root <number> <date> <time> code . <repeated> old localhost / usr / local / bin # . / code - - version code <number> . <number> ( commit <phone> d557a81c9d0b5f8a5a1e9274db5585 ) localhost / usr / local / bin # . / code . <repeated> old - - version code <number> . <number> ( commit 8 b617bd08fd9e3fc94d14adb8d358b56e3f72314 ) ` ` ` steps to reproduce invokde code cli update <number> . examine path where code cli lives",0
microsoft/vscode,"unbounded keybindings are presented in empty workbench hints find in files and show settings provide no value , just noise not sure who owns this , i remember christof but maybe not ?",0
microsoft/vscode,quick search priority over selected text we added support for auto - populating selected text to quick search ( <url> but setting ` preserveinput ` overrides this . this is because ` preserveinput ` takes precedence over any default string ( even if ` defaultfiltervalue ` is defined ) . <url> ( from <url>,0
microsoft/vscode,"when re - requesting a copilot inline chat answer , pressing escape accepts the current solution * trigger inline chat and send a command * press the reload button in the chat * press escape * notice that it keeps the last result ( and does not restore the initial document ) when i do not click the reload button , pressing escape restores the initial document . [ image ] ( <url> context / / remove short suffixes / prefixes for ( let i = <number> ; i < diffs . length ; i + + ) { const cur = diffs [ i ] ; let newdiff = cur ; const fullrange1 = sequence1 . extendtofullines <elongated> ( cur . seq1range ) ; const prefix = sequence1 . gettext ( new offsetrange ( fullrange1 . start , cur . seq1range . start ) ); if ( prefix . length > <number> & & prefix . trim ( ) . length <= <number> & & cur . seq1range . length + cur . seq2range . length > <number> ) { newdiff = newdiff . deltastart ( - prefix . length ) ; } const suffix = sequence1 . gettext ( new offsetrange ( cur . seq1range . endexclusive , fullrange1 . endexclusive ) ); if ( suffix . length > <number> & & ( suffix . trim ( ) . length <= <number> & & cur . seq1range . length + cur . seq2range . length > <number> ) ) { newdiff = newdiff . deltaend ( suffix . length ) ; } while ( true ) { const prevdiff = lastordefault ( newdiffs ) ; if ( prevdiff ) { if ( newdiff . intersectsortouches ( prevdiff ) ) { newdiff = newdiff . join ( prevdiff ) ; newdiffs . pop ( ); continue ; } } break ; } newdiffs . push ( newdiff ) ; } ` ` `",0
microsoft/vscode,"go to symbol in the terminal ' s accessible view does not contain all commands after the first invocation <number> . with screen reader mode enabled , run some commands in the terminal <number> . ` ctrl / cmd + up arrow ` to open the accessible view <number> . ` ctrl / cmd + shift + o ` to go to symbol <number> . ✅ the commands are there <number> . ` escape ` then ` ctrl / cmd + shift + o ` again <number> . 🐛 some commands are missing ( only the most recent one is there )",0
microsoft/vscode,test runner hangs with global ` teardown ` throwing steps to reproduce ` git co ben / eventual - earthworm ` or make sure <url> has landed <number> . in ` test / unit / electron / renderer . js ` make sure to make ` _allowedtestswithunhandledrejections ` and empty ` set ` <number> . open ` src / vs / workbench / services / lifecycle / test / electron - sandbox / lifecycleservice . test . ts ` <number> . click on ` suite ( ' lifecycleservice . <repeated> ` for running the suite => 🐛 the suite never finishes [ image ] ( <url> ! [ recording <number> - <number> - <number> at <number> <number> <number> ] ( <url>,0
microsoft/vscode,"problems with minimumcontrastratio inverse / selection edge cases upstream : <url> to verify on linux / macos / wsl <number> . run ` echo ' normal \\x 1 b [ 7 minverse \ \x 1 b [ 0 m ' ` <number> . test various values of ` terminal . integrated . minimumcontrastratio ` ( eg . <number> , <number> , <number> ) first with no selection and second with a selection . you may need to change your theme to see the differences",0
microsoft/vscode,"terminal : invisible text is visible in the dom renderer upstream : <url> repro on linux / macos / wsl <number> . run ` echo - e ' \\x 1 b [ 8 minvisible ' ` , it should not show invisible in the output",0
microsoft/vscode,"debug console is not working type : <b> bug </b> after updating yesterday , i encountered an issue with my vs code where i set a breakpoint and attempted to enter a variable in the debug console , but the console remained empty . vs code version : code <number> . <number> ( 8 b617bd08fd9e3fc94d14adb8d358b56e3f72314 , <number> - <number> - 0 6 t <time> . 4 3 8 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 9 gb ( <number> . 0 2 gb free ) | | process argv | - - file - uri file :/// d % 3 a / work / instachatai / instachataiapi . code - workspace - - crash - reporter - id 6 da24a21 - c0cd - 4 1 c8 - b3e7 - ed9a77b716df | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - codesnap | adp | <number> . <number> tabout | alb | <number> . <number> bookmarks | ale | <number> . <number> ng - template | ang | <number> . <number> vscode - django | bat | <number> . <number> vscode - opennewinstance | chr | <date> fastapi - snippets | dam | <number> . <number> dart - code | dar | <number> . <number> flutter | dar | <number> . <number> gitlens | eam | <number> . <number> prettier - vscode | esb | <number> . <number> remotehub | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> gc - excelviewer | gra | <date> todo - tree | gru | <date> vscode - drawio | hed | <number> . <number> git - graph | mhu | <number> . <number> dotenv | mik | <number> . <number> vscode - docker | ms - | <number> . <number> csharp | ms - | <number> . <number> vscode - dotnet - runtime | ms - | <number> . <number> vscode - edge - devtools | ms - | <number> . <number> autopep8 | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> remote - explorer | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> remote - server | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> autodocstring | njp | <number> . <number> material - icon - theme | pki | <number> . <number> material - product - icons | pki | <number> . <number> sqlite - viewer | qwt | <date> vscode - thunder - client | ran | <number> . <number> vscode - yaml | red | <number> . <number> errorlens | use | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscodeintellicode - completions | vis | <date> change - case | wma | <number> . <number> material - theme | zhu | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes627cf : <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh93 <time> <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> f6dab26 <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> a2ce337 <time> <number> 7 ij388 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,"port forwarding for remote - ssh does not notice closed socket on server side type : <b> bug </b> since the <number> . <number> update , using port forwards for remote ssh development has been extremely difficult for me , as the port forwarding system does not seem to notice when a socket is closed on the server side . this leads to my client application running on the local side ( generally chrome ) sending packets ( e . g . get requests ) into the port forward ( which shows up in ` netstat ` as ` established ` still from chrome to code , but those packets seem to be dropped into the bit bucket as the socket from the vscode - server to my application is closed ( in ` time_wait ` ) on the server ( remote development machine ) . this causes http requests to time out ( very . <repeated> verry . <repeated> slowly <elongated> ) which severely hampers being able to get anything done . vs code version : code <number> . <number> ( 8 b617bd08fd9e3fc94d14adb8d358b56e3f72314 , <number> - <number> - 0 6 t <time> . 7 5 9 z ) os version : linux x64 <number> . <number> - <number> - generic modes : remote os version : linux x64 <number> . <number> - <number> - cloud - amd64 <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - <number> cpu @ <number> . 0 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : disabled_software <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : disabled_off | | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 1 8 gb ( <number> . 5 4 gb free ) | | process argv | - - unity - launch - - crash - reporter - id f628f52a - 5 1 ea - 4 0 c8 - aedd - 0 af9d4a6bd9f | | screen reader | no | | vm | <percent> | | desktop_session | ubuntu - xorg | | xdg_current_desktop | unity | | xdg_session_desktop | ubuntu - xorg | | xdg_session_type |x 1 1 | | item | value | | - - - | - - - | | remote | ssh | os | linux x64 <number> . <number> - <number> - cloud - amd64 | | cpus | amd epyc 7 b13 ( <number> x <number> )| | memory ( system ) | <number> . 3 6 gb ( <number> . 6 0 gb free ) | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - bookmarks | ale | <number> . <number> vscode - peacock | joh | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - explorer | ms - | <number> . <number> rewrap | stk | <number> . <number> errorlens | use | <number> . <number> github - markdown - preview | bie | <number> . <number> markdown - checkbox | bie | <number> . <number> markdown - emoji | bie | <number> . <number> markdown - footnotes | bie | <number> . <number> markdown - mermaid | bie | <number> . <number> markdown - preview - github - styles | bie | <number> . <number> markdown - yaml - preamble | bie | <number> . <number> vscode - markdownlint | dav | <number> . <number> vscode - eslint | dba | <number> . <number> editorconfig | edi | <number> . <number> vscode - typescript - exportallmodules | eli | <number> . <number> prettier - vscode | esb | <number> . <number> terraform | has | <number> . <number> bash - ide - vscode | mad | <number> . <number> uuid - generator | net | <number> . <number> vscode - commons | red | <number> . <number> vscode - yaml | red | <number> . <number> vscode - workspace - switcher | sad | <number> . <number> code - spell - checker | str | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> <number> <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,""" press ctrl + i to ask copilot . <repeated> ` message showing in empty output channel steps open an empty output channel . to do this , you can open an html file from a fresh reload and then check the html language server output channel . <number> . the output channel says "" press ` ctrl ` + ` i ` to ask copilot to do something . [ image ] ( <url>",0
microsoft/vscode,disposable leaks cause unit test failures build : <url> changes : <url> ` ` ` ( shared with <number> / <number> leaks ) at $ fg ( out - build / vs / base / common / async . js : <number> <time> ) ( shared with <number> / <number> leaks ) at / mnt / vss / _work / <number> / s / out - build / vs / base / common / async . js : <number> <time> ( shared with <number> / <number> leaks ) at $ sg ( out - build / vs / base / common / async . js : <time> ) - stacktraces of <number> other leaks continue with $ sg ( out - build / vs / base / common / async . js : <time> ) ( shared with <number> / <number> leaks ) at object . $ fg ( out - build / vs / base / common / async . js : <number> <time> ) ( shared with <number> / <number> leaks ) at context . <anonymous> ( out - build / vs / base / test / common / async . test . js : <number> <time> ) ( shared with <number> / <number> leaks ) at process . processimmediate ( node : internal / timers : <number> <time> ) = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = leaking disposable <number> / <number> = = = = = = = = = = = = = = = = = = = = ( shared with <number> / <number> leaks ) at <money> s . trackdisposable ( out - build / vs / base / test / common / utils . js : <number> <time> ) ( shared with <number> / <number> leaks ) at $ db ( out - build / vs / base / common / lifecycle . js : <number> <time> ) ( shared with <number> / <number> leaks ) at $ kb ( out - build / vs / base / common / lifecycle . js : <number> <time> ) ( shared with <number> / <number> leaks ) at mutabletoken . q ( out - build / vs / base / common / event . js : <number> <time> ) ( shared with <number> / <number> leaks ) at / mnt / vss / _work / <number> / s / out - build / vs / base / common / async . js : <time> ( shared with <number> / <number> leaks ) at new promise ( <anonymous> ) ( shared with <number> / <number> leaks ) at $ sg ( out - build / vs / base / common / async . js : <time> ) - stacktraces of <number> other leaks continue with $ sg ( out - build / vs / base / common / async . js : <time> ) ( shared with <number> / <number> leaks ) at object . $ fg ( out - build / vs / base / common / async . js : <number> <time> ) ( shared with <number> / <number> leaks ) at context . <anonymous> ( out - build / vs / base / test / common / async . test . js : <number> <time> ) ( shared with <number> / <number> leaks ) at process . processimmediate ( node : internal / timers : <number> <time> ) = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = at <money> s . ensurenoleakingdisposables ( out - build / vs / base / test / common / utils . js : <number> <time> ) at context . <anonymous> ( out - build / vs / base / test / common / utils . js : <number> <time> ) at process . processimmediate ( node : internal / timers : <number> <time> ) ` ` `,0
microsoft/vscode,"sticky scroll : folding icons missing from some sticky headers type : <b> bug </b> > issue troubleshooting has identified that the issue is with visual studio code - insiders . if the sticky scroll header shows only one line , that line has no folding indicator . if it shows <number> or more lines , only the last line has the indicator . [ junk ] ( <url> this is working correctly in <number> . <number> stable . vs code version : code - insiders <number> . <number> - insider ( 5 a400e53e985dc5e24f6ee574b07ab23943841c5 , <number> - <number> - 0 7 t <time> . 7 4 0 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",0
microsoft/vscode,"<number> cannot select text in integrated terminal < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : ubuntu <number> steps to reproduce try to select text in the integrated terminal by shift + select text . does not work . <number> . last working in <number> . *",0
microsoft/vscode,"tab separator setting refers to the same setting twice < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : windows <number> steps to reproduce : <number> . go to settings <number> . find ` terminal . integrated . tabs . separator ` <number> . it refers to one setting twice , it should refer to ` title ` and ` description `",0
microsoft/vscode,"vscode warning <number> bit windows users about deprecated <number> bit windows support < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version <number> pro - <number> bit my vscode just updated this morning to <number> . <number> and now it ' s warning me that i will not be able to use it on windows <number> bit anymore . except i am _not_ using <number> bit windows , i am using <number> bit windows . ! [ image ] ( <url> ! [ image ] ( <url> ! [ image ] ( <url> ! [ image ] ( <url>",0
microsoft/vscode,why does not reflow work in test view output ? when i resize this down and back up again : [ image ] ( <url> i see this : ! [ image ] ( <url> why is not reflow working here ? does the terminal not have scrollback by chance as it will be disabled if so,0
microsoft/vscode,"editor scrollbar markers update only after cursor move <number> . in a ts file , use the keyboard and type out a syntax error . 🐛 the scrollbar error marker does not show up . <number> . move the text cursor to another location using the mouse . the scrollbar error marker shows up then . <url> <user> says i think you need eslint [ to repro ]",0
microsoft/vscode,web : cannot right click into custom title steps to reproduce open <url> <number> . notice the custom title shows by default ( probably because of command center enabled by default ? ) <number> . right click into empty space of custom title => 🐛 the menu does not open ( or quickly closes ) [ image ] ( <url>,0
microsoft/vscode,"forders not opening type : <b> bug </b> when i open new window vs code , showing me "" recent "" part . in this part has a menu more . <repeated> when i press more . <repeated> menu nothing is happend . this problem has been for <number> - <number> month vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 6 5 gb ( <number> . 8 5 gb free ) | | process argv | - - crash - reporter - id ff9a8db9 - c9cf - 4 2 a6 - a0e2 - 5 dc8ac461d11 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vite | ant | <number> . <number> vscode - apollo | apo | <date> vscode - eslint | dba | <number> . <number> gitlens | eam | <number> . <number> prettier - vscode | esb | <number> . <number> vscode - highlight | fab | <number> . <number> vue - snippets | hol | <number> . <number> graphql | mqu | <number> . <number> vetur | oct | <number> . <number> material - icon - theme | pki | <number> . <number> tabnine - vscode | tab | <date> volar | vue | <date> vscode - typescript - vue - plugin | vue | <date> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl49 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd2263cf : <number> vscaac : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> f6dab26 <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> 9 6 2 ge76 <time> <number> a2ce337 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,cannot read properties of null ( reading ' uri ' ) ` ` ` javascript typeerror read properties of null ( reading ' uri ' ) at b . d in src / vs / workbench / contrib / comments / browser / commentthreadzonewidget . ts : <number> <time> at b . create in src / vs / editor / contrib / zonewidget / browser / zonewidget . ts : <number> : <number> at new b in src / vs / workbench / contrib / comments / browser / commentthreadzonewidget . ts : <number> : <number> at f . j in src / vs / platform / instantiation / common / instantiationservice . ts : <number> <time> at f . createinstance in src / vs / platform / instantiation / common / instantiationservice . ts : <number> <time> at m . o in src / vs / workbench / contrib / comments / browser / commentscontroller . ts : <number> <time> at <anonymous> in src / vs / workbench / contrib / comments / browser / commentscontroller . ts : <number> <time> at array . foreach ( <anonymous> ) at <anonymous> in src / vs / workbench / contrib / comments / browser / commentscontroller . ts : <number> <time> at array . foreach ( <anonymous> ) at m . z in src / vs / workbench / contrib / comments / browser / commentscontroller . ts : <number> <time> at <anonymous> in src / vs / workbench / contrib / comments / browser / commentscontroller . ts : <number> : <number> ` ` ` [ go to errors site ] ( <url>,0
microsoft/vscode,"notebook : run button is rendered when revealing cell into view when hitting breakpoint < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : - os version : steps to reproduce add a breakpoint in a cell <number> . debug the cell <number> . scroll the cell out of view <number> . reveal the cell <number> . now the run button is rendered , other than the stop button digging into this a bit and i found that the context key service / update is correct , the problem is we receive an execution ` complete ` message from the extension host right after initializing the debug session so the cell execution state is ` idle ` instead of ` pending ` or ` executing ` . that ' s why when we re - render the cell , the run button is rendered .",0
microsoft/vscode,"code cli should not panic if it can not bind a port ` ` ` ❯ . / code - insiders serve - web * * visual studio code server * * by using the software , you agree to * the visual studio code server license terms ( <url> and * the microsoft privacy statement ( <url> * web ui available at <url> thread ' main ' panicked at ' error binding to <number> . <number> : <number> : error creating server listener : address in use ( os error <number> ) ' , / home / cloudtest / . cargo / registry / src / index . crates . io - 6 f17d22bba15001f / hyper - <date> / src / server / server . rs : <number> <time> note with ` rust_backtrace = <number> ` environment variable to display a backtrace ` ` ` probably should print an error message instead of panicking , and maybe do that before printing the url to connect to .",0
microsoft/vscode,accept button is not visible in inline chat * generate an answer * tweak it * press send again ( by accident ) * press stop generating * the accept button is no longer visible [ image ] ( <url> ` ` ` version : <number> . <number> - insider commit : f1302be1e67e3af5fbeb8bbb2ea784de7bc96150 date : <number> - <number> - 0 1 t <time> . 5 2 3 z electron : <number> . <number> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os arm64 <number> . <number> ` ` `,0
microsoft/vscode,"terminal : white bar on top of terminal version : <number> . <number> - insider ( user setup ) commit : f1302be1e67e3af5fbeb8bbb2ea784de7bc96150 date : <number> - <number> - 0 1 t <time> . 4 1 4 z electron : <number> . <number> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os : windows_nt x64 <number> . <number> a white bar is hiding the first characters of the last line <number> - <number> - <number> at <number> <number> <number> ] ( <url> ! [ image ] ( <url> last week i tested some terminal accessibility issues , using the terminal buffer , maybe that ' s related .",0
microsoft/vscode,do not detect aligned code as moved do not show non - moves [ monaco editor repro ] ( <url>,0
microsoft/vscode,"compress single test messages in the test results tree view <user> testing this out and it looks better to me - although is it the case that now there will always be only a single child in the tree below the test ? [ image ] ( <url> if so , could the output not be shown against the test node and the child removed ? currently it seems like clicking on the test name does not do anything ( except maybe expand / collapse ) which i find confusing . i feel like clicking on the test name and seeing the output ( and it having no children ) would be better - but i am not sure if there are cases where there are more children . thanks ! _originally posted by <user> in <url>",0
microsoft/vscode,"ssh / devcontainer port forwarding broken < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > ` ` ` version : <number> . <number> - insider ( system setup ) commit : 3 cd6f481266dcbd2ca2fcff43b4465d747c78e2f date : <number> - <number> - 3 1 t <time> . 9 1 6 z electron : <number> . <number> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os : windows_nt x64 <number> . <number> ` ` ` issue similar to # <number> - this time it affects * devcontainers <emphasis> * running on * * remote ssh hosts * * ⚠️ client : windows <number> remote - host : ubuntu <number> container : debian <number> repo for reproduction : <url> steps to reproduce : <number> . connect to ssh host <number> . clone [ repo ] ( <url> <number> . open in devcontainer when asked <number> . launch task "" serve "" to start webserver <number> . open http :// localhost : <number> and see indefinite loading . i can not test it without the remote ssh host <annoyed> <details> <summary> shared - log </summary> <p> ` ` ` <number> - <number> - <number> <time> . <number> [ info ] [ sharedprocesstunnelservice ] created tunnel <number> : <number> . <number> : <number> ( local ) to <number> . <number> : <number> ( remote ) . <number> - <number> - <number> <time> . <number> [ info ] [ sharedprocesstunnelservice ] created tunnel <number> : <number> . <number> . <time> <number> ( local ) to <number> . <number> . <time> <number> ( remote ) . <number> - <number> - <number> <time> . <number> [ info ] [ sharedprocesstunnelservice ] created tunnel <number> : localhost : <number> ( local ) to localhost : <number> ( remote ) . <number> - <number> - <number> <time> . <number> [ info ] [ sharedprocesstunnelservice ] created tunnel <number> : localhost : <number> ( local ) to localhost : <number> ( remote ) . <number> - <number> - <number> <time> . <number> [ info ] getting manifest . <repeated> ms - vscode - remote . remote - containers <number> - <number> - <number> <time> . <number> [ info ] installing extension : ms - vscode - remote . remote - containers <number> - <number> - <number> <time> . <number> [ info ] extension signature is verified : ms - vscode - remote . remote - containers <number> - <number> - <number> <time> . <number> [ info ] extracted extension to file :/// c % 3 a / users / max06 / . vscode - insiders / extensions / ms - vscode - remote . remote - containers - <number> . <number> : ms - vscode - remote . remote - containers <number> - <number> - <number> <time> . <number> [ info ] renamed to c :\\ users \ \ max06 \ \ . vscode - insiders \ \ extensions \ \ ms - vscode - remote . remote - containers - <number> . <number> <number> - <number> - <number> <time> . <number> [ info ] extracting extension completed . ms - vscode - remote . remote - containers <number> - <number> - <number> <time> . <number> [ info ] extension installed successfully : ms - vscode - remote . remote - containers <number> - <number> - <number> <time> . <number> [ info ] marked extension as uninstalled ms - vscode - remote . remote - containers - <number> . <number> <number> - <number> - <number> <time> . <number> [ info ] [ sharedprocesstunnelservice ] created tunnel <number> : <number> . <number> . <time> <number> ( local ) to <number> . <number> . <time> <number> ( remote ) . <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - f2cc70c7 - d306 - <number> - b542 - 3 bfdd2cb513f ) . <repeated> <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - f2cc70c7 - d306 - <number> - b542 - 3 bfdd2cb513f ) was successful after <number> ms . <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - 5 7 cbefc6 - cb29 - 4 2 ef - 8 9 ac - 2 ff5873ad23a ) . <repeated> <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - 5 7 cbefc6 - cb29 - 4 2 ef - 8 9 ac - 2 ff5873ad23a ) was successful after <number> ms . <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - d3fcfdea - adbf - 4 4 f9 - a6da - 2 d1089f1c7fd ) . <repeated> <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - d3fcfdea - adbf - 4 4 f9 - a6da - 2 d1089f1c7fd ) was successful after <number> ms . <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - ec10ac1a - bbec - 4 6 d3 - bb84 - 2 6 6 7 f176bf2f ) . <repeated> <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - ec10ac1a - bbec - 4 6 d3 - bb84 - 2 6 6 7 f176bf2f ) was successful after <number> ms . <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - bebfb153 - c346 - 4 1 4 c - bdcf - e567fb8e8bf6 ) . <repeated> <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - bebfb153 - c346 - 4 1 4 c - bdcf - e567fb8e8bf6 ) was successful after <number> ms . <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - 5 4 b3ca0c - f89e - <number> - bd48 - d42869c6094f ) . <repeated> <number> - <number> - <number> <time> . <number> [ info ] creating a socket ( renderer - tunnel - 5 4 b3ca0c - f89e - <number> - bd48 - d42869c6094f ) was successful after <number> ms . ` ` ` </p> </details> dev console does not contain anything related . the extension host shows : ` ` ` <number> - <number> - <number> <time> . <number> [ error ] error : read econnreset at tcp . onstreamread ( node : internal / stream_base_commons : <number> <time> ) <number> - <number> - <number> <time> . <number> [ error ] error : read econnreset at tcp . onstreamread ( node : internal / stream_base_commons : <number> <time> ) <number> - <number> - <number> <time> . <number> [ error ] error : read econnreset at tcp . onstreamread ( node : internal / stream_base_commons : <number> <time> ) <number> - <number> - <number> <time> . <number> [ error ] error : read econnreset at tcp . onstreamread ( node : internal / stream_base_commons : <number> <time> ) <number> - <number> - <number> <time> . <number> [ error ] error : read econnreset at tcp . onstreamread ( node : internal / stream_base_commons : <number> <time> ) ` ` ` although i am not sure if that ' s related . the server output is interesting : ` ` ` <number> - <number> - <number> <time> . <number> [ error ] error : connect econnrefused : : <time> <number> at tcpconnectwrap . afterconnect [ as oncomplete ] ( node : net : <number> <time> ) <number> - <number> - <number> <time> . <number> [ error ] error econnrefused : : <time> <number> at tcpconnectwrap . afterconnect [ as oncomplete ] ( node : net : <number> <time> ) ` ` ` this is directly related - it happens right / shortly after opening the url in the browser .",0
microsoft/vscode,"can not change local address port in port forwarding < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : todays insider - os version : win11 steps to reproduce be in a * devcontainer <emphasis> * ( here on a remote ssh host , if that matters ) . try to set a new local port for an existing port forwarding . enter ` localhost : <number> ` - > does not work enter ` <number> ` - > does work .",0
microsoft/vscode,xterm live region is not present unless output spans full viewport noticed by <user>,0
microsoft/vscode,"` app <hashtag> resolve initial protocol urls </hashtag> ( ) ` does not remove ` ? windowid = _blank "" ` part of the url with ` vscode : ` schema type : <b> bug </b> i am trying to open workspaces with links like this : ` vscode :// vscode - remote / ssh - remote + viknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid = _blank ` when vs code is launched before opening the link , everything working as intended : the new window opens , connects to the server and loads working workspace . but if vs code was not running , loaded workspace has some problems : almost every internal uri contains ` ? windowid = _blank ` in ` external ` and this breaks many extensions . i think this is effect of passing "" query "" : "" windowid = _blank "" to the remote - ssh extension . i enabled trace logging and found different behaviour in handling url when running vs . not running vs code process : <details> <summary> launching vs code with link </summary> ` ` ` <number> - <number> - <number> <time> . <number> [ trace ] app <hashtag> resolve initial protocol urls </hashtag> ( ) protocol urls from macos ' open - url ' event : [ "" vscode :// vscode - remote / ssh - remote + viknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid = _blank "" ] <number> - <number> - <number> <time> . <number> [ trace ] app <hashtag> resolve initial protocol urls </hashtag> ( ) protocol url will be handled as window to open : vscode :// vscode - remote / ssh - remote + viknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid = _blank { "" workspaceuri "" <sad> "" $ mid "" : <number> , "" path "" :""/ home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" , "" query "" : "" windowid = _blank "" } } <number> - <number> - <number> <time> . <number> [ trace ] electronurllistener initialuristohandle : [ ] <number> - <number> - <number> <time> . <number> [ trace ] electronurllistener : waiting for window to be ready to handle urls . <repeated> <number> - <number> - <number> <time> . <number> [ trace ] lifecycle ( main ) : phase changed ( value : <number> ) <number> - <number> - <number> <time> . <number> [ trace ] windowsmanager <hashtag> open </hashtag> <number> - <number> - <number> <time> . <number> [ trace ] windowsmanager <hashtag> open </hashtag> pathstoopen [ { "" workspace "" <sad> "" id "" : "" 8 0 5 a4cf8f <phone> bb008f275ef99 "" , "" configpath "" <sad> "" $ mid "" : <number> , "" external "" : "" vscode - remote :// ssh - remote % 2 bviknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid % 3 d_blank "" , "" path "" :""/ home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" , "" query "" : "" windowid = _blank "" } } , "" remoteauthority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } ] <number> - <number> - <number> <time> . <number> [ trace ] windowsmanager <hashtag> do open folder or workspace </hashtag> { "" folderorworkspace "" <sad> "" workspace "" <sad> "" id "" : "" 8 0 5 a4cf8f <phone> bb008f275ef99 "" , "" configpath "" <sad> "" $ mid "" : <number> , "" external "" : "" vscode - remote :// ssh - remote % 2 bviknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid % 3 d_blank "" , "" path "" :""/ home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" , "" query "" : "" windowid = _blank "" } } , "" remoteauthority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } } ` ` ` </details> <details> <summary> opening link when vs code is running </summary> ` ` ` <number> - <number> - <number> <time> . <number> [ trace ] app <hashtag> handle protocol url </hashtag> (): vscode :// vscode - remote / ssh - remote + viknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid = _blank { "" originalurl "" : "" vscode :// vscode - remote / ssh - remote + viknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid = _blank "" } <number> - <number> - <number> <time> . <number> [ trace ] app <hashtag> handle protocol url </hashtag> ( ) found ' windowid = _blank ' as parameter , setting shouldopeninnewwindow = true : vscode :// vscode - remote / ssh - remote + viknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace ? windowid = _blank <number> - <number> - <number> <time> . <number> [ trace ] app <hashtag> handle protocol url </hashtag> ( ) opening protocol url as window : { "" workspaceuri "" <sad> "" $ mid "" : <number> , "" path "" :""/ home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } } vscode :// vscode - remote / ssh - remote + viknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace <number> - <number> - <number> <time> . <number> [ trace ] windowsmanager <hashtag> open </hashtag> <number> - <number> - <number> <time> . <number> [ trace ] windowsmanager <hashtag> open </hashtag> pathstoopen [ { "" workspace "" <sad> "" id "" : "" f7c3787ac45e98797d40d7528f7be026 "" , "" configpath "" <sad> "" $ mid "" : <number> , "" external "" : "" vscode - remote :// ssh - remote % 2 bviknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace "" , "" path "" :""/ home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } } , "" remoteauthority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } ] <number> - <number> - <number> <time> . <number> [ trace ] windowsmanager <hashtag> do open folder or workspace </hashtag> { "" folderorworkspace "" <sad> "" workspace "" <sad> "" id "" : "" f7c3787ac45e98797d40d7528f7be026 "" , "" configpath "" <sad> "" $ mid "" : <number> , "" external "" : "" vscode - remote :// ssh - remote % 2 bviknet - bionic . sas . yp - c . yandex . net / home / viknet / arc - project / arc - project . code - workspace "" , "" path "" :""/ home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } } , "" remoteauthority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } } ` ` ` </details> and ` trace workbench <hashtag> open </hashtag> (): with configuration ` looks like this : ` ` ` { . <repeated> "" workspace "" : { "" id "" : "" 8 0 5 a4cf8f <phone> bb008f275ef99 "" , "" configpath "" : { "" $ mid "" : <number> , "" path "" : "" / home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" , "" query "" : "" windowid = _blank "" } } , . <repeated> } ` ` ` vs . ` ` ` { . <repeated> "" workspace "" : { "" id "" : "" f7c3787ac45e98797d40d7528f7be026 "" , "" configpath "" : { "" $ mid "" : <number> , "" path "" : "" / home / viknet / arc - project / arc - project . code - workspace "" , "" scheme "" : "" vscode - remote "" , "" authority "" : "" ssh - remote + viknet - bionic . sas . yp - c . yandex . net "" } } , . <repeated> } ` ` ` vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 6 9 8 z ) os version : darwin arm64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | apple m1 pro ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> metal : disabled_off <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 3 2 gb free ) | | process argv | - - enable - proposed - api jeanp413 . open - remote - ssh | | screen reader | no | | vm | <percent> | </details> extensions < - - generated by issue reporter - - >",0
microsoft/vscode,"open dialog filter does not work for multiple extension files ( e . g . . tar . gz ) when working with remote - ssh < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : ubuntu <number> . <number> lts steps to reproduce : <number> . set the open dialog options filter to accept . tar . gz files : const opendialogoptions : vscode . opendialogoptions = { canselectfiles : true , canselectfolders : false , canselectmany : false , openlabel : ' select ' , filters : { ' targz ' } }; await vscode . window . showopendialog ( opendialogoptions ) ; <number> . run the extension in remote - ssh mode and try to select a . tar . gz file",0
microsoft/vscode,"cannot select a path outside the workspace to save the file add issue description here version : <number> . <number> commit : 6 c3e3dba23e8fadc360aed75ce363ba185c49794 user agent : mozilla / <number> ( macintosh ; intel mac os x 1 0 _15_7 ) applewebkit / <number> ( khtml , like gecko ) chrome / <number> . <number> safari / <number> embedder : vscode . dev < - - generated by web issue reporter - - > ! [ bug1 ] ( <url> steps open a repo on vscode . dev <number> . open a file in any directory <number> . double - click the blank space to create a new file and use the shortcut key to save it <number> . you can find the path to save the file can directly click on the previous level although the path beyond the current workspace is not saved successfully , in theory , it should not be possible to choose such a path .",0
microsoft/vscode,bracket colorization for markdown links with mismatched parenthesizes [ image ] ( <url> issue surfaced when testing it correctly displays with < > but the rightmost parenthesis is still highlighted red . likely the bracket pair colorization is not working properly in this case .,0
microsoft/vscode,"change default value of ` focusafterrun ` to be ` none ` for screen reader users changing this behavior could be jarring , so instead , we will set it to ` none ` by default and include a hint about this in the terminal accessibility help dialog .",0
microsoft/vscode,"unable to forward port due to tunnel limit testing # <number> * using latest insiders ` ` ` version : <number> . <number> - insider commit : 3 5 be9bf683eace09796e59d54f1f225bbc3a7866 date : <number> - <number> - 3 0 t <time> . 7 6 0 z electron : <number> . <number> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os : linux x64 <number> . <number> - <number> - generic snap ` ` ` * initiate forward port and after successful sign in flow , following error is seen ` ` ` <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ] starting cli <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ] [ <number> - <number> - <number> <time> ] debug no code server tunnel found , creating new one <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 2 m [ <number> - <number> - <number> <time> ] trace found token in keyring <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 0 m [ <number> - <number> - <number> <time> ] info creating tunnel with the name : parallels - parallels - virtual - platform <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 2 m [ <number> - <number> - <number> <time> ] trace found token in keyring <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 0 m  [ 2 m [ <number> - <number> - <number> <time> ] trace found token in keyring <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 0 m  [ 2 m [ <number> - <number> - <number> <time> ] trace tunnel limit hit , trying to recycle an old tunnel <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 0 m  [ 2 m [ <number> - <number> - <number> <time> ] trace found token in keyring <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 0 m  [ 2 m [ <number> - <number> - <number> <time> ] trace no tunnels available to recycle <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ]  [ 0 m [ <number> - <number> - <number> <time> ] error could not create tunnel with name : parallels - parallels - virtual - platform <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ] reason request was denied because it would exceed the limit for ' tunnelsperuserperlocation ' ( <number> ) . <number> - <number> - <number> <time> . <number> [ info ] [ forwarding ] exited with code <number> ` ` `",0
microsoft/vscode,wrong extension name reported as installed when installing extension pack <number> . install this vsix <url> <number> . : bug code shows this success notification [ image ] ( <url>,0
microsoft/vscode,"` x ` button in accessibility help view triggers error type : <b> bug </b> <number> . run ` open accessibility help . <repeated> ` <number> . try clicking on the ` x ` in the help * bug <emphasis> * see the error : ` ` ` workbench . desktop . main . js : sourcemap : <number> unable to write to user settings because accessibility . verbosity . editor is not a registered configuration . ` ` ` vs code version : code - insiders <number> . <number> - insider ( universal ) ( ebd67244fb2da33ab078bb2baa96106fda29f336 , <number> - <number> - 2 9 t <time> . 7 1 3 z ) os version : darwin x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i9 - 9 9 8 0 hk cpu @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 9 2 gb free ) | | process argv | - - crash - reporter - id 4 8 7 8 1 ca2 - <number> - 4 f64 - 9 bab - 3 2 5 0 5 5 aab55d | | screen reader | no | | vm | <percent> | </details> < - - generated by issue reporter - - >",0
microsoft/vscode,linux accessible view only opens when focusing with mouse testing # <number> after focusing the notification by keyboard i cannot open the accessible view . only after clicking into it with the mouse cursor does the accessible view open . ( today ' s insiders build on linux . ),0
microsoft/vscode,"padding is off on the quick question ` x ` button testing # <number> there ' s not gap between the x button and the right side , hovering it makes it really clear ! [ image ] ( <url> ! [ image ] ( <url>",0
microsoft/vscode,"use better codicon for action to disable verbosity hint we use an x now , which to me feels more like a ' dismiss accessible help ' button . maybe ` bell - slash ` would be more appropriate <url> or even ` circle - slash ` <url> [ image ] ( <url>",0
microsoft/vscode,clicking into notebook markdown search result clears result testing # <number> <number> . create a notebook with a markdown cell <number> . close the notebook <number> . search for some text in the notebook markdown <number> . click on search result for the markdown content * bug <emphasis> * the search results view is cleared [ image ] ( <url> maybe because the markdown cell is now in edit mode ?,0
microsoft/vscode,copy image output does not work on linux testing # <number> <number> . have a cell with an image <number> . copy the cell output <number> . paste in something like gimp <number> . 🐛 nothing happens both ` xclip ` and gimp do not see anything written to the clipboard . copying images from a browser works so i know the clipboard can be written with images .,0
microsoft/vscode,"[ bug ] when the window is downsized , icons to expand the hidden lines move to the left this behavior is seen in the following gif . perhaps the icons should remain on the same position",0
microsoft/vscode,"error : throttler is disposed in serve - web testing # <number> - vs code version : version : <number> . <number> - insider commit : ebd67244fb2da33ab078bb2baa96106fda29f336 date : <number> - <number> - 2 9 t <time> . 7 0 1 z browser : mozilla / <number> (x 1 1 ; linux x86_64 ) applewebkit / <number> ( khtml , like gecko ) chrome / <number> . <number> safari / <number> - os version : arch linux steps to reproduce : <number> . download latest insider vscode cli <number> . run ` code - insider serve - web ` , open the browser and wait for vscode server to open <number> . open and close some workspaces and folders <number> . the following error lines appear in terminal where cli is run : ` ` ` [ <number> - <number> - <number> <time> ] info [ ebd6724 stderr ] : [ <time> ] error : throttler is disposed [ <number> - <number> - <number> <time> ] info [ ebd6724 stderr ] : at c . queue ( / < path - to - vscode - cli > / cli / serve - web / ebd67244fb2da33ab078bb2baa96106fda29f336 / out / vs / server / node / server . main . js : <number> <time> <number> ) [ <number> - <number> - <number> <time> ] info [ ebd6724 stderr ] : at / < path - to - vscode - cli > / cli / serve - web / ebd67244fb2da33ab078bb2baa96106fda29f336 / out / vs / server / node / server . main . js : <number> <time> <number> [ <number> - <number> - <number> <time> ] info [ ebd6724 stderr ] : at / < path - to - vscode - cli > / cli / serve - web / ebd67244fb2da33ab078bb2baa96106fda29f336 / out / vs / server / node / server . main . js : <number> <time> <number> [ <number> - <number> - <number> <time> ] info [ ebd6724 stderr ] : at runnextticks ( node : internal / process / task_queues : <number> : <number> ) [ <number> - <number> - <number> <time> ] info [ ebd6724 stderr ] : at listontimeout ( node : internal / timers : <number> : <number> ) [ <number> - <number> - <number> <time> ] info [ ebd6724 stderr ] process . processtimers ( node : internal / timers : <number> : <number> ) ` ` `",0
microsoft/vscode,"settings feedback testing # <number> two polish items the link to the setting does not seem to work * you talk about "" making the focused view more obvious "" but that is not true , this feature only works for "" text editors "" and "" terminals "" , so i would clarify that [ image ] ( <url>",0
microsoft/vscode,editor placeholder ( error case ) does not dim testing # <number> [ image ] ( <url>,0
microsoft/vscode,keybindings editor does not dim testing # <number> [ image ] ( <url>,0
microsoft/vscode,"remove ` envcollectionoptions ` from product . json ` ` ` via ' product . json <hashtag> extension enabled api proposals </hashtag> ' extension ' ms - python . python ' wants api proposal ' envcollectionoptions ' but that proposal does not exist . likely , the proposal has been finalized ( check ' vscode . d . ts ' ) or was abandoned . ` ` `",0
microsoft/vscode,"[ accessibility ] alt + f1 does not work in terminal type : <b> bug </b> this issue is found on windows . <number> . open terminal . <number> . press alt + f1 . it says : > typeerror : cannot read properties of undefined ( reading ' getarialabel ' ) vs code version : code - insiders <number> . <number> - insider ( ebd67244fb2da33ab078bb2baa96106fda29f336 , <number> - <number> - 2 9 t <time> . 9 6 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 4 5 g7 @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 1 gb ( <number> . 4 9 gb free ) | | process argv | - - crash - reporter - id b05b88e5 - <number> - <number> - ae34 - fa034ebddea9 | | screen reader | yes | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - android - dev - ext | ade | <number> . <number> bookmarks | ale | <number> . <number> openscad | ant | <number> . <number> spellright | ban | <date> zoterolatex | bna | <number> . <number> mermaid - markdown - syntax - highlighting | bpr | <number> . <number> doxdocgen | csc | <number> . <number> vscode - markdownlint | dav | <number> . <number> vscode - eslint | dba | <number> . <number> vscode - quick - select | dba | <number> . <number> vscode - deno | den | <number> . <number> gitlens | eam | <number> . <number> editorconfig | edi | <number> . <number> prettier - vscode | esb | <number> . <number> vscode - google - translate | fun | <date> codespaces | git | <date> copilot | git | <number> . <number> copilot - chat | git | <number> . <phone> remotehub | git | <number> . <number> vscode - github - actions | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> cslpreview | igo | <number> . <number> easy - snippet | inu | <number> . <number> path - autocomplete | ion | <number> . <number> latex - workshop | jam | <number> . <number> lilypond - syntax | jea | <number> . <number> scheme | jea | <number> . <number> better - cpp - syntax | jef | <number> . <number> google - search | kam | <number> . <number> vscode - lua - format | koi | <number> . <number> lilypond - formatter | lhl | <number> . <number> lilypond - pdf - preview | lhl | <number> . <number> lilypond - snippets | lhl | <number> . <number> vslilypond | lhl | <number> . <number> zotero | mbl | <date> git - graph | mhu | <number> . <number> vscode - docker | ms - | <number> . <number> black - formatter | ms - | <number> . <number> flake8 | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> azure - repos | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> powershell | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> vscode - github - issue - notebooks | ms - | <date> vscode - selfhost - test - provider | ms - | <date> vscode - serial - monitor | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> autodocstring | njp | <number> . <number> pandocciter | not | <number> . <number> shiny - python | pos | <number> . <number> shinyuieditor | pos | <number> . <number> quarto | qua | <number> . <number> r - debugger | rde | <number> . <number> java | red | <number> . <number> vscode - xml | red | <number> . <number> r | red | <number> . <number> multi - command | ryu | <number> . <number> vscode - deepl | soe | <number> . <number> abc - music | sof | <number> . <number> lua | sum | <number> . <number> latex - utilities | tec | <date> cmake | twx | <date> errorlens | use | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - arduino | vsc | <number> . <number> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> markdown - all - in - one | yzh | <number> . <number> grammarly | znc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv69 <time> <number> vsins8 <time> <number> vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> pythontb : <number> pythonptprofiler : <number> vshan8 <time> <number> vscod805cf : <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> ecj1e33 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> welcomedialog : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> copilotsettingt : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> pythonlinttype : <number> pythonmpsinfo : <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",0
microsoft/vscode,"debug link created chrome config when only msedge is installed testing # <number> i do not have chrome installed , but edge . if open link would detect which browsers are available , this would have worked out - of - the - box .",0
microsoft/vscode,"quick search - file highlight decoration is not showing up on search <number> . use quick search for something like ` % dispose ( ` that is in the current file . <number> . notice that , while the picker is open , the matches are not highlighted : bug should see it like this on dark modern [ image ] ( <url>",0
microsoft/vscode,"exec server port forwarding fails for certain cases i still have this issue in the latest version : ` ` ` version : <number> . <number> - insider commit : 0 8 3 fca132543aa91a7e1de2dc23857d70ea56dd3 date : <number> - <number> - 2 5 t <time> . 6 2 5 z ( <number> hrs ago ) ` ` ` to reproduce : <number> . use node script [ from here ] ( <url> <number> . do a request from client side : ` ` ` head - c <number> / dev / urandom | curl ' <url> - x post - - data - binary @ - ` ` ` <number> . server side receives only the first chunk on req on data <number> ` ` ` after this , the request gets stuck and never ends . in my case , the issue mostly affects small requests . a 1 0 kb request always has the issue , but a 1 0 0 kb request seems to be consistently fine . size of the response also seems to be important . i connected to a distant server ( with a ping of ~ <number> ms ) , but there does not seem to be any problem with the connection itself . _originally posted by <user> in <url> - - - i have discovered this to be an issue in the cli or sdk ' s compression handling . it seems like something is not flushing or decompressing completely . disabling connection compression fixes , it but this is not a good solution .",0
microsoft/vscode,"context menu for quick search appearing in search view <number> . right - click in the search view . <number> . see this option , which brings you to the quick search : bug should not be here . [ image ] ( <url>",0
microsoft/vscode,"[ bug ] tela preta no terminal do vs code type : <b> bug </b> o meu terminal do vscode ficou todo preto derrepente , ele esta normal e quando fui abri - lo estava preto , nao consigo resolver e nao posso voltar a minha rotina por causa disso . my vscode terminal suddenly went all black , is that normal and when i opened it was black , i can not resolve it and i can not get back to my routine because of this . [ <number> - <number> - <number> ] ( <url> vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> 5 6 0 0 x <number> - core processor ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 9 gb ( <number> . 6 7 gb free ) | | process argv | - - crash - reporter - id 7 4 ce9143 - 4 3 9 b - <number> - a24f - d6f86ccdd59a | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - turbo - console - log | cha | <number> . <number> gitlens | eam | <number> . <number> auto - rename - tag | for | <date> copilot | git | <number> . <number> prettify - json | moh | <number> . <number> vscode - language - pack - pt - br | ms - | <number> . <phone> vscode - thunder - client | ran | <number> . <number> vscode - icons | vsc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> <number> <time> <number> showlangstatbar : <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofb : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < ! - - generated by issue reporter - - >",0
microsoft/vscode,"terminal multiple action icons overlap < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : insiders - os version ! [ image ] ( <url>",0
microsoft/vscode,moved code detection detect moves when nothing moved [ image ] ( <url>,0
microsoft/vscode,"the markdown link in test results is hard to read < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > version : <number> . <number> - insider ( user setup ) commit : a0377f0c51dbb2d3188565cdf35e89929f864e65 date : <number> - <number> - 2 4 t <time> . 0 2 4 z electron : <number> . <number> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os x64 <number> . <number> ! [ image ] ( <url> especially in the dark theme , the font color makes it difficult to read .",0
microsoft/vscode,"search view not showing warnings <number> . open search view and search for something that is not in your workspace . enable ` use exclude files and ignore files ` button that is within the files to exclude input . <number> . you result should say something like "" no results found . review your settings for configured . <repeated> "" , but it says "" <number> results in <number> files "" . buggy behavior : [ image ] ( <url> correct behavior",0
microsoft/vscode,smooth scrolling on tabs < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i ' d like to have smooth scrolling for window tabs ( when you scroll horizontally across open tabs up top ),1
microsoft/vscode,introduce a concept of similar commands in core we can use an implementation of tf - idf to provide quick local similarity search for commands .,1
microsoft/vscode,"allow text in error message popups to be copied or at least selected < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > the possibility to copy the message in an error popup ( the one with a red x in a circle . this would be nice for : * searching error messages * getting key info to resolve the error oneself below is my specific usecase the server i work on does not have ftp access , so i need to download that file on my workstation and scp it onto the server . as it is i cannot select that text to copy the url , so i am left with typing a <number> character ftp url by hand . which is painful enough that i am writing this issue .",1
microsoft/vscode,"add a ' wordwise ' option for the diff inline view < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > as kind of requested in issue # <number> and visible in the mentioned issues attached image i ' d like the option to only display the changed part of the line . the idear is to not have a read line and a green line underneeth each other but rather a single line where only the parts are highlighted that have acually changed . maybe the option could be added to the "" more actions . <repeated> "" drop down menu as "" inline word view "" , "" wordwise view "" or "" word diff view """,1
microsoft/vscode,extension tree that use ` vscode . open ` and ` vscode . diff ` commands should respect enter vs . space when discussing with <user> how we are going to improve accessibility for github pull requests and issues when opening a pr description we found that the built in extensions view does the following : - arrow keys are used to navigate between list / tree items - enter opens the extension item and moves focus to the extension description webview editor - space opens the extension item and keeps focus in the tree extension trees do not work the same way arrow keys are used to navigate between list / tree items ( same as above ) - both enter and space run the tree item command and keep focus in the tree we already have special handling for ` vscode . open ` and ` vscode . diff ` command run from the tree view so that we can keep things ctrl + click as open to the side . we should also handle enter and space as the extensions view does .,1
microsoft/vscode,"diff editor the full block as being replaced # # description mark the full block as being replaced [ image ] ( <url> # # playground example [ monaco editor playground repro ] ( <url> ( click on "" compare withlatest dev "" to verify a future bug - fix )",1
microsoft/vscode,"debug toolbar and cc this pr adds the option to let the debug toolbar show in the command center . while it ' s there , it also updates the background color <url>",1
microsoft/vscode,improve comments accessibility - [x ] indicate when a document has commentable ranges - aria status when a document is opened - [x ] add keyboard shortcut for adding a comment - [x ] provide commands to go to next and previous commentable range - [x ] add an accessible help menu to the comment widget - esc dismisses widget - lists go to next / previous commentable range commands + keyboard shortcuts - lists command and keyboard shortcut to add a comment - lists keyboard shortcut to execute the comment primary action and what the primary action is - [x ] the comments view should respect the enter / space = reveal + focus / reveal - [x ] make the comment widget toolbar always visible when in screen reader mode,1
microsoft/vscode,"improve settings sync diagnostics tooling the settings sync tooling that allows to inspect what happened must be improved . i do understand that bugs like <url> happen but i see myself being unable to file good issues ( and as a consequence i observe that things do not get better ) . the sync view with all its viewlets , diff editors , and logs is overwhelming , esp when you must use in an unpleasant situation . there should be a single command which collects all the information needed ( it can ask for my input ) so that it can create a ( zip ) - file which allows the respective owners to investigate issues",1
microsoft/vscode,"add functionality that copies command and output , as opposed to just copying command , or just copying output < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - >",1
microsoft/vscode,"[ fr ] notebook , markdown cells : please allow to generate a line break using ' \ \ n ' and / or ' <br> ' in the link tooltips < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > hello , 👋 while i do not think it ' s "" standard "" , some markdown renderers show * * link tooltips on multiple lines * * when * *'\\ n ' * * or ' * *\\< br \ \>'* * are used in the link tooltip code . in some cases they require that it be preceded by two spaces . where support exists , the tooltips in the examples i add below are seen on multiple lines , * * however that ' s not the case in vscode ' s markdown cells * * , and for that matter on github . code : ` ` ` markdown [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : \ \ nvisual studio code ' ) [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : \ \ nvisual studio code ' ) [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : <br> visual studio code ' ) [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : <br> visual studio code ' ) ` ` ` example : [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : \ \ nvisual studio code ' ) [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : \ \ nvisual studio code ' ) [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : <br> visual studio code ' ) [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : <br> visual studio code ' ) the only way i have found to achieve what i am aiming for is to write the tooltip spreading multiple lines but i ' d want to avoid having to resort to that method . below i show an example of the successful case with the unwanted method : code : ` ` ` markdown [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : visual studio code github ' ) ` ` ` example : [ microsoft / vscode : visual studio code ] ( <url> ' microsoft / vscode : visual studio code ​ ​ ​ github ' ) please add support for * *'\\ n ' * * and / or ' * *\\< br \ \>'* * in * * link tooltips * * . kind regards . claudio salvio p . s . thank you for the useful work you are doing in the field of notebook support in vscode !",1
microsoft/vscode,"does package . json configuration properties pattern regex support unicode ? i have a configuration property in my extension ' s package . json with the following definition : ` ` ` json "" objectscript . unittest . autoload . folder "" : { "" markdowndescription "" : "" when running client - side test classes , automatically load the contents of sub - directories with this name . see the [ % unittest / autoload qualifier documentation ] ( <url> for details . "" , "" type "" : "" string "" , "" default "" : "" _autoload "" , "" scope "" : "" resource "" , "" pattern "" : "" ^ [ \ \ \ \ p { l } \ \ \ \ d_ . - ]* $ "" } ` ` ` that regex is a valid unicode regex that works in the node repl , but it does not work properly in the vs code settings editor width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> am "" src = "" <url> are these patterns evaluated with the unicode flag on ? if not , can that feature be added or enabled ?",1
microsoft/vscode,"add new scope to vs code settings for only workspace configurable < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i was hoping we could add a new scope to vs code settings . currently , vs code settings have the following scopes : ! [ image ] ( <url> none of these scopes describe a setting that is only workspace configurable . we were hoping we could have a scope that would only show up in the workspace and not in global and user settings . for context as to why we want this use vscode settings to help save default azure resources that users want to deploy that specific project to . this setting does not really make sense to show as a user setting since what resource you want to deploy to is generally always going to be tied to the workspace / project . we are worried that users may end up in a scenario where they have accidentally altered their user setting rather than their workspace setting , and now they will deploy every new project to whatever that resource is",1
microsoft/vscode,enable command center by default we have seen great responses and results of testing with experimentation that the command center is a net - positive feature . so let us turn it on my default .,1
microsoft/vscode,"rename ` - - disable - keytar ` to ` - - disable - persisted - secrets ` or similar follow up from <url> we do not use ` keytar ` anymore , so we should rename this flag to something more generic ` - - disable - persisted - secrets ` * ` - - disable - secrets - storage `",1
microsoft/vscode,"add quick chat to the command center if a chat provider is contributed , we should offer a way to start a quick chat session from the command center so that quick chat is easier to discover .",1
microsoft/vscode,testing . opentesting is not working for testing explorer now version : <number> . <number> - insider ( user setup ) commit : a0377f0c51dbb2d3188565cdf35e89929f864e65 date : <number> - <number> - 2 4 t <time> . 0 2 4 z electron : <number> . <number> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os : windows_nt x64 <number> . <number> noticed that this setting is now controlling the ` test result ` panel . some users hoping that this setting can still work for the testing explorer,1
microsoft/vscode,"support profile inheritance can something like inheritance or import be added ? ` ` ` plain text global ├ ─ ─ web dev │ ├ ─ ─ vue │ ├ ─ ─ react │ └ ─ ─ vanilla ├ ─ ─ python │ ├ ─ ─ data mining │ └ ─ ─ deep learning └ ─ ─ c / cpp ` ` ` when adding a plugin to ` global ` , it means that a plugin is installed globally . when certain settings are added in ` web dev ` , this applies to all web development . _originally posted by <user> - iaq in <url>",1
microsoft/vscode,add quick search to command center as mentioned in title . add the text quick access menu to this list,1
microsoft/vscode,"builtin command executeinlinevalueprovider does not exist < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : any steps to reproduce : <number> . in extension code , call vscode . commands . executecommand ( ' vscode . executeinlinevalueprovider ' , vscode . uri . parse ( ' c <annoyed> foo ' ) , new vscode . range ( <number> , <number> , <number> , <number> )); <number> . returned promise is rejected with error ' _executeinlinevalueprovider ' not found i am developing an extension , and was not interested in this specific command , but noticed it was missing when i was looking for an example of a debug related built - in command . i have no use for the command , i am just reporting it , because its in the the built - in commands wiki .",1
microsoft/vscode,diff editor improve alignment [ image ] ( <url> [ repro ] ( <url> the const line should be aligned ( try latest dev ) .,1
microsoft/vscode,"diff editor v2 : setting for number of expanded lines when clicking top / bot there is now ` diffeditor . hideunchangedregions . reveallinecount ` . verification steps it to a value ( e . g . <number> ) , open a diff where there are many unchanged lines , enable collapsing unchanged lines ( click the map symbol in the editor toolbar ) and click the border of the folded lines indicator . notice that the specified amount of lines are revealed .",1
microsoft/vscode,"integrated terminal code folding < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > when running a node . js script that logs extensive data , it becomes challenging to find and focus on specific sections of the output . code folding in the terminal would significantly improve the user experience and productivity when dealing with such situations . this feature would be a valuable addition to vs code , enhancing its capabilities for working with the integrated terminal .",1
microsoft/vscode,"[ accessibility ] consider adding default keybinding to accept completion in inline accessible view type : <b> feature request </b> in accessible view ( alt + f2 ) for inline suggestion , users can activate some action buttons via keybindings , such as alt + f6 , alt + [ , alt + ] . however , "" accept completion "" does not have its default keybinding so users have to press shift + tab and hit enter . please add default keybinding for this , such as ctrl + / or ctrl + enter to accept the current suggestion . vs code version : code - insiders <number> . <number> - insider ( ccb95fd921349023027a0df25ed291b0992b9a18 , <number> - <number> - 1 7 t <time> . 1 4 1 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",1
microsoft/vscode,add smartselect / camelhumps caret browsing for the f2 rename symbol feature < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > add smartselect / camelhumps caret browsing for the f2 rename symbol feature,1
microsoft/vscode,"use a single action bar [ image ] ( <url> these are currently individual action bars , which makes navigation harder .",1
microsoft/vscode,"dom renderer does not show selection over regular background colors when gpuacceleration = ' off ' , the yellow text background should be blue here",1
microsoft/vscode,support gnu style file : line . column links the [ sail compiler ] ( ) outputs file : line links that follow [ this gnu convention ] ( <url> ` ` ` warning : redundant case sail - riscv / model / riscv_sys_control . sail : <number> - <number> | _ => false | ^ ` ` ` this does not currently work in vscode . it does support a very wide range of formats and i do not recall ever seeing this format before ( even from gnu tools ) so i suspect nobody else uses it . nonetheless it ' s easy to add support in vscode . see <url>,1
microsoft/vscode,adopt xterm . js ' cursorstyleinactive option see <url>,1
microsoft/vscode,"placeholder text for ports tab should be different for local port forwarding < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > currently , it says "" no forwarded ports . forward a port to access your running services locally . "" . but when using the ports tab locally ( no remote ) , this does not have the same meaning because i can already access the port locally . the suggestion is to change the text in the local port forwarding case to show something more meaningful . just as an example , something like "" no forwarded ports . forward a port to securely access your locally running services over the internet . """,1
microsoft/vscode,add title bar to accessible view / help to align with quickpick,1
microsoft/vscode,"explore showing workspace search results in the command center we want to start to explore what it ' d be like to have a quickpick that shows text results . for example , if we search ` activate ` in the ` vscode - livepreview ` repo , we do not get anything because it is not in any filenames . [ image ] ( <url> it would be nice if vscode knew that ` activate ` was in the ` extension . ts ` file and showed that file . ! [ image ] ( <url>",1
microsoft/vscode,"ignore a collapsed code block while copying < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> ( universal ) - os version : darwin arm64 <number> . <number> i am working on a vue . js project , and i have a rather large array of data within one of my components that takes up a lot of space in my file . i often find myself wanting to copy various parts of the code from this component , but i do not want this array to be copied . in vs code , i have the ability to collapse this array , but when i try to copy the code , the collapsed array is still being copied . is this intended behaviour ? is there any way to tell the editor to ignore the collapsed code block when copying ? steps to reproduce : <number> . copy - paste the array to vscode , <number> . collapse the array in the editor <number> . copy the collapsed array <number> . paste the collapsed array anywhere else <number> . the collapsed array will appear full size ` ` ` const categorytitles = { ' choroby - wewnetrzne ' : ' choroby wewnętrzne ' , ' chirurgia ' : ' chirurgia ogólna ' , ' pediatria ' : ' pediatria ' , ' poloznictwo - ginekologia ' i ginekologia ' , }; ` ` `",1
microsoft/vscode,"allow to theme foreground color of status bar entries on hover hi . i am creating a theme pack for vscode . i have discovered that there is a ` "" statusbaritem . hoverbackground "" ` to customize the background color of a status bar hovered item but there is no option to customize the color of the hovered item foreground color . something like ` "" statusbaritem . hoverforeground "" ` [ image ] ( <url>",1
microsoft/vscode,"improve discoverability of accessibility verbosity settings i imagine the accessible view hints ( and others ) that we have around the workbench are annoying if a user does not know they can be disabled . should we include info about disabling at the end of the hint ? for example , "" use tab + shift to access the terminal accessible buffer , disable this hint with the ` accessibility . verbosity . terminal ` setting cc <user> , <user> someone just emailed me that they did not know where this was coming from and were annoyed by it .",1
microsoft/vscode,"diff editor exact moves when a code fragment of at least <number> lines of code is deleted somewhere in inserted somewhere else without modifications , this move should be detected . [ in this example , moves should be detected ] ( <url> ( select latest - dev version to verify )",1
microsoft/vscode,"support actions in the accessible view for features like notifications , a user might want to tab to actions directly instead of having to go back to the item to take action . _originally posted by <user> in <url>",1
microsoft/vscode,adopt new dom renderer performance changes upstream,1
microsoft/vscode,"less aggressive ` comments . openview ` setting < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > with # <number> we got the ` firstfile ` setting to open the comments panel when opening the first file with comments . this is a nice improvement over the more aggressive ` file ` as setting . however users will still have the comments panel focused when there are only resolved comments and therefore no action needs to be taken . this is not optimal , especially in setups where the comments panel hides panels like source control , which might be more relevant in these situations . that ' s why we propose to add an additional option to the ` comments . openview ` setting which behaves like ` firstfile ` but will only consider unresolved comments . naming wise this might be tricky but something among the lines of ` firstfileunresolved ` might work . cc <user> <user> <user>",1
microsoft/vscode,"[ accessibility ] change command history default keybindings in terminal buffer on windows to align with mac type : <b> feature request </b> i am educating blind folks how to use vscode with screen readers . it is confusing to have two different keys . on mac , alt + up / downarrow are used in terminal buffer to navigate executed commands whereas windows uses ctrl + up / downarrow . i suggest using alt + up / downarrow on windows by default to align with mac keybindings . there will be another benefit of saving ctrl + up / downarrow for windows that will be described in a separate feature request . vs code version : code - insiders <number> . <number> - insider ( 9 8 0 0 cf6dd6bf4634889d60720ef46a400f3a7298 , <number> - <number> - 2 8 t <time> . 4 7 2 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",1
microsoft/vscode,"always on top window < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > requst to have an always on top feature for window especially within mac and windows , as of now linux provides a os level always on top window , which has it ' s own use cases especially while multitasking and not wanting to loose the focus upon the coding window . the implementation details which might help could be found over [ here ] ( <url>",1
microsoft/vscode,tunnel factory to provide error message for notification toast < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > we currently can contribute a tunnel factory through the embedder so that vs code can open tunnel connections . the problem is that if something goes wrong within that factory we have no control on what we show to the user because every error falls back to [ this error handler ] ( <url> it would be nice if the tunnel factory could provide a custom error to show as part of the notification to the user and fallback to the default in case an uncaught error was thrown . cc <user>,1
microsoft/vscode,"when no text is selected , ctrl - c should not overwrite the current buffer with nothing < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > sometimes , when it ' s my intention to paste a piece of text into vscode , i accidentally hit ctrl - c instead of ctrl - v . this overwrites the cut / paste buffer with whatever is currently selected in vscode . however , if nothing is selected then it effectively erases the current contents of the cut / paste buffer . i cannot think of a scenario where this is desired functionality . so no text is selected in vscode , entering ctrl - c should have no effect at all ( thus leaving the cut / paste buffer intact ) .",1
microsoft/vscode,should it be possible to use ctrl + up / ctrl + down to navigate within a comment thread testing # <number> <number> . open a file in a pr that has comments <number> . set focus to the comment widget input <number> . : bug ctrl + up / ctrl + down to move focus to the comments within that thread,1
microsoft/vscode,"navigating notification a11y view with alt + ] / [ should announce where you are in the list testing # <number> i am expecting something like "" notification x of y "" , instead it just announces the next focused notification , even if it ' s the same one",1
microsoft/vscode,[ feature ] support sticky display the code stack of the cursor line < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > sticky currently only supports displaying the stack structure of the first line of code in the editor . can it add feature to let sticky shows the code stack of the cursor line ?,1
microsoft/vscode,"support go to symbol in the accessible view atm , this is opening the symbols for the focused editor pane . we will also want to make sure that the accessible view remains open despite the ` blur ` event that will occur on quick pick open . also check the ` zindex ` as i think it ' s currently set to = that of the quickpick , but will need to be < than it",1
microsoft/vscode,". ipynb wrap cell output at fixed character limit type : <b> bug </b> ` ` ` python ' <number> ' * <number> ` ` ` the output is a single line that goes off my screen to the right . i would prefer to have options : - single line , no wrap - fixed margin ( e . g . <number> ) - wrap to visible width ( so if i resize the window it adjusts ) vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 2 9 8 z ) os version : darwin x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 8 5 5 9 u cpu @ <number> . 7 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> metal : disabled_off <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 0 2 gb free ) | | process argv | - - crash - reporter - id ffe7017d - 9 a68 - <number> - a96e - 3 eb92191e23c | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - project - manager | ale | <number> . <number> gitignore | cod | <number> . <number> vscode - office | cwe | <number> . <number> git - extension - pack | don | <number> . <number> githistory | don | <date> gitlens | eam | <number> . <number> copilot | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> git - graph | mhu | <number> . <number> vscode - docker | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> makefile - tools | ms - | <number> . <number> cmake | twx | <date> vscode - open - in - github | ziy | <number> . <number> ( <number> theme extensions excluded ) </details> < - - generated by issue reporter - - >",1
microsoft/vscode,"improve quick question experience for conversational chat right now , the quick question experience only allows for one question and one answer . [ image ] ( <url> we should explore alternatives to this ux that allows for full conversations .",1
microsoft/vscode,"support a ` - - password - store = inmemory ` or similar < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > the main purpose of this would be for running in ci when you need _some_ sort of secret storage store , but it does not have to live on . right now ` - - password - store = basic ` allows the secretstorage api to work , but it still stores things on disk which is not needed in ci scenarios . <repeated> and it ' s probably better to store it in memory than weakly on disk in ci anyway .",1
microsoft/vscode,"behaviour of the search - box type : <b> feature request </b> dear sirs as an older developer using a lot of editors during time i find vs really , really good - so thanks a lot . there is one issue with the search - box , i often found crazy while in ' my workflow ' : simply searching while working with ' ctrl - f ' , so focusing the search - box , all functions for moving in the code are disrupted . so , no page - up , no page - down , no ' home ' / ' end ' and , and , and are ' nt working as long as the search - box is focused - after years i cant get used to - perhaps too old and to much experience while decades with other editors . <repeated> ok , sorry for my poor english , perhaps somebody will think about changing . <repeated> eckart bechler , dortmund , germany vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 6 5 1 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",1
microsoft/vscode,"[ accessibility ] cannot use shift + tab as an input key in terminal type : <b> bug </b> # # repro <number> . configure the settings like below : ` settings . json ` : ` ` ` json { "" terminal . integrated . tabfocusmode "" : false } ` ` ` <number> . create new terminal via ctrl + ` <number> . press ` shift + tab ` from terminal input . # # current behavior pressing shift + tab moves to the terminal buffer . # # expected behavior shift + tab should be passed to terminal as an input key . the focus needs to remain in the terminal input field . we need ` shift + tab ` when cycling back through shell auto - suggestion or ipython completion . vs code version : code - insiders <number> . <number> - insider ( c85bf61a82b0c39886b032d <phone> a55c637 , <number> - <number> - 1 9 t <time> . 4 4 1 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 4 5 g7 @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 1 gb ( <number> . 4 4 gb free ) | | process argv | - - crash - reporter - id b05b88e5 - <number> - <number> - ae34 - fa034ebddea9 | | screen reader | yes | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - android - dev - ext | ade | <number> . <number> bookmarks | ale | <number> . <number> openscad | ant | <number> . <number> spellright | ban | <date> zoterolatex | bna | <number> . <number> mermaid - markdown - syntax - highlighting | bpr | <number> . <number> doxdocgen | csc | <number> . <number> dscodegpt | dan | <date> vscode - markdownlint | dav | <number> . <number> vscode - eslint | dba | <number> . <number> vscode - quick - select | dba | <number> . <number> vscode - deno | den | <number> . <number> gitlens | eam | <number> . <number> editorconfig | edi | <number> . <number> prettier - vscode | esb | <number> . <number> vscode - google - translate | fun | <date> codespaces | git | <date> copilot | git | <number> . <number> copilot - chat | git | <number> . <phone> remotehub | git | <number> . <number> vscode - github - actions | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> easy - snippet | inu | <number> . <number> path - autocomplete | ion | <number> . <number> latex - workshop | jam | <number> . <number> lilypond - syntax | jea | <number> . <number> scheme | jea | <number> . <number> better - cpp - syntax | jef | <number> . <number> google - search | kam | <number> . <number> vscode - lua - format | koi | <number> . <number> lilypond - formatter | lhl | <number> . <number> lilypond - pdf - preview | lhl | <number> . <number> lilypond - snippets | lhl | <number> . <number> vslilypond | lhl | <number> . <number> zotero | mbl | <date> git - graph | mhu | <number> . <number> vscode - docker | ms - | <number> . <number> black - formatter | ms - | <number> . <number> flake8 | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> azure - repos | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> vscode - github - issue - notebooks | ms - | <date> vscode - selfhost - test - provider | ms - | <date> vscode - serial - monitor | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> resourcemonitor | mut | <number> . <number> autodocstring | njp | <number> . <number> pandocciter | not | <number> . <number> shiny - python | pos | <number> . <number> shinyuieditor | pos | <number> . <number> quarto | qua | <number> . <number> r - debugger | rde | <number> . <number> java | red | <number> . <number> vscode - xml | red | <number> . <number> r | red | <number> . <number> multi - command | ryu | <number> . <number> vscode - deepl | soe | <number> . <number> abc - music | sof | <number> . <number> lua | sum | <date> latex - utilities | tec | <date> chatgpt | tim | <number> . <number> cmake | twx | <date> errorlens | use | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - arduino | vsc | <number> . <number> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> markdown - all - in - one | yzh | <number> . <number> grammarly | znc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv69 <time> <number> vsins8 <time> <number> vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> pythontb : <number> pythonptprofiler : <number> vshan8 <time> <number> vscod805cf : <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> pylantcb5 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> ecj1e33 <time> <number> pythonfmttext : <number> pythoncmvfstr : <number> fixshowwlkth : <number> hideindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythondjangots : <number> pythonnoceb : <number> copilotsettingt : <number> e537b57 <time> <number> h0f3276 <time> <number> synctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",1
microsoft/vscode,"there should be a shortcut for jumping between new and old files use "" diff editor side "" command to jump from original to modified and vice versa . notice how selections are mapped . there is no keybinding for it , but users can configure their own .",1
microsoft/vscode,trigger intellisense ( code completions ) after paste or delete ? < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - >,1
microsoft/vscode,"only show top - level variables in ` outline : show variables ` * related to <url> for our js / ts projects , we are declaring functions and components as variables ( eg . ` const foo = ( ) => { . <repeated> } ` ) . for the outline view to be useful , we have ` outline : show variables ` enabled . however , this means a file like : ` ` ` typescript const componenta = ( ) => { const state = null ; const localvar = <number> ; }; const componentb = ( ) => { return ; }; const funcasvar = ( ) => { const localvar2 = <number> ; }; ` ` ` outlines like width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> it would be useful if there was a way to only show top - level variables ` ` ` componenta componentb funcasvar ` ` ` may also be useful for other languages that allow similar function - as - variable declaration",1
microsoft/vscode,add info about go to next / previous accessible view to help menu this is currently supported in notifications and in the chat responses,1
microsoft/vscode,"show more terminal links by default context let us explore pulling all the links when you open it , with some reasonable timeout . we could also do this lazily by showing just the buffer initially but when you filter we backfill the results .",1
microsoft/vscode,"use find ( search text in files ) without expanding already - collapsed sections type : <b> feature request </b> when i am using find / replace , the find is way too aggressive at expanding all my collapsed areas . it seems to do so on a per - typed - letter basis so depending what the first few letters are , the experience is way more or less annoying . vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 6 5 1 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",1
microsoft/vscode,"support link detection in test results terminal < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : vscode <number> . <number> , <number> . <number> - insider ; plugin playwright test for vscode <date> - os version : windows <number> steps to reproduce run playwright ts test throwing an error . - open test results viewer in vs code ( see picture ) - try ctrl + click on call stack item for the error * expected <emphasis> * we jump to source code line * actual <emphasis> * nothing happens . it stopped to work ~ a week ago , i guess . but used to work in vs code insider build . but today is stopped to work in the insider build too . ( monday , <date> ) does not reproduce in vscode <number> . <number> . ! [ скриншот <date> <number> ] ( <url>",1
microsoft/vscode,"feature request : introduce $ tm_suggested_text variable for enhanced snippet creation < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i am a devoted user of vscode and appreciate the powerful snippets feature it offers . i would like to propose adding a new variable , $ tm_suggested_text , to enhance snippet creation . the $ tm_suggested_text variable would capture the prefix or suggested text provided by vscode ' s intellisense . this would simplify creating dynamic snippets that adapt to user input . for instance , using the todo tree extension , accessing the suggested text within snippets would greatly improve workflow , enabling more contextual and efficient code templates . i believe this feature would benefit the vscode community , empowering users to create more sophisticated and personalized snippets . thank you for considering my suggestion to enhance the already remarkable snippets functionality in vscode !",1
microsoft/vscode,"in debug session : add items to watch section by drag - and - drop them from variables section < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > add a feature which will allow to drag - and - drop items from variables debug section to watch section . < img width = "" <number> "" alt = "" image "" src = "" <url>",1
microsoft/vscode,add info about sticky scroll to editor accessibility help menu related to # <number>,1
microsoft/vscode,"debugger : copy value from hover < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > as far as i understand to copy variables i have to either find them in variables view - type them in debugger - > right click copy ultimatively for greater user experience it would be better to add copy button to the hover ( i see there is a space on the right near ` hold alt key to switch to editor language hover ` ) and for advanced users add command to copy value , so they can assign it to keybinding and click mouse less , they just need to hover over variable and thats it ! ( really want this so bad ) ! [ image ] ( <url>",1
microsoft/vscode,"[ feature ] extension hover labelling < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > some extensions provide content on hover in the editor window . sometimes , some extensions provide similar content on hover - leading to duplicated content . a ( debug ? ) feature that can be enabled in settings that prints name of extension contributing a hover content . this name can be printed just below the hover content provided by said extension .",1
microsoft/vscode,speed up creating troubleshooting profile speed up creating troubleshooting profile by copying extensions instead of installing them,1
microsoft/vscode,"when restoring a file editor on a unc path , the security error message should include an option to allow the host . < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : windows <number> 2 2 h2 steps to reproduce : <number> . have a vscode session or workspace with open editors hosted on unc paths ( pre <number> ) <number> . upgrade vscode to a version after the [ ghsa - mmfh - 4 pv3 - 3 9 hr ] ( <url> fix <number> . reopen the workspace and hit this error message : ! [ error ] ( <url> what should happen : <number> . the error message should provide an option to add the server to the ` security . allowedunchosts ` list , like you get when reopening the file manually i have dozens of files on several servers open , so reopening them manually to get this fixed is rather annoying . integrating that allow dialog into the error message would make for a smoother transition experience for users getting blindsided by this upgrade .",1
microsoft/vscode,pick up ts <number> . <number> track picking up <url>,1
microsoft/vscode,"[ feature request ] option to enable ` remote . ssh . defaultextensions ` for all currently installed extensions . < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > to enable a more seamless transition to remote development we ' d like to have users extensions transparently enabled on the remote . i have a script that uses ` code - - list - extensions ` to grab the current set of extensions and add it to the user ' s local ` remote . ssh . defaultextensions ` , but this is cumbersome and error prone . ideally we ' d have an option to install all existing extensions on the remote by default instead of having to sync them periodically .",1
microsoft/vscode,"add accessible view hint cc <user> when a user focuses an item with an accessible view , we should tell them how to access it in the aria label and have a setting to disable that",1
microsoft/vscode,"add option to allow configuration / customization of "" open with vscode "" in windows explorer context menu i encountered an issue during the installation of visual studio code ( vscode ) on windows where there is an option to add an "" open with vscode "" entry to the context menu in windows explorer for folders and files . unfortunately , once this option is selected during installation , there is no built - in way to undo or remove it later within vscode . additionally , there is no option to add or enable this feature after the installation . # workarounds workarounds found online suggest modifying the windows registry to remove or add the "" open with vscode "" entry . while this solution may work , it involves manual registry editing . since these workarounds can be found online , this indicates that there is a solution needed for a problem , and the correct solution should be a setting within vscode . it would be beneficial to have an option within the vscode settings or installer to easily enable or disable the "" open with vscode "" entry in the windows explorer context menu , without the need for manual registry modifications . # steps to reproduce : install vscode on windows . during the installation process , select the option to add "" open with vscode "" to the context menu in windows explorer for folders and files . after installation , observe that there is no built - in option within vscode to remove or disable this feature . # expected behavior : there should be an option within the vscode settings or installer to enable or disable the "" open with vscode "" entry in the windows explorer context menu , allowing users to control this feature without the need for manual registry modifications . # environment : operating system",1
microsoft/vscode,"an small feature to improve the program efficiently hi i have an small improvement for vs code . it will be really efficient in manage files and projects . today i wanted to write a new plugin using other plugins . imagine i have this structure folder > plugin one > plugin two > plugin three in each plugin i have to open some files and all files should be seperated . what if i can group each plugin opened files ? there is a way ? yes i want to group opened files by <number> tabs in the top - top - top of vs code window . if i click on each of those items ( tabs ) , in vs code i can see just opened files for that plugin ( folder ) , and i simply can go to other plugin opened files by choosing right plugin from initial tabs section ( in the top - top - top of vs code window ) best iman ghorbani ui / ux designer and developer",1
microsoft/vscode,"use other extensions to enhance the emmet extension < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i want to add emmet functionality to my extension , but i do not want to add duplicate code 😄 . is it possible to define a configuration so that emmet gets the classnames and idnames from other extensions to enhance autocomplete ?",1
microsoft/vscode,"rounded corner interface request < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i am using windows <number> , but the pages of vs code are more suitable for windows <number> , is it possible to add a theme suitable for windows <number> at the theme color ? thanks !",1
microsoft/vscode,"independent options to enable / disable preview for the editor and source control management < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > my personal preference is to disable the default option of opening files in "" preview "" mode , requiring the user to double - click the file in the explorer to ensure that opening another file does not do so in the same tab . by disabling this option , files open in new tabs without the need to double - click them in the explorer . the default behaviour of opening files in preview mode is great when looking at diffs in the scm view . however , currently , it is only possible to globally enable and disable opening files in preview mode . i would like to request adding a separate option to enable / disable opening files in preview mode for scm . adding a reference to a previous request here",1
microsoft/vscode,"copy notebook output command for built in renderers the jupyter renderer extension provides ` copy image ` through an icon for images , but the builtin renderers do not support any copying . we can provide a context menu and toolbar locations for this command",1
microsoft/vscode,"allow extensions to update configuration enums < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > extensions can contribute configuration items with enum values . these enum values currently have to be hard - coded in ` package . json ` . extensions do not have a way to set these enum values dynamically . use case extension might want to offer the user a configuration to choose a certain version of an installed software . the list of installed software versions is determined on extension start and cannot be hard - coded . <url> added something similar , but not exposed to extensions .",1
microsoft/vscode,"[ accessibility ] make alt + f2 work in notification area type : <b> feature request </b> when focused in the notification area and moving up and down each notification item in the list view , it would be so instrumental if alt + f2 can augment the content in the accessible monaco view . vs code version : code - insiders <number> . <number> - insider ( 6 6 0 3 9 3 deaaa6d1996740ff4880f1bad43768c814 , <number> - <number> - 0 4 t <time> . 7 2 7 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",1
microsoft/vscode,"provide a way to manually reload an opened file . < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > <url> <blockquote> * vscode version : <number> . <number> * * os version : windows <number> <number> bit i am trying to analyze the log files . it would be very helpful if i have a feature like a button click or a command to reload a file from disk . i can see the file being reloaded automatically but i am expecting a command to reload the file manually / only when needed . any suggestion or help on this feature please ? thanks , <user> . </blockquote> was closed prematurely by <url> <blockquote> ` file > revert file ` allows to do so . it will fetch the contents of the file from disk even if not dirty . </blockquote> reverting is not reloading . i do not want to revert certain files , even temporarily . i want to reload <emphasis> them .",1
microsoft/vscode,"preserve sidebar view sizes when resizing , if they are at their minimum < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > when minimizing side tabs like open editors and time line the bottom one is always enlarged to maximum height , the editor should remember manual resizing so when opening and closing side tabs you go back to how you resized the tabs originally",1
microsoft/vscode,"add environmentvariablecollection . description to the environment variables explanation repro : <number> . create <number> terminals <number> . hover one tab <number> . click ` show environment contributions ` this should show something like "" enables the following features auth provider "" [ image ] ( <url>",1
microsoft/vscode,"data science audio and text graph for visually impaired person < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > as we know vscode is most accessible code editor with screen readers . however , i use matplotlib with this but unfortunately , i did not find any accessibility with graphs . in google colab with third parti library called audio - plot - lib i can access the graph with audio and screen readers but it ' s not work with vscode can you do something for that library , or you can provide separate facility for all graphes for more detail you can visit "" <url>",1
microsoft/vscode,"change accessible buffer command navigation keybinding for screen reader users from a screen reader user ' s perspective , the terminal accessible buffer is an editor and should behave as such . ` ctrl / cmd + up / downarrow ` should jump to the top and bottom line . we should keep it as is to align with terminals for non screen reader users and provide a new command navigation keybinding for screen reader users . cc <user>",1
microsoft/vscode,have accessible view for ghost text completions <user> suggested that it would be great to be able to review the text of the suggestion character by character . we could do this using an accessible view,1
microsoft/vscode,"sticky scroll for screen reader users sticky scroll is a feature that allows sighted users to understand the nested context that they are in . <user> suggested it would be cool if we had this for screen reader users . imagine you jump to a line where there ' s a problem reported . you invoke a command which provides context - what class you are in , the function signature , the conditional , etc . cc <user> and <user>",1
microsoft/vscode,"stickyscroll sticks curly brackets instead of class / function if bracket in new line type : <b> bug </b> # # # steps to repoduce - in settings . json : ` ` ` json "" editor . stickyscroll . enabled "" : true , "" editor . stickyscroll . defaultmodel "" : "" indentationmodel "" ` ` ` - or alternatively : ` ` ` json "" editor . stickyscroll . defaultmodel "" : "" foldingprovidermodel "" ` ` ` - create an example file containing a function or class with the opening brace on a new line . - scroll down the file . # # # current behaviour when using stickyscroll in the ` outlinemodel ` , it functions as expected . however , i would prefer to use the ` indentationmodel ` because it allows me to see all indentation levels at the top , which i find useful . unfortunately , in this mode ( indentationmodel ) and also in the ` foldingprovidermodel ` , the curly brackets stick to the screen instead of the class / function when the bracket is on a new line . [ code_cmooy7apcy ] ( <url> # # # expected behaviour it would be great if both the ` indentationmodel ` and ` foldingprovidermodel ` treated opening brackets on a new line the same way as the ` outlinemodel ` does . this means that the respective function should stick to the screen instead of the bracket . vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",1
microsoft/vscode,"add an accessibility verbosity setting for notebooks so users can discover the notebook help menu alt + f1 can be used in notebooks to open the accessibility help , but i do not think that is noted anywhere .",1
microsoft/vscode,"scrolling at the edges of the reference view editor will scroll the outer editor < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : windows_nt x64 <number> . <number> steps to reproduce use go to references / definitions to open a reference view window <number> . scroll to the bottom of the embedded editor <number> . keep scrolling will scroll the outer editor it ' s quite annoying sometimes , make it behaves like the file tree in the right side would be nice <url> but i saw this , so is this behavior intended ? if so may i ask why ? <url>",1
microsoft/vscode,enabling tag telemetry for go < - - thank you for submitting a pull request . please : * read our pull request guidelines * associate an issue with the pull request . * ensure that the code is up - to - date with the ` main ` branch . * include a description of the proposed changes and how to test them . - - >,1
microsoft/vscode,"let me click on "" hidden lines "" text to unfold testing # <number> i was trying to double - click on the the "" <number> hidden lines "" text to unfold that region . i would love to be able to do that if possible < img width = "" <number> "" alt = "" image "" src = "" <url>",1
microsoft/vscode,"peek call / type hierarchy not in command palette testing # <number> < img width = "" <number> "" alt = "" image "" src = "" <url> < img width = "" <number> "" alt = "" image "" src = "" <url>",1
microsoft/vscode,"can not view embedded html pdf files in vscode jupyter # # # discussed in <url> < div type = ' discussions - op - text ' > <sup> originally posted by * mikelemo1 <emphasis> * <date> </sup> i am trying to reference an internal pdf file to view a single page from it with embedded html in vscode jupyter plugin with no luck as it just displays nothing or blank rectangles with no luck ( just for reference the same method works in mkdocs ) here is what i tried to do it with assuming the pdf file is sitting in the same folder as the . ipynb file : ` ` ` py from ipython . display import iframe # display ( html ( ' < embed id = "" mypdf2 "" src = "" stm32f302xd_e_mcu . pdf <hashtag> page </hashtag> = <number> & zoom = <number> & toolbar = <number> & statusbar = <number> & viewrect = <percent> , <percent> , <percent> , <percent> "" type = "" application / pdf "" width = "" <percent> "" height = 8 0 0 px / > ' ) ) iframe ( src = ' stm32f302xd_e_mcu . pdf <hashtag> page </hashtag> = <number> & zoom = <number> & toolbar = <number> & statusbar = <number> ' , width = <number> , height = <number> ) ` ` ` also tried % % html < embed id = "" mypdf2 "" src = "" stm32f302xd_e_mcu . pdf <hashtag> page </hashtag> = <number> & zoom = <number> & toolbar = <number> & statusbar = <number> & viewrect = <percent> , <percent> , <percent> , <percent> "" type = "" application / pdf "" width = "" <percent> "" height = 8 0 0 px / > ` ` ` any idea what can be done to help it work ? </div>",1
microsoft/vscode,"support creating a new task of a particular type programmatically < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > in our extension we would like to guide the user to create a task of a specific type . it ' s already possible to read all the tasks and determine whether one of the desired type exists , however the programmatic flow seems to require executing ` workbench . action . tasks . configuretaskrunner ` which exposes all task types . would it be possible to expose a function in the api to create a specific task ( e . g . by executing [ _configuretask ] ( <url> or accepting a filter in ` workbench . action . tasks . configuretaskrunner ` similar to [ runtask ] ( <url>",1
microsoft/vscode,"small ui improvement type : <b> bug </b> looks like the tooltip ( when hovering on file tabs ) utilizes a light theme approach , meanwhile all the app is used a dark theme . appearing this tooltip when you work in the dark theme for a while is painful for the eyes and difficult to read . so , would be great to have it in a dark color and there will not be such a gap in contrast difference , it will be more pleasant to eyes . vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 8 2 6 5 u cpu @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 8 9 gb ( <number> . 1 2 gb free ) | | process argv | - - crash - reporter - id d513e5e9 - a478 - 4 d2f - b140 - dc7d93a863a3 | | screen reader | no | | vm | <percent> | </details> extensions <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes627cf : <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 2 e4cg34 <time> <number> pyind77 <time> <number> f6dab26 <time> <number> pythonsymbol <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> pythongtdpath : <number> bgfeh9 <time> <number> gsof <time> <number> dh2dc7 <time> <number> pythonidxpt : <number> pythondjangotscf : <number> ` ` ` </details> < - - generated by issue reporter - - >",1
microsoft/vscode,"increase the width of breadcrumb box to support longer function name indexing . < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > hello vscode team , breadcrumb box is quite a good feature for me when indexing functions in a larger file . in a large project , i see lots of functions named like this long prefix but different short suffix , this makes troubles in finding them in breadcrumb box with a fixed width . i wonder if you can consider increase it , thanks a lot <happy> xxxxxxxxxxxxxxxxxxxxxxxxxxx_yyyyyyyyy_aaaaa . <repeated> xxxxxxxxxxxxxxxxxxxxxxxxxxx_yyyyyyyyy_bbbbb . <repeated> xxxxxxxxxxxxxxxxxxxxxxxxxxx_yyyyyyyyy_ccccc . <repeated> best regards , mingliang",1
microsoft/vscode,"picture - in - picture for terminal , using new google chrome api as seen [ in this tweet ] ( <url> by <user> , google chrome mentioned in a blog post [ they are planning to add a new pip mode for html elements ] ( <url> this would be extremely useful for the terminal in vscode . dev and github codespaces , and also on local ( if electron supports it ) . is there any plan to add support ? <url>",1
microsoft/vscode,diff editor : collapse unchanged code - show context header it would be very helpful to include the current symbol name in the collapsed unmodified code indicator ( see ` diffeditorwidget2 ` and ` constructor ` <sad> [ chrome_be4rflvo6w ] ( <url> verification steps open a diff in vscode ( not monaco editor playground ) * enable collapsing unchanged regions ( map icon in editor titlebar ) * observe that the collapsed code shows a header indicating which symbol started inside of the unchanged code but ended outside of it . * verify that clicking on it reveals the symbol,1
microsoft/vscode,"disable alt toggle of menubar altogether since ` alt ` is used to ` move lines up and down ` , if you press it in a certain way ( accidentally ) it will toggle the menu bar , which i prefer to be hidden , always . would be nice if there was a way to never show the menu bar even if ` alt ` is pressed , because it is disrupting .",1
microsoft/vscode,consider providing screen reader with the chat response for inline chat as a screen reader user start code chat <number> . type a request and hit enter <number> . 🐛 tab <number> times to focus response perhaps we should align with the chat view and update via ` status ` with the response when it is ready,1
microsoft/vscode,consider adding audio cues for inline chat now we have audio cues - which are off by default atm - in the chat view . we might want these also in the inline chat .,1
microsoft/vscode,"improve presentation of startup perf raw marks we should put these in a table : [ image ] ( <url> something like this : # # raw perf marks | name | timestamp | delta | total | - - - | - - - | - - - | - - - | code / timeorigin | <number> | <number> | <number> | code / didstartmain | <number> | <number> | <number> | code / willstartcrashreporter | <number> | <number> | <number> | code / didstartcrashreporter | <number> | <number> | <phone> | code / willgeneratenls | <number> | <number> | <phone> | code / mainappready | <number> | <number> | <phone> | code / willoadmainbundle <elongated> | <number> | <number> | <phone> | code / fork / willoadcode <elongated> | <number> | <number> | <phone> | code / registerfilesystem / file | <number> | <number> | <phone> | code / didloadmainbundle | <number> | <number> | <phone> cc <user> , <user>",1
microsoft/vscode,"breadcrumbs are limited to <number> items within a file < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : recent main - 8 b5719b3b65cc5ffd9145f5fca98ab225fd717d6 ( also v1 . <number> ) - os version : windows <number> steps to reproduce : <number> . just open any deeply nested file . personally , i used a jsonified version of the [ docker api specs ] ( <url> <number> . you will see that the breadcrumbs only go to a certain level <number> - <number> - <number> <number> ] ( <url> given that the breadcrumbs container is scrollable , i assume that this is a bug , not an intended limitation . i traced it until ` outlinemodel . ts : outlinegroup . _getitemenclosingposition ( ) ` , because i was hoping that i could maybe see whether it is intended after all . but once i got there and saw that it seems to be caused by an incomplete tree ( ` children ` are empty from that 6 th level onwards ) , i could not justify sinking more time into this .",2
microsoft/vscode,"autocomplete style in javascript < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > good morning , i recently started a javascript course using the self - taught official documentation from firefox . first and foremost , i ' d like to express my gratitude to all the developers who contribute to this project , both voluntarily and professionally . i am new to this , so please forgive me if i may be taking up your time , but i could not find a solution to the problem i encountered . i kindly request that you add the "" . style "" object to the default autocompletion provided by vs code for javascript . you know , the one that allows you to modify certain css properties of html from javascript . i have not come across any extensions that achieve this . the solution suggested by artificial intelligences was for me to either create an extension myself or attempt to configure autocompletion suggestions from the "" settings . json "" file in vs code . unfortunately , neither approach worked . every time i write , for example : element . style . the autocompletion changes it to what i end up doing is pressing space to prevent it from autocompleting . i apologize if there was already a previous solution that i could not find , and i appreciate you taking the time to respond .",2
microsoft/vscode,"vs code stops running react code type : <b> bug </b> hi , vs code stops automatically while running react code , this happens frequently . after this every time npm start command has to be given . this issue is very annoying . kindly check the issue and resolve asap . vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 3 gb ( <number> . 6 5 gb free ) | | process argv | - - crash - reporter - id 2 3 2 4 8 9 fa - <number> - 4 d11 - b31b - 5 8 2 1 7 0 cfc1a7 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - postgres | cko | <number> . <number> prettier - vscode | esb | <number> . <number> fabric8 - analytics | red | <number> . <number> java | red | <number> . <number> liveserver | rit | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - boot - dev - pack | vmw | <number> . <number> vscode - spring - boot | vmw | <number> . <number> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> vscode - spring - boot - dashboard | vsc | <number> . <number> vscode - spring - initializr | vsc | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 2 8 2 f87 <time> <number> <number> <time> <number> showlangstatbar : <number> 0 bi6i64 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> copilotsettingc : <number> synctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"unable to deny built - in port forwarding < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : windows <number> 2 2 h2 issue : [ release notes ] ( <url> specify the new "" built - in port forwarding "" feature that allows users to forward port from within vs code and make it available publicly . the [ documentation ] ( <url> specifies that we can allow / deny access to domain ` global . rel . tunnels . api . visualstudio . com ` to be able to control this feature . during our testing it seems the feature still works even after we denied the domain ` global . rel . tunnels . api . visualstudio . com ` on our enterprise dns secure gateway cisco umbrella . steps to reproduce denied domain ` global . rel . tunnels . api . visualstudio . com ` through our enterprise dns secure gateway cisco umbrella . <number> . validated that the domain ` global . rel . tunnels . api . visualstudio . com ` is blocked by trying to browse to it - shows the blocked message from opendns . <number> . tried steps to ' forward a port ' and it still allows the user to forward port .",2
microsoft/vscode,"sponsored issue : support request - infinite scrolling web app description : hello , i hope this message finds you well . i am currently working on implementing infinite scrolling for a web project and have run into an issue that i could use some assistance with . issue have set up infinite scrolling on my website to load additional content as users scroll down the page . however , i have noticed that the new content is not loading as expected when users reach the bottom of the page . instead , the page remains static , and no new data is loaded . i am using a react - based frontend with a node . js backend . i have followed tutorials and documentation to set up the infinite scrolling feature , but i seem to have missed something . i can share relevant code snippets or configurations if needed . i would greatly appreciate your guidance on resolving this issue and getting infinite scrolling to work correctly on my website . thank you for your assistance , and i look forward to your response . best regards , aniket mandloi # # priority support - <user> is using [ mintycode ] ( <url> to fund this issue . - if you would like to accept [ amount ] ( <url> bounty for solving this issue join [ mintycode ] ( <url> - thank you in advance for helping . [ ! [ mintycode ] ( <url>",2
microsoft/vscode,"terminal process failed to launch type : <b> bug </b> "" the terminal process failed to launch : starting dierectory ( cwd ) "" c <annoyed> program files / - - - - - - - - / - - - - - - - "" does not exist "" how do we solve this terminal issue ? vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i7 - 1 1 6 5 g7 @ <number> . 8 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 6 8 gb ( <number> . 7 4 gb free ) | | process argv | - - crash - reporter - id 7 5 eb889d - 4 3 2 f - 4 f14 - a87e - 2 fbb546928cd | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - ros | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> remote - containers | ms - | <number> . <number> cpptools | ms - | <number> . <number> java | red | <number> . <number> vscode - xml | red | <number> . <number> vscode - java - debug | vsc | <number> . <number> vscode - java - test | vsc | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 3 biah6 <time> <number> f6dab26 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> 9 6 2 ge76 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> copilotsettingc : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"problema con idioma vscode < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : - os version : steps to reproduce : no puedo descargar la extensión spanish en vscode y ya probe todo que puedo hacer este es el error que me tira lo desinstale vscode en limpio <number> veces y lo volvi a instalar y me sigue tirando error tengo la versio <number> . <number> nesesito ayuda en windows <number> <number> bits <number> - <number> - <number> <time> . <number> [ info ] [ perf ] render performance baseline is 3 9 1 ms <number> - <number> - <number> <time> . <number> [ error ] error read the extension from / c <annoyed> users / lenovo / . vscode / extensions / ms - ceintl . vscode - language - pack - es - <number> . <phone> at w . w ( c :\\ users \ \ lenovo \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ out \ \ vs \ \ code \ \ node \ \ sharedprocess \ \ sharedprocessmain . js : <number> <time> <number> ) at async b . u ( c :\\ users \ \ lenovo \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ out \ \ vs \ \ code \ \ node \ \ sharedprocess \ \ sharedprocessmain . js : <number> <time> <number> ) <number> . <number> .",2
microsoft/vscode,"terminal problem type : <b> performance issue </b> when i installed node js i could not type in my terminal vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> 2 2 0 0 u with radeon vega mobile gfx ( <number> x <number> )| | gpu status | 2 d_canvas : unavailable_software <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : disabled_software <br> multiple_raster_threads : enabled_on <br> opengl : disabled_off <br> rasterization : disabled_software <br> raw_draw : disabled_off_ok <br> video_decode : disabled_software <br> video_encode : disabled_software <br> vulkan : disabled_off <br> webgl : unavailable_software <br> webgl2 : unavailable_software <br> webgpu : unavailable_software | | load ( avg ) | undefined | | memory ( system ) | <number> . 6 6 gb ( <number> . 6 3 gb free ) | | process argv || | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> filewatcher [ <number> ] <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ hello \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c :\\ users \ \ hello \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ html - language - features \ \ server \ \ dist \ \ node \ \ htmlservermain "" - - node - ipc - - clientprocessid = <number> ) <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ hello \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c :\\ users \ \ hello \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ json - language - features \ \ server \ \ dist \ \ node \ \ jsonservermain "" - - node - ipc - - clientprocessid = <number> ) <number> <number> <number> ptyhost <number> <number> <number> winpty - agent <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> c :\\ windows \ \ system32 \ \ windowspowershell \ \ v1 . <number> \ \ powershell . exe <number> <number> <number> winpty - agent <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> c :\\ windows \ \ system32 \ \ windowspowershell \ \ v1 . <number> \ \ powershell . exe <number> <number> <number> utility - network - service <number> <number> <number> shared - process <number> <number> <number> gpu - process <number> <number> <number> window [ <number> ] ( index . html - import and exports - visual studio code ) ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` | window ( index . html - import and exports - visual studio code ) | folder ( import and exports ) : <number> files | file types : js ( <number> ) html ( <number> ) | conf files : ; ` ` ` </details> extensions <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 2 8 2 f87 <time> <number> <number> <time> <number> vscrp : <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> copilotsettingc : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"pow ( ) function not working in c + + <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> < math . h > using namespace std ; int main ( ) { int n ; cin > > n ; int ans = <number> ; int i = <number> ; while ( n = <number> ) { int bit = n & <number> ; ans = ( bit * pow ( <number> , i ) ) + ans ; n = n > > <number> ; i + + ; } cout < < ans < < endl ; }",2
microsoft/vscode,"calculation is not being done in higher datatype for cpp code type : <b> bug </b> in . cpp file just cout < < <number> / <number> ; it ' s answer shoulde be <number> but in vs code it is showing <number> which is wrong . vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i3 - 7 0 2 0 u cpu @ <number> . 3 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 0 gb ( <number> . 2 9 gb free ) | | process argv |c :\\\\ users \ \ \ \ dell \ \ \ \ desktop \ \ \ \ d - - crash - reporter - id 8 ac51244 - 6 9 d0 - 4 9 d5 - <number> - 8 dee75c6270b | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - tailwindcss | bra | <number> . <number> bracket - pair - toggler | dzh | <number> . <number> chatgpt - gpt4 - gpt3 - vscode | eas | <number> . <number> auto - rename - tag | for | <date> code - runner | for | <number> . <number> c - cpp - runner | fra | <number> . <number> vscode - pull - request - github | git | <number> . <phone> vscode - language - babel | mgm | <date> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> vscode - thunder - client | ran | <number> . <number> liveserver | rit | <number> . <number> es7 - react - js - snippets | rod | <number> . <number> cmake | twx | <date> vscode - lldb | vad | <number> . <number> vscode - icons | vsc | <number> . <number> javascriptsnippets | xab | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 3 biah6 <time> <number> <number> <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> copilotsettingc : <number> synctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"issues with source control type : <b> performance issue </b> i have over <number> changes to sync and it is not working , i just completed cs50p and most of my folders are not updated to my github how do i push these changes to my repository ? how can i clone this repository ( it is private and id like it to be public ) please help thank you vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : remote os version : linux x64 <number> . <number> - <number> - azure <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 3 7 4 0 qm cpu @ <number> . 7 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : unavailable_off <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 9 1 gb ( <number> . 6 8 gb free ) | | process argv | - - crash - reporter - id ab4cdca6 - 5 af7 - 4 e51 - <number> - bccccc3656ae | | screen reader | no | | vm | <percent> | | item | value | | - - - | - - - | | remote | codespaces : studious space couscous | | os | linux x64 <number> . <number> - <number> - azure | | cpus | amd epyc <number> <number> - core processor ( <number> x <number> )| | memory ( system ) | <number> . 7 5 gb ( <number> . 7 2 gb free ) | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> window [ <number> ] ( seasons . py - <number> [ codespaces : studious space couscous ] - visual studio code ) <number> <number> <number> shared - process <number> <number> <number> filewatcher [ <number> ] <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> crashpad - handler <number> <number> <number> utility - network - service <number> <number> <number> gpu - process remote : codespaces : studious space couscous cpu % mem mb pid process <number> <number> <number> remote agent <number> <number> <number> filewatcher <number> <number> <number> ptyhost <number> <number> <number> / usr / bin / bash - - login <number> <number> <number> extension - host <number> <number> <number> / vscode / bin / linux - x64 / abd2f3db4bdb28f9e95536dfa84d8479f1eb312d / node / home / ubuntu / . vscode - remote / extensions / ms - python . vscode - pylance - <number> . <number> / dist / server . bundle . js - - cancellationreceive = file : e60d5c3ae6864b329640c8625645e31d2b124ef03b - - node - ipc - - clientprocessid = <number> <number> <number> <number> / vscode / bin / linux - x64 / abd2f3db4bdb28f9e95536dfa84d8479f1eb312d / node / vscode / bin / linux - x64 / abd2f3db4bdb28f9e95536dfa84d8479f1eb312d / extensions / json - language - features / server / dist / node / jsonservermain - - node - ipc - - clientprocessid = <number> <number> <number> <number> filewatcher <number> <number> <number> / bin / sh - c / usr / bin / ps - ax - o pid =, ppid =, pcpu =, pmem =, command = <number> <number> <number> / usr / bin / ps - ax - o pid =, ppid =, pcpu =, pmem =, command = ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` | remote : codespaces : studious space couscous | folder ( <number> <sad> <number> files | file types : py ( <number> ) gitignore ( <number> ) tag ( <number> ) md ( <number> ) csv ( <number> ) jpg ( <number> ) json ( <number> ) | pdf ( <number> ) png ( <number> ) pub ( <number> ) | conf files ` ` ` </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - codespaces | git | <number> . <number> cs50 | cs5 | <number> . <number> ddb50 | cs5 | <number> . <number> explain50 | cs5 | <number> . <number> extension - uninstaller | cs5 | <number> . <number> phpliteadmin | cs5 | <number> . <number> style50 | cs5 | <number> . <number> codespaces | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> prettier - sql - vscode | inf | <number> . <number> vscode - pdf | mat | <number> . <number> vscode - docker | ms - | <number> . <number> vscode - language - pack - bg | ms - | <number> . <number> vscode - language - pack - cs | ms - | <number> . <phone> vscode - language - pack - de | ms - | <number> . <phone> vscode - language - pack - es | ms - | <number> . <phone> vscode - language - pack - fr | ms - | <number> . <phone> vscode - language - pack - hu | ms - | <number> . <number> vscode - language - pack - it | ms - | <number> . <phone> vscode - language - pack - ja | ms - | <number> . <phone> vscode - language - pack - ko | ms - | <number> . <phone> vscode - language - pack - pl | ms - | <number> . <phone> vscode - language - pack - pt - br | ms - | <number> . <phone> vscode - language - pack - ru | ms - | <number> . <phone> vscode - language - pack - zh - hans | ms - | <number> . <phone> vscode - language - pack - zh - hant | ms - | <number> . <phone> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> cpptools | ms - | <number> . <number> hexeditor | ms - | <date> vsliveshare | ms - | <number> . <number> java | red | <number> . <number> vscode - java - debug | vsc | <number> . <number> gitdoc | vsl | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl49 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyonecf : <number> 3 biah6 <time> <number> <number> <time> <number> vscrpc : <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> copilotsettingc : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"[ feature request ] add workbench action to split editor terminal below < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i currently have the following actions available : ` ` ` workbench . action . createterminaleditor workbench . action . createterminaleditorsamegroup workbench . action . createterminaleditorside ` ` ` i ' d like to be able to split an editor terminal below . it seems like the ui can do this , because i can drag a terminal editor below another and have a horizontal split width = "" <number> "" alt = "" image "" src = "" <url> so i would love to have a ` workbench . action . createterminaleditorbelow ` action to split it below 😊",2
microsoft/vscode,"giveing wrong output in c programming compilation type : <b> bug </b> mathematical calculation of some number having <number> in its digit , gives worng output which is decremented by <number> from original result . the code which is wrote is of armstrong number , and i mentioning it below - <hashtag> include </hashtag> < stdio . h > <hashtag> include </hashtag> < math . h > int main ( ) { int num , s , arm = <number> , n , count = <number> , r ; printf ( "" enter any number \ \ n "" ); scanf ( "" % d "" , & num ) ; n = num ; s = num ; while ( n = <number> ) { n = n / <number> ; count + + ; } printf ( "" digit \ \ t = % d \ \ n "" , count ) ; while ( s ! = <number> ) { r =s % <number> ; arm + = pow ( r , count ) ; s =s / <number> ; } printf ( "" arm = % d "" , arm ) ; } in this code after compilation when we give input of any number having <number> in its digit for example <number> , <number> , <number> , <number> , <number> , etc . it gives wrong output . the output result decremented by <number> from original result . vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 6 gb ( <number> . 2 2 gb free ) | | process argv | - - crash - reporter - id 2 a3cab1c - 4 2 c1 - 4 a04 - 8 b5e - f30b9eb5e3ad | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - code - runner | for | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> java | red | <number> . <number> cmake | twx | <date> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl49 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> f6dab26 <time> <number> vscrp : <number> 2 i9eh26 <time> <number> showlangstatbar : <number> 9 6 2 ge76 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> copilotsettingc : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc0 <time> <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"terminal issue . type : <b> performance issue </b> intergrated terminal exiting improperly after running the code ny giving the command to run c code , even if the code is correct . vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 7 5 gb ( <number> . 3 4 gb free ) | | process argv | - - crash - reporter - id ed0fb855 - e722 - 4 c59 - b225 - db7fc284d4eb | | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> ptyhost <number> <number> <number> conpty - agent <number> <number> <number> c :\\ windows \ \ system32 \ \ windowspowershell \ \ v1 . <number> \ \ powershell . exe - noexit - command "" try { . \ \ "" d :\\ microsoft vs code \ \ resources \ \ app \ \ out \ \ vs \ \ workbench \ \ contrib \ \ terminal \ \ browser \ \ media \ \ shellintegration . ps1 \ \ "" } catch { } "" <number> <number> <number> filewatcher [ <number> ] <number> <number> <number> window [ <number> ] ( str_problems . c - untitled ( workspace ) - visual studio code ) <number> <number> <number> utility - network - service <number> <number> <number> crashpad - handler <number> <number> <number> gpu - process <number> <number> <number> shared - process <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> c :\\ users \ \ rakshit \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 \ \ bin \ \ cpptools . exe <number> <number> <number> "" c :\\ users \ \ rakshit \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 \ \ bin \ \ cpptools . exe "" <number> <number> <number> c :\\ users \ \ rakshit \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 / bin / cpptools - srv . exe <number> { 1 3 5 bbce3 - <number> - 4 1 da - <number> - 0 c35eb0db490 } <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> electron - nodejs ( "" d :\\ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" d :\\ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ json - language - features \ \ server \ \ dist \ \ node \ \ jsonservermain "" - - node - ipc - - clientprocessid = <number> ) ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` | window ( str_problems . c - untitled ( workspace ) - visual studio code ) | folder ( online - recruitment ) : <number> files | file types : jpg ( <number> ) css ( <number> ) html ( <number> ) ico ( <number> ) jpeg ( <number> ) js ( <number> ) md ( <number> ) | conf files : | folder ( my_portfolio ) : <number> files | file types : html ( <number> ) yaml ( <number> ) xlsx ( <number> ) css ( <number> ) | conf files : | folder ( dsa - practice - problems ) : <number> files | file types : c ( <number> ) exe ( <number> ) json ( <number> ) c + + ( <number> ) md ( <number> ) | conf files : launch . json ( <number> ) settings . json ( <number> ) tasks . json ( <number> ) | launch configs : cppdbg ( <number> ) | folder ( java_practice ) : <number> files | file types java ( <number> ) | conf files : ; ` ` ` </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - project - manager | ale | <number> . <number> blackbox | bla | <date> gitignore | cod | <number> . <number> composer - php - vscode | dev | <number> . <number> phptools - vscode | dev | <number> . <number> profiler - php - vscode | dev | <number> . <number> githistory | don | <date> vscode - html - css | ecm | <number> . <number> code - runner | for | <number> . <number> kotlin | fwc | <date> kotlin | mat | <number> . <number> jupyter | ms - | <number> . <phone> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> java | red | <number> . <number> liveserver | rit | <number> . <number> open - in - browser | tec | <number> . <number> cmake | twx | <date> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> cors - browser | wsc | <date> php - debug | xde | <number> . <number> vscode - open - in - github | ziy | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> f6dab26 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> 0 bi6i64 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> 9 b8hh23 <time> <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"please provide a complete list of files and folders generated by vscode and their locations < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > on re - opening a project and navigating to the terminal via ` ctrl + backtick ` ( toggle terminal ) , i notice that the terminal states * history restored ` this would mean that there is some file / folder on disk somewhere which tracks this project and stores this data . can a complete list of files and folders generated by vscode and their locations be documented and put up on the web ? my hard disk space is running out and i would like to keep deleting such extra folders routinely so that it does not eat into the remaining space . in other words , what files and folders can one safely delete so as to restore vscode to the status it would have been under right after the very first time it has been freshly installed on a new machine without any extensions , cache files , etc . without affecting its functionality .",2
microsoft/vscode,"where are the extensions stored ? type : <b> performance issue </b> i need to know where are the vs code extensions stored . it is not in the vs code subdirectory . vs code version : code <number> . <number> ( abd2f3db4bdb28f9e95536dfa84d8479f1eb312d , <number> - <number> - 1 4 t <time> . 3 9 0 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : enabled_on <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 7 gb ( <number> . 8 1 gb free ) | | process argv | - - crash - reporter - id d28106b3 - cd04 - 4 9 0 a - b194 - f819821f7d80 | | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary>",2
microsoft/vscode,please make sure vscode ' s window title bar changes color when the windows focus is acquired . < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > please make sure vscode ' s window title bar changes color when the windows focus is acquired . i will appreciate seeing the top bar changing its background color to blue ( in my case ) when the windows focus is on vscode . thanks !,2
microsoft/vscode,"terminate batch job issue < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : steps to reproduce press ctrl + c for terminate project <number> . press n for no . but still project terminate if we select no .",2
microsoft/vscode,"please allow for multiple tunnels on same machine < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > it would be amazing if remote tunneling did not force us into one server per machine ( i . e . allow optional work around of <url> an amazing feature of tunnel is to be able to use it in hpc environments , for example starting up a tunnel through an sbatch job with specific allocated resources . this allows users to connect to the newly created tunnel and use vscode ' s debugging with specific resources managed through cluster management systems like slurm . the issue is that if this happens more than once on a machine , any slurm allocation after the first will just point users to the tunnel of the first allocation , leading to conflict of resources . this would be an easy solution to workflow issues described in <url> . could supporting multiple tunnels on a machine be brought back ?",2
microsoft/vscode,"open files from different folders in one workspace without having to split editor < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > when adding a folder to a workspace and opening a file from the new folder , it automatically opens * instead <emphasis> * of an already opened file in the workspace , closing the file from the other active folder in the workspace . the only workaround seems to be to "" open to the side "" which is quite tedious after a while . so it would be nice if the files could all automatically open besides each other in the same editor without having to split .",2
microsoft/vscode,"add terminal highlighting support type : <b> feature request </b> the reason is that when i used wsl to compile the opencv library , the information displayed by the terminal was all white font , and it was difficult to capture some key information . can i add a highlight effect like mobaxterm ? however , i remember that github ' s codespace had some highlighting , but as a user there was no more convenient way to set it up , or plugins . vs code version : code <number> . <number> ( 8 b617bd08fd9e3fc94d14adb8d358b56e3f72314 , <number> - <number> - 0 6 t <time> . 4 3 8 z ) os version : windows_nt x64 <number> . <number> modes to ' wsl + ubuntu - <number> ' could not be established < - - generated by issue reporter - - >",2
microsoft/vscode,"logging into cs50 . dev is ok , but vs code space does not load add issue description here : logging into cs50 . dev is ok , but vs code space does not load , it lasts forever but never ends . i have reloaded , logout - login , restarted browser , rebooted my windows lap . i can not continue with the course , really sad <sad> version : <number> . <number> commit : 8 b617bd08fd9e3fc94d14adb8d358b56e3f72314 user agent : mozilla / <number> ( windows nt <number> ; win64 ; x64 ) applewebkit / <number> ( khtml , like gecko ) chrome / <number> . <number> safari / <number> embedder < - - generated by web issue reporter - - >",2
microsoft/vscode,"search files ( advanced search - filter a particular extension ) < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > is it possible to search file by keyword only for a particular extension . for example , i want to search that lists all files that have extension ` md ` and the search term ` time `",2
microsoft/vscode,"grille . py type : <b> bug </b> i cannot be successfull when i am trying to execute my programms . but , before my programms were running without problem . i use python language . vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 9 9 1 z ) os version : linux x64 <number> . <number> - <number> - generic snap modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 4 6 7 0 k cpu @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : disabled_software <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 6 3 gb ( <number> . 9 8 gb free ) | | process argv | - - no - sandbox - - force - user - env - - unity - launch - - crash - reporter - id e9151a7f - cd85 - 4 7 e8 - <number> - 1 4 9 c97afed6b | | screen reader | no | | vm | <percent> | | desktop_session | ubuntu | | xdg_current_desktop | unity | | xdg_session_desktop | ubuntu | | xdg_session_type |x 1 1 | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - language - pack - fr | ms - | <number> . <phone> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscoreces : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> <number> <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> 0 bi6i64 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"my terminal keeps giving me errors . i can not run my codes in the terminal . type : <b> bug </b> hello , i have been using visual studio code for a long time , but recently i can not run my code in the terminal , no matter what language . when i run a code in python language , it gives the following error in the terminal : "" c :\\ users \ \ lenovo - gamng \ \ desktop \ \ c \ \ hey . py : the term ' c :\\ users \ \ lenovo - gamng \ \ desktop \ \ c \ \ hey . py ' is not recognised as the name of a cmdlet , function , script file , or operable programme . check the spelling of the name , or if a path was included , verif y that the path is correct and try again . at line : <number> char : <number> + c :\\ users \ \ lenovo - gamng \ \ desktop \ \ c \ \ hey . py + ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ + categoryinfo : objectnotfound : ( c :\\ users \ \ lenovo - gamng \ \ desktop \ \ c \ \ hey . py : string ) [ ] , commandnotfoundexcepti on + fullyqualifiederrorid : commandnotfoundexception "" when i run a code in c in the terminal , it gives the following error : "" cd : cannot find path ' c :\\ users \ \ lenovo - gamng \ \ desktop \ \ c \ \ ' because it does not exist . at line : <number> char : <number> + cd "" c :\\ users \ \ lenovo - gamng \ \ desktop \ \ c \ \ "" ; if ($ ? ) { gcc 9 _from_ user_ . <repeated> + ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ + categoryinfo : objectnotfound : ( c :\\ users \ \ lenovo - gamng \ \ desktop \ \ c \ \ : string ) [ set - location ] , itemn otfoundexception + fullyqualifiederrorid : pathnotfound , microsoft . powershell . commands . setlocationcommand "" because of these errors , i can not write code in the terminal in any way , what is the solution to this , please urgently . vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 7 5 0 0 u cpu @ <number> . 7 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 8 gb ( <number> . 9 3 gb free ) | | process argv | - - crash - reporter - id aabdbfeb - c1b6 - 4 fbe - <number> - d6b16ef5132e | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - prettier - vscode | esb | <number> . <number> code - runner | for | <number> . <number> vscode - language - pack - tr | ms - | <number> . <phone> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> live - server | ms - | <number> . <number> javascriptsnippets | tem | <number> . <number> cmake | twx | <date> vscode - lldb | vad | <number> . <number> vscode - icons | vsc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vscaac : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> <number> <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"it compiles but the console instantly closes type : <b> bug </b> /* <number> . realice una función que reciba como parámetros una matriz de enteros , la cantidad de filas , la cantidad de columnas y un valor a buscar . la función debe devolver – por parámetro – la fila y la columna donde se encuentra el valor buscado . en el nombre debe devolver verdadero si lo encontró o falso si no lo hizo . */ <hashtag> include </hashtag> <iostream> using namespace std ; bool busquedas ( int mat [ ] [ <number> ] , int & filas , int & columnas , int dato ) ; int main ( int argc , char const * argv [ ] ) { int matriz [ <number> ] [ <number> ] , fila , columna , dat ; cout < < "" ingrese cantidad de filas y columnas de la matriz "" ; cin > > fila > > columna ; for ( int i = <number> ; i < fila ; i + + ) { for ( int j = <number> ; j < columna ; j + + ) { cout < < "" ingrese el numero de la fila : "" < < i < < "" columna : "" < < j < < "" "" ; cin > > matriz [ i ] [ j ] ; } } cout < < "" ingrese el dato que quiere buscar : "" ; cin > > dat ; bool encontro = busquedas ( matriz , fila , columna , dat ) ; if ( encontro ) cout < < "" el dato fue encontrado en la fila "" < < fila < < "" columna : "" < < columna ; else cout < < "" el dato no fue encontrado "" ; return <number> ; } bool busquedas ( int mat [ ] [ <number> ] , int & filas , int & columnas , int dato ) { for ( int i = <number> ; i < filas ; i + + ) { for ( int j = <number> ; j < columnas ; j + + ) { if ( mat [ i ] [ j ] = = dato ) { filas = i ; columnas = j ; return true ; } } } return false ; } this is the full code i dont see any problems at all , but in this only exercise i have that problem vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> <number> six - core processor ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 3 gb ( <number> . 9 1 gb free ) | | process argv | - - crash - reporter - id a0003ca4 - e173 - <number> - 9 b53 - 5 ef381a1fb2a | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - c - cpp - compile - run | dan | <date> c - cpp - runner | fra | <number> . <number> codespaces | git | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> java | red | <number> . <number> cmake | twx | <date> vscode - lldb | vad | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> material - theme | zhu | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl492cf : <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> <number> <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"pil library encountering error type : <b> bug </b> i am getting this error while i am writing the python code in vs code library for image pil image . ps c :\\ users \ \ musta \ \ desktop \ \ visual studio > & c <annoyed> users / musta / appdata / local / microsoft / windowsapps / python3 . <number> . exe "" c <annoyed> users / musta / desktop / visual studio / main . py "" traceback ( most recent call last ) : file "" c :\\ users \ \ musta \ \ desktop \ \ visual studio \ \ main . py "" , line <number> , in <module> from pil import image , imagetk ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ modulenotfounderror : no module named ' pil ' ps c :\\ users \ \ musta \ \ desktop \ \ visual studio > vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 7 2 0 0 u cpu @ <number> . 5 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : unavailable_off <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 0 gb ( <number> . 9 4 gb free ) | | process argv | - - crash - reporter - id 9 b270cbb - 9 4 2 f - 4 5 c7 - b9a2 - 1 5 7 b6afee602 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - copilot | git | <number> . <number> gc - excelviewer | gra | <date> bash - ide - vscode | mad | <number> . <number> rainbow - csv | mec | <number> . <number> csharp | ms - | <date> vscode - dotnet - runtime | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> cpptools | ms - | <number> . <number> platformio - ide | pla | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> console - ninja | wal | <date> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> f6dab26 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> 9 6 2 ge76 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> dsvsc015cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"wont run the program type : <b> bug </b> whenever i try to run the program on terminal in my mac and write - ' gcc hello . c ' ( hello is the file name ) it wont run and show "" no such file as ' hello . c ' "" i am new to coding and dont know much about visual code thus please help me . vs code version : code <number> . <number> ( universal ) ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 9 2 4 z ) os version : darwin arm64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | apple m2 pro ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> metal : disabled_off <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 0 9 gb free ) | | process argv | - - crash - reporter - id da2b00bf - 0 3 ff - 4 eb9 - 9 a7d - 9 2 2 fa4284720 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - c - cpp - runner | fra | <number> . <number> cpptask | kay | <number> . <number> lldb - vscode | lan | <number> . <number> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> o - language - support | ora | <number> . <number> vscode - lldb | vad | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> <number> <time> <number> showlangstatbar : <number> 9 6 2 ge76 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"autoformat stopped working for javascript type : <b> bug </b> i keep getting ` there is no formatter installed for "" javascript "" ` even though i tried eslint and native autoformatter . "" [ javascript ] [ javascriptreact ] [ typescript ] "" : { "" editor . defaultformatter "" : "" vscode . typescript - language - features "" } , r : vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 1 0 8 7 5 h cpu @ <number> . 3 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 9 gb ( <number> . 8 4 gb free ) | | process argv | - - crash - reporter - id 7 6 7 b857d - <number> - 4 2 c7 - a168 - 3 5 3 9 5 5 dd0e41 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - better - comments | aar | <number> . <number> project - manager | ale | <number> . <number> iconify | ant | <number> . <number> turbo - console - log | cha | <number> . <number> vscode - eslint | dba | <number> . <number> githistory | don | <date> todo - tree | gru | <date> vscode - peacock | joh | <number> . <number> json - to - ts | mar | <number> . <number> vetur | oct | <number> . <number> markdown - preview - enhanced | shd | <number> . <number> vscode - icons | vsc | <number> . <number> volar | vue | <number> . <number> gitblame | wad | <number> . <number> vscode - import - cost | wix | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> f6dab26 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> a2ce337 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"code is not run prperly type : <b> performance issue </b> code is not properly please helpo me vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i3 - 1 0 0 5 g1 cpu @ <number> . 2 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 7 7 gb ( <number> . 0 0 gb free ) | | process argv | - - crash - reporter - id 8 4 f717d1 - 6 7 4 b - 4 f6f - <number> - 8 6 fab8d2c667 | | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> window [ <number> ] ( extension : code runner - practice c lang - partik - visual studio code ) <number> <number> <number> gpu - process <number> <number> <number> shared - process <number> <number> <number> filewatcher [ <number> ] <number> <number> <number> utility - network - service <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> c :\\ windows \ \ system32 \ \ cmd . exe / d / s / c "" cd "" c :\\ users \ \ <number> \ \ desktop \ \ practice c lang \ \ "" & & gcc tempcoderunnerfile . c - o tempcoderunnerfile & & "" c :\\ users \ \ <number> \ \ desktop \ \ practice c lang \ \ "" tempcoderunnerfile "" <number> <number> <number> "" c :\\ users \ \ <number> \ \ desktop \ \ practice c lang \ \ "" tempcoderunnerfile <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> c :\\ users \ \ <number> \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 \ \ bin \ \ cpptools . exe <number> <number> <number> "" c :\\ users \ \ <number> \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 \ \ bin \ \ cpptools . exe "" <number> <number> <number> c :\\ users \ \ <number> \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 / bin / cpptools - srv . exe <number> { 2 8 f83285 - ad47 - 4 8 2 a - <number> - df9450d4b259 } <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> c :\\ users \ \ <number> \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 / bin / cpptools - srv . exe <number> { 5 2 5 5 ad30 - be63 - 4 ebf - b7d8 - 8 9 bf7f1f0a41 } <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ <number> \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c :\\ users \ \ <number> \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ json - language - features \ \ server \ \ dist \ \ node \ \ jsonservermain "" - - node - ipc - - clientprocessid = <number> ) <number> <number> <number> crashpad - handler <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> window <number> <number> <number> ptyhost ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` | window ( extension : code runner - practice c lang - partik - visual studio code ) | folder ( practice c lang ) : <number> files | file types : c ( <number> ) exe ( <number> ) json ( <number> ) txt ( <number> ) c ( <number> ) h ( <number> ) html ( <number> ) | conf files : launch . json ( <number> ) settings . json ( <number> ) tasks . json ( <number> ) | launch configs cppvsdbg ; ` ` ` </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - code - runner | for | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> cmake | twx | <date> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> f6dab26 <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"local host type : <b> bug </b> hello dear , actually am faceing a problem during debuging , crome gives only local host error vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"vscode : perm : operation not permitted , copyfile type : <b> bug </b> this issue is detailed here : <url> <number> . install google drive . this should install a g : drive on your windows <number> system - when setting this up , select ' streaming ' instead of mirrored <number> . create project folder somewhere on the g drive . <number> . open project in vscode and create a dev container . <number> . im thinking now we have to wait for the files to be ' unmirrored ' <number> . re - open the project and then the devcontainer <number> . try to cut and paste a file or folder from one location to another folder . vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : connection to ' dev - container + 7 b22686f737450617468223a222f686f6d652f6d6168656e6472612f70726f6a656374732f72616173222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6e727a646f636b657274657374227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d6168656e6472612f70726f6a656374732f726161732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d ' could not be established remote os version : linux x64 <number> . <number> - microsoft - standard - wsl2 <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> 4 9 0 0 hs with radeon graphics ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 4 2 gb ( <number> . 8 1 gb free ) | | process argv | - - crash - reporter - id a94c5544 - <number> - 4 5 8 f - 8 0 3 c - 0 aecde90a1fc | | screen reader | no | | vm | <percent> | connection to ' dev - container + 7 b22686f737450617468223a222f686f6d652f6d6168656e6472612f70726f6a656374732f72616173222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6e727a646f636b657274657374227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d6168656e6472612f70726f6a656374732f726161732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d ' could not be established | item | value | | - - - | - - - | | remote | dev container | os | linux x64 <number> . <number> - microsoft - standard - wsl2 | | cpus | amd ryzen <number> 4 9 0 0 hs with radeon graphics ( <number> x <number> )| | memory ( system ) | <number> . 2 5 gb ( <number> . 9 3 gb free ) | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - terraform | 4 op | <number> . <number> vscode - azurevirtualmachines | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> remote - explorer | ms - | <number> . <number> remote - server | ms - | <number> . <number> terraform | 4 op | <number> . <number> vscode - postgres | cko | <number> . <number> vscode - eslint | dba | <number> . <number> gitlens | eam | <number> . <number> git - graph | mhu | <number> . <number> azure - dev | ms - | <number> . <number> vscode - azureappservice | ms - | <number> . <number> vscode - azurecontainerapps | ms - | <number> . <number> vscode - azurefunctions | ms - | <number> . <number> vscode - azureresourcegroups | ms - | <number> . <number> vscode - azurestaticwebapps | ms - | <number> . <number> vscode - azurestorage | ms - | <number> . <number> vscode - azurevirtualmachines | ms - | <number> . <number> vscode - cosmosdb | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> azure - account | ms - | <number> . <number> azurecli | ms - | <number> . <number> vscode - node - azure - pack | ms - | <number> . <number> sqltools | mtx | <number> . <number> sqltools - driver - pg | mtx | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> <number> <time> <number> showlangstatbar : <number> 9 6 2 ge76 <time> <number> a2ce337 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofb : <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"can not able to create project type : <b> feature request </b> hi in my vs code it will do not show the create project option on the screen i am installing any version it will display only new file , open files , open folder options only in the window . vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"mysql type : <b> feature request </b> i tried but find very diffculties to query mysql in vscode vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"can you provide ways to distinguish between vscode windows . < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > hi vscode developers , the following description is based on windows . i am constantly working with multiple vscode windows . many times i found it hard to find a particular window when switching from other softwares . vscode shows filename before workspace / folder name , sometime the latter is hidden . i tried to set title bar color for different windows but it does not show in the thumbnail windows pompts when mouse is moved to vscode icon in the taskbar . so i am suggesting a setting item , maybe a property to give to workspaces so they appear differently . this may help users the navigate the the window they want . thanks .",2
microsoft/vscode,"the "" & "" symbol in the terminal is coming automatically after each time i change the directory using the cd command . type : <b> performance issue </b> the "" & "" symbol in the terminal is coming automatically after each time i change the directory using the cd command . how can i get rid from the "" & "" ? i can delete it manually each - time going backward after going the directory . which is pretty exhausting . record of the issue : <url> vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 1 0 7 5 0 h cpu @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 7 5 gb ( <number> . 4 7 gb free ) | | process argv | - - crash - reporter - id 1 6 2 6 e408 - 1 b63 - 4 e0a - abaa - 1 6 e76df5c15a | | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> window [ <number> ] ( welcome - <number> + native + modules - visual studio code ) <number> <number> <number> gpu - process <number> <number> <number> utility - network - service <number> <number> <number> ptyhost <number> <number> <number> conpty - agent <number> <number> <number> c :\\ windows \ \ system32 \ \ windowspowershell \ \ v1 . <number> \ \ powershell . exe - noexit - command "" try { . \ \ "" c :\\ users \ \ webta \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ out \ \ vs \ \ workbench \ \ contrib \ \ terminal \ \ browser \ \ media \ \ shellintegration . ps1 \ \ "" } catch { } "" <number> <number> <number> shared - process <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ webta \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node - - max - old - space - size = <number> "" c :\\ users \ \ webta \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ node_modules \ \ typescript \ \ lib \ \ tsserver . js "" - - servermode partialsemantic - - useinferredprojectperprojectroot - - disableautomatictypingacquisition - - cancellationpipename c :\\ users \ \ webta \ \ appdata \ \ local \ \ temp \ \ vscode - typescript \ \ 4 8 5 4 c7face779ce21e00 \ \ tscancellation - 3 1 7 6 bc4ca8571adec3a9 . tmp * - - locale en - - nogeterronbackgroundupdate - - validatedefaultnpmlocation - - usenodeipc ) <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ webta \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node - - max - old - space - size = <number> "" c :\\ users \ \ webta \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ node_modules \ \ typescript \ \ lib \ \ tsserver . js "" - - useinferredprojectperprojectroot - - enabletelemetry - - cancellationpipename c :\\ users \ \ webta \ \ appdata \ \ local \ \ temp \ \ vscode - typescript \ \ 4 8 5 4 c7face779ce21e00 \ \ tscancellation - ac8b167bdb98eaeffa73 . tmp * - - locale en - - nogeterronbackgroundupdate - - validatedefaultnpmlocation - - usenodeipc ) <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ webta \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c <annoyed> users / webta / appdata / local / programs / microsoft vs code / resources / app / extensions / node_modules / typescript / lib / typingsinstaller . js "" - - globaltypingscachelocation c <annoyed> users / webta / appdata / local / microsoft / typescript / <number> - - enabletelemetry - - typesmaplocation "" c <annoyed> users / webta / appdata / local / programs / microsoft vs code / resources / app / extensions / node_modules / typescript / lib / typesmap . json "" - - validatedefaultnpmlocation ) <number> <number> <number> "" c :\\ program files \ \ google \ \ drive file stream \ \ <number> . <number> \ \ crashpad_handler . exe "" - - database =c :\\ users \ \ webta \ \ appdata \ \ local \ \ google \ \ drivefs \ \ crashpad - - url = <url> - - annotation = application = code . exe - - annotation = prod = drivefs - - annotation = ver = <number> . <number> - - initial - client - data =0 x1180 , 0 x1390 , 0 x143c , 0 x1398 , 0 x140c , 0 x7fff8fa3eff0 , 0 x7fff8fa3f000 , 0 x7fff8fa3f010 <number> <number> <number> crashpad - handler <number> <number> <number> filewatcher [ <number> ] ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` | window ( welcome - <number> + native + modules - visual studio code ) | folder ( <number> + native + modules ) : <number> files | file types txt ( <number> ) | conf files : ; ` ` ` </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - copilot | git | <number> . <number> material - icon - theme | pki | <number> . <number> liveserver | rit | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> <number> <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofb : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"font type : <b> bug </b> currently i am learning to program in html , i am in the "" font size , font face "" phase , but when i use "" font "" it ' s like it does not exist . vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd a4 - <number> apu with radeon ( tm ) hd graphics ( <number> x <number> )| | gpu status | 2 d_canvas : unavailable_software <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : disabled_software <br> multiple_raster_threads : disabled_off <br> opengl : disabled_off <br> rasterization : disabled_software <br> raw_draw : disabled_off_ok <br> video_decode : disabled_software <br> video_encode : disabled_software <br> vulkan : disabled_off <br> webgl : unavailable_software <br> webgl2 : unavailable_software <br> webgpu : unavailable_software | | load ( avg ) | undefined | | memory ( system ) | <number> . 4 3 gb ( <number> . 3 8 gb free ) | | process argv | - - crash - reporter - id 2 1 bdeb6d - <number> - 4 0 bf - 9 f3a - deb26c9321f8 | | screen reader | no | | vm | <percent> | </details> extensions <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd2263cf : <number> vscaac : <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> f6dab26 <time> <number> vscrp : <number> showlangstatbar : <number> a2ce337 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> synctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - > ! [ image ] ( <url> idk if i am missing something",2
microsoft/vscode,"about winerror <number> when i import eel lib on my python code it keeps shown me this error on "" eel . start ( ' index . html ' ) "" is there a problem with my code or it ' s a bug ? ` ` ` [ tasklist ] # # # tasks ` ` `",2
microsoft/vscode,"make pinned tabs small type : <b> feature request </b> it would be nice if the pinned tabs get collapsed like in most web browsers . please make an option in settings to collapse pinned tabs . vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 9 9 1 z ) os version : linux x64 <number> . <number> - <number> - generic modes generated by issue reporter - - >",2
microsoft/vscode,"material - ui website not loading add issue description here version : <number> . <number> commit : 6 c3e3dba23e8fadc360aed75ce363ba185c49794 user agent : mozilla / <number> ( macintosh ; intel mac os x 1 0 _15_7 ) applewebkit / <number> ( khtml , like gecko ) chrome / <number> . <number> safari / <number> embedder < - - generated by web issue reporter - - >",2
microsoft/vscode,"* * on entry to dgebal parameter number <number> had an illegal value type : <b> bug </b> i am trying to run a python code in the visual studio code . in the fourth loop it is showing the following error : "" * * on entry to dgebal parameter number <number> had an illegal value "" . please help me fix this . vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 9 9 1 z ) os version : linux x64 <number> . <number> - <number> - generic modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - <number> cpu @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : disabled_software <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 2 3 gb ( <number> . 8 5 gb free ) | | process argv | - - unity - launch - - crash - reporter - id 0 4 7 b8f1f - 5 a5d - 4 6 c5 - b96d - 1 e3970b7a336 | | screen reader | no | | vm | <percent> | | desktop_session | ubuntu | | xdg_current_desktop | unity | | xdg_session_desktop | ubuntu | | xdg_session_type |x 1 1 | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - python - image - preview | <number> | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyonecf : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> f6dab26 <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> a2ce337 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> asynctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"something wrong with the terminal encoding < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : windows <number> x64 when i am trying to build c + + app , i am getting following error that i am not able to read : "" cmd "" � �  � � � � � � � � <number> � � � � � � � � � 譥 � � � � � � � � � , � ᯮ � � 塞 � � � ண ࠬ � � � � � � � � � � � � 䠩 � � � . i have already set oemcp at regedit to <number> , but it did not help . steps to reproduce try to build a c + + code <number> . recieve this abracadabra as a response .",2
microsoft/vscode,"code not running type : <b> bug </b> i tried running a code to extract audio features from a recordings dataset , but the only output in the terminal is different file paths . someone else tried running it on their computer and it worked for them . please could you help me fix this issue ? thank you . vs code version : code <number> . <number> ( e4503b30fc78200f846c62cf8091b76ff5547662 , <number> - <number> - 1 6 t <time> . 9 5 7 z ) os version : windows_nt ia32 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 cpu m <number> @ <number> . 6 7 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : unavailable_off <br> raw_draw : disabled_off_ok <br> skia_renderer : enabled_on <br> video_decode : enabled <br> video_encode : unavailable_off <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 | load ( avg ) | undefined | | memory ( system ) | <number> . 8 6 gb ( <number> . 1 9 gb free ) | | process argv || | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh93 <time> <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 3 biah6 <time> <number> f6dab26 <time> <number> showlangstatbar : <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofb : <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"to sets of pythan type : <b> bug </b> i have pythan from the extintions and one from axs and when i type in a pythan code it shows me the same code i typed in how to i repair it for one set of code ? vs code version : code <number> . <number> ( universal ) ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 9 2 4 z ) os version : darwin x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 8 2 1 0 y cpu @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> metal : disabled_off <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 1 0 gb free ) | | process argv | - - crash - reporter - id 8 7 b7a8a5 - bf43 - 4 a47 - bc81 - 1 1 da23b14e63 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - ruff | cha | <number> . <number> python - environment - manager | don | <number> . <number> codewiz | fel | <number> . <number> vscode - docker | ms - | <number> . <number> black - formatter | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> vscode - remote - extensionpack | ms - | <number> . <number> remote - explorer | ms - | <number> . <number> remote - server | ms - | <number> . <number> autodocstring | njp | <number> . <number> even - better - toml | tam | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> f6dab26 <time> <number> showlangstatbar : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"macos m1 vscode github copilot chat icon no show < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : - os version : steps to reproduce : <number> . after installed "" github copilot chat "" and reloaded vscode , no extension on side bar < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> versions : macoos : <number> . <number> vscode : version : <number> . <number> commit : 6 c3e3dba23e8fadc360aed75ce363ba185c49794 date : <number> - <number> - 0 9 t <time> . 6 9 8 z ( <number> days ago ) electron : <date> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os : darwin arm64 <number> . <number> copilot chat : both of below version do not work ( pre - release ) v0 . <number>",2
microsoft/vscode,"inform user about workspace tsdk . < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > # # # problem due to security restrictions , we cannot overwrite the tsdk without user consent . it ' s annoying , but understandable . <repeated> the problem is that this is not really visible to the user . this can causes several issues for the team members . <repeated> for example , some plugins just stop working when using the build - in version instead of the workspace tsdk version . the dev does not know about this and may only notice it much later . it ' s annoying and time consuming . just avoidable . * * . vscode / settings . json * * ( workspace ) ` ` ` json { "" typescript . tsdk "" : "" node_modules \ \ \ \ typescript \ \ \ \ lib "" , } ` ` ` [ docs ] ( <url> # # # solution this feature reqeust or improvement is about implementing a better way to inform the user about the workspace setting and make it easier to switch the correct version . we could display a bold blinking modal in the center of the screen , similar to ad banners . "" click here to win . "" but seriously . <repeated> it must be prominent visible and intuitively understandable . we could show a persistent notification until the user makes a choice . . <repeated> what ' s exactly the problem with the workspace setting ? potentially everyone could set any value ? a path to an npm package with vulnerabilities or other problems ? we could validate the value of ` typescript . tsdk ` with a allow list like "" mode_modules / typescript / lib "" which is the official typescript package . but ok , this does not cover to outdated versions that may have security risks . <repeated> anyway , this should be visible to the user . setting the tsdk in the workspace settings is done for serious reasons and should be used within the whole dev team . it might look like the "" do you trust the authors of the files in this folder ? "" dialog . something like : > this project recommends using the workspace ' s typescript tsdk . do you trust this project and want to allow that ? and check this on every start . it seems sometimes , the version is switched back for some reasons . i cannot reproduce . but checking that on every start is not a bad idea . and remain displayed until the user makes a decision . ! [ demo ] ( <url> we could also say , just load the tsdk setting of the workspace if the user confirmed the already existing trust - dialog . # # # info version : <number> . <number> ( user setup ) electron : <date> chromium : <number> . <number> node . js : <number> . <number> os x64 <number> . <number>",2
microsoft/vscode,"is it possible to setup mqtt connection from a server to vs code extension i am developing a source control extension for vscode , and i want to establish an mqtt connection between extension and server , so that after activation of the extension if there is any event or change happened on server side , the extension will get the notification of it . is this possible and how ? i am trying to look if , vs code allows to include such type of subscription to the server , without hampering the other processes in the extension . i tried to execute a cli command , which will keep listening to the server , but the executor method was just executing it and coming out of the method , it was not staying to read the sdt output , and if i tried to set an time interval , then other process were getting queued up so now rather than executing any command , i want to create a method which will create mqtt connection with the server",2
microsoft/vscode,"comment supprimer waka time api key type : <b> feature request </b> je voudrais supprimer waka time api key vs code version : code <number> . <number> ( 6 c3e3dba23e8fadc360aed75ce363ba185c49794 , <number> - <number> - 0 9 t <time> . 1 7 5 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"reload on the local host site not responding type : <b> performance issue </b> after startup while on my project the local host is not responding and if i type npm start on node . js command prompt it gives this message below c :\\ users \ \ user > npm start npm err code enoent npm err ! syscall open npm err ! path c :\\ users \ \ user \ \ package . json npm err ! errno - <number> npm err ! enoent could not read package . json : error : enoent : no such file or directory , open ' c :\\ users \ \ user \ \ package . json ' npm err ! enoent this is related to npm not being able to find a file . npm err ! enoent npm err ! a complete log of this run can be found in : c :\\ users \ \ user \ \ appdata \ \ local \ \ npm - cache \ \ _logs \ \ <number> - <number> - 1 1 t10_21_03_535z - debug - <number> . log c :\\ users \ \ user > vs code version : code <number> . <number> ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 4 8 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 8 5 5 0 u cpu @ <number> . 8 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 9 0 gb ( <number> . 3 0 gb free ) | | process argv | - - crash - reporter - id bfe49888 - c0e3 - 4 7 a0 - <number> - 6 9 3 7 2 2 c43bc6 | | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> gpu - process <number> <number> <number> window [ <number> ] ( message . js - reactp - visual studio code ) <number> <number> <number> ptyhost <number> <number> <number> c :\\ windows \ \ system32 \ \ windowspowershell \ \ v1 . <number> \ \ powershell . exe - noexit - command "" try { . \ \ "" c :\\ users \ \ user \ \ desktop \ \ microsoft vs code \ \ resources \ \ app \ \ out \ \ vs \ \ workbench \ \ contrib \ \ terminal \ \ browser \ \ media \ \ shellintegration . ps1 \ \ "" } catch { } "" <number> <number> <number> conpty - agent <number> <number> <number> crashpad - handler <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ user \ \ desktop \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node - - max - old - space - size = <number> "" c :\\ users \ \ user \ \ desktop \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ node_modules \ \ typescript \ \ lib \ \ tsserver . js "" - - servermode partialsemantic - - useinferredprojectperprojectroot - - disableautomatictypingacquisition - - cancellationpipename c :\\ users \ \ user \ \ appdata \ \ local \ \ temp \ \ vscode - typescript \ \ ebd781def187ffd9e89e \ \ tscancellation - 6 6 6 ce688eecc1201e015 . tmp * - - locale en - - nogeterronbackgroundupdate - - validatedefaultnpmlocation - - usenodeipc ) <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ user \ \ desktop \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node - - max - old - space - size = <number> "" c :\\ users \ \ user \ \ desktop \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ node_modules \ \ typescript \ \ lib \ \ tsserver . js "" - - useinferredprojectperprojectroot - - enabletelemetry - - cancellationpipename c :\\ users \ \ user \ \ appdata \ \ local \ \ temp \ \ vscode - typescript \ \ ebd781def187ffd9e89e \ \ tscancellation - fde1f8ef <phone> c5 . tmp * - - locale en - - nogeterronbackgroundupdate - - validatedefaultnpmlocation - - usenodeipc ) <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ user \ \ desktop \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c <annoyed> users / user / desktop / microsoft vs code / resources / app / extensions / node_modules / typescript / lib / typingsinstaller . js "" - - globaltypingscachelocation c <annoyed> users / user / appdata / local / microsoft / typescript / <number> - - enabletelemetry - - typesmaplocation "" c <annoyed> users / user / desktop / microsoft vs code / resources / app / extensions / node_modules / typescript / lib / typesmap . json "" - - validatedefaultnpmlocation ) <number> <number> <number> shared - process <number> <number> <number> filewatcher [ <number> ] <number> <number> <number> utility - network - service ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` | window ( message . js - reactp - visual studio code ) | folder ( reactp ) : <number> files | file types : js ( <number> ) json ( <number> ) png ( <number> ) css ( <number> ) gitignore ( <number> ) ico ( <number> ) html ( <number> ) | txt ( <number> ) md ( <number> ) svg ( <number> ) | conf files : package . json ( <number> ); ` ` ` </details> extensions <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl492cf : <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vstes26 <time> <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> <number> <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"i am not able to make changes to the settings , everything i change appears this sentence "" unable to record in user settings . open user settings to correct errors / warnings and try again . "" and does not save . { "" editor . minimap . rendercharacters "" : true , "" workbench . editorassociations "" : { "" * . jfif "" : "" default "" } , "" powermode . enabled "" : true , "" workbench . colortheme "" : "" omni "" , "" php . validate . executablepath "" : "" "" if ( isset ( $ _post [ ' url ' ] ) & & strlen ( $ _post [ ' url ' ] ) = = <number> ) { } if ( isset ( $ _post [ ' acao ' ] ) & & $ _post [ ' acao ' ] = = ' enviar ' ) { } if ( isset ( $ _files [ ' arquivo ' ] ) & & $ _files [ ' arquivo ' ] [ ' error ' ] = = = upload_err_ok ) { $ arquivo = $ _files [ ' arquivo ' ]; $ arquivonome = $ _post [ ' arquivo ' ]; } else { / / trate o caso de nenhum arquivo ter sido enviado / / por exemplo , atribuir valores padrão ou mostrar uma mensagem de erro } $ nome = $ _post [ ' nome ' ]; $ email = $ _post [ ' email ' ]; $ assunto = $ _post [ ' assunto ' ]; $ arquivo = $ _files [ ' arquivo ' ]; $ arquivonome = $ _post [ ' arquivo ' ]; $ mensagem = $ _post [ ' mensagem ' ]; $ data = date ( ' d / m / y h : i ' ); if ( $ nome = = ' ' || $ email = = ' ' || $ assunto = = ' ' || $ mensagem = = ' ' ) { echo ' <script> alert ( "" por favor , preencha todos os campos corretamente "" ) ; location . href = "" index . php "" </script> ' ; if ( ! class_exists ( ' phpmailer ' ) ) { require_once ( "" phpmailer / class . phpmailer . php "" ); } / / inicia a classe phpmailer $ mail = new phpmailer ( ); $ mail - > charset = "" utf - <number> "" ; / / define os dados do servidor e tipo de conexão / / $ mail - > issmtp ( ); / / define que a mensagem será smtp $ mail - > host = "" mail . seusite . com . br "" ; / / endereço do servidor smtp $ mail - > smtpauth = true ; $ mail - > port = ' <number> ' ; $ mail - > username = ' <email> ' ; / / usuário do servidor smtp $ mail - > password = ' <number> ' ; / / senha do servidor smtp / / define o remetente $ mail - > from = $ _post [ ' email ' ]; / / seu e - mail $ mail - > fromname = $ _post [ ' nome ' ]; / / seu nome $ mail - > sender = ' <email> ' ; / / define os destinatário ( s ) $ mail - > addaddress ( ' <email> ' ); / / $ mail - > addcc ( ' <email> ' , ' ciclano ' ); / / copia / / $ mail - > addbcc ( ' <email> . br ' , ' fulano da silva ' ); / / cópia oculta / / define os dados técnicos da mensagem $ mail - > ishtml ( true ) ; / / define que o e - mail será enviado como html / / $ mail - > charset = ' iso - <number> - <number> ' ; / / charset da mensagem ( opcional ) / / define a mensagem ( texto e assunto ) $ local = "" mensagem do artigo sobre formulario - seu site "" ; $ mail - > subject = $ local ; / / assunto da mensagem $ mail - > body = ' < div style = "" border : 1 px solid <hashtag> f0f0f0 </hashtag> ; background : <hashtag> f <elongated> </hashtag> ; font - size : 1 em ; color <seallips> <number> ; margin :0 px auto ; padding : 1 em ; overflow : hidden ;""> < p style = "" width : <percent> ; float : left ; margin - bottom : 1 px ; font - size : <number> . 2 em ;""> < strong style = "" color : <hashtag> 0 0 abff </hashtag> ;""> nome :</ strong > ' . $ nome . ' </p> < p style = "" width : <percent> ; float : left ; margin - bottom : 1 px ; font - size : <number> . 2 em ;""> < strong style = "" color : <hashtag> 0 0 abff </hashtag> ;""> e - mail :</ strong > ' . $ email . ' </p> < p style = "" width : <percent> ; float : left ; margin - bottom : 1 px ; font - size : <number> . 2 em ;""> < strong style = "" color : <hashtag> 0 0 abff </hashtag> ;""> assunto :</ strong > ' . $ assunto . ' </p> < p style = "" width : <percent> ; float : left ; margin - bottom :0 px ; font - size : <number> . 2 em ;""> < strong style = "" color : <hashtag> 0 0 abff </hashtag> ;""> mensagem :</ strong > ' . $ mensagem . ' </p> < p style = "" width : <percent> ; float : left ; margin - bottom : 2 px ; color : <hashtag> 0 0 abff </hashtag> ; font - size : <number> . 2 em ; border - top : 1 px <hashtag> e9e9e9 </hashtag> solid ; padding - top : 5 px ;""> <strong> enviado pelo site :</ strong > <url> <br> <br> <strong> data de envio :</ strong > ' . $ data . ' </p> </div> ' ; $ mail - > altbody = "" \ \ r \ \ n <happy> "" ; / / define os anexos ( opcional ) $ mail - > addattachment ( $ arquivo [ ' tmp_name ' ] , $ arquivo [ ' name ' ]); / / $ mail - > addattachment ( "" c <annoyed> temp / documento . pdf "" , "" novo_nome . pdf "" ); / / insere um anexo / / envia o e - mail $ enviado = $ mail - > send ( ); / / limpa os destinatários e os anexos $ mail - > clearallrecipients ( ); $ mail - > clearattachments ( ); / / exibe uma mensagem de resultado if ( $ enviado ) { echo ' < div style = "" max - width : 3 2 0 px ; padding : 3 0 px ; border <happy> px solid <hashtag> 0 0 abff </hashtag> ; color : <hashtag> 0 0 abff </hashtag> ; font - family background : <hashtag> f7f7f7 </hashtag> ; text - align : center ; font - weight : <number> ; margin : 1 8 0 px auto ;""> < p style = "" font - size : <number> . 3 em ;""> obrigado ! </p> < p style = "" font - size : 1 em ;""> mensagem enviada com sucesso ! </p> </div> ' ; echo ' < meta http - equiv = "" refresh "" content = "" <number> ; url = index . php "" >'; } else { echo "" não foi possível enviar o e - mail . "" ; echo "" <b> informações do erro :</ b > "" . $ mail - > errorinfo ; } } / / if verifica campos em brancos } / / fecha condição se alguém clicar no botão } / / fecha verifica se é url vazia ? > ` ` ` [ tasklist ] # # # tasks ` ` `",2
microsoft/vscode,"powershell type : <b> feature request </b> there is an issue with my terminal , that the terminal process failed to launch vs code version : code <number> . <number> ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 4 8 5 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,chatview how display ? vscode version ` chatview ` can not display in activity bar . what happened ? [ image ] ( <url>,2
microsoft/vscode,"metatrader5 type : <b> bug </b> "" pip3 install metatrader5 "" gives requirement already satisfied : metatrader5 in c :\\ users \ \ eric_ \ \ appdata \ \ local \ \ programs \ \ python \ \ python311 \ \ lib \ \ site - packages ( <date> ) requirement already satisfied : numpy > = <number> in c :\\ users \ \ eric_ \ \ appdata \ \ local \ \ programs \ \ python \ \ python311 \ \ lib \ \ site - packages ( from metatrader5 ) ( <number> . <number> ) "" import metatrader5 "" gives import "" metatrader5 "" could not be resolved vs code version : code <number> . <number> ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 4 8 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - <number> cpu @ <number> . 7 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 1 gb ( <number> . 8 2 gb free ) | | process argv | - - crash - reporter - id 5 f67829f - fbdb - 4 a36 - 8 4 b2 - 1 8 c12c20edc2 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - code - runner | for | <number> . <number> vscode - docker | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> f6dab26 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofb : <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"have to reopen files on startup type : <b> bug </b> if you open a folder and create files there , then when you close and start them , they disappear , and you have to open them again , tell me how to fix this ? ( macos ) vs code version : code <number> . <number> ( universal ) ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 7 8 2 z ) os version : darwin arm64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | apple m2 ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> metal : disabled_off <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 5 6 gb free ) | | process argv | - - crash - reporter - id 6 3 c19850 - 0 2 b2 - 4 ed0 - a1f1 - 2 4 2 e41669ad3 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - language - pack - ru | ms - | <number> . <phone> python | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> icons | tal | <number> . <number> cmake | twx | <date> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl492cf : <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> <number> <time> <number> vscrpc : <number> showlangstatbar : <number> vsctsb : <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"errors are not showing type : <b> bug </b> cannot see the errors while writing code vs code version : code <number> . <number> ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 4 8 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 8 2 6 5 u cpu @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 9 gb ( <number> . 8 9 gb free ) | | process argv | - - crash - reporter - id 0 e29f355 - b8e6 - 4 9 b3 - 8 b7a - dc87335b869b | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - bootstrap5 - vscode | anb | <number> . <number> ng - template | ang | <number> . <number> tailwind - docs | aus | <number> . <number> bootstrap - <number> - snippets | bab | <number> . <number> blackbox | bla | <date> tailwindshades | bou | <number> . <number> vscode - tailwindcss | bra | <date> bootstrap - <number> - snippets - by - coder - foundry | cod | <number> . <number> dart - code | dar | <number> . <number> flutter | dar | <number> . <number> vscode - eslint | dba | <number> . <number> maven - dependency - explorer | dhr | <date> javascript - ejs - support | dig | <number> . <number> es7 - react - js - snippets | dsz | <number> . <number> vscode - toggle - column - selection | eri | <number> . <number> prettier - vscode | esb | <number> . <number> file - icons | fil | <number> . <number> auto - close - tag | for | <date> code - runner | for | <number> . <number> bootstrap5 - snippets | han | <number> . <number> stylelint - plus | hex | <number> . <number> csharpextensions | kre | <number> . <number> csharp | ms - | <date> vscode - dotnet - runtime | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> color - highlight | nau | <number> . <number> material - icon - theme | pki | <number> . <number> java | red | <number> . <number> liveserver | rit | <number> . <number> es7 - react - js - snippets | rod | <number> . <number> js - jsx - snippets | sky | <number> . <number> bootstrap4 - vscode | the | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> javascriptsnippets | xab | <number> . <number> bootstrap - v4 - snippets | zac | <number> . <number> tailwind - snippets | zar | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh93 <time> <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 8 2 f87 <time> <number> <number> <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> <number> <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"first lesson type : <b> bug </b> during the first lesson , while compiling the java project : console . log ( "" - - - - - - - - - - - - - - - - - - - - - - - - "" ); console . log ( "" rise & shine "" ); console . log ( "" ready for a new day ! <repeated> "" ); console . log ( "" - - - - - - - - - - - - - - - - - - - - - - - - "" ); selected javascript debug terminal f5 lanched no error warning does not work passing with the mouse on javascript debug terminal popsup message . "" process id ( pid ) : <number> command line <sad> :\\ windows \ \ system32 \ \ windowspoweershell \ \ v1 . <number> \ \ powershell . exe ' - noexit ' ' - command ' ' try { . "" c :\\ program files \ \ microsoft vs code \ \ resources \ \ app \ \ out \ \ vs \ \ workbench \ \ contrib \ \ terminal \ \ browser \ \ media \ \ shellintegration . ps1 "" } catch { } ' shell integration failed to acttivate . vs code version : code <number> . <number> ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 4 8 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) celeron ( r ) cpu n2830 @ <number> . 1 6 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : disabled_off <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : unavailable_off <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 9 gb ( <number> . 1 1 gb free ) | | process argv | - - crash - reporter - id c0ff269f - a2de - 4 c0b - 9 7 a5 - b661bab3d6c1 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - python - environment - manager | don | <number> . <number> python - extension - pack | don | <number> . <number> vsc - python - indent | kev | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> cpptools | ms - | <number> . <number> live - server | ms - | <number> . <number> autodocstring | njp | <number> . <number> java | red | <number> . <number> startanyshell | rem | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> jinja | who | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> <number> <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"background color support for notebook cells < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > hi experts , i am using the notebooks in vs code for lots of data and ml work . yes , we always have to create lots of cells in the notebook and edit them at the same time . so i think that it is possible to set up the cells using different background colors . for example , use light green as the python code cell and use light blue as the markdown cell , etc . it may help us more rapidly locate the cell which needs to edit and can be used with cell tags together .",2
microsoft/vscode,"my c programming code is not working properly type : <b> bug </b> <hashtag> include </hashtag> < stdio . h > int main ( ) { int rating ; printf ( "" enter your rating ( <number> - <number> ) = \ \ n "" ); scanf ( "" % d "" , rating ) ; switch ( rating ) { case <number> : printf ( "" your rating is <number> \ \ n "" ); break ; case <number> : printf ( "" your rating is <number> \ \ n "" ); break ; case <number> : printf ( "" your rating is <number> \ \ n "" ); break ; case <number> : printf ( "" your rating is <number> \ \ n "" ); break ; case <number> : printf ( "" your rating is <number> \ \ n "" ); break ; default : printf ( "" invalid rating "" ); } return <number> ; } vs code version : code <number> . <number> ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 4 8 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 3 4 7 0 s cpu @ <number> . 9 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 0 gb ( <number> . 5 6 gb free ) | | process argv |c :\\\\ users \ \ \ \ pc \ \ \ \ desktop \ \ \ \ dev . c - - crash - reporter - id 8 ab98f09 - 6 d32 - 4 7 e9 - a55d - 1 dfeeb7fe37b | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - prettier - vscode | esb | <number> . <number> code - runner | for | <number> . <number> c - cpp - runner | fra | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> cmake | twx | <date> vscode - lldb | vad | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vstes263cf : <number> vscoreces : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> <number> <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofb : <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"vs code will not run anything type : <b> bug </b> anything i type in the vs code terminal gives me the same error : git : the term ' git ' is not recognized as the name of a cmdlet , function , script file , or operable program . check the spelling of the name , or if a path was included , verify that the path is correct and try again . at line : <number> char : <number> + git clone - - single - branch - b "" react - mini "" <url> . <repeated> + ~ ~ ~ + categoryinfo : objectnotfound : ( git : string ) [ ] , commandnotfoundexception + fullyqualifiederrorid : commandnotfoundexception git is just an example , it gives the same error in pip and everything else as well . please help . i checked everywhere on the internet and the most common answer i got was check the path in the environment variables , but the path is correct , i have checked it multiple times . <url> vs code version : code <number> . <number> ( 6 4 4 5 d93c81ebe42c4cbd7a60712e0b17d9463e97 , <number> - <number> - 0 2 t <time> . 4 8 5 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> 5 8 0 0 h with radeon graphics ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 6 gb ( <number> . 7 8 gb free ) | | process argv | - - crash - reporter - id afa7e0e3 - e800 - 4 e6a - 9 1 3 b - 3 0 e6c57b357a | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - better - comments | aar | <number> . <number> vscode - django | bat | <number> . <number> doxdocgen | csc | <number> . <number> python - environment - manager | don | <number> . <number> python - extension - pack | don | <number> . <number> es7 - react - js - snippets | dsz | <number> . <number> vsc - material - theme | equ | <number> . <number> vsc - material - theme - icons | equ | <number> . <number> prettier - vscode | esb | <number> . <number> mithril - emmet | fal | <number> . <number> auto - close - tag | for | <date> auto - rename - tag | for | <date> code - runner | for | <number> . <number> better - cpp - syntax | jef | <number> . <number> vsc - python - indent | kev | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> remote - explorer | ms - | <number> . <number> color - highlight | nau | <number> . <number> autodocstring | njp | <number> . <number> vscode - css - peek | pra | <number> . <number> liveserver | rit | <number> . <number> pytorch - snippets | sbs | <number> . <number> cmake | twx | <date> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> jinja | who | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd2263cf : <number> vscaac : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> <number> <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofb : <number> pythonnosmt <time> <number> pythonidxptcf : <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"js file logo is different [ screenshot ( <number> ) ] ( <url> < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> <number> "" src = "" <url> ! [ screenshot ( <number> ) ] ( <url> type : <b> bug </b> when i apply vs code icon theme through extension it works very well . then later i try to sign in to github through vs code . unfortunately , my js file icon theme has been changed . vs code version : code <number> . <number> ( 2 ccd690cbff1569e4a83d7c43d45101f817401dc , <number> - <number> - 2 7 t <time> . 9 0 9 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"having trouble with checking my programms befor submitting them in cs50 course for python and ai i have wrote a program for one of the projects in my account which its name is "" home_federal_savings_bank "" . the problem is i face some errors when i entre the checking command ( check50 cs50 / problems / <number> / python / bank ) although i do not observe any error when i run it by my own in vs code . i do not know where the problem is and i appreciate if you help me through this problem . thank you . my program : t = input ( ) . lower ( ) . split ( ) tt = t [ <number> ] [ <number> ] if t [ <number> ][: <number> ] = = ' hello ' : print ( ' <money> ' ) elif t [ <number> ] = ' hello ' and tt = = ' h ' : print ( ' <money> ' ) else : print ( ' <money> ' ) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - output in my own computer : > > > hello [ output <happy> > > > <money> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - result of check50 cs50 / problems / <number> / python / bank command in code space bank . py exists <sad> input of "" hello "" yields output of <money> expected prompt for input , found none <sad> input of "" hello "" yields output of <money> expected prompt for input , found none <sad> input of "" hello , newman "" yields output of <money> expected prompt for input , found none <sad> input of "" how you doing ? "" yields output of <money> expected prompt for input , found none <sad> input of "" what ' s happening ? "" yields output of <money> expected prompt for input , found none <sad> input of "" what ' s up ? "" yields output of <money> expected prompt for input , found none",2
microsoft/vscode,". / population : line <number> : syntax error near unexpected token ' ( ' add issue description here i have this issue and i do not know how to fix it . i have done everything and am unsure if anything is wrong with my bash commands . other files work well but this population is messing up really well and when i create a new one , i can not run any more orders . version : <number> . <number> commit : 2 ccd690cbff1569e4a83d7c43d45101f817401dc user agent : mozilla / <number> ( windows nt <number> ; win64 ; x64 ) applewebkit / <number> ( khtml , like gecko ) chrome / <number> . <number> safari / <number> embedder < - - generated by web issue reporter - - >",2
microsoft/vscode,"cannot open db type : <b> bug </b> i can open any db , i get this error even on new db without any tables on it . [ <time> ] [ vscode - sqlite ] [ error ] failed to open database ' c :\\ users \ \ steve \ \ desktop \ \ test_project \ \ project . db ' : parse error near line <number> : no such column : table aster where ( type = "" table "" or type = "" view "" ) error here - - - ^ vs code version : code <number> . <number> ( 2 ccd690cbff1569e4a83d7c43d45101f817401dc , <number> - <number> - 2 7 t <time> . 9 0 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> 5 7 0 0 x <number> - core processor ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 2 gb ( <number> . 1 9 gb free ) | | process argv | - - crash - reporter - id a0057069 - 8 edb - 4 a13 - 9 4 7 e - 0 2 9 3 0 0 e7b6fe | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - sqlite | ale | <number> . <number> ajax - query | bal | <number> . <number> vscode - intelephense - client | bme | <number> . <number> phpserver | bra | <number> . <number> xml | dot | <number> . <number> editorconfig | edi | <number> . <number> auto - close - tag | for | <date> auto - rename - tag | for | <date> code - runner | for | <number> . <number> node - module - intellisense | lei | <number> . <number> vscode - apache | mrm | <number> . <number> vscode - docker | ms - | <number> . <number> data - workspace - vscode | ms - | <number> . <number> mssql | ms - | <number> . <number> sql - bindings - vscode | ms - | <number> . <number> sql - database - projects - vscode | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> sqltools | mtx | <number> . <number> sqltools - driver - mysql | mtx | <number> . <number> liveserver | rit | <number> . <number> code - spell - checker | str | <number> . <number> php - debug | xde | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyonecf : <number> 2 e4cg34 <time> <number> <number> <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> hideindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc014cf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"error type : <b> performance issue </b> hello , i have recently created a class that consists of a header file and an implementation file but when i try to run the code i receive an error that "" main . exe "" does not exist . how do i fix this please ? vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 6 5 1 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 0 0 h @ <number> . 1 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu : enabled | | load ( avg ) | undefined | | memory ( system ) | <number> . 7 9 gb ( <number> . 0 6 gb free ) | | process argv | - - crash - reporter - id c3fc9a03 - f19d - 4 3 e1 - 8 4 1 d - 0 9 2 e1270c5eb | | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> window [ <number> ] ( main . cpp - . vscode - visual studio code ) <number> <number> <number> filewatcher [ <number> ] <number> <number> <number> ptyhost <number> <number> <number> c :\\ windows \ \ system32 \ \ windowspowershell \ \ v1 . <number> \ \ powershell . exe <number> <number> <number> conpty - agent <number> <number> <number> conpty - agent <number> <number> <number> c :\\ windows \ \ system32 \ \ windowspowershell \ \ v1 . <number> \ \ powershell . exe <number> <number> <number> crashpad - handler <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> c :\\ users \ \ men3em \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 \ \ bin \ \ cpptools . exe <number> <number> <number> "" c :\\ users \ \ men3em \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 \ \ bin \ \ cpptools . exe "" <number> <number> <number> c :\\ users \ \ men3em \ \ . vscode \ \ extensions \ \ ms - vscode . cpptools - <number> . <number> - win32 - x64 / bin / cpptools - srv . exe <number> { bd2eded0 - d037 - 4 dc5 - bb4c - 9 ad3ea73a16a } <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> c :\\ windows \ \ system32 \ \ conhost . exe 0x 4 <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ men3em \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c :\\ users \ \ men3em \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ json - language - features \ \ server \ \ dist \ \ node \ \ jsonservermain "" - - node - ipc - - clientprocessid = <number> ) <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> c :\\ users \ \ men3em \ \ appdata \ \ local \ \ temp \ \ vscode - stable - user - x64 \ \ codesetup - stable - 2 ccd690cbff1569e4a83d7c43d45101f817401dc . exe / verysilent / log / update =""c :\\ users \ \ men3em \ \ appdata \ \ local \ \ temp \ \ vscode - stable - user - x64 \ \ codesetup - stable - 2 ccd690cbff1569e4a83d7c43d45101f817401dc . flag "" / nocloseapplications / mergetasks = runcode , desktopicon , ! quicklaunchicon <number> <number> <number> "" c :\\ users \ \ men3em \ \ appdata \ \ local \ \ temp \ \ is - 3 nvhs . tmp \ \ codesetup - stable - 2 ccd690cbff1569e4a83d7c43d45101f817401dc . tmp "" / sl5 = "" <money> , <number> , c :\\ users \ \ men3em \ \ appdata \ \ local \ \ temp \ \ vscode - stable - user - x64 \ \ codesetup - stable - 2 ccd690cbff1569e4a83d7c43d45101f817401dc . exe "" / verysilent / log / update =""c :\\ users \ \ men3em \ \ appdata \ \ local \ \ temp \ \ vscode - stable - user - x64 \ \ codesetup - stable - 2 ccd690cbff1569e4a83d7c43d45101f817401dc . flag "" / nocloseapplications / mergetasks = runcode , ! desktopicon , ! quicklaunchicon <number> <number> <number> shared - process <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ men3em \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c :\\ users \ \ men3em \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ out \ \ bootstrap - fork "" ms - vscode . cppdbg "" { \ \ "" common . vscodemachineid \ \"": \ \ "" 7 8 c7d868a7a62ab370eef109cc3cab036b011c055c040635442005ce634193bb \ \ "" , \ \ "" common . vscodesessionid \ \"": \ \ "" f8224bc3 - d07e - 4 c98 - b456 - 9 2 0 4 0 1 6 5 a6911690544069520 \ \ "" } "" 0 c6ae279ed8443289764825290e4f9e2 - 1 a736e7c - <number> - <number> - be46 - fc2a58ae4d14 - <number> ) <number> <number> <number> utility - network - service <number> <number> <number> gpu - process ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` | window ( main . cpp - . vscode - visual studio code ) | folder ( . vscode ) : <number> files | file types : py ( <number> ) dll ( <number> ) json ( <number> ) md ( <number> ) js ( <number> ) svg ( <number> ) png ( <number> ) | exe ( <number> ) map ( <number> ) vsixmanifest ( <number> ) | conf files : package . json ( <number> ) launch . json ( <number> ) settings . json ( <number> ) | tasks . json ( <number> ) devcontainer . json ( <number> ) dockerfile ( <number> ) | makefile ( <number> ) | launch configs ` ` ` </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - codesnap | adp | <number> . <number> vscode - intelephense - client | bme | <number> . <number> c - cpp - compile - run | dan | <date> composer - php - vscode | dev | <number> . <number> phptools - vscode | dev | <number> . <number> profiler - php - vscode | dev | <number> . <number> prettier - vscode | esb | <number> . <number> arduino - class - creator | far | <number> . <number> cpp - class - creator | fle | <number> . <number> c - cpp - runner | fra | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> format - html - in - php | rif | <number> . <number> cmake | twx | <date> vscode - lldb | vad | <number> . <number> php - debug | xde | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 2 e4cg34 <time> <number> f6dab26 <time> <number> showlangstatbar : <number> vsctsb : <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> hideindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc0 <time> <number> dsvsc0 <time> <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"run the c code type : <b> feature request </b> i am unable to run the for loop in c . it shows the massage "" ' for ' loop declarations are only allowed in c99 mode . please lead me to solve this issue with full details and step by step . vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 6 5 1 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"environment variables such as path only for a workspace , in settings . json < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > is there a way to have a workspace specific path , added to settings . json for common executables . were working on an extension where go is installed in the extension location , it would be nice to have env var support only for the workspace",2
microsoft/vscode,"javascript in vscode cannot be intelligently completed type : <b> bug </b> javascript in vscode cannot be intelligently completed , but it can be intelligently completed after changing the type of js file to typescript . vs code version : code <number> . <number> ( b3e4e68a0bc097f0ae7907b217c1119af9e03435 , <number> - <number> - 1 0 t <time> . 2 4 8 z ) os version : windows_nt x64 <number> . <number> modes : sandboxed : yes <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 0 gb ( <number> . 1 7 gb free ) | | process argv | - - crash - reporter - id 2 1 2 3 c431 - 8 3 b9 - 4 7 c8 - b7dc - 2 d65961922ff | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - codesnap | adp | <number> . <number> bookmarks | ale | <number> . <number> project - manager | ale | <number> . <number> preview - pdf | ana | <number> . <number> html - end - tag - labels | ant | <number> . <number> browse - lite | ant | <number> . <number> vite | ant | <number> . <number> vue - jumper | atd | <number> . <number> color - info | bie | <number> . <number> bito | bit | <number> . <number> exe - runner | bra | <number> . <number> vsc - jetbrains - icons - enhanced | bre | <number> . <number> vscode - jetbrains - icon - theme | cha | <number> . <number> wechat - snippet | cha | <date> npm - intellisense | chr | <number> . <number> path - intellisense | chr | <number> . <number> gitignore | cod | <number> . <number> laravel - goto - view | cod | <number> . <number> miniprogram - vscode - extension | cra | <date> vscode - mysql - client2 | cwe | <number> . <number> vscode - office | cwe | <number> . <number> xmind - viewer | cwe | <number> . <number> vscode - markdownlint | dav | <number> . <number> vscode - notes | dio | <number> . <number> python - preview | don | <number> . <number> git - extension - pack | don | <number> . <number> githistory | don | <date> python - environment - manager | don | <number> . <number> python - extension - pack | don | <number> . <number> brackethighlighter | dur | <number> . <number> gitlens | eam | <number> . <number> vscode - html - css | ecm | <number> . <number> editorconfig | edi | <number> . <number> vscode - npm - script | eg2 | <date> prettier - vscode | esb | <number> . <number> python - code - snippets | ext | <number> . <number> git - project - manager | fel | <number> . <number> auto - close - tag | for | <date> auto - rename - tag | for | <date> code - runner | for | <number> . <number> codespaces | git | <date> remotehub | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> gc - excelviewer | gra | <date> todo - tree | gru | <date> vue - snippets | hol | <number> . <number> vscode - wordcount - cjk | hol | <number> . <number> beautify | hoo | <number> . <number> vscode - htmlhint | htm | <number> . <number> rest - client | hum | <number> . <number> output - colorizer | ibm | <number> . <number> path - autocomplete | ion | <number> . <number> open - file - from - path | jac | <number> . <number> mysql - syntax | jak | <number> . <number> dot - log | jal | <number> . <number> hungry - delete | jas | <number> . <number> search - node - modules | jas | <number> . <number> shortcut - menu - bar | jer | <number> . <number> intellij - idea - keybindings | k - - | <number> . <number> vsc - python - indent | kev | <number> . <number> vscode - gutter - preview | kis | <number> . <number> node - module - intellisense | lei | <number> . <number> vscode - settings - editor | lir | <number> . <number> magicpython | mag | <number> . <number> template - string - converter | meg | <number> . <number> git - graph | mhu | <number> . <number> dotenv | mik | <number> . <number> vscode - filesize | mkx | <number> . <number> diff - merge | mos | <number> . <number> easy - less | mrc | <number> . <number> vscode - scss | mrm | <number> . <number> vscode - docker | ms - | <number> . <number> vscode - language - pack - zh - hans | ms - | <number> . <phone> isort | ms - | <number> . <number> python | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> azure - repos | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> live - server | ms - | <number> . <number> remote - explorer | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> remote - server | ms - | <number> . <number> one - dark - theme | msk | <number> . <number> vscode - python - typehint | njq | <number> . <number> vscode - versionlens | pfl | <number> . <number> vs - browser | phu | <date> material - icon - theme | pki | <number> . <number> material - product - icons | pki | <number> . <number> vscode - css - peek | pra | <number> . <number> vscode - css - navigation | puc | <number> . <number> minapp - vscode | qiu | <date> sqlite - viewer | qwt | <number> . <number> vscode - thunder - client | ran | <number> . <number> vscode - yaml | red | <number> . <number> shellman | rem | <number> . <number> vscode - statusbar - json - path | ric | <number> . <number> liveserver | rit | <number> . <number> any - rule | rus | <date> vs - code - prettier - eslint | rve | <number> . <number> partial - diff | ryu | <number> . <number> multi - command | ryu | <number> . <number> vue - vscode - snippets | sdr | <number> . <number> markdown - preview - enhanced | shd | <number> . <number> vscode - scss - formatter | sib | <number> . <number> svg - preview | sim | <number> . <number> pip - manager | sli | <number> . <number> css - auto - prefix | spo | <number> . <number> vscode - standard | sta | <number> . <number> autoimport | ste | <number> . <number> code - spell - checker | str | <number> . <number> sass - indented | syl | <date> tabnine - vscode | tab | <date> open - in - browser | tec | <number> . <number> pdf | tom | <number> . <number> luna - paint | tyr | <number> . <number> sort - lines | tyr | <number> . <number> vscode - counter | uct | <number> . <number> highlight - matching - tag | vin | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - svg - previewer | vit | <number> . <number> vscode - icons | vsc | <number> . <number> image - viewer | vsc | <number> . <number> volar | vue | <number> . <number> vscode - typescript - vue - plugin | vue | <number> . <number> gitblame | wad | <number> . <number> crs - al - language - extension | wal | <date> quokka - vscode | wal | <date> fanyi | wan | <number> . <number> vscode - todo - highlight | way | <number> . <number> jinja | who | <number> . <number> vscode - import - cost | wix | <number> . <number> change - case | wma | <number> . <number> javascriptsnippets | xab | <number> . <number> vscode - preview - server | yui | <number> . <number> markdown - pdf | yza | <number> . <number> markdown - all - in - one | yzh | <number> . <number> json | zai | <number> . <number> vscode - open - in - github | ziy | <number> . <number> vue | znc | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd2263cf : <number> vscaat : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> f6dab26 <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosm12tcf : <number> pythonidxpt : <number> pythonnocebcf : <number> h7j2d46 <time> <number> dsvsc013cf : <number> dsvsc0 <time> <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"terminated type : <b> bug </b> the terminal process "" c :\\ users \ \ venka \ \ . dotnet \ \ tools \ \ pwsh . exe "" terminated with exit code : <phone> . vs code version : code - insiders <number> . <number> - insider ( c85bf61a82b0c39886b032d <phone> a55c637 , <number> - <number> - 1 9 t <time> . 4 4 1 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i3 - 1 0 0 5 g1 cpu @ <number> . 2 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 0 gb ( <number> . 8 8 gb free ) | | process argv | - - crash - reporter - id ff0bc616 - 3 4 0 d - 4 e72 - a388 - a233dfe53906 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - dart - code | dar | <number> . <number> flutter | dar | <number> . <number> remote - wsl | ms - | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv69 <time> <number> vsins8 <time> <number> vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> pythontb : <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vscod805cf : <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> pylantcb5 <time> <number> showlangstatbar : <number> <number> <time> <number> pythonfmttext : <number> pythoncmvfstr : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsofa : <number> pythonnosmt <time> <number> pythonidxpt : <number> pythondjangots : <number> pythonnoceb : <number> copilotsettingt : <number> e537b57 <time> <number> h0f3276 <time> <number> synctok : <number> dsvsc0 <time> <number> dsvsc0 <time> <number> diffeditorv <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"when the same variable exists in the open files , intelligent completion will trigger wrong completion type : <b> bug </b> [ image ] ( <url> ! [ image ] ( <url> vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 2 9 8 z ) os version : darwin x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 1 0 3 8 ng7 cpu @ <number> . 0 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> metal : disabled_off <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | <number> , <number> , <number> | | memory ( system ) | <number> . 0 0 gb ( <number> . 3 7 gb free ) | | process argv | - - crash - reporter - id 2 5 3 3 7 f27 - 0 fd6 - 4 ad2 - a343 - d23e45e01d53 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - tailwindcss | bra | <date> gitignore | cod | <number> . <number> vscode - eslint | dba | <number> . <number> gitlens | eam | <number> . <number> editorconfig | edi | <number> . <number> prettier - vscode | esb | <number> . <number> auto - close - tag | for | <date> code - runner | for | <number> . <number> remotehub | git | <number> . <number> git - graph | mhu | <number> . <number> vscode - language - pack - zh - hans | ms - | <number> . <phone> remote - repositories | ms - | <number> . <number> material - icon - theme | pki | <number> . <number> liveserver | rit | <number> . <number> even - better - toml | tam | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> pretty - ts - errors | yoa | <number> . <number> markdown - all - in - one | yzh | <number> . <number> material - theme | zhu | <date> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 2 e4cg34 <time> <number> f6dab26 <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> h7j2d46 <time> <number> dsvsc013cf : <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"allow webview context menus triggered by primary click < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i ' d like to be able to use platform native menus in extensions that use a web view . this would allow for more complex controls , such as split buttons and gear menus . currently it ' s possible for extensions to [ provide a context menu ] ( <url> but the menu can only be triggered using a secondary click ( and there ' s no way to hack around this ) . the only way to pop up a native menu is through misusing a ` <select> ` element . however this causes different cross - platform interaction and styling inconsistencies . it would be much better to be able to use a real menu . perhaps an option to the ` data - vscode - context ` attribute could be added . something like ` devicebutton : primary | secondary ` . ` ` ` html < textarea data - vscode - context ='{ "" webviewsection "" : "" editor "" , "" devicebutton "" : "" primary "" , "" preventdefaultcontextmenuitems "" : true } ' > </textarea> ` ` ` it would also be useful to define multiple context menus using names . advantages no need to implement own menus that look out of place ( that can not extend outside the web view area ) - good looking and accessible native menus on every platform - more consistency across the ide - more flexibility for extension authors cc <user> <user>",2
microsoft/vscode,"python bug type : <b> bug </b> hello when i try basics like print ( "" hello ) it open a lot of things in the terminal but not print my hello and after a few seconde visual studio code crash like i cannot click anywhere and i need to close the app by force . vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 6 5 1 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 2 th gen intel ( r ) core ( tm ) i9 - 1 2 9 0 0 kf ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 2 gb ( <number> . 4 0 gb free ) | | process argv | - - crash - reporter - id f2a2bdb6 - bf28 - <number> - aa08 - 0 b9445264d58 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - importmagic | cod | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyonecf : <number> vsc <elongated> : <number> 2 e4cg34 <time> <number> pyind77 <time> <number> f6dab26 <time> <number> vscrp : <number> pythonsymbol <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> a2ce337 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> bgfeh9 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> e537b57 <time> <number> dsvsc013cf : <number> dsvsc0 <time> <number> ` ` ` </details> < - - generated by issue reporter - - > ! [ test py - visual studio code 1 7 _07_2023 1 9 _03_35 ] ( <url>",2
microsoft/vscode,"[ go to reference ] need some jump < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > hello guys , i dont know what i think is a feature or a bug ? what happen to me ? i use c / c + + extension for stm32 c language coding . but when i push the button [ go to reference ] . it do not work , it just show some reference at left by a new tab , do not jump , do not report the error . just show out at the left tab by a new page , so i have to click the new tab page to see what i want . is there a switch for show on reference tab or jump to reference ? i do not want my hands away from keyboard so when i just have to check out some reference . thanks for watch , have a nice day . see yah . btw this is the png for what happen to me",2
microsoft/vscode,"issue in writing react native styles hi , <number> . i saw an issue when writing styles in react native . <number> . i write some inline styling like this < text styles ={ styles . one } > instead of this < text style ={ styles . one } > . * * * i am not able to apply the styles with this < text styles ={ styles . one } > but even i wrote like this it was not give any error . * * * please do something to show some error when we not apply the styles as per the rules in react native . [ vscodeerror . zip ] ( <url>",2
microsoft/vscode,"not working and run in terminal the codes . type : <b> feature request </b> vs code on windows <number> / windows server <number> will soon stop receiving updates . consider upgrading your windows version . vs code version : code <number> . <number> ( 7 4 f6148eb9ea00507ec113ec51c489d6ffb4b771 , <number> - <number> - 1 2 t <time> . 6 5 1 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"install libraries type : <b> bug </b> i just want to install and use some new libraries in vscode ( python ) when i use "" pip install "" in terminal terminal gives me this errors please help me and let me know what i have to do for fix it "" "" "" error : exception : traceback ( most recent call last ) : file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ urllib3 \ \ response . py "" , line <number> , in _error_catcher yield file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ urllib3 \ \ response . py "" , line <number> , in read data = self . _fp_read ( amt ) if not fp_closed else b "" "" ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ urllib3 \ \ response . py "" , line <number> , in _fp_read return self . _fp . read ( amt ) if amt is not none else self . _fp . read ( ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ cachecontrol \ \ filewrapper . py "" , line <number> , in read data = self . __fp . read ( amt ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ http \ \ client . py "" , line <number> , in read s = self . fp . read ( amt ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ socket . py "" , line <number> , in readinto return self . _sock . recv_into ( b ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ ssl . py "" , line <number> , in recv_into return self . read ( nbytes , buffer ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ ssl . py "" , line <number> , in read return self . _sslobj . read ( len , buffer ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ timeouterror : the read operation timed out during handling of the above exception , another exception occurred : traceback ( most recent call last ) : file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ cli \ \ base_command . py "" , line <number> , in exc_logging_wrapper status = run_func ( * args ) ^^^ ^^^ ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ cli \ \ req_command . py "" , line <number> , in wrapper return func ( self , options , args ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ commands \ \ install . py "" , line <number> , in run requirement_set = resolver . resolve ( ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ resolver . py "" , line <number> , in resolve result = self . _result = resolver . resolve ( ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ resolvelib \ \ resolvers . py "" , line <number> , in resolve state = resolution . resolve ( requirements , max_rounds = max_rounds ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ resolvelib \ \ resolvers . py "" , line <number> , in resolve self . _add_to_criteria ( self . state . criteria , r , parent = none ) file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ resolvelib \ \ resolvers . py "" , line <number> , in _add_to_criteria if not criterion . candidates : file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ resolvelib \ \ structs . py "" , line <number> , in __bool__ return bool ( self . _sequence ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ found_candidates . py "" , line <number> , in __bool__ return any ( self ) ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ found_candidates . py "" , line <number> , in <genexpr> return ( c for c in iterator if id ( c ) not in self . _incompatible_ids ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ found_candidates . py "" , line <number> , in _iter_built candidate = func ( ) ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ factory . py "" , line <number> , in _make_candidate_from_link self . _link_candidate_cache [ link ] = linkcandidate ( ^^^ ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ candidates . py "" , line <number> , in __init__ super ( ) . __init__ ( file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ candidates . py "" , line <number> , in __init__ self . dist = self . _prepare ( ) ^^^ ^^^ ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ candidates . py "" , line <number> , in _prepare dist = self . _prepare_distribution ( ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ resolution \ \ resolvelib \ \ candidates . py "" , line <number> , in _prepare_distribution return preparer . prepare_linked_requirement ( self . _ireq , parallel_builds = true ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ operations \ \ prepare . py "" , line <number> , in prepare_linked_requirement return self . _prepare_linked_requirement ( req , parallel_builds ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ operations \ \ prepare . py "" , line <number> , in _prepare_linked_requirement local_file = unpack_url ( ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ operations \ \ prepare . py "" , line <number> , in unpack_url file = get_http_url ( ^^^ ^^^ ^^^ ^^^ ^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ operations \ \ prepare . py "" , line <number> , in get_http_url from_path , content_type = download ( link , temp_dir . path ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ network \ \ download . py "" , line <number> , in __call__ for chunk in chunks : file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ cli \ \ progress_bars . py "" , line <number> , in _rich_progress_bar for chunk in iterable : file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _internal \ \ network \ \ utils . py "" , line <number> , in response_chunks for chunk in response . raw . stream ( file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ urllib3 \ \ response . py "" , line <number> , in stream data = self . read ( amt = amt , decode_content = decode_content ) ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^ file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ urllib3 \ \ response . py "" , line <number> , in read with self . _error_catcher ( <sad> file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ contextlib . py "" , line <number> , in __exit__ self . gen . throw ( typ , value , traceback ) file "" e :\\ software \ \ programing \ \ python \ \ python \ \ lib \ \ site - packages \ \ pip \ \ _vendor \ \ urllib3 \ \ response . py "" , line <number> , in _error_catcher raise readtimeouterror ( self . _pool , none , "" read timed out . "" ) pip . _vendor . urllib3 . exceptions . readtimeouterror : httpsconnectionpool ( host = ' files . pythonhosted . org ' , port = <number> <sad> read timed out . "" thank you vs code version : code <number> . <number> ( 6 6 0 3 9 3 deaaa6d1996740ff4880f1bad43768c814 , <number> - <number> - 0 4 t <time> . 4 0 7 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> 5 5 0 0 u with radeon graphics ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 6 gb ( <number> . 1 1 gb free ) | | process argv | - - crash - reporter - id 4 b693618 - aa7b - 4 6 9 c - <number> - 3 df9104aff72 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - matlab - formatter | aff | <date> matlab - interactive - terminal | apo | <number> . <number> matlab - extension - pack | bat | <number> . <number> matlab - code - run | bra | <number> . <number> code - runner | for | <number> . <number> c - cpp - runner | fra | <number> . <number> matlab | gim | <number> . <number> language - matlab | mat | <number> . <number> csharp | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> ispy | ric | <number> . <number> matlab - complete | sla | <number> . <number> cmake | twx | <date> vscode - lldb | vad | <number> . <number> nbconverter | yig | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vswsl492cf : <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh93 <time> <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 3 biah6 <time> <number> pyind77 <time> <number> <number> <time> <number> pythonsymbol <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> ecj1e33 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> bgfeh9 <time> <number> pythonnosm12tcf : <number> pythonidxpt : <number> pythonnocebcf : <number> e537b57 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"jsdoc <user> tag does not respect line breaks unless two spaces are added at the end of the line < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > does this issue occur when all extensions are disabled ? : yes - vs code version : <number> . <number> - insider - os version : macos <number> . <number> , apple m1 pro i have a question about the ` <user> ` tag in jsdoc comments in vs code . it seems that line breaks within the ` <user> ` tag are not respected unless two spaces are added at the end of the line . i believe this should not be the case , and line breaks should be respected without the need for two spaces at the end of the line . if vs code is not using jsdoc , please inform me of the correct format for line breaks within the ` <user> ` tag . steps to reproduce : <number> . use the latest version of vs code insiders and create a new profile , only changing the theme and ` editor . renderwhitespace ` setting . <number> . write different function comments as shown below . notice that the ` <user> ` content does not respect line breaks unless two spaces are added at the end of the line . ` ` ` js /* * * <user> * example1 : it will no line break . * line <number> . * line <number> . */ const fn1 = ( ) => { } /* * * <user> * example2 : 这将不会换行 。 * 行2 。 * 行3 。 */ const fn2 = ( ) => { } /* * * <user> * example1 : it will line break . * line <number> . * line <number> . */ const fn3 = ( ) => { } /* * * <user> * example2 * 行2 。 * 行3 。 */ const fn4 = ( ) => { } ` ` ` ! [ snipaste_2023 - <number> - 1 3 _16 - <number> - <number> ] ( <url>",2
microsoft/vscode,"ports in codespace < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> ( universal ) - os version : darwin x64 <number> . <number> , macos big sure <number> . <number> steps to reproduce no ports on panel in codespace",2
microsoft/vscode,"unable to resolve resource vscode - remote :// codespaces % 2 bboli8845 - ideal - fiesta - 7 r579g4xprfx57 / workspaces / <number> add issue description here can not load my file as error message says : "" unable to resolve resource vscode - remote :// codespaces % 2 bboli8845 - ideal - fiesta - 7 r579g4xprfx57 / workspaces / <number> "" version : <number> . <number> commit : 6 6 0 3 9 3 deaaa6d1996740ff4880f1bad43768c814 user agent : mozilla / <number> ( macintosh ; intel mac os x 1 0 _15_7 ) applewebkit / <number> ( khtml , like gecko ) chrome / <number> . <number> safari / <number> embedder < - - generated by web issue reporter - - >",2
microsoft/vscode,"how do i recover deleted files ? i accidentally removed my entire project file , is there any way i can recover it ? add issue description here version : <number> . <number> commit : 6 6 0 3 9 3 deaaa6d1996740ff4880f1bad43768c814 user agent : mozilla / <number> (x 1 1 ; linux x86_64 ) applewebkit / <number> ( khtml , like gecko ) chrome / <number> . <number> safari / <number> embedder < - - generated by web issue reporter - - >",2
microsoft/vscode,"repeatedly getting errors launching flutter app in iphone [ error launching application ] does this issue occur when all extensions are disabled ? : yes i just downloaded vscode , and when i run the application on my iphone it is extremely intermittent , it will run on 4 th or 5 th try . on xcode , android studio it will run on first try this is the error ` ` ` launching lib / main . dart on pannam <number> in debug mode . <repeated> automatically signing ios for device deployment using specified development team in xcode project : ftssdsd68a xcode build done . <number> . 5 s could not run build / ios / iphoneos / runner . app on 6 4 7 1 0 b4b6289ef663692fc70dfa0912fdcc7a0ce . try launching xcode and selecting "" product > run "" to fix the problem : open ios / runner . xcworkspace error launching application on pannam <number> . ` ` ` can assist with this . - - > - vs code version : - version : <number> . <number> ( universal ) commit : 6 6 0 3 9 3 deaaa6d1996740ff4880f1bad43768c814 date : <number> - <number> - 0 4 t <time> . 7 6 6 z electron : <date> electronbuildid : <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os : darwin x64 <number> . <number> - os version : - system version : macos <number> . <number> ( 2 1 g651 ) kernel version <number> . <number> mac os monterey",2
microsoft/vscode,"html incompleto type : <b> bug </b> quando vou criar um código com html ele não "" começa "" o código pra mim , tenho que digitar tudo desde o princípio sendo que no outro computador que mexo eu digito apenas html e ele faz todo o começo do código pra mim , como o titulo , o idioma e etc . queria saber o que posso fazer para que o vscode termine o código pra mim . por favor me ajude . <repeated> google translate : > ‎ when i create a code with html it does not "" start "" the code for me , i have to type everything from the beginning being that on the other computer that i move i type only html and it does all the beginning of the code for me , such as the title , the language and etc . i wanted to know what i can do so that vscode finishes the code for me . please help me . <repeated> ‎ vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 3 5 g7 @ <number> . 4 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 8 gb ( <number> . 3 2 gb free ) | | process argv | - - crash - reporter - id 8 c484ca8 - <number> - 4 4 c9 - <number> - 0 3 4 d6b067eb1 | | screen reader | yes | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - django | bat | <number> . <number> vscode - eslint | dba | <number> . <number> python - environment - manager | don | <number> . <number> python - extension - pack | don | <number> . <number> vscode - firefox - debug | fir | <number> . <number> auto - rename - tag | for | <date> copilot | git | <number> . <number> vsc - python - indent | kev | <number> . <number> vscode - docker | ms - | <number> . <number> vscode - language - pack - pt - br | ms - | <number> . <phone> vscode - edge - devtools | ms - | <number> . <number> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> color - highlight | nau | <number> . <number> autodocstring | njp | <number> . <number> open - html - in - browser | pea | <date> java | red | <number> . <number> liveserver | rit | <number> . <number> python | tht | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> vscode - icons | vsc | <number> . <number> jinja | who | <number> . <number> html - css - class - completion | zig | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscoreces : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 3 biah6 <time> <number> pyind77 <time> <number> <number> <time> <number> pythonsymbol <time> <number> a9j8j15 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> pythongtdpath : <number> bgfeh9 <time> <number> pythonnosm12tcf : <number> pythonidxpt : <number> pythonnocebcf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"js reference irrelevant file across open editors < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : win10 steps to reproduce bug ] ( <url> references is correct when only one file is open , but when the sercond one is open , things goes wrong . is there a way to prevent this behavior ?",2
microsoft/vscode,"botbuild type : <b> performance issue </b> it occured when i tried to install an application vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 1 0 7 5 0 h cpu @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 4 gb ( <number> . 1 6 gb free ) | | process argv | - - crash - reporter - id 6 9 e01fc4 - 9 ccd - 4 bb9 - 8 0 b1 - d04d8a4f8fd2 | | screen reader | no | | vm | <percent> | </details> <details> <summary> process info </summary> ` ` ` cpu % mem mb pid process <number> <number> <number> code main <number> <number> <number> window [ <number> ] ( botbuild - visual studio code ) <number> <number> <number> window [ <number> ] ( issue reporter ) <number> <number> <number> crashpad - handler <number> <number> <number> gpu - process <number> <number> <number> extensionhost [ <number> ] <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ jspet \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node c :\\ users \ \ jspet \ \ . vscode \ \ extensions \ \ ms - python . vscode - pylance - <number> . <number> \ \ dist \ \ server . bundle . js - - cancellationreceive = file <sad> 0 2 1 6 1 c352f39d5fe13ccb45f213c121639f255104 - - node - ipc - - clientprocessid = <number> ) <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ jspet \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node "" c :\\ users \ \ jspet \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ resources \ \ app \ \ extensions \ \ json - language - features \ \ server \ \ dist \ \ node \ \ jsonservermain "" - - node - ipc - - clientprocessid = <number> ) <number> <number> <number> electron - nodejs ( "" c :\\ users \ \ jspet \ \ appdata \ \ local \ \ programs \ \ microsoft vs code \ \ code . exe "" - - ms - enable - electron - run - as - node c :\\ users \ \ jspet \ \ . vscode \ \ extensions \ \ formulahendry . auto - rename - tag - <date> \ \ packages \ \ server \ \ dist \ \ servermain . js - - node - ipc - - clientprocessid = <number> ) <number> <number> <number> utility - network - service <number> <number> <number> ptyhost <number> <number> <number> c :\\ windows \ \ system32 \ \ cmd . exe <number> <number> <number> c :\\ windows \ \ system32 \ \ cmd . exe <number> <number> <number> console - window - host ( windows internal process ) <number> <number> <number> console - window - host ( windows internal process ) <number> <number> <number> c :\\ windows \ \ system32 \ \ cmd . exe <number> <number> <number> console - window - host ( windows internal process ) <number> <number> <number> shared - process <number> <number> <number> filewatcher [ <number> ] <number> <number> <number> "" c :\\ program files \ \ google \ \ drive file stream \ \ <number> . <number> \ \ crashpad_handler . exe "" - - database =c :\\ users \ \ jspet \ \ appdata \ \ local \ \ google \ \ drivefs \ \ crashpad - - url = <url> - - annotation = application = code . exe - - annotation = prod = drivefs - - annotation = ver = <number> . <number> - - initial - client - data =0 x1694 , 0 x17bc , 0 x1748 , 0 x14d0 , 0 x145c , 0 x7ffe2a1a7550 , 0 x7ffe2a1a7560 , 0 x7ffe2a1a7570 ` ` ` </details> <details> <summary> workspace info </summary> ` ` ` ; ` ` ` </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - prettier - vscode | esb | <number> . <number> auto - rename - tag | for | <date> fluent - icons | mig | <date> gather | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> liveserver | rit | <number> . <number> vscode - icons | vsc | <number> . <number> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdc : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> pyind77 <time> <number> <number> <time> <number> pythonsymbol <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> 5 7 b7757 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> bgfeh9 <time> <number> pythonnosmt <time> <number> pythonidxpt : <number> pythonnoceb : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"only subset of references of a symbol found unless file from specific directories is opened in editor < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes _the video is recorded with extensions still enabled , however the behavior is identical after launching with no extensions . _ < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > version : <number> . <number> ( user setup ) commit : 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 date : <number> - <number> - 1 4 t <time> . 3 7 9 z electron : <number> . <number> chromium : <number> . <number> node . js : <number> . <number> v8 : <number> . <number> - electron . <number> os : windows_nt x64 <number> . <number> * * expected behavior * * : searching for references of a symbol takes all files in a project into consideration , regardless of whether any particular file is open . * * observed behavior * * : only if particular files are opened does it locate references in all files . it ' s completely unobvious which file this has to be , or why it has this weird requirement . it misses over half of usages . * * steps to reproduce * * ( i do not know which aspect of my folder structure is triggering this , possibly hard to reproduce , but you can follow these steps in the video ) open a file that contains symbols with references throughout many folders <number> . control + click on a symbol to get a popup with the references <number> . note there is a small amount of references that misses most references <number> . open a file from a folder where a missing reference lives <number> . control + click again on the same symbol <number> . note that now it lists all references that were missing , even if they live in another folder than the file that was opened in step <number> . in my case i think ( or hope ) that it now does include everything i am looking for <number> . close the file that was opened in step <number> again <number> . now it again only includes a subset of references <url> the above happens for no apparent reason . i never changed any editor configuration that could reasonably be expected to affect this behavior . nor did i find any configuration that could fix this issue . it ' s definitely unrelated to long paths on windows ( mentioned in similar issues ) , all paths are under <number> characters , well below <number> . likely you can clone [ the repository in question ] ( <url> to reproduce the behavior . * * why is this a problem ? * * the ability to reliably locate symbol usages is part of the core , absolute minimum functionality you ' d expect from an ide . if it misses usages , this can lead to serious real world bugs . it also significantly erodes confidence and slows down work . there is no good reason for it to exclude any file unless specifically configured to do so . and if vscode would , for some reason , not default to looking everywhere , it should be very obvious about this and put a big warning saying that not each directory was considered for a particular search of any kind .",2
microsoft/vscode,"chrome like behaviour when closing tabs , this is so frustrating (⚠️) < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > if a photo worth a thousand words a video worth a million words terrible vs code ux [ screencast from <date> <time> . webm ] ( <url> great google chrome ux [ screencast from <date> <time> . webm ] ( <url> thanks a lot , love your product !",2
microsoft/vscode,". length property not working ? type : <b> bug </b> let numbers = [ <number> , <number> , <number> , <number> ] / / console . log correctly logs numbers array console . log ( numbers . length ) function findbiggestandsmallest ( numbers ) { const biggestsmallest = { } / / typeerror : cannot read properties of undefined ( reading ' length ' ) / / when otherwise should not be an error if ( numbers . length = = = <number> ) { return biggestsmallest } let biggest = numbers [ <number> ] let smallest = numbers [ <number> ] for ( let i = <number> ; i < numbers . length ; i + + ) { if ( numbers [ i ] > biggest ) { biggest = numbers [ i ] } if ( numbers [ i ] < smallest ) { smallest = numbers [ i ] } } biggestsmallest . biggest = biggest biggestsmallest . smallest = smallest return biggestsmallest } vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 1 0 2 1 0 u cpu @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 7 6 gb ( <number> . 1 0 gb free ) | | process argv | - - crash - reporter - id ee8117d4 - 6 3 1 c - 4 0 d4 - b0f9 - 6 bc53f06d153 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - npm - intellisense | chr | <number> . <number> path - intellisense | chr | <number> . <number> vscode - eslint | dba | <number> . <number> code - runner | for | <number> . <number> vscode - versionlens | pfl | <number> . <number> node - pack | swe | <date> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes263cf : <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 3 biah6 <time> <number> pyind77 <time> <number> f6dab26 <time> <number> pythonsymbol <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> 5 7 b7757 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> e440d66 <time> <number> pythonidxptcf : <number> pythondjangots : <number> pythonnocebcf : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"mouse not working at all in terminal + all terminal editor keybinding is occupied by vs code < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : <number> . <number> - os version : windows <number> . steps to reproduce : <number> . open vs code <number> . open new terminal <number> . ssh into a server , for example : ssh username <user> . <number> . <number> ( i was logged into an ubuntu server ) <number> . open some larger config file @ the server . for example : sudo nano . bashrc sudo micro . bashrc # # # the first bug : * * the mouse does not work at all in does editors * * . nor in nano , nor in micro . in different terminal softwares : "" micro editor "" > > uses the mouse with no problem . "" nano editor "" could use the mouse with the - m switch . after two hours of ai chat and google and youtube i could not use the mouse in the terminal . # # # the second bug in nano or micro editor i try to do anything usual ( save , exit , delete a line , copy / paste ) , there is a huge possibility that a vs code keyboard shortcut is conflicting with the nano and or micro editor . - ctrl + k in nano editor to delete a line > > no chance to use it in vs code terminal - ctrl + shift + k in micro editor to delete a line > > does not work in vs code terminal - ctrl + q to exit from micro editor in the terminal > > steps out from the terminal in vs code so you can not close the micro editor vs code look promissing , but without the mouse usage in the terminal it has a "" dos "" system productivity , and with the keybindings conflict , using vs code to ssh is basically impossible thanks i hope you find solution , get back to me if you need help or testing . bence gyulai",2
microsoft/vscode,"will not run code type : <b> bug </b> hi i keep getting the following error when i try to run any code in visual studio code . crbug / <number> , non - js module files deprecated . vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 7 7 0 0 t cpu @ <number> . 9 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 2 gb ( <number> . 7 8 gb free ) | | process argv | - - crash - reporter - id 8 0 a3cc3c - a773 - 4 d91 - <number> - 1 b31dda2242c | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - edge - devtools | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> open - html - in - browser | pea | <date> cors - browser | wsc | <date> </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh93 <time> <number> vshan8 <time> <number> vstes263cf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa59 <time> <number> pythonvs93 <time> <number> py29gd226 <time> <number> vscaat : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 2 8 2 f87 <time> <number> pyind77 <time> <number> <number> <time> <number> pythonsymbol <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> pythongtdpath : <number> bgfeh9 <time> <number> dh2dc7 <time> <number> pythonidxptcf : <number> pythondjangots : <number> pythonnocebcf : <number> ` ` ` </details> < ! - - generated by issue reporter - - >",2
microsoft/vscode,"code actions on save can also be used in a runcommands keybinding < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > i want to be able to run the following commands with a keyboard shortcut _without saving the file_ : - "" source . addmissingimports "" - "" source . fixall "" - "" source . organizeimports "" i tried to do this with a custom runcommands keybinding , but i get error "" command ' source . addmissingimports ' not found "" . ` ` ` { "" command "" : "" runcommands "" , "" key "" : "" alt + s "" , "" args "" : { "" commands "" : [ "" source . addmissingimports "" , "" source . fixall "" , "" source . organizeimports "" ] } , "" when "" } ` ` ` appreciate you all !",2
microsoft/vscode,"terminal type : <b> bug </b> running a c program on using "" gets ( str ) "" but the terminal says its running code and no results displayed <number> the expected results is that the user should be allowed to enter their complete na7mes and the program runs as designed vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) celeron ( r ) n4000 cpu @ <number> . 1 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : disabled_off <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 3 gb ( <number> . 9 4 gb free ) | | process argv || | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - code - runner | for | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools - extension - pack | ms - | <number> . <number> cmake | twx | <date> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vsdfh931cf : <number> vshan8 <time> <number> vstes26 <time> <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 2 e4cg34 <time> <number> pyind77 <time> <number> f6dab26 <time> <number> pythonsymbol <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> showindicator : <number> pythongtdpath : <number> i26e353 <time> <number> gsof <time> <number> e440d66 <time> <number> pythonidxptcf : <number> pythondjangotscf : <number> h7j2d46 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"bug in update . < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : yes / no < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : - os version : ! [ image ] ( <url> steps to reproduce click download update in vscode and get the zip . <number> . upzip the zip in the folder and overlap original files . <number> . it updated successfully and the version became <number> . <number> . <number> . when i rebooted computer , the version reverted to the original version .",2
microsoft/vscode,"cant use my import type : <b> bug </b> like i have use and install openai but is not importing and showing missing import vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | amd ryzen <number> 3 5 0 0 u with radeon vega mobile gfx ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 9 5 gb ( <number> . 5 7 gb free ) | | process argv | - - crash - reporter - id a751a3b7 - cf5a - 4 f61 - ab08 - 0 4 c382dc8d34 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - vscode - openapi | 4 2 c | <number> . <number> android - dev - ext | ade | <number> . <number> vscode - django | bat | <number> . <number> simple - react - snippets | bur | <number> . <number> npm - intellisense | chr | <number> . <number> doxdocgen | csc | <number> . <number> dart - code | dar | <number> . <number> flutter | dar | <number> . <number> vscode - eslint | dba | <number> . <number> emulate | die | <number> . <number> python - environment - manager | don | <number> . <number> python - extension - pack | don | <number> . <number> gitlens | eam | <number> . <number> vscode - html - css | ecm | <number> . <number> vscode - npm - script | eg2 | <date> react - native - react - redux | equ | <number> . <number> prettier - vscode | esb | <number> . <number> vscode - firefox - debug | fir | <number> . <number> code - runner | for | <number> . <number> copilot | git | <number> . <number> pyformat | giy | <number> . <number> open - url | gru | <number> . <number> better - cpp - syntax | jef | <number> . <number> vscode - insertdatestring | jsy | <number> . <number> solidity | jua | <date> vsc - python - indent | kev | <number> . <number> csharpextensions | kre | <number> . <number> bash - ide - vscode | mad | <number> . <number> fluent - icons | mig | <date> vscode - docker | ms - | <number> . <number> csharp | ms - | <number> . <number> vscode - kubernetes - tools | ms - | <date> playwright | ms - | <date> isort | ms - | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> js - debug - nightly | ms - | <number> . <number> powershell | ms - | <number> . <number> vscode - react - native | msj | <number> . <number> awesome - flutter - snippets | nas | <number> . <number> autodocstring | njp | <number> . <number> material - icon - theme | pki | <number> . <number> vscode - rapidapi - client | rap | <number> . <number> vscode - services | rap | <number> . <number> vscode - yaml | red | <number> . <number> liveserver | rit | <number> . <number> tabnine - vscode | tab | <date> python | tht | <number> . <number> cmake | twx | <date> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> vscode - icons | vsc | <number> . <number> jinja | who | <number> . <number> commandlist | yam | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr242cf : <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod8 <time> <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd226 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc0 <time> <number> pynewext5 <time> <number> azure - dev_surveyone : <number> 3 biah6 <time> <number> pyind77 <time> <number> <number> <time> <number> pythonsymbol <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixshowwlkth : <number> hideindicator : <number> pythongtdpath : <number> gsof <time> <number> dh2dc7 <time> <number> pythonidxptcf : <number> pythondjangots : <number> e537b57 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"environment variables in % path % are not expanded type : <b> bug </b> > this issue seems to be a duplicate of # <number> , but since that was closed and i had some more info i could not add , i created this one . # # # summary i have some environment variables set to some directories , and they are used in my % path % variable ( system space , not user ) and they are not getting expanded in the integrated terminal . if i type ` echo % path % ` i see the variables unexpanded , instead of the directories they point to ( here ' s the output ) : ` ` ` c :\\ program files (x 8 6 ) \ \ intel \ \ intel ( r ) management engine components \ \ icls \ \ ;c :\\ program files \ \ intel \ \ intel ( r ) management engine components \ \ icls \ \; % systemroot %\\ system32 ; % systemroot % ; % systemroot %\\ system32 \ \ wbem ; % systemroot %\\ system32 \ \ windowspowershell \ \ v1 . <number> \\; % systemroot %\\ system32 \ \ openssh \ \ ;c :\\ program files \ \ dotnet \ \ ;c :\\ program files (x 8 6 ) \ \ bitvise ssh client ;c :\\ program files \ \ git \ \ cmd ;c :\\ program files (x 8 6 ) \ \ intel \ \ intel ( r ) management engine components \ \ dal ;c :\\ program files \ \ intel \ \ intel ( r ) management engine components \ \ dal ;c :\\ program files (x 8 6 ) \ \ intel \ \ intel ( r ) management engine components \ \ ipt ;c :\\ program files \ \ intel \ \ intel ( r ) management engine components \ \ ipt ; % path_progs % ;c :\\ program files \ \ putty \ \; % arina_cli_dir % ; a <annoyed> prog / dev / rust / win / cargohome \ \ bin ;c :\\ users \ \ dante \ \ appdata \ \ local \ \ microsoft \ \ windowsapps ;c :\\ users \ \ dante \ \ . dotnet \ \ tools ; ` ` ` but variables in user space ( everything after ` a <annoyed> prog / dev / rust / win / cargohome \ \ bin ` above ) are expanded , here is their unexpanded version from system settings : ` ` ` % userprofile %\\ appdata \ \ local \ \ microsoft \ \ windowsapps ; % userprofile %\\ . dotnet \ \ tools ; ` ` ` # # # workaround seeing this behavior i tried running vscode as administrator , and this time the variables are correctly expanded . # # # info vs code version : code <number> . <number> ( b380da4ef1ee00e224a15c1d4d9793e27c2b6302 , <number> - <number> - 0 7 t <time> . 5 5 2 z ) ( portable ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i7 - 8 5 5 0 u cpu @ <number> . 8 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 8 gb ( <number> . 1 1 gb free ) | | process argv | - - crash - reporter - id ea812d11 - 4 c3b - 4 1 3 a - b4b7 - c326d9aa68d1 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - git - graph | mhu | <number> . <number> csharp | ms - | <number> . <number> remote - ssh | ms - | <number> . <number> remote - ssh - edit | ms - | <number> . <number> hexeditor | ms - | <date> remote - explorer | ms - | <number> . <number> vscode - open | san | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv36 <time> <number> vsreu68 <time> <number> python383cf : <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscorecescf : <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> py29gd2263cf : <number> vsclangdc : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyone : <number> vsc <elongated> : <number> 3 biah6 <time> <number> pyind77 <time> <number> f6dab26 <time> <number> pythonsymbol <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> 0 3 d3595 <time> <number> pythonfmttext : <number> pythoncmv : <number> fixshowwlkth : <number> hideindicator : <number> pythongtdpath : <number> e440d66 <time> <number> pythonidxptcf : <number> pythondjangotscf : <number> pythonnoceb : <number> e537b57 <time> <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"how to automatically guide users to upgrade from one vscode extension to another ? hi , i am seeking advice on an issue related to vscode themes . previously , i published a theme called luke - dark - theme , and recently , i released a new theme called photonica . photonica is intended to be a direct upgrade from luke - dark - theme . i am wondering if there is a way to facilitate users who have installed luke - dark - theme to easily or automatically upgrade to the new photonica theme . how can i do this ? thank you in advance",2
microsoft/vscode,"active tab in vs code is not very clear type : <b> bug </b> vs code is great , but there is one bad thing about it annoys me too much . "" active tab "" in vs code in not very clear to detect . either i code or when i see video course , it is very hard for me to detect active tab in first glance in fact , active tab is lost between different colors of tabs ( because of git property for changed files , new files , etc ) . i suggest that , show active tab in vs code with "" bordered thick blue color "" . please , fix this . vs code version : code <number> . <number> ( b3e4e68a0bc097f0ae7907b217c1119af9e03435 , <number> - <number> - 1 0 t <time> . 2 4 8 z ) os version : windows_nt x64 <number> . <number> modes : sandboxed < ! - - generated by issue reporter - - >",2
microsoft/vscode,"the facility for exposing default settings launch . json < - - ⚠️ ⚠️ do not delete this ! feature_request_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - please search existing issues to avoid creating duplicates . - - > < ! - - describe the feature you ' d like . - - > the official documentation for vs code ' s built - in debugger does not provide comprehensive detail on the attributes exposed by intellisense for launch . json . for example , showasyncstacks is a boolean , for which no default is indicated . neither symbols nor settings expose its value . for example , intellisense does not expose an ` address ` attribute , contrary to the ' official ' documentation , which asserts that remote debugging is baked into vs code , and is specified with the ` address ` attribute . without a facility to expose internals , it ' s difficult to know if this was simply an oversight in the preparation of the intellisence database , or if vs code does not recognize an ` address ` attribute , if included in launch . json . intellisense exposes the following <number> attributes : args , attachsimpleport , autoattachchildprocesses , cascadeterminatetoconfigurations , console , customdescriptiongenerator , custompropertiesgenerator , debugserver , enablecontentvalidation , enableturbosourcemaps , env , envfile , internalconsoleoptions , killbehavior , linus , localroot , name , nodeversionhint , osx , outfiles , outputcapture , pauseforsourcemap , postdegugtask , prelaunchtask , presentation , profilestartup , program , remotesroot , request , resolvesourcemaplocations , restart , runtimeargs , runtimeexecutable , runtimesourcemappausepatterns , runtimeversion , serverreadyaction , showasyncstacks , skipfiles , smartstep , sourcemappathoverrides , sourcemaprenames , sourcemaps , supressmultiplesessionwarning , timeout , timeouts , trace , type , windows btw , the attribute , runtimeargs , appears to be misnamed for its intended purpose include command - line arguments . runtimeargs has the same symantics as args ( args are passed at runtime ) . ` commandoptions ` would be more appropriate . - mda <email>",2
microsoft/vscode,"background theme type : <b> bug </b> my usual theme would be the "" shade of purple "" and this allow the background of the vscode theme to turn purple . the problem is when i want to change the theme , only code color that change but not the background . this make my report progression slow as i need to screenshot and print the report and i dont like the pruple background and want to change it to another theme . could u help to solve this issues thanks sincerely , mrkiko vs code version : code <number> . <number> ( 6 9 5 af097c7bd098fbf017ce3ac85e09bbc5dda06 , <number> - <number> - 1 4 t <time> . 3 7 9 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | intel ( r ) core ( tm ) i5 - 8 2 6 5 u cpu @ <number> . 6 0 ghz ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 8 5 gb ( <number> . 1 4 gb free ) | | process argv | - - crash - reporter - id acb7f439 - <number> - 4 d71 - 8 f63 - 6 8 0 3 f8ec56e2 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - html - snippets | abu | <number> . <number> codesnap | adp | <number> . <number> vscode - sqlite | ale | <number> . <number> flutter - snippets | ale | <number> . <number> jar - builder | asl | <number> . <number> code - gnu - global | aus | <number> . <number> phpserver | bra | <number> . <number> java - run | cao | <number> . <number> coddx - alpha | cod | <number> . <number> doxdocgen | csc | <number> . <number> c - cpp - compile - run | dan | <date> dart - code | dar | <number> . <number> flutter | dar | <number> . <number> composer - php - vscode | dev | <number> . <number> phptools - vscode | dev | <number> . <number> githistory | don | <date> javadebugger | don | <number> . <number> vscode - html - css | ecm | <number> . <number> auto - close - tag | for | <date> auto - complete - tag | for | <number> . <number> auto - rename - tag | for | <date> html - preview - vscode | geo | <number> . <number> vscode - javac | geo | <date> html - snippets | gey | <number> . <number> remotehub | git | <number> . <number> vscode - pull - request - github | git | <number> . <number> jason - vscode - pack | jas | <number> . <number> elixir - ls | jas | <date> better - cpp - syntax | jef | <number> . <number> subway - surfers | jir | <number> . <number> flutter - tree | mar | <number> . <number> vscode - html - format | moh | <number> . <number> vscode - dotnet - runtime | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> remote - containers | ms - | <number> . <number> remote - wsl | ms - | <number> . <number> azure - repos | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> remote - repositories | ms - | <number> . <number> vsliveshare | ms - | <number> . <number> sqltools | mtx | <number> . <number> awesome - flutter - snippets | nas | <number> . <number> reload | nat | <number> . <number> material - icon - theme | pki | <number> . <number> java | red | <number> . <number> format - html - in - php | rif | <number> . <number> liveserver | rit | <number> . <number> html5 - boilerplate | sid | <number> . <number> cmake | twx | <date> lorem - ipsum | tyr | <number> . <number> intellicode - api - usage - examples | vis | <number> . <number> vscodeintellicode | vis | <date> vscode - java - debug | vsc | <number> . <number> vscode - java - dependency | vsc | <number> . <number> vscode - java - pack | vsc | <date> vscode - java - test | vsc | <number> . <number> vscode - maven | vsc | <number> . <number> codetour | vsl | <date> javascriptsnippets | xab | <number> . <number> php - debug | xde | <number> . <number> php - pack | xde | <number> . <number> php - intellisense | zob | <number> . <number> ( <number> theme extensions excluded ) </details> <details> <summary> a / b experiments </summary> ` ` ` vsliv368cf : <number> vsreu68 <time> <number> python38 <time> <number> vspor87 <time> <number> vspor7 <time> <number> vspor36 <time> <number> vstes6 <time> <number> vslsvsres3 <time> <number> vserr24 <time> <number> pythontb : <number> vsjup5 <time> <number> pythonptprofiler : <number> vshan8 <time> <number> vstes26 <time> <number> vscod805cf : <number> binariesv6 <time> <number> bridge07 <time> <number> bridge07 <time> <number> vsaa593cf : <number> pythonvs93 <time> <number> vsclangdf : <number> c4g489 <time> <number> dsvsc012cf : <number> pynewext5 <time> <number> azure - dev_surveyonecf : <number> 3 biah6 <time> <number> pyind77 <time> <number> <number> <time> <number> pythonsymbol <time> <number> 2 i9eh26 <time> <number> showlangstatbar : <number> vsctsb : <number> pythonms3 <time> <number> a2ce337 <time> <number> <number> <time> <number> pythonfmttext : <number> pythoncmvfstrcf : <number> fixhidewlkth : <number> showindicator : <number> pythongtdpath : <number> dh2dc7 <time> <number> pythondjangots : <number> ` ` ` </details> < - - generated by issue reporter - - >",2
microsoft/vscode,"issue with esc key mapping and copilot < - - ⚠️ ⚠️ do not delete this ! bug_report_template ⚠️ ⚠️ - - > < ! - - please read our rules of conduct : <url> - - > < ! - - 🕮 read our guide about submitting issues : <url> - - > < ! - - 🔎 search existing issues to avoid creating duplicates . - - > < ! - - 🧪 test using the latest insiders build to see if your issue has already been fixed : <url> - - > < ! - - 💡 instead of creating your report here , use ' report issue ' from the ' help ' menu in vs code to pre - fill useful information . - - > < ! - - 🔧 launch with ` code - - disable - extensions ` to check . - - > does this issue occur when all extensions are disabled ? : no , copilot issue < ! - - 🪓 if you answered no above , use ' help : start extension bisect ' from command palette to try to identify the cause . - - > < ! - - 📣 issues caused by an extension need to be reported directly to the extension publisher . the ' help > report issue ' dialog can assist with this . - - > - vs code version : version : <number> . <number> - commit : 4 cb974a7aed77a74c7813bdccd99ee0d04901215 - os version : macos ventura <number> steps to reproduce : <number> . create two cursors <number> . start typing until copilot suggests something . <number> . press esc . desired behavior : suggestion goes away and <emphasis> my cursors reset to one cursor . actual behavior : suggestion goes away i still have multiple cursors . details : while the multi - cursor example will show you the behavior without any extensions besides copilot , the real issue here is when using ` escape ` as a keybind for anything . if the copilot suggestion is shown , the ` escape ` keybind is not populated down to the rest of the features that want it . this is a huge issue for vscodevim . i tried looking for a way to rebind the "" cancel copilot suggestion "" action , but could not find a relevant action that worked . i was certain it was going to be ` editor . action . inlinesuggest . hide ` , setting the following in my keybinds did not unbind ` escape ` from hiding copilot suggestions : ` ` ` { "" key "" : "" escape "" , "" command "" : "" - editor . action . inlinesuggest . hide "" , "" when "" } , ` ` ` i have no data to back this up , but i am fairly certain this is new - ish behavior because my vim muscle memory for hitting the esc key has me stumbling all over the place recently as i have been having to hit esc esc to go back to normal mode .",2
microsoft/vscode,"can not launch vs code from linux terminal : symbol lookup error : . <repeated> , undefined symbol : gbm_bo_map type : <b> bug </b> <number> . ~ $ : code <number> . symbol lookup error : / usr / share / code - insiders / bin / . <repeated> / code - insiders : undefined symbol : gbm_bo_map vs code version : code - insiders <number> . <number> - insider ( 6 5 4 5 c4c2671127c323182225963fcd732e1fbcc5 , <number> - <number> - 1 5 t <time> . 7 2 0 z ) os version : windows_nt x64 <number> . <number> modes generated by issue reporter - - >",2
microsoft/vscode,"opening a file replaces another open file type : <b> bug </b> open a text file ( source code , . txt , . sh ) , then open another . i expect to have two files open in different tabs . sometimes , only the second is open . it has replaced the first . i have not found a pattern for when this happens , except that the disappearing file is never dirty . vs code version : code <number> . <number> ( 4 cb974a7aed77a74c7813bdccd99ee0d04901215 , <number> - <number> - 1 2 t <time> . 1 0 2 z ) os version : windows_nt x64 <number> . <number> modes : <details> <summary> system info </summary> | item | value | | - - - | - - - | | cpus | 1 2 th gen intel ( r ) core ( tm ) i5 - 1 2 3 5 u ( <number> x <number> )| | gpu status | 2 d_canvas : enabled <br> canvas_oop_rasterization : disabled_off <br> direct_rendering_display_compositor : disabled_off_ok <br> gpu_compositing : enabled <br> multiple_raster_threads : enabled_on <br> opengl : enabled_on <br> rasterization : enabled <br> raw_draw : disabled_off_ok <br> video_decode : enabled <br> video_encode : enabled <br> vulkan : disabled_off <br> webgl : enabled <br> webgl2 : enabled <br> webgpu | load ( avg ) | undefined | | memory ( system ) | <number> . 6 9 gb ( <number> . 4 0 gb free ) | | process argv | - - crash - reporter - id 1 8 5 8 a141 - bb01 - 4 2 e0 - bcd1 - 7 0 cad9e543e3 | | screen reader | no | | vm | <percent> | </details> <details> <summary> extensions ( <number> ) </summary> extension | author ( truncated ) | version - - - | - - - | - - - git - graph | mhu | <number> . <number> python | ms - | <number> . <number> vscode - pylance | ms - | <number> . <number> jupyter | ms - | <number> . <phone> jupyter - keymap | ms - | <number> . <number> jupyter - renderers | ms - | <date> vscode - jupyter - cell - tags | ms - | <number> . <number> vscode - jupyter - slideshow | ms - | <number> . <number> cmake - tools | ms - | <date> cpptools | ms - | <number> . <number> cpptools - extension - pack | ms - | <number> . <number> cmake | twx | <date> ( <number> theme extensions excluded ) </details> < - - generated by issue reporter - - >",2
bitcoin/bitcoin,<hashtag> f </hashtag> #,1
bitcoin/bitcoin,"additional bitcoin - qt capability to mine regtest blocks # # # please describe the feature you ' d like to see added . able to mine blocks through the bitcoin - qt while in regtest mode . # # # is your feature related to a problem , if so please describe it . feature addresses none ideal ux with bitcoin - qt and mining regtest blocks . currently if you want to use the console of bitcoin - qt you would need to close this out and then use ` bitcoin - cli ` separately to mine blocks . when running bitcoin - qt in regtest mode it ' s clear by seeing a blue bitcoin logo instead of the orange one . < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> however , there is no way to thoroughly test some capabilities without having the ability to mine blocks . # # # describe the solution you ' d like bitcoin - qt is able to use ` generate ` or ` - generate ` flag similar to what ` bitcoin - cli ` can do . currently if you run ` generate ` the response is has been replaced by the - generate cli option . refer to - help for more information . ( code - <number> ) ` ` ` # # # describe any alternatives you have considered having bitcoin - cli shipped with all binaries on bitcoincore . org . # # # please leave any additional context low priority",1
bitcoin/bitcoin,"easy loading custom blockchains # # # please describe the feature you ' d like to see added . running custom coins ( genesis ) / configs could be easier to maintain if the source code was built for it rather than forking from it with no idea how to update the forks . # # # is your feature related to a problem , if so please describe it . once forked and modified its hard to maintain ( stay uptodate ) to existing bitcoin source tree automatically # # # describe the solution you ' d like put custom coin genesis loading / generation into the main branch so its easier to maintain coins . # # # describe any alternatives you have considered _no response_ # # # please leave any additional context _no response_",1
bitcoin/bitcoin,"an option for a shell command that runs just before bitcoind completes shutting down . # # # please describe the feature you ' d like to see added . it basically works similar to the blocknotify config option which runs a shell script when a block is mined , but the purpose of this new option is different . it can be called something like "" shutdowncomplete "" and a shell command is passed to it as an argument , which then runs just before the following message is printed in debug . log : ` ` ` <number> - <number> - 2 6 t <time> z shutdown : done ` ` ` it can be ran utilizing a function such as ` runcommand ` . the reason such an option will be useful is to support automatic updates of bitcoin core to newer version . some 3 rd - party program used for detecting new bitcoin core releases on bitcoincore . org , downloading / verifying them , installing them to / usr / local or wherever the user - specified path is or alternatively running an installer , needs to be able to stop bitcoin core first and know when the process is about to quit so that it can proceed with installing ( following which it simply runs the new version of bitcoin daemon and exits ) . currently this can be done by detecting the bitcoind process , but it ' s not portable across multiple operating systems , which all have wildly different process apis . # # # is your feature related to a problem , if so please describe it . the problem is can bitcoin core make it easier to create external programs for automatically updating installations to the newest version ? # # # describe the solution you ' d like as specified above , a command - line & config option for running a shell script right before shutdown is the solution for facilitating automatic updates of bitcoin core ( similar to stuff like livepatch and k - splice for the linux kernel ) . # # # describe any alternatives you have considered as noted , the bitcoind process can be detected in the running process lists , but this can cause a deadlock inside applications if bitcoin core takes a long time to shut down ( eg . a network thread takes too long to exit ) . # # # please leave any additional context none .",1
bitcoin/bitcoin,"optimization : utilize <percent> resources of a computer in long operations like rescan / initial block download # # # please describe the feature you ' d like to see added . as a user , i want bitcoin core to utilize maximum resources ( cpu , network bandwith , memory ) so that intensive operations are perfomed faster ( take shorter time ) , e . g . rescan after importing a key to a wallet opened in a pruned node . # # # is your feature related to a problem , if so please describe it . there is the problem that intensive operations take long while computer resources are not utilized in full : - cpu utilization never exceeds <percent> , - bandwith utilization rarely exceed a few mb ( approx . <number> - <percent> of capacity , wired ) , - ram < <percent> , - disk ( ssd ) rarely exceeds a few %. the computer specification : [ cpu ] 1 1 th gen intel ( r ) core ( tm ) i5 - 1 1 4 0 0 h @ <number> . 7 0 ghz base speed : <number> ghz sockets : <number> cores : <number> logical processors : <number> virtualization : enabled l1 cache : <number> kb l2 cache : <number> mb l3 cache : <number> mb [ ram ] <number> gb speed : <number> mhz slots used : <number> of <number> form factor : sodimm hardware reserved : <number> mb [ ssd ] nvme micron <number> nvme 5 1 2 gb capacity : <number> gb formatted : <number> gb system disk : yes page file : yes type [ connectivity ] 1 gb ethernet , <number> mbit internet bandwith . [ software ] windows <number> , offical build of bitcoin core <number> ( altough the same concerns the older versions ) , default configuration ( e . g . block storage pruned to 2 gb ) . # # # describe the solution you ' d like _no response_ # # # describe any alternatives you have considered _no response_ # # # please leave any additional context there is <percent> cpu utilization when prime95 stress test is run on the machine .",1
bitcoin/bitcoin,"bitcoin ' s relay fee refactoring # # # please describe the feature you ' d like to see added . it would be great to refactor the bitcoin relay fee in a way that would benefit full nodes operators # # # is your feature related to a problem , if so please describe it . since btc is getting bigger and bigger , the incentive to run a full bitcoin node is just ridiculous . data storage cost a lot , and laptop manufacturers does not give a damn about it . # # # describe the solution you ' d like it would be nice to reward full nodes with a few satoshis , 5 k sat would be a good start . # # # describe any alternatives you have considered a good alternative would be to take parts of the miner ' s fees and spread them across the nodes who relayed transactions . # # # please leave any additional context i think there is a way to make it fair for everyone , and i know this was discussed for a while , but it would be good to have an update about this anyways . maybe there is something to be done through lightning ? <repeated> i would love to run a full btc node with txindex and all , but god damn it it is too expencive",1
bitcoin/bitcoin,"depriortisetransaction # # # please describe the feature you ' d like to see added . let me know if this is a wanted change and i can work on it but , if a user had already prioritized a transaction to be mined there would be no way to get it deprioritized until after this pr <url> which adds a new rpc call to getpriotisationmap . there should be a way to remove the prioritization entirely and set it to zero without calling two separate rpcs . # # # is your feature related to a problem , if so please describe it . if a miner wants to deprioritize a transaction then they need to call two rpc methods instead of just one which would simplify things # # # describe the solution you ' d like add new rpc deprioritisetransaction ( txid ) this will set the delta to <number> and remove the txid from the delta map # # # describe any alternatives you have considered change prioritisetransaction ( txid , <number> , fee_delta = <number> ) ( may cause breakage ) where if fee_delta = <number> then we set the delta to zero instead of modifying it <number> or add new param prioritisetransaction ( txid , <number> , fee_delta ( optional ) , hardset_delta ( optional ) ) where now fee_delta and hardset_delta are both optional but at least one is needed # # # please leave any additional context this idea mentioned here towards the end in pr review club <url> related pr <url>",1
bitcoin/bitcoin,"script verification being run when rebuilding utxo database . it seems that script verification is being run during the rebuilding of the utxo database , which , if the intention is simply to rebuild the utxo ( due to a disk corruption ) then this ought to be unnecessary given the verification has already occurred . gpt - <number> suggested a simple code - change , although it ' s a little more complex than this as it needs to ensure that the script verification is only skipped on blocks we can be sure have previously been checked . gpt - <number> ' s suggestion nevertheless ( i love how it ' s familiar with the project ' s code though )",1
bitcoin/bitcoin,"provide optional rpc parameter to not scramble sendmany transactions # # # please describe the feature you ' d like to see added . passed bitcoin core <number> . x the order of sendmany transactions is scrambled via rpc command forcing projects that utilizing the order of transactions to use older wallets . # # # is your feature related to a problem , if so please describe it . _no response_ # # # describe the solution you ' d like add an optional parameter to the sendmany rpc command that allows for the sendmany transaction to work as it did before . giving the option to scramble or not to scramble the order of a sendmany transaction back to bitcoin users . # # # describe any alternatives you have considered _no response_ # # # please leave any additional context _no response_",1
bitcoin/bitcoin,"add parallelism for downloading the blockchain please add parallelism ( at least , multithreading ; multithreading + some kind of clustering are better ) for downloading blockchain by client / wallet ( required by ` getblocktemplate ` ) . * * the speed of downloading the blockchain of bitcoin is very slow , so much time is required , it ' s absolutely awful . and the further , the worse . * * as i can understand , it happens because of nature of blockchain processing client must check block n contents ( transactions ) , then it can proceed to check of block n + <number> . but we can behave like modern cpus branch predictors . why not ? just pretend block n is correct for thread m and let thread m + <number> check block n + <number> . then let thread m + <number> pass necessary information to thread m + <number> for checking block n + <number> . and so on . so all threads can check it ' s blocks , doing cpus utilization . threads can be reused as they become free . just break processing at some points and do rollback , if some previous blocks ( n , n + <number> , . <repeated> ) gets corrupted . as far i can see by cpus usage , bitcoin core / wallet does not behave like that . my internet connection is not such slow and unstable ; i once experimented with connection limit options , it did not work for me . the behavior i suggest has some performance risk , so it can be explicitly controlled by the user with launch option [ s ] ( command line , . <repeated> ) . <details> <summary> a little spoiler ;)</ summary > it would not be a problem at all , if the user could just download the blockchain ( full or pruned ) from some popular ( so popular to be found ) websites he trust . ( i aware about the security considerations , but this is not a issue if the user just wants to try mining or something . ) </details>",1
bitcoin/bitcoin,"full support for spending untrusted unconfirmed outputs spending untrusted unconfirmed outputs should be supported and robust . key feature : <number> . calculation of the appropriate fee based upon the transaction package . <number> . when a dependent transaction is modified , ( for example rbf increase ) , the dependent transaction should be updated appropriately . users can optionally automate this process , and keep the appropriate signing keys online until the transaction package confirms ( as this involves decreasing the transaction fee as the dependent transaction has been replaced with a larger fee version ) . <number> . when a conflicting unconfirmed - transaction package gets a higher fee , the user should be able to compare the transactions , and provided an option to increase the fee , change the funding inputs , or abandon the transaction all - together . <number> . when the unconfirmed input goes out - of - scope ( a conflicting transaction is confirmed in it ' s place ) , the dependent transactions should become "" unfunded "" and the user will need to select new inputs to fund the transaction , or abandon it . new concepts : unfunded , partiality , and fully funded transactions , and supporting the lifecycle between these states . related issues : [ policy rbf descendant carveout whenever conflicts exist , # <number> ] ( <url> [ enable cpfp via gui # <number> ] ( <url> [ coin controll for unconfirmed outputs # <number> ] ( <url>",1
bitcoin/bitcoin,"bitcoin core full node with s3 bucket * * is your feature request related to a problem ? please describe . * * i am trying to run a bitcoin full node on a aws ec2 instance . the problem is when allocating ssd , the cost is too much . the cost for s3 storage is really low . since bitcoin total block chain size is increasing every day it is better if we can use these kind of services . as i understand frequency for a full node to get the old data is relatively low . * * describe the solution you ' d like * * i suggest , we should be able to configure how we store the blocks . one possible way is storing the data and fetching the data using rest calls . in this approach bitcoin core will not worry about how blocks are stored and where . whenever it gets a new block it will invoke a post http call to the confgured url and save it . whenever it needs a old block data it will do a get call to the server using the configured url . this way individuals can develop their own version of servers that will use different type of storage services . the rest approach is just a suggestion we can implement anything that let us configure to use different type of storage mechanisms . one of the main argument against bitcoin is of the growing blockchain size it will become impossible to run a full node by an average individual . with this kind of feature we can use very cost effective solutions for data storage .",1
bitcoin/bitcoin,"add configuration option that will allow for setting the upper bound on transaction size for relaying the recent events , where people store big data on the blockchain in the witness ( like images ) showed that the dispute about this topic was not settled during op_return discussion . some people like the idea that every payed transaction is not a spam , some do not . i suggest that users could set the transaction size limit in the configuration file that will make node drop transactions from the memory pool that are larger . this way node operators would decide what kind of transactions gets relayed via their node . alternatively this limit could be on the consensus layer , but i do not think it is a good idea . if i would get some help , i can try to implement this feature ( no guarantee of success , because i do not know the bitcoin core codebase yet , however i have some experience in programming ) .",1
bitcoin/bitcoin,"summary of bitcoin core improvements scalability : bitcoin ' s current architecture has scalability limitations , and efforts should be made to improve its ability to process a large number of transactions per second . privacy : while bitcoin is pseudonymic , it can still be traceable . improving privacy could involve implementing privacy - enhancing technologies like coinjoin or zero - knowledge proofs . interoperability : making it easier for different bitcoin - based systems to interact with each other could help to foster innovation and adoption . security : the code should be continuously audited and improved to prevent potential security vulnerabilities . usability the user experience could involve making the software easier to use , speeding up confirmation times , or simplifying the process of setting up a full node .",1
bitcoin/bitcoin,"ci containerfiles ? containerfiles have the advantage that they can be cached locally , so for example an ` apt ` operation in an image layer is faster to retrieve from the ( local ) cache than to run vanilla . converting the ci system to those is non - trivial , because it uses a lot of env vars , different configs , and numerous per - config hacks . my understanding of docker is limited , but to pass env vars into a containerfile would require using ` arg ` in the file , as well as code to pass in the arg at runtime via the command line . for hundreds of args , this should be possible , but verbose , which is why i have not looked at it yet .",1
bitcoin/bitcoin,. * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - >,1
bitcoin/bitcoin,"bring back the zap ( zaptransaction rpc ) it can be useful to completely remove a transaction from a wallet rather than just abandon it . see e . g . # <number> . the original ` - zapwallettxes ` startup option was removed in # <number> . it was perhaps overkill , but a simple ` zaptransaction ` rpc would be nice .",1
bitcoin/bitcoin,"keep seed phrase / mnemonic on cold encrypted * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > it is not safe to keep the seed phrase or private keys on the computer or smartphones . * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > need to have an option to user save the seed phrase or private keys encripted on nfc card or usb device , like a cold wallet integrated with bitcoin core . so every time user wants to withdraw bitcoin , need to have the usb "" pendrive "" connected on pc or tap the nfc card . * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > i have checked and there is another wallets using this solution . * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - > i already have this working without integration with bitcoin core .",1
bitcoin/bitcoin,"creat code example with python to send bitcoin ( bc1 - p2wpkh / bech32 ) hi i am looking for someone who could make me a python code example with which i can send bitcoin with python from a "" bc1 "" address to another "" bc1 "" address . ( bc1 = p2wpkh / bech32 e . g . address example ( last <number> characters removed for safety )",1
bitcoin/bitcoin,"no surprise rescan for importprivkey newbie * * is your feature request related to a problem ? please describe . * * calling importprivkey ( <number> ) triggers rescan . rescan of long chains using bad and old equipment takes many days . * * describe the solution you ' d like * * reject importprivkey ( <number> ) completely . deprecate in release i , disable in release i + <number> ( prompting user to use importprivkey ( <number> ) or importprivkey ( <number> ) ) , remove in release i + <number> . * * describe alternatives you have considered * * make the program so it knows that equipment is old and chain is long , then estimate rescan is large , if so rejecting importprivkey ( <number> ) unless confirmed yes when prompted . * * additional context * * tba .",1
bitcoin/bitcoin,"it is possible bitcoin core be rewarded ? theoretically , a reward for running a full node can be useful to the network . possibly more people will join efforts and the the network will become stronger . run a full node <number> hours and <number> days per week , can be expensive ( price of electricity , internet and computer available ) . why not reward the fullnoders whit sats ?",1
bitcoin/bitcoin,"[ brainstorm ] policies for default ` minrelaytxfee ` as experiment for a release * * is your feature request related to a problem ? please describe . * * some users have been curious about a lower minimum fee rate . a recent thread on mailing list : <url> * * describe the solution you ' d like * * a new config option that changes the default minrelaytxfee to one of these for a minor release after v24 . <number> : <number> . odd / even : <number> sat / vb on odd dates and <number> sat / vb on even dates . <number> . market : <number> sat / vb during us market open hours else <number> sat / vb . <number> . interval : starts with <number> sat / vb and keep changing after defined time interval * * describe alternatives you have considered * * if enough users and miners agree to experiment this could be done without making changes in bitcoin core . since most of the nodes use default it ' s difficult to experiment and know if one of these policies increase revenue for miners , provides better fee rates etc . - - - a related tweet thread",1
bitcoin/bitcoin,"miniscript support for decodescript current behavior : ` ` ` src / bitcoin - cli - signet decodescript 2 1 0 3 d3b9c8cc852f3b4a06bad1711fd1a1761a592bf1475edc0a5f97b31759eba330ac736476a914b6e87320e876a740fc1365aeb1f4b6ab2fe4210b88ad53b268 ` ` ` ` ` ` json { "" asm "" : "" 0 3 d3b9c8cc852f3b4a06bad1711fd1a1761a592bf1475edc0a5f97b31759eba330 op_checksig op_ifdup op_notif op_dup op_hash160 b6e87320e876a740fc1365aeb1f4b6ab2fe4210b op_equalverify op_checksigverify <number> op_checksequenceverify op_endif "" , "" desc "" : "" raw ( 2 1 0 3 d3b9c8cc852f3b4a06bad1711fd1a1761a592bf1475edc0a5f97b31759eba330ac736476a914b6e87320e876a740fc1365aeb1f4b6ab2fe4210b88ad53b268 ) <hashtag> uul8nd2t </hashtag> "" , "" type "" : "" nonstandard "" , "" p2sh "" : "" 2 n62ryy2gbc2qbsdsm832tv6qcw5py53wjn "" , "" segwit "" : { "" asm "" : "" <number> 4 3 c1d0387e91045591f19ff6d60af2bc0d91473b79dc3238aa9d0430f89741bc "" , "" desc "" : "" addr ( tb1qg0qaqwr7jyz9ty03nlmdvzhjhsxez3em08wryw92n5zrp7yhgx7qj56vra ) <hashtag> ugngfnm5 </hashtag> "" , "" hex "" : "" 0 0 2 0 4 3 c1d0387e91045591f19ff6d60af2bc0d91473b79dc3238aa9d0430f89741bc "" , "" address "" : "" tb1qg0qaqwr7jyz9ty03nlmdvzhjhsxez3em08wryw92n5zrp7yhgx7qj56vra "" , "" type "" : "" witness_v0_scripthash "" , "" p2sh - segwit "" } } ` ` ` it would be nice if this ( also ) returned miniscript . perhaps ` getaddressinfo ` could do this as well ( after # <number> ) . cc <user> , <user>",1
bitcoin/bitcoin,"benchmarks slow benchmarks "" option ? often i ' d like to do some quick benchmarks on a slower platform ( e . g . risc - v , arm32 ) . various ` wallet * ` benchmarks are extremely slow even on state of the art hardware . i think an option to skip slow benchmarks would be useful . it might be possible with a ` - filter = ` expression , i am not sure .",1
bitcoin/bitcoin,"parallel compact block download there have been a couple of old attempts to enable parallel compact block downloads , see # <number> and # <number> . there are additional notes in # <number> . the idea is that we currently might request missing transactions for a new block from the first peer to announce the block to us ; but if that peer is a miner ( or close to a miner ) , that peer might be busy ( eg it might be in connecttip ) , and not able to reply quickly , while some other node has meanwhile obtained the block and is able to quickly give you the few transactions you are missing . therefore , at some point we should pick up the patches in those earlier prs , or otherwise solve this <happy>",1
bitcoin/bitcoin,"getrpcinfo should provide version number * * is your feature request related to a problem ? please describe . * * rpc details change , like fields in responses & i want to write robust code that can handle that . * * describe the solution you ' d like * * ` getrpcinfo ` or a new rpc call should provide the version of the client as a string such as "" <number> "" or similar . * * describe alternatives you have considered * * would need to fingerprint a few responses and apply heuristics to determine what we are talking to otherwise .",1
bitcoin/bitcoin,"add an option to create taproot descriptor for old descriptor wallets * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > new wallets created with bitcoin core v <number> rc3 have by default descriptors = true and taproot descriptor is generated . * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > using a wallet created with descriptors = true with the precedent version <number> does not allow me to create receiving bech32taproot address ( which is normal , since by that time "" desc "" : "" tr was not present ) . i have tried to upgrade wallet with the command "" upgradewallet "" but it is already at latest version : { "" wallet_name "" : "" wallet_22 . <number> "" , "" previous_version "" : <number> , "" current_version "" : <number> , "" result "" at latest version . wallet version unchanged . "" } i think it would be great a way to upgrade / add taproot descriptors to the wallet instead of having to create a new one .",1
bitcoin/bitcoin,"python tests : use black and isort for formatting there does not seem to be an agreed upon code formatter for the files in ` ` ` tests / ` ` ` . some widely used formatters are [ ` ` ` black ` ` ` ] ( <url> which does general code formatting , and [ ` ` ` isort ` ` ` ] ( <url> which sorts the imports . example usage black . isort . - - profile black ` ` ` this could reduce time spent reviewing and discussing code style .",1
bitcoin/bitcoin,"util / check . h assert / assume : namespacing issues the ` assert ` / ` assume ` macros are implemented via lambda functions to allow the result of the assertion to both be evaluated ( and trigger an abort ) and be returned without having the expression be evaluated twice . this causes some ugly namespacing issues though . because there ' s a function call , clang ' s thread safety annotations do not get passed through ( as the lambda is unannotated ) , possibly causing an unnecessary compiler error because the compiler loses track that a mutex is held when a guarded variable is accessed . it also seems that gcc ( but not clang ) gets confused about member functions ( but not member variables ) , eg : ` ` ` c + + class testassert { public : int variable = <number> ; int test_1 ( void ) { return variable ; } int test_2 ( void ) { auto x = [ & ] ( ) { assert ( test_1 ( ) = = <number> ); }; x() ; return + + variable ; } }; ` ` ` results in : ` ` ` test / util_tests . cpp : <number> <time> : error call member function ‘ int util_tests : : testassert : : test_1 ( ) ’ without object <number> | assert ( test_1 ( ) = = <number> ); ` ` ` requiring you to write ` assert ( this - > test_1 ( ) = = <number> ) ` instead .",1
bitcoin/bitcoin,"[ brainstorm ] improving ` makeseeds . py ` a . filtering hosts with multiple ports can be removed imo : <url> b . tor v3 can also be included in the results . c . recent observation which can be confirmed with : ` ` ` wget <url> sudo dpkg - i nrich_0 . <number> . 1 _amd64 . deb host - t a seed . bitcoin . sipa . be | sed - e ' s / seed . bitcoin . sipa . be has address / / g ' | nrich - ` ` ` possible reasons for vulnerable machines used for bitcoin nodes : <number> . false positives <number> . users not aware or do not care <number> . attackers prefer using these for better results <number> . honeypots <number> . other reasons leaving <number> which will not be true for all the results , filtering such nodes in ` makeseeds . py ` should make sense . below is an example for one ip copied from [ ` suspicious_hosts . txt ` ] ( <url> ` ` ` python ip = ' <number> . <number> ' url = ' <url> + ip response = requests . get ( url ) if response . text . find ( ' cve ' ) = - <number> ` ` `",1
bitcoin/bitcoin,"guix - attest should support custom gpg executable names * * is your feature request related to a problem ? please describe . * * in qubes os , the "" split - gpg "" feature allows keeping the private key in a separate vm from the application ( in this case guix - attest ) . this prevents a compromised vm ( in which bitcoin core was built ) from stealing the private signing key . qubes provides a ` qubes - gpg - client - wrapper ` executable that has the same api as ` gpg ` . unfortunately , there is currently no way to make ` guix - attest ` use that executable instead of plain ` gpg ` . * * describe the solution you ' d like * * support an optional environment variable in ` guix - attest ` , which allows specifying an arbitrary command name that replaces ` gpg ` . * * describe alternatives you have considered * * i considered a command - line parameter , but it seems that environment variables are the convention in ` guix - attest ` . * * additional context * * i believe opentimestamps provides a wrapper with ` gpg ` ' s api as well , so maybe this would also be helpful for facilitating opentimestamps with guix .",1
bitcoin/bitcoin,pruneblockchain should be able to increase the size of pruned blockchain is it possible to update ` pruneblockchain ` command so it can also increase the size of pruned blockchain ? it seems to me that now it is only able to decrease it : ` ` ` bitcoin <user> : ~ $ bitcoin - cli pruneblockchain <number> error code : - <number> error message is shorter than the attempted prune height . ` ` `,1
bitcoin/bitcoin,"sync pruned blockchain * * is your feature request related to a problem ? please describe . * * syncing bitcoin can take tens or hundreds of hours . this is annoying especially if you are a developer and want to use bitcoincore ' s rpc api . * * describe the solution you ' d like * * adding a "" sync pruned blocks "" feature would be cool . it would for example allow you to only download the part of the blockchain you actually need . the cryptocurrency monero has already got this feature .",1
bitcoin/bitcoin,"moderation required for bitcoincore in the microsoft winget package repository bitcoincore is showing up in the [ winget package repo ] ( <url> ) . it ' s great to see the packages there , but you might want to take over the pr submission for your org . the packages there seem legit , but technically , anyone could contribute any package there and call it "" bitcoincore "" . your dev team may want to take over these submissions , or request you appear on the pr approval list for your org . * [ bitcoincore products on microsoft repo ] ( <url> * [ package contributing guidelines ] ( <url> * [ open discussion on microsoft moderation practices ] ( <url>",1
bitcoin/bitcoin,"doc : add a brief description to each namespace * * is your feature request related to a problem ? please describe . * * many namespaces are as yet un - annotated with a brief description , as used by doxygen to generate developer documentation , locally or at <url> < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > incomplete developer documentation may affect developer onboarding time , and this seems like low - hanging fruit . * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > to add annotations to each of these namespaces . there may be existing descriptions elsewhere , if not i or someone else could attempt to describe each namespace , and reviewers could suggest improvements or alternatives . * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > ideally each description would be committed by its author , so perhaps handling this with one pr that is then squashed is not the best solution . on the other hand , if this would ease developer onboarding perhaps that ' s more important . * * additional context * * documentation at time of opening <date>",1
bitcoin/bitcoin,"allow duplicate output addresses ` createrawtransaction ` * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > ` invalid parameter , duplicated address * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > remove the duplicate address check or add an optional argument to remove the check * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > hex editing * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - > [ 4 0 ac7fcef6a918e0c073f74cf79bb97b043f311e9f3b6e3d5067b0e6f2b6be5a ] ( <url>",1
bitcoin/bitcoin,"[ meta ] reworking the merge commit format currently merge commits include the list of commits , the description and a list of acks . ( exmaple merge : 8 8 7 7 9 6 a5ffcbafcd281b920f8d55fcb6e8347584 ) i think it could make sense to also include a list of stale acks and potentially non - code - review acks or nacks . obviously this has the issue that any of them might be stale , but it might make it easier to get a general idea of the support / opposition on a pull request . * signatures for acks . the benefit will be that signatures are less likely to be "" made up "" ( for example by github or by someone who compromised a github account ) . the problem is that practically no one signs acks and that signature formats are too verbose to include verbatim in the merge commit message . if there was a better way to include signatures , we could move toward a scheme where several reviewers contribute toward the merge commit similar to how the guix attestations are produced .",1
bitcoin/bitcoin,"wallet function and deprecating subtractfeefromoutputs the subtractfeefromoutputs function has long been the cause of many issues in coin selection . it is unclear whether it is being used for things other than sweeping the entire wallet balance , and sweeping specific inputs ( i . e . spending inputs without creating change and without figuring out the feerate manually ) . many issues opened about subtractfeefromoutputs indicate that users are using it for sweeping , and the linked issue in the pr that adds it also discusses sweeping as the intended feature . instead of using subtractfeefromoutputs in order to implement this feature , it makes more sense to me to add specific functionality for sweeping . this would allow us to de - complicate our coin selection code by removing subtractfeefromoutputs . * * * there are a few specific things that i would want to see in a sweep function , besides the obvious spending all utxos with one destination . it is possible that users will want to sweep to multiple destinations , so the sweep function should optionally allow users to specify amounts with addresses . if no amount is provided for an address , then the remaining value being swept will be sent to that address . furthermore , multiple addresses may have no amount specified , in which case the remainder is split equally among the addresses , much in the same way that subtractfeefromoutputs currently distributes the fee among the outputs . additionally , sweeping may be used to sweep only specific inputs . so this sweep function should be able to allow users to specify which inputs to use . all specified inputs should be spent . if no inputs are provided , then the entire wallet will be spent . * * * there are a few ways this could be implemented . the obvious is a new rpc with an api similar to ` send ` so that all of the relevant options can be provided . this would allow for a psbt to be returned in the case that the wallet does not have private keys , or if the user requests it . another way would be to add it as an option to ` send ` , however i do not think that the api for using it would be easy to understand . for the gui , there should be a dedicated button . internally , it should be completely separate from existing coin selection ( i . e . not in ` createtransaction ` , ` selectcoins ` , or ` attemptselection ` ) . lastly , when sweep is implemented , subtractfeefromoutputs should be added to ` - deprecatedrpc ` and the option removed from the gui . users should be informed that they can use the sweep function if that is what they are doing . otherwise they can open an issue to discuss their use case . after one ( or two ) major release with ` - deprecatedrpc ` and no users complaining about a use case for subtractfeefromoutputs that was not sweeping , then the subtractfeefromoutputs option can be removed and the code for handling it removed from coin selection .",1
bitcoin/bitcoin,wallet rescan multiple wallets why does rescanblockchain not scan many wallets the same time ? it can only scan one ( inefficient when requiring to scan multiple wallets ) .,1
bitcoin/bitcoin,"password for encrypted wallets on all pw protected functions ( such as sendtoaddress , dumpprivkey , etc ) * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > i want this to be very clear , this is not from an experience of being hacked ( well , yet anyway , knock on wood ) . this is completely theoretical based on my experience creating a webapp that interacts with bitcoind via rpc calls and thus it got me to thinking about how the hotwallet could be hacked , how to prevent it , etc . unlocking the wallet for x amount of time is a massive security flaw imo . let us say you have <number> ' withdraw ' processes running and they all have to ' unlock ' the wallet to processes their sends . thats fine if they finish quickly ( this isnt always the case btw ) . but what if you have 1 0 0 s or 1 0 0 0 s or something just causes it to go slowly and you have to increase the unlock period for some reason ? then what you have got is a wallet that is essentially in an "" unlocked "" stated almost constantly . this is a really bad idea . it would be better to ask for the pw on specific functions instead of a global scope . use case : server <number> : apache webserver , maybe has other services on it like mysql , ssh , etc , something that ' s vulnerable to be hacked server <number> server , has absolutely nothing on it other than bitcoind in rpc mode , it ' s buttoned down as much as possible short of actually unplugging it from the router . server <number> has rpc creds on it so that some application ( like a web app ) can interact with a btc wallet . it does not have the btc wallet encryption pw on it however . so it ' s only means of sending out btc or creating transactions is when server <number> checks a queue that resides on server <number> . <repeated> months go by and one day the machine is hacked . the hacker then monitors the server and notices that they can make rpc calls to the wallet ( oh crap ) . but the wallet is encrypted so we are good right ? ! <repeated> ha . wrong . they have access to the queue which seems to take a long time to empty . then they notice that the wallet is being unlocked consistently to empty the queue . <repeated> it this point it ' s game over for mr wallet . server <number> * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > i ' d like to see at minimum sendtoaddress , sendmany , sendrawtransaction , send , and createrawtransaction refuse to function if a pw on an encrypted wallet is detected . essentially anything that isnt a read ( except for something like dumping keys , obviously that should be as well ) . * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > there are alternatives but i am not interested in any of them as they are overly convoluted , difficult to setup , and just not a good user experience as a developer at all , all the while solving no security problems at all , at some point on some device ( whether connected to other devices or not ) that unlock period is going to come into play and when it does , this vulnerability rears it ' s head . i realize i can setup a ' read only ' wallet ( and i have ) , but had bitcoind not had this issue , i would not have had to do this for my purposes . i can see other use cases involving cell phones as well . * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - >",1
bitcoin/bitcoin,use notifications . dat for - * notify * * is your feature request related to a problem ? please describe . * * ` - startupnotify ` and ` - shutdownnotify ` configuration parameter accept shell commands to be executed after bitcoin core starts / shutdown one is still wip and not merged : <url> this provides options for attackers to target new users of bitcoin core and one example which involves some social engineering is explained in <url> * * describe the solution you ' d like * * i am not sure how this is used currently by different users and projects however if reading notifications about start / shutdown is the goal maybe a file with name ` notifications . dat ` with below format can help lastshutdown = <phone> lastrestart = someunixtime currentstate = shutdown ` ` ` initially suggested this solution in <url> * * describe alternatives you have considered * * educate users about misuse of * notify options,1
bitcoin/bitcoin,"tracing : tests for usdt tracepoints # <number> added the first three usdt based tracepoints to bitcoin core . to provide a [ semi - stable ] ( <url> tracepoint api the tracepoints need test coverage . the tracepoints can be tested in the functional tests using the python wrapper of [ bcc ] ( <url> before adding more tracepoints , the existing three tracepoints from # <number> should be tested . notes we currently only support the tracepoints on linux . the tests should be skipped on other operating systems . <number> . hooking into the tracepoints via the linux kernel requires special privileges . since kernel version <number> . ( aug . <number> ) the ` cap_bpf ` can be used . on older kernel version the overloaded catch - all capability ` cap_sys_admin ` is required . functional tests should not require ` cap_sys_admin ` as that essentially means running the test suite with ` root ` privileges . <number> . the tests require the bcc python library . this should be an optional dependency . tests should be skipped if the dependency is not present . the ` connect_block ` tracepoint can be tested by mining blocks with transactions and checking that the tracepoint passes the correct data . the ` net ` ` inbound_message ` and ` outbound_message ` tracepoints can be tested by checking the traffic between two nodes .",1
bitcoin/bitcoin,bitcoin - cli getaddressofwallet sorry to ask for this feature i have created a regtest network on ubuntu but when i create a bitcoin wallet i can not get the address of that with bitcoin - cli please provide a method to get the current wallet address,1
bitcoin/bitcoin,"rpc user to supply weight of external input this would allow wallet operations like funding transactions with smart contract - based inputs such as ln , or any input the core wallet does not know how to sign for . <url>",1
bitcoin/bitcoin,"coin selection algorithm proposal i ’ ve been working on a coin selection algorithm using evolutionary algorithm . i am creating this issue to discuss the possibilities related to it . if here is not the best place to discuss it , feel free to close this issue . if you don ’ t know what an evolutionary algorithm is , here is a good definition : "" ea is a subset of evolutionary computation , a generic population - based metaheuristic optimization algorithm . an ea uses mechanisms inspired by biological evolution , such as reproduction , mutation , recombination , and selection . candidate solutions to the optimization problem play the role of individuals in a population , and the fitness function determines the quality of the solutions ( see also loss function ) . evolution of the population then takes place after the repeated application of the above operators "" . anyway , i recommend you to study more about ea before trying to understand this proposal . in evolutionary algorithms we have genes , chromosomes , and population , for example : [ image ] ( <url> so , to begin our algorithm , we must first create an initial population . the population will contain an arbitrary number of possible solutions to the problem , oftentimes called members . in this case , a gene is a utxo , so , every chromosome is a set of utxos . ` ` ` member1 = [ utxo1 , utxo2 , utxo3 ] member2 = [ uxto2 , utxo5 , utxo6 , utxo7 , utxo8 ] . <repeated> ` ` ` to create the initial population , we can use the following approach ( considering <number> members per population ) : - <number> member composed of all utxos - <number> member that selects randomly from the shuffled utxos until the target is exceeded - <number> random members obs . : most evolutionary algorithms set a length for the chromosome . however , for this approach , we don ’ t do it because we do not know how many utxos our final solution will use . ok , having our initial population , it is time to evaluate each solution ( fitness ) . to do it , we can use the waste metric , introduced in bitcoin core recently . so , our metric to evaluate the members is the cost of creating change , the excess selection amount , and the cost of spending inputs now as opposed to sometime in the future ( when we expect to be able to consolidate inputs ) . see more : <url> after evaluating each member , we can define what is the best one among them and build our next population ( new generation ) . our new population will have ( considering <number> members ) : - <number> members from mutation - <number> member keeping the same chromosome of the best solution from the previous generation - <number> new random member considering <percent> mutation rate , we create <number> members copying the same chromosome of the best solution from the previous generation and applying mutation , like for ( gene in chromosome ) { const random_value = getrandomvaluebetween0and1 ( ) if ( random_value = = <number> ) { gene = getrandomutxo ( ) } } ` ` ` ok , now we have a new population , and then , we can repeat all the processes ( fitness and mutation ) n times ( being n the number of generations ) , the best member of the last generation will be our final solution .",1
bitcoin/bitcoin,"full cjdns support cjdns overview = = = = = cjdns is like a distributed , shared vpn with multiple entry points where every participant can reach any other participant . all participants use addresses from the ` fc00 : : / <number> ` network ( reserved ipv6 range ) . installation and configuration is done outside of applications , similarly to vpn ( either in the host / os or on the network router ) . motivation = = = = = even without this pr it is possible to connect two bitcoin core nodes through cjdns manually by using e . g . ` - addnode ` in environments where cjdns is set up . however , this pr is necessary for address relay to work properly and automatic connections to be made to cjdns peers . i . e . to make cjdns a first class citizen network like ipv4 , ipv6 , tor and i2p . considerations = = = = = an address from the ` fc00 : : / <number> ` network , could mean two things : <number> . part of a local network , as defined in rfc <number> . like ` <number> . <number> / <number> ` . bitcoin core could be running on a machine with such address and have peers with those ( e . g . in a local network ) , but those addresses are not relayed to other peers because they are not globally routable on the internet . <number> . part of the cjdns network . this is like tor or i2p - if we have connectivity to that network then we could reach such peers and we do relay them to other peers . so , bitcoin core needs to be able to tell which one is it when it encounters a bare ` fc00 : : / <number> ` address , e . g . from ` - externalip = ` or by looking up the machine ' s own addresses . thus a new config option is introduced ` - cjdnsreachable ` : * ` - cjdnsreachable = <number> ` : it is assumed a ` fc00 : : / <number> ` address is a private ipv6 ( <number> . ) * ` - cjdnsreachable = <number> ` is assumed a ` fc00 : : / <number> ` address is a cjdns one ( <number> . ) after setting up cjdns outside of bitcoin core , a node operator only needs to enable this option . addresses from p2p relay / gossip do not need that because they are properly tagged as ipv6 or as cjdns . for testing = = = = = ` ` ` [ fc3 <time> ea : e415 :c3 bf : <number> <time> 9 d <tong> 5 a2 <sad> 9 aa ] : <number> [ fc68 : <number> : cb27 <tong> 0 <time> <number> : e609 : dcdb : 2 2 a2 ] : <number> [ fcb3 : dc50 : e1ae : <number> : 7 dc0 : 7 fa <time> <number> : 8 e46 ] : <number> [ fcc7 : be49 : ccd1 : dc9 <time> <number> : f0da : 4 5 7 d : 8 ce ] : <number> [ fcf2 : d9e <happy> a25 : 4 eef : 8 f8 <time> 1 b : 1 b4d <sad> 5 9 6 ] : <number> ` ` `",1
bitcoin/bitcoin,"allow utxo locks to be written to wallet db addresses and closes # <number> as per that issue ( and its predecessor # <number> ) , there seems to be some interest in allowing unspent outputs to be locked persistently . this pr does so by adding a flag to lockunspent to store the change in the wallet database . defaults to false , so there is no change in default behaviour . edit commit changes default behaviour . utxos locked / unlocked via the gui are now persistent .",1
bitcoin/bitcoin,. * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - > oro coin,1
bitcoin/bitcoin,"add cbor rpc interface this issue is a proposal to add a cbor rpc interface to bitcoin - core . the interface would be in addition to the current json - rpc , not a replacement . the main goal of the proposal is to offer an rpc interface that is more efficient than the current json - rpc . remote clients with constraints on data usage will see the biggest advantage . cbor seems like the best choice for a minimal rpc implementation , since it has wide support in industry , and is the de - facto standard for iot communication protocols like [ coap ] ( <url> ) . meaning , there is likely to be a large community outside bitcoin to get support / developers . # # advantages - rfc standard specification : [ rfc <number> ] ( <url> - cbor uses binary representation - no need for base64 or other encoding - well - defined data types with minimal encoding overhead - small amount of types - several existing free open - source libraries to fork - many existing implementations are small ( ~ <number> - <number> loc ) - decreased data transmission for remote clients # # disadvantages - added code to the core implementation - larger attack surface - maintenance costs - added complexity - unclear data - size savings versus compressed json / base64 # # alternative approaches # # # external cbor proxy one possible alternative , suggested by <user> , is to write a proxy translating cbor to json . the proxy could be stand - alone from bitcoin - core , thus removing the disadvantage of added code . also , the proxy could be written in a memory - safe language like rust , decreasing the attack surface . there would also be disadvantages to a proxy implementation : - small overhead of translating cbor to json , and passing to the original json - rpc - installation of an additional piece of software # # # internal cbor proxy another alternative is to add cbor support to univalue , and implement the proxy in bitcoin - core . this would have the advantage of direct access to rpc internals , and potentially reduce overall code size . the proxy would listen on a separate port , translate the incoming cbor to json , and pass the json to existing rpc interfaces . # # free open - source implementations here is a list of some of the better candidates for a bitcoin - core cbor fork : - cb0r : <url> - zero - allocation c implementation - cppbor : <url> - c + + <number> implementation based on ` std : : variant ` - cbor11 : <url> - c + + <number> implementation - tinycbor : <url> - intel implementation , includes cbor - json translation - ironically , largest loc count of the candidates - cbor - lite - c + + <number> implementation , header - only - used in [ bc - ur ] ( <url> # # comparing to json - rpc <user> raised the point that compressed json may provide similar savings to cbor . to test whether the savings from cbor provides significant size reduction , i will implement a small number of rpc calls in cbor , and compare the uncompressed and compressed sizes against the current json encoding .",1
bitcoin/bitcoin,"protect a number of outbound tor connections from eviction * * is your feature request related to a problem ? please describe . * * outbound tor connections lose against outbound clearnet connections after the eviction logic starts having an effect . although i "" manually "" add outbound tor connections ( via ` bitcoin - cli ` ) , after some time typically only <number> or <number> outbound tor connection survives . my node currently has <number> outbound connections , of which only <number> is a tor connection ( bitcoin core version <number> . <number> ) . the issue does not depend on which tor version is being used . the ( good ) outbound connections that are manually added from the start are the <number> tor v3 onion addresses recommended [ here ] ( <url> * * a clear and concise description of what you want to happen . * * inbound tor connections are well protected from eviction since [ <number> ] ( <url> was merged . this suggests it would be good idea to apply a similar method to protect a number of outbound tor connections from eviction ( <number> for default parameters , for example ) . ` bitcoin - cli - netinfo ` on my node ( default parameters ) shows ipv6 onion total block - relay in <number> <number> <number> <number> <number> out <number> <number> <number> <number> <number> total <number> <number> <number> <number> <number>",1
bitcoin/bitcoin,"docs : add more examples and clarifications to external - signer . md proposing updates to ` docs / external - signer . md ` , specifically an explanation of how accounts are being used and examples of using the same device to create multiple wallets ( motivation and discussion",1
bitcoin/bitcoin,"please make gui responsive while syncing with network , especially to stop sync it is not possible to enter a transaction while the gui is syncing , because its lagging . sometimes it is important to enter a transaction and go away and the transaction will only be fullfilled after the blockchain sync is finished . for that there needs to be a responsive button to on / off the sync . i know the network symbol is there , but it does work that laggy . <repeated> thanks as a workaround i tried - connect = <number> . <number> a simple fix would be a - startwithnosync option same for "" processing blocks on disk "" . everything is stuck .",1
bitcoin/bitcoin,"additional arg * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > the rpc . cookie is generated with <number> permissions ( i . e . only the user running the daemon can use the cookie ) . when running bitcoind under a dedicated user and group ( e . g . user = "" bitcoin "" and group = "" bitcoin "" ) , distinct users who are also in the "" bitcoin "" group cannot use the cookie for auth . this forces your hand when running additional rpc client software like electrs to have it also run under the "" bitcoin "" user if you want to use cookie based authentication . currently the only way to alter this is to pass "" - sysperms "" but this uses the system umask for all files / dirs , not just the cookie . the cookie permissions should be individually tweak - able . * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > a "" - groupcookie "" argument could be added which generated the cookie with <number> permissions . this would allow distinct users added to the "" bitcoin "" group the ability to authenticate using the rpc cookie . in turn affording more flexible , and potentially more secure , installations . * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > continue to run additional rpc client software under the same user as the daemon or settle for username / password authentication .",1
bitcoin/bitcoin,"wallet : use database for locked coins * * is your feature request related to a problem ? * * utxo locks are stored in memory only . nodes start with zero locked outputs , and the locked output list is always cleared ( by virtue of process exit ) when a node stops or fails . it was added as memory - only filter in <url> few users wanted persistency for locking unspent in issue but it was closed in may <number> because of lack of interest . * * describe the solution you ' d like : * * use wallet db for locked utxos * * describe alternatives you have considered : * * use other wallets * * additional context : * * i tried fixing this , initially had issues related to [ wrong use of vector in c + + ] ( <url> and could never resolve it after trying few things . i think it will be easy for devs who work on wallet related issues in bitcoin core or anyone else good with c + + . would appreciate if someone could fix this and improve privacy in core wallet .",1
bitcoin/bitcoin,add a way to decrypt wallets without password i dont know maybe you add a semi complex puzzle to do it so it can be a little hard to decrypt not too hard though . idk,1
bitcoin/bitcoin,listransactions : documentation missing of txs with negative confs i figured out that conflicted transactions are erased from the list how much many time is needed or in which conditions they are erased ?,1
bitcoin/bitcoin,"sanitize fee rates ( user input ) it would be nice to sanitize fee rates from user input . for example the block min fee rate is simply parsed as int64_t value . as fee rates are multiplied by the package size , this can easily lead to overflow . ` ` ` if ( gargs . isargset ( "" - blockmintxfee "" ) & & parsemoney ( gargs . getarg ( "" - blockmintxfee "" , "" "" ) , n ) ) { ` ` ` assuming a maximum transaction size of at most 4 mvb , this would give an upper bound for the fee rate of ~ <number> btc / kvb . though , any fee rate larger than <number> btc / kvb is probably nonsense and should be rejected early on startup .",1
bitcoin/bitcoin,"error messages for invalid address can we add more information in error messages for invalid address especially the errors mentioned in pr : <url> example : change <url> to ` ` ` c + + error_str = "" invalid prefix for bech32 address . valid bech32 address starts with ` bc1 ` ( mainnet ) or ` tb1 ` ( testnet ) "" ; ` ` ` context",1
bitcoin/bitcoin,"tx fee estimation does not take into account time of day or day of week there seem to be patterns regarding fee required based on time of day and day of week , which is not currently ( last i checked ) being factored into the fee estimation code . for example , rather than giving a duration , it perhaps ought to give a estimated day of the week or time of the day of anticipated inclusion into a block with a disclaimer that the estimate is based on patterns of the past ( which do not predict the future ) . in terms of specific development of a gui wallet , it could be useful to have some visual representation of the minfees that were successful over the last <number> weeks to help the user decide on a suitable fee .",1
bitcoin/bitcoin,"having dataworkdir and dataarchivedir to increase velocity * * process is very slow . * * it makes many days to import full blocks . in my case , i had an index issue during download and resetindexes was very long process ( too long in fact ) * * ssd drives seems to increase process speed * * looking at forum and my personal tests , using ssd drive increase process speed . unfortunatly , big ssd drives are very expensive . * * speed up is only needed during current traitment * * one solution should be to have <number> data emplacements instead of <number> : - dataworkdir : path inside ssd drive to store curently files in process ( block , index , chainstate ) - archivedir where to store ended files ( those files are not modifed often ) like this , no need of a large and expensive ssd drive to run bitcoin core server",1
bitcoin/bitcoin,"[ wallet ] dumprivkey descriptor support i ' d like to able to access the ` xpriv ` corresponding to the ` xpub ` returned by ` getaddressinfo ` . we could have ` dumprivkey ` return the private key at the ` parent_desc ` level , either by default or by adding an boolean argument ` parent ` to the method .",1
bitcoin/bitcoin,"simple and intuitive way of watching / monitoring xpub keys ? * * is your feature request related to a problem ? please describe . * * trying to keep track of xpub addresses using core rpc and did not figure out how to do so . * * describe the solution you ' d like * * any clear way like importaddress or importmulti to keep track of xpub addresses ? is there any way to "" monitor "" all addresses of xpub - key without having to resolve every path / address adding them each by each manually ?",1
bitcoin/bitcoin,"add ` include_unsafe ` option to ` fundrawtransaction ` would it be completely unreasonable to allow ` fundrawtransaction ` to use unsafe outputs ? i understand this means the resulting transaction may be invalidated whenever the unsafe output i am relying one disappears ( e . g . because the transaction that produced it was rbf - ed ) but in my case that ' s ok , i will react to that and re - publish the tree of child transactions accordingly . but let me know if you think that ' s too much of a footgun for users , in that case i will architect my solution differently .",1
bitcoin/bitcoin,. .,1
bitcoin/bitcoin,. * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - >,1
bitcoin/bitcoin,"ios build support in macos bigsur <number> i am trying to build the bitcoin core for ios but it seems that the library only support for mac linux ubuntu and android so far . i have look at this repository <url> but it seems out of maintain for a long time . and when i call * make <emphasis> * , it still show out a lib for macos instead of ios . can anyone help me for some instructions ? i am using xcode12 and mac bigsur <number> . <number> . openssl for ios <url> ( we can refer to <url> for c + + xcode example for ios )",1
bitcoin/bitcoin,"guix : make it arch agnostic it would be nice if guix was arch agnostic , so different archs can be used to get the same binary . i tried running guix on amd64 and arm64 , for the target ` bitcoin - 6 2 cc2180afc1 - powerpc64le - linux - gnu . tar . gz ` and only got a few bits difference : ` ` ` diff - - - . / bitcoin - arm64 / bin / bitcoin - cli + + + . / bitcoin - amd64 / bin / bitcoin - cli ├ ─ ─ readelf - - wide - - decompress - - hex - dump = . gnu_debuglink { } │ @ @ - <number> + <number> @ @ │ │ hex dump of section ' . gnu_debuglink ' 0x0 0 0 0 0 0 0 0 <number> 6 f696e2d 6 3 6 c692e <number> bitcoin - cli . dbg . │ - 0x0 0 0 0 0 0 1 0 1 3 a837f9 . <repeated> <number> . │ + 0x0 0 0 0 0 0 1 0 0 8 b973c6 . <repeated> s .",1
bitcoin/bitcoin,"new feature : faster - - reindex speed optimisation hi , if a user uses the - - reindex command to download the block chain this works fine . however if you stop it midway for what ever reason for example : - computer crash - not leaving computer on for days - running out of disk space then in this case you need to use the ` ` ` - - reindex ` ` ` command again . however it takes forever to recheck each already downloaded ` ` ` blk000 * . dat ` ` ` file before continuing to reindex . currently on my machine my blocks are reindexing between <number> - <number> seconds per block . ( my machine : mac mini with external hdd ) do you think it would be a good idea to use file hashing checks to speed up this process for example on ubuntu you can run this command blk00000 . dat ` ` ` which returns this hash ` ` ` be88bbfc0c09b3527e71f38fe14ba8693d35271d15bfdca57567429e06671003 ` ` ` would it be possible to create another . dat file containing all blk file hashes . then this file can be cross referenced against your file system to ensure it matches . as long as each node contains a copy of the same file , then this ` ` ` block - hashes . dat ` ` ` type file can be redownloaded from a peer or a hash check to compare it with your current ` ` ` block - hashes . dat ` ` ` file . then your computer can cross reference each file sha256sum with the ` ` ` block - hashes . dat ` ` ` file to speed up the process . then i think this would speed up the duplicate - - reindex by up to <number> - 1 0 x faster depending on your machine currently my blocks are reindexing between <number> - <number> seconds per block . if this was using the ` ` ` sha256sum ` ` ` it would take about <number> seconds per block on a standard hdd im am sure ssd would probably be even faster . i believe the change would need to be made in this file <url> near line <number> i would do this myself yet i am not a c programmer . - does anybody think this would be an improvement . - would anybody like to implement this update ? - i think this would take about <number> minutes to add this feature for a fluent c programmer .",1
bitcoin/bitcoin,follow - ups to pr <number> - message capture this issue tracks follow - up actions from # <number> - [ ] use <number> file = <number> session <url> - [x ] update message type checking in p2p_message_capture . py - [x ] remove makeucharspan <url> - [ ] add rpc to enable / disable message capture per peer - [x ] vulture warning about discarded value <url>,1
bitcoin/bitcoin,"~ ~ <money> bounty for offline multisignature through the gui ~ ~ view # <number> there has been incredible work implementing descriptor wallets , psbts , offline signing , hwws ; and gui support for it all into bitcoin core . it has been incredibly exciting to watch my goal is to financially support developers to implement offline multisignature wallets into bitcoin core . i believe we are almost there . i am here to humbly try to attempt to describe what i see , as a user and through talks with other developers , as the work that is needed to implement secure , offline multisignature wallets in bitcoin core . <number> ) a standard for coordinating multisignature wallets , with an authentication scheme . this is being discussed [ here ] ( <url> blockchaincommons has done a lot of work around this : online node coordinator sends a ' policy request ' to offline co - signers , if acceptable , co - signers send a ' keyset ' , and then get an ' account map ' back . policy request = empty descriptor keyset = bip48 path account map = descriptor w / no xprvs in it and / or co - signers send array of descriptors for all script types ( [ bcr - <number> - <number> ] ( <url> to coordinator , coordinator selects necessary descriptor and creates wallet , then sends ' account map ' back . concerns : lack of complete standardization . use of bip48 . names still up in the air . <user> also discussed the possibility of a ' wallet composer file ' that could compose a wallet interactively , use future - proof syntax ( can the signer decompile miniscript ? ) , and support other capabilities . not sure how much work has been done on this . <number> a ) the authentication : just trust on first use , with warnings if data changes ? <user> has done great research and reporting on this : to receive securely , the offline signers need to be able to verify the following : > the receive address , which has to encode the hash of an ordinary multisig redeem script with no other spending conditions > the key of the hardware wallet , which has to be one of the public keys in the redeem script > the keypath of the displayed address in order to avoid ransom attacks if no restrictions are enforced by the hardware wallet > the number of cosigners in order to prevent an attacker from adding more > the threshold of required signatures to not be higher or lower than intended > the xpubs of the cosigners in order to prevent an attacker from swapping them the above is written for hardware wallets , but i believe any bip written and code implemented should be for both hwws and offline core wallets . with descriptor wallets , i believe a lot of the above authentication can be automated by the info in the account map that all offline co - signers have . to send securely , the offline signers need to be able to verify the following : > the recipient ’ s address , displayed and confirmed by the user like with singlesig > the change address , having the same cosigners and threshold in an ordinary multisig script with no other spending conditions > the change goes to an address at a keypath recoverable by the user i think all the above is very important , since there have been many instances of devices not properly implementing the above security measures , so having a bip for devices / software to comply with would be important . <user> and <user> have been doing a ton of work integrating hwws . this looks like it will be merged soon : ( <url> after that , the ui will be worked on ( <url> and there is a currently - closed pr for hww multisig functionality on top ( <url> perhaps some of this code can be re - used for multisig with core on offline computers , but i am not sure . i believe having this ability would be an extensive security gain ( being able to create a multisig wallet with core on offline computers through the gui ) . <number> ) represent multiple derivation paths with one descriptor ( <url> single descriptors make creating , backing up , and restoring multisignature wallets much simpler . for example : to create a multisignature wallet in bitcoin core , you can currently : <number> . create wallet <number> . dump ` hdseed ` <number> . create address , dump xpriv <number> . repeat steps <number> - <number> n times <number> . create multisig wallet using descriptor containing all n xprvs ( m of n multisig ) <number> . use the n ` hdseed ` s along with account map as backup however , the above wallet can not create change addresses . you need to create ( backup and restore ) a second descriptor for change addresses , even though most of the descriptor is the same , except for the derivation path at the end . this can be very time consuming / confusing for end users , especially when backing up by paper / hand . for a comprehensive offline multisignature wallet , i believe this change needs to be implemented . currently in yeti , we bypass this by recommending coin control and only sending entire utxo ' s ( which is a pretty bad user experience and short term solution we have chosen ) . some users like setting custom change descriptors ( for example , for sending to an application for mixing change ) so i believe this should be able to be done behind expert options , and perhaps this makes a single descriptor less controversial . <number> ) qr code scanner ( <url> qr codes are the most secure way to pass data between airgapped signers . i currently have a <money> bounty on implementing this . blockchaincommons has a standard ( [ bcr - <number> - <number> ] ( <url> that is compatible with psbts ( multiple qr codes checksummed ; or a single animated qr code ) , and has a c + + reference implementation ( <url> <number> ) after the above ( <number> - <number> ) is finished , i believe implementing offline multisignature wallets into bitcoin core will be possible . i am not trying to influence consensus ( this should just be wallet code ) , and ultimately it is of course up to the developers and the community if these are changes that are good for bitcoin , and if the above is how it should be implemented . i am just trying to put all the thoughts / discussions down in one place . developers who might be interested : <user> <user> <user> <user> - - - - - begin pgp signed message - - - - - hash i , robert spigler , am offering a <money> bounty for implementing <number> , <number> , <number> , and <number> ( standard for coordination of co - signers , single descriptors , qr codes , and offline multisignature wallets ) in bitcoin core . this does not include the already existing <money> bounty for # <number> ( qr codes ) . the bounty will be split between developers as i see most fair ( author and substantial reviews / discussions ) . the bounty has no expiration and will be paid in bitcoin . the date is <number> - <number> - <number> . - - - - - begin pgp signature - - - - - iqizbaebcgadfieef4wkhnge9pwzsby0usewl8eq8 / afamaajz0acgkqusewl8eq <number> / cvqw / / zoqkdabwlyxqcf669fqvswrk / q / mnidabor9gvwfixzsbp1j7knggpvz wcpek6jpmu4b1za2jobbsakcaearuibrmvoxwnhmeg0igjmnhzyhl9d4lvy1kubd 3 f8khqz0yilazgrwu6 + ckovltmqfws / giagoweqca8a4nx0wjbhtymwvxqmxlbnj 7 zjn3nfjdi7cyxmggyfnlljscdugt205piwphwi9or2tjvwfl6rrlr1rzakchooa zvd6ud0mgchijmvlwv5qyk6kgm4o9xtvpywu9dkwq1jahv4mtzvb + n1dsgt6zqxf gnzvop + iuigemgwe1qw8wsiwjubjrvbhwcg3cffchmryefmo6 + 5 3 rcym8 + vnbyem vfts1rmmtlex8utfrxx4fala1wdphlnfcnilnnabbmtrck7wutqdo07enc6ki / wz qxbabulqip3fehlcsv9ozqikqmtawn2235an + b0j7bflaegbg2e + ur3lildpkzvo u1r + ngdfnf9zka8rkjxrench5o46sbxi6gpyvtvy8nay8pj2rfcgmyg1a0dew1g2 zy / <number> / 4 umud5mr92ggkjwbkke7hwqypyexwhc + vo5foocy5xtjza0hoyiw + 5 vhkmm ygs81oaqfiv / mjfffsj581uu6th1s + 7 g9nwjet9vgqtsjbnd1p4 = = xm2a - - - - - end pgp signature - - - - -",1
bitcoin/bitcoin,"setting a label on bitcoin - qt changes the label of all unlabeled transactions < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * when selecting one transaction , and choosing "" edit label "" , it changes the label of every single transaction which did not have a label previously . * * actual behavior * * what happens is the aforementioned effect - all transactions get such label < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> * * expected behavior * * as one clicks one transaction and it says "" edit label "" , i would expect that the label is transaction - related , not per receiving address . either the gui is misleading in the description or it ' s not behaving as it should . * * to reproduce * * choose one transaction . choose edit label with mouse right - button . all transactions to that receiving address will change to such label . * * system information * * bitcoin - qt <number> . <number> from bitcoin . org mac os big sur , whatever version came out last week",1
bitcoin/bitcoin,rpc : derive wallet addresses * * is your feature request related to a problem ? please describe . * * it is not possible to simply derive the wallet ' s addresses . i have a need to find the address inside the hd wallet at a given hd path . * * describe the solution you ' d like * * - derive address using the node i . e . ` derivewalletaddress ( path ) ` that returns the same as ` getaddressinfo ` * * describe alternatives you have considered * * - export xpub - not possible - export the seed - ` dumpwallet ` only exports to file - cannot be used over network - ` deriveaddresses ` - requires xpub / xprv - ` listaddressgroupings ` + ` getaddressinfo ` for every address and find by ` hdkeypath ` - this is way too intensive * * additional context * * some context i found about xpub exporting explains that this is not possible,1
bitcoin/bitcoin,"dbcache config option is missing from example bitcoin . conf * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > no , just requesting an update to the example bitcoin . conf * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > ` dbcache ` config option to be added to [ example config ] ( <url> ref",1
bitcoin/bitcoin,"can i make readme . md and other introduction files in another language ? * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > i think i can add the another version of readme . md and other introduction to bitcoin files in another language . i think this can improve the accessibility of this project . <br> * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > i will translate the documents , then other people can help * * etc . * * i am korean , so i will translate this documents in korean .",1
bitcoin/bitcoin,"add i2p support using i2p sam add i2p support by using the [ i2p sam ] ( <url> protocol . unlike tor , for incoming connections we get the i2p address of the peer ( and they also receive ours when we are the connection initiator ) . two new options are added : ` ` ` - i2psam =< ip : port > i2p sam proxy to reach i2p peers and accept i2p connections ( default : none ) - i2pacceptincoming if set and - i2psam is also set then incoming i2p connections are accepted via the sam proxy . if this is not set but - i2psam is set then only outgoing connections will be made to the i2p network . ignored if - i2psam is not set . notice that listening for incoming i2p connections is done through the sam proxy , not by binding to a local address and port ( default : true ) ` ` ` # overview of the changes # # make ` readbinary ( ) ` and ` writebinary ( ) ` reusable we would need to dump the i2p private key to a file and read it back later . move those two functions out of ` torcontrol . cpp ` . ` ` ` util : extract { read , write } binaryfile ( ) to its own files util : fix readbinaryfile ( ) returning partial contents util : fix writebinaryfile ( ) claiming success even if error occurred ` ` ` # # split ` cconnman : : acceptconnection ( ) ` most of ` cconnman : : acceptconnection ( ) ` is agnostic of how the socket was accepted . the other part of it deals with the details of the ` accept ( <number> ) ` system call . split those so that the protocol - agnostic part can be reused if we accept a socket by other means . ` ` ` net : check for invalid socket earlier in cconnman : : acceptconnection ( ) net : get the bind address earlier in cconnman : : acceptconnection ( ) net : isolate the protocol - agnostic part of cconnman : : acceptconnection ( ) net : avoid unnecessary getbindaddress ( ) call ` ` ` # # implement the i2p [ sam ] ( <url> protocol ( not all of it ) just the parts that would enable us to make outgoing and accept incoming i2p connections . ` ` ` net : extend cnetaddr : : setspecial ( ) to support i2p net : move the constant maxwait out of interruptiblerecv ( ) net : dedup msg_nosignal and msg_dontwait definitions net : extend sock : : wait ( ) to report a timeout net : extend sock with methods for robust send & read until terminator net : extend sock with a method to check whether connected net : implement the necessary parts of the i2p sam protocol ` ` ` # # use i2p sam to connect to and accept connections from i2p peers profit from all of the preceding commits . ` ` ` init : introduce i2p connectivity options net : add i2p to the reachability map net : make outgoing i2p connections from cconnman net : accept incoming i2p connections from cconnman net : recognize i2p from parsenetwork ( ) so that - onlynet = i2p works net not skip the i2p network from getnetworknames ( ) ` ` `",1
bitcoin/bitcoin,"rfc on logging improvements perhaps we can consider creating different levels of net logging . for instance , we could separate lower - frequency , important peer - level events ( ` netpeers ` ) from very high - frequency message - level passing ( ` netmessages ` ) . categories and naming suggestions welcome . one further suggestion by <user> was no objections . i ' d take it ever further though , and add an ( optional ) logging severity ( debug / info / warning / error or similar ) that can be added to all log messages . the user can then either choose what severity logs they want for each category ( eg = - debug = net : warning , tor : debug etc ) , or have a logging post - processor that can filter by severity / category . i like the idea of optional logging levels ( debug / info / warning / error ) for each category , including the default debug log , but agreement on which events go into which level may be difficult to achieve . to begin with , i propose separating the net logging into at least two categories . thoughts ? implementation suggestions ?",1
bitcoin/bitcoin,"psbt is not handling psbt_global_xpub the psbt_global_xpub should be populated when creating psbts when using multisig , as offline signers such as the bitbox02 hardware wallet require it to register and retrieve a multisig account . <url> would there be any obstacles in implementing this ?",1
bitcoin/bitcoin,"use try_emplace on std : : map with c + + <number> let us have a discussion and see if a structure change is warranted to many places std : : maps / unsorted_maps are used in the code . now that we support c + + <number> as a minimum as of #[ <number> ] ( <url> we should consider using try_emplace to gain efficiency when objects are not added , it also leads to more expressive and safer code ( prevents stealing from arguments during failed insertion ) . for example , it seems fetchcoin uses emplace but does a piecewise_construct however it can be replaced with try_emplace : ` ccoinsmap : : iterator ret = cachecoins . emplace ( std : : piecewise_construct , std : : forward_as_tuple ( outpoint ) , std : : forward_as_tuple ( std : : move ( tmp ) ) ) . first ; ` becomes ` ccoinsmap : : iterator ret = cachecoins . try_emplace ( outpoint , std : : move ( tmp ) ) . first ; ` i also noticed emplace was used on dir_locks which is a map to unique_ptrs which is generally discouraged . it is used [ here ] ( <url> and should likely just look like this = std : : move ( lock ) ); `",1
bitcoin/bitcoin,"bitcoin address format . * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > dear everyone , i am working on cryptocurrency exchange platform newly . i downloaded bitcoin - core and synchronized full node . i am using json - rpc request to connect to bitcoind . i created new wallet and it always returns segwit address . * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > there are <number> formats for bitcoin address . p2pkh or legacy address format ( addresses start with “ <number> ” ) p2sh or compatibility address format ( addresses start with “ <number> ” ) bech32 or segwit address format ( addresses start with “ bc1 ” ) * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > but bech32 address is not recognized in several exchanges and i need get p2pkh or p2sh address . * * additional context * * how can i get this type address by using json - rpc ? please help me ! <repeated> < ! - - add any other context or screenshots about the feature request here . - - >",1
bitcoin/bitcoin,test_bitcoin - qt should not bind to regtest ports ` test_bitcoin - qt ` binds to the regtest ports which causes it to hang if a regtest bitcoind or bitcoin - qt is already running . this causes ` make check ` to hang and be annoying to kill . so ` test_bitcoin - qt ` should not bind to these ports to avoid conflicting with an active regtest instance . or it should fail gracefully instead of just hanging and then timing out .,1
bitcoin/bitcoin,document json - rpc wallet endpoints it appears we do not have any documentation of the / wallet / <walletname> json - rpc endpoint . maybe json - rpc - interface . md is a good place to put it .,1
bitcoin/bitcoin,"dependency on github after reading [ this post ] ( <url> with the title « important open source projects should not use github » i thought instantly about bitcoin and it ' s source code . it is the most important open source project and it is hosted on github . was this topic ever discussed ? i would think so after microsoft aquired github , but i could not find it . what happens if github requires a microsoft account to login to github , are all developers willing to create a microsoft account ? i know , i do not offer a solution at this point . i heard about [ sourcehut ] ( <url> as an alternative to github . the problem is , the source code of bitcoin will ( with the current available git hosting providers ) always be centralized . is that the reason why bitcoin did not move away from github ? this is more like a discussion , if this is the wrong place for that or there is already an open issue . please close this one and point me in the right direction . thanks",1
bitcoin/bitcoin,"allow spending from segwit addresses created from uncompressed private keys ( p2sh - p2wpkh ) trying to create a transaction that is sent from a segwit addresses created from an uncompressed private key raises this error : _non - mandatory - script - verify - flag ( using non - compressed keys in segwit ) ( code <number> ) _ this makes the transaction non - standard , which has resulted in stuck user funds . a small change is needed in the source code to allow for such segwit addresses in order to have their transactions not marked as non - standard . * * please enable relaying and mining of non - standard p2sh - p2wpkh transactions that use uncompressed public keys . * * * * additional context * * one specific user has over <number> btc that is unspendable due to all outgoing transactions being marked as non - standard . address with funds : 3 4 dqaqvqnwmgbmjmmxva8legz7st6att97 please see",1
bitcoin/bitcoin,"rpc : fetch block from peer the node is very efficient at not downloading blocks it does not care about . e . g . if a peer has headers for a lower proof - of - work branch , we will not fetch the full block . it ' ll appear as ` headers - only ` or ` valid - headers ` in ` getchaintips ` . this is fine , but if a user is curious about a block , there ' s no easy way to obtain it . <number> . you can call ` invalidateblock ` on the current tip and wait for the node to jump to the other branch <number> . you can use some other software to obtain the block via p2p and then feed it to the node with ` submitblock ` it would be nice if you can just fetch it from a peer , if you know they have it . in the most simple implementation , the user has to specify which node to ask . a more fancy version could automatically try all nodes , and perhaps even randomly connect to new peers until it finds the block . usage bitcoin - cli getblockfrompeer hash peer_n ` ` `",1
bitcoin/bitcoin,built in restore wallet we have a ` backupwallet ` rpc and a way to backup a wallet from the gui . but there ' s no way to restore a wallet other than copying the backup file into the walletdir . we should add a restore .,1
bitcoin/bitcoin,"improve block file pre - allocation speed on linux * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > the block file pre - allocation takes too long as currently done by ` fallocate_posix ` on linux ( ext4 ) . * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > there is a way to make it uncomparably faster . i am not yet sure if it is switching to another function for linux , or just setting some options for the ` fallocate_posix ` . * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > i know that file allocation in [ transmissionbt ] ( <url> torrent client is very fast on linux . these commits i have identified from searching the logs as related , ordered from newest to oldest transmission / transmission <user> , transmission / transmission <user> , transmission / transmission <user> . ` ` ` $ man <number> fallocate ` ` ` <url> * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - > because i can not work more on it right now , i am dumping what i have found so far into this issue . feel free to comment or even make a pr . thank you !",1
bitcoin/bitcoin,"fuzz : how to scale fuzzing with the number of fuzz targets having different fuzz targets is useful to give the fuzzer a specific and well defined task to work on . this makes it also easier for developers to see what an individual fuzz test / target is doing . moreover , the fuzzer might be more performant in finding new inputs because the input directory as well as the search space is smaller . however , there are also several downsides limiting the overall search space the fuzzer can explore will make it impossible to reach coverage for the code paths that have been excluded . * building numerous small fuzz targets , instrumenting them and linking them with debug symbols is costly in cpu time and disk space . a quick build is not only important for devs , but also for ci . similar to how the unit tests are compiled and linked into one binary , we could look into linking the fuzz targets into one binary . individual targets could be selected with some kind of runtime argument .",1
bitcoin/bitcoin,"[ idea ] multiple ports for faster overall performance ? i am coming at this from the angle of overall throughput of the network . so it looks like the bitcoin daemon listens on <number> and <number> for connections . what if , bitcoin used . <repeated> say <number> ports , or maybe even just <number> on both sides . i think you ' d be able to receive multiple at the same time given they were operating in an asynchronous manner . i am not sure of the overall code structure , but would not it allow for more throughput overall if both sides were communicating and routing based on open sockets ? i do not know the deep technicalities of ports and throughput and i know it ' s not your job to teach me , but i am curious if there ' s any possible gain here .",1
bitcoin/bitcoin,"rescanning use only <number> core when i run * * bitcoin - qt . exe * * with _ - zapwallettxes_ parameter , it rescan my wallet , but using only <number> of <number> core ~ <percent> of maximum , and only <number> - <number> mb / sec reading on m2ssd drive . how can i add more cores for running qt ? [ <url> bitcoin . conf = ` dbcache = <number> par = <number> txindex = <number> addresstype = legacy proxy = <number> . <number> : <number> listen = <number> bind = <number> . <number> onlynet = onion datadir = e :\\ roaming \ \ bitcoin blocksdir = e :\\ roaming \ \ bitcoin `",1
bitcoin/bitcoin,"rfc : svg images / icons support there are some concerns about possible security issues . [* * luke - jr * *]( <url> > . <repeated> the concern is importing something complex like qtsvg into the overall codebase / runtime process . <repeated> any vulnerability compromises the entire program . otoh , [* nicolasdorier <emphasis> *]( <url> > given svg files are auditable ( it ' s only text ) , and we do not accept svg from any untrusted source , i do not think this is a good concern * * luke - jr * * and one more concern : [* marcofalke <emphasis> *]( <url> > > concept ack if this worked out of the box without the build system changes . > > the build system changes are required for static builds . the questions are if the project really sticks to the png only image / icon format , why ` src / qt / res / src / * . svg ` are still present in the repo ? <number> . if concerns about svg are not good , why not switch all icons to svg ( now we have designers to help with that ) , and get rid of ` src / qt / res / icons / * . png ` ?",1
bitcoin/bitcoin,"improve tor support documentation * * is your feature request related to a problem ? please describe . * * i think we can add few things in <url> to make it easier and better for users to use bitcoin over tor * * describe the solution you ' d like * * <number> . add few examples to run bitcoin as onion service : <url> <number> . add information about use of tor bridges and safe ways to connect over tor : <url> <number> . if we can not add everything in [ tor . md ] ( <url> maybe add more docs for separate platforms and issues . example ` tor - linux ` , ` tor - privacy ` * * describe alternatives you have considered * * i have tried to experiment , research and share things on <url> to discuss about tor related setups involved in using bitcoin * * additional context * * i am only suggesting few ideas based on my research and observation . i am sure people who use or build things related to tor and more experienced than me are involved in bitcoin so maybe we can improve the docs related to ' tor support ' .",1
bitcoin/bitcoin,"script interpreter cleanups extracting this topic from # <number> as during its review general cleanups of the script interpreter clean have been advocated . given that taproot implementation review is already far advanced , i think no one is proposing to address them now ? this issue is more to track interesting points raised . i guess there is at least two different axis which have been under discussion ( but they may overlap a bit ) : * <user> has a branch splitting consensus from policy as of today , it sounds like the distribution of consensus and policy checks is fairly arbitrary and may lead to confusion on expected behaviors ( see <url> * <user> was proposing to split further interpreters ( see <url> taproot is complexifying the script rules matrix thus making it hard to reason on in the prevision of future script softforks if you have more comments worthy to be pinned please add them .",1
bitcoin/bitcoin,"transactions propagation design goals during the last p2p meeting , <user> pointed the lack of a transactions propagation framework thus hindering progress in the tx - relay network area , devoid of clear goals to achieve . this is a blocking issue in a spawn of subjects , like countering cheap rbf replacements , increasing mempool feerate of resources constraints nodes , better support of bitcoin applications with more demanding fee / tx - relay requirements , scope of tx - rejection filter , etc # # core mechanisms of tx - relay i think one of the starter goal of the tx - relay network is obviously to let miners discover the best - feerate transactions candidate for inclusion in block . as bitcoin censorship - resistance lays on distribution of mining , bias in tx - relay topology privileging a subset of miners with an advantage in fee discovery may provoke disequilibrium beyond their hashrate contributions . thus an unstructured p2p network , vetted of uniform tx - relay peers selection is likely the best option . a distributed network is also more - robust against infrastructure disruption or targeted transaction censorship . an additional goal is preserving the pseudonymity of transactions original broadcaster which can be enforced with high guarantees only if tx - relay topology is non - observable by a protocol participants or a coalition of them . introduction of randomized timers at propagation ( e . g <url> is an improvement towards this direction , even if [ research ] ( <url> has hinted that the number of tx - relay mechanisms potentially exploitable to learn about topology is likely wide . future improvements like mempool rebroadcasts ( <url> or initial - broadcast - over - tor - only may improve the situation . lastly , an other important goal to consider is bandwidth - savings , as underscored in the [ erlay ] ( <url> paper , a too prohibitive tx - relay cost disincentives potential node operators , especially running full - relay public ones contributing the most to good health of the network . this goal might be in trade - offs with aforementioned ones , where tx - relay peering redundancy increases robustness and higher mempool rebroadcast frequencies add noise to the propagation graph at the price of higher bandwidth costs . # # tx - relay & node policies if the set of messages as inherited from first protocol versions or specified in peer services bips defines what bitcoin data structures are accepted by compliant peers , afaiu it does not mandate a relay behavior , neither outlaw a superset of constraints on p2p messages , at the discretion of local node . this superset of constraints is i guess what people commonly called p2p network transaction policy , even in fact such _policies_ vary by full - node implementation , versions and local node settings . on the core side , such policies encompass some dos / vulnerabilities counter - measures like ` script_verify_minimalif ` at the script interpreter level or ` min_standard_tx_nonwitness_size ` at the mempool level , invariants which can not be disabled by local settings , so we can qualify them as implementation / version policy . another range of policies checks are vetted with hopefully anti - dos default values like ` incrementalrelayfee ` or ` m_limit_descendant ` but configurable by node operator to express a different pricing of resources offered to the network or increasing the chance to learn good feerate chain of transactions by accepting higher dos risks . due to this divergence of policies across the network and adding to the absence of events order in a distributed system , mempools convergence has never been considered as a goal . however , there is a p2p mechanism for peers to discover and adapt its peers policies , namely [ ` feefilter ` ] ( <url> this mechanism prevent bandwidth - waste by will - be - rejected low - feerate transactions . further p2p mechanisms could be devised to improve peer policy negotiation , like ` txfilter ` announcing the local standardness applied or ` utxofeerate ` announcing the feerate of a package for a known utxo spend candidate . that said , communicating more information to opportunistically save more bandwidth is likely quickly bounded . # # fee / relay assumptions for bitcoin applications bitcoin applications aiming to confirm their transactions should ensure first to be connected to a high number of tx - relay peers , then ensure these transactions are formatted to pass at least ` testmempoolaccept ` of their local nodes . if a propagation failure is detected or suspected , a ) a rotation should be triggered to probabilistically find a peer with an identical policy , at least for the subset of policy rules you share or b ) a warning can be triggered back to the user hinting to do something about likely a badly - formatted transaction . such model does not work great with regards to multi - party bitcoin applications ( e . g ln or vaults ) , where signing interactivity is costly or impossible . further , if a transaction is time - sensitive with regards to advancing state of protocol forward , propagation failures are direct risks for fund safety . even further such potential propagation failures could be exploited by a malicious counterparty , if applications participants are assumed to be distrusted . such application can never be sure that transaction will confirm but should be able to express its best - feerate bid for this time - sensitive transaction , even if bid is not won due to a better blockspace demand . any such application / protocol developper will be confronted with the following questions : - how to decide the format of my transactions ( size , scripts , witness , minimal fee , . <repeated> ) ? - what should be the size / weight of chain of transactions ? - what should be my tx - relay strategy and should rebroadcast / peer rotation be triggered ? - what fee - bumping strategy are offered between rbf , cpfp , parent - pay - for - child , etc ? how network mempools will evaluate each one ? how a malicious counterparty could leverage [ them ] ( <url> ? - what dev process will follow ecosystem / implementations in case of rules tightening / changes potentially hindering application / protocol security , e . g what are core guarantees wrt to [ carve - out ] ( <url> backward - compatibility ? historically , we have an example of bip <number> , specifying out the mempool rbf policy , ready to be consumed as an interface by bitcoin applications . but otherwise , due to fear of silently breaking an obscure policy rule , some application are literally leaking them in their stack ( see <url> of course to avoid getting stuck in endless debates , here few questions we may evaluate as a guideline what have been historically propagation assumptions of bitcoin applications ? how newer class of bitcoin applications should conceive their operational and security models with regards to propagation ? - should we support requirements of newer classes of bitcoin applications ? if so , what should be the scope and expressivity of an fee / tx - relay api rules ? - what set of constraints ( dos , bandwidth , privacy , deployment , . <repeated> ) do we have to bind to ?",1
bitcoin/bitcoin,"signing transactions on offline computer without blockchain * * is your feature request related to a problem ? please describe . * * i am working with a team on yeti ( <url> which is a script for a ui for setting up offline , hd multisig with only minimal software beyond bitcoin core . only qr codes are used for transferring private keys . as core continues to merge prs on offline , multisig , and ui work , yeti will remove its own written code for the more peer reviewed core releases . the goal is that yeti is eventually not needed at all . currently , core needs a blockchain to sign transactions , even if the wallet is offline ( and does not truly need a blockchain ) . this means that although the wallet is getting the data it needs to sign from the qr code , the process now must look like this computer needs to be online for days first in order to sync the blockchain ( even though it ' ll never be used ) , then network access can be disabled , and descriptors generated . this could be made much simpler without having to sync . * * describe the solution you ' d like * * i know there is a lot of work on making core more modular ( <url> once that project is finished , is it part of the plan to be able to sign transactions without a blockchain present ?",1
bitcoin/bitcoin,"deprecate banlist . dat ` banlist . dat ` was introduced in <url> storing nodes that were automatically banned ( due to exceeding the misbehavior threshold ) and manually banned ( through the ` setban ` rpc ) . automatic bans were removed in <url> and replaced with a discouragement filter . that filter is not saved to disk / persisted over shutdown / startup . the ` banlist . dat ` therefore now only contains addresses that have been banned through the ` setban ` rpc . since <url> we have a specific file for configuration that is updated through the rpc and persisted over shutdown / startup , namely ` settings . json ` . we should therefore move the manual ban configuration from ` banlist . dat ` to ` settings . json ` . doing so has a couple of benefits ` settings . json ` is human readable and easily analyzable by any json parser . - we would not need to maintain custom [ de ] serialization code for the ` banlist . dat ` file . ` banlist . dat ` is expected to be fairly small and infrequently updated , so disk space / performance are not huge concerns .",1
bitcoin/bitcoin,"expose compact blocks high - bandwidth mode state through getpeerinfo for every peer expose through ` getpeerinfo ` rpc whether or not we selected them as hb peers , and whether or not they selected us as hb peers . suggestion by <user> .",1
bitcoin/bitcoin,add explicit feerate option for sendmany rpc method * * is your feature request related to a problem ? please describe . * * it ' s always hard to send a bunch of transactions with sendmany method using conf_target option . cause build - in fee estimator not suggesting required fee rate for our purposes . how could i specify transaction fee in btc / kb for sendmany without creating raw transaction ( building outputs and inputs manually ) ? * * describe the solution you ' d like * * add fee_rate option to sendmany rpc method . * * describe alternatives you have considered * * currently i am trying to estimate required conf_target based on mempool size and making weird algorithms that limiting that value someway . * * additional context * * that is not so convenient for us . so the better solution would be to provide fee_rate option that is much easier to manipulate . thanks in advance,1
bitcoin/bitcoin,"show the "" <n> of the last <number> blocks have unexpected version "" warning only when running - debug = validation ? [ google search results ] ( <url> suggest that our users are more confused than helped by the ` <n> of the last <number> blocks have unexpected version ` warning we are printing . as developers we know the unfortunate reason behind this warning and how "" unexpected "" should be interpreted in this context , and thus why it is safe to disregard this warning . however , i do not think it reasonable to expect our users to know the historical context here . in order to not desensitize our users to potentially critical "" real "" warnings , would it make sense to move this message to the ` - debug = validation ` log category ?",1
bitcoin/bitcoin,"solve year <number> problem by taking timestamps mod <number> ^ <number> * * is your feature request related to a problem ? please describe . * * with the current block validation rules , bitcoin will "" die "" on <number> - <number> - <number> , when the unsigned <number> - bit timestamp rolls over . * * describe the solution you ' d like * * currently , bitcoin ' s timestamp protection rules work as follows : <number> . the new block timestamp may not be lower than the median of the last <number> blocks ' <number> . the new block timestamp may not be greater than the current time plus two hours if they would be changed to the following , the problem would be solved the new block timestamp plus k <emphasis> \\* <number> ^ <number> , where k <emphasis> is an integer , may not be lower than the median of the last <number> blocks ' <number> . the new block timestamp plus k <emphasis> \\* <number> ^ <number> , where k <emphasis> is an integer , may not be greater than the current time plus two hours <number> . the values of k <emphasis> in <number> and <number> must be the same this would cause a hardfork in <number> , which is <number> years from now , by which time <percent> of nodes would hopefully have updated . * * describe alternatives you have considered * * <number> - bit timestamps have been proposed . they would break compatibility with a lot of other software , and cause a hardfork before the date of timestamp overflow .",1
bitcoin/bitcoin,"normalize fee units for rpc ( "" btc / kb "" and "" sat / b ) this needs to happen before the next major release . otherwise , it will be a breaking change . some more context",1
bitcoin/bitcoin,"sign and verify message not working # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour it is example address generated to purpose to test sign and verify a message . address : bc1qlhkfryasnna2fy0jrz794gmqkqnddk6pcpugg2 private key : l5js9y2yf17kkqpsgawjh61uhm168p9vjvhje15tvcsbl18kgfdu the message for verification : "" message "" signature : h7uksk3skjn4jjxyvvypavusnwbh1a1zjuo8g7iuhzq5drqnzyvvgzp / v + lk + 9 1 uu4dlncos6rifgvoqus3wd / q = the signature only successful using private key commands . using the online tool verifying the signature and message is successful : <url> note : wallet passphrase used but the bitcoin qt wallet version <number> and also previous versions error ! ! [ qterror ] ( <url> # # # expected behaviour sign and verify # # # steps to reproduce trying to sign by rpc , trying to sign using console , trying to veryfy both . # # # relevant log output _no response_ # # # how did you obtain bitcoin core compiled from source # # # what version of bitcoin core are you using ? v24 . <number> and v25 . <number> # # # operating system and version windows # # # machine specifications i9 and 1 2 8 gb ram , <number> tb ssd",2
bitcoin/bitcoin,"i did not modify anything before i run make check , but it can not work # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour when i run make check on my ubuntu , it said in file included from . / primitives / transaction . h : <number> : <number> , from . / primitives / block . h : <number> , from . / consensus / merkle . h : <number> , from consensus / merkle . cpp : <number> : . / script / script . h : in function ‘ cscript buildscript ( ts & & . <repeated> ) ’ : . / script / script . h : <number> <time> : error : parameter packs not expanded with ‘ . <repeated> ’ : ( [ & ret , & cnt ] ( ts & & input ) { ^ . / script / script . h : <number> <time> : note : ‘ ts ’ . / script / script . h : in lambda function : . / script / script . h : <number> <time> : error : parameter packs not expanded with ‘ . <repeated> ’ : if constexpr ( std : : is_same_v < std : : remove_cv_t < std : : remove_reference_t <ts> > , cscript > ) { ^ ~ ~ . / script / script . h : <number> <time> : note : ‘ ts ’ . / script / script . h : <number> <time> : error : parameter packs not expanded with ‘ . <repeated> ’ : ret = std : : forward <ts> ( input ) ; ~ ~ ~ ~ ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ . / script / script . h : <number> <time> : note : ‘ ts ’ makefile : <number> : recipe for target ' consensus / libbitcoinconsensus_la - merkle . lo ' failed make [ <number> <sad> * * * [ consensus / libbitcoinconsensus_la - merkle . lo ] error <number> . <repeated> makefile : <number> : recipe for target ' check - recursive ' failed make [ check - recursive ] error <number> what should i do now ? i just want to run the code # # # expected behaviour normal compilation # # # steps to reproduce . / autogen . sh . / configure nothing wrong # # # relevant log output _no response_ # # # how did you obtain bitcoin core compiled from source # # # what version of bitcoin core are you using ? lastest # # # operating system and version ubuntu <number> # # # machine specifications _no response_",2
bitcoin/bitcoin,"make it very obvious to the new people that the bitcoin core program first needs to be installed and run on the "" c "" drive . # # # issues , reports or feature requests related to the gui should be opened directly on the gui repo - [x ] i still think this issue should be opened here # # # report hello developers , i know that you probably think that this is so obvious and basic but it needs to be said . when a new person wants to run a full btc node on their computer for the first time can you make it very obvious to that person that the bitcoin core program needs to be downloaded and installed onto their "" c "" drive of their computer first . then that person will have the ability to sync up and store the btc blockchain to what every drive they intend , whether that be the "" d "" drive of their computer or an external hdd or ssd so that they can carry around the node with them . the problem i had was that i had downloaded and installed the bitcoin core program onto an external hdd , then i plugged that external hdd into my laptop thinking that it would just carry on syncing up , it did not because the bitcoin core program needs to be already installed on to the c drive of the laptop first , then i would need to point the program as to where it needs to sync up the data to ( in this case my external hdd or that i am not using up all of the space on the laptop ) . thanks",2
bitcoin/bitcoin,"error c3203 : ' uniquelock ' # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour when compiling the libbitcoin_node library in microsoft visual studio community <number> , version <date> got error c3203 : ' uniquelock ' : unspecialized class template can not be used as a template argument for template parameter ' _ty ' , expected a real type in the * * validationinterface . cpp * * file , code section : template < typename f > void iterate ( f & & f ) exclusive_locks_required ( m_mutex ) { wait_lock ( m_mutex , lock ) ; for ( auto it = m_list . begin ( ); it ! = m_list . end ( ); ) { + + it - > count ; { reverse_lock ( lock ) ; f ( * it - > callbacks ) ; } it = - - it - > count ? std : : next ( it ) : m_list . erase ( it ) ; } } line : ` reverse_lock ( lock ) ; ` reverse_lock macro in * * sync . h * * file : ` <hashtag> define </hashtag> reverse_lock ( g ) typename std : : decay < decltype ( g ) <sad> : type : : reverse_lock unique_name ( revlock ) ( g , <hashtag> g </hashtag> , __file__ , __line__ ) ` # # # expected behaviour the compilation problem was solved by adding a macro : ` <hashtag> define </hashtag> reverse_lock_ ( g ) typename uniquelock <mutex> : : reverse_lock unique_name ( revlock ) ( g , <hashtag> g </hashtag> , __file__ , __line__ ) ` with explicit ` typename uniquelock <mutex> : : reverse_lock ` instead of ` typename std : : decay < decltype ( g ) <sad> : type : : reverse_lock ` after which the ` reverse_lock ( lock ) ` call is changed to ` reverse_lock_ ( lock ) ` after compilation , run the test : ` test_bitcoin - - run_test = "" validationinterface_tests "" - - - checkaddrman = <number> - printtoconsole = <number> ` result errors detected ` # # # steps to reproduce before compiling in vs2019 , in the project configuration file * * common . init . vcxproj * * ` <platformtoolset> ` tag change to ` v142 ` # # # relevant log output _no response_ # # # how did you obtain bitcoin core compiled from source # # # what version of bitcoin core are you using ? v25 . <number> # # # operating system and version windows <number> # # # machine specifications _no response_",2
bitcoin/bitcoin,"master does not compile on macos x <number> high sierra hello guys , i am trying to compile the current master branch on a quite old macbook pro ( early <number> ) for which the latest supported os is mac os x <number> high sierra , and i am getting the following error : ` ` ` alessios - macbook - pro : src feeder $ make v = <number> g + + - std =c + + <number> - dhave_config_h - i . - i . <repeated> / src / config - u_fortify_source - d_fortify_source = <number> - dhave_build_info - xclang - internal - isystem / usr / local / include - dmac_osx - dobjc_old_dispatch_prototypes = <number> - dprovide_fuzz_main_function - i . - i . / minisketch / include - i . / secp256k1 / include - i . / univalue / include - i . / leveldb / include - wstack - protector - fstack - protector - all - wall - wextra - wgnu - wformat - wformat - security - wvla - wshadow - field - wthread - safety - wloop - analysis - wredundant - decls - wunused - member - function - wdate - time - wconditional - uninitialized - woverloaded - virtual - wunreachable - code - loop - increment - wimplicit - fallthrough - wdocumentation - wno - unused - parameter - wno - self - assign - g - o2 - mt bitcoind - bitcoind . o - md - mp - mf . deps / bitcoind - bitcoind . tpo - c - o bitcoind - bitcoind . o ` test - f ' bitcoind . cpp ' || echo ' . / ' ` bitcoind . cpp in file included from bitcoind . cpp : <number> : in file included from . / chainparams . h : <number> : in file included from . / kernel / chainparams . h : <number> : in file included from . / netaddress . h : <number> : . / util / strencodings . h : <time> : fatal error : ' charconv ' file not found <hashtag> include </hashtag> <charconv> ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ <number> error generated . make [ <number> <sad> * * * [ bitcoind - bitcoind . o ] error <number> make : * * * [ all - recursive ] error <number> ` ` ` i think this is a known issue , and seems to be related to an old compiler , that does not fully support c + + <number> ( and charconv , in particular ) my current compiler is an apple llvm <number> , that i would believe is not that old : ` ` ` alessios - macbook - pro : src feeder $ g + + - - version configured with : - - prefix <annoyed> library / developer / commandlinetools / usr - - with - gxx - include - dir <annoyed> usr / include / c + + / <number> . <number> apple llvm version <number> . <number> ( clang - <number> . <number> ) target : x86_64 - apple - darwin17 . <number> thread model : posix installeddir : / library / developer / commandlinetools / usr / bin ` ` ` does anybody know if macos <number> is not supported anymore and it ' s necessary to upgrade to a different release ? is it known if macos <number> catalina is supported ? ps also tried to install a newer version of gcc through brew , but this release of macos is not supported anymore , so i am just considering to change environment .",2
bitcoin/bitcoin,"wallet not loaded # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour suddenly wallet not loaded . i was resyncing blockchain ( now synced ) . the wallet is old and has balance . yesterday there was no problem . recently updated for v24 to v25 . all was working ok until today . node is not pruned . disk that blocks are stored is external toshiba with usb connection , i have just a soft link between . bitcoin / blocks to blocks at toshiba . i have repaired this disk a couple of times using windows disk tools . i did a repair because bitcoincore wanted to reindex blockchain . after the repair bitcoinore was ok ( not asking for reindex ) and continue syncing . tried this command : bitcoin - cli listaccounts and get error code method not found error message # # # expected behaviour load my wallet # # # steps to reproduce run bitcoin - qt or bitcoind , all working ok except wallet loading # # # relevant log output "" wallet disabled "" from bitcoind running messages # # # how did you obtain bitcoin core pre - built binaries # # # what version of bitcoin core are you using ? v25 . <number> # # # operating system and version fedora linux <number> # # # machine specifications intel 8 2 6 5 u i5 cpu / 1 6 g ram / samsung evo <number> ssd drive / external usb disk for blocks storage",2
bitcoin/bitcoin,"alternative read only paths for - blocksdir # # # please describe the feature you ' d like to see added . the blockchain is growing in size over the years . it would be nice to be able to store it accross multiple hard drives and specify additional blocksdirs that are meant for validation in full nodes . when the client writes a file , it is still written to the - blocksdir , always . when reading a file , it is first looked up in the - blocksdir . when it ' s not present there , it is looked up in the additional blocksdirs , in order as they are specified by the command line arguments . # # # is your feature related to a problem , if so please describe it . _no response_ # # # describe the solution you ' d like _no response_ # # # describe any alternatives you have considered combining multiple hard drives is possible using a raid , but these are prone to failure and would force the user to format their drives , which is possibly something that the user does not want to do . # # # please leave any additional context i think i would be able to implement this myself . however , i want to know if this feature is wanted or if i might have overlooked some existing possibility to achieve this and generally want to collect some feedback on this .",2
bitcoin/bitcoin,"indicate rbf replaceability , also after transactions have been confirmed # # # please describe the feature you ' d like to see added . wallet transactions retrieved with rpc should indicate rbf replaceability , also after they are confirmed . # # # is your feature related to a problem , if so please describe it . currently , rbf replaceability is set to a hard ' no ' if the transaction has any confirmations this makes it hard to figure out if this transaction has the rbf flag set . to determine this currently , the user would need to parse the raw transaction data and iterate over the transaction inputs , and inspect their sequence number . this is not something i think it ' s reasonable to expect people to do . # # # describe the solution you ' d like i ' d like the ` bip125 - replaceable ` field to indicate the rbf flag of the transaction , also after it has received confirmations . # # # describe any alternatives you have considered _no response_ # # # please leave any additional context _no response_",2
bitcoin/bitcoin,"compute ' short id ' when transaction joins mempool when a node receives a ` cmpctblock ` it has to verify to its check mempool in order to know whether it has all the required transactions to construct that block . if it does not , it will send ` getblocktxn ` to fetch the missing tx { s } . ` partiallydownloadedblock : : initdata ` shows we have to iterate the whole mempool in order to get the short id and do the verifications , see for ( size_t i = <number> ; i < pool - > vtxhashes . size ( ); i + + ) { uint64_t shortid = cmpctblock . getshortid ( pool - > vtxhashes [ i ] . first ) ; std : : unordered_map < uint64_t , uint16_t > : : iterator idit = shorttxids . find ( shortid ) ; if ( idit = shorttxids . end ( ) ) { if ( ! have_txn [ idit - > second ] ) { txn_available [ idit - > second ] = pool - > vtxhashes [ i ] . second - > getsharedtx ( ); have_txn [ idit - > second ] = true ; mempool_count + + ; } else { / / if we find two mempool txn that match the short id , just request it . / / this should be rare enough that the extra bandwidth does not matter , / / but eating a round - trip due to fillblock failure would be annoying if ( txn_available [ idit - > second ] ) { txn_available [ idit - > second ] . reset ( ); mempool_count - - ; } } } / / though ideally we ' d continue scanning for the two - txn - match - shortid case , / / the performance win of an early exit here is too good to pass up and worth / / the extra risk . if ( mempool_count = = shorttxids . size ( ) ) break ; } ` ` ` this means that every time we receive a compact block we have to iterate the whole mempool and calculate the "" short id "" s all over again . could not ` ctxmempool ` have a hashmap where we could store the transactions ' short id right after joining the mempool and remove it once the tx gets confirmed / out of mempool ?",2
bitcoin/bitcoin,"can not compile v24 . <number> # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour i am trying to install bitcoin core headless with wallet on raspi4 with raspi os installed on a bootable ssd . berkeley db <number> is installed as per this tutorial <url> when i try to compile the <number> . <number> branch , i only get as far as the configure command here : when i enter ( in the cloned bitcoin folder ) : ` . / configure cppflags = "" - i / usr / local / berkeleydb . <number> / include - o2 "" ldflags = "" - l / usr / local / berkeleydb . <number> / lib "" ` i get the following response : ` ` ` checking for pkg - config . <repeated> / usr / bin / pkg - config checking pkg - config is at least version <number> . <number> . <repeated> yes configure : error run / bin / bash build - aux / config . sub ` ` ` not sure why this is happening . when i look at the config file in the "" build - aux "" folder , it looks like the config file i updated previously when trying to solve a previous error with installing the berkeleydb . i am a bit out of my depth and would appreciate any help # # # expected behaviour bitcoin core compiles correctly # # # steps to reproduce setup raspi4 with raspi os installed on a bootable ssd install bdb <number> clone bitcoin repo <number> . <number> configure # # # relevant log output _no response_ # # # how did you obtain bitcoin core compiled from source # # # what version of bitcoin core are you using ? v24 . <number> # # # operating system and version raspberry os ( raspnode ) # # # machine specifications raspi 4 b 8 gb , 1 tb ssd",2
bitcoin/bitcoin,"build broken when enabling fuzzing on apple m1 hw using homebrew llvm . # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour i got same error in <url> # # # expected behaviour shoule be able to compolice fuzzer # # # steps to reproduce ` ` ` bash . / configure - - enable - fuzz - - with - sanitizers = fuzzer , address , undefined - - disable - asm cc <annoyed> opt / homebrew / opt / llvm / bin / clang cxx <annoyed> opt / homebrew / opt / llvm / bin / clang + + make making all in src cxxld test / fuzz / fuzz undefined symbols for architecture arm64 : "" crc32c : : extendarm64 ( unsigned int , unsigned char const * , unsigned long ) "" , referenced from : crc32c : : extend ( unsigned int , unsigned char const * , unsigned long ) in libcrc32c . a ( libcrc32c_a - crc32c . o ) ld : symbol ( s ) not found for architecture arm64 clang - <number> : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ test / fuzz / fuzz ] error <number> make [ <number> <sad> * * * [ all - recursive ] error <number> make : * * * [ all - recursive ] error <number> ` ` ` ` ` ` / opt / homebrew / opt / llvm / bin / clang - - version homebrew clang version <number> . <number> target : arm64 - apple - darwin22 . <number> thread model : posix installeddir : / opt / homebrew / opt / llvm / bin ` ` ` # # # relevant log output _no response_ # # # how did you obtain bitcoin core compiled from source # # # what version of bitcoin core are you using ? v24 . <number> # # # operating system and version macos ( 2 2 e261 ) # # # machine specifications chip apple m1 pro , 1 6 gb memory",2
bitcoin/bitcoin,"- fallbackfee should apply to estimatesmartfee # # # please describe the feature you ' d like to see added . ` - fallback ` fee is used by ` sendtoaddress ` to provide a fallback fee when sending transactions . however , this does not apply to ` estimatesmartfee ` , which still returns the error . # # # is your feature related to a problem , if so please describe it . the reason for this is because it ' s difficult to test client applications on regtest , that would use ` estimatesmartfee ` on mainnet , but because it requires a lot of transactions before ` estimatesmartfee ` to work , it ' s difficult . this related stack exchange question has had a bit of interest # # # describe the solution you ' d like see above . # # # describe any alternatives you have considered - a separate flag would also work , like ` fallbackestimatefee ` # # # please leave any additional context _no response_",2
bitcoin/bitcoin,"index : threadsanitizer : data race on vptr seen with master @ 2 2 0 0 0 8 6 0 4 f15d5078092dea28be3e3f7f11b6c8f on aarch64 ( with ` no_bdb = <number> ` ) . follow up from # <number> . see also # <number> . ` ` ` bash <number> - <number> - 2 8 t <time> . 8 8 2 2 9 5 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ dbwrapper . cpp : <number> ] [ cdbwrapper ] opened leveldb successfully <number> - <number> - 2 8 t <time> . 8 8 2 3 9 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ dbwrapper . cpp : <number> ] [ cdbwrapper ] using obfuscation key for / tmp / test_common_bitcoin core / 0 9 5 9 fba80d599fe246b0b5ced04b4d1ecd504db9812edbff4ada2d88c6b218ae / regtest / indexes / txindex : <number> <number> - <number> - 2 8 t <time> . 8 8 4 0 0 2 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ txindex ] [ util / thread . cpp : <number> ] [ tracethread ] txindex thread start test / txindex_tests . cpp ( <number> <sad> fatal error : in "" txindex_tests / txindex_initial_sync "" : critical check time_start + timeout_ms > gettimemillis ( ) has failed llvmsymbolizer : error reading file : no such file or directory make [ <number> <sad> * * * [ makefile : <number> : test / txindex_tests . cpp . test ] error <number> make [ <number> <sad> leaving directory ' / home / fedora / bitcoin / ci / scratch / build / bitcoin - aarch64 - unknown - linux - gnu / src ' make [ <number> <sad> * * * [ makefile : <number> : check - am ] error <number> make [ <number> <sad> leaving directory ' / home / fedora / bitcoin / ci / scratch / build / bitcoin - aarch64 - unknown - linux - gnu / src ' make [ <number> <sad> * * * [ makefile : <number> : check - recursive ] error <number> make [ <number> <sad> leaving directory ' / home / fedora / bitcoin / ci / scratch / build / bitcoin - aarch64 - unknown - linux - gnu / src ' make : * * * [ makefile : <number> : check - recursive ] error <number> = = = = = = = = = = = = = = = = = = warning : threadsanitizer : data race on vptr ( ctor / dtor vs virtual call ) ( pid = <number> ) write of size <number> at 0 xfffffee67968 by main thread : # <number> baseindex : : ~ baseindex ( ) src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xc54cc8 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> txindex : : ~ txindex ( ) src / index / txindex . cpp : <number> <time> ( test_bitcoin + 0 xc6daec ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> txindex_tests : : txindex_initial_sync : : test_method ( ) src / test / txindex_tests . cpp : <number> : <number> ( test_bitcoin + 0x 7 c281c ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> txindex_tests : : txindex_initial_sync_invoker ( ) src / test / txindex_tests . cpp : <number> : <number> ( test_bitcoin + 0x 7 c0f78 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : detail : : function : : void_function_invoker0 < void (* ) ( ) , void > : : invoke ( boost : : detail : : function : : function_buffer & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 2 b78e8 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : function0 <void> : : operator ( ) ( ) const / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 2 4 f35c ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : detail : : forward : : operator ( ) ( ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 2 4 f35c ) # <number> boost : : detail : : function : : function_obj_invoker0 < boost : : detail : : forward , int > : : invoke ( boost : : detail : : function : : function_buffer & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 2 4 f35c ) # <number> boost : : function0 <int> : : operator ( ) ( ) const / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 1 e3384 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> int boost : : detail : : do_invoke < boost : : shared_ptr < boost : : detail : : translator_holder_base > , boost : : function < int ( ) > > ( boost : : shared_ptr < boost : : detail : : translator_holder_base > const & , boost : : function < int ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 1 e3384 ) # <number> boost : : execution_monitor : : catch_signals ( boost : : function < int ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 1 e3384 ) # <number> boost : : execution_monitor : : execute ( boost : : function < int ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 1 e367c ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : execution_monitor : : vexecute ( boost : : function < void ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> : <number> ( test_bitcoin + 0x 1 dcec0 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : unit_test_monitor_t : : execute_and_translate ( boost : : function < void ( ) > const & , unsigned long ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / unit_test_monitor . ipp : <number> : <number> ( test_bitcoin + 0x 1 dcec0 ) # <number> boost : : unit_test : : framework : : state : : execute_test_tree ( unsigned long , unsigned long , boost : : unit_test : : framework : : state : : random_generator_helper const <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 2 0 cdfc ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : framework : : state : : execute_test_tree ( unsigned long , unsigned long , boost : : unit_test : : framework : : state : : random_generator_helper const <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 2 0 d128 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : framework : : state : : execute_test_tree ( unsigned long , unsigned long , boost : : unit_test : : framework : : state : : random_generator_helper const <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 2 0 d128 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : framework : : run ( unsigned long , bool ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 1 dbe64 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : unit_test_main ( boost : : unit_test : : test_suite * (* ) ( int , char * <wink> , int , char * <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / unit_test_main . ipp : <number> : <number> ( test_bitcoin + 0x 1 f57c8 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> main / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / unit_test_main . ipp : <number> <time> ( test_bitcoin + 0x 1 f5d74 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) previous read of size <number> at 0 xfffffee67968 by thread t4 : # <number> baseindex : : threadsync ( ) src / index / base . cpp : <number> <time> ( test_bitcoin + 0 xc55ba0 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> baseindex : : start ( <sad> : $ _0 : : operator ( ) ( ) const src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xc59324 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> decltype ( std : : declval < baseindex : : start ( <sad> : $ _0 & >()()) std : : __1 : : __invoke [ abi : v160000 ] < baseindex : : start ( <sad> : $ _0 & > ( baseindex : : start ( <sad> : $ _0 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> <time> ( test_bitcoin + 0 xc59324 ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < baseindex : : start ( <sad> : $ _0 & > ( baseindex : : start ( <sad> : $ _0 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( test_bitcoin + 0 xc59324 ) # <number> std : : __1 : : __function : : __alloc_func < baseindex : : start ( <sad> : $ _0 , std : : __1 : : allocator < baseindex : : start ( <sad> : $ _0 > , void ()>: : operator ( ) [ abi : v160000 ] ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0 xc59324 ) # <number> std : : __1 : : __function : : __func < baseindex : : start ( <sad> : $ _0 , std : : __1 : : allocator < baseindex : : start ( <sad> : $ _0 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0 xc59324 ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) [ abi : v160000 ] ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 cbd30 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 cbd30 ) # <number> util : : tracethread ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>) src / util / thread . cpp : <number> : <number> ( test_bitcoin + 0x 1 0 cbd30 ) # <number> decltype ( std : : declval < void (* ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>)>() ( std : : declval < std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > > ( ) , std : : declval < baseindex : : start ( <sad> : $ _0 > ())) std : : __1 : : __invoke [ abi : v160000 ] < void (* ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>), std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > , baseindex : : start ( <sad> : $ _0 > ( void (* & & ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>), std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > & & , baseindex : : start ( <sad> : $ _0 & & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> <time> ( test_bitcoin + 0 xc58e70 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> void std : : __1 : : __thread_execute [ abi : v160000 ] < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>), std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > , baseindex : : start ( <sad> : $ _0 , 2 ul , 3 ul > ( std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>), std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > , baseindex : : start ( <sad> : $ _0 > & , std : : __1 : : __tuple_indices < 2 ul , 3 ul > ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( test_bitcoin + 0 xc58e70 ) # <number> void * std : : __1 : : __thread_proxy [ abi : v160000 ] < std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>), std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > , baseindex : : start ( <sad> : $ _0 > > ( void <wink> / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( test_bitcoin + 0 xc58e70 ) location is stack of main thread . location is global ' ? <repeated> ' at 0 xfffffee4a000 ( [ stack ] + 0x 1 d968 ) thread t4 ' b - txindex ' ( tid = <number> , running ) created by main thread at : # <number> pthread_create <null> ( test_bitcoin + 0x 1 3 7 7 6 c ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> std : : __1 : : __libcpp_thread_create [ abi : v160000 ] ( unsigned long * , void * (* ) ( void <wink> , void <wink> / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __threading_support : <number> <time> ( test_bitcoin + 0 xc58b00 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> std : : __1 : : thread : : thread < void (* ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>), std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , baseindex : : start ( <sad> : $ _0 , void > ( void (* & & ) ( std : : __1 : : basic_string_view < char , std : : __1 : : char_traits <char> > , std : : __1 : : function < void ()>), std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , baseindex : : start ( <sad> : $ _0 & & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> <time> ( test_bitcoin + 0 xc58b00 ) # <number> baseindex : : start ( ) src / index / base . cpp : <number> <time> ( test_bitcoin + 0 xc58b00 ) # <number> txindex_tests : : txindex_initial_sync : : test_method ( ) src / test / txindex_tests . cpp : <number> : <number> ( test_bitcoin + 0x 7 c18d8 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> txindex_tests : : txindex_initial_sync_invoker ( ) src / test / txindex_tests . cpp : <number> : <number> ( test_bitcoin + 0x 7 c0f78 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : detail : : function : : void_function_invoker0 < void (* ) ( ) , void > : : invoke ( boost : : detail : : function : : function_buffer & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 2 b78e8 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : function0 <void> : : operator ( ) ( ) const / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 2 4 f35c ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : detail : : forward : : operator ( ) ( ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 2 4 f35c ) # <number> boost : : detail : : function : : function_obj_invoker0 < boost : : detail : : forward , int > : : invoke ( boost : : detail : : function : : function_buffer & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 2 4 f35c ) # <number> boost : : function0 <int> : : operator ( ) ( ) const / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / function / function_template . hpp : <number> <time> ( test_bitcoin + 0x 1 e3384 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> int boost : : detail : : do_invoke < boost : : shared_ptr < boost : : detail : : translator_holder_base > , boost : : function < int ( ) > > ( boost : : shared_ptr < boost : : detail : : translator_holder_base > const & , boost : : function < int ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 1 e3384 ) # <number> boost : : execution_monitor : : catch_signals ( boost : : function < int ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 1 e3384 ) # <number> boost : : execution_monitor : : execute ( boost : : function < int ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> <time> ( test_bitcoin + 0x 1 e367c ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : execution_monitor : : vexecute ( boost : : function < void ( ) > const & ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / execution_monitor . ipp : <number> : <number> ( test_bitcoin + 0x 1 dcec0 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : unit_test_monitor_t : : execute_and_translate ( boost : : function < void ( ) > const & , unsigned long ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / unit_test_monitor . ipp : <number> : <number> ( test_bitcoin + 0x 1 dcec0 ) # <number> boost : : unit_test : : framework : : state : : execute_test_tree ( unsigned long , unsigned long , boost : : unit_test : : framework : : state : : random_generator_helper const <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 2 0 cdfc ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : framework : : state : : execute_test_tree ( unsigned long , unsigned long , boost : : unit_test : : framework : : state : : random_generator_helper const <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 2 0 d128 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : framework : : state : : execute_test_tree ( unsigned long , unsigned long , boost : : unit_test : : framework : : state : : random_generator_helper const <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 2 0 d128 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : framework : : run ( unsigned long , bool ) / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / framework . ipp : <number> <time> ( test_bitcoin + 0x 1 dbe64 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> boost : : unit_test : : unit_test_main ( boost : : unit_test : : test_suite * (* ) ( int , char * <wink> , int , char * <wink> / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / unit_test_main . ipp : <number> : <number> ( test_bitcoin + 0x 1 f57c8 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) # <number> main / home / fedora / bitcoin / depends / aarch64 - unknown - linux - gnu / include / boost / test / impl / unit_test_main . ipp : <number> <time> ( test_bitcoin + 0x 1 f5d74 ) ( buildid : 4 e139378821749f690b2477a97607af03b8272e9 ) summary : threadsanitizer race on vptr ( ctor / dtor vs virtual call ) src / index / base . cpp : <number> : <number> in baseindex : : ~ baseindex ( ) = = = = = = = = = = = = = = = = = = real 3 0 m28 . 8 1 8 s user 0 m1 . 7 3 1 s sys 0 m1 . 8 7 4 s ` ` `",2
bitcoin/bitcoin,"bitcoind crashed , how to debug os : debian gnu / linux <number> ( bullseye ) available ram : ~ 3 gb i run ` bitcoind ` on the machine by ` ~ / bin / bitcoin - <number> / bin / bitcoind - daemon ` as ` root ` ( as this is a vm dedicated to ` bitcoind ` , no other ordinary users are added ) . i make local rpc calls relatively frequently ( up to 1 0 k calls per sec ) but only sequentially ( i . e . , the 2 nd rpc call is only made if the first rpc call returned ) . it usually works fine for a few days / weeks , then the process just disappears . the log is like the following ( the 2 nd part of the log is written by the new ` bitcoind ` process ) : ` ` ` <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 2 6 0 d63755c13802609649b30886a021edc108f724294 height = <number> version =0 x2c8d2000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 0 mib ( 8 9 6 4 3 2 txo ) <number> - <number> - 2 3 t <time> z new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( block - relay - only ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 9 4 2 9 7 1 4 9 fa2e2a5a8003335ec1f05bd5826e49286203 height = <number> version =0 x2ba92000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 2 mib ( 8 9 8 2 8 4 txo ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 bd51f8197b30b21799f42ac7bd305a5114c486bc6699 height = <number> version =0 x2aaa0000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 3 mib ( 8 9 8 5 5 4 txo ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 d9729560ddab94371c2d357d9b6e9eb9bdcccd7ef6ba height = <number> version =0 x20400000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 3 mib ( 8 9 8 9 7 7 txo ) <number> - <number> - 2 3 t <time> z new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( block - relay - only ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 3 a08e446a1493a97472fe2f110d8479b7107584b8ec5 height = <number> version =0 x2456e000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 4 mib ( 8 9 9 7 8 3 txo ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 5 9 b6d6e4f6e0b023f989b9049762f40a3efe622832e1 height = <number> version =0 x20084000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 0 mib ( 9 0 4 5 3 8 txo ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 d0f15e488c5205370c9ded96f3fdb40ac65238db6ad height = <number> version =0 x2001c000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 8 mib ( 9 1 1 0 9 4 txo ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 cbd091c3a153f2bcd918f9d08306a76c0ca93c105f8b height = <number> version =0 x20000000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 8 mib ( 9 1 0 9 2 3 txo ) <number> - <number> - 2 3 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 3 6 a430222ee553d9898c8f7f113f337372f6df2d0bb2 height = <number> version =0 x20e00000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 3 t <time> z ' progress = <number> cache = <number> . 0 mib ( 9 1 2 7 0 7 txo ) <number> - <number> - 2 3 t <time> z new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( block - relay - only ) <number> - <number> - 2 4 t <time> z bitcoin core version v22 . <number> ( release build ) <number> - <number> - 2 4 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 a89e854d57e5667df88f1cdef6fde2fbca1de5b639ad have valid signatures . <number> - <number> - 2 4 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 fa4663bbbe19f82de <phone> - <number> - 2 4 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) , avx2 ( 8 way ) ' sha256 implementation <number> - <number> - 2 4 t <time> z using rdseed as additional entropy source <number> - <number> - 2 4 t <time> z using rdrand as an additional entropy source <number> - <number> - 2 4 t <time> z default data directory / root / . bitcoin <number> - <number> - 2 4 t <time> z using data directory / mnt / bitcoin <number> - <number> - 2 4 t <time> z config file : / mnt / bitcoin / bitcoin . conf ( not found , skipping ) <number> - <number> - 2 4 t <time> z config file arg : datadir =""/ mnt / bitcoin / "" <number> - <number> - 2 4 t <time> z config file arg : rpcpassword = * * * * <number> - <number> - 2 4 t <time> z config file arg : rpcuser = * * * * <number> - <number> - 2 4 t <time> z config file arg : txindex = "" <number> "" <number> - <number> - 2 4 t <time> z config file arg : walletdir =""/ mnt / bitcoin / wallets / ak_wallet / "" <number> - <number> - 2 4 t <time> z command - line arg <number> - <number> - 2 4 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 2 4 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 2 4 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 2 4 t <time> z script verification uses <number> additional threads ` ` ` is there anyway for me to get debug info etc which could hopefully give me some hints on what exactly happened ?",2
bitcoin/bitcoin,"configure : error : cannot figure out how to use std : : filesystem got this error from ` configure ` when trying to build from tag ` v24 . <number> ` on ubuntu <number> . at first my gcc was version ` gcc version <number> . <number> ( ubuntu <number> . <number> - 3 ubuntu1 ~ <number> ) ` so i tried installing clang <number> : ` clang version <number> . <number> - 4 ubuntu1 ~ <number> . <number> ` and linked to ` cxx ` , etc . <repeated> still got the same error . ` ` ` $ uname - a linux party <number> . <number> - <number> - generic # <number> - ubuntu smp fri <date> <time> utc <number> x86_64 x86_64 x86_64 gnu / linux $ lsb_release - a no lsb modules are available . distributor id : ubuntu description : ubuntu <number> . <number> lts release : <number> codename : bionic ` ` ` complete output : ` ` ` $ . / configure - - without - gui - - with - incompatible - bdb checking for pkg - config . <repeated> / usr / bin / pkg - config checking pkg - config is at least version <number> . <number> . <repeated> yes checking build system type . <repeated> x86_64 - pc - linux - gnu checking host system type . <repeated> x86_64 - pc - linux - gnu checking for a bsd - compatible install . <repeated> / usr / bin / install - c checking whether build environment is sane . <repeated> yes checking for a thread - safe mkdir - p . <repeated> / bin / mkdir - p checking for gawk . <repeated> gawk checking whether make sets $( make ) . <repeated> yes checking whether make supports nested variables . <repeated> yes checking whether to enable maintainer - specific portions of makefiles . <repeated> yes checking whether make supports nested variables . <repeated> ( cached ) yes checking whether the c + + compiler works . <repeated> yes checking for c + + compiler default output file name . <repeated> a . out checking for suffix of executables . <repeated> checking whether we are cross compiling . <repeated> no checking for suffix of object files . <repeated> o checking whether we are using the gnu c + + compiler . <repeated> yes checking whether / usr / bin / clang + + - <number> accepts - g . <repeated> yes checking for style of include used by make . <repeated> gnu checking dependency style of / usr / bin / clang + + - <number> . <repeated> gcc3 checking whether / usr / bin / clang + + - <number> supports c + + <number> features with - std =c + + <number> . <repeated> yes checking whether std : : filesystem can be used without link library . <repeated> no checking whether std : : filesystem needs - lstdc + + fs . <repeated> no checking whether std : : filesystem needs - lc + + fs . <repeated> configure : error : in ` / root / bitcoin ' : configure : error figure out how to use std : : filesystem see ` config . log ' for more details ` ` `",2
bitcoin/bitcoin,"intermittent issue in p2p_ibd_stalling . py self . wait_until ( lambda : self . total_bytes_recv_for_blocks ( ) = = <number> ) ` ` ` wget <url> tar - xvf p2p_ibd_stalling_96 . tar . xz test / functional / combine_logs . py - c . / p2p_ibd_stalling_96 ` ` ` ` ` ` test <number> - <number> - 1 4 t <time> . 4 7 9 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / p2p_ibd_stalling . py "" , line <number> , in run_test self . wait_until ( lambda : self . total_bytes_recv_for_blocks ( ) = = <number> ) file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in wait_until return wait_until_helper ( test_function , timeout = timeout , timeout_factor = self . options . timeout_factor ) file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in wait_until_helper raise assertionerror ( "" predicate { } not true after { } seconds "" . format ( predicate_source , timeout ) ) assertionerror : predicate ' ' ' ' self . wait_until ( lambda = = <number> ) ' ' ' not true after <number> seconds",2
bitcoin/bitcoin,"changing the path of the . bitcoin folder hi , could someone please advise me how to change the path to the . bitcoin folder or what command to enter when running . / bitcoind to create a name other than . bitcoin",2
bitcoin/bitcoin,"no wallet command found hi bitcoiners < <number> , so my ras . pi <number> 8 gbs is coming in <number> days and tried to install bitcoin core on desktop , to practice a little . i downloaded <number> , newest version , compiled it from code here . <repeated> and there is no bitcoin - cli createwallet command . i wanted to create descriptor and play a little with bitcoin . conf walletnotify command . what did i do wrong ? do you have any recommendations . did i compile it wrong ( i read some configuration needs to be good ) or is it the problem with this new version ? thanks for any help . edit version would you recommend me ?",2
bitcoin/bitcoin,"building or loading the ms visual studio project issue to build msvs <number> , in the folder of source "" build_msvc "" cannot load or locate projects . common error for all project files : bitcoin - tx \ \ bitcoin - tx . vcxproj : error "" "" does not contain any configuration . [ image ] ( <url>",2
bitcoin/bitcoin,"` 2 8 e72909f1717fe9607754f8a7beb2621678d37d ` key not specified in builder keys and ` <number> ` release signed with it i would expect each key that signs new release to be included in ` contrib / builder - keys / keys . txt ` - am i wrong ? ` <number> ` is signed with ` 2 8 e72909f1717fe9607754f8a7beb2621678d37d ` < <email> > but this key is not included in ` keys . txt ` . if above is not true , where does one find all the keys that sign new releases ?",2
bitcoin/bitcoin,"[ msvc ] bitcoin build failed due to bitcoin \ \ src \ \ fs . h ( <number> <sad> error c2039 : ' u8string ' : is not a member of ' std ' with msvc option / c + + latest < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > recently , we updated the commit of bitcoin for msvc rwc testing , it failed to build due to the error like below with option / c + + latest , could you please help take a look ? thanks . ` ` ` bitcoin \ \ src \ \ fs . h ( <number> <sad> error c2039 : ' u8string ' : is not a member of ' std ' [ f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc \ \ libbitcoin_qt \ \ libbitcoin_qt . vcxproj ] c :\\ program files (x 8 6 ) \ \ microsoft visual studio \ \ <number> \ \ enterprise \ \ vc \ \ tools \ \ msvc \ \ <number> . <number> \ \ include \ \ filesystem ( <number> <sad> message : see declaration of ' std ' [ f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc \ \ libbitcoin_qt \ \ libbitcoin_qt . vcxproj ] ` ` ` * * expected behavior * * < ! - - - what behavior did you expect ? - - > build successfully . * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > ` ` ` bitcoin \ \ src \ \ fs . h ( <number> <sad> error c2039 : ' u8string ' : is not a member of ' std ' [ f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc \ \ libbitcoin_qt \ \ libbitcoin_qt . vcxproj ] c :\\ program files (x 8 6 ) \ \ microsoft visual studio \ \ <number> \ \ enterprise \ \ vc \ \ tools \ \ msvc \ \ <number> . <number> \ \ include \ \ filesystem ( <number> <sad> message : see declaration of ' std ' [ f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc \ \ libbitcoin_qt \ \ libbitcoin_qt . vcxproj ] ` ` ` * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > <number> . git clone <url> f :\\ gitp \ \ bitcoin \ \ bitcoin <number> . git - c "" f :\\ gitp \ \ bitcoin \ \ bitcoin "" fetch - - recurse - submodules = no - - force <number> . git - c "" f :\\ gitp \ \ bitcoin \ \ bitcoin "" reset - - hard 4 3 e813cab266eef42e622519836f171f6a18d426 <number> . set _cl_ = / std <sad> + + latest <number> . cd f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc <number> . py - <number> msvc - autogen . py <number> . set _cl_ = % _cl_ % / d_has_deprecated_allocator_members / d_silence_cxx20_u8path_deprecation_warning / zc : char8_t - / d_silence_cxx23_aligned_storage_deprecation_warning <number> . set the vcpkg info and run ` bootstrap - vcpkg . bat ` and ` vcpkg integrate install ` , in my environment , as follows : cd f :\\ gitp \ \ bitcoin \ \ tools \ \ vcpkg git - c "" f :\\ gitp \ \ bitcoin \ \ tools \ \ vcpkg "" clean - xdf bootstrap - vcpkg . bat set path = % cd % ; % path % vcpkg integrate install <number> . switch to the directory : cd f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc <number> . msbuild / m / p : platform =x 6 4 / p : configuration = release / p : platformtoolset = v142 bitcoin . sln / t : rebuild * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > the commit of bitcoin : 4 3 e813cab266eef42e622519836f171f6a18d426 < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > os : windows server <number> datacenter 2 1 h2 < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > detailed log",2
bitcoin/bitcoin,"getblockchaininfo . verificationprogress never reaching <number> < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * ` getblockchaininfo . verificationprogress ` is <number> when it is done syncing < ! - - - what behavior did you expect ? - - > * * actual behavior * * the highest value that ` getblockchaininfo . verificationprogress ` gets to is something like ` <number> ` . as a result , we can not rely on this value to determine if syncing is complete . we can not rely on ` getblockchaininfo . initialblockdownload ` either due to <url> < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * call ` getblockchaininfo ` on a synced node and observe that ` verificationprogress ` is < <number> . < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * version <number> of the bitcoin core binary , downloaded from the website < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",2
bitcoin/bitcoin,"the “ bitcoin peers implement a reputation - based protocol ” are exists ? when i reading the paper 《 bitcoin over tor isn ’ t a good idea 》 founding some introudce about bitcoin policy for anti - dos 。 in this paper ， seeing that bitcoin peers implement a reputation - based protocol with eachnode keeping a penalty score for every other bitcoin peer ( identified by its ip address ) . whenever a malformed message is sent to the node , the latter increases the penalty score of the sender and bans the “ misbehaving ” ip address for <number> hours when the penalty reaches the value of <number> . this paper published by <number> . i want konw it are outdated at now ？ thanks bro ！",2
bitcoin/bitcoin,"macos : make issue libsecp256k1_precomputed . a : no such file or directory < - - describe the issue - - > while building bitcoin core on macos monterey <number> an issue with libsecp256k1 occurred . while going through [ the steps in the instruction ] ( <url> could not proceed properly . * * expected behavior * * a regular building . * * actual behavior * * output of ` make ` is following : ` ` ` . / libtool : line <number> : cd : / users / * * * * */ * * * * */ * * * * * : no such file or directory . / libtool : line <number> : cd : . libs / libsecp256k1 . lax / libsecp256k1_precomputed . a : no such file or directory make [ <number> <sad> * * * [ libsecp256k1 . la ] error <number> make [ <number> <sad> * * * [ secp256k1 / libsecp256k1 . la ] error <number> make [ <number> <sad> * * * [ all - recursive ] error <number> make : * * * [ all - recursive ] error <number> ` ` ` < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * macos monterey <number> < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > i also had this output after running the command ` . / configure ` ( maybe it could be useful too ) ` ` ` checking for pkg - config . <repeated> / usr / local / bin / pkg - config checking pkg - config is at least version <number> . <number> . <repeated> yes checking build system type . <repeated> x86_64 - apple - darwin21 . <number> checking host system type . <repeated> x86_64 - apple - darwin21 . <number> checking for a bsd - compatible install . <repeated> / usr / bin / install - c checking whether build environment is sane . <repeated> yes checking for a race - free mkdir - p . <repeated> . / build - aux / install - sh - c - d checking for gawk . <repeated> no checking for mawk . <repeated> no checking for nawk . <repeated> no checking for awk . <repeated> awk checking whether make sets $( make ) . <repeated> yes checking whether make supports nested variables . <repeated> yes checking whether to enable maintainer - specific portions of makefiles . <repeated> yes checking whether make supports nested variables . <repeated> ( cached ) yes checking for g + + . <repeated> g + + checking whether the c + + compiler works . <repeated> yes checking for c + + compiler default output file name . <repeated> a . out checking for suffix of executables . <repeated> checking whether we are cross compiling . <repeated> no checking for suffix of object files . <repeated> o checking whether the compiler supports gnu c + + . <repeated> yes checking whether g + + accepts - g . <repeated> yes checking for g + + option to enable c + + <number> features . <repeated> none needed checking whether make supports the include directive . <repeated> yes ( gnu style ) checking dependency style of g + + . <repeated> gcc3 checking whether g + + supports c + + <number> features with - std =c + + <number> . <repeated> yes checking whether std : : filesystem can be used without link library . <repeated> yes checking whether the compiler supports gnu objective c + + . <repeated> yes checking whether g + + - std =c + + <number> accepts - g . <repeated> yes checking dependency style of g + + - std =c + + <number> . <repeated> gcc3 configure : warning : libtool does not cope well with whitespace in ` pwd ` checking how to print strings . <repeated> printf checking for gcc . <repeated> gcc checking whether the compiler supports gnu c . <repeated> yes checking whether gcc accepts - g . <repeated> yes checking for gcc option to enable c11 features . <repeated> none needed checking whether gcc understands - c and - o together . <repeated> yes checking dependency style of gcc . <repeated> gcc3 checking for a sed that does not truncate output . <repeated> / usr / local / bin / gsed checking for grep that handles long lines and - e . <repeated> / usr / bin / grep checking for egrep . <repeated> / usr / bin / grep - e checking for fgrep . <repeated> / usr / bin / grep - f checking for ld used by gcc . <repeated> / library / developer / commandlinetools / usr / bin / ld checking if the linker ( / library / developer / commandlinetools / usr / bin / ld ) is gnu ld . <repeated> no checking for bsd - or ms - compatible name lister ( nm ) . <repeated> / usr / bin / nm - b checking the name lister ( / usr / bin / nm - b ) interface . <repeated> bsd nm checking whether ln - s works . <repeated> yes checking the maximum length of command line arguments . <repeated> <number> checking how to convert x86_64 - apple - darwin21 . <number> file names to x86_64 - apple - darwin21 . <number> format . <repeated> func_convert_file_noop checking how to convert x86_64 - apple - darwin21 . <number> file names to toolchain format . <repeated> func_convert_file_noop checking for / library / developer / commandlinetools / usr / bin / ld option to reload object files . <repeated> - r checking for file . <repeated> file checking for objdump . <repeated> objdump checking how to recognize dependent libraries . <repeated> pass_all checking for dlltool . <repeated> no checking how to associate runtime and link libraries . <repeated> printf %s \ \ n checking for ar . <repeated> ar checking for archiver <user> support . <repeated> no checking for strip . <repeated> strip checking for ranlib . <repeated> ranlib checking command to parse / usr / bin / nm - b output from gcc object . <repeated> ok checking for sysroot . <repeated> no checking for a working dd . <repeated> / bin / dd checking how to truncate binary pipes . <repeated> / bin / dd bs = <number> count = <number> checking for mt . <repeated> no checking if : is a manifest tool . <repeated> no checking for dsymutil . <repeated> dsymutil checking for nmedit . <repeated> nmedit checking for lipo . <repeated> lipo checking for otool . <repeated> otool checking for otool64 . <repeated> no checking for - single_module linker flag . <repeated> yes checking for - exported_symbols_list linker flag . <repeated> yes checking for - force_load linker flag . <repeated> yes checking for stdio . h . <repeated> yes checking for stdlib . h . <repeated> yes checking for string . h . <repeated> yes checking for inttypes . h . <repeated> yes checking for stdint . h . <repeated> yes checking for strings . h . <repeated> yes checking for sys / stat . h . <repeated> yes checking for sys / types . h . <repeated> yes checking for unistd . h . <repeated> yes checking for dlfcn . h . <repeated> yes checking for objdir . <repeated> . libs checking if gcc supports - fno - rtti - fno - exceptions . <repeated> yes checking for gcc option to produce pic . <repeated> - fno - common - dpic checking if gcc pic flag - fno - common - dpic works . <repeated> yes checking if gcc static flag - static works . <repeated> no checking if gcc supports - c - o file . o . <repeated> yes checking if gcc supports - c - o file . o . <repeated> ( cached ) yes checking whether the gcc linker ( / library / developer / commandlinetools / usr / bin / ld ) supports shared libraries . <repeated> yes checking dynamic linker characteristics . <repeated> darwin21 . <number> dyld checking how to hardcode library paths into programs . <repeated> immediate checking whether stripping libraries is possible . <repeated> yes checking if libtool supports shared libraries . <repeated> yes checking whether to build shared libraries . <repeated> yes checking whether to build static libraries . <repeated> yes checking how to run the c + + preprocessor . <repeated> g + + - std =c + + <number> - e checking for ld used by g + + - std =c + + <number> . <repeated> / library / developer / commandlinetools / usr / bin / ld checking if the linker ( / library / developer / commandlinetools / usr / bin / ld ) is gnu ld . <repeated> no checking whether the g + + - std =c + + <number> linker ( / library / developer / commandlinetools / usr / bin / ld ) supports shared libraries . <repeated> yes checking for g + + - std =c + + <number> option to produce pic . <repeated> - fno - common - dpic checking if g + + - std =c + + <number> pic flag - fno - common - dpic works . <repeated> yes checking if g + + - std =c + + <number> static flag - static works . <repeated> no checking if g + + - std =c + + <number> supports - c - o file . o . <repeated> yes checking if g + + - std =c + + <number> supports - c - o file . o . <repeated> ( cached ) yes checking whether the g + + - std =c + + <number> linker ( / library / developer / commandlinetools / usr / bin / ld ) supports shared libraries . <repeated> yes checking dynamic linker characteristics . <repeated> darwin21 . <number> dyld checking how to hardcode library paths into programs . <repeated> immediate checking for ar . <repeated> / usr / bin / ar checking for gcov . <repeated> / usr / bin / gcov checking for llvm - cov . <repeated> no checking for lcov . <repeated> no checking for python3 . <number> . <repeated> no checking for python3 . <number> . <repeated> / users / * * * * */ . pyenv / shims / python3 . <number> checking for genhtml . <repeated> no checking for git . <repeated> / usr / bin / git checking for ccache . <repeated> no checking for xgettext . <repeated> / usr / local / bin / xgettext checking for hexdump . <repeated> / usr / bin / hexdump checking for objcopy . <repeated> no checking for doxygen . <repeated> no checking whether c + + compiler accepts - werror . <repeated> yes checking whether the linker accepts - wl , - fatal_warnings . <repeated> yes checking whether c + + compiler accepts - wall . <repeated> yes checking whether c + + compiler accepts - wextra . <repeated> yes checking whether c + + compiler accepts - wgnu . <repeated> yes checking whether c + + compiler accepts - wformat - wformat - security . <repeated> yes checking whether c + + compiler accepts - wvla . <repeated> yes checking whether c + + compiler accepts - wshadow - field . <repeated> yes checking whether c + + compiler accepts - wthread - safety . <repeated> yes checking whether c + + compiler accepts - wloop - analysis . <repeated> yes checking whether c + + compiler accepts - wredundant - decls . <repeated> yes checking whether c + + compiler accepts - wunused - member - function . <repeated> yes checking whether c + + compiler accepts - wdate - time . <repeated> yes checking whether c + + compiler accepts - wconditional - uninitialized . <repeated> yes checking whether c + + compiler accepts - wduplicated - branches . <repeated> no checking whether c + + compiler accepts - wduplicated - cond . <repeated> no checking whether c + + compiler accepts - wlogical - op . <repeated> no checking whether c + + compiler accepts - woverloaded - virtual . <repeated> yes checking whether c + + compiler accepts - wsuggest - override . <repeated> yes checking whether c + + compiler accepts - wunreachable - code - loop - increment . <repeated> yes checking whether c + + compiler accepts - wimplicit - fallthrough . <repeated> yes checking whether c + + compiler accepts - wunused - parameter . <repeated> yes checking whether c + + compiler accepts - wself - assign . <repeated> yes checking whether c + + compiler accepts - wdeprecated - copy . <repeated> yes checking whether c + + compiler accepts - fno - extended - identifiers . <repeated> no checking whether c + + compiler accepts - msse4 . <number> . <repeated> yes checking whether c + + compiler accepts - msse4 . <number> . <repeated> yes checking whether c + + compiler accepts - mavx - mavx2 . <repeated> yes checking whether c + + compiler accepts - msse4 - msha . <repeated> yes checking whether c + + compiler accepts - mpclmul . <repeated> yes checking for sse4 . <number> intrinsics . <repeated> yes checking for sse4 . <number> intrinsics . <repeated> yes checking for avx2 intrinsics . <repeated> yes checking for x86 sha - ni intrinsics . <repeated> yes checking whether c + + compiler accepts - march = armv8 - a + crc . <repeated> no checking whether c + + compiler accepts - march = armv8 - a + crypto . <repeated> no checking for armv8 crc32 intrinsics . <repeated> no checking for armv8 sha - ni intrinsics . <repeated> no checking for brew . <repeated> brew checking whether the linker accepts - wl , - headerpad_max_install_names . <repeated> yes checking whether byte ordering is bigendian . <repeated> no checking how to run the c preprocessor . <repeated> gcc - e checking whether gcc is clang . <repeated> yes checking whether pthreads work with "" - pthread "" and "" - lpthread "" . <repeated> yes checking whether clang needs flag to prevent "" argument unused "" warning when linking with - pthread . <repeated> no checking for joinable pthread attribute . <repeated> pthread_create_joinable checking whether more special flags are required for pthreads . <repeated> no checking for pthread_prio_inherit . <repeated> yes checking whether std : : atomic can be used without link library . <repeated> yes checking for special c compiler options needed for large files . <repeated> no checking for _file_offset_bits value needed for large files . <repeated> no checking for g + + - std =c + + <number> options needed to detect all undeclared functions . <repeated> none needed checking whether strerror_r is declared . <repeated> yes checking whether strerror_r returns char * . <repeated> no checking for library containing clock_gettime . <repeated> none required checking whether c + + compiler accepts - fpic . <repeated> yes checking whether c + + compiler accepts - fstack - reuse = none . <repeated> no checking whether c + + compiler accepts - wstack - protector . <repeated> yes checking whether c + + compiler accepts - fstack - protector - all . <repeated> yes checking whether c + + compiler accepts - fcf - protection = full . <repeated> yes checking whether c + + compiler accepts - fstack - clash - protection . <repeated> no checking whether c + + preprocessor accepts - d_fortify_source = <number> . <repeated> yes checking whether c + + preprocessor accepts - u_fortify_source . <repeated> yes checking whether the linker accepts - wl , - - enable - reloc - section . <repeated> no checking whether the linker accepts - wl , - - dynamicbase . <repeated> no checking whether the linker accepts - wl , - - nxcompat . <repeated> no checking whether the linker accepts - wl , - - high - entropy - va . <repeated> no checking whether the linker accepts - wl , - z , relro . <repeated> no checking whether the linker accepts - wl , - z , now . <repeated> no checking whether the linker accepts - wl , - z , separate - code . <repeated> no checking whether the linker accepts - fpie - pie . <repeated> no checking whether the linker accepts - wl , - dead_strip . <repeated> yes checking whether the linker accepts - wl , - dead_strip_dylibs . <repeated> yes checking whether the linker accepts - wl , - bind_at_load . <repeated> yes checking for endian . h . <repeated> no checking for sys / endian . h . <repeated> no checking for byteswap . h . <repeated> no checking for unistd . h . <repeated> ( cached ) yes checking for sys / types . h . <repeated> ( cached ) yes checking for sys / stat . h . <repeated> ( cached ) yes checking for sys / select . h . <repeated> yes checking for sys / prctl . h . <repeated> no checking for sys / sysctl . h . <repeated> yes checking for vm / vm_param . h . <repeated> no checking for sys / vmmeter . h . <repeated> yes checking for sys / resources . h . <repeated> no checking whether getifaddrs is declared . <repeated> yes checking whether ifaddrs funcs can be used without link library . <repeated> yes checking whether freeifaddrs is declared . <repeated> yes checking whether ifaddrs funcs can be used without link library . <repeated> yes checking whether fork is declared . <repeated> yes checking whether setsid is declared . <repeated> yes checking whether pipe2 is declared . <repeated> no checking for timingsafe_bcmp . <repeated> yes checking whether le16toh is declared . <repeated> no checking whether le32toh is declared . <repeated> no checking whether le64toh is declared . <repeated> no checking whether htole16 is declared . <repeated> no checking whether htole32 is declared . <repeated> no checking whether htole64 is declared . <repeated> no checking whether be16toh is declared . <repeated> no checking whether be32toh is declared . <repeated> no checking whether be64toh is declared . <repeated> no checking whether htobe16 is declared . <repeated> no checking whether htobe32 is declared . <repeated> no checking whether htobe64 is declared . <repeated> no checking whether bswap_16 is declared . <repeated> no checking whether bswap_32 is declared . <repeated> no checking whether bswap_64 is declared . <repeated> no checking for __builtin_clzl . <repeated> yes checking for __builtin_clzll . <repeated> yes checking for getmemoryinfo . <repeated> no checking for mallopt m_arena_max . <repeated> no checking for posix_fallocate . <repeated> no checking for default visibility attribute . <repeated> yes checking for dllexport attribute . <repeated> no checking for thread_local support . <repeated> yes checking for gmtime_r . <repeated> yes checking for linux getrandom syscall . <repeated> no checking for getentropy via random . h . <repeated> yes checking for sysctl . <repeated> yes checking for sysctl kern_arnd . <repeated> no checking for if type char equals int8_t . <repeated> no checking for fdatasync . <repeated> no checking for f_fullfsync . <repeated> yes checking for o_cloexec . <repeated> yes checking for __builtin_prefetch . <repeated> yes checking for _mm_prefetch . <repeated> yes checking for strong getauxval support in the system headers . <repeated> no checking for std : : system . <repeated> yes checking for : : _wsystem . <repeated> no checking for qt5core >= <number> . <number> . <repeated> yes checking for qt5gui >= <number> . <number> . <repeated> yes checking for qt5widgets >= <number> . <number> . <repeated> yes checking for qt5network >= <number> . <number> . <repeated> yes checking for qt5test >= <number> . <number> . <repeated> yes checking for qt5dbus >= <number> . <number> . <repeated> yes checking for static qt . <repeated> no checking whether - fpie can be used with this qt config . <repeated> yes checking for moc - qt5 . <repeated> no checking for moc5 . <repeated> no checking for moc . <repeated> / usr / local / cellar / qt <user> / <number> . <number> / bin / moc checking for uic - qt5 . <repeated> no checking for uic5 . <repeated> no checking for uic . <repeated> / usr / local / cellar / qt <user> / <number> . <number> / bin / uic checking for rcc - qt5 . <repeated> no checking for rcc5 . <repeated> no checking for rcc . <repeated> / usr / local / cellar / qt <user> / <number> . <number> / bin / rcc checking for lrelease - qt5 . <repeated> no checking for lrelease5 . <repeated> no checking for lrelease . <repeated> / usr / local / cellar / qt <user> / <number> . <number> / bin / lrelease checking for lupdate - qt5 . <repeated> no checking for lupdate5 . <repeated> no checking for lupdate . <repeated> / usr / local / cellar / qt <user> / <number> . <number> / bin / lupdate checking for lconvert - qt5 . <repeated> no checking for lconvert5 . <repeated> no checking for lconvert . <repeated> / usr / local / cellar / qt <user> / <number> . <number> / bin / lconvert checking whether the linker accepts - framework foundation - framework appkit . <repeated> yes checking whether to build bitcoin core gui . <repeated> yes ( qt5 ) checking whether main function is needed for fuzz binary . <repeated> checking whether the linker accepts . <repeated> no yes checking for __builtin_mul_overflow . <repeated> yes checking for sqlite3 >= <date> . <repeated> yes checking whether to build wallet with support for sqlite . <repeated> yes checking whether userspace , statically defined tracing tracepoints are supported . <repeated> no checking for miniupnpc / miniupnpc . h . <repeated> no checking for miniupnpc / upnpcommands . h . <repeated> no checking for miniupnpc / upnperrors . h . <repeated> no checking for natpmp . h . <repeated> no checking for boostlib >= <number> . <number> ( <number> ) . <repeated> yes checking whether boost . process can be used . <repeated> yes checking for seccomp - bpf ( linux x86 - <number> ) . <repeated> no checking for libevent >= <number> . <number> . <repeated> yes checking for libevent_pthreads >= <number> . <number> . <repeated> yes checking if evhttp_connection_get_peer expects const char * * . <repeated> no checking for libqrencode . <repeated> yes checking for libzmq >= <number> . <repeated> yes checking for libmultiprocess . <repeated> no checking whether to build bitcoind . <repeated> yes checking whether to build bitcoin - cli . <repeated> yes checking whether to build bitcoin - tx . <repeated> yes checking whether to build bitcoin - wallet . <repeated> yes checking whether to build bitcoin - util . <repeated> yes checking whether to build experimental bitcoin - chainstate . <repeated> no checking whether to build libraries . <repeated> yes checking if ccache should be used . <repeated> no checking if wallet should be enabled . <repeated> yes checking whether to build with support for upnp . <repeated> no checking whether to build with support for nat - pmp . <repeated> no checking whether to build gui with support for d - bus . <repeated> yes checking whether to build gui with support for qr codes . <repeated> yes checking whether to build test_bitcoin - qt . <repeated> yes checking whether to build test_bitcoin . <repeated> yes checking whether to reduce exports . <repeated> no checking that generated files are newer than configure . <repeated> done configure : creating . / config . status config . status : creating libbitcoinconsensus . pc config . status : creating makefile config . status : creating src / makefile config . status : creating doc / man / makefile config . status : creating share / setup . nsi config . status : creating share / qt / info . plist config . status : creating test / config . ini config . status : creating contrib / devtools / split - debug . sh config . status : creating src / config / bitcoin - config . h config . status : src / config / bitcoin - config . h is unchanged config . status : executing depfiles commands config . status : executing libtool commands = = = configuring in src / secp256k1 ( / users / * * * * */ * * * * */ * * * * */ * * * * */ src / secp256k1 ) configure : running / bin / sh . / configure - - disable - option - checking ' - - prefix <annoyed> usr / local ' ' pythonpath <annoyed> users / * * * * * */ * * * * * */ spark - <number> . <number> - bin - hadoop3s / python / lib / py4j - <number> . <number> - src . zip <annoyed> users / * * * * * */ * * * * * */ spark - <number> . <number> - bin - hadoop3s / python / : ' ' - - disable - shared ' ' - - with - pic ' ' - - enable - benchmark = no ' ' - - enable - module - recovery ' ' - - enable - module - schnorrsig ' - - cache - file <annoyed> dev / null - - srcdir = . checking build system type . <repeated> x86_64 - apple - darwin21 . <number> checking host system type . <repeated> x86_64 - apple - darwin21 . <number> checking for a bsd - compatible install . <repeated> / usr / bin / install - c checking whether build environment is sane . <repeated> yes checking for a race - free mkdir - p . <repeated> . / build - aux / install - sh - c - d checking for gawk . <repeated> no checking for mawk . <repeated> no checking for nawk . <repeated> no checking for awk . <repeated> awk checking whether make sets $( make ) . <repeated> yes checking whether make supports nested variables . <repeated> yes checking whether make supports nested variables . <repeated> ( cached ) yes checking for gcc . <repeated> gcc checking whether the c compiler works . <repeated> yes checking for c compiler default output file name . <repeated> a . out checking for suffix of executables . <repeated> checking whether we are cross compiling . <repeated> no checking for suffix of object files . <repeated> o checking whether the compiler supports gnu c . <repeated> yes checking whether gcc accepts - g . <repeated> yes checking for gcc option to enable c11 features . <repeated> none needed checking whether gcc understands - c and - o together . <repeated> yes checking whether make supports the include directive . <repeated> yes ( gnu style ) checking dependency style of gcc . <repeated> gcc3 checking dependency style of gcc . <repeated> gcc3 checking for ar . <repeated> ar checking the archiver ( ar ) interface . <repeated> ar configure : warning : libtool does not cope well with whitespace in ` pwd ` checking how to print strings . <repeated> printf checking for a sed that does not truncate output . <repeated> / usr / local / bin / gsed checking for grep that handles long lines and - e . <repeated> / usr / bin / grep checking for egrep . <repeated> / usr / bin / grep - e checking for fgrep . <repeated> / usr / bin / grep - f checking for ld used by gcc . <repeated> / library / developer / commandlinetools / usr / bin / ld checking if the linker ( / library / developer / commandlinetools / usr / bin / ld ) is gnu ld . <repeated> no checking for bsd - or ms - compatible name lister ( nm ) . <repeated> / usr / bin / nm - b checking the name lister ( / usr / bin / nm - b ) interface . <repeated> bsd nm checking whether ln - s works . <repeated> yes checking the maximum length of command line arguments . <repeated> <number> checking how to convert x86_64 - apple - darwin21 . <number> file names to x86_64 - apple - darwin21 . <number> format . <repeated> func_convert_file_noop checking how to convert x86_64 - apple - darwin21 . <number> file names to toolchain format . <repeated> func_convert_file_noop checking for / library / developer / commandlinetools / usr / bin / ld option to reload object files . <repeated> - r checking for file . <repeated> file checking for objdump . <repeated> objdump checking how to recognize dependent libraries . <repeated> pass_all checking for dlltool . <repeated> no checking how to associate runtime and link libraries . <repeated> printf %s \ \ n checking for archiver <user> support . <repeated> no checking for strip . <repeated> strip checking for ranlib . <repeated> ranlib checking command to parse / usr / bin / nm - b output from gcc object . <repeated> ok checking for sysroot . <repeated> no checking for a working dd . <repeated> / bin / dd checking how to truncate binary pipes . <repeated> / bin / dd bs = <number> count = <number> checking for mt . <repeated> no checking if : is a manifest tool . <repeated> no checking for dsymutil . <repeated> dsymutil checking for nmedit . <repeated> nmedit checking for lipo . <repeated> lipo checking for otool . <repeated> otool checking for otool64 . <repeated> no checking for - single_module linker flag . <repeated> yes checking for - exported_symbols_list linker flag . <repeated> yes checking for - force_load linker flag . <repeated> yes checking for stdio . h . <repeated> yes checking for stdlib . h . <repeated> yes checking for string . h . <repeated> yes checking for inttypes . h . <repeated> yes checking for stdint . h . <repeated> yes checking for strings . h . <repeated> yes checking for sys / stat . h . <repeated> yes checking for sys / types . h . <repeated> yes checking for unistd . h . <repeated> yes checking for dlfcn . h . <repeated> yes checking for objdir . <repeated> . libs checking if gcc supports - fno - rtti - fno - exceptions . <repeated> yes checking for gcc option to produce pic . <repeated> - fno - common - dpic checking if gcc pic flag - fno - common - dpic works . <repeated> yes checking if gcc static flag - static works . <repeated> no checking if gcc supports - c - o file . o . <repeated> yes checking if gcc supports - c - o file . o . <repeated> ( cached ) yes checking whether the gcc linker ( / library / developer / commandlinetools / usr / bin / ld ) supports shared libraries . <repeated> yes checking dynamic linker characteristics . <repeated> darwin21 . <number> dyld checking how to hardcode library paths into programs . <repeated> immediate checking whether stripping libraries is possible . <repeated> yes checking if libtool supports shared libraries . <repeated> yes checking whether to build shared libraries . <repeated> no checking whether to build static libraries . <repeated> yes checking for brew . <repeated> brew checking if gcc supports - werror = unknown - warning - option . <repeated> yes checking if gcc supports - std =c 8 9 - pedantic - wno - long - long - wnested - externs - wshadow - wstrict - prototypes - wundef . <repeated> yes checking if gcc supports - wno - overlength - strings . <repeated> yes checking if gcc supports - wall . <repeated> yes checking if gcc supports - wno - unused - function . <repeated> yes checking if gcc supports - wextra . <repeated> yes checking if gcc supports - wcast - align . <repeated> yes checking if gcc supports - wcast - align = strict . <repeated> no checking if gcc supports - wconditional - uninitialized . <repeated> yes checking if gcc supports - fvisibility = hidden . <repeated> yes checking for x86_64 assembly availability . <repeated> yes checking that generated files are newer than configure . <repeated> done configure : creating . / config . status config . status : creating makefile config . status : creating libsecp256k1 . pc config . status : creating src / libsecp256k1 - config . h config . status : src / libsecp256k1 - config . h is unchanged config . status : executing depfiles commands config . status : executing libtool commands build options : with external callbacks = no with benchmarks = no with tests = yes with coverage = no with examples = no module ecdh = no module recovery = yes module extrakeys = yes module schnorrsig = yes asm = x86_64 ecmult window size = <number> ecmult gen prec . bits = <number> valgrind = no cc = gcc cppflags = secp_cflags = - o2 - std =c 8 9 - pedantic - wno - long - long - wnested - externs - wshadow - wstrict - prototypes - wundef - wno - overlength - strings - wall - wno - unused - function - wextra - wcast - align - wconditional - uninitialized - fvisibility = hidden cflags = - g - o2 ldflags = options used to compile and link signer = yes multiprocess = no with experimental syscall sandbox support = no with libs = yes with wallet = yes with sqlite = yes with bdb = yes with gui / qt = yes with qr = yes with zmq = yes with test = yes with fuzz binary = yes with bench = yes with upnp = no with natpmp = no use asm = yes usdt tracing = no sanitizers = debug enabled = no gprof enabled = no werror = no lto = no target os = darwin21 . <number> build os = darwin21 . <number> cc = gcc cflags = - pthread - g - o2 cppflags = - u_fortify_source - d_fortify_source = <number> - dhave_build_info - dmac_osx - dobjc_old_dispatch_prototypes = <number> - dprovide_fuzz_main_function cxx = g + + - std =c + + <number> cxxflags = - wstack - protector - fstack - protector - all - fcf - protection = full - wall - wextra - wgnu - wformat - wformat - security - wvla - wshadow - field - wthread - safety - wrange - loop - analysis - wredundant - decls - wunused - member - function - wdate - time - wconditional - uninitialized - woverloaded - virtual - wsuggest - override - wunreachable - code - loop - increment - wimplicit - fallthrough - wno - unused - parameter - wno - self - assign - wno - deprecated - copy - g - o2 ldflags = - lpthread - wl , - bind_at_load - wl , - headerpad_max_install_names - wl , - dead_strip - wl , - dead_strip_dylibs ar = / usr / bin / ar arflags = cr ` ` ` any help would be appreciated !",2
bitcoin/bitcoin,why createwallet command not work in compiled bitcoin core i compiled bitcoin core version <number> with berkeleydb <date> when i call . / bitcoin - cli createwallet mywallet . it show method not found . am i missing wallet support ? why ?,2
bitcoin/bitcoin,"error code - <number> . how to fix is ? hi there . i installed bitcoin core version v . <number> . <number> from source code , then create test wallet : ` bitcoin - cli createwallet "" testwallet "" ` it worked , wallet created . but , when i trying using command dumpwallet , sethdseed . <repeated> etc it ' s not work . i see error : ` error code : - <number> error message legacy wallets are supported by this command ` why i see this error , and how to fix it ?",2
bitcoin/bitcoin,"bitcoin - cli does ' nt have any method . error - <number> i have installed bitcoin core running on my local machine . ( linux ubuntu <number> lts ) i want to create a new address , wallet using bitcoin - cli , executing a command as follows then an error message was displayed . how can i solve it ? bitcoin - cli createwallet ( or etc . <repeated> ) error code : - <number> error message not found i try to use bitcoin - cli and rpc curl , but nothing",2
bitcoin/bitcoin,"bitcoin - cli : compiled without bdb support ( required for legacy wallets ) i have installed bitcoin core following the official github docs . ( <url> i have the berkeley - db4 installed . however , when i run this command ` . / bitcoin - cli - named createwallet wallet_name = alice descriptors = false passphrase = alice ` i get this error : ` ` ` error code : - <number> error message without bdb support ( required for legacy wallets ) ` ` ` can someone help me understand what is being missed here ?",2
bitcoin/bitcoin,"[ arch ] bitcoin stalls randomly , pegs a thread until manually stopped < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > i was told to open an issue here . i have been having a really annoying issue with my bitcoin client that i cant find the solution to . randomly , my bitcoin peer will start failing to send requests . at the same time , it pegs an entire thread , and it will stay that way until i intervene and restart it . i have tried everything , even using a different computer with the default config ( other than ` debug = <number> ` ) . i can not seem to find anyone else having my issue , and nothing in my logs stands out to me . something to note , when i did my test with the default config , i used bitcoin - qt to monitor , and it was still saying it was connected to <number> peers , although i couldnt add or remove any . * * expected behavior * * i expect my bitcoin node to stay up without me needing to intervene . * * actual behavior * * my node instead stalls and pegs a thread . * * to reproduce * * i can reproduce it every time i start my client , although it will randomly occur within an observed 4 hr - 4 8 hr window . * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > main peer : - os : endeavouros linux x86_64 - host : macbookair7 , <number> <number> - kernel : <number> . <number> - zen1 - <number> - zen - cpu : intel i5 - 5 3 5 0 u @ <number> . 9 0 0 ghz - bitcoin core v23 . <number> ( self - compiled ) , used bitcoind - wm : none ( headless ) clean test peer : - os : endeavouros linux x86_64 - host : macbookpro16 , <number> <number> - kernel : <date> - arch1 - cpu : intel i5 - 1 0 3 8 ng7 @ <number> . 8 0 0 ghz - bitcoin core v23 . <number> ( downloaded from github releases ) , used bitcoin - qt - wm : i3 - graphical shell < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > * logs <emphasis> * [ full logs for both machines are here . ] ( <url>",2
bitcoin/bitcoin,"lambda function in src / script / miniscript . h : <number> : asserts ( ) on invalid input script ( if compiled in debug mode ) , but does not return a valid string otherwise some possibly invalid input miniscripts may cause the miniscript evaluator to misbehave when compiling in debug mode , at least we get an assertion failure ( the program will crash and exit ) . - when compiling in the release , that function may return some random std : : string reference , causing ub . see the lamda fucntion starting on src / script / miniscript . h : <number> . detected by gcc during compilation with - wreturn - type . but as it is in a lambda , itself hidden in a template , it was hard to see at the location indicated ( which is just the 1 st line of the lambda missing some valid return ) . so the final ` assert ( false ) ; ` is insufficient , it should at least be an exception that can be caught , or some valid string such as "" "" ( depending on the expected semantics ) .",2
bitcoin/bitcoin,"continued from closed # <number> . / configure and installing llvm thanks to everyone and especially _fanquake_ for the help . here we go . <repeated> this is a bug continued from . / configure when installing ` brew install llvm ` i get a string of this : : ` ` ` ==> llvm : stable <number> . <number> , head [ keg - only ] next - gen compiler infrastructure <url> not installed from : <url> license : apache - <number> with llvm - exception ==> dependencies build : cmake ✔ , swig ✔ required : python <user> . <number> ✔ , libffi ✔ ==> options - - head install head version ==> caveats to use the bundled libc + + please add the following ldflags - wl , - rpath , / usr / local / opt / llvm / lib "" ` ` ` llvm is keg - only , which means it was not symlinked into / usr / local , because macos already provides this software and installing another version in parallel can cause all kinds of trouble . i feel like i am getting nowhere . still unable to configure the bitcoin / bitcoin git . <repeated> its heartwrenching , but i am trying diligently and patiently to fix my issues . is there something wrong with my mac itself . it is very old <number> . <repeated> over ten years old ! very outdated . running mac os <number> . <number> do i need to go ahead and use ` brew info llvm ` ' s out put of / usr / local / opt / llvm / lib or what sense it is not symlinked . <repeated> ? <repeated> and just use that ldflag as the path ? it says it can not symlink ? should i use the keg ' s path / usr / local / opt / llvm or the other , or will this cause problems . i will get this thing worked out eventually . just need a little nudge in the right direction one more time .",2
bitcoin/bitcoin,"wallet file verification failed error hello , "" bitcoin - cli createwallet adminwallet "" ran on ubuntu server and admin_wallet folder was created in "" ~ / . bitcoin / "" directory . then when i type "" bitcoin - cli loadwallet adminwallet "" i get this error : error code : - <number> error message : wallet file verification failed . sqlitedatabase to obtain an exclusive lock on the database , is it being used by another instance of bitcoin core ? ` ps - aux | grep bitcoin root <number> <number> <number> <number> <number> ? ssl aug08 <number> <time> bitcoind - - daemon root <number> <number> <number> <number> <number> pts / <number> s + <time> <time> grep - - color = auto bitcoin `",2
bitcoin/bitcoin,"ibd stalls permanently with bitcoin core v23 after "" ignoring getheaders from peer = <number> because node is in initial block download "" with bitcoin core v23 ( qt versin on windows , or with the daemon from commandline ) , the ibd process can stall indefinitely after receiving a large block : ` ` ` <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ cnode ] added connection to <number> . <number> : <number> peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending version ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ pushnodeversion ] send version message : version <number> , blocks = <number> , them = <number> . <number> : <number> , txrelay = <number> , peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : version ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending verack ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending getaddr ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] receive version message : / satoshi : <number> . <number> /: version <number> , blocks = <number> , us = <number> . <number> : <number> , txrelay = <number> , peer = <number> , peeraddr = <number> . <number> : <number> <number> - <number> - 0 7 t <time> z [ timedata . cpp : <number> ] [ addtimedata ] added time data , samples <number> , offset - <number> ( + <number> minutes ) <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : verack ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] new outbound peer connected : version : <number> , blocks = <number> , peer = <number> , peeraddr = <number> . <number> : <number> ( manual ) <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending ping ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ sendmessages ] initial getheaders ( <number> ) to peer = <number> ( startheight : <number> ) <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending getheaders ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending feefilter ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : ping ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending pong ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : getheaders ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] ignoring getheaders from peer = <number> because node is in initial block download <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : feefilter ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : feefilter of <number> btc / kvb from peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : pong ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processmessage ] received : headers ( <number> bytes ) peer = <number> ` ` ` then any other attemps to connect to other peers ( or accept incoming connections ) stalls permanently ( we can waitfior hours : no network activity , no disk activity , but some thread uses <percent> of a cpu core , probably in a tight loop generated by a deadlock and infinite attemps to recover from it ) . if we try to shutdown , al most all databases thread are closed , the rpc services are closed , but the conenction manager remains locked for about ~ <number> minutes , not doing anything . in fact the received headers are not even starting to be parse until after these ~ <number> minutes . at which time we see that in logs : ( note : i have enabled ` ` ` logtimestamps = <number> ` ` ` , ` ` ` logsourcelocations = <number> ` ` ` and ` ` ` logthreadnames = <number> ` ` ` in bitcoin . conf to have more traceable traces ; and run it with ` ` ` debug = all ` ` ` ) . it seems that a lock is kept somewhere in "" net_processing . cpp "" after the processmessage ( ) exists with "" ignoring getheaders from peer = <number> because node is in initial block download "" only when we shut down the node we see instantly : ` ` ` <number> - <number> - 0 7 t <time> z [ qt / bitcoin . cpp : <number> ] [ debugmessagehandler ] gui : requestshutdown : requesting shutdown <number> - <number> - 0 7 t <time> z [ rpc / server . cpp : <number> ] [ operator ( ) ] interrupting rpc <number> - <number> - 0 7 t <time> z [ rpc / server . cpp : <number> ] [ operator ( ) ] stopping rpc <number> - <number> - 0 7 t <time> z [ init . cpp : <number> ] [ onrpcstopped ] rpc stopped . <number> - <number> - 0 7 t <time> z [ qt / bitcoin . cpp : <number> ] [ debugmessagehandler ] gui : running shutdown in thread <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ interrupthttpserver ] interrupting http server <number> - <number> - 0 7 t <time> z [ httprpc . cpp : <number> ] [ interrupthttprpc ] interrupting http rpc server <number> - <number> - 0 7 t <time> z [ init . cpp : <number> ] [ shutdown ] shutdown : in progress . <repeated> <number> - <number> - 0 7 t <time> z [ httprpc . cpp : <number> ] [ stophttprpc ] stopping http rpc server <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ unregisterhttphandler ] unregistering http handler for / ( exactmatch <number> ) <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ unregisterhttphandler ] unregistering http handler for / wallet / ( exactmatch <number> ) <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ stophttpserver ] stopping http server <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ stophttpserver ] waiting for http worker threads to exit <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] opencon thread exit <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] dnsseed thread exit <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] addcon thread exit <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ threadhttp ] exited http event loop <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ stophttpserver ] waiting for http event thread to exit <number> - <number> - 0 7 t <time> z [ httpserver . cpp : <number> ] [ stophttpserver ] stopped http server <number> - <number> - 0 7 t <time> z [ mapport . cpp : <number> ] [ processupnp ] upnp_deleteportmapping ( ) returned : <number> <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] mapport thread exit ` ` ` and then we wait for about <number> - <number> minutes to finally see this : the received block headers are processed , an attempt for sending another requests for headers is emitted , but all peers are finally disconnected ( because we were shutting down ) , and all remaining data in moemory is flushed to disk and the node finally exits correctly . ` ` ` <number> - <number> - 0 7 t <time> z [ validation . cpp : <number> ] [ processnewblockheaders ] synchronizing blockheaders , height : <number> ( ~ <percent> ) <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ processheadersmessage ] more getheaders ( <number> ) to end to peer = <number> ( startheight : <number> ) <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ createnodefromacceptedsocket ] connection from [ <number> : d500 : <number> : <number> : : <number> <sad> <number> accepted <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] net thread exit <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ pushmessage ] sending getheaders ( <number> bytes ) peer = <number> <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = txindex , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] msghand thread exit <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = txindex , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] txindex thread exit <number> - <number> - 0 7 t <time> z [ random . cpp : <number> ] [ seedperiodic ] feeding <number> bytes of dynamic environment data into rng <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ dumpaddresses ] flushed <number> addresses to peers . dat 7 0 1 ms <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ closesocketdisconnect ] disconnecting peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ finalizenode ] cleared nodestate for peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ closesocketdisconnect ] disconnecting peer = <number> <number> - <number> - 0 7 t <time> z [ net_processing . cpp : <number> ] [ finalizenode ] cleared nodestate for peer = <number> <number> - <number> - 0 7 t <time> z [ net . cpp : <number> ] [ dumpaddresses ] flushed <number> addresses to peers . dat 1 5 ms <number> - <number> - 0 7 t <time> z [ util / thread . cpp : <number> ] [ tracethread ] scheduler thread exit <number> - <number> - 0 7 t <time> z [ validation . cpp : <number> ] [ dumpmempool ] writing <number> unbroadcast transactions to disk . <number> - <number> - 0 7 t <time> z [ validation . cpp : <number> ] [ dumpmempool ] dumped mempool : 0 s to copy , <number> . 0 3 6 8 9 2 s to dump <number> - <number> - 0 7 t <time> z [ policy / fees . cpp : <number> ] [ flushunconfirmed ] recorded <number> unconfirmed txs from mempool in 0 s <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block and undo data to disk started <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block and undo data to disk completed ( <number> . 0 2 ms ) <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block index to disk started <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = index , before = <number> . 0 mib , after = <number> . 3 mib <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block index to disk completed ( <number> . 9 8 ms ) <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write coins cache to disk ( <number> coins , 0 kb ) started <number> - <number> - 0 7 t <time> z [ txdb . cpp : <number> ] [ batchwrite ] writing final batch of <number> mib <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = chainstate , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 0 7 t <time> z [ txdb . cpp : <number> ] [ batchwrite ] committed <number> changed transaction outputs ( out of <number> ) to coin database . <repeated> <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write coins cache to disk ( <number> coins , 0 kb ) completed ( <number> . 0 0 ms ) <number> - <number> - 0 7 t <time> z [ validationinterface . cpp : <number> ] [ chainstateflushed ] enqueuing chainstateflushed : block hash = 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 a873661c59cd6301ace5a9108786284693eb0e35038713f4d <number> - <number> - 0 7 t <time> z [ validationinterface . cpp : <number> ] [ operator ( ) ] chainstateflushed : block hash = 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 a873661c59cd6301ace5a9108786284693eb0e35038713f4d <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = db , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = db , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block and undo data to disk started <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block and undo data to disk completed ( <number> . 2 7 ms ) <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block index to disk started <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = index , before = <number> . 3 mib , after = <number> . 3 mib <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write block index to disk completed ( <number> . 6 3 ms ) <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write coins cache to disk ( <number> coins , 0 kb ) started <number> - <number> - 0 7 t <time> z [ txdb . cpp : <number> ] [ batchwrite ] writing final batch of <number> mib <number> - <number> - 0 7 t <time> z [ dbwrapper . cpp : <number> ] [ writebatch ] writebatch memory usage : db = chainstate , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 0 7 t <time> z [ txdb . cpp : <number> ] [ batchwrite ] committed <number> changed transaction outputs ( out of <number> ) to coin database . <repeated> <number> - <number> - 0 7 t <time> z [ logging / timer . h : <number> ] [ log ] flushstatetodisk : write coins cache to disk ( <number> coins , 0 kb ) completed ( <number> . 0 0 ms ) <number> - <number> - 0 7 t <time> z [ validationinterface . cpp : <number> ] [ chainstateflushed ] enqueuing chainstateflushed : block hash = 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 a873661c59cd6301ace5a9108786284693eb0e35038713f4d <number> - <number> - 0 7 t <time> z [ init . cpp : <number> ] [ shutdown ] shutdown : done <number> - <number> - 0 7 t <time> z [ qt / bitcoin . cpp : <number> ] [ debugmessagehandler ] gui : shutdown finished <number> - <number> - 0 7 t <time> z [ qt / bitcoin . cpp : <number> ] [ debugmessagehandler ] gui : ~ initexecutor : stopping thread <number> - <number> - 0 7 t <time> z [ qt / bitcoin . cpp : <number> ] [ debugmessagehandler ] gui : ~ initexecutor : stopped thread ` ` ` if we relaunch the node , it loads all data successfully , connects to a new peer = <number> and requests another set of headers , then stalls again exactly as above , and we have to shutdown and wait <number> - <number> minutes exactly the same way as above . a single connection is made instantly to download a single nex set of headers , and then stalls forever . other connections are added to the list ( the upnp discovery occurs , other peers are also discovered ) , but will never start . these extra connections are locked again until . <repeated> we shutdown the ui and then wait for <number> - <number> minutes when the rpc services are closed . these pending connections are then open and closed immediately and the ui closes . result : we have been able to download a single set of headers at each run ( less than <number> minute to start and then seeing the lock after the 1 st download of headers , just about 1 8 0 kb , then no network or disk activity at all dor an infinite time , then shutdown and wait <number> - <number> minutes ) . * * expected behavior * * ibd should not stall . it should also connect to other peers , and not just to the initial one ( the qt interface dispays constantly to peers . <repeated> "" . * * system information * * bitcoin v23 for windows ( from <url> extracted from the zip file , because the current exe installer does not run on a windows system enforcing aslt ) < - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > windows <number> x64 ( intel core i7 ) , <number> gb ram",2
bitcoin/bitcoin,"cannot do http json rpc request on wallet i am trying to figure out how to query specific wallets . snippet of my config datadir <annoyed> data wallet <annoyed> data / wallets / test1 / wallet <annoyed> data / wallets / test2 / ` ` ` view of the wallets user <user> <annoyed> data # ls / data / wallets / test1 / database db . log wallet . dat user <user> <annoyed> data # ls / data / wallets / test2 / database db . log wallet . dat user <user> <annoyed> data # bitcoin - cli - conf = bitcoin . conf listwallets [ "" / data / wallets / test1 / "" , "" / data / wallets / test2 / "" ] no errors or issues via cli . the wallets are empty as expected as they were just created for testing user <user> <annoyed> data # bitcoin - cli - conf = bitcoin . conf - rpcwallet <annoyed> data / wallets / test1 / listunspent [ ] ` ` ` when i try an rpc curl request on it , i get the following error message ` curl - x post - - data - binary ' { "" jsonrpc "" : "" <number> "" , "" id "" : "" curltest "" , "" method "" : "" listunspent "" , "" params "" : [ <number> , <number> , [ ] , true , { "" minimumamount "" : <number> } ] } ' - h ' content - type : application / json ' ' https <annoyed> mynodeaddress . com / wallet / data / wallets / test2 ` ` { "" result "" : null , "" error "" <sad> "" code "" : - <number> , "" message "" : "" requested wallet does not exist or is not loaded "" } , "" id "" : "" curltest "" } ` * note <emphasis> * this works if i place the wallet in / data / test1 . the curl request will be successful if my config was wallet = test1 user <user> <annoyed> data # ls / data / test1 / database db . log wallet . dat ` curl - x post - - data - binary ' { "" jsonrpc "" : "" <number> "" , "" id "" : "" curltest "" , "" method "" : "" listunspent "" , "" params "" : [ <number> , <number> , [ ] , true , { "" minimumamount "" : <number> } ] } ' - h ' content - type ' https <annoyed> mynodeaddress . com / wallet / test2 ` it will return success fully return albeit an empty response similar to bitcoin - cli my question is , is it possible to have the wallet file in any directory within my datadir and still be able run rpc query against it using curl .",2
bitcoin/bitcoin,"stop the gpg verification madness * * is your feature request related to a problem ? please describe . * * it ' s becoming increasingly difficult to automate verification of the releases . for "" gpg - - verify sha256sums . asc sha256sums "" to succeed , all the keys have to be imported . some keys are not present on public keyservers and keyservers are anyway commonly considered as unreliable . currently for v23 , after importing <number> ( ) keys ( others are not available ) the sha256sums . asc verification still fails . * * describe the solution you ' d like * * reduce the signer list to a set of well known , trusted signers and have their keys optionally signed by whoever verified their identity and is willing to sign . alternatively , provide one signature file per signer , not a global file that always fails to pass all checks .",2
bitcoin/bitcoin,"ubuntu <number> server - build error < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * building bitcoin v . <number> < ! - - - what behavior did you expect ? - - > * * actual behavior * * ` root <user> - s - 1 vcpu - 1 gb - ams3 - <number> : ~ / bitcoin # make making all in src make [ <number> <sad> entering directory ' / root / bitcoin / src ' make [ <number> <sad> entering directory ' / root / bitcoin / src ' make [ <number> <sad> entering directory ' / root / bitcoin ' make [ <number> <sad> leaving directory ' / root / bitcoin ' cxxld bitcoind / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : thread_data < appinitmain ( util : : ref const & , nodecontext & , interfaces : : blockandheadertipinfo <wink> : : { lambda ( )# <number> }>: : ~ thread_data ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : thread_data < appinitmain ( util : : ref const & , nodecontext & , interfaces : : blockandheadertipinfo <wink> : : { lambda ( )# <number> }>: : ~ thread_data ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : sp_counted_impl_p < boost : : detail : : thread_data < appinitmain ( util : : ref const & , nodecontext & , interfaces : : blockandheadertipinfo <wink> : : { lambda ( )# <number> } > <sad> : dispose ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : sp_counted_impl_p < boost : : detail : : thread_data < appinitmain ( util : : ref const & , nodecontext & , interfaces : : blockandheadertipinfo <wink> : : { lambda ( )# <number> } > <sad> : dispose ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread_group : : interrupt_all ( <sad> / usr / include / boost / thread / detail / thread_group . hpp : <number> : undefined reference to ` boost : : thread : : interrupt ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread_group : : join_all ( <sad> / usr / include / boost / thread / detail / thread_group . hpp : <number> : undefined reference to ` boost : : thread : : joinable ( ) const ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread : : get_id ( ) const ' : / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : thread : : native_handle ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread : : join ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : thread : : join_noexcept ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread : : start_thread ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : thread : : start_thread_noexcept ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : thread_data_base : : thread_data_base ( <sad> / usr / include / boost / thread / pthread / thread_data . hpp : <number> : undefined reference to ` vtable for boost : : detail : : thread_data_base ' / usr / bin / ld : / usr / include / boost / thread / pthread / thread_data . hpp : <number> : undefined reference to ` vtable for boost : : detail : : thread_data_base ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread : : start_thread ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : thread : : start_thread_noexcept ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : thread_data < appinitmain ( util : : ref const & , nodecontext & , interfaces : : blockandheadertipinfo <wink> : : { lambda ( )# <number> }>: : ~ thread_data ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : thread_data < appinitmain ( util : : ref const & , nodecontext & , interfaces : : blockandheadertipinfo <wink> : : { lambda ( )# <number> }>: : ~ thread_data ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` appinitmain ( util : : ref const & , nodecontext & , interfaces : : blockandheadertipinfo <wink> [ clone . cold ] ' : / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : detail : : thread_data_base : : ~ thread_data_base ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread : : ~ thread ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : thread : : detach ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : detail : : interruption_checker : : interruption_checker ( pthread_mutex_t * , pthread_cond_t <wink> ' : / usr / include / boost / thread / pthread / thread_data . hpp : <number> : undefined reference to ` boost : : detail : : get_current_thread_data ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : shared_mutex : : lock ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : condition_variable : : wait ( boost : : unique_lock < boost : : mutex > & <sad> / usr / include / boost / thread / pthread / condition_variable . hpp : <number> : undefined reference to ` boost : : this_thread : : interruption_point ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : shared_mutex : : lock ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : shared_mutex : : lock_shared ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : condition_variable : : wait ( boost : : unique_lock < boost : : mutex > & <sad> / usr / include / boost / thread / pthread / condition_variable . hpp : <number> : undefined reference to ` boost : : this_thread : : interruption_point ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : shared_mutex : : lock_shared ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) : in function ` boost : : thread : : ~ thread ( <sad> / usr / include / boost / thread / detail / thread . hpp : <number> : undefined reference to ` boost : : thread : : detach ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) <sad> . data . rel . ro + 0x 9 8 ) : undefined reference to ` typeinfo for boost : : detail : : thread_data_base ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - init . o ) <sad> . data . rel . ro + 0 xb0 ) : undefined reference to ` typeinfo for boost : : detail : : thread_data_base ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : shared_mutex : : lock_shared ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : condition_variable : : wait ( boost : : unique_lock < boost : : mutex > & <sad> / usr / include / boost / thread / pthread / condition_variable . hpp : <number> : undefined reference to ` boost : : this_thread : : interruption_point ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : shared_mutex : : lock_shared ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : shared_mutex : : lock ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : condition_variable : : wait ( boost : : unique_lock < boost : : mutex > & <sad> / usr / include / boost / thread / pthread / condition_variable . hpp : <number> : undefined reference to ` boost : : this_thread : : interruption_point ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : shared_mutex : : lock ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : shared_mutex : : lock_shared ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - sigcache . o ) : in function ` boost : : shared_mutex : : lock ( <sad> / usr / include / boost / thread / pthread / shared_mutex . hpp : <number> : undefined reference to ` boost : : this_thread : : disable_interruption : : ~ disable_interruption ( ) ' / usr / bin / ld : libbitcoin_server . a ( libbitcoin_server_a - validation . o ) : in function ` boost : : condition_variable : : wait ( boost : : unique_lock < boost : : mutex > & <sad> / usr / include / boost / thread / pthread / condition_variable . hpp : <number> : undefined reference to ` boost : : this_thread : : interruption_point ( ) ' collect2 : error : ld returned <number> exit status make [ <number> <sad> * * * [ makefile : <number> : bitcoind ] error <number> make [ <number> <sad> leaving directory ' / root / bitcoin / src ' make [ <number> <sad> * * * [ makefile : <number> : all - recursive ] error <number> make [ <number> <sad> leaving directory ' / root / bitcoin / src ' make : * * * [ makefile : <number> : all - recursive ] error <number> ` < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * <number> . go to the server hosting provider ( e . g . digitalocean . com ) <number> . create a dropplet ( e . g . ubuntu <number> server ) <number> . clone bitcoin <number> . use the commands below ` ` ` sudo apt install build - essential libtool autotools - dev automake pkg - config bsdmainutils python3 sudo apt install libevent - dev libboost - dev libboost - system - dev libboost - filesystem - dev libboost - test - dev ` ` ` ` ` ` sudo apt install libsqlite3 - dev . / contrib / install_db4 . sh $( pwd ) export bdb_prefix =$( pwd ) / db4 ` ` ` ` . / autogen . sh ` ` . / configure bdb_libs = "" - l ${ bdb_prefix } / lib - ldb_cxx - <number> "" bdb_cflags = "" - i ${ bdb_prefix } / include "" ` ` make ` < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * linux ubuntu - s - 1 vcpu - 1 gb - ams3 - <number> <number> . <number> - <number> - generic # <number> - ubuntu smp wed may <number> <time> utc <number> x86_64 x86_64 x86_64 gnu / linux cpu : architecture : x86_64 cpu op - mode ( s ) : <number> - bit , <number> - bit byte order : little endian address sizes : <number> bits physical , <number> bits virtual cpu ( s ) : <number> on - line cpu ( s ) list : <number> thread ( s ) per core : <number> core ( s ) per socket : <number> socket ( s ) : <number> numa node ( s ) : <number> vendor id : genuineintel cpu family : <number> model : <number> model name : do - regular stepping : <number> cpu mhz : <number> bogomips : <number> virtualization : vt - x hypervisor vendor : kvm virtualization type : full l1d cache : <number> kib l1i cache : <number> kib l2 cache : <number> mib numa node0 cpu ( s ) : <number> vulnerability itlb multihit : kvm : mitigation : split huge pages vulnerability l1tf : mitigation ; pte inversion ; vmx conditional cache flushes , smt disabled vulnerability mds : mitigation ; clear cpu buffers ; smt host state unknown vulnerability meltdown : mitigation ; pti vulnerability spec store bypass : mitigation ; speculative store bypass disabled via prctl and seccomp vulnerability spectre v1 : mitigation ; usercopy / swapgs barriers and __user pointer sanitization vulnerability spectre v2 : mitigation ; retpolines , ibpb conditional , ibrs_fw , stibp disabled , rsb filling vulnerability srbds : not affected vulnerability tsx async abort : not affected flags vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon rep_good nopl cpuid tsc_known_freq pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf _lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveop t md_clear < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",2
bitcoin/bitcoin,"makehost error using wsl including pictures . < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > i have followed the steps to compile bitcoin on windows and i am receiving an error that is syntax in nature . this happened when i use this command in the terminal host =x 8 6 _64 - w64 - mingw32 in the depends folder . i will attach an image to clarify this issue . * * expected behavior * * < ! - - - what behavior did you expect ? - - > a complete compilation of bitcoin . * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > i am using bitcoin core <number> < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > i am using an asus x555y latop and my os is windows <number> < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - ! [ new bitcoin issue ] ( <url> >",2
bitcoin/bitcoin,when can use tap root ? is there any document for tap root developer ? when can use tap root ? is there any document for tap root developer ?,2
bitcoin/bitcoin,"on node startup , load mempool from peers ? let us say i shutdown my bitcoin node for one hour , the default behaviour at the startup is to load the file mempool . dat but all transactions that were broadcasted during this outage will not appear . i tried to disable the saving and loading with ` persistmempool = <number> ` but it starts with an empty mempool on startup . how can i get the full list of unconfirmed transactions on a restart ?",2
bitcoin/bitcoin,"rpc ` getblockfrompeer ` returns an error with bitcoin - cli i encounter an error with new command ` getblockfrompeer ` . ` ` ` bitcoin - cli getblockfrompeer "" 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 a7dedef4a161fa058a2d67a173a90155f3a2fe6fc132e0ebf "" <number> error code : - <number> error message : json value is not an integer as expected ` ` ` it ' s working with curl : ` ` ` curl - v - - user myusername - - data - binary ' { "" jsonrpc "" : "" <number> "" , "" id "" : "" curltest "" , "" method "" : "" getblockfrompeer "" , "" params "" : [ "" 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 a7dedef4a161fa058a2d67a173a90155f3a2fe6fc132e0ebf "" , <number> ] } ' - h ' content - type <url> ` ` ` i use the version bitcoin - core - <number> / test . rc5 / bitcoin - <number> . 0 rc5 - arm64 - apple - darwin . dmg",2
bitcoin/bitcoin,"non - mandatory - script - verify - flag ( witness program hash mismatch ) when trying to spend taproot output with 3 2 x 0x0 0 tapbranch < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > i made a taproot output with an internal key , a tapscript in a leaf and a nonexistent tapscript with a sha256 of 3 2 x 0x0 0 spending it doesnt work , but when i change the hash of the nonexistent tapscript to 3 1 x 0x0 0 + 0x0 1 is does work . there is no reason why with <number> it wouldnt work as this theoretically is a valid sha256 hash * * expected behavior * * < ! - - - what behavior did you expect ? - - > the transaction got accepted * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > it got not * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > <percent> reliable with <url> if you dont have time to make one yourself here is my tx : taproot output ( this one is in the testnet blockchain [ eed3cb854b1faaf3a342d2738b356ba4c176cb0c96e06a378b7ee47d8d68a12f ] ( <url> ` ` ` 0 2 0 0 0 0 0 0 0 0 0 1 0 1 eb9ed40b43fc676e2d33d6059338b75850611ea7ec7480a1cc030d7997cc7e730000000000feffffff021027000000000000225120c730e130570fb56367fb31d9ab9d492e38be719d31a0b4602fda344caa4b3d03fee468000000000016001494634ec1184c82d6a12b984f0e5efab9f6b053ec0247304402203ba26bbd89ddb641e19bab67773652ea09512ed7996a591d94d197109bf794ea0220375b5614eb4eb6a5f123aa5abce257f0273a9b70a9d87e6087378fc3fd452b68012102ca71026e93dc7183350a3c7af0c38ced30fea24dd230ccb2ffa365c55ec3e5da71762100 ` ` ` trying to spend 0 2 0 0 0 0 0 0 0 0 0 1 0 1 b294960b0f1c6d185882abab322dab58cba995b77fac80afc13b5595a0add7810000000000ffffffff017a2600000000000016001411b07a052ffdb815bb7eb017631b23d13eba5af904401a5f24e4d351e59eb64b213e5ce5dbe8e610eca7ea9128fd2f99bcc72eae122b6517a4a689122301dfa21f31c002cd3e55289be36be80bfd910e3f5649529f54401a5f24e4d351e59eb64b213e5ce5dbe8e610eca7ea9128fd2f99bcc72eae122b6517a4a689122301dfa21f31c002cd3e55289be36be80bfd910e3f5649529f54462042c68328c229ddef4f0588bd952e05eaca009bee43d01ff6bcbb0b681c15c894ac2042c68328c229ddef4f0588bd952e05eaca009bee43d01ff6bcbb0b681c15c894ba528741c15be1beaf62c286f2eae1b60ee1f1f6dcc9b96104ede0f09f1497c5bae82ea5aa000000000000000000000000000000000000000000000000000000000000000000000000 ` ` ` * * system information * * what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? bitcoin . org binary v22 what type of machine are you observing the error on ( os / cpu and disk type ) ? not needed , this is consensus related < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",2
bitcoin/bitcoin,"main . cpp error during make . ubuntu <number> with boost <number> < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > does anyone know how to address the rpcserver . cpp error during the make process ? i am using ubuntu <number> with the default boost <number> . ` ` ` cxx rpcserver . o rpcserver . cpp : <number> <time> <number> : error : wrong number of template arguments ( <number> , should be <number> ) static void rpcaccepthandler ( boost : : shared_ptr < basic_socket_acceptor < protocol , socketacceptorservice > > acceptor , ^ in file included from / usr / local / include / boost / asio . hpp : <number> , from rpcprotocol . h : <number> , from rpcserver . h : <number> , from rpcserver . cpp : <number> : / usr / local / include / boost / asio / basic_socket_acceptor . hpp : <number> : <number> : note : provided for ‘ template < class protocol > class boost : : asio : : basic_socket_acceptor ’ class basic_socket_acceptor ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ rpcserver . cpp : <number> <time> <number> : error : template argument <number> is invalid static void rpcaccepthandler ( boost : : shared_ptr < basic_socket_acceptor < protocol , socketacceptorservice > > acceptor , ^ rpcserver . cpp : <number> : <number> : error number of template arguments ( <number> , should be <number> ) static void rpclisten ( boost : : shared_ptr < basic_socket_acceptor < protocol , socketacceptorservice > > acceptor , ` ` ` < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * ubuntu <number> , default boost <number> installed . < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",2
bitcoin/bitcoin,"apple silicon massive performance degredation in function tests / rpc ( m1 ) i discovered this significant slowdown when functional tests took substancially longer than expected on my new m1 macbook pro . ( completes in ~ <number> seconds on my 1 9 5 0 x , and <number> seconds on m1 ) to validate this issue , i deployed two new regtest networks ( both compiled locally ) , one on an amd 1 9 5 0 x cpu running ubuntu <number> , and one on a <number> in m1 macbook pro <number> core . i found that the m1 macbook had substantially better results in benchmarks compared to x86 , ~ <percent> faster in the assembleblock benchmark for example . however , the functional tests were very slow , and rpc was very slow . it is my current believe that there is some issues in rpc handling / code that is very heavily slowing down the functional tests . i compared some rpc calls in [ m1 ] ( <url> and [x 8 6 ] ( <url> i found m1 rpc calls were around 1 0 x slower . ~ for example , getblockchaininfo took <number> seconds on m1 , <number> seconds on x86 . ~ i have not been able to replicate this specific issue now . <repeated> non - db / disk involved rpc calls seem mostly comparable between the two systems . generating <number> blocks took <number> seconds on m1 , and <number> seconds on x86 . if someone has any ideas as to why this is so slow , or how to fix it , i am all ears also , if someone on mac ( non - m1 ) could replicate this test and post their information ( so we can compare m1 mac to non - m1 mac ) that ' d be highly appreciated . if other developers using m1 could share their experiences , that ' d be helpful .",2
bitcoin/bitcoin,can not unlock bitcoin wallet with correct password i encrypted my wallet . used special characters in the password . and now the password does not work ( exactly correct ) . maybe the problem is in special characters ? the first character of the password is - and the body of the password contains - ~,2
bitcoin/bitcoin,error while windows build . root <user> : ~ / bitcoin # make deploy,2
bitcoin/bitcoin,` sendtoaddress ` tries to use unspendable utxos and fails * * is your feature request related to a problem ? please describe . * * < - - a clear and concise description of what the problem is . ex . i am always frustrated when [ . <repeated> ] - - > problem to wait for a confirmation before able to spend them with ` sendtoaddress ` * * describe the solution you ' d like * * < ! - - a clear and concise description of what you want to happen . - - > an optional argument to enable it for one time ( i agree with <url> but i think you should be able to override it ) * * describe alternatives you have considered * * < ! - - a clear and concise description of any alternative solutions or features you have considered . - - > i could ` createrawtransaction ` but i have a lot of utxos i want to bundle in one coin and it is easier to send the wallet balance to one address * * additional context * * < ! - - add any other context or screenshots about the feature request here . - - > on the testnet btw,2
bitcoin/bitcoin,"the weak getauxval in centos <number> < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * the ` . / configure ` of v22 . <number> defines two macros : ` have_strong_getauxval ` & ` have_weak_getauxval ` judging by the code , the file sys / auxv . h to be included when one from these macros are defined . the centos <number> . * does not have a file * * ` sys / auxv . h ` * * < ! - - - what behavior did you expect ? - - > the configure at centos <number> should define macros as : ` ` ` have_strong_getauxval = ' <number> ' have_weak_getauxval = ' <number> ' ` ` ` and compiling without errors * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > the ` . / configure ` should define macros as : ` ` ` have_strong_getauxval = ' <number> ' have_weak_getauxval = ' <number> ' ` ` ` errors of compilation : ` ` ` randomenv . cpp : <number> <time> : fatal error : sys / auxv . h : no such file or directory <number> | <hashtag> include </hashtag> < sys / auxv . h > | ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ` ` ` * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * / etc / centos - release release <number> ( final ) < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",2
bitcoin/bitcoin,"about restore the wallet hi ~ i just have some questions about restoring a wallet . most users had showed how to use bitcoin core , but few focus on how to restore the wallet . i have read the book "" grokking bitcoin "" , where kalle said that we should keep ` wallet . dat ` file safe . my try is as following : first i create a test wallet : ` ` ` $ bitcoin - cli createwallet testwallet false false - passphrase = test111 false false true false ` ` ` next , i started to backup the wallet and kept it safe . this step seemed that the passphrase was not necessary . ` ` ` $ bitcoin - cli - rpcwallet = testwallet backupwallet ~ / testwallet . dat ` ` ` get an adress for someone who would send me some bitcoins : ` ` ` $ bitcoin - cli - rpcwallet = "" testwallet "" - named getnewaddress address_type = bech32 bc1q7y3uj . <repeated> unpn9 # get private key $ bitcoin - cli - rpcwallet = "" testwallet "" dumpprivkey "" bc1q7y3uj . <repeated> unpn9 "" kzqz3uop . <repeated> 9 8 k ` ` ` supposed that i have got the pay , but suddenly my server was exploded . i decided to restore the wallet in a new linux server . after install ` bitcoin core ` software completely , i created a new wallet : ` ` ` $ bitcoin - cli createwallet testwallet2 false false - passphrase = test444 false false true false ` ` ` unlock it for 1 2 0 s : ` ` ` $ bitcoin - cli - rpcwallet = testwallet2 walletpassphrase - passphrase = test444 <number> ` ` ` restored the wallet : ` ` ` $ bitcoin - cli - rpcwallet = testwallet2 importwallet < testwallet . dat > # without any error information ` ` ` however , it seemed that the wallet could not access the private key ` ` ` $ bitcoin - cli - rpcwallet = "" testwallet2 "" dumpprivkey "" bc1q7y3uj . <repeated> unpn9 "" error code : - <number> error message : private key for address bc1q7y3uj . <repeated> unpn9 is not known ` ` ` here are some questions : a . was i do the right thing to restore the wallet ? b . if i was right , it means that anyone ( hackers of my servers , for example ) who own the ` testwallet . dat ` file could get all the bitcoins . in the ` importwallet ` step , i did not need to use any passphrase ( test111 ) of the previous wallet . it seemed not very safe , because my server may be easy to be cracked . so i guess i was wrong , but i have no idea how to do this . any suggestions ? my ` bitcoin core ` version is : ` ` ` "" version "" : <number> , "" subversion "" ` ` `",2
bitcoin/bitcoin,"bitcoincore update linux ( tgz ) or arm linux i am running a node on a raspberry pi <number> model b 8 gb with linux as os , should i update bitcoincore with linux ( tgz ) or arm linux . thanks",2
bitcoin/bitcoin,"how to mine continuously in segtest of version bitcoin - <number> ? hello , i am just learning the bitcoin codes of version bitcoin - <number> and i make it successfully . additionlly , i have only one pc . i want to mine continuously in segtest , however i only found methods below = = generating = = generatetoaddress nblocks "" address "" ( maxtries ) generatetodescriptor num_blocks "" descriptor "" ( maxtries ) ` ` ` but these methods can not mine continuously . hence would you please tell my how to mine continuously in segtest of version bitcoin - <number> ? thank you very much .",2
bitcoin/bitcoin,"script verification threads are idle during ibd system : odroid - hc1 , arm <number> - bit , armbian <number> . <number> focal client [ v22 . 0 rc2 ] ( <url> ` ` ` $ bitcoind - version bitcoin core version v22 . <number> - g873fbc745d037ad43570f81e58334c397bc95477 ` ` ` started ibd from scratch ( with ` txindex = <number> ` ) , now synced up to height ~ <number> . according to data provided by ` htop ` tool , all additional script verification threads were idle since ibd started from <number> - <number> - <number> <date> ] ( <url> is such behavior expected ?",2
bitcoin/bitcoin,"is it possible to disable bind on onion network listening port ? this may also be a bug depending on understanding of ` listenonion ` option . * * what is happening : * * we have upgraded bitcoin node from v0 . <number> to v0 . <number> , bitcoind tries to bind to port <number> ( tor listening ) , which we use for another service . * * possible solution : * * move the port using ` bind ` option to some unused port . * * preferred solution : * * disable listening on this particular port . i have tried using ` listenonion = <number> ` but the only effect is that the tor service is not started , the port is however still used . can binding of this port be disabled ? and is ` listenonion ` working correctly ?",2
bitcoin/bitcoin,"[ question ] how can i use ip : host not localhost : port in rpc ? i want to use ip ( lan ip ) in rpc , not <number> . <number> or localhost , but i try to change the configuration of conf with [ this ] ( <url> , but it did not work i have been try to close firewall , still not work , and try to add more rpcallowip one by one my system is ubuntu <number> my conf now is : ` ` ` server = <number> testnet = <number> rpcuser = test rpcpassword = <number> rpcallowip = <number> . <number> rpcallowip = <number> . <number> rpcallowip = <number> . <number> rpcallowip = <number> . <number> / <number> . <number> ` ` ` command report : ` ` ` <number> / <number> / <number> <time> post "" <url> dial tcp <number> . <number> <time> <number> : connect refused ` ` ` ( it work in localhost and <number> . <number> ) what should i do ?",2
bitcoin/bitcoin,"increase trust through wallet aliases and transfer confirmations * * is your feature request related to a problem ? please describe . * * users still fear doing bitcoin transactions , scared that something might go wrong . this fear is based on <number> closely - related issues : - first : "" is the account i am transferring to the correct one ? maybe i did not copy it correctly , maybe i still have a previous address in my clipboard ? - second : users only know <percent> that they transferred correctly after the transaction has gone through . * * describe the solution you ' d like * * i think this could be greatly improved by implementing <number> solutions : - help users know where they are transferring to : allow users to give their wallet ' s an alias . something like [ myamazingalias ] . then , when someone is preparing a transactions , after he fills out the wallet address , it could display : ` "" transferring to id : [ x <elongated> ] label : [ myamazingalias ] , confirm ? ` - allow the receiver to confirm his wallet before the transfer - confirmation the destination address and ammount are already filled out , already display the transaction in the receiver ' s wallet , but with the status "" <number> confirmations "" or "" awaiting confirmation "" . this way , a user can ask "" did the transaction arrive at your wallet ? "" and only confirm after hearing from the receiver ( but in this mode , the fee would probably have be paid , at least in part , even if the transaction is canceled ) . solutions but that would make people feel much safer when using cryptocurrencies ( even safer then when doing bank - transfers , that do not offer this ) , and would help with adoption not only for new users , but even for users that might still not use bitcoin for purchases , out of fear of doing something wrong at some point . * * describe alternatives you have considered * * implementing just the alias system would already solve most of this * * additional context * * the chance of typing a wrong wallet address that works is very low , but still , users feel very uneasy when having to transfer funds through bitcoin , and questions about this can be found in most forums about bitcoin . coming up with a solution for this issue could greatly increase trust and make people relax more when using bitcoin , which i believe is important for greater adoption . and no one is perfect , people are bound to making mistakes , and bitcoin should not be the network where one day a story surfaces saying "" . <repeated> transferred 1 0 0 million dollars to the wrong address and no way of recuperating them . """,2
bitcoin/bitcoin,"rpc usage for "" logging "" unclear it ' s not clear how to enable / include or disable / exclude debug settings from within the console . the usage is not clear . for example , i have tried logging exclude mempool logging exclude [ mempool ] logging exclude [ "" mempool "" ] logging exclude [ \ \ "" mempool \ \ "" ] logging exclude "" [ \ \ \ \ "" mempool \ \ \ \ "" ] "" none of them work",2
bitcoin/bitcoin,"unable to link with libc + + - <number> ( undefined reference to symbol ' _znst18condition_variable10notify_oneev @ <user> . <number> ' ) steps to reproduce on current master ( 5 6 7 6 7 0 bec5ecf9bc252e91370382be53fd81ccee ) : ` ` ` # . / configure cc = clang - <number> cxx = "" clang + + - <number> - stdlib = libc + + "" . <repeated> # make v = <number> making all in src make [ <number> <sad> entering directory ' / bitcoin / src ' make [ <number> <sad> entering directory ' / bitcoin / src ' make [ <number> <sad> entering directory ' / bitcoin ' make [ <number> <sad> leaving directory ' / bitcoin ' / bin / bash . <repeated> / libtool - - tag = cxx - - preserve - dup - deps - - mode = link / usr / bin / ccache clang + + - <number> - stdlib = libc + + - std =c + + <number> - fdebug - prefix - map <annoyed> bitcoin / src = . - wstack - protector - fstack - protector - all - fcf - protection = full - wall - wextra - wgnu - wformat - wformat - security - wvla - wshadow - field - wswitch - wthread - safety - wrange - loop - analysis - wredundant - decls - wunused - variable - wunused - member - function - wdate - time - wconditional - uninitialized - wsign - compare - woverloaded - virtual - wunreachable - code - loop - increment - wno - unused - parameter - wno - self - assign - wno - unused - local - typedef - wno - implicit - fallthrough - fpie - g - o2 - wl , - z , relro - wl , - z , now - wl , - z , separate - code - pie - pthread - lpthread - o bitcoind bitcoind - bitcoind . o init / bitcoind - bitcoind . o libbitcoin_server . a libbitcoin_wallet . a libbitcoin_common . a libbitcoin_util . a univalue / libunivalue . la libbitcoin_consensus . a crypto / libbitcoin_crypto_base . a crypto / libbitcoin_crypto_sse41 . a crypto / libbitcoin_crypto_avx2 . a crypto / libbitcoin_crypto_shani . a leveldb / libleveldb . a crc32c / libcrc32c . a crc32c / libcrc32c_sse42 . a leveldb / libmemenv . a secp256k1 / libsecp256k1 . la - l / usr / lib / x86_64 - linux - gnu - lboost_system - lboost_filesystem - ldb_cxx - levent_pthreads - levent - levent - lsqlite3 libtool : link : / usr / bin / ccache clang + + - <number> - stdlib = libc + + - std =c + + <number> - fdebug - prefix - map <annoyed> bitcoin / src = . - wstack - protector - fstack - protector - all - fcf - protection = full - wall - wextra - wgnu - wformat - wformat - security - wvla - wshadow - field - wswitch - wthread - safety - wrange - loop - analysis - wredundant - decls - wunused - variable - wunused - member - function - wdate - time - wconditional - uninitialized - wsign - compare - woverloaded - virtual - wunreachable - code - loop - increment - wno - unused - parameter - wno - self - assign - wno - unused - local - typedef - wno - implicit - fallthrough - fpie - g - o2 - wl , - z - wl , relro - wl , - z - wl , now - wl , - z - wl , separate - code - pie - pthread - o bitcoind bitcoind - bitcoind . o init / bitcoind - bitcoind . o - lpthread libbitcoin_server . a libbitcoin_wallet . a libbitcoin_common . a libbitcoin_util . a univalue / . libs / libunivalue . a libbitcoin_consensus . a crypto / libbitcoin_crypto_base . a crypto / libbitcoin_crypto_sse41 . a crypto / libbitcoin_crypto_avx2 . a crypto / libbitcoin_crypto_shani . a leveldb / libleveldb . a crc32c / libcrc32c . a crc32c / libcrc32c_sse42 . a leveldb / libmemenv . a secp256k1 / . libs / libsecp256k1 . a - l / usr / lib / x86_64 - linux - gnu - lboost_system - lboost_filesystem - ldb_cxx - levent_pthreads - levent - levent / usr / lib / x86_64 - linux - gnu / libsqlite3 . so - pthread / usr / bin / ld : leveldb / libleveldb . a ( leveldb_libleveldb_a - env_posix . o ) : undefined reference to symbol ' _znst18condition_variable10notify_oneev @ <user> . <number> ' / / usr / lib / x86_64 - linux - gnu / libstdc + + . so . <number> : error adding symbols : dso missing from command line clang : error : linker command failed with exit code <number> ( use - v to see invocation ) makefile : <number> : recipe for target ' bitcoind ' failed make [ <number> <sad> * * * [ bitcoind ] error <number> make [ <number> <sad> leaving directory ' / bitcoin / src ' makefile : <number> : recipe for target ' all - recursive ' failed make [ <number> <sad> * * * [ all - recursive ] error <number> make [ <number> <sad> leaving directory ' / bitcoin / src ' makefile : <number> : recipe for target ' all - recursive ' failed make [ all - recursive ] error <number> ` ` ` < - - <number> - > <number> export debian_frontend = noninteractive & & apt update & & apt install curl wget htop git vim ccache - y & & git clone <url> & & cd bitcoin & & git checkout master & & apt install build - essential libtool autotools - dev automake pkg - config bsdmainutils python3 - zmq libevent - dev libboost - system - dev libboost - filesystem - dev libboost - test - dev libboost - thread - dev libsqlite3 - dev libdb + + - dev - y & & . / autogen . sh & & apt install libqt5gui5 libqt5core5a libqt5dbus5 qttools5 - dev qttools5 - dev - tools - y & & apt install clang - <number> llvm - <number> libc + + abi - <number> - dev libc + + - <number> - dev - y & & . / configure cc = clang - <number> cxx = "" clang + + - <number> - stdlib = libc + + "" - - with - incompatible - bdb & & make - j $( nproc ) src / bitcoind & & make - j <number>",2
bitcoin/bitcoin,"how to support native segwit ( bech32 ) address i run the bitcoin node version is <number> . <number> , and now we want to support the native segwit ( bech32 ) format , how do i need to upgrade the node or redeploy a new node , or what method can i use to convert the nested segwit ( p2sh ) format to bech32 address",2
bitcoin/bitcoin,"compiling macos environment on ubuntu <number> i have an issue compiling the macos environment for bitcoin <number> and bitcoin <number> . <number> on ubuntu <number> . i installed the following dependencies : sudo apt - get install curl librsvg2 - bin libtiff - tools bsdmainutils cmake imagemagick libcap - dev libz - dev libbz2 - dev python3 - setuptools libtinfo5 sudo apt - get install make automake cmake curl g + + - multilib libtool binutils - gold bsdmainutils pkg - config python3 patch the following commands where executed to compile the macos environment : wget <url> tar - xzvf v0 . <number> . tar . gz cd bitcoin - <number> . <number> mkdir - p depends / sdk - sources mkdir - p depends / sdks curl <url> - o depends / sdk - sources / macosx10 . <number> . sdk . tar . gz tar - c depends / sdks - xf depends / sdk - sources / macosx10 . <number> . sdk . tar . gz cd depends make host =x 8 6 _64 - apple - darwin16 the compiling results in multiple errors regarding "" . / boost / config / detail / select_stdlib_config . hpp : <time> : fatal error : ' cstddef ' file not found "" , see attached txt file for the complete compiling output . compiling output",2
bitcoin/bitcoin,"fatal leveldb error : corruption : block checksum mismatch had this problem with one long running node . tried to restart bitcoind with ` - debug = leveldb - reindex ` , ended up with : ` ` ` <number> - <number> - 1 8 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 5 3 fc4f4aee341eacc92b28450dfff90810b4d2df216e height = <number> version =0 x2fffe000 log2_work = <number> tx = <number> date = ' <number> - <number> - 0 8 t <time> z ' progress = <number> cache = <number> . 0 mib ( 6 4 9 2 9 6 txo ) <number> - <number> - 1 8 t <time> z leveldb : generated table # <number> : <number> keys , <number> bytes <number> - <number> - 1 8 t <time> z leveldb : generated table # <number> : <number> keys , <number> bytes <number> - <number> - 1 8 t <time> z leveldb : generated table # <number> : <number> keys , <number> bytes <number> - <number> - 1 8 t <time> z leveldb : compacted <number> <user> + <number> <user> files => <number> bytes <number> - <number> - 1 8 t <time> z leveldb : compacted to : files [ <number> <number> <phone> <number> <number> ] <number> - <number> - 1 8 t <time> z leveldb : delete type = <number> # <phone> - <number> - 1 8 t <time> z leveldb : delete type = <number> # <phone> - <number> - 1 8 t <time> z leveldb : delete type = <number> # <phone> - <number> - 1 8 t <time> z leveldb : delete type = <number> # <phone> - <number> - 1 8 t <time> z leveldb : compacting <number> <user> + <number> <user> files <number> - <number> - 1 8 t <time> z leveldb read failure : corruption : block checksum mismatch <number> - <number> - 1 8 t <time> z fatal leveldb error : corruption : block checksum mismatch <number> - <number> - 1 8 t <time> z you can use - debug = leveldb to get more complete diagnostic messages <number> - <number> - 1 8 t <time> z leveldb : generated table # <number> : <number> keys , <number> bytes <number> - <number> - 1 8 t <time> z error : error reading from database , shutting down . <number> - <number> - 1 8 t <time> z error reading from database : fatal leveldb error : corruption checksum mismatch ` ` ` any hints how to debug this ? ` ` ` # bitcoind - version bitcoin core version v0 . <number> . <number> - gentoo ` ` `",2
bitcoin/bitcoin,"error : acceptblockheader : block is marked invalid compiled the latest git version ( <date> , revision : c00852653f2bf9cd3ee53ab05d574fe4a9ff6dcc ) with msvc <number> <number> of bitcoind ( 3 2 bit ) and get the following error : > bitcoind - txindex = <number> > error : acceptblockheader : block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 bff65a2701c0b7f82d2d9c0a69bec94ca45f3fc4fdf4b6 is marked invalid also getting : > bitcoin - cli reconsiderblock > error : connectblock : consensus : : checktxinputs : cb33f844ef77a7282389c515df3831d13771851a4cf2b63e5be406eebc578ceb , bad - txns - inputs - missingorspent , checktxinputs : inputs missing / spent > invalidchainfound : invalid block = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 bff65a2701c0b7f82d2d9c0a69bec94ca45f3fc4fdf4b6 height = <number> log2_work = <number> date = <number> - <number> - 3 0 t <time> z > bitcoin - cli getblockchaininfo > { "" chain "" : "" main "" , "" blocks "" : <number> , "" headers "" : <number> , "" bestblockhash "" : "" 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 9 8 7 b914811f687096790995b9aba7abf9c5b2db64e8e "" , "" difficulty "" : <number> , "" mediantime "" : <phone> , "" verificationprogress "" : <number> , "" initialblockdownload "" : true , "" chainwork "" : "" 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 5 bbcd1e85726a7ac80c38 "" , "" size_on_disk "" : <number> , "" pruned "" : false , "" softforks "" : { "" bip34 "" : { "" type "" : "" buried "" , "" active "" : true , "" height "" : <number> } , "" bip66 "" : { "" type "" : "" buried "" , "" active "" : true , "" height "" : <number> } , "" bip65 "" : { "" type "" : "" buried "" , "" active "" : true , "" height "" : <number> } , "" csv "" : { "" type "" : "" buried "" , "" active "" : true , "" height "" : <number> } , "" segwit "" : { "" type "" : "" buried "" , "" active "" : false , "" height "" : <number> } } , "" warnings "" is a pre - release test build - use at your own risk - do not use for mining or merchant applications "" } is 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 bff65a2701c0b7f82d2d9c0a69bec94ca45f3fc4fdf4b6 actually a valid hash ? what can i do now ?",2
bitcoin/bitcoin,"block pre - allocation appears to have surprisingly poor performance when syncing bitcoin core with extremely fast storage the pre - allocation of block files with ` fallocate ` looks to be a surprising portion for the wall time for ibd and appears to sometimes slow down block relay at the tip of the chain . it ' s not completely clear why this would be the case , 3 0 0 ms to write 1 6 mb to ` tmpfs ` would be excessively slow . is this an artifact of the logging ( altered in # <number> ) , or an actual performance concern ? ` ` ` <number> - <number> - 2 4 t <time> . 6 3 7 3 6 5 z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 fc15108523bcb10b5b76a3fd61ce57fb8460f666f845 height = <number> version =0 x20000000 log2_work = <number> tx = <number> date = ' <number> - <number> - 0 1 t <time> z ' progress = <number> cache = <number> . 0 mib ( 3 7 2 1 1 0 txo ) <number> - <number> - 2 4 t <time> . 8 2 8 9 1 0 z pre - allocating up to position 0x 6 0 0 0 0 0 0 in blk01663 . dat . <repeated> <number> - <number> - 2 4 t <time> . 6 8 3 4 8 4 z pre - allocating up to position 0x 1 0 0 0 0 0 0 in blk01667 . dat <number> - <number> - 2 4 t <time> . 9 5 1 3 6 2 z pre - allocating up to position 0x 2 0 0 0 0 0 0 in blk01667 . dat <number> - <number> - 2 4 t <time> . 2 5 7 1 3 1 z pre - allocating up to position 0x 3 0 0 0 0 0 0 in blk01667 . dat <number> - <number> - 2 4 t <time> . 5 1 0 1 5 1 z pre - allocating up to position 0x 4 0 0 0 0 0 0 in blk01667 . dat <number> - <number> - 2 4 t <time> . 7 5 2 6 0 4 z pre - allocating up to position 0x 5 0 0 0 0 0 0 in blk01667 . dat <number> - <number> - 2 4 t <time> . 0 7 4 4 8 9 z pre - allocating up to position 0x 6 0 0 0 0 0 0 in blk01667 . dat <number> - <number> - 2 4 t <time> . 3 4 1 4 7 8 z pre - allocating up to position 0x 7 0 0 0 0 0 0 in blk01667 . dat <number> - <number> - 2 4 t <time> . 6 5 5 5 8 1 z pre - allocating up to position 0x 8 0 0 0 0 0 0 in blk01667 . dat . <repeated> <number> - <number> - 2 4 t <time> . 8 8 6 5 8 6 z pre - allocating up to position 0x 1 0 0 0 0 0 0 in blk01668 . dat <number> - <number> - 2 4 t <time> . 1 4 8 6 5 1 z pre - allocating up to position 0x 2 0 0 0 0 0 0 in blk01668 . dat <number> - <number> - 2 4 t <time> . 5 1 5 4 8 0 z pre - allocating up to position 0x 1 0 0 0 0 0 in rev01668 . dat <number> - <number> - 2 4 t <time> . 5 2 5 1 2 2 z updatetip best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 c7af325f257778530cd2127b0ceacb1f56ce4c98fa4dc height = <number> version =0 x20c00000 log2_work = <number> tx = <number> date = ' <number> - <number> - 0 2 t <time> z ' progress = <number> cache = <number> . 9 mib ( 1 2 6 4 7 txo ) ` ` `",2
bitcoin/bitcoin,"mandatory - script - verify - flag - failed ( public key is neither compressed or uncompressed ) "" txdata "" : "" 0 1 0 0 0 0 0 0 0 0 0 1 3 4 3 4 1 4 1 0 2 f9b41a1c1269bc0301fb865bfa5d33eca9267f4216c59069a99b5d1b <phone> b483045022100eb67bf6fa2b71fded0b19198383eb4a45e75bee1f0207ea41378c986a212884302202d35ace9bc3b855b7b14c064e1914cddda053798ec184871937dc3a59b9bb32e010100fdffffff4a1d6a31aef67692923beaf5746c3e3177f7090719e5f26d5ae392b0c25b91d <phone> a47304402206d0125cbcf941fce57419ed19c22f4ee64e54fc4671bf31a0fc3aeeb5aceef0702206f44436c80d559e28de00311cac6b70cdc0bc53d9f3d78897cbaa8dcff5ded2a010100fdffffff2ab55faafba7a2c42e034ca958ac00cc0f7d0eb214cc13d1666eeb6d95eb6232010000004b483045022100ff6339a400f4f45ba9f7220a658818c2287b39e0c8d55ac5f48f1fa7cd12b54502202eec8739ca3f1ab26c3164773ad0cb7bc8d05a92c3af0dee21a3027a0b2fb304010100fdffffffaaaa313654b83474468b74b338bc93191ae16585b4976ec6c0df6d5e2803fbf <phone> b483045022100e1d8079e57572613047e5d0feaba154bd6b1ed4c115136bb487cab47fe6c720602204c7ec1be709da004fbba7ca35a007eaad8960067f9ecc3106fff7b982a946410010100fdffffffdb920ad4a0c484de3aab084807b671c23aad7eddf697b23a48bafdd9b696cc14010000004b483045022100877344baddacdffdecabd3a0c453b64072f89f373750f8c28fe1c9c794d09237022036fd6491cb104672e08447bfd2fb221adfc65eb962f57049e73423170d37ec01010100fdffffff6538903c67dc01a3c069fc45d1601660d91ff093ce9a5df6c4e0e53435bff996010000004a47304402204460f39b11f869bf34b51146e25f4eca39dcf41692c6c60684b47fea22b1f8a002206c82fe15607d34196f701bb4f1ab1d8a50f9afc00bf6e0bbb5ae25c0489c6b14010100fdffffff82ab5d8eb1aa3d2318702745637b1866a17f92fcd556992a3083d0e744e1ab7a010000004a47304402206fbd84d5bdfce1e64c16d4917063d9e5ba442992b715eebf225c7bae4c91572402200b2fc074a3aa1e750009102a4824d81c18491f27a45f2efa328148f6cdb662c6010100fdffffff195788a615893f7013970ec8a6ef8d01a032343b5130b50308824868ca04db73010000004a47304402203ccee315759c7adf49475f4f40ca13c7173c1eee709ba39fc4454aa76b3bc0b702205f610fd1e2148677b121b2d66f5433c50eb38b663900020abde4acdfbcc363f7010100fdffffff56faa9c6924e2221905c11bf455079dab94f0bc6b2ef243a599953f21a66b679010000004a473044022008dee895689f6f2009ab8e32f54ccfd65915eebee3ba3b1db2fddc6f6082caae022024371b490b9c13237a2ad810029732c007c6a59fb4a815f53ce18246bdb39476010100fdffffff32ad63ac36294719c323632ea3b0b87ac3a5d024cd23a6fecd45aa75f6fe01e <phone> a47304402203ad7371bfaf287992bc14df0df20d306db1125d96dc106d5df628e00ffe8f65f02203c2514a7e8b624200bac0f6a32b7518c9f9178f5ee001240590af8be52d48341010100fdffffff99a67d2830ad7f13e587e512a41896d319198a2db6acc4793715a95ebb752235010000004b483045022100a61b462ad9590cc7a082862aeb3b992f712bd97a0dec849f4b1f2a7be053ab0a02204601e8ca7dee8a254950cf6e6a5aa73db7535f8d7e28ff72846638c8a8a4227b010100fdffffff1e0d923adfe9af7059d345843003036af0a0a95e376eea2a6453d64afe8eaca <phone> a4730440220454cb3eb3aae42c131bb2ac6e24a946d7f3c48acd27a702533cc23748535991a0220501d279847931b39159e983f9fb69b2e0c8187edb67ef60d3e652598ce9b1b46010100fdffffff535a7dbb24c9faab83ffb0f8588a5a050a98324dff86cbc3c33736c429459bc <phone> b483045022100d1026f4fe67af62a98a50b24dc27e06d12b45ac012640cc4588e6b1321614b160220784b765f025d291c6608dddfdb5fee48a4c33ed65e0dfc06bba24d49f48911af010100fdffffff5d36731c4a2a964131d684c77e9f66026141827ca2f5ee07279c87b5e4672365010000004a47304402201a1b9cd5f3908aea7244d3f8042568fda3ecf9ecd99e717ae31bb895dcffa0ea0220113f91e67647345c3498981f458881411de3a844a8490ba0f59574a4ed6b435c010100fdffffff97409d520719545c620c4c29fb9589ee2c495beff2aa06157e7277b62ca6585d010000004a473044022038719f878aebf18393001337586c822ead4b9e919cb6c7182aac803b9481139d022053c61dc49cb3f57d833499fdf3f4e9347448c83c8e33f9de55a126f55e661850010100fdffffffbc56b136f0f43cfb21222a70671059175409e1b89d1e4843ea4572b4013ef26e010000004a4730440220557f4e3f7e6ae4133ed56515a1edfd179d999097f0bc829d3d152ca9c0cc47150220438612dfd61ca806e13c7f003b672cb82c22ec14aa402c5d07da566548244be1010100fdfffffff4ab39a44c3d85489d549dc18e4a3f9b090c60a55d96d0142cfc36ecbbadad19010000004a473044022032222d2f9c42812e097f29a86d66d7ad849c41fe92717cefc1e73d60695e4bd7022025f9cfeef77a213a75a174f42326bbb1f3b003f7211e6d4203d7dbd5c334b05d010100fdffffffc0ecbab <phone> bbcade2435ff5899c60cbebcc9bfe8f5b566bc878ef860f010000004b4830450221009f9aca7cf1e2ef4842b50386b23ff38a77706cf263625f3e90323e1cbfa <phone> e548d266309b0511e2b319c5c72f967d654ffe2e9d576cfc3980434e506e49d010100fdffffff32eff66cb81c7c95be5be7b712492a45a2e0925c9f3a1c56dc220f64b4990e22010000004a473044022020f190680ec06109ca0f38b0839965b4d594bb05d6b38c94be1ecca1fc3083a902205560dde76b7e8de3a117c2a01252515fec94e78b755035da891acf058ce7ff2c010100fdffffff0713f30faf3df3eecc36e0d470427c4ff75ee83c6c587800c83a285e6d9e207e010000004a473044022006f4b18b69e02e8a41561773b6f26349800415c4d40caa0a1e43f8b1e432ff6502200de75f2b12d97f5b403dcf251906270fe699b13cd522ca2a547f7502bbd76ca1010100fdffffffeb9abcc6b62b4a4502b39cf8e95bf1a8ed025de3e92cb0308ec9cac9f09d5f32010000004a473044022037059d74e09701b5da5db39c468975acdfada034b8a970f875e76843e0874a38022005671d6e42349e283850b9766b250dc0ab99df5662c772ca2e00f355f7fbc985010100fdffffff8cf19ee3d2a410202be825ab57b0d3296aba0ce830869717a4fa6a4d3f29dc84010000004a473044022020d2d681b7081a7291eb92b70168f5e9b76fbfb725cd1d7d5ace2639d626d9e002200a9229c35cbbb2dc572e1f9e7994d458d7abdae1b53188a555c67e863c088fb8010100fdfffffffb18c17a7c29237b5fd84774da48b2008f685648b1071023ae7edccfdd21462d010000004b483045022100efd8b5b3854a744863e43c9e235cf93a3eb17cb6061dde8f37535ea20d1945c702205aa93d4ef6e38b57d505072b251c096166ae993d83303e8710c3ed4772e8fba2010100fdffffffa7df914434ebd4bf85b2484e87844bc0d1a40476e9ef755638dedb87e5ac3ec <phone> a47304402201b9c8e96e4ff3927a48e5d0389937ad847c1b313b2d50edffef035cdfe18ccc402204307afba5a45aa2df3504e2d19e27b4ddb7c0b3a2c9f027bc658213e05d284e1010100fdffffff54073a38f6810e2df1d5f618ea1c6f304510e47a9901f1660c57bdb8dd6e25bd000000004b483045022100a42a8d2a29bf7d5d719363e222e5fd2bb5dc39b88bd411054ac5efc08a91a583022016362fd43e797f65530550d2ff4e16fd4226ac8ec8aba8232e00bb888785cde4010100fdffffffa671657e815be305aa65867ea96e0df76b3a6ba0f76ac4c46c353db1539492a <phone> b483045022100a022a65c6b5d7975dc4a908d9609eab81285cf02385221f612c668015133ca3f <phone> f45da55665488d340725af2272eaf0ebace667da3abae9d872f97c5dc4010100fdfffffff1a9960e1535bffed89f39d35633a0a101e15fd14134ae2f01d12ceaa5526c20000000004b483045022100e56c37899fa196ee44e36b7058f0f5614ec7a39394c87343e4ec8cce6fb7edb1022060d5a5bc32fd319fe29a6289a1c5a3fa7ab116458eb178bd4d5452d5a3d787c2010100fdffffff5428d5b891f26c68216b9f2e24509e3f850a1d02b785be4951ac6b52c6c203cd000000004a47304402202628b26b8d71cb3fea7babdfa <phone> af85699010ecc5364b75faec7e23602205bb3678f43c5725c815f64516eb73c94b027fbe93b0e2f16b5886b3b44939b62010100fdffffffc950908e94af4fb542e68b8f5486f98fbab4b79728e23640af42c5d997969d15010000004a47304402205639aff74dfbcf94381f51d3a5e06c2ca6b2667a7818e445f68e7a9e80043f760220549d3ceb1a19e9ed3d59ed79f68be9746e0422240247006b1d3b6012a13f407e010100fdffffff01e083b41bd3f1c78b4bb8d9ad44f76ba835646151ed20ed7702aeec9c730a1d000000004b483045022100a780da0591835c9228073582020aaa089ee8962a7a2a39091cb384ded0d80905022068bf1091d09326745ec544e1bd9fd856e30d1d394503f5ef367f1d6f7e0a3c70010100fdffffffd7b5033b444daad4950366855184e83c4125a6323c83c9e1fba3b64e6d332cdc010000004b48304502210083147402aff6d0682f4282199d3ee30b690c603d3b35f313c72c9a5b8d36630d02206549757777cffbb9becbedf31f304ba3c6e67d2d7820a85dcc126b81ae853d23010100fdffffff738f88b9ed5be2a59eb23d1042b6b645def6f7dcd7053ed8e6681657fe2668af010000004b4830450221008236806f3e8d23154e413f9848c1542673a7e8a700cf8a5cda2fe3091d82c57302200aec446be2fc7e3d19f819849632d97462f10f3a26190ada025ae546ea06981f010100fdffffffbec4f8414a0c3cc33ec64f0c0a08d422b1b885b320de4c59f7e487937147fba <phone> b483045022100c13a908fe1565ab752f1a6a2b6b37a2e2c154a1df1017781bf03f3f7a6fd57130220079670f3b1f1e79e7b6ac44c305fc4d3dc9632799bbbe30a096b3e767a79d6b4010100fdffffff738f88b9ed5be2a59eb23d1042b6b645def6f7dcd7053ed8e6681657fe2668af000000004a473044022059ce8dd4d05eb8eb037f3d2317b215a7e7c040ef8f182b88e106042100892e4002205de259afa7624b86a3ec427cd6b39192a5814190c1d09ebc27043d3718c39c00010100fdffffff73700f0e896a4071a4fabd6371c5ddf42744136d2e7cf5f09c7063a6817d9f1c000000004b4830450221009aca2aac4cefb2b168194a9d5396d39d531f50f2c9b4eee02ef28e829d1e1e470220493eba6f56a50fe6282b127f16946c7bd6525bb37143b06d4ca1e4469c803a0c010100fdffffffc8a41808b844520e46a7a9d5dc58ffd13941d013979916226b6a39beacf8feba000000004b483045022100e980ac919e371de45e107352b857c595b2bb03e1dee86fde1050eb37f66004eb02201089a4b359a08e7160bbe9d9beae86251f92ef3f02ac094cc2e1fe3135026b7a010100fdffffffb38c1c912373ab6b5ade53f634877fa3a851362e7e6d778b11e37b6b08248d34070000004b483045022100aaeb5f185653c51b9a88583fb1211ab4c4c75ad4d9a6bffb1a87fbf6b59d075402205fad99e1e0e00a46c7f3c610901f8e44ebc03e446da1a95887bcb88caa5f750c010100fdffffffc0f3a <phone> e2c1b36cff10b52765645fd25a1b07fd5405d93a1bf885981000000004a47304402205764f36473509eb6fa0e3239f6140a26b03410a3c9723e531157f0128bca75f0022071d2b16599217e5cd22727cacb9797f20f5522a3055af5b2f2884111b70deeb9010100fdffffffbee4a2188b524b97785b4b4123c3d0e0d2a8068387e7ca10e81b3004aef52bd <phone> b483045022100ab3872df421402b67754e3b56b92fc9f24faeea3aa8d7aa16e6272fcd11ace91022072812d10d21fe30ff951fae96e2bf7081fe7bd6eaebc3501dce7cd757ec67fdb010100fdffffff2887aee1bd96208b2bd05b43e17d4fc44c4db04834ea3f7472f7391ec55328e <phone> b483045022100b236d0f0c00b601cbcfa8367f890bbb5de62e29d5fa7d42649f03342edc1c <phone> ff8bbdaf7ad71eecf48b4b60984df8d95680fd67d756dece37256a2e53730010100fdffffff1f871d4a2d45ec14af5413af5aa0bdf658362aa94fe123fce3bdc609e6a1a5fc000000004a4730440220366773cf00b63f268bf95d8a2bde5a4a0a4ad43ff4709a611679fda37d5abc8c0220128f0009cfd40fd74ed698e589de6b5e20a43afcf0a4c497fc86bda048c4462f010100fdffffff6bb7ea26b9bdf4ae5d34d79c3e2e0d0c9f3f8b851150985125035605f8e1a288000000004b4830450221008003628c014d7130f6ea40754a98deb90b3fcf0aaff6a568c6a1c9b671cd3e760220249bb59d35fa56531e186461270cd3ea41ae8dcc985ff6e73b0bb91d592c4c16010100fdffffff08d90ec68db6646b07f61d5ee87d223deb8331594d0238c017f22a488835c39d000000004b483045022100fd53f61e54b108dc05527724ff71afed67d6d210b8afa4271e951f95130092fa02201320b754b012712feb157e97d1713e4977de81f5a56e2c97e5535d057b9cbf18010100fdffffff7b7b86363515b0f4f07a266e83e9f33aad0a34225e900c49ac6094d1154e1fec010000004a47304402204fd96c861d3a3d83f91a5394c6df933db7462b4eba6a6125c3051518be5844f802204238293ecf8a779300093de72756d295dba3758944d472d594b27567481e147c010100fdffffffa56afd6e38a987777a1ebcbec0430d94661f39941231eacf64a038c8730ed23b010000004a47304402203d1a853f <phone> a4f9cdf9b50f87b8912085737247b9d75afc6596ae44d7022044235843dd555ec08adcd85a548484b8c98490be49e507d525c5ee98d33c470b010100fdffffff2aa5e50dc9c51bd94d <phone> aae4f22b4717ef4729bc249183c3be5509fd00000000171600149f7fd096d37ed2c0e3f7f0cfc924beef4ffceb68fdffffff4b343ce2ebcd43be4f21d79f93ab4d20497fece1ac57c8b94f882698363e295600000000171600149f7fd096d37ed2c0e3f7f0cfc924beef4ffceb68fdffffff3dcf24194b9dd3f252f9544f236dfa6711349f409d0f68457e92cf29f9a7c3e <phone> b4830450221009f0df211d72443be2f60394de021513e74b74248e6ef57e8c9529736dd1ab61502202ab62e0a21dd75cad9bd866aaa8b9a5cca49156d6590794361301c8e6e3e033c010100fdffffffdb9ec8af478e3e35722db1ad1a21f844be7c0ba1cfc37243e3befe30f4b007ab000000004a473044022011d29748eccb00a163d31ca72de7a224905d1aa99eb456b3c33afd3f9820895d <phone> cd003af55462aab3d921beacab92253a8b80d032f52795e00fd50e <phone> fdffffff4eadceace3ede8948e8ca6bb6b439790f3c70591edae53f685196d3b5f3ec879020000004a473044022018853567387850ae6806a899e07d42875ba91a18027bd37b22a2956d72d <phone> f912918e27a871b310c1985517fe927104076190219cf97658d1fcbb9cffb76010100fdffffff8e00fd85b96618944c054eb71f14002d88a4aa0c4414fe <phone> f12ea85d020000004b483045022100c4f2c4e40291d59f911a73577ba5fce075ad9f706bbe0c462156c9bfd75a2bbf02201e8311d5311b4ce0d9eebb381e356657714378389c89814a4154d3d3de88dce9010100fdffffff09eb01207eec33aa780dbb3a92406c7df4d672a68cf4ef2aeea014e5de6eab04010000004a4730440220259f521ca028046b03957d49586352b55967f1ec43c133845dac2b6ac7cbdbbf0220523af29e56dc887dc0de794181eca29e009b53a744f443f6bf3618f5adce081f010100fdffffff016b761a160000000017a91480aa3c461c7633fc1ee1ce01397bf863330ce6c0870000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000247304402203945c2e0d1784f2c2e482182d2ebf64f718ceed37a8a3283b683368f78fcb248022052bb37761ecb88f71cc3a83aecc99ca626f1157f3952e7ff332bd1856850299501010002483045022100d0fcc7854bc85b5edfb0c6910148a29fdc6a5b45c26c52a20d45b8cb4e310a2d022013e4f10363d58db4bb3ba3b0f5b04bfaf35a90a7fc1a858fcfe0731a441569f4010100000000000000000000 "" , "" utxos "" :[{ "" tx_hash "" :""b 2 d1b5999a06596c21f46792ca3ed3a5bf65b81f30c09b26c1a1419b2f101434 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" d6915bc2b092e35a6df2e5190709f777313e6c74f5ea3b929276f6ae316a1d4a "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 3 2 6 2 eb956deb6e66d113cc14b20e7d0fcc00ac58a94c032ec4a2a7fbaa5fb52a "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" f3fb03285e6ddfc0c66e97b48565e11a1993bc38b3748b467434b8543631aaaa "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 1 4 cc96b6d9fdba483ab297f6dd7ead3ac271b6074808ab3ade84c4a0d40a92db "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 9 6 f9bf3534e5e0c4f65d9ace93f01fd9601660d145fc69c0a301dc673c903865 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 7 aabe144e7d083302a9956d5fc927fa166187b6345277018233daab18e5dab82 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 7 3 db04ca <phone> b530513b3432a0018defa6c80e9713703f8915a6885719 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 7 9 b6661af25399593a24efb2c60b4fb9da795045bf115c9021224e92c6a9fa56 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" e801fef675aa45cdfea623cd24d0a5c37ab8b0a32e6323c319472936ac63ad32 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 3 5 2 2 7 5 bb5ea9153779c4acb62d8a1919d39618a412e587e5137fad30287da699 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" a8ac8efe4ad653642aea6e375ea9a0f06a <phone> d35970afe9df3a920d1e "" , "" vout_index "" : <number> } , { "" tx_hash "" :""c 2 9 b4529c43637c3c3cb86ff4d32980a055a8a58f8b0ff83abfac924bb7d5a53 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 6 5 2 3 6 7 e4b5879c2707eef5a27c82416102669f7ec784d63141962a4a1c73365d "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 5 d58a62cb677727e1506aaf2ef5b492cee8995fb294c0c625c541907529d4097 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 6 ef23e01b47245ea43481e9db8e1095417591067702a2221fb3cf4f036b156bc "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 1 9 adadbbec36fc2c14d0965da5600c099b3f4a8ec19d549d48853d4ca439abf4 "" , "" vout_index "" : <number> } , { "" tx_hash "" :""0 f86ef78c86b565b8ffe9bccebcb609c89f55f43e2adbc4b88079898b3baecc0 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 2 2 0 e99b4640f22dc561c3a9f5c92e0a2452a4912b7e75bbe957c1cb86cf6ef32 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 7 e209e6d5e283ac80078586c3ce85ef74f7c4270d4e036cceef33daf0ff31307 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 3 2 5 f9df0c9cac98e30b02ce9e35d02eda8f15be9f89cb302454a2bb6c6bc9aeb "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 8 4 dc293f4d6afaa417978630e80cba6a29d3b057ab25e82b2010a4d2e39ef18c "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 2 d4621ddcfdc7eae231007b14856688f00b248da7447d85f7b23297c7ac118fb "" , "" vout_index "" : <number> } , { "" tx_hash "" :""c 7 3 eace587dbde385675efe97604a4d1c04b84874e48b285bfd4eb344491dfa7 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" bd256eddb8bd570c66f101997ae41045306f1cea18f6d5f12d0e81f6383a0754 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" a1929453b13d356cc4c46af7a06b3a6bf70d6ea97e8665aa05e35b817e6571a6 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 2 0 6 c52a5ea2cd1012fae3441d15fe101a1a03356d3399fd8febf35150e96a9f1 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" cd03c2c6526bac5149be85b7021d0a853f9e50242e9f6b21686cf291b8d52854 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 1 5 9 d9697d9c542af4036e22897b7b4ba8ff986548f8be642b54faf948e9050c9 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 1 d0a739cecae0277ed20ed51616435a86bf744add9b84b8bc7f1d31bb483e001 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" dc2c336d4eb6a3fbe1c9833c32a625413ce8845185660395d4aa4d443b03b5d7 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" af6826fe571668e6d83e05d7dcf7f6de45b6b642103db29ea5e25bedb9888f73 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" a1fb47719387e4f7594cde20b385b8b122d4080a0c4fc63ec33c0c4a41f8c4be "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" af6826fe571668e6d83e05d7dcf7f6de45b6b642103db29ea5e25bedb9888f73 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 1 c9f7d81a663709cf0f57c2e6d134427f4ddc57163bdfaa471406a890e0f7073 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" bafef8acbe396a6b <phone> d04139d1ff58dcd5a9a7460e5244b80818a4c8 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 3 4 8 d24086b7be3118b776d7e2e3651a8a37f8734f653de5a6bab7323911c8cb3 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 8 1 5 9 8 8 bfa1935d40d57fb0a125fd455676520bf1cf361b2c3e40065570a6f3c0 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" d72bf5ae04301be810cae7878306a8d2e0d0c323414b5b78974b528b18a2e4be "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" e12853c51e39f772743fea3448b04d4cc44f7de1435bd02b8b2096bde1ae8728 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" fca5a1e609c6bde3fc23e14fa92a3658f6bda05aaf1354af14ec452d4a1d871f "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 8 8 a2e1f80556032551985011858b3f9f0c0d2e3e9cd7345daef4bdb926eab76b "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 9 dc33588482af217c038024d593183eb3d227de85e1df6076b64b68dc60ed908 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" ec1f4e15d19460ac490c905e22340aad3af3e9836e267af0f4b <phone> b7b "" , "" vout_index "" : <number> } , { "" tx_hash "" :""3 bd20e73c838a064cfea311294391f66940d43c0bebc1e7a7787a9386efd6aa5 "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" fd0955bec3839124bc2947ef17472bf2e4aa05553965104dd91bc5c90de5a52a "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 5 6 2 9 3 e369826884fb9c857ace1ec7f49204dab939fd7214fbe43cdebe23c344b "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" e7c3a7f929cf927e45680f9d409f341167fa6d234f54f952f2d39d4b1924cf3d "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" ab07b0f430febee34372c3cfa10b7cbe44f8211aadb12d72353e8e47afc89edb "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 7 9 c83e5f3b6d1985f653aeed9105c7f39097436bbba68c8e94e8ede3accead4e "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 5 da82ef18664968630fe14440caaa4882d00141fb74e054c941866b985fd008e "" , "" vout_index "" : <number> } , { "" tx_hash "" : "" 0 4 ab6edee514a0ee2aeff48ca672d6f47d6c40923abb0d78aa33ec7e2001eb09 "" , "" vout_index "" : <number> } ] }",2
bitcoin/bitcoin,"we should remove max_block_base_size in functional tests ? i can see that <user> pushed a commit to ` remove confusing max_block_base_size ` ( 3 babbcb48 ) , by the way , i still can see the use of it in a lot of functional tests ( p2p_segwit , mempool_accept . <repeated> ) , do these test cases still make any sense ? should we remove them as well ?",2
bitcoin/bitcoin,"idea suggestion : allow using external db ( for instance rethinkdb ) engines for block storage considering the huge size of block database , maybe it is practical to allow users to use external db engines for this . imho , rethinkdb , with it ' s gui , is very easy to setup , including it ' s mirroring and clustering . because of size of blocks db and of amount of time it is required to download and / or reindex existing backup , mirroring features of real db engines may be more practical to use . use case user downloads bitcoin core <number> . user downloads and sets up rethinkdb ( possibly with mirroring and / or clustering ) <number> . user selects usage of rethinkdb in bitcoin - qt options window <number> . user restarts bitcoin - qt <number> . bitcoin - qt checks db structure and tables and indexes and creates / changes them as needed <number> . bitcoin - qt does it ' s work on blocks db using rethinkdb * such db could be placed on external computer * connection to db could be encrypted and secured * less chances to destroy hdd / ssd on local pc and data on it ( because of intensive use of drive by bitcoin software ) * less chances to lose blocks db * less load on network from those who lost their blocks db and now re - downloading it * easier for user to shutdown bitcoin - qt - less time to wait while bitcoin - qt syncs and closes db * easier to restart in case of power failures",2
bitcoin/bitcoin,""" segmentation fault : <number> "" on macos when "" - rescan "" large ( <number> gb ) wallet . dat its a custom testnet based on ` v0 . <number> . 0 rc1 ` but i could not test on real bitcoin , because i do not have such large btc wallet . dat . i may test on regtest soon . - reproduce run bitcoind with ` - rescan ` large wallet . dat ( ~ <number> gb mining wallet ) . [ image ] ( <url> strange thing is linux64 is just fine , but macos and win10 this error . - macos ` ` ` segmentation fault : <number> ` ` ` - win10 : similar behavier like macos , but daemon just killed . no segfault or any error log . - fyi 2 cpu 4 0 9 6 ram macos ( high sierra <number> . <number> ) 2 cpu 4 0 9 6 ram ( macbook air <number> inch <number> ) - related issues bitcoin / bitcoin # <number> bitcoin / bitcoin # <number> bitcoin / bitcoin # <number>",2
bitcoin/bitcoin,"question : how to debug using docker & ci shell script ? hi , my pr # <number> fails on several platforms so i have attempted to run on my ubuntu <number> : ` ` ` bash file_env ="". / ci / test / 0 0 _setup_env_native_tsan . sh "" . / ci / test_run_all . sh ` ` ` as per instructions in <url> i can reproduce issue on ci which is great news . however , i would love to modify source code and re - run the ` file_env ="". / ci / test / 0 0 _setup_env_native_tsan . sh "" . / ci / test_run_all . sh ` script or attach to docker to run a failing functional test again so that i can debug it easier . does anybody have a workflow for this ? notes i have tried ` docker attach < container id > ` but it ' s not possible to simply execute ` test / functional / wallet_hd . py ` as it fails in that docker instance because it is supposed to be run somehow differently ( that ' s as much as i gather from studying ` ci / test_run_all . sh ` ) .",2
bitcoin/bitcoin,"processblock not accepted , leveldb batch commit failure : io error : unsufficient space fatal error has occurred , bad_alloc runaway exception error when starting bitcoin core debug log says error on processblock then creates orphanblocks and finally ends with : leveldb batch commit failure : io error : winmapfile . append : : unmapcurrent region or mapnewregion : unsufficient memory available to process this task error acceptblock : addtoblockindex failed error processblock : acceptblock failed processblock , block not accepted > orphanblock can anyone help me with this issue ? i did fix the bad alloc runaway error with this memory issue before by configuring the configuration file adding the following bind = <number> . <number> port = <number> maxconnections = <number> maxmempool = <number> upnp = <number> dnsseed = <number> discover = <number> dbcache = <number> dblogsize = <number> par = <number> checkblocks = <number> checklevel = <number> disablewallet = <number> rpcbind = <number> . <number> rpcport = <number> rpcallowip = <number> . <number> maxuploadtargets = <number> rescan = <number> maxorphanblocksmib = <number> testnet = <number> can anyone help me solve the issue ? it keeps coming back at the memory issue as the underlying problem but why does it not accept the block ? i think i need to fix the memory issue first . this is done on the latest bitcoin core wallet",2
bitcoin/bitcoin,"unable to compile on native macos after 3 caee16946575e71e90ead9ac531f5a3a1259307 introduced with 3 caee16946575e71e90ead9ac531f5a3a1259307 . ` ` ` cxxld qt / test / test_bitcoin - qt undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_xonly_pubkey_parse "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_schnorrsig_verify "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) ld : symbol ( s ) not found for architecture x86_64 clang : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ bitcoin - tx ] error <number> make [ <number> <sad> * * * waiting for unfinished jobs . <repeated> undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_xonly_pubkey_parse "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_schnorrsig_verify "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) ld : symbol ( s ) not found for architecture x86_64 clang : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ bitcoin - wallet ] error <number> undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_xonly_pubkey_parse "" , referenced from : xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_xonly_pubkey_parse "" , referenced from : "" _secp256k1_xonly_pubkey_parse "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_schnorrsig_verify "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_schnorrsig_verify "" , referenced from : "" _secp256k1_schnorrsig_verify "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) ld : symbol ( s ) not found for architecture x86_64 ld : symbol ( s ) not found for architecture x86_64 ld : symbol ( s ) not found for architecture x86_64 clang : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ bench / bench_bitcoin ] error <number> clang : error : linker command failed with exit code <number> ( use - v to see invocation ) clang : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ bitcoind ] error <number> make [ <number> <sad> * * * [ bitcoin - node ] error <number> undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_xonly_pubkey_parse "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_schnorrsig_verify "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) ld : symbol ( s ) not found for architecture x86_64 clang : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ test / test_bitcoin ] error <number> undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_xonly_pubkey_parse "" , referenced from : undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : undefined symbols for architecture x86_64 : "" _secp256k1_xonly_pubkey_tweak_add_check "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_schnorrsig_verify "" , referenced from : "" _secp256k1_xonly_pubkey_parse "" , referenced from : "" _secp256k1_xonly_pubkey_parse "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : checkpaytocontract ( xonlypubkey const & , uint256 const & , bool ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) "" _secp256k1_schnorrsig_verify "" , referenced from : "" _secp256k1_schnorrsig_verify "" , referenced from : xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) xonlypubkey : : verifyschnorr ( uint256 const & , span < unsigned char const > ) const in libbitcoin_consensus . a ( libbitcoin_consensus_a - pubkey . o ) ld : symbol ( s ) not found for architecture x86_64 clang : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ qt / test / test_bitcoin - qt ] error <number> ld : symbol ( s ) not found for architecture x86_64 ld : symbol ( s ) not found for architecture x86_64 clang : error : linker command failed with exit code <number> ( use - v to see invocation ) clang : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ bitcoin - gui ] error <number> make [ <number> <sad> * * * [ qt / bitcoin - qt ] error <number> make [ <number> <sad> * * * [ all - recursive ] error <number> make [ all - recursive ] error <number> ` ` `",2
bitcoin/bitcoin,"bitcoincore fatal internal error when syncing hey guys so i just downloaded bitcoin core on my macbook air today and it was syncing . it synced up to <percent> and now says : "" error fatal internal error occurred , see debug . log for details "" i do not know anything about coding so if some one can guide me through the process step by step it would be great . also i already transferred money into the wallet while it was syncing but now i cannot recover it and it never was even fully synced ! can someone please help me ?",2
bitcoin/bitcoin,"fail to build on fedora <number> ` ` ` $ cat / etc / system - release fedora release <number> ( thirty two ) $ gcc - - version | grep gcc gcc ( gcc ) <number> . <number> <number> ( red hat <number> . <number> - <number> ) $ make - - version gnu make <number> . <number> built for x86_64 - redhat - linux - gnu copyright ( c ) <number> - <number> free software foundation , inc . license gplv3 + : gnu gpl version <number> or later < <url> this is free software : you are free to change and redistribute it . there is no warranty , to the extent permitted by law . $ git rev - parse head 0 3 6 8 9 3 1 7 0 2 1 a72431762c1974530f2a980a7fffa $ . / autogen . sh $ . / configure $ make clean $ make . <repeated> cxx libbitcoin_common_a - warnings . o ar libbitcoin_common . a bfd plugin : script / libbitcoin_common_a - descriptor . <surprise> file too short / usr / bin / ranlib : out of memory allocating <number> bytes after a total of <number> bytes make [ <number> <sad> * * * [ makefile : <number> : libbitcoin_common . a ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / bitcoin / src ' make [ <number> <sad> * * * [ makefile : <number> : all - recursive ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / bitcoin / src ' make : * * * [ makefile : <number> error <number> ` ` `",2
bitcoin/bitcoin,"bech32 address not provided when creating a new receiving address < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * < ! - - - what behavior did you expect ? - - > i go to the receive tab , ensuring that "" generate native segwit ( bech32 ) address "" is selected . i fill the label as "" test bech32 "" and then click "" create new receiving address "" . i expect the address to be a bech32 address * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > the address is a p2pkh address . ! [ 2 0 2 0 0 7 0 4 _174715_bitcoin_no_work ] ( <url> * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > on my own wallet this is reproducible according to the steps above each time . * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > v0 . <number> from bitcoin . org / en / bitcoin - core / ( the issue was present in <number> . <number> too ) < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > linux debian <date> - <number> + deb10u1 (x 8 6 - <number> ) hdd kde plasmashell <number> . <number> < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > this is using a pre - hd wallet",2
bitcoin/bitcoin,"on windows <number> most of the time the wallet is in the - ( not responding ) mode , please tell me what to do < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * < ! - - - what behavior did you expect ? - - > * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",2
bitcoin/bitcoin,"built <number> . <number> from source , get the warning "" this is a pre - release . <repeated> "" developers forgot to remove it . < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * < ! - - - what behavior did you expect ? - - > * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",2
bitcoin/bitcoin,"bitcoin - core snap issues following up the recent discussion about bitcoin core packaging (# <number> , [ irc meeting ] ( <url> i have started to test [ ` bitcoin - core ` ] ( <url> snap . <number> . the most frighten issue , imo , is automatic updates : - <url> - <url> > however , some users do not wish to have their software updated immediately . . <repeated> snaps enable users to control when updates are delivered . users can postpone them to update outside the working day , overnight , or later in the month it seems there is no way to disable updates at all . <number> . the default datadir is ` ~ / snap / bitcoin - core / common / . bitcoin ` , which means it will be removed during removing of ` bitcoin - core ` snap or the entire snap framework . <number> . the gui settings ( [ currently ] ( <url> ` qsettings ` ) are stored in ` ~ / snap / bitcoin - core / <revision> / . config / bitcoin ` directory , which means they will be dropped after the snap update . <number> . ~ on debian <number> i did not find the way to launch ` bitcoin - qt ` with command line options . this makes it impossible to use ` - choosedatadir ` option ( a minor issue ) . ~ ( ` bitcoin - core . qt ` [ works ] ( <url> <number> . on debian <number> "" start bitcoin core on system login "" does not work ( a minor issue ) . should we clear inform users about mentioned pitfalls ? refs # <number> - # <number>",2
bitcoin/bitcoin,"p2p message response iiuc , since # <number> ( 3 4 1 7 3 5 eb8f42e898cf9d4d130709471e5d01abe2 ) has been merged , i . e . v0 . <number> , the bitcoin core has no means to send [ ` getblocks ` ] ( <url> messages to its peers . how long should we support the means to handle ` getblocks ` messages from other peers ?",2
bitcoin/bitcoin,"balance is <number> after send transaction in testnet v0 . <number> and blocksonly flag enabled < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > i tried to send <number> btc from <number> btc total in testnet3 . the daemon reports a txid but this one is not visible in any explorer and the transaction is not processing it at all . furthermore the balance is set to <number> ( getbalance "" * "" <number> ) . i can query the transaction via listtransactions . it is a transaction from and to the same wallet . also maybe related , in regtest mode some invisible fee is reduced from total wallet balance but not logged in any receive - send info . the amount is just missing . < ! - - - what behavior did you expect ? - - > just send a test transaction < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > bitcoin core version v0 . <number> . <number> ( release build ) - blocksonly = <number> - prune = <number> < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > linux <number> ( ubuntu <number> . <number> lts ) < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > there is nothing special logged : ` ` ` <number> - <number> - 0 3 t <time> z [ test ] committransaction : ctransaction ( hash = 8 9 6 cc84018 , ver = <number> , vin . size = <number> , vout . size = <number> , nlocktime = <number> ) ctxin ( coutpoint ( 2 1 8 6 6 e5057 , <number> ) , scriptsig = 1 6 0 0 1 4 a5a09ce3f5f5d78d39 , nsequence = <phone> ) ctxin ( coutpoint ( 5 a847af857 , <number> ) , scriptsig = 1 6 0 0 1 4 a5a09ce3f5f5d78d39 , nsequence = <phone> ) cscriptwitness ( 3 0 4 4 0 2 2 0 7 f290913ac2c796278b9ae2271f17c39e9039bbbfe6e37e6a3d9b97fd19d <phone> e46bceec87b3195ca0fe1477366ef21c9f9a11ffd7acec039a3dea8cf2839501 , 0 2 baab <phone> a82ced2b84009217fd81e83d3325d44e865970f3ffe9c7a162 ) cscriptwitness ( 3 0 4 4 0 2 2 0 6 ba62fc2a8a37c59e7474f318021fd09c67e6b6b38aaf7ac10ec60125c04555c02204608cd5764f1c38f814b55f8e5629f0a69a2f07ac094505a1249d0524fa3ec0b01 , 0 2 baab <phone> a82ced2b84009217fd81e83d3325d44e865970f3ffe9c7a162 ) ctxout ( nvalue = <number> , scriptpubkey = a914da26d8b5010fb615fe442b678c ) ctxout ( nvalue = <number> , scriptpubkey = a914fafbd45c56f6a2a593b115b0fa ) <number> - <number> - 0 3 t <time> z [ test ] addtowallet 8 9 6 cc8401843a2f7d0682a43faa180a5b2f722db96039a9d30b2158e3b7e97ea new ` ` ` ` ` ` { "" address "" : "" 2 nd8hqcu4r4raj6pank3fthsb9szx8bad57 "" , "" category "" : "" receive "" , "" amount "" : <number> , "" label "" : "" "" , "" vout "" : <number> , "" confirmations "" : <number> , "" trusted "" : false , "" txid "" : "" 8 9 6 cc8401843a2f7d0682a43faa180a5b2f722db96039a9d30b2158e3b7e97ea "" , "" walletconflicts "" : [ ] , "" time "" : <phone> , "" timereceived "" : <phone> , "" bip125 - replaceable "" : "" unknown "" } , { "" address "" : "" 2 nd8hqcu4r4raj6pank3fthsb9szx8bad57 "" , "" category "" : "" send "" , "" amount "" : - <number> , "" label "" : "" "" , "" vout "" : <number> , "" fee "" : - <number> , "" confirmations "" : <number> , "" trusted "" : false , "" txid "" : "" 8 9 6 cc8401843a2f7d0682a43faa180a5b2f722db96039a9d30b2158e3b7e97ea "" , "" walletconflicts "" : [ ] , "" time "" : <phone> , "" timereceived "" : <phone> , "" bip125 - replaceable "" : "" unknown "" , "" abandoned "" : false } ` ` ` does maybe the peers do not accept my transaction ? all peers have a lower version : ` ` ` "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" : "" / satoshi : <number> . <number> / "" , "" subver "" ` ` `",2
bitcoin/bitcoin,""" <number> "" address unexpectedly changed to "" m "" address in testnet using bitcoin core <number> testing a change i made to my local nomp pool software . - my bitcoin core * * bitcoin - cli getnewaddress * * gave me the address that nomp used to communicate with the bitcoin test network ( 2 n5tv3gjzbd1zz2hri2ffybhsm1aehpnqfz ) ; - i began mining ; - i found <number> blocks , but at the heights found , instead of having my "" <number> "" address , it showed all were found by the ( random ? ) "" m "" address in the link below these blocks on testnet ] ( <url> ( other transactions shown are test transactions with faucet coins ) i have no idea where this "" m "" address came from or how or why it "" changed "" from my "" <number> "" address ; it does not belong to my bitcoin core wallet and i have no access to the funds ( not an issue but it would be nice to return faucet coins ) . concern is whether something like this can occur on mainnet .",2
bitcoin/bitcoin,"flushstatetodisk ( ) takes more than <number> minutes ` ` ` <number> - <number> - 0 6 t <time> z [ qt - init ] shutdown : in progress . <repeated> <number> - <number> - 0 6 t <time> z [ msghand ] msghand thread exit <number> - <number> - 0 6 t <time> z [ net ] net thread exit <number> - <number> - 0 6 t <time> z [ scheduler ] scheduler thread interrupt <number> - <number> - 0 6 t <time> z [ shutoff ] dumped mempool : <number> . 0 1 6 0 4 1 s to copy , <number> . 0 4 3 1 3 2 s to dump <number> - <number> - 0 6 t <time> z [ shutoff ] flushstatetodisk : write coins cache to disk ( <number> coins , 9 4 9 3 5 7 1 kb ) started <number> - <number> - 0 6 t <time> z [ shutoff ] flushstatetodisk : write coins cache to disk ( <number> coins , 9 4 9 3 5 7 1 kb ) completed ( <number> . 5 7 s ) <number> - <number> - 0 6 t <time> z [ shutoff ] flushstatetodisk : write coins cache to disk ( <number> coins , 1 0 2 7 9 9 7 kb ) started <number> - <number> - 0 6 t <time> z [ shutoff ] flushstatetodisk : write coins cache to disk ( <number> coins , 1 0 2 7 9 9 7 kb ) completed ( <number> . 0 7 s ) <number> - <number> - 0 6 t <time> z [ shutoff ] shutdown : done ` ` ` i understand that cache is about <number> gb , nevertheless , is it expected flush duration ? configuration datadir resides on ssd - blocksdir resides on hdd - master ( 8 6 7 7 1 d431054efb780a2be4a83a6952530c14875 )",2
bitcoin/bitcoin,"private test network - outgoing connections ? hello , i wanted to make a private network of bitcoin nodes ( in testnet ) but they are not connecting to each other . they receive addr messages but do not issue a connection afterwards . i have <number> different hosts with <number> different ip adresses ( but same sub network ) . <number> of them are connected to a fourth one ( addnode rpc call ) . the fourth one issues addr messages to the nodes but they will not connect to each other . # # # describe the issue # # # # what behavior did you expect ? if a node learn about a new node ( by receiving an addr message ) and if its <number> outgoing connections are not filled it will try to connect to the new node # # # # what was the actual behavior ( provide screenshots if the issue is gui - related ) ? the node will not issue an outgoing connection # # # # how reliably can you reproduce the issue , what are the steps to do so ? all host : ` $ . / bitcoind - datadir <annoyed> home / jpe / bitcoin - test / datadir - conf = bitcoin . conf - debug = net - debug = rpc - debug = addrman - printtoconsole - logips ` test the connection with bitcoin - cli getconnectioncount rpc call # # # # what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? bitcoin <number> . <number> , from the website # # # # any extra information that might be useful in the debugging process . # # # # # bitcoin . conf ` ` ` # generated by <url> # this config should be placed in following path : # ~ / . bitcoin / bitcoin . conf # [ network ] # allow dns lookups for - addnode , - seednode and - connect values . dns = <number> # query for peer addresses via dns lookup , if low on addresses . dnsseed = <number> # automatically create tor hidden service . listenonion = <number> listen = <number> # [ debug ] # run this node on the bitcoin test network . testnet = <number> # [ rpc ] # accept command line and json - rpc commands . server = <number> rpcuser = user rpcpassword = qwerty # [ sections ] # most options automatically apply to mainnet , testnet , and regtest networks . # if you want to confine an option to just one network , you should add it in the relevant section . # exceptions : the options addnode , connect , port , bind , rpcport , rpcbind and wallet # only apply to mainnet unless they appear in the appropriate section below . # options only for mainnet [ main ] # options only for testnet [ test ] # listen for incoming connections on non - default port . # listen for json - rpc connections on this port rpcport = <number> rpcallowip =[ my_ip_here ] rpcbind = <number> . <number> # options only for regtest [ regtest ] ` ` ` # # # # # logs the node connected to the <number> others ` ` ` <number> - <number> - 2 9 t <time> z bitcoin core version v0 . <number> ( release build ) <number> - <number> - 2 9 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 7 a8cd3e06cd5edbfe9dd1dbcc5dacab279376ef7cfc2b4c75 have valid signatures . <number> - <number> - 2 9 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 dbe94253893cbd463 <number> - <number> - 2 9 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) ' sha256 implementation <number> - <number> - 2 9 t <time> z using rdrand as an additional entropy source <number> - <number> - 2 9 t <time> z default data directory / home / jpe / . bitcoin <number> - <number> - 2 9 t <time> z using data directory / home / jpe / bitcoin - test / datadir / testnet3 <number> - <number> - 2 9 t <time> z config file : / home / jpe / bitcoin - test / datadir / bitcoin . conf <number> - <number> - 2 9 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 2 9 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 2 9 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 2 9 t <time> z using <number> threads for script verification <number> - <number> - 2 9 t <time> z scheduler thread start <number> - <number> - 2 9 t <time> z warning : the rpc server is not safe to expose to untrusted networks such as the public internet <number> - <number> - 2 9 t <time> z http : creating work queue of depth <number> <number> - <number> - 2 9 t <time> z starting rpc <number> - <number> - 2 9 t <time> z starting http rpc server <number> - <number> - 2 9 t <time> z config options rpcuser and rpcpassword will soon be deprecated . locally - run instances may remove rpcuser to use cookie - based auth , or may be replaced with rpcauth . please see share / rpcauth for rpcauth auth generation . <number> - <number> - 2 9 t <time> z http : starting <number> worker threads <number> - <number> - 2 9 t <time> z using wallet directory / home / jpe / bitcoin - test / datadir / testnet3 <number> - <number> - 2 9 t <time> z init message : verifying wallet ( s ) . <repeated> <number> - <number> - 2 9 t <time> z using berkeleydb version berkeley db <date> : ( <date> ) <number> - <number> - 2 9 t <time> z using wallet / home / jpe / bitcoin - test / datadir / testnet3 <number> - <number> - 2 9 t <time> z berkeleyenvironment : : open : logdir <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / database errorfile <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / db . log <number> - <number> - 2 9 t <time> z init message : loading banlist . <repeated> <number> - <number> - 2 9 t <time> z loaded <number> banned node ips / subnets from banlist . dat 0 ms <number> - <number> - 2 9 t <time> z net : setting try another outbound peer = false <number> - <number> - 2 9 t <time> z cache configuration : <number> - <number> - 2 9 t <time> z * using <number> mib for block index database <number> - <number> - 2 9 t <time> z * using <number> mib for chain state database <number> - <number> - 2 9 t <time> z * using <number> mib for in - memory utxo set ( plus up to <number> mib of unused mempool space ) <number> - <number> - 2 9 t <time> z init message : loading block index . <repeated> <number> - <number> - 2 9 t <time> z opening leveldb in / home / jpe / bitcoin - test / datadir / testnet3 / blocks / index <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / home / jpe / bitcoin - test / datadir / testnet3 / blocks / index : <number> <number> - <number> - 2 9 t <time> z loadblockindexdb : last block file = <number> <number> - <number> - 2 9 t <time> z loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) <number> - <number> - 2 9 t <time> z checking all blk files are present . <repeated> <number> - <number> - 2 9 t <time> z opening leveldb in / home / jpe / bitcoin - test / datadir / testnet3 / chainstate <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / home / jpe / bitcoin - test / datadir / testnet3 / chainstate : d94cbd34778bbbff <number> - <number> - 2 9 t <time> z loaded best chain : hashbestchain = 0 0 0 0 0 0 0 0 0 9 3 3 ea01ad0ee984209779baaec3ced90fa3f408719526f8d77f4943 height = <number> date = <number> - <number> - 0 2 t <time> z progress = <number> . <phone> - <number> - 2 9 t <time> z init message : rewinding blocks . <repeated> <number> - <number> - 2 9 t <time> z init message : verifying blocks . <repeated> <number> - <number> - 2 9 t <time> z block index 3 8 3 ms <number> - <number> - 2 9 t <time> z init message : loading wallet . <repeated> <number> - <number> - 2 9 t <time> z berkeleyenvironment : : open : logdir <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / database errorfile <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / db . log <number> - <number> - 2 9 t <time> z [ default wallet ] nfileversion = <phone> - <number> - 2 9 t <time> z [ default wallet ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records : <number> <number> - <number> - 2 9 t <time> z [ default wallet ] wallet completed loading in 1 1 6 ms <number> - <number> - 2 9 t <time> z [ default wallet ] setkeypool . size ( ) = <number> <number> - <number> - 2 9 t <time> z [ default wallet ] mapwallet . size ( ) = <number> <number> - <number> - 2 9 t <time> z [ default wallet ] mapaddressbook . size ( ) = <number> <number> - <number> - 2 9 t <time> z mapblockindex . size ( ) = <number> <number> - <number> - 2 9 t <time> z nbestheight = <number> <number> - <number> - 2 9 t <time> z imported mempool transactions from disk : <number> succeeded , <number> failed , <number> expired , <number> already there <number> - <number> - 2 9 t <time> z addlocal ( [ ip_address_host1 ] : <number> ) <number> - <number> - 2 9 t <time> z discover : ipv4 eno1 : [ ip_address_host1 ] <number> - <number> - 2 9 t <time> z bound to [ ip_address_host1 ] : <number> <number> - <number> - 2 9 t <time> z addlocal ( [ ip_address_host1 ] : <number> ) <number> - <number> - 2 9 t <time> z init message : loading p2p addresses . <repeated> <number> - <number> - 2 9 t <time> z loaded <number> addresses from peers . dat 1 ms <number> - <number> - 2 9 t <time> z init message : starting network threads . <repeated> <number> - <number> - 2 9 t <time> z dns seeding disabled <number> - <number> - 2 9 t <time> z net thread start <number> - <number> - 2 9 t <time> z addcon thread start <number> - <number> - 2 9 t <time> z opencon thread start <number> - <number> - 2 9 t <time> z init message : done loading <number> - <number> - 2 9 t <time> z msghand thread start <number> - <number> - 2 9 t <time> z added connection to [ ip_address_host3 ] : <number> peer = <number> <number> - <number> - 2 9 t <time> z connection from [ ip_address_host3 ] : <number> accepted <number> - <number> - 2 9 t <time> z received : version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , them =[ ip_address_host3 ] : <number> , peer = <number> <number> - <number> - 2 9 t <time> z sending verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z receive version message : / satoshi : <number> . <number> /: version <number> , blocks = <number> , us =[ ip_address_host1 ] : <number> , peer = <number> , peeraddr =[ ip_address_host3 ] : <number> <number> - <number> - 2 9 t <time> z added time data , samples <number> , offset + <number> ( + <number> minutes ) <number> - <number> - 2 9 t <time> z received : verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z initial getheaders ( <number> ) to peer = <number> ( startheight : <number> ) <number> - <number> - 2 9 t <time> z sending getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getaddr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z ignoring getheaders from peer = <number> because node is in initial block download <number> - <number> - 2 9 t <time> z received : feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : feefilter of <number> btc / kb from peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending addr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z added connection to [ ip_address_host2 ] : <number> peer = <number> <number> - <number> - 2 9 t <time> z connection from [ ip_address_host2 ] : <number> accepted <number> - <number> - 2 9 t <time> z received : version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , them =[ ip_address_host2 ] : <number> , peer = <number> <number> - <number> - 2 9 t <time> z sending verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z receive version message : / satoshi : <number> . <number> /: version <number> , blocks = <number> , us =[ ip_address_host1 ] : <number> , peer = <number> , peeraddr =[ ip_address_host2 ] : <number> <number> - <number> - 2 9 t <time> z added time data , samples <number> , offset + <number> ( + <number> minutes ) <number> - <number> - 2 9 t <time> z received : verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getaddr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z ignoring getheaders from peer = <number> because node is in initial block download <number> - <number> - 2 9 t <time> z received : feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : feefilter of <number> btc / kb from peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending addr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z flushed <number> addresses to peers . dat 3 2 ms <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z added connection to [ ip_address_host4 ] : <number> peer = <number> <number> - <number> - 2 9 t <time> z connection from [ ip_address_host4 ] : <number> accepted <number> - <number> - 2 9 t <time> z received : version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , them =[ ip_address_host4 ] : <number> , peer = <number> <number> - <number> - 2 9 t <time> z sending verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z receive version message : / satoshi : <number> . <number> /: version <number> , blocks = <number> , us =[ ip_address_host1 ] : <number> , peer = <number> , peeraddr =[ ip_address_host4 ] : <number> <number> - <number> - 2 9 t <time> z added time data , samples <number> , offset + <number> ( + <number> minutes ) <number> - <number> - 2 9 t <time> z received : verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getaddr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z ignoring getheaders from peer = <number> because node is in initial block download <number> - <number> - 2 9 t <time> z received : feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : feefilter of <number> btc / kb from peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending addr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> ` ` ` logs of one of the <number> node connected to the fourth one : ` ` ` <number> - <number> - 2 9 t <time> z bitcoin core version v0 . <number> ( release build ) <number> - <number> - 2 9 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 7 a8cd3e06cd5edbfe9dd1dbcc5dacab279376ef7cfc2b4c75 have valid signatures . <number> - <number> - 2 9 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 dbe94253893cbd463 <number> - <number> - 2 9 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) , avx2 ( 8 way ) ' sha256 implementation <number> - <number> - 2 9 t <time> z using rdrand as an additional entropy source <number> - <number> - 2 9 t <time> z default data directory / home / jpe / . bitcoin <number> - <number> - 2 9 t <time> z using data directory / home / jpe / bitcoin - test / datadir / testnet3 <number> - <number> - 2 9 t <time> z config file : / home / jpe / bitcoin - test / datadir / bitcoin . conf <number> - <number> - 2 9 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 2 9 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 2 9 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 2 9 t <time> z using <number> threads for script verification <number> - <number> - 2 9 t <time> z scheduler thread start <number> - <number> - 2 9 t <time> z warning : the rpc server is not safe to expose to untrusted networks such as the public internet <number> - <number> - 2 9 t <time> z http : creating work queue of depth <number> <number> - <number> - 2 9 t <time> z starting rpc <number> - <number> - 2 9 t <time> z starting http rpc server <number> - <number> - 2 9 t <time> z config options rpcuser and rpcpassword will soon be deprecated . locally - run instances may remove rpcuser to use cookie - based auth , or may be replaced with rpcauth . please see share / rpcauth for rpcauth auth generation . <number> - <number> - 2 9 t <time> z http : starting <number> worker threads <number> - <number> - 2 9 t <time> z using wallet directory / home / jpe / bitcoin - test / datadir / testnet3 <number> - <number> - 2 9 t <time> z init message : verifying wallet ( s ) . <repeated> <number> - <number> - 2 9 t <time> z using berkeleydb version berkeley db <date> : ( <date> ) <number> - <number> - 2 9 t <time> z using wallet / home / jpe / bitcoin - test / datadir / testnet3 <number> - <number> - 2 9 t <time> z berkeleyenvironment : : open : logdir <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / database errorfile <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / db . log <number> - <number> - 2 9 t <time> z init message : loading banlist . <repeated> <number> - <number> - 2 9 t <time> z loaded <number> banned node ips / subnets from banlist . dat 0 ms <number> - <number> - 2 9 t <time> z net : setting try another outbound peer = false <number> - <number> - 2 9 t <time> z cache configuration : <number> - <number> - 2 9 t <time> z * using <number> mib for block index database <number> - <number> - 2 9 t <time> z * using <number> mib for chain state database <number> - <number> - 2 9 t <time> z * using <number> mib for in - memory utxo set ( plus up to <number> mib of unused mempool space ) <number> - <number> - 2 9 t <time> z init message : loading block index . <repeated> <number> - <number> - 2 9 t <time> z opening leveldb in / home / jpe / bitcoin - test / datadir / testnet3 / blocks / index <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / home / jpe / bitcoin - test / datadir / testnet3 / blocks / index : <number> <number> - <number> - 2 9 t <time> z loadblockindexdb : last block file = <number> <number> - <number> - 2 9 t <time> z loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) <number> - <number> - 2 9 t <time> z checking all blk files are present . <repeated> <number> - <number> - 2 9 t <time> z opening leveldb in / home / jpe / bitcoin - test / datadir / testnet3 / chainstate <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / home / jpe / bitcoin - test / datadir / testnet3 / chainstate : 6 9 0 5 5 9 6 8 0 cb906bf <number> - <number> - 2 9 t <time> z loaded best chain : hashbestchain = 0 0 0 0 0 0 0 0 0 9 3 3 ea01ad0ee984209779baaec3ced90fa3f408719526f8d77f4943 height = <number> date = <number> - <number> - 0 2 t <time> z progress = <number> . <phone> - <number> - 2 9 t <time> z init message : rewinding blocks . <repeated> <number> - <number> - 2 9 t <time> z init message : verifying blocks . <repeated> <number> - <number> - 2 9 t <time> z block index 1 2 8 ms <number> - <number> - 2 9 t <time> z init message : loading wallet . <repeated> <number> - <number> - 2 9 t <time> z berkeleyenvironment : : open : logdir <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / database errorfile <annoyed> home / jpe / bitcoin - test / datadir / testnet3 / db . log <number> - <number> - 2 9 t <time> z [ default wallet ] nfileversion = <phone> - <number> - 2 9 t <time> z [ default wallet ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records : <number> <number> - <number> - 2 9 t <time> z [ default wallet ] wallet completed loading in 6 4 ms <number> - <number> - 2 9 t <time> z [ default wallet ] setkeypool . size ( ) = <number> <number> - <number> - 2 9 t <time> z [ default wallet ] mapwallet . size ( ) = <number> <number> - <number> - 2 9 t <time> z [ default wallet ] mapaddressbook . size ( ) = <number> <number> - <number> - 2 9 t <time> z mapblockindex . size ( ) = <number> <number> - <number> - 2 9 t <time> z nbestheight = <number> <number> - <number> - 2 9 t <time> z imported mempool transactions from disk : <number> succeeded , <number> failed , <number> expired , <number> already there <number> - <number> - 2 9 t <time> z addlocal ( [ ip_address_host2 ] : <number> ) <number> - <number> - 2 9 t <time> z discover : ipv4 em1 : [ ip_address_host2 ] <number> - <number> - 2 9 t <time> z bound to [ ip_address_host2 ] : <number> <number> - <number> - 2 9 t <time> z addlocal ( [ ip_address_host2 ] : <number> ) <number> - <number> - 2 9 t <time> z init message : loading p2p addresses . <repeated> <number> - <number> - 2 9 t <time> z loaded <number> addresses from peers . dat 0 ms <number> - <number> - 2 9 t <time> z init message : starting network threads . <repeated> <number> - <number> - 2 9 t <time> z dns seeding disabled <number> - <number> - 2 9 t <time> z net thread start <number> - <number> - 2 9 t <time> z init message : done loading <number> - <number> - 2 9 t <time> z addcon thread start <number> - <number> - 2 9 t <time> z opencon thread start <number> - <number> - 2 9 t <time> z msghand thread start <number> - <number> - 2 9 t <time> z threadrpcserver method = addnode user = user peeraddr =[ ip_address_host_bitcoin - cli ] : <number> <number> - <number> - 2 9 t <time> z trying connection [ ip_address_host1 ] lastseen = <number> . 0 hrs <number> - <number> - 2 9 t <time> z added connection to [ ip_address_host1 ] peer = <number> <number> - <number> - 2 9 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , them =[ ip_address_host1 ] : <number> , peer = <number> <number> - <number> - 2 9 t <time> z received : version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending getaddr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z receive version message : / satoshi : <number> . <number> /: version <number> , blocks = <number> , us =[ ip_address_host2 ] : <number> , peer = <number> , peeraddr =[ ip_address_host1 ] : <number> <number> - <number> - 2 9 t <time> z added time data , samples <number> , offset + <number> ( + <number> minutes ) <number> - <number> - 2 9 t <time> z received : verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z new outbound peer connected : version : <number> , blocks = <number> , peer = <number> , peeraddr =[ ip_address_host1 ] : <number> <number> - <number> - 2 9 t <time> z sending sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z initial getheaders ( <number> ) to peer = <number> ( startheight : <number> ) <number> - <number> - 2 9 t <time> z sending getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z ignoring getheaders from peer = <number> because node is in initial block download <number> - <number> - 2 9 t <time> z received : feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : feefilter of <number> btc / kb from peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : addr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z flushed <number> addresses to peers . dat 1 4 ms <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z flushed <number> addresses to peers . dat 1 5 ms <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z potential stale tip detected , will try using extra outbound peer ( last tip update : <number> seconds ago ) <number> - <number> - 2 9 t <time> z net : setting try another outbound peer = true <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z potential stale tip detected , will try using extra outbound peer ( last tip update : <number> seconds ago ) <number> - <number> - 2 9 t <time> z net try another outbound peer = true ` ` `",2
bitcoin/bitcoin,"outgoing p2p connections are reset immediately ` ` ` <number> - <number> - 2 5 t <time> z bitcoin core version v0 . <number> . <number> ( release build ) <number> - <number> - 2 5 t <time> z initparameterinteraction : parameter interaction : - whitelistforcerelay = <number> - > setting - whitelistrelay = <number> <number> - <number> - 2 5 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 e63058c023a9a1de233554f28c7b21380b6c9003f36a8 have valid signatu res . <number> - <number> - 2 5 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 8 8 2 2 fef1c230963535a90d <number> - <number> - 2 5 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) , avx2 ( 8 way ) ' sha256 implementation <number> - <number> - 2 5 t <time> z using rdrand as an additional entropy source <number> - <number> - 2 5 t <time> z default data directory / home / mpsp / . bitcoin <number> - <number> - 2 5 t <time> z using data directory / data / project / online_project / node / bitcoin_test / bitcoin <number> - <number> - 2 5 t <time> z using config file / data / project / online_project / node / bitcoin_test / bitcoin / bitcoin . conf <number> - <number> - 2 5 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 2 5 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 2 5 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 2 5 t <time> z using <number> threads for script verification <number> - <number> - 2 5 t <time> z scheduler thread start <number> - <number> - 2 5 t <time> z allowing http connections from : <number> . <number> / <number> : : <number> / <number> <number> . <number> / <number> <number> - <number> - 2 5 t <time> z binding rpc on address <number> . <number> port <number> <number> - <number> - 2 5 t <time> z initialized http server <number> - <number> - 2 5 t <time> z http : creating work queue of depth <number> <number> - <number> - 2 5 t <time> z starting rpc <number> - <number> - 2 5 t <time> z starting http rpc server <number> - <number> - 2 5 t <time> z config options rpcuser and rpcpassword will soon be deprecated . locally - run instances may remove rpcuser to use cookie - based auth , or may be replaced with rpcauth . please see share / rpcauth for rpcauth auth generation . <number> - <number> - 2 5 t <time> z registering http handler for / ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / wallet / ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / tx / ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / block / notxdetails / ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / block / ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / chaininfo ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / mempool / info ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / mempool / contents ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / headers / ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z registering http handler for / rest / getutxos ( exactmatch <number> ) <number> - <number> - 2 5 t <time> z starting http server <number> - <number> - 2 5 t <time> z http : starting <number> worker threads <number> - <number> - 2 5 t <time> z entering http event loop <number> - <number> - 2 5 t <time> z using wallet directory / data / project / online_project / node / bitcoin_test / bitcoin <number> - <number> - 2 5 t <time> z init message : verifying wallet ( s ) . <repeated> <number> - <number> - 2 5 t <time> z using berkeleydb version berkeley db <date> : ( <date> ) <number> - <number> - 2 5 t <time> z using wallet wallet . dat <number> - <number> - 2 5 t <time> z berkeleyenvironment : : open : logdir <annoyed> data / project / online_project / node / bitcoin_test / bitcoin / database errorfile <annoyed> da ta / project / online_project / node / bitcoin_test / bitcoin / db . log <number> - <number> - 2 5 t <time> z net : setting try another outbound peer = false <number> - <number> - 2 5 t <time> z cache configuration : <number> - <number> - 2 5 t <time> z * using <number> . 0 mib for block index database <number> - <number> - 2 5 t <time> z * using <number> . 0 mib for transaction index database <number> - <number> - 2 5 t <time> z * using <number> . 0 mib for chain state database <number> - <number> - 2 5 t <time> z * using <number> . 0 mib for in - memory utxo set ( plus up to <number> . 1 mib of unused mempool space ) <number> - <number> - 2 5 t <time> z init message : loading block index . <repeated> <number> - <number> - 2 5 t <time> z leveldb using max_open_files = <number> ( default = <number> ) <number> - <number> - 2 5 t <time> z opening leveldb in / data / project / online_project / node / bitcoin_test / bitcoin / blocks / index <number> - <number> - 2 5 t <time> z leveldb : delete type = <number> # <number> <number> - <number> - 2 5 t <time> z opened leveldb successfully <number> - <number> - 2 5 t <time> z using obfuscation key for / data / project / online_project / node / bitcoin_test / bitcoin / blocks / index : <number> <number> - <number> - 2 5 t <time> z loadblockindexdb : last block file = <number> <number> - <number> - 2 5 t <time> z loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) <number> - <number> - 2 5 t <time> z checking all blk files are present . <repeated> <number> - <number> - 2 5 t <time> z initializing databases . <repeated> <number> - <number> - 2 5 t <time> z pre - allocating up to position 0x 1 0 0 0 0 0 0 in blk00000 . dat <number> - <number> - 2 5 t <time> z leveldb using max_open_files = <number> ( default = <number> ) <number> - <number> - 2 5 t <time> z opening leveldb in / data / project / online_project / node / bitcoin_test / bitcoin / chainstate <number> - <number> - 2 5 t <time> z leveldb : delete type = <number> # <number> <number> - <number> - 2 5 t <time> z opened leveldb successfully <number> - <number> - 2 5 t <time> z writebatch memory usage : db = chainstate , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 2 5 t <time> z wrote new obfuscate key for / data / project / online_project / node / bitcoin_test / bitcoin / chainstate : 2 8 8 7 9 9 0 0 dc24e41c <number> - <number> - 2 5 t <time> z using obfuscation key for / data / project / online_project / node / bitcoin_test / bitcoin / chainstate : 2 8 8 7 9 9 0 0 dc24e41c <number> - <number> - 2 5 t <time> z init message : rewinding blocks . <repeated> <number> - <number> - 2 5 t <time> z block index 3 ms <number> - <number> - 2 5 t <time> z leveldb using max_open_files = <number> ( default = <number> ) <number> - <number> - 2 5 t <time> z opening leveldb in / data / project / online_project / node / bitcoin_test / bitcoin / indexes / txindex <number> - <number> - 2 5 t <time> z leveldb : delete type = <number> # <number> <number> - <number> - 2 5 t <time> z opened leveldb successfully <number> - <number> - 2 5 t <time> z using obfuscation key for / data / project / online_project / node / bitcoin_test / bitcoin / indexes / txindex : <number> <number> <number> - <number> - 2 5 t <time> z init message : loading wallet . <repeated> <number> - <number> - 2 5 t <time> z txindex thread start <number> - <number> - 2 5 t <time> z txindex is enabled <number> - <number> - 2 5 t <time> z txindex thread exit <number> - <number> - 2 5 t <time> z [ default wallet ] nfileversion = <phone> - <number> - 2 5 t <time> z [ default wallet ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records : <number> <number> - <number> - 2 5 t <time> z [ default wallet ] performing wallet upgrade to <phone> - <number> - 2 5 t <time> z [ default wallet ] keypool added <number> keys ( <number> internal ) , size = <number> ( <number> internal ) <number> - <number> - 2 5 t <time> z [ default wallet ] wallet completed loading in 1 1 0 3 ms <number> - <number> - 2 5 t <time> z [ default wallet ] setkeypool . size ( ) = <number> <number> - <number> - 2 5 t <time> z [ default wallet ] mapwallet . size ( ) = <number> <number> - <number> - 2 5 t <time> z [ default wallet ] mapaddressbook . size ( ) = <number> <number> - <number> - 2 5 t <time> z - load block from disk : <number> . 1 1 ms [ <number> . 0 0 s ] <number> - <number> - 2 5 t <time> z - connect total : <number> . 0 6 ms [ <number> . 0 0 s ( infms / blk ) ] <number> - <number> - 2 5 t <time> z - flush : <number> . 0 1 ms [ <number> . 0 0 s ( infms / blk ) ] <number> - <number> - 2 5 t <time> z - writing chainstate : <number> . 0 1 ms [ <number> . 0 0 s ( infms / blk ) ] <number> - <number> - 2 5 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 1 9 d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f height = <number> version =0 x0000000 <number> log2_work = <number> tx = <number> date = ' <number> - <number> - 0 3 t <time> z ' progress = <number> cache = <number> . 0 mib ( 0 txo ) <number> - <number> - 2 5 t <time> z - connect postprocess : <number> . 3 7 ms [ <number> . 0 1 s ( infms / blk ) ] <number> - <number> - 2 5 t <time> z - connect block : <number> . 5 7 ms [ <number> . 0 1 s ( infms / blk ) ] <number> - <number> - 2 5 t <time> z mapblockindex . size ( ) = <number> <number> - <number> - 2 5 t <time> z failed to open mempool file from disk . continuing anyway . <number> - <number> - 2 5 t <time> z nbestheight = <number> <number> - <number> - 2 5 t <time> z torcontrol thread start <number> - <number> - 2 5 t <time> z writebatch memory usage : db = txindex , before = <number> . 0 mib , after = <number> . 0 mib <number> - <number> - 2 5 t <time> z tor : error connecting to tor control socket <number> - <number> - 2 5 t <time> z tor : not connected to tor control port <number> . <number> : <number> , trying to reconnect <number> - <number> - 2 5 t <time> z bound to <happy> : <sad> <number> <number> - <number> - 2 5 t <time> z bound to <number> . <number> : <number> <number> - <number> - 2 5 t <time> z init message : loading p2p addresses . <repeated> <number> - <number> - 2 5 t <time> z error : deserializefiledb : failed to open file / data / project / online_project / node / bitcoin_test / bitcoin / peers . dat <number> - <number> - 2 5 t <time> z invalid or missing peers . dat ; recreating <number> - <number> - 2 5 t <time> z flushed <number> addresses to peers . dat 0 ms <number> - <number> - 2 5 t <time> z init message : loading banlist . <repeated> <number> - <number> - 2 5 t <time> z error : deserializefiledb : failed to open file / data / project / online_project / node / bitcoin_test / bitcoin / banlist . da t <number> - <number> - 2 5 t <time> z invalid or missing banlist . dat ; recreating <number> - <number> - 2 5 t <time> z flushed <number> banned node ips / subnets to banlist . dat 1 ms <number> - <number> - 2 5 t <time> z init message : starting network threads . <repeated> <number> - <number> - 2 5 t <time> z net thread start <number> - <number> - 2 5 t <time> z dnsseed thread start <number> - <number> - 2 5 t <time> z loading addresses from dns seeds ( could take a while ) <number> - <number> - 2 5 t <time> z init message : done loading <number> - <number> - 2 5 t <time> z addcon thread start <number> - <number> - 2 5 t <time> z opencon thread start <number> - <number> - 2 5 t <time> z msghand thread start <number> - <number> - 2 5 t <time> z added <number> addresses from sxa35bqgjufzajdt . internal : <number> tried , <number> new <number> - <number> - 2 5 t <time> z added <number> addresses from 3 ruqazlhqrx4izs4 . internal : <number> tried , <number> new <number> - <number> - 2 5 t <time> z added <number> addresses from fc46cby4cw6bvgfz . internal : <number> tried , <number> new <number> - <number> - 2 5 t <time> z added <number> addresses from nzcecuuaj4fa5dcl . internal : <number> tried , <number> new <number> - <number> - 2 5 t <time> z trying connection [ 2 a01 : 4 f8 : 1 c17 : 7 e2a : : <number> <sad> <number> lastseen = <number> . 2 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ 2 a01 : 4 f8 : 1 c17 : 7 e2a : : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z tor : error connecting to tor control socket <number> - <number> - 2 5 t <time> z tor : not connected to tor control port <number> . <number> : <number> , trying to reconnect <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 4 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z added <number> addresses from epu7hertnka6c2px . internal : <number> tried , <number> new <number> - <number> - 2 5 t <time> z trying connection [ <number> : <number> : 2 c0c : <number> : f4bb : ff : fe80 : 2 b42 ] : <number> lastseen = <number> . 1 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ <number> : <number> : 2 c0c : <number> : f4bb : ff : fe80 : 2 b42 ] : <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z added <number> addresses from mr3yswg4s4rrqkm4 . internal : <number> tried , <number> new <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 3 hrs <number> - <number> - 2 5 t <time> z flushing wallet . dat <number> - <number> - 2 5 t <time> z tor : error connecting to tor control socket <number> - <number> - 2 5 t <time> z tor : not connected to tor control port <number> . <number> : <number> , trying to reconnect <number> - <number> - 2 5 t <time> z flushed wallet . dat 2 ms <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 9 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z added <number> addresses from 7 v4ngmag7nmkcv4l . internal : <number> tried , <number> new <number> - <number> - 2 5 t <time> z <number> addresses found from dns seeds <number> - <number> - 2 5 t <time> z dnsseed thread exit <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 0 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> * * <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> )* * <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 1 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> * * <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> )* * <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z tor : error connecting to tor control socket <number> - <number> - 2 5 t <time> z tor : not connected to tor control port <number> . <number> : <number> , trying to reconnect <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 8 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 4 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 0 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 0 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection [ 2 a01 : 4 f8 <sad> 2 c : 1 b21 : : <number> <sad> <number> lastseen = <number> . 3 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ 2 a01 : 4 f8 <sad> 2 c : 1 b21 : : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z tor : error connecting to tor control socket <number> - <number> - 2 5 t <time> z tor : not connected to tor control port <number> . <number> : <number> , trying to reconnect <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 7 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 3 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 4 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection [ 2 a01 : 4 f8 <sad> 0 1 0 : 2 f11 : : <number> <sad> <number> lastseen = <number> . 8 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ 2 a01 : 4 f8 <sad> 0 1 0 : 2 f11 : : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection [ <number> : 6 7 c : 2 2 fc : <number> : : <number> <sad> <number> lastseen = <number> . 4 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ <number> : 6 7 c : 2 2 fc : <number> : : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection [ <number> : <number> : 9 d38 : 6 ab <time> 1 b : 2 d1 <tong> 8 3 d : <number> <sad> <number> lastseen = <number> . 3 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ <number> : <number> : 9 d38 : 6 ab <time> 1 b : 2 d1 <tong> 8 3 d : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection [ <number> : <time> <number> : 9 e7 <time> c <time> 5 c <tong> 9 5 4 : 9 2 d9 ] : <number> lastseen = <number> . 0 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ <number> : <time> <number> : 9 e7 <time> c <time> 5 c <tong> 9 5 4 : 9 2 d9 ] : <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 6 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 8 hrs <number> - <number> - 2 5 t <time> z tor : error connecting to tor control socket <number> - <number> - 2 5 t <time> z tor : not connected to tor control port <number> . <number> : <number> , trying to reconnect <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 7 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection [ <number> : <number> : 5 ef5 : 7 9 fb : <number> : 2 e42 <tong> 3 bc : 4 1 c8 ] : <number> lastseen = <number> . 1 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ <number> : <number> : 5 ef5 : 7 9 fb : <number> : 2 e42 <tong> 3 bc : 4 1 c8 ] : <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection [ 2 a01 : 4 f8 <sad> 2 c : 2 7 fc : : <number> <sad> <number> lastseen = <number> . 5 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ 2 a01 : 4 f8 <sad> 2 c : 2 7 fc : : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection [ 2 a01 : cb00 : 7 cd <tong> 0 0 0 : fa1f : bd1 : fe0 : 6 2 a6 ] : <number> lastseen = <number> . 2 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ 2 a01 : cb00 : 7 cd <tong> 0 0 0 : fa1f : bd1 : fe0 : 6 2 a6 ] : <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 5 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection [ 2 a00 : d2a0 : a <happy> d <time> <number> <happy> f71 <tong> 2 e : 3 4 f9 ] : <number> lastseen = <number> . 3 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ 2 a00 : d2a0 : a <happy> d <time> <number> <happy> f71 <tong> 2 e : 3 4 f9 ] : <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 1 hrs <number> - <number> - 2 5 t <time> z tor : error connecting to tor control socket <number> - <number> - 2 5 t <time> z tor : not connected to tor control port <number> . <number> : <number> , trying to reconnect <number> - <number> - 2 5 t <time> z connection to <number> . <number> : <number> timeout <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 1 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 7 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 1 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection [ <number> <time> <number> : 6 c8 <time> <number> : : <number> <sad> <number> lastseen = <number> . 1 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ <number> <time> <number> : 6 c8 <time> <number> : : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 6 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 7 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 7 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 7 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message : version <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> <number> - <number> - 2 5 t <time> z cleared nodestate for peer = <number> <number> - <number> - 2 5 t <time> z trying connection [ 2 a01 : 4 f <time> <time> 8 f : : <number> <sad> <number> lastseen = <number> . 5 hrs <number> - <number> - 2 5 t <time> z connect ( ) to [ 2 a01 : 4 f <time> <time> 8 f : : <number> <sad> <number> failed : network is unreachable ( <number> ) <number> - <number> - 2 5 t <time> z trying connection <number> . <number> : <number> lastseen = <number> . 8 hrs <number> - <number> - 2 5 t <time> z added connection peer = <number> <number> - <number> - 2 5 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 5 t <time> z send version message <number> , blocks = <number> , us =[ : : <sad> <number> , peer = <number> <number> - <number> - 2 5 t <time> z socket recv error connection reset by peer ( <number> ) <number> - <number> - 2 5 t <time> z disconnecting peer = <number> ` ` ` when my node starts , it always wraps “ socket recv error connection reset by peer ( <number> ) ” error ， does not synchronize blocks ， why ？",2
bitcoin/bitcoin,"how to ensure there is no version mismatch ? # # # motivation we would like to ship ` bitcoind ` with our software , however it ' s problematic if the user has already bitcoin core in her machine , because of the disk requirements . in order to avoid api / database / etc incompatibilities and various potential disastrous scenarios we would like to prevent the user to use bitcoin core with our software if the version of her own core and our shipped core differs . # # # question how do similar software resolve this issue ? # # # idea <number> should i play a setup procedure with the user like this <number> . do you want to use bitcoin core with wasabi ? yes - > <number> . / no - > end <number> . do you have already bitcoin core installed ? yes - > <number> . / no - > good <number> . what version of bitcoin core do you have ? . <repeated> - > same - > <number> . / different - > bad <number> . try to detect data folder automatically . success - > good / fail - > <number> . <number> . what ' s your current bitcoin core ' s data folder ? . <repeated> - > good - what if we update bitcoin core ? replay step <number> . - what if the user updates bitcoin core ? it ' s a problem , there ' s no way we can detect it . ` ` ` # # # idea <number> what i can do is to try to detect bitcoin core ' s default data folder and also get some input from the user if she ' s using a custom data folder , but is there a way to acquire the version from the data folder somehow ? # # # idea <number> i could call ` bitcoind - - version ` . in this case the user should tell us the location of ` bitcoind ` . in that case , is it possible to recognize programmatically her custom data folder if she ' s using one ? # # # reiterating the question what are the common strategies of doing this ? is it possible to detect if bitcoin core is installed and what data folder is used ?",2
bitcoin/bitcoin,"build depends to use with ccache ? is it possible to compile depends with ccache enabled ? if so , what is the recommended way of doing so ?",2
bitcoin/bitcoin,"armhf gui : permission denied : "" / database / lost + found / wallet . dat "" aborted bitcoin core version v0 . <number> . <number> - 4 bfef0dae - dirty compiled natively on "" linux debian - desktop <date> # <number> smp fri <date> <time> edt <number> aarch64 gnu / linux "" ` ` ` . / autogen . sh . / configure - - disable - debug cflags = "" - g0 - o3 "" cxxflags = "" - g0 - o3 "" bdb_libs = "" - l ${ bdb_prefix } / lib - ldb_cxx - <number> "" bdb_cflags = "" - i ${ bdb_prefix } / include "" - - enable - werror - - with - qrencode - - enable - cxx - - disable - shared - - with - pic - - with - boost - libdir <annoyed> usr / lib / arm - linux - gnueabihf ` ` ` gui runs ok . and noticeable faster than previously compiled ( with debug enabled ) v0 . <number> . <number> - 4 9 5 db72ee - dirty . but both - bitcoin core version v0 . <number> . <number> - 4 9 5 db72ee - dirty ( debug enabled , default optimization ) - bitcoin core version v0 . <number> . <number> - 4 bfef0dae - dirty ( debug disabled , - o3 ) are crashing when mouse cursor is pointed to file / openwallet menu item . starting parameters are the same : bitcoin - qt - datadir <annoyed> bdb - nodebug - dbcache = <number> / bdb is dedicated raid1 volume with bitcoin database inside . console output : ` ` ` terminate called after throwing an instance of ' boost : : filesystem : : filesystem_error ' what ( <sad> boost : : filesystem : : status : permission denied ` ` ` there is nothing about the crash in debug . log before sudden application abort . i am wondering for what purpose to access the wallets in lost + found folder ? i thought there may be a problems with access rights for that folder . i have deleted lost + found and executed fsck - f / dev / md0 for / bdb directory volume . the problem still here . while configuring the build , i had to add ` ` ` - - with - boost - libdir <annoyed> usr / lib / arm - linux - gnueabihf ` ` ` because configure script was unable to find boost executables .",2
bitcoin/bitcoin,"accessing function in anonymous namespace from a unit test looking at script / descriptor . cpp , and the associated test file descriptor_tests . cpp , much of the code in descriptor . cpp is inside an anonymous namespace ( an ) . if i am not mistaken , this makes functions accessible only within the translation unit corresponding to the source file they are defined in . functions that are used in the test in descriptor_tests . cpp ( such as the ` parse ` function ) are outside of the an . i would like to use the ` descriptorchecksum ` function from descriptor . cpp in a unit test , but it ' s inside the an and thus inaccessible from descriptor_tests . cpp . i currently see three options ` <hashtag> include </hashtag> "" descriptor . cpp "" ` at the top of descriptor_tests . cpp , which is ugly - move the ` descriptorchecksum ` function outside of the an . - leave it alone and find something else to unit test what ' s the best way to approach this ? also - a lot of the code is inside ans . is there a special reason for this ? would not it make sense to gradually move the code outside of ans to make it more accessible to unit tests ?",2
bitcoin/bitcoin,new to bitcoin core hello there i am a little lost here and wondering if you can help . i thought bitcoincore was a plug and play set up for receiving btc for validation of a bitcoin transaction between two people . however i did not know there was more steps to this . wonder if anyone have insight and can lend me there time and helping me through this ? not sure where to look or what to read . i download bitcoincore and downloaded the whole network . and obtained my wallet . what ' s next in order to validate btc transactions ? i currently have this set up through windows <number>,2
bitcoin/bitcoin,how to create hd address ? i am wondering if it ' s possible to create an hd address with bitcoind ' s getnewaddress rpc call ? if not how does one create an hd address ?,2
bitcoin/bitcoin,"bumpfee not returning hash of newly created transaction i am trying to implement replace by fee functionality with bictoind ( v18 ) and bumpfee rpc call described here it works by mean that new transaction is created with higher fee , but result should be : ` ` ` { "" txid "" : "" value "" , ( string ) the id of the new transaction "" origfee "" : n , ( numeric ) fee of the replaced transaction "" fee "" : n , ( numeric ) fee of the new transaction "" errors "" : [ str . <repeated> ] ( json array of strings ) errors encountered during processing ( may be empty ) } ` ` ` but i am getting basically all null response ` ` ` { "" id "" : "" bumpfeerequest <number> "" , "" error "" : null , "" txid "" : null , "" origfee "" : null , "" fee "" : null , "" errors "" : null } ` ` ` which makes it hard to identify the new transaction in down - steam system . i believe that hash of newly created tx should be returned i posted this also here",2
bitcoin/bitcoin,"can not bind rpcport inside docker i dont really know if it is a bitcoin core problem or not , but i am trying hard and i can not get it > binding rpc on address : : port <number> failed . more info",2
bitcoin/bitcoin,"bitcoin testnet rpc is binding to localhost hello , thanks for the efforts here . currently , i have installed couple of time and at different server bitcoind and i have even pull up github at server and compiled it still bitcoind rpc is binding to localhost even after i have added rpcallowip = <number> . <number> / <number> i saw root <user> - desktop : ~ / . bitcoin # sudo netstat - - ip - lpa | grep bitcoin tcp <number> <number> localhost : <number> <number> . <number> <kiss> listen <number> / bitcoind tcp <number> <number> localhost : <number> <number> . <number> <kiss> listen <number> / bitcoind tcp <number> <number> <number> . <number> . <time> <number> <number> . <number> <kiss> listen <number> / bitcoind i used this config file testnet = <number> rpcallowip = <number> . <number> / <number> port = <number> rpcport = <number> rpcuser = foo rpcpassword = bar it was working for me before . any solution for this ?",2
bitcoin/bitcoin,"is it possible to downgrade from <number> . <number> to <number> . <number> ? i am running a full node on a ubuntu server . yesterday , i upgraded the bitcoin package from <number> . <number> to <number> . <number> using apt - get . however , i really need the account rpcs . is it possible to get back to <number> . <number> without the full sync from the scratch ?",2
bitcoin/bitcoin,"signing transactions locked with op_checklocktimeverify i have been trying to send and sign a transaction paying to a multisig locked with ` <locktime> op_checklocktimeverify op_drop ` and noticed that this is considered nonstandard in bitcoin and thus not possible . are there any plans or interest in implementing something like this ? i have implemented this in a fork using a new transaction type ( tx_locked_multisig ) , where the solver first checks for the lock script above and then proceeds to "" matchmultisig "" . similarly this new type can be recognised when signing the transaction by simply ignoring the preceding lock script , which is checked when verifying the script anyway . it would be quite straightforward to implement for the remaining standard transaction types as well or maybe even better with some manipulation use a single transaction type if possible .",2
bitcoin/bitcoin,"unable to importprivkey have been trying to import some recovered private keys into bitcoin core for the past <number> days . after syncing the entire bitcoin blockchain , i have verified the same using ` bitcoin - cli getnetworkinfo ` . then , i have tried to run ` bitcoin - cli importprivkey the_key "" "" true ` to enable a rescan after import ( since i wanted to do one at a time , to verify spend - ability of balances ) . however , while looking at the debug . log , i notice that the rescan is complete , yet the balances are not updated across my wallets . since i am unable to determine why the balances are not updating , i am trying to import the address into bitcoin core first before importing the private key . note , that the private key i tried to import starts with a k and has <number> characters . the beginning part of the recovered path is i expect to be able to import these balances and make them spendable . however , i am not even able to see the balances when running ` bitcoin - cli getwalletinfo ` .",2
bitcoin/bitcoin,"fixed some times can not remove "" $ suffix - dirty "" on version number cor … fixed some times can not remove "" $ suffix - dirty "" on version number correctly with git tag using gitian . even you use git annotated tag encounter with such problem .",2
bitcoin/bitcoin,"error : <hashtag> error </hashtag> "" bitcoin cannot be compiled without assertions . "" hi , all : * * my env : * * _ubuntu <number> . <number> qt <number> . <number> bitcoin : git master of the day <date> . _ my configuration is : ` ` ` console $ export pkg_config_path <annoyed> opt / qt / current / gcc_64 / lib / pkgconfig $ . / configure - - with - incompatible - bdb - - enable - gprof = yes - with - gui = yes - - with - boost - libdir <annoyed> usr / lib - - with - boost - system = boost_system - - with - boost - filesystem = boost_filesystem - - with - boost - thread = boost_thread - - with - boost - chrono = boost_chrono - - with - boost - unit - test - framework = boost_unit_test_framework ` ` ` if ` - - with - gui = no ` , i can successfully build * bitcoin <emphasis> * . however , by enabling gui / qt , i obtained the following * error <emphasis> * messages : ` ` ` in file included from . / util / system . h : <number> , from . / dbwrapper . h : <number> , from . / txdb . h : <number> , from . / test / test_bitcoin . h : <number> , from . / wallet / test / wallet_test_fixture . h : <number> , from wallet / test / wallet_test_fixture . cpp : <number> : . / compat / assumptions . h : <number> : <number> : error : <hashtag> error </hashtag> "" bitcoin cannot be compiled without assertions . "" # error "" bitcoin cannot be compiled without assertions . "" ^ ~ ~ ~ ~ in file included from . / util / system . h : <number> , from . / dbwrapper . h : <number> , from . / txdb . h : <number> , from . / test / test_bitcoin . h : <number> , from test / test_bitcoin . cpp : <number> : . / compat / assumptions . h : <number> : <number> : error : <hashtag> error </hashtag> "" bitcoin cannot be compiled without assertions . "" # error "" bitcoin cannot be compiled without assertions . "" ^ ~ ~ ~ ~ cxx crypto / libbitcoinconsensus_la - siphash . lo cxx crypto / libbitcoinconsensus_la - sha256_sse4 . lo cxx libbitcoinconsensus_la - arith_uint256 . lo cxx consensus / libbitcoinconsensus_la - merkle . lo cxx libbitcoinconsensus_la - hash . lo cxx primitives / libbitcoinconsensus_la - block . lo cxx primitives / libbitcoinconsensus_la - transaction . lo cxx libbitcoinconsensus_la - pubkey . lo in file included from . / wallet / walletdb . h : <number> , from . / wallet / wallet . h : <number> , from . / wallet / test / wallet_test_fixture . h : <number> , from wallet / test / wallet_test_fixture . cpp : <number> : . / wallet / db . h : in destructor ‘ berkeleydatabase : : ~ berkeleydatabase ( ) ’ : . / wallet / db . h : <number> <time> : warning : unused variable ‘ erased ’ [ - wunused - variable ] size_t erased = env - > m_databases . erase ( strfile ) ; ^ ~ ~ ~ ~ ~ cxx script / libbitcoinconsensus_la - bitcoinconsensus . lo cxx script / libbitcoinconsensus_la - interpreter . lo make [ <number> <sad> * * * [ makefile : <number> : test / qt_test_test_bitcoin_qt - test_bitcoin . o ] error <number> make [ <number> <sad> * * * waiting for unfinished jobs . <repeated> make [ <number> <sad> * * * [ makefile : <number> : wallet / test / qt_test_test_bitcoin_qt - wallet_test_fixture . o ] error <number> make [ <number> <sad> leaving directory ' . <repeated> / bitcoingui / src ' make [ <number> <sad> * * * [ makefile : <number> : all - recursive ] error <number> make [ <number> <sad> leaving directory ' . <repeated> / bitcoingui / src ' make : * * * [ makefile : <number> error <number> ` ` ` any suggestions ?",2
bitcoin/bitcoin,"macos wallet compilation on linux ubuntu can anyone provide step by step instructions , how to compile bitcoin wallet for macos / xos on an * * ubuntu <number> or <number> * * machine ?",2
bitcoin/bitcoin,void nan,2
bitcoin/bitcoin,"rpc not working on <number> . <number> ` ` ` curl - - user test : test - - data - binary ' { "" jsonrpc "" : "" <number> "" , "" id "" : "" curltest "" , "" method "" : "" getbalance "" , "" params "" : [""* "" , <number> ] } ' - h ' content - type : text / plain ; ' <url> curl : ( <number> ) failed to connect to <number> . <number> port <number> refused ` ` ` but version <number> works",2
bitcoin/bitcoin,"why did not return ? i use bitcoind - daemon - datadir <annoyed> mydata / btc / storage - rpcport = <number> to start btc wallet . and use code : as follows ( python ) import requests params ={ "" method "" : "" getbestblockhash "" , "" params "" : [ ] , "" id "" url = "" <url> print ( requests . post ( url = url , json = params ) . text ) but no return",2
bitcoin/bitcoin,"error when building binary files under windows <number> / <number> bit hello , i collect bitcoin client under windows <number> / <number> and an error occurred . staging miniupnpc . <repeated> postprocessing miniupnpc . <repeated> caching miniupnpc . <repeated> copying packages : native_ccache native_protobuf boost openssl libevent zeromq qrencode protobuf zlib qt bdb miniupnpc to : / root / bitcoin / depends / x86_64 - w64 - mingw32 bash : . / configure such file or directory i tried to collect on ubunt <number> ; <number> ; <number> <number> bit",2
bitcoin/bitcoin,"rpc error : error - <number> i just setup btc wallet and it show this error : rpc error : error - <number> value must be set to "" * "" i have tried run . / bitcoind - - deprecatedrpc = accounts but the error still showing",2
bitcoin/bitcoin,"rpc one more quote from non - string oneline description this fixes a silent conflict between <url> ( which removed all ` \ \ "" options \ \ "" ` ) and <url> ( which added a new one ) . it should fix the current ci failures .",0
bitcoin/bitcoin,"wallets created on master get corrupted when processed with v25 # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour i randomly encountered this by loading a wallet created from master with an older version . i could trace it down to bd13dc2f46ea10302a928fcf0f53b7aed77ad260 (# <number> ) , but i do not know descriptor wallets enough to understand what ' s going on ( cc <user> <user> ) . # # # expected behaviour ` bitcoind ` starts , or at least tells me to use a later version if # <number> was a breaking change instead of corrupting ` wallet . dat ` . # # # steps to reproduce ( master , clean chain ) : ` createwallet - regtest "" "" ` ( v25 . 0 rc2 ) : first ` bitcoind - regtest ` succeeds then stop and restart the node : the second ` bitcoind - regtest ` leads to an initerror : ` error : error to expand wallet descriptor from cache ` now , the wallet cannot be loaded by either version . # # # relevant log output _no response_ # # # how did you obtain bitcoin core compiled from source # # # what version of bitcoin core are you using ? v25 . 0 rc2 / master # # # operating system and version ubuntu # # # machine specifications _no response_",0
bitcoin/bitcoin,"indefinite "" bitcoin core is shutting down . <repeated> "" # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour after shutting down bitcoin core qt , the window "" bitcoin core is shutting down . <repeated> do not shut down the computer until this window disappears . "" remains open indefinitely ( or at least 2 4 h ) . # # # expected behaviour quick shutdown . # # # steps to reproduce try to stop bitcoin - qt # # # relevant log output <number> - <number> - 0 9 t <time> z upnp port mapping successful . <number> - <number> - 0 9 t <time> z tor : thread interrupt <number> - <number> - 0 9 t <time> z shutdown : in progress . <repeated> <number> - <number> - 0 9 t <time> z addcon thread exit <number> - <number> - 0 9 t <time> z torcontrol thread exit <number> - <number> - 0 9 t <time> z opencon thread exit <number> - <number> - 0 9 t <time> z net thread exit <number> - <number> - 0 9 t <time> z upnp_deleteportmapping ( ) returned : <number> <number> - <number> - 0 9 t <time> z mapport thread exit <number> - <number> - 0 9 t <time> z msghand thread exit <number> - <number> - 0 9 t <time> z potential stale tip detected , will try using extra outbound peer ( last tip update : <number> seconds ago ) <number> - <number> - 0 9 t <time> z potential stale tip detected , will try using extra outbound peer ( last tip update : <number> seconds ago ) <number> - <number> - 0 9 t <time> z potential stale tip detected , will try using extra outbound peer ( last tip update : <number> seconds ago ) . <repeated> <number> - <number> - 1 0 t <time> z potential stale tip detected , will try using extra outbound peer ( last tip update seconds ago ) # # # how did you obtain bitcoin core pre - built binaries # # # what version of bitcoin core are you using ? v25 . <number> # # # operating system and version debian <number> . <number> - <number> - amd64 # # # machine specifications <number> core <number> gb ram at times flaky but fast internet secondary 2 tb ssd with symlinks under ~ / . bitcoin / { blocks , chainstate , indexes }",0
bitcoin/bitcoin,"validation of malformed address fails with a peculiar message # # # is there an existing issue for this ? - [x ] i have searched the existing issues # # # current behaviour open rpc console and execute this command : ` validateaddress bc1qqrq69gfzvvqcxs6rgg3crqjzcw369sxzyp3v9sspursx9gmzyv32x7xa5z ` following message is the result : ` ` ` internal bug detected : ' isvalid = = error_msg . empty ( ) ' rpc / misc . cpp : <number> ( operator ( ) ) you may report this issue here ( code - <number> ) ` ` ` # # # expected behaviour well it should tell me something , like what is wrong exactly . though i believe that too much is wrong with this particular address . # # # steps to reproduce run validateaddress method using ` bc1qqrq69gfzvvqcxs6rgg3crqjzcw369sxzyp3v9sspursx9gmzyv32x7xa5z ` as its argument . # # # relevant log output _no response_ # # # how did you obtain bitcoin core pre - built binaries # # # what version of bitcoin core are you using ? / satoshi : <number> . <number> / # # # operating system and version macos ventura <number> ( 2 2 f66 ) # # # machine specifications macbook pro <number> - inch , m1 , <number> with 1 6 gb of ram",0
bitcoin/bitcoin,"ci : failure in docker build step failure here : <url> in # <number> . does this just need a rebase ? cc <user> ` ` ` bash docker build - - tag gcr . io / cirrus - ci - community / bitcoin / bitcoin / ci / test_imagefile : d050f5b1ebc8c0ebdf779e9eda85ea03bfd0fca46391a14e57fbe478652e6623 - - file ci / test_imagefile - - build - arg ci_image_name_tag = "" ubuntu : focal "" - - build - arg file_env ="". / ci / test / 0 0 _setup_env_native_nowallet_libbitcoinkernel . sh "" ${ cirrus_docker_context :-$ cirrus_working_dir } sending build context to docker daemon <number> . 5 7 mb step <number> / <number> : arg ci_image_name_tag step <number> / <number> : from ${ ci_image_name_tag } focal : pulling from library / ubuntu ca1778b69356 : pulling fs layer ca1778b69356 : verifying checksum ca1778b69356 : download complete ca1778b69356 : pull complete digest : sha256 : db8bf6f4fb351aa7a26e27ba2686cf35a6a409f65603e59d4c203e58387dc6b3 status : downloaded newer image for ubuntu : focal - - - > 8 8 bd68917189 step <number> / <number> : arg file_env - - - > running in 7 7 bc178b543a removing intermediate container 7 7 bc178b543a - - - > a52b7bf6ebc8 step <number> / <number> : env file_env =${ file_env } - - - > running in 2 d35ad9e7577 removing intermediate container 2 d35ad9e7577 - - - > 6 bdfd4b02a40 step <number> / <number> : copy . / ci / retry / retry / usr / bin / retry - - - > 8 d3f67387e0d step <number> / <number> : copy . / ci / test / 0 0 _setup_env . sh . /$ { file_env } . / ci / test / 0 1 _base_install . sh / ci_base_install / ci / test / - - - > ca5c1a6cf9b3 step <number> / <number> : run [ "" bash "" , "" - c "" , "" cd / ci_base_install / & & set - o errexit & & source . / ci / test / 0 0 _setup_env . sh & & . / ci / test / 0 1 _base_install . sh "" ] - - - > running in bda994800fa2 setting specific values in env fallback to default values in env ( if not yet set ) . / ci / test / 0 0 _setup_env . sh : line <number> : / ci_base_install / depends / config . guess : no such file or directory . / ci / test / 0 1 _base_install . sh : line <number> : git : command not found get : <number> <url> buster - backports inrelease [ <number> kb ] get : <number> <url> focal inrelease [ <number> kb ] err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 get : <number> <url> focal - updates inrelease [ <number> kb ] get : <number> <url> focal - backports inrelease [ <number> kb ] get : <number> <url> focal / restricted amd64 packages [ <number> kb ] get : <number> <url> focal / universe amd64 packages [ <number> mb ] get : <number> <url> focal / multiverse amd64 packages [ <number> kb ] get : <number> <url> focal / main amd64 packages [ <number> kb ] get : <number> <url> focal - updates / main amd64 packages [ <number> kb ] get : <number> <url> focal - updates / universe amd64 packages [ <number> kb ] get : <number> <url> focal - updates / multiverse amd64 packages [ <number> kb ] get : <number> <url> focal - updates / restricted amd64 packages [ <number> kb ] get : <number> <url> focal - backports / universe amd64 packages [ <number> kb ] get : <number> <url> focal - backports / main amd64 packages [ <number> kb ] get : <number> <url> focal - security inrelease [ <number> kb ] get : <number> <url> focal - security / restricted amd64 packages [ <number> kb ] get : <number> <url> focal - security / universe amd64 packages [ <number> kb ] get : <number> <url> focal - security / main amd64 packages [ <number> kb ] get : <number> <url> focal - security / multiverse amd64 packages [ <number> kb ] reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal - backports inrelease hit : <number> <url> focal - security inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal - backports inrelease hit : <number> <url> focal - security inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease hit : <number> <url> focal - backports inrelease hit : <number> <url> focal - security inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal - security inrelease hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease hit : <number> <url> focal - backports inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal - security inrelease hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease hit : <number> <url> focal - backports inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] hit : <number> <url> focal inrelease err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal - updates inrelease hit : <number> <url> focal - backports inrelease hit : <number> <url> focal - security inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal - backports inrelease hit : <number> <url> focal - security inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease hit : <number> <url> focal - backports inrelease hit : <number> <url> focal - security inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease hit : <number> <url> focal - security inrelease hit : <number> <url> focal - backports inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . before retry # <number> : sleeping <number> seconds get : <number> <url> buster - backports inrelease [ <number> kb ] err : <number> <url> buster - backports inrelease the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 hit : <number> <url> focal - security inrelease hit : <number> <url> focal inrelease hit : <number> <url> focal - updates inrelease hit : <number> <url> focal - backports inrelease reading package lists . <repeated> w : gpg error : <url> buster - backports inrelease : the following signatures could not be verified because the public key is not available : no_pubkey 6 4 8 acfd622f3d138 no_pubkey 0 e98404d386fa1d9 e : the repository ' <url> buster - backports inrelease ' is not signed . retries exhausted reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources before retry # <number> : sleeping <number> seconds reading package lists . <repeated> e : the value ' buster - backports ' is invalid for apt : : default - release as such a release is not available in the sources retries exhausted . / ci / test / 0 1 _base_install . sh : line <number> : git : command not found the command ' bash - c cd / ci_base_install / & & set - o errexit & & source . / ci / test / 0 0 _setup_env . sh & & . / ci / test / 0 1 _base_install . sh ' returned a non - zero code : <number> exit status ` ` `",0
bitcoin/bitcoin,"issue with ` wallet_importdescriptors . py - - descriptors ` under valgrind this was running # <number> rebased on master ( at the time 8 d12127a9c19cb218d661a88ab9b6871c9d853b9 ) . ` ` ` bash <number> / <number> - wallet_importdescriptors . py - - descriptors failed , duration : <number> s stdout : <number> - <number> - 0 8 t <time> . 6 4 7 0 0 0 z testframework ( info ) : prng seed is : <number> <number> - <number> - 0 8 t <time> . 6 4 8 0 0 0 z testframework ( info ) : initializing test directory / home / ubuntu / ci_scratch / ci / scratch / test_runner / test_runner_ ₿ _ 🏃 _20230308_165259 / wallet_importdescriptors_86 <number> - <number> - 0 8 t <time> . 4 2 2 0 0 0 z testframework ( info ) : setting up wallets <number> - <number> - 0 8 t <time> . 6 4 3 0 0 0 z testframework ( info ) : mining coins <number> - <number> - 0 8 t <time> . 1 9 6 0 0 0 z testframework ( info ) : import should fail if a descriptor is not provided <number> - <number> - 0 8 t <time> . 2 3 2 0 0 0 z testframework ( info ) : should import a p2pkh descriptor <number> - <number> - 0 8 t <time> . 2 5 7 0 0 0 z testframework ( info ) : test can import same descriptor with public key twice <number> - <number> - 0 8 t <time> . 4 8 1 0 0 0 z testframework ( info ) : test can update descriptor label <number> - <number> - 0 8 t <time> . 7 3 2 0 0 0 z testframework ( info ) : internal addresses cannot have labels <number> - <number> - 0 8 t <time> . 7 4 6 0 0 0 z testframework ( info ) : internal addresses should be detected as such <number> - <number> - 0 8 t <time> . 9 8 7 0 0 0 z testframework ( info ) : should not import a p2sh - p2wpkh descriptor without checksum <number> - <number> - 0 8 t <time> . 0 0 0 0 0 0 z testframework ( info ) : should not import a p2sh - p2wpkh descriptor that has range specified <number> - <number> - 0 8 t <time> . 0 4 9 0 0 0 z testframework ( info ) : should not import a p2sh - p2wpkh descriptor and have it set to active <number> - <number> - 0 8 t <time> . 0 6 5 0 0 0 z testframework ( info ) : should import a ( non - active ) p2sh - p2wpkh descriptor <number> - <number> - 0 8 t <time> . 9 7 6 0 0 0 z testframework ( info ) : should import a <number> - of - <number> bare multisig from descriptor <number> - <number> - 0 8 t <time> . 2 6 0 0 0 0 z testframework ( info ) : should not treat individual keys from the imported bare multisig as watchonly <number> - <number> - 0 8 t <time> . 2 8 4 0 0 0 z testframework ( info ) : ranged descriptors cannot have labels <number> - <number> - 0 8 t <time> . 3 4 6 0 0 0 z testframework ( info ) : private keys required for private keys enabled wallet <number> - <number> - 0 8 t <time> . 4 0 7 0 0 0 z testframework ( info ) : ranged descriptor import should warn without a specified range <number> - <number> - 0 8 t <time> . 9 0 2 0 0 0 z testframework ( info ) : should not import a ranged descriptor that includes xpriv into a watch - only wallet <number> - <number> - 0 8 t <time> . 9 5 9 0 0 0 z testframework ( info ) : should not import a descriptor with hardened derivations when private keys are disabled <number> - <number> - 0 8 t <time> . 2 3 3 0 0 0 z testframework ( info ) : verify we can only extend descriptor ' s range <number> - <number> - 0 8 t <time> . 9 6 5 0 0 0 z testframework ( info ) : check we can change descriptor internal flag <number> - <number> - 0 8 t <time> . 5 2 4 0 0 0 z testframework ( info ) : key ranges should be imported in order <number> - <number> - 0 8 t <time> . 0 2 7 0 0 0 z testframework ( info ) : check we can change next_index <number> - <number> - 0 8 t <time> . 3 5 9 0 0 0 z testframework ( info ) : check imported descriptors are not active by default <number> - <number> - 0 8 t <time> . 9 6 0 0 0 0 z testframework ( info ) : check can activate inactive descriptor <number> - <number> - 0 8 t <time> . 7 5 0 0 0 0 z testframework ( info ) : check can deactivate active descriptor <number> - <number> - 0 8 t <time> . 4 8 0 0 0 0 z testframework ( info ) : verify activation state is persistent <number> - <number> - 0 8 t <time> . 0 7 3 0 0 0 z testframework ( info ) : should import a descriptor with a wif private key as spendable <number> - <number> - 0 8 t <time> . 3 2 3 0 0 0 z testframework ( info ) : test can import same descriptor with private key twice <number> - <number> - 0 8 t <time> . 1 2 1 0 0 0 z testframework ( info ) : test that multisigs can be imported , signed for , and getnewaddress ' d <number> - <number> - 0 8 t <time> . 3 2 2 0 0 0 z testframework ( info ) : multisig with distributed keys <number> - <number> - 0 8 t <time> . 9 2 4 0 0 0 z testframework ( info ) : we can create and use a huge multisig under p2wsh <number> - <number> - 0 8 t <time> . 8 7 0 0 0 0 z testframework ( info ) : under p2sh , multisig are standard with up to <number> compressed keys <number> - <number> - 0 8 t <time> . 9 2 6 0 0 0 z testframework ( info ) : amending multisig with new private keys <number> - <number> - 0 8 t <time> . 7 0 5 0 0 0 z testframework ( info ) : combo descriptors cannot be active <number> - <number> - 0 8 t <time> . 7 4 8 0 0 0 z testframework ( info ) : descriptors with no type cannot be active <number> - <number> - 0 8 t <time> . 5 4 2 0 0 0 z testframework ( info ) : test importing a descriptor to an encrypted wallet <number> - <number> - 0 8 t <time> . 6 1 1 0 0 0 z testframework ( info ) : stopping nodes <number> - <number> - 0 8 t <time> . 6 5 4 0 0 0 z testframework . utils ( error ) : wait_until ( ) failed . predicate : ' ' ' ' def is_node_stopped ( self ) : "" "" "" checks whether the node has stopped . returns true if the node has stopped . false otherwise . this method is responsible for freeing resources ( self . process ) . "" "" "" if not self . running : return true return_code = self . process . poll ( ) if return_code is none : return false # process has stopped . assert that it did not return an error code . assert return_code = = <number> , self . _node_msg ( "" node returned non - zero exit code ( % d ) when stopping "" % return_code ) self . running = false self . process = none self . rpc_connected = false self . rpc = none self . log . debug ( "" node stopped "" ) return true ' ' ' [ node <number> ] cleaning up leftover process [ node <number> ] cleaning up leftover process stderr : traceback ( most recent call last ) : file "" / home / ubuntu / ci_scratch / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / wallet_importdescriptors . py "" , line <number> , in <module> importdescriptorstest ( ) . main ( ) file "" / home / ubuntu / ci_scratch / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main exit_code = self . shutdown ( ) file "" / home / ubuntu / ci_scratch / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in shutdown self . stop_nodes ( ) file "" / home / ubuntu / ci_scratch / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in stop_nodes node . wait_until_stopped ( ) file "" / home / ubuntu / ci_scratch / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_node . py "" , line <number> , in wait_until_stopped wait_until_helper ( self . is_node_stopped , timeout = timeout , timeout_factor = self . timeout_factor ) file "" / home / ubuntu / ci_scratch / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in wait_until_helper raise assertionerror ( "" predicate { } not true after { } seconds "" . format ( predicate_source , timeout ) ) assertionerror : predicate ' ' ' ' def is_node_stopped ( self ) : "" "" "" checks whether the node has stopped . returns true if the node has stopped . false otherwise . this method is responsible for freeing resources ( self . process ) . "" "" "" if not self . running : return true return_code = self . process . poll ( ) if return_code is none : return false # process has stopped . assert that it did not return an error code . assert return_code = = <number> , self . _node_msg ( "" node returned non - zero exit code ( % d ) when stopping "" % return_code ) self . running = false self . process = none self . rpc_connected = false self . rpc = none self . log . debug ( "" node stopped "" ) return true ' ' ' not true after <number> seconds ` ` ` see here for combined log",0
bitcoin/bitcoin,release <number> . <number> file system error . release <number> . <number> executable buildet at debian <number> ( mingw ) give error at windows file system . ` ` ` exception : nst10filesystem7__cxx1116filesystem_errore filesystem error remove [ d :\\ chains \ \ bitcoin22 \ \ anchors . dat ] h :\\ testing \ \ dssdds \ \ bin \ \ bitcoin - qt . exe in runaway exception ` ` ` no matter installer or setup . what commit is stable for that version for self build ?,0
bitcoin/bitcoin,miniscript_stable fuzz timeout <url>,0
bitcoin/bitcoin,"failure in feature_bip68_sequence . py <url> ` ` ` bash node0 <number> - <number> - 1 6 t <time> . 5 0 5 4 0 5 z [ httpworker . <number> ] [ rpc / request . cpp : <number> ] [ parse ] [ rpc ] threadrpcserver method = sendrawtransaction user = __cookie__ node0 <number> - <number> - 1 6 t <time> . 5 0 6 1 5 6 z [ httpworker . <number> ] [ txmempool . cpp : <number> ] [ check ] [ mempool ] checking mempool with <number> transactions and <number> inputs test <number> - <number> - 1 6 t <time> . 5 1 3 0 0 0 z testframework ( error ) : jsonrpc error traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_bip68_sequence . py "" , line <number> , in run_test self . test_sequence_lock_unconfirmed_inputs ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_bip68_sequence . py "" , line <number> , in test_sequence_lock_unconfirmed_inputs tx1 = self . wallet . send_self_transfer ( from_node = self . nodes [ <number> ] ) [ "" tx "" ] file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / wallet . py "" , line <number> , in send_self_transfer self . sendrawtransaction ( from_node = from_node , tx_hex = tx [ ' hex ' ] ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / wallet . py "" , line <number> , in sendrawtransaction txid = from_node . sendrawtransaction ( hexstring = tx_hex , maxfeerate = maxfeerate , * * kwargs ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / coverage . py "" , line <number> , in __call__ return_val = self . auth_service_proxy_instance . __call__ ( * args , * * kwargs ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / authproxy . py "" , line <number> , in __call__ raise jsonrpcexception ( response [ ' error ' ] , status ) test_framework . authproxy . jsonrpcexception : bad - txns - premature - spend - of - coinbase , tried to spend coinbase at depth <number> ( - <number> ) test <number> - <number> - 1 6 t <time> . 5 1 4 0 0 0 z testframework ( debug ) : closing down network thread test <number> - <number> - 1 6 t <time> . 5 6 4 0 0 0 z testframework ( info ) : stopping nodes test <number> - <number> - 1 6 t <time> . 5 6 4 0 0 0 z testframework . node0 ( debug ) node ` ` `",0
bitcoin/bitcoin,"on osx , bitcoind chooses different data directory than bitcoin - qt bitcoind uses ` ~ / library / application support / bitcoin ` as base data directory path but bitcoin - qt uses ` ~ / . bitcoin ` i actually much prefer the latter since it is more unix - like and i assume users running the daemon from the command line probably do as well . it might make sense if this behavior was swapped and the gui chose the user - friendly library / support path , but my preference would be using ` ~ / . bitcoin ` on osx all the time . the issue most likely comes down to this logic in system . cpp : <url> . <repeated> but i have no idea why bitcoin - qt would be compiled without the ` mac_osx ` flag while bitcoind would be . i confirmed the behavior building bitcoind and - qt both from master and also by downloading the v24 . <number> gui for osx from bitcoincore . org it ' s also possible that this issue only affects m1 ( arm64 ) macs like mine : ` ` ` - - > uname - a darwin <number> . <number> darwin kernel version <number> . <date> <time> pdt <number> ; root : xnu - <number> . <number> ~ <number> / release_arm64_t8101 arm64 ` ` `",0
bitcoin/bitcoin,"failing to fetch ` cfheader ` corresponding to block header in ` headers ` message < - - describe the issue - - > occasionally when i receive a ` headers ` message on the p2p network , and attempt to fetch the ` cfheader ` that corresponds to a block header inside of a ` headers ` , i get this error message inside of my ` debug . log ` > <number> - <number> - 0 7 t <time> z [ net ] failed to find block filter hashes in index : filter_type = basic , start_height = <number> , stop_hash <laugh> ca9030aeb6c2721cfbab0116b8d96e2d3c7e00738238010e0bc622566dc2aed * * expected behavior * * i should be able to fetch a ` cfheader ` for a block after the block has been relayed to me over the p2p network via ` headers ` p2p message . < ! - - - what behavior did you expect ? - - > * * actual behavior * * it fails to fetch the ` cfheader ` that corresponds to the block . * * to reproduce * * i am unable to reproduce reliably , but this does occur ~ <number> / <number> times when running test suites on bitcoin - s . * * system information * * <number> ( although i have seen this behavior for awhile and believe this issue exists in older versions of ` bitcoind ` ) the os / cpu arch does not seem to be a factor in this bug . i can reproduce on linux / mac machines with older / newer versions of bitcoind i have attached the ` debug . log ` for my ` bitcoind ` instance . the block hash in question is ` 3 ca9030aeb6c2721cfbab0116b8d96e2d3c7e00738238010e0bc622566dc2aed ` . [ debug . log ] ( <url> this is related to",0
bitcoin/bitcoin,"private key import via rpc importdescriptors should not fail with the error code - <number> , "" missing checksum "" * * expected behavior * * descriptor is imported successfully . * * actual behavior * * descriptor is not imported . there is the error : ` ` ` [ { "" success "" : false , "" error "" : { "" code "" : - <number> , "" message "" : "" missing checksum "" } } ] ` ` ` * * to reproduce * * <number> . execute the rpc command , e . g . : ` importdescriptors ' [ { "" desc "" : "" tr ( cutfblpuabapmtkwjcds4rwhuseububfkpmogrbtmqfnja3vgrle ) "" , "" timestamp "" : "" now "" } ] ' ` * * system information * * bitcoin core <number> . <number> excerpt from the bip - <number> specification the top level expression is a script . this expression * may <emphasis> * be followed by <hashtag> check sum </hashtag> , where checksum is an <number> character alphanumeric descriptor checksum .",0
bitcoin/bitcoin,"intermittent issue in wallet_pruning . py ` ` ` wget <url> tar - xvf . / wallet_pruning_258 . tar . xz test / functional / combine_logs . py - c . / wallet_pruning_258 ` ` ` ` ` ` test <number> - <number> - 0 8 t <time> . 7 8 7 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / wallet_pruning . py "" , line <number> , in run_test self . mine_large_blocks ( self . nodes [ <number> ] , <number> ) file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / wallet_pruning . py "" , line <number> , in mine_large_blocks self . sync_all ( ) file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in sync_all self . sync_blocks ( nodes ) file "" / root / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in sync_blocks assert ( all ( [ len ( x . getpeerinfo ( ) ) for x in rpc_connections ] ) ) assertionerror",0
bitcoin/bitcoin,"macos depends build does not cache in the ci at least in the ci , the depends build does not cache . e . g . <url> this causes the build to take an hour when it should be done in less than <number> minutes witch a ccache .",0
bitcoin/bitcoin,"signrawtransactionwithkey command should not output the "" witness program was passed an empty witness "" error for a taproot transaction there is the irrelevant error message output by the signrawtransactionwithkey command . * * expected behavior * * hex string of the raw transaction with signature or meaningful message about an alternative way to achieve one . * * actual behavior * * ` ` ` { "" hex "" : "" <phone> a2c0d82460883696219dbca6f545f72963b2b3ee085d832eb5ef9a69a374af160000000000fdffffff01e011000000000000225120052e44f45a6e381be8e06d3f3362b58034a68ba98081e24de7bfc5795420a90b00000000 "" , "" complete "" : false , "" errors "" : [ { "" txid "" : "" 1 6 af74a3699aefb52e835d08eeb3b26329f745f5a6bc9d219636886024d8c0a2 "" , "" vout "" : <number> , "" witness "" : [ ] , "" scriptsig "" : "" "" , "" sequence "" : <phone> , "" error "" : "" witness program was passed an empty witness "" } ] } ` ` ` * * to reproduce * * ` ` ` $ signrawtransactionwithkey "" 0 2 0 0 0 0 0 0 0 1 1 1 5 7 6 6 7 b81a1a4e688938c42ee7cdea23761cb7622a3476f0bc8ace7d0ec523100000000000000000001e8030000000000002251203b82b2b2a9185315da6f80da5f06d0440d8a5e1457fa93387c2d919c86ec878600000000 "" ' [ "" cutfblpuabapmtkwjcds4rwhuseububfkpmogrbtmqfnja3vgrle "" ] ' ' [ { "" txid "" : "" 3 1 5 2 ecd0e7acc80b6f47a32276cb6137a2de7cee428c9388e6a4a1817b665711 "" , "" vout "" : <number> , "" scriptpubkey "" : "" 5 1 2 0 c38859777bc9c3294d3587035fc3823a146dabaab1fa250bc04e92f16887a065 "" , "" amount "" : <number> } ] ' "" default "" ` ` ` * * system information * * console in bitcoin core <number> . <number> portable , windows <number> . ( occurs in both cases of a descriptor wallet loaded and not loaded ) . hint : signrawtransactionwithwallet works fine if preceded with the importdescriptors ' [ { "" desc "" : "" tr ( cutfblpuabapmtkwjcds4rwhuseububfkpmogrbtmqfnja3vgrle ) <hashtag> tdkpah70 </hashtag> "" , "" timestamp """,0
bitcoin/bitcoin,"rpc request gives an exception on more than two wallet has been loaded . < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > rpc request gives an exception on more than two wallet has been loaded . but it is working as normal when only one of them opened . therefore , it makes it difficult to operate using multiple api on bitcoincore . * * expected behavior * * working with no exception when we call the wallet using api . < ! - - - what behavior did you expect ? - - > * * actual behavior * * the exception message file not specified ( must request wallet rpc through / wallet / <filename> uri - path ) . || <number> - jan - <number> <time> < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,"intermittent failure in mining_getblocktemplate_longpoll . py seen on master , <url> ` ` ` <number> - <number> - 2 4 t <time> . 1 7 3 0 0 0 z testframework ( info ) : test that introducing a new transaction into the mempool will terminate the longpoll <number> - <number> - 2 4 t <time> . 1 8 2 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / mining_getblocktemplate_longpoll . py "" , line <number> , in run_test assert not thr . is_alive ( ) assertionerror <number> - <number> - 2 4 t <time>",0
bitcoin/bitcoin,"signmessage and verifymessage : "" address does not refer to key "" < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > sign and verify message functions not working with ( probobaly bech32 type addresse like : "" bc1qg0kmtkmgf4angrmcr9wz2fslxjj4jzj95tkg6r "" . i was able to sign using signmessagewithprivkey "" privkey "" "" my message "" and the result if it is correct : "" h + qaukt8fp / tfh3bchd9orj00s7rzuxzsxnxh10y4tgkwkymkfsffxos50bo9510ngnhgsube1yg7bbldc2qvgy = "" however using signmessage "" bc1qg0kmtkmgf4angrmcr9wz2fslxjj4jzj95tkg6r "" "" my message "" and verifymessage "" bc1qg0kmtkmgf4angrmcr9wz2fslxjj4jzj95tkg6r "" "" signature "" "" my message "" examples gives error does not refer to key "" * * expected behavior * * signing and verifying messages using bech32 addresses . < ! - - - what behavior did you expect ? - - > * * actual behavior * * "" address does not refer to key "" error < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,"contrib / install_db4 . sh script fails on openbsd <number> ( rpi <number> ) ( error : unable to find a mutex implementation ) when trying to compile bitcoin core with legacy wallet on openbsd <number> stable running on rpi3 , the process fails while running install_db4 . sh script checking for getopt optreset variable . <repeated> yes checking for mutexes . <repeated> unix / fcntl configure : warning : no shared latch implementation found for this platform . configure : error to find a mutex implementation",0
bitcoin/bitcoin,"s390x fails to compile ( werror = free - nonheap - object ) steps to reproduce on a fresh install of ` debian : bookworm ` : ` ` ` export debian_frontend = noninteractive & & apt update & & apt install htop git vim - y & & git clone <url> - - depth = <number> . / bitcoin - core & & cd . / bitcoin - core no_qt = <number> dir_qa_assets <annoyed> qa_assets ccache_dir <annoyed> ccache_dir ccache_size = 5 0 0 m danger_run_ci_on_host = "" <number> "" makejobs = "" - j9 "" file_env ="". / ci / test / 0 0 _setup_env_s390x . sh "" . / ci / test_run_all . sh ` ` ` ` ` ` / usr / bin / ccache s390x - linux - gnu - g + + - std =c + + <number> - dhave_config_h - i . - i . <repeated> / src / config - fmacro - prefix - map <annoyed> tmp / cirrus - ci - build / bitcoin - core / ci / scratch / build / bitcoin - s390x - linux - gnu = . - u_fortify_source - d_fortify_source = <number> - dhave_build_info - dprovide_fuzz_main_function - i . - i . / minisketch / include - i . / secp256k1 / include - i . / univalue / include - i . / leveldb / include - isystem / tmp / cirrus - ci - build / bitcoin - core / depends / s390x - linux - gnu / include - dboost_multi_index_disable_serialization - dboost_no_cxx98_function_base - isystem / tmp / cirrus - ci - build / bitcoin - core / depends / s390x - linux - gnu / include - i / tmp / cirrus - ci - build / bitcoin - core / depends / s390x - linux - gnu / include - i / tmp / cirrus - ci - build / bitcoin - core / depends / s390x - linux - gnu / include / - fdebug - prefix - map <annoyed> tmp / cirrus - ci - build / bitcoin - core / ci / scratch / build / bitcoin - s390x - linux - gnu = . - fstack - reuse = none - wstack - protector - fstack - protector - all - fstack - clash - protection - werror - fno - extended - identifiers - fvisibility = hidden - fpie - pipe - std =c + + <number> - o2 - c - o libbitcoin_node_a - txmempool . o ` test - f ' txmempool . cpp ' || echo ' . / ' ` txmempool . cpp in file included from / usr / s390x - linux - gnu / include / c + + / <number> / s390x - linux - gnu / bits / c + + allocator . h : <number> , from / usr / s390x - linux - gnu / include / c + + / <number> / bits / allocator . h : <number> , from / usr / s390x - linux - gnu / include / c + + / <number> / bits / stl_tree . h : <number> , from / usr / s390x - linux - gnu / include / c + + / <number> / map : <number> , from . / txmempool . h : <number> , from txmempool . cpp : <number> : in member function ‘ void std : : __new_allocator <_tp> : : deallocate ( _tp * , size_type ) [ with _tp = char ] ’ , inlined from ‘ static void std : : allocator_traits < std : : allocator <_tp1> <sad> : deallocate ( allocator_type & , pointer , size_type ) [ with _tp = char ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / bits / alloc_traits . h : <number> <time> , inlined from ‘ void std : : __cxx11 : : basic_string < _chart , _traits , _alloc > : : _m_destroy ( size_type ) [ with _chart = char ; _traits = std : : char_traits <char> ; _alloc = std : : allocator <char> ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / bits / basic_string . h : <number> <time> , inlined from ‘ void std : : __cxx11 : : basic_string < _chart , _traits , _alloc > : : _m_dispose ( ) [ with _chart = char ; _traits = std : : char_traits <char> ; _alloc = std : : allocator <char> ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / bits / basic_string . h : <number> <time> , inlined from ‘ std : : __cxx11 : : basic_string < _chart , _traits , _alloc > : : ~ basic_string ( ) [ with _chart = char ; _traits = std : : char_traits <char> ; _alloc = std : : allocator <char> ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / bits / basic_string . h : <number> <time> , inlined from ‘ bilingual_str : : ~ bilingual_str ( ) ’ at . / util / translation . h : <number> : <number> , inlined from ‘ constexpr void std : : _destroy ( _tp <wink> [ with _tp = bilingual_str ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / bits / stl_construct . h : <number> <time> , inlined from ‘ std : : __detail : : __variant : : _variant_storage < false , bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : _m_reset ( <sad> : < lambda ( auto : <number> & & ) > mutable [ with auto : <number> = bilingual_str & ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ constexpr _res std : : __invoke_impl ( __invoke_other , _fn & & , _args & & . <repeated> ) [ with _res = void ; _fn = __detail : : __variant : : _variant_storage < false , bilingual_str , set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : _m_reset ( <sad> : < lambda ( auto : <number> & & )>; _args = { bilingual_str & } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / bits / invoke . h : <number> <time> , inlined from ‘ constexpr std : : enable_if_t < is_invocable_r_v < _res , _callable , _args . <repeated> > , _res > std : : __invoke_r ( _callable & & , _args & & . <repeated> ) [ with _res = void ; _callable = __detail : : __variant : : _variant_storage < false , bilingual_str , set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : _m_reset ( <sad> : < lambda ( auto : <number> & & )>; _args = { bilingual_str & } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / bits / invoke . h : <number> <time> , inlined from ‘ static constexpr decltype ( auto ) std : : __detail : : __variant : : __gen_vtable_impl < std : : __detail : : __variant : : _multi_array < _result_type (* ) ( _visitor , _variants . <repeated> ) > , std : : integer_sequence < long unsigned int , __indices . <repeated> > <sad> : __visit_invoke ( _visitor & & , _variants . <repeated> ) [ with _result_type = void ; _visitor = std : : __detail : : __variant : : _variant_storage < false , bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : _m_reset ( <sad> : < lambda ( auto : <number> & & ) > & & ; _variants = { std : : variant < bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > > & }; long unsigned int . <repeated> __indices = { <number> } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ constexpr decltype ( auto ) std : : __do_visit ( _visitor & & , _variants & & . <repeated> ) [ with _result_type = void ; _visitor = __detail : : __variant : : _variant_storage < false , bilingual_str , set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : _m_reset ( <sad> : < lambda ( auto : <number> & & )>; _variants = { variant < bilingual_str , set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > > & } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> : <number> , inlined from ‘ constexpr decltype ( auto ) std : : __do_visit ( _visitor & & , _variants & & . <repeated> ) [ with _result_type = void ; _visitor = __detail : : __variant : : _variant_storage < false , bilingual_str , set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : _m_reset ( <sad> : < lambda ( auto : <number> & & )>; _variants = { variant < bilingual_str , set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > > & } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> : <number> , inlined from ‘ constexpr void std : : __detail : : __variant : : _variant_storage < false , _types . <repeated> <sad> : _m_reset ( ) [ with _types = { bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ std : : __detail : : __variant : : _variant_storage < false , _types . <repeated> <sad> : ~ _variant_storage ( ) [ with _types = { bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ std : : __detail : : __variant : : _copy_ctor_base < false , bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : ~ _copy_ctor_base ( ) ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ std : : __detail : : __variant : : _move_ctor_base < false , bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : ~ _move_ctor_base ( ) ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ std : : __detail : : __variant : : _copy_assign_base < false , bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : ~ _copy_assign_base ( ) ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ std : : __detail : : __variant : : _move_assign_base < false , bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : ~ _move_assign_base ( ) ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ std : : __detail : : __variant : : _variant_base < bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > <sad> : ~ _variant_base ( ) ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ std : : variant <_types> : : ~ variant ( ) [ with _types = { bilingual_str , std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash , std : : allocator < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > > > } ] ’ at / usr / s390x - linux - gnu / include / c + + / <number> / variant : <number> <time> , inlined from ‘ util : : result < std : : set < boost : : multi_index : : detail : : hashed_index_iterator < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : hashed_index_node < boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : ordered_index_node < boost : : multi_index : : detail : : null_augment_policy , boost : : multi_index : : detail : : index_node_base < ctxmempoolentry , std : : allocator <ctxmempoolentry> > > > > > > , boost : : multi_index : : detail : : bucket_array < std : : allocator <ctxmempoolentry> > , boost : : multi_index : : detail : : hashed_unique_tag , boost : : multi_index : : detail : : hashed_index_global_iterator_tag > , compareiteratorbyhash > <sad> : ~ result ( ) ’ at . / util / result . h : <number> : <number> , inlined from ‘ ctxmempool : : setentries ctxmempool : : assumecalculatemempoolancestors ( std : : string_view , const ctxmempoolentry & , const limits & , bool ) const ’ at txmempool . cpp : <number> <time> : / usr / s390x - linux - gnu / include / c + + / <number> / bits / new_allocator . h : <number> <time> : error : ‘ void operator delete ( void * , std : : size_t ) ’ called on unallocated object ‘ <anonymous> ’ [ - werror = free - nonheap - object ] <number> | _glibcxx_operator_delete ( _glibcxx_sized_dealloc ( __p , __n ) ); | ^ in file included from txmempool . cpp : <number> : txmempool . cpp : in member function ‘ ctxmempool : : setentries ctxmempool : : assumecalculatemempoolancestors ( std : : string_view , const ctxmempoolentry & , const limits & , bool ) const ’ : txmempool . cpp : <number> <time> : note : declared here <number> | auto result { assume ( calculatemempoolancestors ( entry , limits , fsearchforparents ) )}; | ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ . / util / check . h : <number> <time> : note : in definition of macro ‘ assume ’ <number> | <hashtag> define </hashtag> assume ( val ) inline_assertion_check <false> ( val , __file__ , __line__ , __func__ , <hashtag> val </hashtag> ) | ^ ~ ~ cc1plus : all warnings being treated as errors make [ <number> <sad> * * * [ makefile : <number> : libbitcoin_node_a - txmempool . o ] error <number> make [ <number> <sad> leaving directory ' / tmp / cirrus - ci - build / bitcoin - core / ci / scratch / build / bitcoin - s390x - linux - gnu / src ' make [ <number> <sad> * * * [ makefile : <number> : install - recursive ] error <number> make [ <number> <sad> leaving directory ' / tmp / cirrus - ci - build / bitcoin - core / ci / scratch / build / bitcoin - s390x - linux - gnu / src ' make : * * * [ makefile : <number> error <number>",0
bitcoin/bitcoin,"p2p_disconnect_ban intermittent issue <url> ` ` ` test <number> - <number> - 1 7 t <time> . 6 9 9 0 0 0 z testframework . utils ( error ) : wait_until ( ) failed . predicate : ' ' ' ' self . wait_until ( lambda : sum ( peer [ ' version ' ] = <number> for peer in to_connection . getpeerinfo ( ) ) = = to_num_peers ) ' ' ' test <number> - <number> - 1 7 t <time> . 6 9 9 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / p2p_disconnect_ban . py "" , line <number> , in run_test self . connect_nodes ( <number> , <number> ) # reconnect the node file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in connect_nodes self . wait_until ( lambda : sum ( peer [ ' version ' ] ! = <number> for peer in to_connection . getpeerinfo ( ) ) = = to_num_peers ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in wait_until return wait_until_helper ( test_function , timeout = timeout , timeout_factor = self . options . timeout_factor ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in wait_until_helper raise assertionerror ( "" predicate { } not true after { } seconds "" . format ( predicate_source , timeout ) ) assertionerror : predicate ' ' ' ' self . wait_until ( lambda ! = <number> for peer in to_connection . getpeerinfo ( ) ) = = to_num_peers ) ' ' ' not true after <number> seconds",0
bitcoin/bitcoin,"` test / lint / lint - python . py ` thinks flake8 is not installed when it actually is ` ` ` $ . / test / lint / lint - python . py skipping python linting since flake8 is not installed . $ flake8 - - version <number> . <number> ( mccabe : <number> . <number> , pycodestyle : <number> . <number> , pyflakes cpython <number> . <number> on linux ` ` ` if i try [ old ` lint - python . sh ` ] ( <url> it works .",0
bitcoin/bitcoin,"i2p : limit transient addresses the per - connection transient address feature in <number> . <number> is , we are pretty sure , putting a large load on the i2p network . starting on dec . <number> the number of tunnels in the network started to increase , and as measured at one router , it peaked at about 3 x normal levels on dec . <number> . while the load is manageable for now , if the transient feature becomes popular , it has the potential to get much much worse . i2p is not really designed to work that way , and some limit on the number of addresses ( aka destinations or tunnels ) built by the bitcoin client is necessary . i2p destinations are designed to be long - lived , it ' s not like in tor where you can create tons of circuits . waiting for tunnels to be built for each connection also adds a huge amount of delay to connection setup time . a high number of addresses will also result in excessive cpu and bandwidth usage by your router to build the tunnels for each . additionally , other routers will reject your excessive tunnel building , which will increase your resource usage even more as your router retries . and , of course , the overhead applies to every connection attempt , not just every successful connection . depending on your security goals , and the max number of i2p connections you wish to support , there ' s a few options for you to consider : - use a single transient address , created at startup - hard limit the number of i2p connections if configured for transient - group several connections into one of several addresses in a pool - rate limit new connections or creation of new addresses the i2pd router does not currently limit the number of local destinations , i do not think . the java router limits to <number> by default and will reject addresses over that limit . if you do choose to continue using multiple addresses , we recommend a reasonable maximum number of addresses of around <number> or so , together with a rate limit on how frequently you create new ones . unfortunately i did not realize this was happening when i reviewed your transient changes , but your <number> . <number> release notes confirm it . we ask that you please fix and include this in your next point release . in the meantime , please update your i2p doc to discourage the transient option . also in that doc , in the bandwidth section at the bottom , please encourage people to share as much bandwidth and transittunnels as they can , to increase their anonymity with the cover traffic , and so that bitcoin users contribute more to the i2p network than they consume . if a popular application uses more network resources than it contributes , it has the potential to take down the entire network . reference files : <url> <url> thank you very much for considering this change . graph of number of tunnels on a typical high - speed i2p router , dec . <number> - <number> replaced link ) <url>",0
bitcoin/bitcoin,codespell errors in ` src / wallet / test / walletload_tests . cpp ` on current master ( cb32328d1b80d0ccd6eb9532bd8fe4e0a4de385e ) . ` ` ` $ . / test / lint / all - lint . py skipping python linting since flake8 is not installed . src / wallet / test / walletload_tests . cpp : <number> : crypted ==> encrypted src / wallet / test / walletload_tests . cpp : <number> : crypted ==> encrypted src / wallet / test / walletload_tests . cpp : <number> : crypted ==> encrypted ^ warning identified likely spelling errors . any false positives ? add them to the list of ignored words in test / lint / spelling . ignore - words . txt ` ` `,0
bitcoin/bitcoin,"ci : clang - tidy does not check header files ? inside the ci env ` file_env ="". / ci / test / 0 0 _setup_env_native_tidy . sh "" ` clang - tidy only checks our cpp files and not our header files ? currently it passes on master , however if manually invoked on a header file , it will fail : ` ` ` # clang - tidy - <number> - p <annoyed> bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu - quiet / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . cpp & & echo $ ? <number> warnings generated . <number> warnings generated . <number> # clang - tidy - <number> - p <annoyed> bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu - quiet / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h & & echo $ ? <number> warnings generated . / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' name ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] : m_names { std : : move ( name ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' type ' of the trivially - copyable type ' const rpcarg : : type ' has no effect ; remove std : : move ( ) [ performance - move - const - arg , - warnings - as - errors ] m_type { std : : move ( type ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' fallback ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_fallback { std : : move ( fallback ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' description ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_description { std : : move ( description ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' name ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] : m_names { std : : move ( name ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' type ' of the trivially - copyable type ' const rpcarg : : type ' has no effect ; remove std : : move ( ) [ performance - move - const - arg , - warnings - as - errors ] m_type { std : : move ( type ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' inner ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_inner { std : : move ( inner ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' fallback ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_fallback { std : : move ( fallback ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' description ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_description { std : : move ( description ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' type ' of the trivially - copyable type ' const rpcresult : : type ' has no effect ; remove std : : move ( ) [ performance - move - const - arg , - warnings - as - errors ] : m_type { std : : move ( type ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' m_key_name ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_key_name { std : : move ( m_key_name ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' inner ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_inner { std : : move ( inner ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' description ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_description { std : : move ( description ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' cond ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_cond { std : : move ( cond ) } ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' type ' of the trivially - copyable type ' const rpcresult : : type ' has no effect ; remove std : : move ( ) [ performance - move - const - arg , - warnings - as - errors ] : m_type { std : : move ( type ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' m_key_name ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_key_name { std : : move ( m_key_name ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error : std : : move of the const variable ' inner ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_inner { std : : move ( inner ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / bitcoin - core / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src / rpc / util . h : <number> <time> : error of the const variable ' description ' has no effect ; remove std : : move ( ) or make the variable non - const [ performance - move - const - arg , - warnings - as - errors ] m_description { std : : move ( description ) } , ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~",0
bitcoin/bitcoin,"unable to create psbt for legacy watchonly wallets in the gui a user reported to me that they are unable to create a psbt with a legacy watchonly wallet when they use the gui . they get an error "" the amount exceeds your balance "" . i think the issue is that the gui will retrieve the wallet ' s balance via ` availablecoins ` before calling ` createtransaction ` . this call to ` availablecoins ` is resulting in fewer coins being returned with recent changes to how ` availablecoins ` works , particularly with additional filtering of spendable coins and preset coins . * * * note that this does not effect descriptor wallets . a workaround for this issue is to switch to using descriptor wallets . an existing legacy wallet can be turned into a descriptor wallet using the ` migratewallet ` rpc . however many watchonly legacy wallets are likely the result of importing descriptors via ` importmulti ` . for such wallets , i recommend creating a new descriptor wallet and re - importing the descriptors .",0
bitcoin/bitcoin,"pruned node unable to start when a wallet is present this is the weirdest bug i have seen in a while , as i can not reproduce , but it happens persistently on a server of one of our users . i tried to delete wallet and recreate it , it does not work , still stuck . i tried to remove the wallet and not recreate it , and bitcoin core starts properly . i uploaded a wallet generated there : <url> i tried to load the wallet on my local node ( non - pruned ) , it works and there is no rescan . ` ` ` <number> - <number> - 0 8 t <time> z no coin database inconsistencies in last <number> blocks ( <number> transactions ) <number> - <number> - 0 8 t <time> z block index 1 0 5 2 2 ms <number> - <number> - 0 8 t <time> z init message : loading wallet … <number> - <number> - 0 8 t <time> z berkeleyenvironment : : open : logdir =c :\\ users \ \ nicolasdorier \ \ tmp \ \ database errorfile =c :\\ users \ \ nicolasdorier \ \ tmp \ \ db . log <number> - <number> - 0 8 t <time> z [ default wallet ] wallet file version = <phone> - <number> - 0 8 t <time> z [ default wallet ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records : <number> <number> - <number> - 0 8 t <time> z [ default wallet ] wallet completed loading in 6 0 ms <number> - <number> - 0 8 t <time> z [ default wallet ] setkeypool . size ( ) = <number> <number> - <number> - 0 8 t <time> z [ default wallet ] mapwallet . size ( ) = <number> <number> - <number> - 0 8 t <time> z [ default wallet ] m_address_book . size ( ) = <number> <number> - <number> - 0 8 t <time> z unsetting node_network on prune mode <number> ` ` ` on the server of the user the node is pruned , and there is a rescan with error ` ` ` <number> - <number> - 0 8 t <time> z [ default wallet ] wallet completed loading in 1 5 2 ms <number> - <number> - 0 8 t <time> z error : prune : last wallet synchronisation goes beyond pruned data . you need to - reindex ( download the whole blockchain again in case of pruned node ) error : prune : last wallet synchronisation goes beyond pruned data . you need to - reindex ( download the whole blockchain again in case of pruned node ) ` ` ` even though the wallet just got created . the pruneheight should also be big enough : ` ` ` bash getblockchaininfo ` ` ` ` ` ` json { "" chain "" : "" test "" , "" blocks "" : <number> , "" headers "" : <number> , "" bestblockhash "" : "" 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 a51915a9d3473d6185744de708a1bf008a471e702dfc43fc "" , "" difficulty "" : <number> , "" time "" : <phone> , "" mediantime "" : <phone> , "" verificationprogress "" : <number> , "" initialblockdownload "" : false , "" chainwork "" : "" 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 3 9 f6768de759ba571f "" , "" size_on_disk "" : <phone> , "" pruned "" : true , "" pruneheight "" : <number> , "" automatic_pruning "" : true , "" prune_target_size "" : <number> , "" warnings "" : "" unknown new rules activated ( versionbit <number> ) "" } ` ` ` anything else i can provide you ? i am really at loss about why this specific node is asking for a rescan . * * expected behavior * * node starts properly when a new wallet is just created . * * actual behavior * * node stuck ` ` ` <number> - <number> - 0 8 t <time> z bitcoin core version v24 . <number> ( release build ) <number> - <number> - 0 8 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) ' sha256 implementation <number> - <number> - 0 8 t <time> z default data directory / home / bitcoin / . bitcoin <number> - <number> - 0 8 t <time> z using data directory / home / bitcoin / . bitcoin / testnet3 <number> - <number> - 0 8 t <time> z config file : / home / bitcoin / . bitcoin / bitcoin . conf <number> - <number> - 0 8 t <time> z config file arg : testnet = "" <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] maxmempool = "" <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] onion = "" tor : <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] port = "" <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] printtoconsole = "" <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] prune = "" <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] rpcallowip = "" : : / <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] rpcallowip = "" <number> . <number> / <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] rpcauth = * * * * <number> - <number> - 0 8 t <time> z config file arg : [ test ] rpcauth = * * * * <number> - <number> - 0 8 t <time> z config file arg : [ test ] rpcbind = * * * * <number> - <number> - 0 8 t <time> z config file arg : [ test ] rpcport = "" <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] walletdir =""/ walletdata / testnet "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] whitelist = "" <number> . <number> / <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] zmqpubhashblock = "" tcp :// <number> . <number> . <time> <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] zmqpubrawblock = "" tcp :// <number> . <number> . <time> <number> "" <number> - <number> - 0 8 t <time> z config file arg : [ test ] zmqpubrawtx = "" tcp :// <number> . <number> . <time> <number> "" <number> - <number> - 0 8 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 0 8 t <time> z using <number> mib out of <number> mib requested for signature cache , able to store <number> elements <number> - <number> - 0 8 t <time> z using <number> mib out of <number> mib requested for script execution cache , able to store <number> elements <number> - <number> - 0 8 t <time> z script verification uses <number> additional threads <number> - <number> - 0 8 t <time> z scheduler thread start <number> - <number> - 0 8 t <time> z warning : the rpc server is not safe to expose to untrusted networks such as the public internet <number> - <number> - 0 8 t <time> z [ http ] creating work queue of depth <number> <number> - <number> - 0 8 t <time> z using random cookie authentication . <number> - <number> - 0 8 t <time> z generated rpc authentication cookie / home / bitcoin / . bitcoin / testnet3 / . cookie <number> - <number> - 0 8 t <time> z using rpcauth authentication . <number> - <number> - 0 8 t <time> z [ http ] starting <number> worker threads <number> - <number> - 0 8 t <time> z using wallet directory / walletdata / testnet <number> - <number> - 0 8 t <time> z init message : verifying wallet ( s ) … <number> - <number> - 0 8 t <time> z using berkeleydb version berkeley db <date> : ( <date> ) <number> - <number> - 0 8 t <time> z using wallet / walletdata / testnet / wallet . dat <number> - <number> - 0 8 t <time> z berkeleyenvironment : : open : logdir <annoyed> walletdata / testnet / database errorfile <annoyed> walletdata / testnet / db . log <number> - <number> - 0 8 t <time> z using / <number> prefix for ip bucketing <number> - <number> - 0 8 t <time> z init message : loading p2p addresses … <number> - <number> - 0 8 t <time> z loaded <number> addresses from peers . dat 3 9 3 ms <number> - <number> - 0 8 t <time> z init message : loading banlist … <number> - <number> - 0 8 t <time> z setnetworkactive : true <number> - <number> - 0 8 t <time> z cache configuration : <number> - <number> - 0 8 t <time> z * using <number> mib for block index database <number> - <number> - 0 8 t <time> z * using <number> mib for chain state database <number> - <number> - 0 8 t <time> z * using <number> mib for in - memory utxo set ( plus up to <number> mib of unused mempool space ) <number> - <number> - 0 8 t <time> z init message : loading block index … <number> - <number> - 0 8 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 8 7 7 fa2d36316398528de4f347df2f8a96f76613a298ce060 have valid signatures . <number> - <number> - 0 8 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 6 f6e7cbd0beade5d20 <number> - <number> - 0 8 t <time> z prune configured to target <number> mib on disk for block and undo files . <number> - <number> - 0 8 t <time> z switching active chainstate to chainstate [ ibd ] @ height - <number> ( null ) <number> - <number> - 0 8 t <time> z opening leveldb in / home / bitcoin / . bitcoin / testnet3 / blocks / index <number> - <number> - 0 8 t <time> z opened leveldb successfully <number> - <number> - 0 8 t <time> z using obfuscation key for / home / bitcoin / . bitcoin / testnet3 / blocks / index : <number> <number> - <number> - 0 8 t <time> z loadblockindexdb : last block file = <number> <number> - <number> - 0 8 t <time> z loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) <number> - <number> - 0 8 t <time> z checking all blk files are present . <repeated> <number> - <number> - 0 8 t <time> z loadblockindexdb ( <sad> block files have previously been pruned <number> - <number> - 0 8 t <time> z opening leveldb in / home / bitcoin / . bitcoin / testnet3 / chainstate <number> - <number> - 0 8 t <time> z opened leveldb successfully <number> - <number> - 0 8 t <time> z using obfuscation key for / home / bitcoin / . bitcoin / testnet3 / chainstate : dd2d995e0b39a1e4 <number> - <number> - 0 8 t <time> z loaded best chain : hashbestchain = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 e323100923fd63334a2b4e3e087609da60e07bfcb41fc3e66 height = <number> date = <number> - <number> - 0 7 t <time> z progress = <number> . <phone> - <number> - 0 8 t <time> z init message : verifying blocks … <number> - <number> - 0 8 t <time> z verifying last <number> blocks at level <number> <number> - <number> - 0 8 t <time> z [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ done ] . <number> - <number> - 0 8 t <time> z no coin database inconsistencies in last <number> blocks ( <number> transactions ) <number> - <number> - 0 8 t <time> z block index 6 7 6 2 2 ms <number> - <number> - 0 8 t <time> z init message : loading wallet … <number> - <number> - 0 8 t <time> z berkeleyenvironment : : open : logdir <annoyed> walletdata / testnet / database errorfile <annoyed> walletdata / testnet / db . log <number> - <number> - 0 8 t <time> z [ default wallet ] wallet file version = <number> , last client version = <phone> - <number> - 0 8 t <time> z [ default wallet ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records : <number> <number> - <number> - 0 8 t <time> z [ default wallet ] wallet completed loading in 1 5 2 ms <number> - <number> - 0 8 t <time> z error : prune : last wallet synchronisation goes beyond pruned data . you need to - reindex ( download the whole blockchain again in case of pruned node ) error : prune : last wallet synchronisation goes beyond pruned data . you need to - reindex ( download the whole blockchain again in case of pruned node ) <number> - <number> - 0 8 t <time> z shutdown : in progress . <repeated> <number> - <number> - 0 8 t <time> z scheduler thread exit <number> - <number> - 0 8 t <time> z shutdown ` ` ` * * to reproduce * * i can only reproduce on a single instance , i tried to reproduce on my own server and did not managed to . ` ` ` bash bitcoin - wallet "" - datadir <annoyed> walletdata / testnet "" "" - legacy "" "" - wallet = "" create ` ` ` config ` ` ` ini testnet = <number> [ test ] walletdir <annoyed> walletdata / testnet printtoconsole = <number> rpcallowip = : : / <number> rpcport = <number> rpcbind = <number> . <number> . <time> <number> rpcallowip = <number> . <number> / <number> port = <number> whitelist = <number> . <number> / <number> maxmempool = <number> prune = <number> zmqpubrawblock = tcp :// <number> . <number> . <time> <number> zmqpubrawtx = tcp :// <number> . <number> . <time> <number> zmqpubhashblock = tcp :// <number> . <number> . <time> <number> onion = tor : <number> ` ` ` * * system information * * bitcoin core <number> amd64 docker hub ` btcpayserver / bitcoin : <number> ` .",0
bitcoin/bitcoin,"intermittent failure in validation_chainstatemanager unit test <url> ` test_bitcoin : . / chain . h : <number> : uint256 cblockindex : : getblockhash ( ) const phashblock = nullptr failed . ` observed in # <number> , but i do not see how this crash ( which looks related to assumeutxo loading of a chainstate ) could be related to the changes from that pr . fyi <user>",0
bitcoin/bitcoin,"cjdns does not resolve inbound / outbound to same addr , resulting in duplicated connections for two peers connecting to each other over cjdns via ` addnode ` , it results in <number> connections . we would expect them to determine they are connecting to each other and not duplicate the connection . ` getpeerinfo ` gives the following : inbound connection - ` "" addr "" : "" [ x <elongated> : x <elongated> : x <elongated> : x <elongated> : x <elongated> : x <elongated> : x <elongated> <sad> port > <sad> <random_port> "" , ` , outbound connection - ` "" addr "" not sure if it would be possible to determine that the inbound connection is the same as our outbound , and do not make an outbound if requested with that same cjdns address .",0
bitcoin/bitcoin,"bitcoin - cli - netinfo ignores inbound peer from local network i have bitcoind serving cfilters to an lnd node on my local network on separate machines . both have ` <number> . <number> . x ` ip addresses and they connect fine using neutrino . however , the lnd node does not appear in the ` bitcoin - cli - netinfo ` table . the reason is because if you look at the ` getpeerinfo ` response : ` ` ` { "" id "" : <number> , "" addr "" : "" <number> . <number> : <number> "" , "" addrbind "" : "" <number> . <number> : <number> "" , "" addrlocal "" : "" <number> . <number> : <number> "" , "" network "" : "" not_publicly_routable "" , "" services "" : "" <number> "" , "" servicesnames "" : [ "" witness "" , "" compact_filters "" ] , . <repeated> ` ` ` . <repeated> so bitcoin - cli ignores the peer here : <url> . <repeated> expecting one of these strings only : <url> i am happy to fix / add this myself unless there ' s a reason ? maybe instead of skipping the peer we can just add an "" unknown network "" category , or "" other "" ? . <repeated> cc",0
bitcoin/bitcoin,"multiple connections to same i2p address < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > this behavior is okay for ipv4 based on <url> however , making multiple connections to same i2p peer makes no sense imo * * expected behavior * * no connections ( outbound / inbound ) should be initiated with i2p address that already exists as one of the peer . * * actual behavior * * ! [ image ] ( <url> ! [ screenshot <number> - <number> - <number> <number> ] ( <url> * * to reproduce * * - setup <number> nodes such that node2 and node3 works with i2p - connect node2 manually with ` addnode ` in config to node1 - connect node3 manually with node2 using i2p address - observe result for ` getpeerinfo ` in a few minutes or check peers list in bitcoin - qt * * system information * * bitcoin core master branch , v24 . 0 rc2 and v24 . 0 rc4",0
bitcoin/bitcoin,"[ systemd ] use of discouraged network target here are the current network hooks used in bitcoin core systemd integration template : <url> semantically , it makes sense , so i never questioned those lines when deploying new nodes , but here are some quotes from the official systemd website > $ network / network - online . target is a mechanism that is required only to deal with software that assumes continuous network is available ( i . e . of the simple not - well - written kind ) > services using the network should hence simply place an after = network . target stanza in their unit files , without wants = network . target or requires = network . target > after = network . target can be sure that it is stopped before the network is shut down when the system is going down . this allows services to cleanly terminate connections before going down , instead of losing ongoing connections leaving the other side in an undefined state . > if you are a developer , instead of wondering what to do about network . target , please just fix your program to be friendly to dynamically changing network configuration . > watch rtnetlink and react to network configuration changes as they happen . this is usually the nicest solution , but not always the easiest . it looks like the use of ` network - online . target ` is discouraged and ` network . target ` is a preferred option for any program which knows how to adapt to changing network conditions . are there any good reasons not to follow the official recommendation ?",0
bitcoin/bitcoin,"[ <number> . 0 rc4 ] ` - - torcontrol ` without ` - - onion ` connects to wrong tor proxy * * actual behavior * * i am using ` - - torcontrol ` without ` - - onion ` , which should be possible in <number> . i get these errors in the log , repeated every couple of secs : ` connect ( ) to <number> . <number> : <number> failed after wait : connection refused ( <number> ) ` if i use ` - - onion = tor : <number> ` , it works . ` tor ` is the hostname of my tor proxy . * * expected behavior * * bitcoind to fetch the correct tor proxy address / port from the control port and use it . * * system information * * bitcoind <number> . 0 rc4 ( self - built docker image ) , tor <number> . <number> ( docker image from docker . io ) , docker <date> ( from ubuntu <number> . <number> ) < - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > my startup log until the error occurs ( tor hidden service addresses redacted ) : ` ` ` bitcoind_1 | bitcoin core version v24 . 0 rc4 ( release build ) bitcoind_1 | using the ' x86_shani ( 1 way , 2 way ) ' sha256 implementation bitcoind_1 | using rdseed as an additional entropy source bitcoind_1 | using rdrand as an additional entropy source bitcoind_1 | startup time : <number> - <number> - 1 0 t <time> z bitcoind_1 | default data directory / home / bitcoin / . bitcoin bitcoind_1 | using data directory / home / bitcoin / . bitcoin bitcoind_1 | config file : / home / bitcoin / . bitcoin / bitcoin . conf ( not found , skipping ) bitcoind_1 | command - line arg : bind =""[ : : <sad> <number> "" bitcoind_1 | command - line arg : bind = "" <number> . <number> : <number> "" bitcoind_1 | command - line arg : bind =""[ : : <sad> <number> = onion "" bitcoind_1 | command - line arg : bind = "" <number> . <number> : <number> = onion "" bitcoind_1 | command - line arg : connect = "" redacted : <number> "" bitcoind_1 | command - line arg : debug = "" rpc "" bitcoind_1 | command - line arg : debug = "" tor "" bitcoind_1 | command - line arg : disablewallet = "" <number> "" bitcoind_1 | command - line arg : discover = "" <number> "" bitcoind_1 | command - line arg : dnsseed = "" <number> "" bitcoind_1 | command - line arg : listen = "" <number> "" bitcoind_1 | command - line arg : listenonion = "" <number> "" bitcoind_1 | command - line arg : logtimestamps = "" <number> "" bitcoind_1 | command - line arg : maxconnections = "" <number> "" bitcoind_1 | command - line arg : mempoolexpiry = "" <number> "" bitcoind_1 | command - line arg : onlynet = "" onion "" bitcoind_1 | command - line arg : par = "" <number> "" bitcoind_1 | command - line arg : prune = "" <number> "" bitcoind_1 | command - line arg : rpcallowip = "" <number> . <number> "" bitcoind_1 | command - line arg : rpcallowip =""[ : : ] "" bitcoind_1 | command - line arg : rpcbind = * * * * bitcoind_1 | command - line arg : rpcthreads = "" <number> "" bitcoind_1 | command - line arg : server = "" <number> "" bitcoind_1 | command - line arg : torcontrol = "" tor : <number> "" bitcoind_1 | command - line arg : torpassword = * * * * bitcoind_1 | using at most <number> automatic connections ( <number> file descriptors available ) bitcoind_1 | using <number> mib out of <number> mib requested for signature cache , able to store <number> elements bitcoind_1 | using <number> mib out of <number> mib requested for script execution cache , able to store <number> elements bitcoind_1 | script verification uses <number> additional threads bitcoind_1 | no wallet support compiled in ! bitcoind_1 | scheduler thread start bitcoind_1 | warning : the rpc server is not safe to expose to untrusted networks such as the public internet bitcoind_1 | [ http ] creating work queue of depth <number> bitcoind_1 | [ rpc ] starting rpc bitcoind_1 | [ rpc ] starting http rpc server bitcoind_1 | using random cookie authentication . bitcoind_1 | generated rpc authentication cookie / home / bitcoin / . bitcoin / . cookie bitcoind_1 | [ http ] starting <number> worker threads bitcoind_1 | using / <number> prefix for ip bucketing bitcoind_1 | init message : loading p2p addresses … bitcoind_1 | loaded <number> addresses from peers . dat 2 7 ms bitcoind_1 | init message : loading banlist … bitcoind_1 | setnetworkactive : true bitcoind_1 | cache configuration : bitcoind_1 | * using <number> mib for block index database bitcoind_1 | * using <number> mib for chain state database bitcoind_1 | * using <number> mib for in - memory utxo set ( plus up to <number> mib of unused mempool space ) bitcoind_1 | init message : loading block index … bitcoind_1 | assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 c97098b5295f7e5f183ac811fb5d1534040adb93cabd have valid signatures . bitcoind_1 | setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 0 4 ba <phone> f903495e bitcoind_1 | prune configured to target <number> mib on disk for block and undo files . bitcoind_1 | switching active chainstate to chainstate [ ibd ] @ height - <number> ( null ) bitcoind_1 | opening leveldb in / home / bitcoin / . bitcoin / blocks / index bitcoind_1 | opened leveldb successfully bitcoind_1 | using obfuscation key for / home / bitcoin / . bitcoin / blocks / index : <number> bitcoind_1 | loadblockindexdb : last block file = <number> bitcoind_1 | loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) bitcoind_1 | checking all blk files are present . <repeated> bitcoind_1 | loadblockindexdb ( <sad> block files have previously been pruned bitcoind_1 | opening leveldb in / home / bitcoin / . bitcoin / chainstate bitcoind_1 | opened leveldb successfully bitcoind_1 | using obfuscation key for / home / bitcoin / . bitcoin / chainstate : cec422b42319b403 bitcoind_1 | loaded best chain : hashbestchain = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 8 0 5 3 6 9 0 3 d286f9010f25b6582c80a892c3e95bf80d06 height = <number> date = <number> - <number> - 0 9 t <time> z progress = <number> bitcoind_1 | init message : verifying blocks … bitcoind_1 | verifying last <number> blocks at level <number> bitcoind_1 | [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ done ] . bitcoind_1 | no coin database inconsistencies in last <number> blocks ( <number> transactions ) bitcoind_1 | block index 3 2 4 3 ms bitcoind_1 | init message : pruning blockstore … bitcoind_1 | leaving initialblockdownload ( latching to false ) bitcoind_1 | block tree size = <number> bitcoind_1 | nbestheight = <number> bitcoind_1 | warning : more than one onion bind address is provided . using <happy> : <sad> <number> for the automatically created tor onion service . bitcoind_1 | warning : more than one onion bind address is provided . using <happy> : <sad> <number> for the automatically created tor onion service . bitcoind_1 | bound to <happy> : <sad> <number> bitcoind_1 | bound to <number> . <number> : <number> bitcoind_1 | bound to <happy> : <sad> <number> bitcoind_1 | bound to <number> . <number> : <number> bitcoind_1 | init message : starting network threads … bitcoind_1 | loadblk thread start bitcoind_1 | dns seeding disabled bitcoind_1 | torcontrol thread start bitcoind_1 | imported mempool transactions from disk : <number> succeeded , <number> failed , <number> expired , <number> already there , <number> waiting for initial broadcast bitcoind_1 | loadblk thread exit bitcoind_1 | init message : done loading bitcoind_1 | msghand thread start bitcoind_1 | addcon thread start bitcoind_1 | opencon thread start bitcoind_1 | cannot create socket for redacted . onion : <number> : unsupported network bitcoind_1 | net thread start bitcoind_1 | [ tor ] reading cached private key from / home / bitcoin / . bitcoin / onion_v3_private_key bitcoind_1 | [ tor ] successfully connected ! bitcoind_1 | [ tor ] connected to tor version <number> . <number> bitcoind_1 | [ tor ] supported authentication method : hashedpassword bitcoind_1 | [ tor ] using hashedpassword authentication bitcoind_1 | [ tor ] authentication successful bitcoind_1 | [ tor ] get socks port command yielded <happy> : <sad> <number> bitcoind_1 | [ tor ] configuring onion proxy for <number> . <number> : <number> bitcoind_1 | [ tor ] add_onion successful bitcoind_1 | [ tor ] got service id redacted , advertising service redacted . onion : <number> bitcoind_1 | [ tor ] cached service private key to / home / bitcoin / . bitcoin / onion_v3_private_key bitcoind_1 | addlocal ( redacted . onion : <number> ) bitcoind_1 | connect ( ) to <number> . <number> : <number> failed after wait : connection refused ( <number> ) bitcoind_1 | connect ( ) to <number> . <number> : <number> failed after wait refused ( <number> ) ` ` `",0
bitcoin/bitcoin,"[ wallet ] when unloading a wallet which still rescans the wallet , the command should fail but bitcoind gets in a buggy state < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > i am loading descriptors into bitcoind using the rpcclient with the function it automatically starts rescanning the blockchain . now when i try to unload the wallet , bitcoin - cli will allow me to do it ( wallet disappears from the ` listwallet ` section , but it will not abort the rescan . thats a problem bc now when trying to reload the wallet , the wallet sqlite db is locked by bitcoind and this wallet is unusable unitl the rescan is over . ` abortrescan ` will not work bc the wallet is not loaded anymore according to ` bitcoin - cli listwallets ` . the only solution for me was to delete the wallet dir and create a new wallet with the same name . now everything works as expected , but as soon as i want to unload the wallet again , bitcoind crashes < ! - - - what behavior did you expect ? - - > the ` unloadwallet ` function should internally abort the rescan and unload the wallet , so that it can be reloaded afterwards without waiting for the rescan . or it should fail and leading the user to abort the rescan with ` abortrescan ` < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * create a descriptor wallet * import a descriptor and unload the wallet <elongated> while bitcoind is still rescanning * now you are stuck bc abortrescan will not work bc wallet is not loaded and the only solution is to delete the wallet dir * now create a new wallet with the same name and import the descriptors again . when the wallet is faster synced then the old process still syncing , and you unload the wallet , bitcoind crashes < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > ` linux <date> - v8 + # <number> smp preempt tue <date> <time> gmt <number> aarch64 gnu / linux ` < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > bitcoind v . <number> ( release binary for raspberry pi ) < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,"` prevector ` is basically doing ub if on c + + <number> things like this are technically ub in c + + <number> : <url> - you cannot start the lifetime of an array like this . you need to do some compiler magic ( such as perhaps call ` std : : launder ` ? or actually some weird placement - new that does nothing ? ) here to properly start the lifetime of the ` t ` array object , as far as the c + + abstract machine is concerned . see : <url> - c + + <number> does now <emphasis> allows this - - implicit lifetimes can be started when you use some backing store in this way for trivial types only , but in c + + <number> this is technically ub . - the fact that this works is a happy accident because most major compiler support such ( mis ) - use of the language for trivial types owing to its c roots . so much so that they actually changed the standard for c + + <number> to support this , but for ' <number> this is ub ( but works in practice on all major compilers ) . - the following is not fixed in c + + <number> though is not guaranteed to be aligned to whatever t requires here . ( this is not fixed by c + + <number> - - unaligned access is ub , even if it happens to work on your platform ) . so ` prevector ` only really works without ub for ` uint8_t ` and similar types , if on c + + <number> .",0
bitcoin/bitcoin,"failure in rpc_getblockfrompeer . py <url> <url> ` ` ` bash hash = 5 0 0 5 fd299f78e023c07fa4cce23642e5a689c535f8adbc379825b7604b928b64 ) ] ) test <number> - <number> - 2 8 t <time> . 7 7 6 0 0 0 z testframework . p2p ( debug ) : received message from <number> . <number> . <time> <number> : msg_sendheaders ( ) test <number> - <number> - 2 8 t <time> . 7 7 6 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in try_rpc fun ( * args , * * kwds ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / coverage . py "" , line <number> , in __call__ return_val = self . auth_service_proxy_instance . __call__ ( * args , * * kwargs ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / authproxy . py "" , line <number> , in __call__ raise jsonrpcexception ( response [ ' error ' ] , status ) test_framework . authproxy . jsonrpcexception : block header missing ( - <number> ) during handling of the above exception , another exception occurred : traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / rpc_getblockfrompeer . py "" , line <number> , in run_test assert_raises_rpc_error ( - <number> , error_msg , self . nodes [ <number> ] . getblockfrompeer , blockhash , node1_interface_id ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in assert_raises_rpc_error assert try_rpc ( code , message , fun , * args , * * kwds ) , "" no exception raised "" file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in try_rpc message , e . error [ ' message ' ] ) ) assertionerror : expected substring not found in error message : substring : ' in prune mode , only blocks that the node has already synced previously can be fetched from a peer ' error message header missing ' . ` ` `",0
bitcoin/bitcoin,"v22 . <number> wallet freezes on mac os ventura on arm64 i upgraded to the newest mac os ventura . the bitcoin core application was deleted automatically from my computer . i downloaded bitcoin core again fro my mac . and when i tried to open bitcoin core it has been stuck on verifying wallet ( s ) for over an hour . < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * < ! - - - what behavior did you expect ? - - > * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,""" system_tests / run_command "" unit test fails on msvc i am building v24 . 0 rc2 on windows <number> using visual studio <number> . the build succeeds without errors and the binary works fine , but there is one failing unit test : ` ` ` c :\\ bitcoin \ \ src > test_bitcoin . exe running <number> test cases . <repeated> c <annoyed> bitcoin / src / test / system_tests . cpp ( <number> <sad> error : in "" system_tests / run_command "" what . find ( expected ) = std : : string : : npos has failed * * * <number> failure is detected in the test module "" bitcoin core test suite "" ` ` ` also tried with v23 . <number> and latest master , same error ( for v23 . <number> the line number is different ) .",0
bitcoin/bitcoin,"bitcoin - qt crashes if it can not listen on the port it wants to i created new folders ~ / . bitcoin2 and ~ / . bitcoin3 , then ran bitcoin - qt using both of them as data directories . the first one ran fine : qt / bitcoin - qt - datadir <annoyed> home / chris / . bitcoin2 i left the first one running . the second one crashed in various ways : $ qt / bitcoin - qt - datadir <annoyed> home / chris / . bitcoin3 error : unable to bind to <number> . <number> : <number> on this computer . bitcoin core is probably already running . error : failed to listen on any port . use - listen = <number> if you want this . segmentation fault $ qt / bitcoin - qt - datadir <annoyed> home / chris / . bitcoin3 error : unable to bind to <number> . <number> : <number> on this computer . bitcoin core is probably already running . error : failed to listen on any port . use - listen = <number> if you want this . free ( <sad> double free detected in tcache <number> aborted $ qt / bitcoin - qt - datadir <annoyed> home / chris / . bitcoin3 error : unable to bind to <number> . <number> : <number> on this computer . bitcoin core is probably already running . error to listen on any port . use - listen = <number> if you want this . corrupted size vs . prev_size in fastbins aborted i would expect it to complain about the unavailable port , but not to crash in such random ways . this is bitcoin built against git tag ` v24 . 0 rc2 ` .",0
bitcoin/bitcoin,"doc : internal bug detected running listtransactions on op_return output i saw an internal bug detected message running ` listtransactions ` : $ bitcoin - cli listtransactions ' * ' <number> error code : - <number> error message : internal bug detected : "" std : : any_of ( m_results . m_results . begin ( ) , m_results . m_results . end ( ) , [ & ret ] ( const rpcresult & res ) { return res . matchestype ( ret ) ; } ) "" rpc / util . cpp : <number> ( handlerequest ) please report this issue here : <url> i narrowed it down to a particular transaction in my history : $ for i in { <number> . <repeated> <number> }; do echo "" - - - $ i - - - "" ; bitcoin - cli listtransactions ' * ' <number> $ i ; done - - - <number> - - - [ { "" address "" : "" bc1qnle0kjvz4wyju49m00krxztdqu5ygak00nft37 "" , "" category "" : "" send "" , "" amount "" : - <number> , "" label "" : "" "" , "" vout "" : <number> , "" fee "" : - <number> , "" confirmations "" : <number> , "" blockhash "" : "" 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 5 a92c80f5c259ca5d9d36d407906dbefbd8075c3ae77b "" , "" blockheight "" : <number> , "" blockindex "" : <number> , "" blocktime "" : <phone> , "" txid "" : "" b6439e1c9eb3915b3cc89871d2c2479f3f1847f0c7bab252c3ebc503b8f6d344 "" , "" wtxid "" : "" 3 9 3 cfba86cb0d3274850aa461dab433b5d62c1dce68dc10d43de969b8dec2359 "" , "" walletconflicts "" : [ ] , "" time "" : <phone> , "" timereceived "" : <phone> , "" bip125 - replaceable "" : "" no "" , "" abandoned "" : false } ] - - - <number> - - - error code : - <number> error message : internal bug detected : "" std : : any_of ( m_results . m_results . begin ( ) , m_results . m_results . end ( ) , [ & ret ] ( const rpcresult & res ) { return res . matchestype ( ret ) ; } ) "" rpc / util . cpp : <number> ( handlerequest ) please report this issue here : <url> - - - <number> - - - [ { "" address "" : "" bc1qnle0kjvz4wyju49m00krxztdqu5ygak00nft37 "" , "" parent_descs "" : [ ] , "" category "" : "" receive "" , "" amount "" : <number> , "" label "" : "" "" , "" vout "" : <number> , "" confirmations "" : <number> , "" blockhash "" : "" 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 5 a92c80f5c259ca5d9d36d407906dbefbd8075c3ae77b "" , "" blockheight "" : <number> , "" blockindex "" : <number> , "" blocktime "" : <phone> , "" txid "" : "" b6439e1c9eb3915b3cc89871d2c2479f3f1847f0c7bab252c3ebc503b8f6d344 "" , "" wtxid "" : "" 3 9 3 cfba86cb0d3274850aa461dab433b5d62c1dce68dc10d43de969b8dec2359 "" , "" walletconflicts "" : [ ] , "" time "" : <phone> , "" timereceived "" : <phone> , "" bip125 - replaceable "" } ] note how the txid on the two transactions surrounding the bad one are the same . [ the block explorer ] ( <url> shows that this transaction has an op_return output , which is probably what is triggering this internal bug detection . * * system information * * i built bitcoin core from the git tag ` v24 . 0 rc1 ` . it ' s running on a debian linux system , intel ( r ) core ( tm ) i7 - 8 7 5 0 h cpu @ <number> . 2 0 ghz , ssd .",0
bitcoin/bitcoin,"bitcoin failed to build with error msb3073 on msvc < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * build successfully . < ! - - - what behavior did you expect ? - - > * * actual behavior * * hi all , bitcoin fails to build on msvc due to error msb3073 , the same problem also appeared in vs2019 , i mentioned a same issue but it was closed . could you help look ? < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * error message * * <number> > f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc \ \ libbitcoin_qt \ \ libbitcoin_qt . vcxproj ( <number> <sad> error msb3073 : the command "" c :\\ qt_static \ \ bin \ \ moc . exe "" . <repeated> \ \ . <repeated> \ \ src \ \ qt \ \ bitcoinamountfield . cpp "" - o . \ \ qtgeneratedfiles \ \ qt \ \ bitcoinamountfield . moc "" exited with code <number> . <number> > done building project "" f :\\ gitp \ \ bitcoin \ \ bitcoin \ \ build_msvc \ \ libbitcoin_qt \ \ libbitcoin_qt . vcxproj "" ( rebuild target ( s ) ) - - failed . * * detail log * * [ build ( <number> ) . log ] ( <url> * * to reproduce * * <number> . set vscmd_skip_sendtelemetry = <number> & "" c :\\ program files (x 8 6 ) \ \ microsoft visual studio \ \ <number> \ \ enterprise \ \ common7 \ \ tools \ \ vsdevcmd . bat "" - host_arch = amd64 - arch = amd64 <number> . git clone <url> f :\\ bitcoin \ \ bitcoin <number> . cd f :\\ bitcoin \ \ bitcoin \ \ build_msvc <number> . py - <number> msvc - autogen . py <number> . cd f :\\ bitcoin <number> . mkdir tools \ \ vcpkg <number> . git clone <url> f :\\ bitcoin \ \ tools \ \ vcpkg <number> . cd f :\\ bitcoin \ \ tools \ \ vcpkg <number> . bootstrap - vcpkg . bat <number> > & <number> <number> . set path = % cd % ; % path % <number> . vcpkg integrate install <number> > & <number> <number> . cd f :\\ bitcoin \ \ bitcoin \ \ build_msvc <number> . msbuild / m / p : platform =x 6 4 / p : configuration = release bitcoin . sln / t : rebuild <number> > & <number> < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * vs version : vs2022 ( <number> . <number> ) operating system server <number> the commit of bitcoin we use is 5 1 7 4 a13 < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,intermittent failure in ` feature_fee_estimation . py ` <url>,0
bitcoin/bitcoin,"testnet difficulty was reset at height <number> < - - describe the issue - - > it appears that the testnet difficulty was reset from ` <number> , <number> ` at block height [ <number> ] ( <url> down to ` <number> ` in the next block at height [ <number> ] ( <url> i am seeing this on my own testnet nodes ( ` v23 . <number> ` ) as well as on several blockchain explorers ( e . g . [ blockchain . com ] ( <url> and [ blockchair ] ( <url> at the time of writing this post , the network has produced about 1 6 k blocks in <number> hours , while the difficulty is crawling back up slowly ( it ' s at ` <number> . <number> ` at the time of writing ) . was this a scheduled testnet reset of some kind or maybe a bug ?",0
bitcoin/bitcoin,"test : ` minisketch_tests . cpp ` can fail when built with msvc to trigger the [ failure ] ( <url> consider the [ diff ] ( <url> as follows : ` ` ` diff - - - a / src / test / minisketch_tests . cpp + + + b / src / test / minisketch_tests . cpp @ @ - <number> + <number> @ @ boost_auto_test_case ( minisketch_test ) uint32_t start_b = start_a + a_not_b ; uint32_t end_b = start_b + both + b_not_a ; + <hashtag> if def </hashtag> _msc_ver + / / fixme + boost_test_message ( "" this message breaks <emphasis> this test when running with ' - l test_suite ' "" ); + <hashtag> end if </hashtag> + minisketch sketch_a = makeminisketch32 ( <number> ); for ( uint32_t a = start_a ; a < end_a ; + + a ) sketch_a . add ( a ) ; minisketch sketch_b = makeminisketch32 ( <number> ); ` ` ` the observing behavior : ` ` ` > build_msvc \ \x 6 4 \ \ release \ \ test_bitcoin . exe - t minisketch_tests running <number> test case . <repeated> unknown location ( <number> <sad> fatal error : in "" minisketch_tests / minisketch_test "" : memory access violation occurred at address 0 xffffffff , while attempting to read inaccessible data c :\\ users \ \ hebasto \ \ bitcoin \ \ src \ \ test \ \ minisketch_tests . cpp ( <number> <sad> last checkpoint test entry * * * <number> failure is detected in the test module "" bitcoin core test suite "" ` ` ` assuming either msvc bug or non - portable code ?",0
bitcoin/bitcoin,"retry add onion after tor ' s controller closed connection < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > i am running bitcoind on qubes - whonix . whonix - gateway is where tor resides , and every tor controller ' s command made by whonix - workstation to whonix - gateway is filtered by a proxy called onion - grater ( upstream development is made by tails os ) from this point on i will be referring to tor ' s controller simply by "" control "" or "" controller "" . if the control connection is closed by restarting onion - grater to apply new rules ( even not regarding the bitcoind . yml ) file , bitcoind will remove the current onion and will not be able to set it as address again . ` ` ` removelocal ( myonion . onion : <number> ) tor : no supported authentication method ` ` ` and ` bitcoin - cli - netinfo ` ` ` ` local addresses : n / a ` ` ` and of course none of my nodes listening to this address will continue working . add_onion command works the first time but not the second . the problem occurs because bitcoind does not give time for the controller to restart the second time , so the authentication is not "" available yet "" . in fact , tor is not being reloaded or restarted , only the proxy , which is what bitcoind sees as the controller . this happens because i am using bitcoind tor controller feature to send add_onion . if i set the onion service manually on the gateway , i would not have this problem , but then the problem would be : - it would not be pragmatically deleted , although i am rewriting it with ` flag = discardpk ` anyway - it would stay as a file on the gateway and the onion address would need to be manually inserted into the bitcoin . conf * * expected behavior * * < ! - - - what behavior did you expect ? - - > i expect that after bitcoind can not authenticate to the controller , it tries again after some time . this way , i can restart my controller without needing to restart bitcoind for it to get a onion listening address again . * * actual behavior * * < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > bitcoind removes current listening onion hostname and not retry to authenticate to the controller . * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > this is difficult to reproduce on normal systems . first , qubes may not interfere , so you could try to reproduce on whonix kvm or virtualbox or tails os ( probably ) . if you can not test on that setup , i would try to simple close the controller connection on a normal system and then see what bitcoind does to the listening onion address . also you need to add the bitcoind onion - grater profile , i do not know if tails has , but for whonix , i am using <url> it is not the current whonix onion - grater profile but it is the correct one and will be merged upstream soon . if that is the case , add that profile to ` / usr / local / etc / onion - grater - merger . d / 4 0 _bitcoind . yml ` also set in the ` bitcoin . conf ` the onion binding to ` bind = <number> . <number> : <number> = onion ` and not ` <number> . <number> ` . this makes the service listen on the whonix internal interface and does not affect security . restart bitcoind to apply changes . you will also have to open the port on the whonix - workstation firewall . ` ` ` $ sudo mkdir - p / usr / local / etc / whonix_firewall . d $ echo "" external_open_ports + = "" <number> "" | tee - a / usr / local / etc / whonix_firewall . d / 5 0 _user . conf ` $ sudo whonix_firewall ` ` ` to view onion - grater logs , you need to enable debug mode on the whonix - gateway : ` ` ` $ echo "" [ service ] # # clear onion - grater default file ' / lib / systemd / system / onion - grater . service ' . execstart = # # enable debug mode . execstart <annoyed> usr / lib / onion - grater - - listen - interface eth1 - - debug "" | tee / usr / lib / systemd / system / onion - grater . service . d / 5 0 _user . conf $ sudo systemctl daemon - reload $ sudo systemctl restart onion - grater ` ` ` then after adding the profile , enabling onion - grater debug mode , restarting onion - grater and bitcoind , test if the address is reachable externally . use the bitcoid option ` connect = address . onion ` , so you are sure it is connecting . if it is , restart onion - grater . ` ` ` $ sudo systemctl restart onion - grater ` ` ` on the bitcoin debug . logs , you should see the same error i saw above about removing onion address and not able to authenticate to the controller . but that is not entirely correct , because i can issue an add_onion manually and it will accept , but bitcoind does not try to issue add_onion a second time . ` ` ` host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : - > protocolinfo <number> host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - <number> - protocolinfo <number> host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - <number> - auth methods = null host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - <number> - version tor = "" <number> . <number> "" host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - <number> ok host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : - > authenticate host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - <number> ok ` ` ` the controller actually lets bitcoind authenticate , as seen from the onion - grater logs above . but i do not understand why bitcoind says it can not authenticate . the ip does not matter , it is internal ip . what you should expect from onion - grater logs is the following : ` ` ` host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : - > authenticate host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - <number> ok host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : - > add_onion new : ed25519 - v3 port = <number> . <number> . <number> : <number> host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : rewrote command : host onion - grater [ <number> <sad> add_onion new : ed25519 - v3 port = <number> . <number> . <number> : <number> host onion - grater [ <number> <sad> to : host onion - grater [ <number> <sad> add_onion new : ed25519 - v3 port = <number> . <number> . <number> : <number> flags = discardpk host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - ( multi - line ) host onion - grater [ <number> <sad> <number> - serviceid = myonionhostnamewithoutonion host onion - grater [ <number> <sad> <number> ok host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : - > quit host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) : < - <number> closing connection host onion - grater [ <number> <sad> <number> . <number> <time> <number> ( filter : 3 0 _autogenerated ) disconnected : client quit ` ` ` you could try on whonix with ` tor - ctrl ` to authenticate after restarting onion - grater and it will work $ tor - ctrl add_onion new : ed25519 - v3 port = <number> . <number> . <number> : <number> ` ` ` and it will authenticate . but for some unknown reason bitcoind does not reauthenticate to the controller . i understand that once the contoller connection closes , the commands send to the controller are not valid anymore . but bitcoind should be able to reauthenticate once it loses connection . * * system information * * < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > system information was already described above . i understand this may be difficult debug because it requires a system with onion - grater . but it does not rely on whonix or tails or onion - grater package to fix this , as they are only restarting to read the new configuration , but bitcoind understand that as a connection that must be closed forever . if you read all this and is open to make bitcoind retry to authenticate cleanly , i am open to help debug and instruct how to reproduce .",0
bitcoin/bitcoin,"opening macos dmg does not open finder window when i open ` bitcoin - <number> . 0 rc1 - arm64 - apple - darwin . dmg ` the volume is mounted silently , but does not open finder window leading to very confusing user experience . os : macos <number> ( 2 1 g115 ) on macbook air ( m1 , <number> ) this is a regression from ` bitcoin - <number> - arm64 - apple - darwin . dmg ` which opens the following finder window : < img width = "" <number> "" alt = "" screenshot <number> - <number> - <number> at <number> <number> <number> "" src = "" <url> ps downloaded the file from <url>",0
bitcoin/bitcoin,fuzz : miniscript_string : assert = = script_size probably after commit 5 5 e1deb745531a0749f668ed7265770c70a58563 <url>,0
bitcoin/bitcoin,"test : failure in interface_rest . py <url> ` ` ` traceback ( most recent call last ) : file "" c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ cirrus - ci - build \ \ test \ \ functional \ \ test_framework \ \ test_framework . py "" , line <number> , in main self . run_test ( ) file "" c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ cirrus - ci - build \ \ test \ \ functional \ \ interface_rest . py "" , line <number> , in run_test json_obj = self . test_rest_request ( f "" / blockfilterheaders / basic / { bb_hash } "" , query_params ={ "" count "" : <number> } ) file "" c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ cirrus - ci - build \ \ test \ \ functional \ \ interface_rest . py "" , line <number> , in test_rest_request assert_equal ( resp . status , status ) file "" c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ cirrus - ci - build \ \ test \ \ functional \ \ test_framework \ \ util . py "" , line <number> , in assert_equal raise assertionerror ( "" not ( %s ) "" % "" = = "" . join ( str ( arg ) for arg in ( thing1 , thing2 ) + args ) ) assertionerror = = <number> ) ` ` `",0
bitcoin/bitcoin,"segmentation fault in the scheduler thread when an index fails to commit to the db see <url> : * first , it fails to commit ( for some unknown reason ) : ` error : commit : failed to commit latest coinstatsindex state ` * then , it considers itself synced : ` coinstatsindex is enabled at height <number> ` , ` coinstatsindex thread exit ` * then , the scheduler thread segfaults . ` ` ` . <repeated> <number> - <number> - 1 2 t <time> . 8 0 0 1 4 7 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - sanity checks : <number> . 0 0 ms [ <number> . 0 0 s ( <number> . 0 1 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 2 2 7 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - fork checks : <number> . 0 8 ms [ <number> . 2 3 s ( <number> . 5 7 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 3 1 1 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - connect <number> transactions : <number> . 0 8 ms ( <number> . 0 7 6 ms / tx , <number> . 0 0 0 ms / txin ) [ <number> . 0 4 s ( <number> . 1 0 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 3 9 9 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - verify <number> txins : <number> . 1 7 ms ( <number> . 0 0 0 ms / txin ) [ <number> . 0 9 s ( <number> . 2 3 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 5 2 8 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - write undo data : <number> . 1 3 ms [ <number> . 0 3 s ( <number> . 0 7 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 5 9 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - index writing : <number> . 0 7 ms [ <number> . 0 2 s ( <number> . 0 4 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 6 9 2 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validationinterface . cpp : <number> ] [ blockchecked ] [ validation ] blockchecked : block hash = 5 7 1 d80a9967ae599cec0448b0b0ba1cfb606f584d8069bd7166b86854ba7a191 state = valid <number> - <number> - 1 2 t <time> . 8 0 0 7 6 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connecttip ] [ bench ] - connect total : <number> . 7 1 ms [ <number> . 1 8 s ( <number> . 4 5 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 8 2 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connecttip ] [ bench ] - flush : <number> . 0 6 ms [ <number> . 0 5 s ( <number> . 1 2 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 0 9 2 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connecttip ] [ bench ] - writing chainstate : <number> . 0 9 ms [ <number> . 0 2 s ( <number> . 0 4 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 1 5 1 7 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ policy / fees . cpp : <number> ] [ processblock ] [ estimatefee ] blockpolicy estimates updated by <number> of <number> block txs , since last block <number> of <number> tracked , mempool map size <number> , max target <number> from current <number> - <number> - 1 2 t <time> . 8 0 1 6 4 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ updatetiplog ] updatetip : new best = 5 7 1 d80a9967ae599cec0448b0b0ba1cfb606f584d8069bd7166b86854ba7a191 height = <number> version =0 x20000000 log2_work = <number> tx = <number> date = ' <number> - <number> - 3 1 t <time> z ' progress = <number> cache = <number> . 0 mib ( 1 0 0 txo ) <number> - <number> - 1 2 t <time> . 8 0 1 7 0 1 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connecttip ] [ bench ] - connect postprocess : <number> . 7 8 ms [ <number> . 3 4 s ( <number> . 8 3 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 1 7 5 5 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connecttip ] [ bench ] - connect block : <number> . 7 2 ms [ <number> . 7 5 s ( <number> . 8 5 ms / blk ) ] <number> - <number> - 1 2 t <time> . 8 0 1 8 1 9 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ txmempool . cpp : <number> ] [ check ] [ mempool ] checking mempool with <number> transactions and <number> inputs <number> - <number> - 1 2 t <time> . 8 0 1 9 5 2 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validationinterface . cpp : <number> ] [ blockconnected ] [ validation ] enqueuing blockconnected : block hash = 5 7 1 d80a9967ae599cec0448b0b0ba1cfb606f584d8069bd7166b86854ba7a191 block height = <number> <number> - <number> - 1 2 t <time> . 8 0 2 0 6 9 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ scheduler ] [ validationinterface . cpp : <number> ] [ operator ( ) ] [ validation ] blockconnected : block hash = 5 7 1 d80a9967ae599cec0448b0b0ba1cfb606f584d8069bd7166b86854ba7a191 block height = <number> <number> - <number> - 1 2 t <time> . 8 0 2 1 8 3 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validationinterface . cpp : <number> ] [ updatedblocktip ] [ validation ] enqueuing updatedblocktip : new block hash = 5 7 1 d80a9967ae599cec0448b0b0ba1cfb606f584d8069bd7166b86854ba7a191 fork block hash = 6 8 aef0c7c1c2cc15ca20a558ea1d6e66aecc1d6398bddea75e4c031cb79cc07e ( in ibd = false ) <number> - <number> - 1 2 t <time> . 8 0 2 2 9 5 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ scheduler ] [ validationinterface . cpp : <number> ] [ operator ( ) ] [ validation ] updatedblocktip : new block hash = 5 7 1 d80a9967ae599cec0448b0b0ba1cfb606f584d8069bd7166b86854ba7a191 fork block hash = 6 8 aef0c7c1c2cc15ca20a558ea1d6e66aecc1d6398bddea75e4c031cb79cc07e ( in ibd = false ) <number> - <number> - 1 2 t <time> . 8 0 3 3 1 3 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ dbwrapper . cpp : <number> ] [ cdbwrapper ] opened leveldb successfully <number> - <number> - 1 2 t <time> . 8 0 3 4 5 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ dbwrapper . cpp : <number> ] [ cdbwrapper ] using obfuscation key for / tmp / test_common_bitcoin core / 7 b9ce9462bbe925416385de4a76d6cf557607ae446c058cb3eba456ddb39ce92 / regtest / indexes / coinstats / db : <number> <number> - <number> - 1 2 t <time> . 8 0 4 3 3 6 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ coinstatsindex ] [ util / thread . cpp : <number> ] [ tracethread ] coinstatsindex thread start <number> - <number> - 1 2 t <time> . 8 0 4 4 6 2 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ coinstatsindex ] [ index / base . cpp : <number> ] [ threadsync ] syncing coinstatsindex with block chain from height <number> <number> - <number> - 1 2 t <time> . 8 0 4 5 4 7 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ coinstatsindex ] [ util / system . h : <number> ] [ error ] error : commit : failed to commit latest coinstatsindex state <number> - <number> - 1 2 t <time> . 6 0 7 9 2 1 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ coinstatsindex ] [ index / base . cpp : <number> ] [ threadsync ] coinstatsindex is enabled at height <number> <number> - <number> - 1 2 t <time> . 6 0 8 0 0 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ coinstatsindex ] [ util / thread . cpp : <number> ] [ tracethread ] coinstatsindex thread exit <number> - <number> - 1 2 t <time> . 6 0 8 4 4 4 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ node / miner . cpp : <number> ] [ createnewblock ] createnewblock ( <sad> block weight : <number> txs : <number> fees : <number> sigops <number> <number> - <number> - 1 2 t <time> . 6 0 8 6 5 1 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - sanity checks : <number> . 0 1 ms [ <number> . 0 0 s ( <number> . 0 1 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 0 8 7 5 2 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - fork checks : <number> . 1 1 ms [ <number> . 2 3 s ( <number> . 5 7 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 0 8 8 6 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - connect <number> transactions : <number> . 0 9 ms ( <number> . 0 8 8 ms / tx , <number> . 0 0 0 ms / txin ) [ <number> . 0 4 s ( <number> . 1 0 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 0 8 9 7 4 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - verify <number> txins : <number> . 2 2 ms ( <number> . 0 0 0 ms / txin ) [ <number> . 1 0 s ( <number> . 2 3 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 0 9 0 5 1 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ node / miner . cpp : <number> ] [ createnewblock ] [ bench ] createnewblock ( ) packages : <number> . 0 5 ms ( <number> packages , <number> updated descendants ) , validity : <number> . 6 9 ms ( total <number> . 7 4 ms ) <number> - <number> - 1 2 t <time> . 6 0 9 7 6 7 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validationinterface . cpp : <number> ] [ newpowvalidblock ] [ validation ] newpowvalidblock : block hash =0 e146357c1f82a8b9e2c54cb53a619a0ffbcace90d33ad228dc0ef44752b6844 <number> - <number> - 1 2 t <time> . 6 1 0 5 2 4 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connecttip ] [ bench ] - using cached block <number> - <number> - 1 2 t <time> . 6 1 0 6 0 1 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connecttip ] [ bench ] - load block from disk : <number> . 0 7 ms [ <number> . 1 6 s ( <number> . 4 1 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 1 0 7 0 2 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - sanity checks : <number> . 0 0 ms [ <number> . 0 0 s ( <number> . 0 1 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 1 0 7 9 4 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - fork checks : <number> . 0 9 ms [ <number> . 2 3 s ( <number> . 5 7 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 1 0 9 2 0 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - connect <number> transactions : <number> . 1 0 ms ( <number> . 0 9 6 ms / tx , <number> . 0 0 0 ms / txin ) [ <number> . 0 4 s ( <number> . 1 0 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 1 1 0 1 2 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - verify <number> txins : <number> . 2 1 ms ( <number> . 0 0 0 ms / txin ) [ <number> . 1 0 s ( <number> . 2 3 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 1 1 1 5 1 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - write undo data : <number> . 1 4 ms [ <number> . 0 3 s ( <number> . 0 7 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 1 1 2 1 7 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ validation . cpp : <number> ] [ connectblock ] [ bench ] - index writing : <number> . 0 7 ms [ <number> . 0 2 s ( <number> . 0 4 ms / blk ) ] <number> - <number> - 1 2 t <time> . 6 1 1 2 9 6 z ( mocktime : <number> - <number> - 3 1 t <time> z ) [ test ] [ valithreadsanitizer : deadlysignal make [ <number> <sad> * * * [ makefile : <number> : test / coinstatsindex_tests . cpp . test ] error <number> make [ <number> <sad> * * * waiting for unfinished jobs . <repeated> pass : qt / test / test_bitcoin - qt = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = testsuite summary for bitcoin core <number> . <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = # total : <number> # pass : <number> # skip : <number> # xfail : <number> # fail : <number> # xpass : <number> # error : <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = make [ <number> <sad> leaving directory ' / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src ' make [ <number> <sad> leaving directory ' / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src ' make [ <number> <sad> * * * [ makefile : <number> : check - am ] error <number> make [ <number> <sad> leaving directory ' / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src ' make [ <number> <sad> * * * [ makefile : <number> : check - recursive ] error <number> make [ <number> <sad> leaving directory ' / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / src ' make : * * * [ makefile : <number> : check - recursive ] error <number> = = <number> = = error : threadsanitizer : segv on unknown address 0x0 0 0 0 0 0 0 0 0 0 6 8 ( pc 0x 5 5 e8c6500aeb bp 0x 7 b <phone> sp 0x 7 fdf23d0ec80 t25670 ) = = <number> = = the signal is caused by a read memory access . = = <number> = = hint : address points to the zero page . # <number> baseindex : : setbestblockindex ( cblockindex const <wink> : : $ _1 : : operator ( ) ( ) const src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xd78aeb ) # <number> baseindex : : setbestblockindex ( cblockindex const <wink> src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xd78aeb ) # <number> baseindex : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xd7ae5b ) # <number> cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const : : ' lambda ' ( cvalidationinterface & <sad> : operator ( ) ( cvalidationinterface & ) const src / validationinterface . cpp : <number> : <number> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> void mainsignalsimpl : : iterate < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const : : ' lambda ' ( cvalidationinterface & ) > ( cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const : : ' lambda ' ( cvalidationinterface & ) & & ) src / validationinterface . cpp : <number> <time> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const src / validationinterface . cpp : <number> <time> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 : : operator ( ) ( ) const src / validationinterface . cpp : <number> : <number> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> decltype ( static_cast < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & > ( fp ) ( ) ) std : : __1 : : __invoke < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & > ( cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & > ( cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> std : : __1 : : __function : : __alloc_func < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 , std : : __1 : : allocator < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> std : : __1 : : __function : : __func < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 , std : : __1 : : allocator < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 f0f54 ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 8 bc01 ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 8 bc01 ) # <number> singlethreadedschedulerclient : : processqueue ( ) src / scheduler . cpp : <number> : <number> ( test_bitcoin + 0x 1 1 8 bc01 ) # <number> singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 : : operator ( ) ( ) const src / scheduler . cpp : <number> <time> ( test_bitcoin + 0x 1 1 8 d915 ) # <number> decltype ( static_cast < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & > ( fp ) ( ) ) std : : __1 : : __invoke < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & > ( singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0x 1 1 8 d915 ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & > ( singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( test_bitcoin + 0x 1 1 8 d915 ) # <number> std : : __1 : : __function : : __alloc_func < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 , std : : __1 : : allocator < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 8 d915 ) # <number> std : : __1 : : __function : : __func < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 , std : : __1 : : allocator < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 8 d915 ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 8 abec ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 8 abec ) # <number> cscheduler : : servicequeue ( ) src / scheduler . cpp : <number> <time> ( test_bitcoin + 0x 1 1 8 abec ) # <number> chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 : : operator ( ) ( ) const src / test / util / setup_common . cpp : <number> <time> <number> ( test_bitcoin + 0 xab5148 ) # <number> decltype ( static_cast < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & > ( fp ) ( ) ) std : : __1 : : __invoke < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & > ( chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0 xab5148 ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & > ( chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( test_bitcoin + 0 xab5148 ) # <number> std : : __1 : : __function : : __alloc_func < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 , std : : __1 : : allocator < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0 xab5148 ) # <number> std : : __1 : : __function : : __func < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 , std : : __1 : : allocator < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0 xab5148 ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 2 4 b1af ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 2 4 b1af ) # <number> util : : tracethread ( char const * , std : : __1 : : function < void ()>) src / util / thread . cpp : <number> : <number> ( test_bitcoin + 0x 1 2 4 b1af ) # <number> decltype ( static_cast < void (*> ( fp ) ( static_cast < char const *>( fp0 ) , static_cast < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > ( fp0 ) ) ) std : : __1 : : __invoke < void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > ( void (* & & ) ( char const * , std : : __1 : : function < void ()>), char const * & & , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0 xab4d41 ) # <number> void std : : __1 : : __thread_execute < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 , 2 ul , 3 ul > ( std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > & , std : : __1 : : __tuple_indices < 2 ul , 3 ul > ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( test_bitcoin + 0 xab4d41 ) # <number> void * std : : __1 : : __thread_proxy < std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > > ( void <wink> / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( test_bitcoin + 0 xab4d41 ) # <number> __tsan_thread_start_func <null> ( test_bitcoin + 0x 1 3 3 1 9 c ) # <number> <null> <null> ( libc . so . <number> + 0x 9 4 b42 ) # <number> <null> <null> ( libc . so . <number> + 0x 1 2 6 9 ff ) threadsanitizer can not provide additional info . summary : threadsanitizer : segv src / index / base . cpp : <number> : <number> in baseindex : : setbestblockindex ( cblockindex const <wink> : : $ _1 : : operator ( ) ( ) const = = <number> = = aborting exit status",0
bitcoin/bitcoin,"intermittent failure in rpc_invalidateblock . py seen in doc - only pr : <url> ` ` ` file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / rpc_invalidateblock . py "" , line <number> , in run_test assert_equal ( chain_tips , self . nodes [ <number> ] . getchaintips ( ) ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in assert_equal raise assertionerror ( "" not ( %s ) "" % "" = = "" . join ( str ( arg ) for arg in ( thing1 , thing2 ) + args ) ) assertionerror : not ( [ { ' height ' : <number> , ' hash ' : ' 1 e8c7b54ab7c4556c4602fc89c0796d104260df2e2f8d2de9006d2446676d71c ' , ' branchlen ' : <number> , ' status ' : ' active ' } , { ' height ' : <number> , ' hash ' : ' 4 6 7 2 7 2 1 3 ae639f43edd7fde6d5c2dcd54cc182f7c3a5c7a652784a7ece5aa0cf ' , ' branchlen ' : <number> , ' status ' : ' invalid ' } , { ' height ' : <number> , ' hash ' : ' 0 fefbfc08f4e5e4ae4dd1a74113c580530bda9bfa85ed2c40e59ee8ff5bc352d ' , ' branchlen ' : <number> , ' status ' : ' headers - only ' } ] = = [ { ' height ' : <number> , ' hash ' : ' 1 e8c7b54ab7c4556c4602fc89c0796d104260df2e2f8d2de9006d2446676d71c ' , ' branchlen ' : <number> , ' status ' : ' active ' } , { ' height ' : <number> , ' hash ' : ' 4 6 7 2 7 2 1 3 ae639f43edd7fde6d5c2dcd54cc182f7c3a5c7a652784a7ece5aa0cf ' , ' branchlen ' : <number> , ' status ' : ' invalid ' } , { ' height ' : <number> , ' hash ' : ' 0 fefbfc08f4e5e4ae4dd1a74113c580530bda9bfa85ed2c40e59ee8ff5bc352d ' , ' branchlen ' : <number> , ' status ' : ' headers - only ' } , { ' height ' : <number> , ' hash ' : ' 4 ff28db3f1e2007c2a8f321dc6759ffdb7ff0c81ea9334d982049b9c8ae674a9 ' , ' branchlen ' : <number> , ' status ' ` ` `",0
bitcoin/bitcoin,"test : bdb - only build fails wallet_basic . py steps to reproduce : * compile bdb - only * run wallet_basic . py ` ` ` test <number> - <number> - 0 5 t <time> . 8 6 6 0 0 0 z testframework ( error ) : jsonrpc error traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / wallet_basic . py "" , line <number> , in run_test self . nodes [ <number> ] . createwallet ( wallet_name = "" wo "" , descriptors = true , disable_private_keys = true ) file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / test_framework / test_node . py "" , line <number> , in createwallet return self . __getattr__ ( ' createwallet ' ) ( wallet_name , disable_private_keys , blank , passphrase , avoid_reuse , descriptors , load_on_startup , external_signer ) file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / test_framework / coverage . py "" , line <number> , in __call__ return_val = self . auth_service_proxy_instance . __call__ ( * args , * * kwargs ) file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / test_framework / authproxy . py "" , line <number> , in __call__ raise jsonrpcexception ( response [ ' error ' ] , status ) test_framework . authproxy . jsonrpcexception without sqlite support ( required for descriptor wallets ) ( - <number> )",0
bitcoin/bitcoin,"sendall creates tx that fails tx - size mempool check steps to reproduce : * create many inputs * call ` sendall ` error : ` <number> - <number> - 0 5 t <time> z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] committransaction ( ) cannot be broadcast immediately , tx - size `",0
bitcoin/bitcoin,"stop loading wallet at startup * * describe the issue * * bitcoin core qt auto loads wallet at startup [ ] ( <url> * * what behavior did you expect ? * * i did not specify to load a wallet at startup . * * what was the actual behavior ( provide screenshots if the issue is gui - related ) ? * * starting bitcoin core qt with double click on bitcoin - qt . exe , then it auto loads a wallet at startup screenshot : <url> i must click on ok . my configuration file ( bitcoin . conf ) : ` ` ` server = <number> testnet = <number> rpcuser =< redacted > rpcpassword =< redacted > daemon = <number> ` ` ` * * system information * * < - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > bitcoin core <number> windows <number> x64 * * debug . log : * * <number> - <number> - 0 2 t <time> z default data directory x <elongated> <number> - <number> - 0 2 t <time> z using data directory x <elongated> <number> - <number> - 0 2 t <time> z config file : x <elongated> \ \ bitcoin . conf <number> - <number> - 0 2 t <time> z config file arg : daemon = "" <number> "" <number> - <number> - 0 2 t <time> z config file arg : rpcpassword = * * * * <number> - <number> - 0 2 t <time> z config file arg : rpcuser = * * * * <number> - <number> - 0 2 t <time> z config file arg : server = "" <number> "" <number> - <number> - 0 2 t <time> z config file arg : testnet = "" <number> "" * * <number> - <number> - 0 2 t <time> z setting file arg : wallet = [ "" x <elongated> "" ]* * <number> - <number> - 0 2 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 0 2 t <time> z gui : "" registershutdownblockreason : successfully registered : bitcoin core did not yet exit safely . <repeated> "" <number> - <number> - 0 2 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 0 2 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 0 2 t <time> z script verification uses <number> additional threads <number> - <number> - 0 2 t <time> z scheduler thread start <number> - <number> - 0 2 t <time> z http : creating work queue of depth <number> <number> - <number> - 0 2 t <time> z using wallet directory x <elongated> <number> - <number> - 0 2 t <time> z init message : verifying wallet ( s ) . <repeated> * * <number> - <number> - 0 2 t <time> z warning : skipping - wallet path that does not exist . failed to load database path ' x <elongated> ' . path does not exist . * * * * issue looks like to be at line "" <number> - <number> - 0 2 t <time> z setting file arg = [ "" x <elongated> "" ]""* * * * but why bitcoin core loads it ? i did not specify it in bitcoin . conf * * thanks .",0
bitcoin/bitcoin,"compilation / build failed - mac <number> m1 - ld : unknown option : - soname - make [ <number> <sad> * * * [ libbitcoinconsensus . la ] error <number> < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * build should not failed < ! - - - what behavior did you expect ? - - > * * actual behavior * * build is failing < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * m1 - mac os monterey - version <number> xcode version <number> . <number> ( 1 3 f100 ) <number> . sh . / autogen . sh ( working fine ) <number> . . / configure - - prefix <annoyed> users / amit / downloads / androidproject / wow / doit / bitcoin / depends / aarch64 - linux - android - - without - gui - - disable - zmq - - with - miniupnpc = no - - with - incompatible - bdb - - disable - bench - - disable - tests - - enable - module - ecdh cc <annoyed> opt / homebrew / cellar / llvm / <number> . 6 _1 / bin / clang cxx <annoyed> opt / homebrew / cellar / llvm / <number> . 6 _1 / bin / clang + + * * . / configure is failing with following errors ld : unknown option : - soname - make [ <number> <sad> * * * [ libbitcoinconsensus . la ] error <number> * * making all in src cxx node / libbitcoin_node_a - interface_ui . o cxx node / libbitcoin_node_a - interfaces . o cxx node / libbitcoin_node_a - miner . o cxx node / libbitcoin_node_a - mempool_persist_args . o cxx node / libbitcoin_node_a - transaction . o cxx libbitcoin_node_a - noui . o cxx policy / libbitcoin_node_a - fees . o cxx policy / libbitcoin_node_a - rbf . o cxx libbitcoin_node_a - rest . o cxx rpc / libbitcoin_node_a - blockchain . o cxx rpc / libbitcoin_node_a - fees . o cxx rpc / libbitcoin_node_a - mempool . o cxx rpc / libbitcoin_node_a - mining . o cxx rpc / libbitcoin_node_a - net . o cxx rpc / libbitcoin_node_a - rawtransaction . o cxx rpc / libbitcoin_node_a - server . o cxx rpc / libbitcoin_node_a - server_util . o cxx rpc / libbitcoin_node_a - txoutproof . o cxx libbitcoin_node_a - torcontrol . o cxx libbitcoin_node_a - txmempool . o cxx libbitcoin_node_a - txrequest . o cxx libbitcoin_node_a - validation . o cxx wallet / libbitcoin_node_a - init . o cxx wallet / libbitcoin_wallet_a - dump . o cxx wallet / libbitcoin_wallet_a - external_signer_scriptpubkeyman . o cxx wallet / libbitcoin_wallet_a - feebumper . o cxx wallet / libbitcoin_wallet_a - fees . o cxx wallet / libbitcoin_wallet_a - interfaces . o cxx wallet / libbitcoin_wallet_a - load . o cxx wallet / libbitcoin_wallet_a - receive . o cxx wallet / rpc / libbitcoin_wallet_a - addresses . o cxx wallet / rpc / libbitcoin_wallet_a - backup . o cxx wallet / rpc / libbitcoin_wallet_a - coins . o cxx wallet / rpc / libbitcoin_wallet_a - encrypt . o cxx wallet / rpc / libbitcoin_wallet_a - spend . o cxx wallet / rpc / libbitcoin_wallet_a - signmessage . o cxx wallet / rpc / libbitcoin_wallet_a - transactions . o cxx wallet / rpc / libbitcoin_wallet_a - util . o cxx wallet / rpc / libbitcoin_wallet_a - wallet . o cxx wallet / libbitcoin_wallet_a - scriptpubkeyman . o cxx wallet / libbitcoin_wallet_a - spend . o cxx wallet / libbitcoin_wallet_a - wallet . o cxx wallet / libbitcoin_wallet_a - walletdb . o cxx wallet / libbitcoin_wallet_a - sqlite . o cxx wallet / libbitcoin_wallet_a - bdb . o cxx wallet / libbitcoin_wallet_a - salvage . o cxx interfaces / libbitcoin_util_a - handler . o cxx util / libbitcoin_util_a - system . o cxx util / libbitcoin_util_a - time . o cxx util / libbitcoin_util_a - url . o cxx bitcoin_cli - bitcoin - cli . o cxx bitcoin_tx - bitcoin - tx . o cxx wallet / libbitcoin_wallet_tool_a - wallettool . o cxx wallet / test / fuzz / test_fuzz_fuzz - coinselection . o cxx wallet / test / fuzz / test_fuzz_fuzz - notifications . o cxx test / fuzz / fuzz - addition_overflow . o cxx test / fuzz / fuzz - addrman . o cxx test / fuzz / fuzz - autofile . o cxx test / fuzz / fuzz - banman . o cxx test / fuzz / fuzz - block . o cxx test / fuzz / fuzz - block_header . o cxx test / fuzz / fuzz - blockfilter . o cxx test / fuzz / fuzz - bloom_filter . o cxx test / fuzz / fuzz - buffered_file . o cxx test / fuzz / fuzz - chain . o cxx test / fuzz / fuzz - checkqueue . o cxx test / fuzz / fuzz - coins_view . o cxx test / fuzz / fuzz - connman . o cxx test / fuzz / fuzz - crypto . o cxx test / fuzz / fuzz - crypto_aes256 . o cxx test / fuzz / fuzz - crypto_aes256cbc . o cxx test / fuzz / fuzz - crypto_chacha20 . o cxx test / fuzz / fuzz - crypto_chacha20_poly1305_aead . o cxx test / fuzz / fuzz - crypto_common . o cxx test / fuzz / fuzz - crypto_diff_fuzz_chacha20 . o cxx test / fuzz / fuzz - crypto_hkdf_hmac_sha256_l32 . o cxx test / fuzz / fuzz - crypto_poly1305 . o cxx test / fuzz / fuzz - cuckoocache . o cxx test / fuzz / fuzz - deserialize . o cxx test / fuzz / fuzz - fee_rate . o cxx test / fuzz / fuzz - fees . o cxx test / fuzz / fuzz - flatfile . o cxx test / fuzz / fuzz - float . o cxx test / fuzz / fuzz - golomb_rice . o cxx test / fuzz / fuzz - http_request . o cxx test / fuzz / fuzz - i2p . o cxx test / fuzz / fuzz - integer . o cxx test / fuzz / fuzz - kitchen_sink . o cxx test / fuzz / fuzz - load_external_block_file . o cxx test / fuzz / fuzz - merkleblock . o cxx test / fuzz / fuzz - message . o cxx test / fuzz / fuzz - miniscript . o cxx test / fuzz / fuzz - minisketch . o cxx test / fuzz / fuzz - muhash . o cxx test / fuzz / fuzz - multiplication_overflow . o cxx test / fuzz / fuzz - net . o cxx test / fuzz / fuzz - net_permissions . o cxx test / fuzz / fuzz - netaddress . o cxx test / fuzz / fuzz - netbase_dns_lookup . o cxx test / fuzz / fuzz - node_eviction . o cxx test / fuzz / fuzz - parse_hd_keypath . o cxx test / fuzz / fuzz - policy_estimator . o cxx test / fuzz / fuzz - policy_estimator_io . o cxx test / fuzz / fuzz - pow . o cxx test / fuzz / fuzz - primitives_transaction . o cxx test / fuzz / fuzz - process_message . o cxx test / fuzz / fuzz - process_messages . o cxx test / fuzz / fuzz - protocol . o cxx test / fuzz / fuzz - random . o cxx test / fuzz / fuzz - rbf . o cxx test / fuzz / fuzz - rolling_bloom_filter . o cxx test / fuzz / fuzz - rpc . o cxx test / fuzz / fuzz - script . o cxx test / fuzz / fuzz - script_bitcoin_consensus . o cxx test / fuzz / fuzz - script_descriptor_cache . o cxx test / fuzz / fuzz - script_format . o cxx test / fuzz / fuzz - script_interpreter . o cxx test / fuzz / fuzz - script_ops . o cxx test / fuzz / fuzz - script_sigcache . o cxx test / fuzz / fuzz - script_sign . o cxx test / fuzz / fuzz - scriptnum_ops . o cxx test / fuzz / fuzz - secp256k1_ec_seckey_import_export_der . o cxx test / fuzz / fuzz - secp256k1_ecdsa_signature_parse_der_lax . o cxx test / fuzz / fuzz - signature_checker . o cxx test / fuzz / fuzz - signet . o cxx test / fuzz / fuzz - socks5 . o cxx test / fuzz / fuzz - span . o cxx test / fuzz / fuzz - string . o cxx test / fuzz / fuzz - strprintf . o cxx test / fuzz / fuzz - system . o cxx test / fuzz / fuzz - timedata . o cxx test / fuzz / fuzz - torcontrol . o cxx test / fuzz / fuzz - transaction . o cxx test / fuzz / fuzz - tx_pool . o cxx test / fuzz / fuzz - txorphan . o cxx test / fuzz / fuzz - utxo_snapshot . o cxx test / fuzz / fuzz - validation_load_mempool . o cxx test / fuzz / fuzz - versionbits . o cxx test / util / libtest_util_a - blockfilter . o cxx test / util / libtest_util_a - mining . o cxx test / util / libtest_util_a - setup_common . o cxx test / util / libtest_util_a - validation . o cxx test / util / libtest_util_a - wallet . o cxx test / fuzz / libtest_fuzz_a - fuzz . o cxx test / fuzz / libtest_fuzz_a - util . o * * cxxld libbitcoinconsensus . la cxx libbitcoin_node_a - blockencodings . o ld : unknown option : - soname clang - <number> : error : linker command failed with exit code <number> ( use - v to see invocation ) make [ <number> <sad> * * * [ libbitcoinconsensus . la ] error <number> make [ <number> <sad> * * * waiting for unfinished jobs . <repeated> make [ <number> <sad> * * * [ all - recursive ] error <number> make [ all - recursive ] error <number> * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > * * system information * * m1 - mac os monterey - version <number> xcode version <number> . <number> ( 1 3 f100 ) < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,"qt . qpa . xcb : could not connect to display < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > ubuntu <number> desktop with necessary build tools for bitcoin core qfactoryloader : : qfactoryloader ( ) ignoring "" org . qt - project . qt . qpa . qplatformintegrationfactoryinterface . <number> "" since plugins are disabled in static builds qt . qpa . xcb : could not connect to display qt . qpa . plugin : could not load the qt platform plugin "" xcb "" in "" "" even though it was found bitcoin core v23 . <number> built using depends on ubuntu <number> note issue is present with <number> binaries built on ubuntu <number> the binaries run just fine on the <number> server this appears to be a dependency issue in the build tree * * expected behavior * * < ! - - - what behavior did you expect ? - - > bitcoin - qt to start * * actual behavior * * bitcoin - qt failed to start , error message above < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * install fresh ubuntu <number> or lubuntu <number> desktop apt - get install . <repeated> the build stuff for bitcoin core cd depends make cd . <repeated> . / autogen . sh configure - - - with lots of stuff normally used run binary with normal config < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > <percent> every time * * system information * * lubuntu <number> and ubuntu <number> < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > github checkout tag v23 . <number> < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > proliant gl380 - g7 1 9 2 g / ram 2 t disk < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > see above < ! - - any extra information that might be useful in the debugging process . - - > tried all the solutions found with google , about a half dozen of them the error message about platforms not included in static build appears to be the key , do not know how to resolve that . < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,c + + compiler wont make ` ` ` errirayech : bitcoin folderhub $ . / configure cc <annoyed> opt / homebrew / opt / llvm / bin / clang @ cxx <annoyed> opt / homebrew / opt / llvm / bin / clang + + checking for pkg - config . <repeated> / usr / local / bin / pkg - config checking pkg - config is at least version <number> . <number> . <repeated> yes checking build system type . <repeated> i386 - apple - darwin17 . <number> checking host system type . <repeated> i386 - apple - darwin17 . <number> checking for a bsd - compatible install . <repeated> / usr / bin / install - c checking whether build environment is sane . <repeated> yes checking for a race - free mkdir - p . <repeated> . / build - aux / install - sh - c - d checking for gawk . <repeated> no checking for mawk . <repeated> no checking for nawk . <repeated> no checking for awk . <repeated> awk checking whether make sets $( make ) . <repeated> yes checking whether make supports nested variables . <repeated> yes checking whether to enable maintainer - specific portions of makefiles . <repeated> yes checking whether make supports nested variables . <repeated> ( cached ) yes checking whether the c + + compiler works . <repeated> no configure : error : in ` / users / folderhub / heard / bitcoin ' : configure : error compiler cannot create executables see ` config . log ' for more details ` ` `,0
bitcoin/bitcoin,"mac os latest bitcoin core latest release will not run as mac os , "" you can not open the application ' bitcoin core ' "" similar to # <number> , but different error message . < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url> < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url>",0
bitcoin/bitcoin,<number> test fails when running make check ( windows visual studio wsl ubuntu ) see log below . <repeated> bottom line up front : the test fails because test_bitcoin - qt . exe fails to launch . i attempted just running the executable manually in my c :\\ drive ' s bitcoin \ \ bin folder and that also does not launch . bitcoin - qt . exe launches though and runs nicely . from test - suite . log : = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = bitcoin core <number> . <number> : src / test - suite . log = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = # total : <number> # pass : <number> # skip : <number> # xfail : <number> # fail : <number> # xpass : <number> # error : <number> . <repeated> contents : : : depth : <number> fail : qt / test / test_bitcoin - qt = = = = = = = = = = = = = = = = = = = = = = = = = = = = = a crash occurred in \ \ \ \ wsl $\\ ubuntu \ \ home \ \ jglann \ \ bitcoin \ \ src \ \ qt \ \ test \ \ test_bitcoin - qt . exe . function time : 8 3 6 ms total time : 8 3 6 ms exception address : 0x <phone> bc5988 exception code : 0 xc0000005 stack : # <number> : unable to obtain symbol # <number> : unhandledexceptionfilter ( ) - 0x0 0 0 0 7 ffe7fdbfe70 # <number> : memset ( ) - 0x0 0 0 0 7 ffe82634000 # <number> : _c_specific_handler ( ) - 0x0 0 0 0 7 ffe8261c6d0 # <number> : _chkstk ( ) - 0x0 0 0 0 7 ffe82632180 # <number> : rtlraiseexception ( ) - 0x0 0 0 0 7 ffe825e1020 # <number> : kiuserexceptiondispatcher ( ) - 0x0 0 0 0 7 ffe82630da0 # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : unable to obtain symbol # <number> : basethreadinitthunk ( ) - 0x0 0 0 0 7 ffe82357020 # <number> : rtluserthreadstart ( ) - 0x0 0 0 0 7 ffe825e2630 fail qt / test / test_bitcoin - qt . exe ( exit status,0
bitcoin/bitcoin,"pubkey . cpp : <number> <time> : runtime error : implicit conversion from type ' int ' of value <number> ( <number> - bit , signed ) to type ' unsigned char ' changed the value to <number> ( <number> - bit , unsigned ) steps to reproduce : * build with ` integer ` sanitizer * start . / src / qt / bitcoin - qt - chain = main ` * enter ` getdescriptorinfo "" sh ( multi ( <number> , xprv9updjpeqgrqfdcw7bkf7etya6rpxxejcqcjghucj4girvlzktxbajmu2qamwprs7aanyqdq6vcbcbudjcvvfceuvjfjapdgz2y9wacvil4l / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <number> / <date> / <number> / <date> / <number> / <number> / <number> / <number> / <date> / <number> / <number> / <date> / <number> / <number> / <number> / <number> , [ <number> ] xprv9updjpeqgrqfdcw7bkf7etya6rpxxejcqcjghucj4girvlzktxbajmu2qamwprs7aanyqdq6vcbcbudjcvvfceuvjfjapdgz2y9wacvil4l / <number> ) <number> ) "" ` into the console",0
bitcoin/bitcoin,"test : failure in rpc_net . py <url> ` ` ` bash test <number> - <number> - 2 9 t <time> . 5 1 0 0 0 0 z testframework . utils ( error ) : wait_until ( ) failed . predicate : ' ' ' ' self . wait_until ( lambda : sum ( peer [ ' version ' ] = <number> for peer in to_connection . getpeerinfo ( ) ) = = to_num_peers ) ' ' ' test <number> - <number> - 2 9 t <time> . 5 1 1 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" / tmp / cirrus - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / rpc_net . py "" , line <number> , in run_test self . test_getnetworkinfo ( ) file "" / tmp / cirrus - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / rpc_net . py "" , line <number> , in test_getnetworkinfo self . connect_nodes ( <number> , <number> ) file "" / tmp / cirrus - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in connect_nodes self . wait_until ( lambda : sum ( peer [ ' version ' ] ! = <number> for peer in to_connection . getpeerinfo ( ) ) = = to_num_peers ) file "" / tmp / cirrus - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in wait_until return wait_until_helper ( test_function , timeout = timeout , timeout_factor = self . options . timeout_factor ) file "" / tmp / cirrus - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in wait_until_helper raise assertionerror ( "" predicate { } not true after { } seconds "" . format ( predicate_source , timeout ) ) assertionerror : predicate ' ' ' ' self . wait_until ( lambda ! = <number> for peer in to_connection . getpeerinfo ( ) ) = = to_num_peers ) ' ' ' not true after <number> seconds ` ` `",0
bitcoin/bitcoin,"macos : ` importdescriptors ` rpc call very slow with release and source - built binaries , but fast for homebrew binaries i am working on a project on macos that makes rpc calls using the rust [ bitcoincore - rpc crate ] ( <url> against the bitcoind prebuilt binary available [ here ] ( <url> some rpc calls succeed , but some fail with this error : ` ` ` error : rpc ( jsonrpc ( transport ( socketerror ( os { code : <number> , kind : wouldblock , message : "" resource temporarily unavailable "" } ) ) ) ) ` ` ` after much debugging , we found that when we used the version of ` bitcoind ` provided by [ homebrew ] ( <url> the exact same sequence of rpc calls would succeed . we were able to reproduce this on both an x86 mac and an arm mac . we have not been able to figure out what the disparity is , but looking at the homebrew [ bitcoind formula defiinition ] ( <url> might provide some clues . in particular def install system "" . / autogen . sh "" system "" . / configure "" , * std_configure_args , "" - - disable - dependency - tracking "" , "" - - disable - silent - rules "" , "" - - with - boost - libdir =#{ formula [ "" boost <user> . <number> "" ] . opt_lib } "" system "" make "" , "" install "" pkgshare . install "" share / rpcauth "" end ` ` ` it looks like homebrew is passing additional arguments to ` configure ` , ` std_configure_args ` , and is using a version of boost built by homebrew . i tried using ` brew install - s boost <user> . <number> bitcoind ` , to see if this also produced a binary that worked , and it did . the logs from that build are available [ here ] ( <url> i have run into similar problems like this one a few times before , i . e . , rpc calls to bitcoind failing on macos due to inscrutable i / o errors . one time , i was able to fix it by increasing the open file limit using ` ulimit - n big_number ` , but that does not seem to work here . my best guess is that the homebrew poeople have gotten pretty good at configuring packages on macos , and they are passing some flag , or using a patched version of boost , or linking it differently , such that the binary they produce is not affected by this issue .",0
bitcoin/bitcoin,"wallet_backup . py fails with assertionerror : not ( <number> = = <number> ) [ assert_equal ( self . nodes [ <number> ] . getbalance ( ) , <number> ) ] from <url> ` ` ` node2 <number> - <number> - 2 0 t <time> . 0 8 2 8 3 1 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] wallet file version = <number> , last client version = <number> node2 <number> - <number> - 2 0 t <time> . 0 8 2 8 5 8 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records : <number> node2 <number> - <number> - 2 0 t <time> . 3 6 3 2 3 0 z [ httpworker . <number> ] [ wallet / scriptpubkeyman . h : <number> ] [ walletlogprintf ] [ default wallet ] keypool added <number> keys ( <number> internal ) , size = <number> ( <number> internal ) node2 <number> - <number> - 2 0 t <time> . 3 7 2 7 4 3 z [ httpworker . <number> ] [ wallet / scriptpubkeyman . h : <number> ] [ walletlogprintf ] [ default wallet ] legacyscriptpubkeyman : : newkeypool rewrote keypool node2 <number> - <number> - 2 0 t <time> . 3 7 4 2 2 8 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] wallet completed loading in 3 0 1 ms node2 <number> - <number> - 2 0 t <time> . 3 7 4 2 8 3 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] setkeypool . size ( ) = <number> node2 <number> - <number> - 2 0 t <time> . 3 7 4 2 9 3 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] mapwallet . size ( ) = <number> node2 <number> - <number> - 2 0 t <time> . 3 7 4 3 0 2 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] m_address_book . size ( ) = <number> node2 <number> - <number> - 2 0 t <time> . 3 7 5 1 2 9 z [ http ] [ httpserver . cpp : <number> ] [ http_request_cb ] [ http ] received a post request for / from <number> . <number> . <time> <number> node2 <number> - <number> - 2 0 t <time> . 3 7 5 1 7 8 z [ httpworker . <number> ] [ rpc / request . cpp : <number> ] [ parse ] [ rpc ] threadrpcserver method = getwalletinfo user = __cookie__ node2 <number> - <number> - 2 0 t <time> . 3 7 5 8 5 2 z [ http ] [ httpserver . cpp : <number> ] [ http_request_cb ] [ http ] received a post request for / from <number> . <number> . <time> <number> node2 <number> - <number> - 2 0 t <time> . 3 7 5 8 9 6 z [ httpworker . <number> ] [ rpc / request . cpp : <number> ] [ parse ] [ rpc ] threadrpcserver method = importprivkey user = __cookie__ node2 <number> - <number> - 2 0 t <time> . 3 8 4 6 9 1 z [ httpworker . <number> ] [ wallet / scriptpubkeyman . h : <number> ] [ walletlogprintf ] [ default wallet ] already have script 0 0 1 4 4 ff785b8221dc206314ca12e65773a876dff30ff , skipping node2 <number> - <number> - 2 0 t <time> . 3 8 5 6 7 4 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] rescanfromtime : rescanning last <number> blocks node2 <number> - <number> - 2 0 t <time> . 3 8 5 6 8 8 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] rescan started from block 0 f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206 . <repeated> node2 <number> - <number> - 2 0 t <time> . 3 8 6 0 0 0 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] addtowallet 4 cddeee95a635bbf1efa02cd90f11f3385981ba1461309d7e4787e8f3c95d2df new node2 <number> - <number> - 2 0 t <time> . 3 9 1 1 7 0 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] scanning current mempool transactions . node2 <number> - <number> - 2 0 t <time> . 3 9 1 1 8 7 z [ httpworker . <number> ] [ wallet / wallet . h : <number> ] [ walletlogprintf ] [ default wallet ] rescan completed in 5 ms node0 <number> - <number> - 2 0 t <time> . 3 9 1 9 4 4 z [ http ] [ httpserver . cpp : <number> ] [ http_request_cb ] [ http ] received a post request for / from <number> . <number> . <time> <number> node0 <number> - <number> - 2 0 t <time> . 3 9 1 9 9 2 z [ httpworker . <number> ] [ rpc / request . cpp : <number> ] [ parse ] [ rpc ] threadrpcserver method = getbalance user = __cookie__ node1 <number> - <number> - 2 0 t <time> . 3 9 2 5 1 8 z [ http ] [ httpserver . cpp : <number> ] [ http_request_cb ] [ http ] received a post request for / from <number> . <number> . <time> <number> node1 <number> - <number> - 2 0 t <time> . 3 9 2 5 6 4 z [ httpworker . <number> ] [ rpc / request . cpp : <number> ] [ parse ] [ rpc ] threadrpcserver method = getbalance user = __cookie__ test <number> - <number> - 2 0 t <time> . 3 9 3 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / wallet_backup . py "" , line <number> , in run_test assert_equal ( self . nodes [ <number> ] . getbalance ( ) , <number> ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / util . py "" , line <number> , in assert_equal raise assertionerror ( "" not ( %s ) "" % "" = = "" . join ( str ( arg ) for arg in ( thing1 , thing2 ) + args ) ) assertionerror = = <number> )",0
bitcoin/bitcoin,"summary : threadsanitizer : segv src / index / base . cpp : <number> : <number> in baseindex : : setbestblockindex ( cblockindex const <wink> : : $ _1 : : operator ( ) ( ) const on current master ( d806407173926e46421ad807750a06e49afbbdbd ) : ` ` ` = = <number> = = error : threadsanitizer : segv on unknown address 0x0 0 0 0 0 0 0 0 0 0 6 8 ( pc 0x 5 6 3 f9856361b bp 0x 7 b140000ae48 sp 0x 7 f2a8bcfec90 t93437 ) = = <number> = = the signal is caused by a read memory access . = = <number> = = hint : address points to the zero page . # <number> baseindex : : setbestblockindex ( cblockindex const <wink> : : $ _1 : : operator ( ) ( ) const src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xcf161b ) # <number> baseindex : : setbestblockindex ( cblockindex const <wink> src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xcf161b ) # <number> baseindex : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> src / index / base . cpp : <number> : <number> ( test_bitcoin + 0 xcf3899 ) # <number> cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const : : ' lambda ' ( cvalidationinterface & <sad> : operator ( ) ( cvalidationinterface & ) const src / validationinterface . cpp : <number> : <number> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> void mainsignalsimpl : : iterate < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const : : ' lambda ' ( cvalidationinterface & ) > ( cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const : : ' lambda ' ( cvalidationinterface & ) & & ) src / validationinterface . cpp : <number> <time> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _8 : : operator ( ) ( ) const src / validationinterface . cpp : <number> <time> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 : : operator ( ) ( ) const src / validationinterface . cpp : <number> : <number> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> decltype ( static_cast < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & > ( fp ) ( ) ) std : : __1 : : __invoke < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & > ( cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & > ( cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> std : : __1 : : __function : : __alloc_func < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 , std : : __1 : : allocator < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> std : : __1 : : __function : : __func < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 , std : : __1 : : allocator < cmainsignals : : blockconnected ( std : : __1 : : shared_ptr < cblock const > const & , cblockindex const <wink> : : $ _9 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 4 ac34 ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 e3661 ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 e3661 ) # <number> singlethreadedschedulerclient : : processqueue ( ) src / scheduler . cpp : <number> : <number> ( test_bitcoin + 0x 1 0 e3661 ) # <number> singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 : : operator ( ) ( ) const src / scheduler . cpp : <number> <time> ( test_bitcoin + 0x 1 0 e5365 ) # <number> decltype ( static_cast < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & > ( fp ) ( ) ) std : : __1 : : __invoke < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & > ( singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0x 1 0 e5365 ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & > ( singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( test_bitcoin + 0x 1 0 e5365 ) # <number> std : : __1 : : __function : : __alloc_func < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 , std : : __1 : : allocator < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 e5365 ) # <number> std : : __1 : : __function : : __func < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 , std : : __1 : : allocator < singlethreadedschedulerclient : : maybescheduleprocessqueue ( <sad> : $ _1 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 e5365 ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 e264c ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 0 e264c ) # <number> cscheduler : : servicequeue ( ) src / scheduler . cpp : <number> <time> ( test_bitcoin + 0x 1 0 e264c ) # <number> chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 : : operator ( ) ( ) const src / test / util / setup_common . cpp : <number> <time> <number> ( test_bitcoin + 0 xa733c8 ) # <number> decltype ( static_cast < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & > ( fp ) ( ) ) std : : __1 : : __invoke < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & > ( chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0 xa733c8 ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & > ( chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( test_bitcoin + 0 xa733c8 ) # <number> std : : __1 : : __function : : __alloc_func < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 , std : : __1 : : allocator < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0 xa733c8 ) # <number> std : : __1 : : __function : : __func < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 , std : : __1 : : allocator < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0 xa733c8 ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 a229f ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( test_bitcoin + 0x 1 1 a229f ) # <number> util : : tracethread ( char const * , std : : __1 : : function < void ()>) src / util / thread . cpp : <number> : <number> ( test_bitcoin + 0x 1 1 a229f ) # <number> decltype ( static_cast < void (*> ( fp ) ( static_cast < char const *>( fp0 ) , static_cast < chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > ( fp0 ) ) ) std : : __1 : : __invoke < void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > ( void (* & & ) ( char const * , std : : __1 : : function < void ()>), char const * & & , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 & & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( test_bitcoin + 0 xa72fc1 ) # <number> void std : : __1 : : __thread_execute < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 , 2 ul , 3 ul > ( std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > & , std : : __1 : : __tuple_indices < 2 ul , 3 ul > ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( test_bitcoin + 0 xa72fc1 ) # <number> void * std : : __1 : : __thread_proxy < std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , chaintestingsetup : : chaintestingsetup ( std : : __1 : : basic_string < char , std : : __1 : : char_traits <char> , std : : __1 : : allocator <char> > const & , std : : __1 : : vector < char const * , std : : __1 : : allocator < char const *> > const & <sad> : $ _0 > > ( void <wink> / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( test_bitcoin + 0 xa72fc1 ) # <number> __tsan_thread_start_func <null> ( test_bitcoin + 0x 1 2 d2bc ) # <number> <null> <null> ( libc . so . <number> + 0x 9 4 b42 ) # <number> <null> <null> ( libc . so . <number> + 0x 1 2 6 9 ff ) threadsanitizer can not provide additional info . summary : threadsanitizer : segv src / index / base . cpp : <number> : <number> in baseindex : : setbestblockindex ( cblockindex const <wink> : : $ _1 : : operator ( ) ( ) const = = <number> = = aborting exit status ` ` ` <url>",0
bitcoin/bitcoin,"build failure on m1 ( arm64 ) : error : unknown target cpu ' armv8 - a + crc + crypto ' system : ` ` ` - - > uname - a darwin <number> . <number> darwin kernel version <number> . <number> : fri <date> <time> pdt <number> ; root : xnu - <number> . <number> ~ <number> / release_arm64_t8101 arm64 - - > gcc - v apple clang version <number> . <number> ( clang - <number> . <number> . <number> ) target : arm64 - apple - darwin21 . <number> thread model : posix installeddir : / applications / xcode . app / contents / developer / toolchains / xcodedefault . xctoolchain / usr / bin ` ` ` bitcoin : ( master branch ) ` ` ` - - > git rev - parse head aeab1b42e67cc8146bfc7d127d15633bd652fe60 ` ` ` build command : ` ` ` . / autogen . sh . / configure - - without - gui - - with - incompatible - bdb make - j <number> ` ` ` error output : ` ` ` . <repeated> <number> warnings generated . cxx zmq / libbitcoin_zmq_a - zmqutil . o cxx primitives / libbitcoin_consensus_a - block . o cxx primitives / libbitcoin_consensus_a - transaction . o cxx crypto / libbitcoin_crypto_base_la - aes . lo cxx crypto / libbitcoin_crypto_base_la - chacha_poly_aead . lo cxx crypto / libbitcoin_crypto_base_la - chacha20 . lo cxx crypto / libbitcoin_crypto_base_la - hkdf_sha256_32 . lo cxx crypto / libbitcoin_crypto_base_la - hmac_sha256 . lo cxx crypto / libbitcoin_crypto_base_la - hmac_sha512 . lo cxx crypto / libbitcoin_crypto_base_la - poly1305 . lo cxx crypto / libbitcoin_crypto_base_la - muhash . lo cxx crypto / libbitcoin_crypto_base_la - ripemd160 . lo cxx crypto / libbitcoin_crypto_base_la - sha1 . lo cxx crypto / libbitcoin_crypto_base_la - sha256 . lo cxx crypto / libbitcoin_crypto_base_la - sha3 . lo cxx crypto / libbitcoin_crypto_base_la - sha512 . lo cxx crypto / libbitcoin_crypto_base_la - siphash . lo cxx crypto / libbitcoin_crypto_base_la - sha256_sse4 . lo cxx crypto / libbitcoin_crypto_arm_shani_la - sha256_arm_shani . lo cxx leveldb / db / libleveldb_la - builder . lo error : unknown target cpu ' armv8 - a + crc + crypto ' note : valid target cpu values are : nocona , core2 , penryn , bonnell , atom , silvermont , slm , goldmont , goldmont - plus , tremont , nehalem , corei7 , westmere , sandybridge , corei7 - avx , ivybridge , core - avx - i , haswell , core - avx2 , broadwell , skylake , skylake - avx512 , skx , cascadelake , cooperlake , cannonlake , icelake - client , rocketlake , icelake - server , tigerlake , sapphirerapids , alderlake , knl , knm , k8 , athlon64 , athlon - fx , opteron , k8 - sse3 , athlon64 - sse3 , opteron - sse3 , amdfam10 , barcelona , btver1 , btver2 , bdver1 , bdver2 , bdver3 , bdver4 , znver1 , znver2 , znver3 , x86 - <number> , x86 - <number> - v2 , x86 - <number> - v3 , x86 - <number> - v4 make [ <number> <sad> * * * [ crypto / libbitcoin_crypto_arm_shani_la - sha256_arm_shani . lo ] error <number> make [ <number> <sad> * * * waiting for unfinished jobs . <repeated> make [ <number> <sad> * * * [ all - recursive ] error <number> make [ all - recursive ] error <number> ` ` `",0
bitcoin/bitcoin,"build failing on ubuntu <number> < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > < ! - - describe the issue - - > * * expected behavior * * to run bitcoin - core in ubuntu <number> after following all the steps in [ build - unix . md ] ( <url> * * actual behavior * * even after carefully following all the steps the build is failing in ubuntu <number> version but by following the same steps again in ubuntu <number> and <number> i am able to successfully run bitcoin - core . * * to reproduce * * to verify this first follow all the instructions in the [ build - unix . md ] ( <url> in ubuntu <number> and then try to run the following command : ` ` ` python3 test / functional / feature_taproot . py ` ` ` you will be met with the following error of some sort : ` ` ` <number> - <number> - 1 1 t <time> . 0 7 5 0 0 0 z testframework ( info ) : initializing test directory / tmp / bitcoin_func_test_2wz38651 <number> - <number> - 1 1 t <time> . 4 7 6 0 0 0 z testframework ( info ) : post - activation tests . <repeated> <number> - <number> - 1 1 t <time> . 8 3 2 0 0 0 z testframework ( error ) : unexpected exception caught during testing traceback ( most recent call last ) : file "" / usr / lib / python3 . <number> / hashlib . py "" , line <number> , in __hash_new return _hashlib . new ( name , data , * * kwargs ) valueerror envelope routines ] unsupported ` ` ` this error is not in particular for running tests but shows a problem with the installation of bitcoin - core in general . i searched for the issues and came across a few articles and conversations regarding this particular issue in ubuntu <number> . will be providing links to them .",0
bitcoin/bitcoin,"build : autoconf <number> warns that ` %. raw . h ` was already defined the master branch ( cc22bd7f708fc3f5e793bf0138cd340f71c0feb9 ) on ubuntu <number> : ` ` ` $ . / autogen . sh . <repeated> src / makefile . bench . include : <number> : warning : %. raw . h was already defined in condition true , which includes condition enable_bench . <repeated> src / makefile . am : <number> : ' src / makefile . bench . include ' included from here src / makefile . test . include : <number> : . <repeated> ' %. raw . h ' previously defined here src / makefile . am : <number> included from here . <repeated> ` ` `",0
bitcoin/bitcoin,"importdescriptors does not scan the mempool just noticed this while debugging a watch - only wallet . step <number> : create watch - only wallet step <number> : import some descriptor step <number> : notice that if a transaction is currently in the mempool , it will not show up in the wallet step <number> bitcoin core , it ' ll show up cc <user>",0
bitcoin/bitcoin,"mac : app gui freezes when synchronizing with network when app is synchronising with network , often app becomes not responsive window is not focused when you press the app icon and it does not handle mouse clicks , always showing loader instead of mouse arrow . it still has some progress loading blocks though . after some time while being focused using f3 button on mac , it may become responsive . * * expected behavior * * it should always be responsive . * * actual behavior * * it is not responsive . * * to reproduce * * just start synchronizing , probably reproduced better on the last percents . * * system information * * bitocoin core <number> macbook air ( m1 , <number> ) mac <number>",0
bitcoin/bitcoin,"cve - <number> - <number> child transactions do not inherit rbf signaling the original issue reported at <url> and at <url> seems to be unresolved in the codebase , and there are no open issues to track this , so i am opening one .",0
bitcoin/bitcoin,nlocktime bug * * block height * * for ` nlocktime ` does not work .,0
bitcoin/bitcoin,""" estimated fee out of range "" intermittent failure in feature_fee_estimation . py <url> on [ nowallet libbitcoinkernel ] [ bionic ] ` ` ` bash node1 <number> - <number> - 2 0 t <time> . 6 3 5 1 2 8 z [ httpworker . <number> ] [ policy / fees . cpp : <number> ] [ estimatemedianval ] fest <elongated> : <number> > <percent> decay <number> : feerate : <number> from ( <number> - <number> ) <percent> <number> / ( <number> <number> mem <number> out ) fail : ( <number> - <number> ) <percent> <number> / ( <number> <number> mem <number> out ) node1 <number> - <number> - 2 0 t <time> . 6 3 5 6 6 9 z [ httpworker . <number> ] [ policy / fees . cpp : <number> ] [ estimatemedianval ] fest <elongated> : <number> > <percent> decay <number> : feerate : <number> from ( <number> - 1 e + <number> ) <percent> <number> / ( <number> <number> mem <number> out ) fail : ( <number> - <number> ) <percent> <number> / ( <number> <number> mem <number> out ) test <number> - <number> - 2 0 t <time> . 6 3 8 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in run_test self . sanity_check_estimates_range ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in sanity_check_estimates_range check_estimates ( self . nodes [ <number> ] , self . fees_per_kb ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in check_estimates check_raw_estimates ( node , fees_seen ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in check_raw_estimates f "" estimated fee ( { feerate } ) out of range ( { min ( fees_seen ) } , { max ( fees_seen ) } ) "" assertionerror : estimated fee ( <number> ) out of range ( <number> . 9 3 7 0 0 7 8 7 4 0 1 5 7 4 8 5 e - <number> . <number> ) test <number> - <number> - 2 0 t <time> . 6 3 9 0 0 0 z testframework ( debug ) : closing down network thread test <number> - <number> - 2 0 t <time> . 6 9 0 0 0 0 z testframework ( info ) : stopping nodes test <number> - <number> - 2 0 t <time> . 6 9 0 0 0 0 z testframework . node0 ( debug ) node ` ` ` i initially thought this might be the same as # <number> ( and <url> and <url> that return * estimated fee ( a ) larger than last fee ( b ) for lower number of confirms . * but this one is * estimated fee out of range * , so opening this issue and linking to the other ones .",0
bitcoin/bitcoin,subtractfeefromamount = true fails with insufficient funds was : <url> steps to reproduce wget <url> tar - xvf datadir_node0 . tar . gz export dd = ' - datadir = . / node0 / ' bitcoin - qt $ dd & bitcoin - cli $ dd loadwallet rpc_online bitcoin - cli $ dd - named sendtoaddress address = bcrt1qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq3xueyj amount = <number> subtractfeefromamount = true,0
bitcoin/bitcoin,"tapleaf hash is calculated differently from bip340 reference implementation due to using the bitcoin serialization routines within chashwriter , tapleaf hasher is fed with an excessive byte , which contains the length of a hashed script . * * expected behavior * * bip341 refers tapleaf hash calculation as tagged_hash function having reference implementation as <url> : ` ` ` def tagged_hash ( tag : str , msg : bytes ) - > bytes : tag_hash = hashlib . sha256 ( tag . encode ( ) ) . digest ( ) return hashlib . sha256 ( tag_hash + tag_hash + msg ) . digest ( ) ` ` ` * * actual behavior * * cscript , and its parent - prevector , are fed to chashwriter as \ \ < compact length \ \>|| \ \ < prevector bytes \ \ > which leads to the wrong hash calculation compared to the reference implementation from bip . * * to reproduce * * here is the sample test which shows the behavior * * system information * * bitcoin v23 . <number> and master",0
bitcoin/bitcoin,"fix chain tip data race and corrupt rest response this fixes two issues : * a data race in ` activechain ` , which returns a reference to the chain ( a ` std : : vector ` ) , which is not thread safe . see also below traceback . * a corrupt rest response , which returns a blockheight and blockhash , which are unrelated to each other and to the result , as the chain might advance between each call without cs_main held . the issues are fixed by taking cs_main and holding it for the required time . ` ` ` = = = = = = = = = = = = = = = = = = warning : threadsanitizer : data race ( pid = <number> ) write of size <number> at 0x 7 b3c000008f0 by thread t22 ( mutexes : write m131626 , write m151 , write m131553 ) : # <number> std : : __1 : : enable_if < ( is_move_constructible < cblockindex * *> : : value ) & & ( is_move_assignable < cblockindex * *> : : value ) , void > : : type std : : __1 : : swap < cblockindex * *>( cblockindex * * & , cblockindex * * & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __utility / swap . h : <number> : <number> ( bitcoind + 0x 5 0 1 2 3 9 ) # <number> std : : __1 : : vector < cblockindex * , std : : __1 : : allocator < cblockindex *> <sad> : __swap_out_circular_buffer ( std : : __1 : : __split_buffer < cblockindex * , std : : __1 : : allocator < cblockindex *> & > & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / vector : <number> : <number> ( bitcoind + 0x 5 0 1 2 3 9 ) # <number> std : : __1 : : vector < cblockindex * , std : : __1 : : allocator < cblockindex *> <sad> : __append ( unsigned long ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / vector : <number> : <number> ( bitcoind + 0x 5 0 1 2 3 9 ) # <number> std : : __1 : : vector < cblockindex * , std : : __1 : : allocator < cblockindex *> <sad> : resize ( unsigned long ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / vector : <number> <time> ( bitcoind + 0x 4 ffe29 ) # <number> cchain : : settip ( cblockindex <wink> src / chain . cpp : <time> ( bitcoind + 0x 4 ffe29 ) # <number> cchainstate : : connecttip ( blockvalidationstate & , cblockindex * , std : : __1 : : shared_ptr < cblock const > const & , connecttrace & , disconnectedblocktransactions & ) src / validation . cpp : <number> <time> ( bitcoind + 0x 4 7 5 d00 ) # <number> cchainstate : : activatebestchainstep ( blockvalidationstate & , cblockindex * , std : : __1 : : shared_ptr < cblock const > const & , bool & , connecttrace & ) src / validation . cpp : <number> <time> ( bitcoind + 0x 4 7 7 3 9 e ) # <number> cchainstate : : activatebestchain ( blockvalidationstate & , std : : __1 : : shared_ptr < cblock const > ) src / validation . cpp : <number> <time> ( bitcoind + 0x 4 7 7 baf ) # <number> node : : threadimport ( chainstatemanager & , std : : __1 : : vector < fs : : path , std : : __1 : : allocator < fs : : path > > , argsmanager const & ) src / node / blockstorage . cpp : <number> <time> ( bitcoind + 0x 2 3 cd74 ) # <number> appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 : : operator ( ) ( ) const src / init . cpp : <number> : <number> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> decltype ( static_cast < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & > ( fp ) ( ) ) std : : __1 : : __invoke < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & > ( appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & > ( appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> std : : __1 : : __function : : __alloc_func < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 , std : : __1 : : allocator < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> std : : __1 : : __function : : __func < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 , std : : __1 : : allocator < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 8 8 8 9 1 f ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 8 8 8 9 1 f ) # <number> util : : tracethread ( char const * , std : : __1 : : function < void ()>) src / util / thread . cpp : <number> : <number> ( bitcoind + 0x 8 8 8 9 1 f ) # <number> decltype ( static_cast < void (*> ( fp ) ( static_cast < char const *>( fp0 ) , static_cast < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > ( fp0 ) ) ) std : : __1 : : __invoke < void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > ( void (* & & ) ( char const * , std : : __1 : : function < void ()>), char const * & & , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( bitcoind + 0x 1 5 7 e6a ) # <number> void std : : __1 : : __thread_execute < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 , 2 ul , 3 ul > ( std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > & , std : : __1 : : __tuple_indices < 2 ul , 3 ul > ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( bitcoind + 0x 1 5 7 e6a ) # <number> void * std : : __1 : : __thread_proxy < std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > > ( void <wink> / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( bitcoind + 0x 1 5 7 e6a ) previous read of size <number> at 0x 7 b3c000008f0 by main thread : # <number> std : : __1 : : vector < cblockindex * , std : : __1 : : allocator < cblockindex *> <sad> : size ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / vector : <number> : <number> ( bitcoind + 0x 1 5 1 7 9 d ) # <number> cchain : : tip ( ) const src / . / chain . h : <number> <time> ( bitcoind + 0x 1 5 1 7 9 d ) # <number> chainstatemanager : : activetip ( ) const src / . / validation . h : <number> <time> ( bitcoind + 0x 1 5 1 7 9 d ) # <number> appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> src / init . cpp : <number> <time> ( bitcoind + 0x 1 5 1 7 9 d ) # <number> appinit ( node : : nodecontext & , int , char * <wink> src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) # <number> main src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) location is heap block of size <number> at 0x 7 b3c00000870 allocated by main thread : # <number> operator new ( unsigned long ) <null> ( bitcoind + 0x 1 3 2 6 6 8 ) # <number> chainstatemanager : : initializechainstate ( ctxmempool * , std : : __1 : : optional <uint256> const & ) src / validation . cpp : <number> <time> ( bitcoind + 0x 4 8 e26b ) # <number> node : : loadchainstate ( bool , chainstatemanager & , ctxmempool * , bool , consensus : : params const & , bool , long , long , long , bool , bool , std : : __1 : : function < bool ( ) > , std : : __1 : : function < void ()>) src / node / chainstate . cpp : <number> <time> ( bitcoind + 0x 2 4 de07 ) # <number> appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> src / init . cpp : <number> <time> ( bitcoind + 0x 1 4 e994 ) # <number> appinit ( node : : nodecontext & , int , char * <wink> src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) # <number> main src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) mutex m131626 ( 0x 7 b3c00000898 ) created at : # <number> pthread_mutex_lock <null> ( bitcoind + 0 xda898 ) # <number> std : : __1 : : mutex : : lock ( ) <null> ( libc + + . so . <number> + 0x 4 9 f35 ) # <number> node : : threadimport ( chainstatemanager & , std : : __1 : : vector < fs : : path , std : : __1 : : allocator < fs : : path > > , argsmanager const & ) src / node / blockstorage . cpp : <number> <time> ( bitcoind + 0x 2 3 cd74 ) # <number> appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 : : operator ( ) ( ) const src / init . cpp : <number> : <number> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> decltype ( static_cast < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & > ( fp ) ( ) ) std : : __1 : : __invoke < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & > ( appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> void std : : __1 : : __invoke_void_return_wrapper < void , true > : : __call < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & > ( appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / invoke . h : <number> : <number> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> std : : __1 : : __function : : __alloc_func < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 , std : : __1 : : allocator < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> std : : __1 : : __function : : __func < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 , std : : __1 : : allocator < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > , void ()>: : operator ( ) ( ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 1 5 8 6 3 e ) # <number> std : : __1 : : __function : : __value_func < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 8 8 8 9 1 f ) # <number> std : : __1 : : function < void ()>: : operator ( ) ( ) const / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __functional / function . h : <number> <time> ( bitcoind + 0x 8 8 8 9 1 f ) # <number> util : : tracethread ( char const * , std : : __1 : : function < void ()>) src / util / thread . cpp : <number> : <number> ( bitcoind + 0x 8 8 8 9 1 f ) # <number> decltype ( static_cast < void (*> ( fp ) ( static_cast < char const *>( fp0 ) , static_cast < appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > ( fp0 ) ) ) std : : __1 : : __invoke < void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > ( void (* & & ) ( char const * , std : : __1 : : function < void ()>), char const * & & , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / type_traits : <number> : <number> ( bitcoind + 0x 1 5 7 e6a ) # <number> void std : : __1 : : __thread_execute < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 , 2 ul , 3 ul > ( std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > & , std : : __1 : : __tuple_indices < 2 ul , 3 ul > ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( bitcoind + 0x 1 5 7 e6a ) # <number> void * std : : __1 : : __thread_proxy < std : : __1 : : tuple < std : : __1 : : unique_ptr < std : : __1 : : __thread_struct , std : : __1 : : default_delete < std : : __1 : : __thread_struct > > , void (* ) ( char const * , std : : __1 : : function < void ()>), char const * , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 > > ( void <wink> / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> : <number> ( bitcoind + 0x 1 5 7 e6a ) mutex m151 ( 0x 5 5 aacb8ea030 ) created at : # <number> pthread_mutex_init <null> ( bitcoind + 0 xbed2f ) # <number> std : : __1 : : recursive_mutex : : recursive_mutex ( ) <null> ( libc + + . so . <number> + 0x 4 9 fb3 ) # <number> __libc_start_main <null> ( libc . so . <number> + 0x 2 9 eba ) mutex m131553 ( 0x 7 b4c000042e0 ) created at : # <number> pthread_mutex_init <null> ( bitcoind + 0 xbed2f ) # <number> std : : __1 : : recursive_mutex : : recursive_mutex ( ) <null> ( libc + + . so . <number> + 0x 4 9 fb3 ) # <number> std : : __1 : : __unique_if <ctxmempool> : : __unique_single std : : __1 : : make_unique < ctxmempool , cblockpolicyestimator * , int const & > ( cblockpolicyestimator * & & , int const & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __memory / unique_ptr . h : <number> <time> ( bitcoind + 0x 1 5 c81d ) # <number> appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> src / init . cpp : <number> <time> ( bitcoind + 0x 1 4 e7b4 ) # <number> appinit ( node : : nodecontext & , int , char * <wink> src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) # <number> main src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) thread t22 ' b - loadblk ' ( tid = <number> , running ) created by main thread at : # <number> pthread_create <null> ( bitcoind + 0 xbd5bd ) # <number> std : : __1 : : __libcpp_thread_create ( unsigned long * , void * (* ) ( void <wink> , void <wink> / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __threading_support : <number> <time> ( bitcoind + 0x 1 5 5 e06 ) # <number> std : : __1 : : thread : : thread < void (* ) ( char const * , std : : __1 : : function < void ()>), char const ( & ) [ <number> ] , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 , void > ( void (* & & ) ( char const * , std : : __1 : : function < void ()>), char const ( & ) [ <number> ] , appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> : : $ _7 & & ) / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / thread : <number> <time> ( bitcoind + 0x 1 5 5 e06 ) # <number> appinitmain ( node : : nodecontext & , interfaces : : blockandheadertipinfo <wink> src / init . cpp : <number> <time> ( bitcoind + 0x 1 5 0 1 6 4 ) # <number> appinit ( node : : nodecontext & , int , char * <wink> src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) # <number> main src / bitcoind . cpp : <number> <time> ( bitcoind + 0x 1 3 3 fd2 ) summary : threadsanitizer race / usr / lib / llvm - <number> / bin / . <repeated> / include / c + + / v1 / __utility / swap . h : <number> : <number> in std : : __1 : : enable_if < ( is_move_constructible < cblockindex * *> : : value ) & & ( is_move_assignable < cblockindex * *> : : value ) , void > : : type std : : __1 : : swap < cblockindex * *>( cblockindex * * & , cblockindex * * & ) = = = = = = = = = = = = = = = = = = ` ` ` from <url>",0
bitcoin/bitcoin,"ci failure in feature_fee_estimation . py <url> ` ` ` traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in run_test self . sanity_check_estimates_range ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in sanity_check_estimates_range check_estimates ( self . nodes [ <number> ] , self . fees_per_kb ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in check_estimates check_smart_estimates ( node , fees_seen ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - x86_64 - pc - linux - gnu / test / functional / feature_fee_estimation . py "" , line <number> , in check_smart_estimates raise assertionerror ( assertionerror fee ( <number> ) larger than last fee ( <number> ) for lower number of confirms ` ` `",0
bitcoin/bitcoin,"node will not serve blocks when connect = <number> , listen = <number> set due to ibd logic i have a <number> machine setup on my local network that i use for testing and i have performed dozens of syncs without any issues until recently . i have a node on a laptop that is configured not to make any outbound connections via connect = <number> but does listen for connections via listen = <number> . this node , as a result , never downloads new blocks . i then run a node on a desktop that it set to only connect to the laptop node via connect =< local network ip > * * expected behavior * * this node then downloads all of the blocks it can from the laptop node and then stops . this has been the case for many months of testing i have performed . * * actual behavior * * however , when trying to run a test recently , the desktop node wasn ' t syncing . after enabling net debugging i see that the laptop node is deciding not to serve any blocks because it considers itself to be in ibd . this is odd because it ' s unclear why it would know that there are more blocks available out on the network when it is explicitly told not to connect to any peers . * * to reproduce * * hard to reproduce this far . easy to fix by having the main node connect to other peers and sync to chain tip . * * system information * * bitcoin core <number> on debian , official build < - - any extra information that might be useful in the debugging process . - - > example startup log from previous testing runs that went as expected . i find it interesting that it says "" progress = <number> "" <pre> <number> - <number> - 1 2 t <time> z bitcoin core version v22 . <number> ( release build ) <number> - <number> - 1 2 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 a89e854d57e5667df88f1cdef6fde2fbca1de5b639ad have valid signatures . <number> - <number> - 1 2 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 fa4663bbbe19f82de <phone> - <number> - 1 2 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) , avx2 ( 8 way ) ' sha256 implementation <number> - <number> - 1 2 t <time> z using rdseed as additional entropy source <number> - <number> - 1 2 t <time> z using rdrand as an additional entropy source <number> - <number> - 1 2 t <time> z default data directory / home / jameson / . bitcoin <number> - <number> - 1 2 t <time> z using data directory / media / jameson / blockchain / bitcoin <number> - <number> - 1 2 t <time> z config file : / media / jameson / blockchain / bitcoin / bitcoin . conf ( not found , skipping ) <number> - <number> - 1 2 t <time> z config file arg : blockfilterindex = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : connect = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : datadir =""/ media / jameson / blockchain / bitcoin "" <number> - <number> - 1 2 t <time> z config file arg : dns = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : dnsseed = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : listen = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : rpcauth = * * * * <number> - <number> - 1 2 t <time> z config file arg : rpcthreads = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : rpcworkqueue = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : server = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : txindex = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : wallet = "" <number> "" <number> - <number> - 1 2 t <time> z config file arg : zmqpubrawblock = "" tcp :// <number> . <number> . <time> <number> "" <number> - <number> - 1 2 t <time> z config file arg : zmqpubrawtx = "" tcp :// <number> . <number> . <time> <number> "" <number> - <number> - 1 2 t <time> z command - line arg : daemon = "" "" <number> - <number> - 1 2 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 1 2 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 1 2 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 1 2 t <time> z script verification uses <number> additional threads <number> - <number> - 1 2 t <time> z scheduler thread start <number> - <number> - 1 2 t <time> z http : creating work queue of depth <number> <number> - <number> - 1 2 t <time> z using random cookie authentication . <number> - <number> - 1 2 t <time> z generated rpc authentication cookie / media / jameson / blockchain / bitcoin / . cookie <number> - <number> - 1 2 t <time> z using rpcauth authentication . <number> - <number> - 1 2 t <time> z http : starting <number> worker threads <number> - <number> - 1 2 t <time> z using wallet directory / media / jameson / blockchain / bitcoin <number> - <number> - 1 2 t <time> z init message : verifying wallet ( s ) … <number> - <number> - 1 2 t <time> z warning : skipping - wallet path that does not exist . failed to load database path ' / media / jameson / blockchain / bitcoin / <number> ' . path does not exist . <number> - <number> - 1 2 t <time> z init message : loading banlist … <number> - <number> - 1 2 t <time> z setnetworkactive : true <number> - <number> - 1 2 t <time> z using / <number> prefix for ip bucketing <number> - <number> - 1 2 t <time> z cache configuration : <number> - <number> - 1 2 t <time> z * using <number> mib for block index database <number> - <number> - 1 2 t <time> z * using <number> mib for transaction index database <number> - <number> - 1 2 t <time> z * using <number> mib for basic block filter index database <number> - <number> - 1 2 t <time> z * using <number> mib for chain state database <number> - <number> - 1 2 t <time> z * using <number> mib for in - memory utxo set ( plus up to <number> mib of unused mempool space ) <number> - <number> - 1 2 t <time> z init message : loading block index … <number> - <number> - 1 2 t <time> z switching active chainstate to chainstate [ ibd ] @ height - <number> ( null ) <number> - <number> - 1 2 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / blocks / index <number> - <number> - 1 2 t <time> z opened leveldb successfully <number> - <number> - 1 2 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / blocks / index : <number> <number> - <number> - 1 2 t <time> z loadblockindexdb : last block file = <number> <number> - <number> - 1 2 t <time> z loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) <number> - <number> - 1 2 t <time> z checking all blk files are present . <repeated> <number> - <number> - 1 2 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / chainstate <number> - <number> - 1 2 t <time> z opened leveldb successfully <number> - <number> - 1 2 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / chainstate : 0 5 e83c6994e2e4d1 <number> - <number> - 1 2 t <time> z loaded best chain : hashbestchain = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 c2190b3b7f475db5a19123e8e19da20af0629e3aeaa1 height = <number> date = <number> - <number> - 1 2 t <time> z progress = <number> . <phone> - <number> - 1 2 t <time> z init message : verifying blocks … <number> - <number> - 1 2 t <time> z verifying last <number> blocks at level <number> <number> - <number> - 1 2 t <time> z [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ done ] . <number> - <number> - 1 2 t <time> z no coin database inconsistencies in last <number> blocks ( <number> transactions ) <number> - <number> - 1 2 t <time> z block index 3 4 5 5 ms <number> - <number> - 1 2 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / indexes / txindex <number> - <number> - 1 2 t <time> z opened leveldb successfully <number> - <number> - 1 2 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / indexes / txindex : <number> <number> - <number> - 1 2 t <time> z txindex thread start <number> - <number> - 1 2 t <time> z txindex is enabled at height <phone> - <number> - 1 2 t <time> z txindex thread exit <number> - <number> - 1 2 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / indexes / blockfilter / basic / db <number> - <number> - 1 2 t <time> z opened leveldb successfully <number> - <number> - 1 2 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / indexes / blockfilter / basic / db : <number> <number> - <number> - 1 2 t <time> z basic block filter index thread start <number> - <number> - 1 2 t <time> z basic block filter index is enabled at height <phone> - <number> - 1 2 t <time> z basic block filter index thread exit <number> - <number> - 1 2 t <time> z block tree size = <phone> - <number> - 1 2 t <time> z nbestheight = <phone> - <number> - 1 2 t <time> z loadblk thread start <number> - <number> - 1 2 t <time> z bound to <number> . <number> : <number> <number> - <number> - 1 2 t <time> z bound to <happy> : <sad> <number> <number> - <number> - 1 2 t <time> z bound to <number> . <number> : <number> <number> - <number> - 1 2 t <time> z torcontrol thread start <number> - <number> - 1 2 t <time> z init message : loading p2p addresses … <number> - <number> - 1 2 t <time> z leaving initialblockdownload ( latching to false ) <number> - <number> - 1 2 t <time> z loaded <number> addresses from peers . dat 1 2 2 ms <number> - <number> - 1 2 t <time> z init message : starting network threads … <number> - <number> - 1 2 t <time> z dns seeding disabled <number> - <number> - 1 2 t <time> z init message : done loading <number> - <number> - 1 2 t <time> z addcon thread start <number> - <number> - 1 2 t <time> z net thread start <number> - <number> - 1 2 t <time> z msghand thread start <number> - <number> - 1 2 t <time> z imported mempool transactions from disk : <number> succeeded , <number> failed , <number> expired , <number> already there , <number> waiting for initial broadcast <number> - <number> - 1 2 t <time> z loadblk thread exit </pre> here ' s the network debug log ; note it says "" progress = <number> "" why did this change if the node was instructed to never connect to any other nodes outside of my lan ? <pre> <number> - <number> - 2 9 t <time> z bitcoin core version v23 . <number> ( release build ) <number> - <number> - 2 9 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 2 d314a259755ca65944e68df6b12a067ea8f1f5a7091 have valid signatures . <number> - <number> - 2 9 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 9 2 7 cdceccbd5209e81e80db <number> - <number> - 2 9 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) , avx2 ( 8 way ) ' sha256 implementation <number> - <number> - 2 9 t <time> z using rdseed as additional entropy source <number> - <number> - 2 9 t <time> z using rdrand as an additional entropy source <number> - <number> - 2 9 t <time> z default data directory / home / jameson / . bitcoin <number> - <number> - 2 9 t <time> z using data directory / media / jameson / blockchain / bitcoin <number> - <number> - 2 9 t <time> z config file : / media / jameson / blockchain / bitcoin / bitcoin . conf ( not found , skipping ) <number> - <number> - 2 9 t <time> z config file arg : blockfilterindex = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : connect = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : datadir =""/ media / jameson / blockchain / bitcoin "" <number> - <number> - 2 9 t <time> z config file arg : debug = "" net "" <number> - <number> - 2 9 t <time> z config file arg : dns = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : dnsseed = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : listen = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : rpcauth = * * * * <number> - <number> - 2 9 t <time> z config file arg : rpcthreads = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : rpcworkqueue = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : server = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : txindex = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : wallet = "" <number> "" <number> - <number> - 2 9 t <time> z config file arg : zmqpubrawblock = "" tcp :// <number> . <number> . <time> <number> "" <number> - <number> - 2 9 t <time> z config file arg : zmqpubrawtx = "" tcp :// <number> . <number> . <time> <number> "" <number> - <number> - 2 9 t <time> z command - line arg : daemon = "" "" <number> - <number> - 2 9 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 2 9 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 2 9 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 2 9 t <time> z script verification uses <number> additional threads <number> - <number> - 2 9 t <time> z scheduler thread start <number> - <number> - 2 9 t <time> z http : creating work queue of depth <number> <number> - <number> - 2 9 t <time> z using random cookie authentication . <number> - <number> - 2 9 t <time> z generated rpc authentication cookie / media / jameson / blockchain / bitcoin / . cookie <number> - <number> - 2 9 t <time> z using rpcauth authentication . <number> - <number> - 2 9 t <time> z http : starting <number> worker threads <number> - <number> - 2 9 t <time> z using wallet directory / media / jameson / blockchain / bitcoin <number> - <number> - 2 9 t <time> z init message : verifying wallet ( s ) … <number> - <number> - 2 9 t <time> z warning : skipping - wallet path that does not exist . failed to load database path ' / media / jameson / blockchain / bitcoin / <number> ' . path does not exist . <number> - <number> - 2 9 t <time> z using / <number> prefix for ip bucketing <number> - <number> - 2 9 t <time> z init message : loading p2p addresses … <number> - <number> - 2 9 t <time> z loaded <number> addresses from peers . dat 0 ms <number> - <number> - 2 9 t <time> z init message : loading banlist … <number> - <number> - 2 9 t <time> z banlist . dat ignored because it can only be read by bitcoin core version <number> . x . remove "" / media / jameson / blockchain / bitcoin / banlist . dat "" to silence this warning . <number> - <number> - 2 9 t <time> z loaded <number> banned node addresses / subnets 0 ms <number> - <number> - 2 9 t <time> z net : setting try another outbound peer = false <number> - <number> - 2 9 t <time> z setnetworkactive : true <number> - <number> - 2 9 t <time> z cache configuration : <number> - <number> - 2 9 t <time> z * using <number> mib for block index database <number> - <number> - 2 9 t <time> z * using <number> mib for transaction index database <number> - <number> - 2 9 t <time> z * using <number> mib for basic block filter index database <number> - <number> - 2 9 t <time> z * using <number> mib for chain state database <number> - <number> - 2 9 t <time> z * using <number> mib for in - memory utxo set ( plus up to <number> mib of unused mempool space ) <number> - <number> - 2 9 t <time> z init message : loading block index … <number> - <number> - 2 9 t <time> z switching active chainstate to chainstate [ ibd ] @ height - <number> ( null ) <number> - <number> - 2 9 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / blocks / index <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / blocks / index : <number> <number> - <number> - 2 9 t <time> z loadblockindexdb : last block file = <number> <number> - <number> - 2 9 t <time> z loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) <number> - <number> - 2 9 t <time> z checking all blk files are present . <repeated> <number> - <number> - 2 9 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / chainstate <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / chainstate : 0 5 e83c6994e2e4d1 <number> - <number> - 2 9 t <time> z loaded best chain : hashbestchain = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 4 ccfdf28b7b062aec08384456eba68e2070fc61ec811 height = <number> date = <number> - <number> - 1 0 t <time> z progress = <number> . <phone> - <number> - 2 9 t <time> z init message : verifying blocks … <number> - <number> - 2 9 t <time> z verifying last <number> blocks at level <number> <number> - <number> - 2 9 t <time> z [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ done ] . <number> - <number> - 2 9 t <time> z no coin database inconsistencies in last <number> blocks ( <number> transactions ) <number> - <number> - 2 9 t <time> z block index 3 7 4 4 ms <number> - <number> - 2 9 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / indexes / txindex <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / indexes / txindex : <number> <number> - <number> - 2 9 t <time> z txindex thread start <number> - <number> - 2 9 t <time> z txindex is enabled at height <phone> - <number> - 2 9 t <time> z txindex thread exit <number> - <number> - 2 9 t <time> z opening leveldb in / media / jameson / blockchain / bitcoin / indexes / blockfilter / basic / db <number> - <number> - 2 9 t <time> z opened leveldb successfully <number> - <number> - 2 9 t <time> z using obfuscation key for / media / jameson / blockchain / bitcoin / indexes / blockfilter / basic / db : <number> <number> - <number> - 2 9 t <time> z block tree size = <phone> - <number> - 2 9 t <time> z nbestheight = <phone> - <number> - 2 9 t <time> z basic block filter index thread start <number> - <number> - 2 9 t <time> z basic block filter index is enabled at height <phone> - <number> - 2 9 t <time> z basic block filter index thread exit <number> - <number> - 2 9 t <time> z loadblk thread start <number> - <number> - 2 9 t <time> z torcontrol thread start <number> - <number> - 2 9 t <time> z imported mempool transactions from disk : <number> succeeded , <number> failed , <number> expired , <number> already there , <number> waiting for initial broadcast <number> - <number> - 2 9 t <time> z loadblk thread exit <number> - <number> - 2 9 t <time> z bound to <number> . <number> : <number> <number> - <number> - 2 9 t <time> z bound to <happy> : <sad> <number> <number> - <number> - 2 9 t <time> z bound to <number> . <number> : <number> <number> - <number> - 2 9 t <time> z init message : starting network threads … <number> - <number> - 2 9 t <time> z dns seeding disabled <number> - <number> - 2 9 t <time> z init message : done loading <number> - <number> - 2 9 t <time> z net thread start <number> - <number> - 2 9 t <time> z addcon thread start <number> - <number> - 2 9 t <time> z msghand thread start <number> - <number> - 2 9 t <time> z added connection peer = <number> <number> - <number> - 2 9 t <time> z connection from <number> . <number> <time> <number> accepted <number> - <number> - 2 9 t <time> z received : version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending version ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z send version message : version <number> , blocks = <number> , txrelay = <number> , peer = <number> <number> - <number> - 2 9 t <time> z sending wtxidrelay ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendaddrv2 ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z receive version message : / satoshi : <number> . <number> /: version <number> , blocks = <number> , us =[ : : <sad> <number> , txrelay = <number> , peer = <number> <number> - <number> - 2 9 t <time> z received : wtxidrelay ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendaddrv2 ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : verack ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z initial getheaders ( <number> ) to peer = <number> ( startheight : <number> ) <number> - <number> - 2 9 t <time> z sending getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getaddr ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : sendcmpct ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : ping ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z sending pong ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : getheaders ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z ignoring getheaders from peer = <number> because node is in initial block download <number> - <number> - 2 9 t <time> z received : feefilter ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z received : feefilter of <number> btc / kvb from peer = <number> <number> - <number> - 2 9 t <time> z received ( <number> bytes ) peer = <number> <number> - <number> - 2 9 t <time> z socket closed for peer = <number> <number> - <number> - 2 9 t <time> z disconnecting peer = <number> <number> - <number> - 2 9 t <time> z cleared nodestate for peer = <number> </pre>",0
bitcoin/bitcoin,intermittent win64 ci failure in feature_index_prune . py <url> win64 native [ msvc ] task ` ` ` test <number> - <number> - 2 9 t <time> . 8 4 3 0 0 0 z testframework ( warning ) : not cleaning up dir c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ test_runner_ ₿ _ 🏃 _20220429_140215 \ \ feature_index_prune_242 test <number> - <number> - 2 9 t <time> . 8 4 3 0 0 0 z testframework ( error ) : test failed . test logging available at c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ test_runner_ ₿ _ 🏃 _20220429_140215 \ \ feature_index_prune_242 / test_framework . log test <number> - <number> - 2 9 t <time> . 8 4 3 0 0 0 z testframework ( error ) : node0 stderr error : basic block filter index best block of the index goes beyond pruned data . please disable the index or reindex ( which will download the whole blockchain again ) node1 stderr error : coinstatsindex best block of the index goes beyond pruned data . please disable the index or reindex ( which will download the whole blockchain again ) node2 stderr error block filter index best block of the index goes beyond pruned data . please disable the index or reindex ( which will download the whole blockchain again ),0
bitcoin/bitcoin,"wallet_createwallet . py - - legacy - wallet fails on a system with only bdb installed ` ` ` traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / wallet_createwallet . py "" , line <number> , in run_test assert_raises_rpc_error ( - <number> , "" passphrase provided but private keys are disabled . a passphrase is only used to encrypt private keys , so cannot be used for wallets with private keys disabled . "" , file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / test_framework / util . py "" , line <number> , in assert_raises_rpc_error assert try_rpc ( code , message , fun , * args , * * kwds ) , "" no exception raised "" file "" / tmp / cirrus - ci - build / bitcoin - core / test / functional / test_framework / util . py "" , line <number> , in try_rpc raise assertionerror ( assertionerror : expected substring not found in error message : substring : ' passphrase provided but private keys are disabled . a passphrase is only used to encrypt private keys , so cannot be used for wallets with private keys disabled . ' error message without sqlite support ( required for descriptor wallets ) ' .",0
bitcoin/bitcoin,"` - torcontrol ` asks tor to connect to port <number> , and tor refuses < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > i am using the ` - torcontrol ` and ` - torpassword ` directives to let bitcoind set up a tor onion service . < ! - - describe the issue - - > * * expected behavior * * bitcoind sets up an onion service and incoming connections will be received via tor . * * actual behavior * * in the tor log , i see : > application asked to connect to port <number> . refusing . bitcoind does not receive any incoming connections via tor . < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * system information * * bitcoin core <number> on signet or testnet chains , self - compiled alpine based image , running in docker <date> on ubuntu <number> lts . tor <number> . <number> , self - compiled image , running in docker <date> on ubuntu <number> lts . both are composed via docker - compose <number> . <number> . < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - > tor . log : ` ` ` tor_1 | <date> <time> . <number> [ notice ] tor can not help you if you use it wrong ! learn how to be safe at <url> tor_1 | <date> <time> . <number> [ notice ] read configuration file "" / etc / tor / torrc "" . tor_1 | <date> <time> . <number> [ warn ] you have a controlport set to accept connections from a non - local address . this means that programs not running on your computer can reconfigure your tor . that ' s pretty bad , since the controller protocol is not encrypted ! maybe you should just listen on <number> . <number> and use a tool like stunnel or ssh to encrypt remote connections to your control port . tor_1 | <date> <time> . <number> [ warn ] you specified a public address ' <number> . <number> : <number> ' for socksport . other people on the internet might find your computer and use it as an open proxy . please do not allow this unless you have a good reason . tor_1 | <date> <time> . <number> [ warn ] you have a controlport set to accept connections from a non - local address . this means that programs not running on your computer can reconfigure your tor . that ' s pretty bad , since the controller protocol is not encrypted ! maybe you should just listen on <number> . <number> and use a tool like stunnel or ssh to encrypt remote connections to your control port . tor_1 | <date> <time> . <number> [ notice ] opening socks listener on <number> . <number> : <number> tor_1 | <date> <time> . <number> [ notice ] opened socks listener connection ( ready ) on <number> . <number> : <number> tor_1 | <date> <time> . <number> [ notice ] opening control listener on <number> . <number> : <number> tor_1 | <date> <time> . <number> [ notice ] opened control listener connection ( ready ) on <number> . <number> : <number> tor_1 | <date> <time> . <number> [ notice ] parsing geoip ipv4 file / usr / local / share / tor / geoip . tor_1 | <date> <time> . <number> [ notice ] parsing geoip ipv6 file / usr / local / share / tor / geoip6 . tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( starting ) : starting tor_1 | <date> <time> . <number> [ notice ] starting with guard context "" default "" tor_1 | <date> <time> . <number> [ notice ] new control connection opened from <number> . <number> . tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( conn ) : connecting to a relay tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( conn_done ) : connected to a relay tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( handshake ) : handshaking with a relay tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( handshake_done ) : handshake with a relay done tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( onehop_create ) : establishing an encrypted directory connection tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( requesting_status ) : asking for networkstatus consensus tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( loading_status ) : loading networkstatus consensus tor_1 | <date> <time> . <number> [ notice ] i learned some more directory information , but not enough to build a circuit : we have no usable consensus . tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( loading_keys ) : loading authority key certs tor_1 | <date> <time> . <number> [ notice ] the current consensus has no exit nodes . tor can only build internal paths , such as paths to onion services . tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( requesting_descriptors ) : asking for relay descriptors tor_1 | <date> <time> . <number> [ notice ] i learned some more directory information , but not enough to build a circuit : we need more microdescriptors : we have <number> / <number> , and can only build <percent> of likely paths . ( we have <percent> of guards bw , <percent> of midpoint bw , and <percent> of end bw ( no exits in consensus , using mid ) = <percent> of path bw . ) tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( loading_descriptors ) : loading relay descriptors tor_1 | <date> <time> . <number> [ notice ] the current consensus contains exit nodes . tor can build exit and internal paths . tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( loading_descriptors ) : loading relay descriptors tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( loading_descriptors ) : loading relay descriptors tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( loading_descriptors ) : loading relay descriptors tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( enough_dirinfo ) : loaded enough directory info to build circuits tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( ap_conn ) : connecting to a relay to build circuits tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( ap_conn_done ) : connected to a relay to build circuits tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( ap_handshake ) : finishing handshake with a relay to build circuits tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( ap_handshake_done ) : handshake finished with a relay to build circuits tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( circuit_create ) : establishing a tor circuit tor_1 | <date> <time> . <number> [ notice ] bootstrapped <percent> ( done ) : done tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . tor_1 | <date> <time> . <number> [ notice ] application asked to connect to port <number> . refusing . tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . tor_1 | <date> <time> . <number> [ notice ] application asked to connect to port <number> . refusing . tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . tor_1 | <date> <time> . <number> [ notice ] application asked to connect to port <number> . refusing . tor_1 | <date> <time> . <number> [ notice ] application asked to connect to port <number> . refusing . tor_1 | <date> <time> . <number> [ notice ] application asked to connect to port <number> . refusing . tor_1 | <date> <time> . <number> [ notice ] application asked to connect to port <number> . refusing . tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . tor_1 | <date> <time> . <number> [ notice ] application asked to connect to port <number> . refusing . tor_1 | <date> <time> . <number> [ notice ] closed <number> streams for service [ scrubbed ] . onion for reason resolve failed . fetch status : no more hsdir available to query . ` ` ` as you can see , there is an incoming control connection : ` new control connection opened from <number> . <number> . ` ( that ' s my bitcoind container ) then : ` application asked to connect to port <number> . refusing . ` bitcoind . log , just in case : ` ` ` bitcoind_1 | / entrypoint . sh : assuming arguments for bitcoind bitcoind_1 | / entrypoint . sh : setting data directory to / home / bitcoin / . bitcoin bitcoind_1 | bitcoind_1 | bitcoin core version v23 . <number> ( release build ) bitcoind_1 | signet derived magic ( message start ) : 0 a03cf40 bitcoind_1 | assuming ancestors of block 0 0 0 0 0 1 1 2 8 5 2 4 8 4 b5fe <phone> f93cfd2723279af3464e478aee35115256ef have valid signatures . bitcoind_1 | setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 de26b0e471 bitcoind_1 | using the ' x86_shani ( 1 way , 2 way ) ' sha256 implementation bitcoind_1 | using rdseed as additional entropy source bitcoind_1 | using rdrand as an additional entropy source bitcoind_1 | startup time : <number> - <number> - 2 5 t <time> z bitcoind_1 | default data directory / home / bitcoin / . bitcoin bitcoind_1 | using data directory / home / bitcoin / . bitcoin / signet bitcoind_1 | config file : / home / bitcoin / . bitcoin / bitcoin . conf ( not found , skipping ) bitcoind_1 | command - line arg : blockfilterindex = "" basic "" bitcoind_1 | command - line arg : datadir =""/ home / bitcoin / . bitcoin "" bitcoind_1 | command - line arg : disablewallet = "" <number> "" bitcoind_1 | command - line arg : discover = "" <number> "" bitcoind_1 | command - line arg : dnsseed = "" <number> "" bitcoind_1 | command - line arg : i2pacceptincoming = "" <number> "" bitcoind_1 | command - line arg : i2psam = "" i2pd : <number> "" bitcoind_1 | command - line arg : listen = "" <number> "" bitcoind_1 | command - line arg : logtimestamps = "" <number> "" bitcoind_1 | command - line arg : maxconnections = "" <number> "" bitcoind_1 | command - line arg : onion = "" tor : <number> "" bitcoind_1 | command - line arg : onlynet = "" i2p "" bitcoind_1 | command - line arg : onlynet = "" onion "" bitcoind_1 | command - line arg : par = "" <number> "" bitcoind_1 | command - line arg : peerblockfilters = "" <number> "" bitcoind_1 | command - line arg : peerbloomfilters = "" <number> "" bitcoind_1 | command - line arg : rpcallowip = "" <number> . <number> / <number> "" bitcoind_1 | command - line arg : rpcauth = * * * * bitcoind_1 | command - line arg : rpcbind = * * * * bitcoind_1 | command - line arg : rpcthreads = "" <number> "" bitcoind_1 | command - line arg : signet = "" <number> "" bitcoind_1 | command - line arg : torcontrol = "" tor : <number> "" bitcoind_1 | command - line arg : torpassword = * * * * bitcoind_1 | command - line arg : txindex = "" <number> "" bitcoind_1 | using at most <number> automatic connections ( <number> file descriptors available ) bitcoind_1 | using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements bitcoind_1 | using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements bitcoind_1 | script verification uses <number> additional threads bitcoind_1 | wallet disabled ! bitcoind_1 | scheduler thread start bitcoind_1 | warning : the rpc server is not safe to expose to untrusted networks such as the public internet bitcoind_1 | http : creating work queue of depth <number> bitcoind_1 | using random cookie authentication . bitcoind_1 | generated rpc authentication cookie / home / bitcoin / . bitcoin / signet / . cookie bitcoind_1 | using rpcauth authentication . bitcoind_1 | http : starting <number> worker threads bitcoind_1 | using / <number> prefix for ip bucketing bitcoind_1 | init message : loading p2p addresses … bitcoind_1 | loaded <number> addresses from peers . dat 1 ms bitcoind_1 | init message : loading banlist … bitcoind_1 | setnetworkactive : true bitcoind_1 | cache configuration : bitcoind_1 | * using <number> mib for block index database bitcoind_1 | * using <number> mib for transaction index database bitcoind_1 | * using <number> mib for basic block filter index database bitcoind_1 | * using <number> mib for chain state database bitcoind_1 | * using <number> mib for in - memory utxo set ( plus up to <number> mib of unused mempool space ) bitcoind_1 | init message : loading block index … bitcoind_1 | switching active chainstate to chainstate [ ibd ] @ height - <number> ( null ) bitcoind_1 | opening leveldb in / home / bitcoin / . bitcoin / signet / blocks / index bitcoind_1 | opened leveldb successfully bitcoind_1 | using obfuscation key for / home / bitcoin / . bitcoin / signet / blocks / index : <number> bitcoind_1 | loadblockindexdb : last block file = <number> bitcoind_1 | loadblockindexdb : last block file info : cblockfileinfo ( blocks = <number> , size = <number> , heights = <number> . <repeated> <number> , time = <number> - <number> - <number> . <repeated> <number> - <number> - <number> ) bitcoind_1 | checking all blk files are present . <repeated> bitcoind_1 | opening leveldb in / home / bitcoin / . bitcoin / signet / chainstate bitcoind_1 | opened leveldb successfully bitcoind_1 | using obfuscation key for / home / bitcoin / . bitcoin / signet / chainstate : 5 f5400e5be1d375a bitcoind_1 | loaded best chain : hashbestchain = 0 0 0 0 0 1 5 8 8 9 6 b9a56d815300f485b244d183936eb787c88eab0ba1cf3e2d8fcaf height = <number> date = <number> - <number> - 2 5 t <time> z progress = <number> bitcoind_1 | init message : verifying blocks … bitcoind_1 | verifying last <number> blocks at level <number> bitcoind_1 | [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ done ] . bitcoind_1 | no coin database inconsistencies in last <number> blocks ( <number> transactions ) bitcoind_1 | block index 1 0 3 8 ms bitcoind_1 | opening leveldb in / home / bitcoin / . bitcoin / signet / indexes / txindex bitcoind_1 | opened leveldb successfully bitcoind_1 | using obfuscation key for / home / bitcoin / . bitcoin / signet / indexes / txindex : <number> bitcoind_1 | txindex thread start bitcoind_1 | opening leveldb in / home / bitcoin / . bitcoin / signet / indexes / blockfilter / basic / db bitcoind_1 | txindex is enabled at height <number> bitcoind_1 | txindex thread exit bitcoind_1 | opened leveldb successfully bitcoind_1 | using obfuscation key for / home / bitcoin / . bitcoin / signet / indexes / blockfilter / basic / db : <number> bitcoind_1 | basic block filter index thread start bitcoind_1 | basic block filter index is enabled at height <number> bitcoind_1 | basic block filter index thread exit bitcoind_1 | loadblk thread start bitcoind_1 | block tree size = <number> bitcoind_1 | nbestheight = <number> bitcoind_1 | torcontrol thread start bitcoind_1 | leaving initialblockdownload ( latching to false ) bitcoind_1 | bound to <number> . <number> . <time> <number> bitcoind_1 | bound to <happy> : <sad> <number> bitcoind_1 | bound to <number> . <number> . <time> <number> bitcoind_1 | loaded <number> addresses from "" anchors . dat "" bitcoind_1 | <number> block - relay - only anchors will be tried for connections . bitcoind_1 | init message : starting network threads … bitcoind_1 | dns seeding disabled bitcoind_1 | net thread start bitcoind_1 | msghand thread start bitcoind_1 | i2paccept thread start bitcoind_1 | opencon thread start bitcoind_1 | addcon thread start bitcoind_1 | init message : done loading bitcoind_1 | imported mempool transactions from disk : <number> succeeded , <number> failed , <number> expired , <number> already there , <number> waiting for initial broadcast bitcoind_1 | loadblk thread exit bitcoind_1 | tor : got service id x <elongated> , advertising service x <elongated> . onion : <number> bitcoind_1 | addlocal ( x <elongated> . onion : <number> ) bitcoind_1 | i2p : sam session created : session id = eeb28ebf5c , my address = x <elongated> . b32 . i2p : <number> bitcoind_1 | addlocal ( x <elongated> . b32 . i2p : <number> ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | updatetip : new best = 0 0 0 0 0 0 dd9afeb8d7a6e63dbf99aac137e38dc73d9acd6f58de0a0366c388681d height = <number> version =0 x20000000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 5 t <time> z ' progress = <number> cache = <number> . 0 mib ( 1 1 5 txo ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | socks5 ( ) connect to m42cdyruu4g4mcrbku4q5faklcr6wa3yq2syu4f6ga634nc2uc5w5vad . onion : <number> failed : host unreachable bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | socks5 ( ) connect to cr423k6sqllxbvtd4nvriy5dvqijly2eaxewjjvxxqjzjba2p2ggqdid . onion : <number> failed : host unreachable bitcoind_1 | socks5 ( ) connect to qscbjfqbglaoge2juooutgliw7uipjoyrs2puy5key23vcpl3j3eirqd . onion : <number> failed : host unreachable bitcoind_1 | socks5 ( ) connect to qb77j7stj2sq3ags3nn4gmfs3ts6k7xwyc5sxows7k5ugn36a3cljyyd . onion : <number> failed : host unreachable bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | socks5 ( ) connect to d27tvdmi6wjjlffjyhm5mogwsw3433jxkaiwhti32eagvljdzseilqqd . onion : <number> failed : host unreachable bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( outbound - full - relay ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( block - relay - only ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( block - relay - only ) bitcoind_1 | socks5 ( ) connect to okdqiz5nlhsoofaorxgjbrmqnywkxvlr3eswytjdtyx5ktljnfwc3lid . onion : <number> failed : host unreachable bitcoind_1 | socks5 ( ) connect to tm7eh4voltdm25wexfsyh6hzvdvmhgjjj4jbdr7lzaihb5ejivkcakqd . onion : <number> failed : host unreachable bitcoind_1 | socks5 ( ) connect to 3 ysg6mt5toaa4pfg2onva <time> oyo7swxkziv6i3bjuejp7qg5etz6m5id . onion : <number> failed : host unreachable bitcoind_1 | socks5 ( ) connect to m42cdyruu4g4mcrbku4q5faklcr6wa3yq2syu4f6ga634nc2uc5w5vad . onion : <number> failed : host unreachable bitcoind_1 | updatetip : new best = <phone> b391d8b8017d50356ad231fd60d97d5b6974a1a4a42bcdb386d6bc height = <number> version =0 x20000000 log2_work = <number> tx = <number> date = ' <number> - <number> - 2 5 t <time> z ' progress = <number> cache = <number> . 0 mib ( 1 3 1 txo ) bitcoind_1 | new outbound peer connected : version : <number> , blocks = <number> , peer = <number> ( block - relay - only ) bitcoind_1 | socks5 ( ) connect to cr423k6sqllxbvtd4nvriy5dvqijly2eaxewjjvxxqjzjba2p2ggqdid . onion : <number> failed : host unreachable bitcoind_1 | socks5 ( ) connect to okdqiz5nlhsoofaorxgjbrmqnywkxvlr3eswytjdtyx5ktljnfwc3lid . onion : <number> failed unreachable ` ` `",0
bitcoin/bitcoin,permissions corrupted in gen - sdk macosx headers i think # <number> broke the macos sdk : ` ` ` guest <user> / tmp / xcode - <number> - 1 2 b45b - extracted - sdk - with - libcxx - headers $ ls - al total <number> drwxr - xr - x <number> guest users <date> <time> . / drwxrwxrwt <number> root root <date> <time> . <repeated> / - - - x - - - r - - <number> guest users <date> entitlements . plist - - - x - - - r - - <number> guest users <date> sdksettings . json - - - x - - - r - - <number> guest users <date> sdksettings . plist drwxr - xr - x <number> guest users <date> system / drwxr - xr - x <number> guest users <date> usr / ` ` ` causing the guix build to fail with : ` ` ` checking for x86_64 - apple - darwin - gcc . <repeated> env - u c_include_path - u cplus_include_path - u objc_include_path - u objcplus_include_path - u cpath - u library_path / home / kvaciral / . guix - profile / bin / clang - - target =x 8 6 _64 - apple - darwin - mmacosx - version - min = <number> - b / bitcoin / depends / x86_64 - apple - darwin / native / bin - mlinker - version = <number> - isysroot / bitcoin / depends / sdks / xcode - <number> - 1 2 b45b - extracted - sdk - with - libcxx - headers - xclang - internal - externc - isystem / gnu / store / v770rvqs8q21mbzwb3gkihr2glgn <time> - clang - <number> . <number> / lib / clang / <number> . <number> / include - xclang - internal - externc - isystem / bitcoin / depends / sdks / xcode - <number> - 1 2 b45b - extracted - sdk - with - libcxx - headers / usr / include checking whether the c compiler works . <repeated> no configure : error : in ` / bitcoin / depends / work / build / x86_64 - apple - darwin / libevent / <date> - stable - 6 3 9 5 cab7fb6 ' : configure : error : c compiler cannot create executables see ` config . log ' for more details make : * * * [ [ funcs . mk : <number> ] ( <url> / bitcoin / depends / work / build / x86_64 - apple - darwin / libevent / <date> - stable - 6 3 9 5 cab7fb6 / . / . stamp_configured ] error <number> make directory ' / bitcoin / depends ' kvaciral <user> : ~ / projects / bitcoin $ ` ` ` reported by <user> .,0
bitcoin/bitcoin,intermittent failure in feature_fee_estimation . py observed in # <number> ( <url> but very likely unrelated . looks to me that a testmempoolaccept rpc call issued by the mini - wallet timed out - so it seems that it occurs after the # <number> rework but has a root cause in bitcoind ? ` ` ` node1 <number> - <number> - 1 1 t <time> . 4 5 6 1 1 7 z [ httpworker . <number> ] [ rpc / request . cpp : <number> ] [ parse ] threadrpcserver method = testmempoolaccept user = __cookie__ node1 <number> - <number> - 1 1 t <time> . 6 3 5 8 7 0 z [ msghand ] [ net . cpp : <number> ] [ pushmessage ] sending ping ( <number> bytes ) peer = <number> node1 <number> - <number> - 1 1 t <time> . 6 6 9 5 9 1 z [ scheduler ] [ random . cpp : <number> ] [ seedperiodic ] feeding <number> bytes of dynamic environment data into rng node0 <number> - <number> - 1 1 t <time> . 6 6 9 6 9 9 z [ net ] [ net . cpp : <number> ] [ sockethandlerconnected ] socket closed for peer = <number> node0 <number> - <number> - 1 1 t <time> . 6 7 1 0 7 5 z [ net ] [ net . cpp : <number> ] [ closesocketdisconnect ] disconnecting peer = <number> ` ` `,0
bitcoin/bitcoin,"crash when creating wallet via bitcoin - cli * description <emphasis> * i expect to be able to create and load a wallet with bitcoin cli using the command "" bitcoin - cli createwallet mywallet . dat "" but it fails and bitcoin core crashes . the wallet appears to be partially created and the folder does exist . i also have that wallet listed as one to load via the config . the crash then causes bitcoin to restart via the systemd service and when it restarts it exits with an error indicating the wallet cannot be read . * * expected behavior * * i expected the wallet to be created . this works fine on bitcoin core <number> , but fails on <number> . * * actual behavior * * bitcoin crashes and a corrupt wallet is made . this causes bitcoin to reboot , attempt to read the new wallet , and exit again leading to a cyclic restart . * reliability <emphasis> * i can reliably re - create it , but only on one device . on another very similar device , the issue is not present . * version <emphasis> * v22 . <number> from the website . * * device info * * debian , amd64 . linux mynode <number> . <number> - <number> - amd64 # <number> smp debian <date> - <number> ( <number> - <number> - <number> ) x86_64 gnu / linux * gui <emphasis> * not gui related . * * cli output when creating wallet * * ` ` ` admin <user> : ~ $ bitcoin - cli createwallet break2 error : timeout on transient error : could not connect to the server <number> . <number> : <number> ( error code <number> - "" eof reached "" ) make sure the bitcoind server is running and that you are connecting to the correct rpc port . admin <user> : ~ $ ` ` ` * * log when creating wallet * * ( read bottom to top ) ` ` ` . <repeated> <number> - <number> - 0 8 t <time> z bitcoin core version v22 . <number> ( release build ) <crash> <number> - <number> - 0 8 t <time> z berkeleyenvironment : : open : logdir <annoyed> home / bitcoin / . bitcoin / break2 / database errorfile <annoyed> home / bitcoin / . bitcoin / break2 / db . log <number> - <number> - 0 8 t <time> z using wallet / home / bitcoin / . bitcoin / break2 / wallet . dat <number> - <number> - 0 8 t <time> z using berkeleydb version berkeley db <date> : ( <date> ) <number> - <number> - 0 8 t <time> z updatetip : new best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 ce88f1e73e85f7463f002b093b635e6fbdfb937937c5 height = <number> version =0 x20000000 log2_work = <number> tx = <number> date = ' <number> - <number> - 0 2 t <time> z ' progress = <number> cache = <number> . 6 mib ( 4 6 2 0 4 3 6 txo ) <number> - <number> - 0 8 t <time> z updatetip best = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 6 cd6e6d1ffad655908877051cc7b7b778d7236ae64e14 height = <number> version =0 x20c00000 log2_work = <number> tx = <number> date = ' <number> - <number> - 0 2 t <time> z ' progress = <number> cache = <number> . 4 mib ( 4 6 1 8 9 0 3 txo ) ` ` `",0
bitcoin/bitcoin,"build breaks with . / configure - - enable - debug on macosx ( apple m1 ) with clang <number> this is only broken when i enable the debug flag . $ gcc - - version configured with : - - prefix <annoyed> applications / xcode . app / contents / developer / usr - - with - gxx - include - dir <annoyed> applications / xcode . app / contents / developer / platforms / macosx . platform / developer / sdks / macosx . sdk / usr / include / c + + / <number> . <number> apple clang version <number> . <number> ( clang - <number> . <number> ) target : arm64 - apple - darwin21 . <number> thread model : posix installeddir : / applications / xcode . app / contents / developer / toolchains / xcodedefault . xctoolchain / usr / bin error reported below : in file included from util / system . cpp : <number> : in file included from / opt / homebrew / / include / boost / process . hpp : <number> : in file included from / opt / homebrew / / include / boost / process / async_system . hpp : <number> : in file included from / opt / homebrew / / include / boost / process / child . hpp : <number> : in file included from / opt / homebrew / / include / boost / process / detail / execute_impl . hpp : <number> : / opt / homebrew / / include / boost / process / detail / posix / executor . hpp : <number> <time> : error : non - constant - expression cannot be narrowed from type ' unsigned long ' to ' int ' in initializer list [ - wc + + <number> - narrowing ] int data [ <number> ] = { ec . value ( ) , len + <number> }; ^ ~ ~ ~ ~ ~ ~ / opt / homebrew / / include / boost / process / detail / posix / executor . hpp : <number> <time> : note : in instantiation of member function ' boost : : process : : detail : : posix : : executor < boost : : fusion : : joint_view < boost : : fusion : : tuple < boost : : process : : detail : : posix : : exe_cmd_init <char> > , boost : : fusion : : filter_view < const boost : : fusion : : tuple < const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_in & > , boost : : process : : detail : : is_initializer < mpl_ : : arg < - <number> >>>>>: : write_error ' requested here write_error ( ec , msg ) ; ^ / opt / homebrew / / include / boost / process / detail / posix / executor . hpp : <number> : <number> : note : in instantiation of member function ' boost : : process : : detail : : posix : : executor < boost : : fusion : : joint_view < boost : : fusion : : tuple < boost : : process : : detail : : posix : : exe_cmd_init <char> > , boost : : fusion : : filter_view < const boost : : fusion : : tuple < const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_in & > , boost : : process : : detail : : is_initializer < mpl_ : : arg < - <number> >>>>>: : internal_error_handle ' requested here internal_error_handle ( ec , msg , has_error_handler ( ) , has_ignore_error ( ) , shall_use_vfork ( )); ^ / opt / homebrew / / include / boost / process / detail / posix / executor . hpp : <number> <time> : note : in instantiation of member function ' boost : : process : : detail : : posix : : executor < boost : : fusion : : joint_view < boost : : fusion : : tuple < boost : : process : : detail : : posix : : exe_cmd_init <char> > , boost : : fusion : : filter_view < const boost : : fusion : : tuple < const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_in & > , boost : : process : : detail : : is_initializer < mpl_ : : arg < - <number> >>>>>: : set_error ' requested here set_error ( : : boost : : process : : detail : : get_last_error ( ) , "" pipe ( <number> ) failed "" ); ^ / opt / homebrew / / include / boost / process / detail / posix / executor . hpp : <number> <time> : note : in instantiation of member function ' boost : : process : : detail : : posix : : executor < boost : : fusion : : joint_view < boost : : fusion : : tuple < boost : : process : : detail : : posix : : exe_cmd_init <char> > , boost : : fusion : : filter_view < const boost : : fusion : : tuple < const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_in & > , boost : : process : : detail : : is_initializer < mpl_ : : arg < - <number> >>>>>: : invoke ' requested here return invoke ( has_ignore_error ( ) , shall_use_vfork ( )); ^ / opt / homebrew / / include / boost / process / detail / execute_impl . hpp : <number> <time> : note : in instantiation of member function ' boost : : process : : detail : : posix : : executor < boost : : fusion : : joint_view < boost : : fusion : : tuple < boost : : process : : detail : : posix : : exe_cmd_init <char> > , boost : : fusion : : filter_view < const boost : : fusion : : tuple < const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > & , boost : : process : : detail : : posix : : pipe_in & > , boost : : process : : detail : : is_initializer < mpl_ : : arg < - <number> >>>>>: : operator ( ) ' requested here return exec ( ); ^ / opt / homebrew / / include / boost / process / detail / execute_impl . hpp : <number> <time> : note : in instantiation of function template specialization ' boost : : process : : detail : : basic_execute_impl < char , const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > , boost : : process : : detail : : posix : : pipe_in > ' requested here return basic_execute_impl <req_char_type> ( ^ / opt / homebrew / / include / boost / process / child . hpp : <number> <time> : note : in instantiation of function template specialization ' boost : : process : : detail : : execute_impl < const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > , boost : : process : : detail : : posix : : pipe_in > ' requested here : child ( : : boost : : process : : detail : : execute_impl ( std : : forward <args> ( args ) . <repeated> ) ) { } ^ util / system . cpp : <number> <time> : note : in instantiation of function template specialization ' boost : : process : : child : : child < const std : : string & , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > , boost : : process : : detail : : posix : : pipe_out < <number> , - <number> > , boost : : process : : detail : : posix : : pipe_in > ' requested here bp : : child c ( ^ / opt / homebrew / / include / boost / process / detail / posix / executor . hpp : <number> <time> : note : insert an explicit cast to silence this issue int data [ <number> ] = { ec . value ( ) , len + <number> }; ^ ~ ~ ~ ~ ~ ~ static_cast <int> ( ) <number> warnings and <number> errors generated . make [ <number> <sad> * * * [ util / libbitcoin_util_a - system . o ] error <number> make [ <number> <sad> * * * [ all - recursive ] error <number> make [ all - recursive ] error <number>",0
bitcoin/bitcoin,cross - compiled ` bitcoind - signet ` silently fails on windows the issue was [ discovered ] ( <url> during <number> . 0 rc2 testing . msvc build works flawlessly . ` bitcoind - testnet ` also works flawlessly .,0
bitcoin/bitcoin,"build fails on ubuntu <number> with gcc <number> building master ( f05cf59d91eb03857dd9bdcc77607764da0349d2 ) on ubuntu <number> with gcc <number> : ` ` ` $ . / autogen . sh $ . / configure - - with - incompatible - bdb cc = gcc - <number> cxx = g + + - <number> $ make clean $ make . <repeated> cxx libbitcoin_node_a - validation . o during rtl pass : reload validation . cpp : in member function ‘ bool cchainstate : : flushstatetodisk ( blockvalidationstate & , flushstatemode , int ) ’ : validation . cpp : <number> : <number> : internal compiler error : max . number of generated reload insns per insn is achieved ( <number> ) } ^ unrecognized dwarf version in . debug_info at <number> unrecognized dwarf version in . debug_info at <number> unrecognized dwarf version in . debug_info at <number> please submit a full bug report , with preprocessed source if appropriate . see < file :/// usr / share / doc / gcc - <number> / readme . bugs > for instructions . make [ <number> <sad> * * * [ makefile : <number> : libbitcoin_node_a - validation . o ] error <number> make [ <number> <sad> * * * waiting for unfinished jobs . <repeated> make [ <number> <sad> leaving directory ' / home / hebasto / github / bitcoin / src ' make [ <number> <sad> * * * [ makefile : <number> : all - recursive ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / github / bitcoin / src ' make : * * * [ makefile : <number> : all - recursive ] error <number> ` ` ` interesting that the upstream [ bug ] ( <url> has been fixed and [ backported ] ( <url> gcc - <number> ( <number> . <number> - <number> ) unstable ; urgency = medium * update to svn <number> ( r278718 ) from the gcc - <number> - branch . - fix pr c / <number> , pr tree - optimization / <number> , pr middle - end / <number> , pr target / <number> (x 8 6 ) , pr c / <number> , pr middle - end / <number> , pr c + + / <number> , pr tree - optimization / <number> , pr tree - optimization / <number> , pr middle - end / <number> , pr middle - end / <number> , pr middle - end / <number> , pr middle - end / <number> , pr other / <number> , pr target / <number> (x 8 6 ) , pr target / <number> (x 8 6 ) , pr target / <number> ( sparc ) , pr fortran / <number> , pr tree - optimization / <number> , pr c + + / <number> , pr c + + / <number> , pr preprocessor / <number> , pr fortran / <number> , pr ada / <number> . - - matthias klose < <email> > tue , <date> <time> + <number> ` ` `",0
bitcoin/bitcoin,"ci : failure wallet_send . py - - legacy - wallet <url> ` ` ` test <number> - <number> - 1 8 t <time> . 2 5 1 0 0 0 z testframework ( error ) : assertion failed traceback ( most recent call last ) : file "" c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ cirrus - ci - build \ \ test \ \ functional \ \ test_framework \ \ test_framework . py "" , line <number> , in main self . run_test ( ) file "" c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ cirrus - ci - build \ \ test \ \ functional \ \ wallet_send . py "" , line <number> , in run_test assert_fee_amount ( testres [ "" fees "" ] [ "" base "" ] , testres [ "" vsize "" ] , decimal ( <number> ) ) file "" c :\\ users \ \ containeradministrator \ \ appdata \ \ local \ \ temp \ \ cirrus - ci - build \ \ test \ \ functional \ \ test_framework \ \ util . py "" , line <number> , in assert_fee_amount raise assertionerror ( "" fee of %s btc too high ( should be %s btc ) "" % ( str ( fee ) , str ( target_fee ) ) ) assertionerror of <number> btc too high ! ( should be <number> btc ) ` ` `",0
bitcoin/bitcoin,"qa : intermittent failure in feature_segwit . py - - descriptors <url> ` ` ` <number> / <number> - feature_segwit . py - - descriptors failed , duration : <number> s stdout : <number> - <number> - 1 6 t <time> . 2 4 2 0 0 0 z testframework ( info ) : initializing test directory / tmp / cirrus - ci - build / ci / scratch / test_runner / test_runner_ ₿ _ 🏃 _20220316_183814 / feature_segwit_225 <number> - <number> - 1 6 t <time> . 1 7 7 0 0 0 z testframework ( info ) : verify sigops are counted in gbt with pre - bip141 rules before the fork <number> - <number> - 1 6 t <time> . 1 6 8 0 0 0 z testframework ( info ) : verify witness txs cannot be mined before the fork <number> - <number> - 1 6 t <time> . 2 0 0 0 0 0 z testframework ( info ) : verify unsigned p2sh witness txs without a redeem script are invalid <number> - <number> - 1 6 t <time> . 6 3 0 0 0 0 z testframework ( error ) : jsonrpc error traceback ( most recent call last ) : file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in main self . run_test ( ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / feature_segwit . py "" , line <number> , in run_test self . generate ( self . nodes [ <number> ] , <number> ) # blocks <number> - <number> file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / test_framework . py "" , line <number> , in generate blocks = generator . generate ( * args , invalid_call = false , * * kwargs ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / test_node . py "" , line <number> , in generate return self . generatetoaddress ( nblocks = nblocks , address = self . get_deterministic_priv_key ( ) . address , maxtries = maxtries , * * kwargs ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / test_node . py "" , line <number> , in generatetoaddress return self . __getattr__ ( ' generatetoaddress ' ) ( * args , * * kwargs ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / coverage . py "" , line <number> , in __call__ return_val = self . auth_service_proxy_instance . __call__ ( * args , * * kwargs ) file "" / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / test_framework / authproxy . py "" , line <number> , in __call__ raise jsonrpcexception ( response [ ' error ' ] , status ) test_framework . authproxy . jsonrpcexception : createnewblock : testblockvalidity failed : unexpected - witness , contextualcheckblock : unexpected witness data found ( - <number> ) <number> - <number> - 1 6 t <time> . 6 8 2 0 0 0 z testframework ( info ) : stopping nodes <number> - <number> - 1 6 t <time> . 8 5 6 0 0 0 z testframework ( warning ) : not cleaning up dir / tmp / cirrus - ci - build / ci / scratch / test_runner / test_runner_ ₿ _ 🏃 _20220316_183814 / feature_segwit_225 <number> - <number> - 1 6 t <time> . 8 5 6 0 0 0 z testframework ( error ) : test failed . test logging available at / tmp / cirrus - ci - build / ci / scratch / test_runner / test_runner_ ₿ _ 🏃 _20220316_183814 / feature_segwit_225 / test_framework . log <number> - <number> - 1 6 t <time> . 8 6 6 0 0 0 z testframework ( error ) : <number> - <number> - 1 6 t <time> . 8 6 6 0 0 0 z testframework ( error ) : hint : call / tmp / cirrus - ci - build / ci / scratch / build / bitcoin - i686 - pc - linux - gnu / test / functional / combine_logs . py ' / tmp / cirrus - ci - build / ci / scratch / test_runner / test_runner_ ₿ _ 🏃 _20220316_183814 / feature_segwit_225 ' to consolidate all logs <number> - <number> - 1 6 t <time> . 8 6 6 0 0 0 z testframework ( error ) : <number> - <number> - 1 6 t <time> . 8 6 6 0 0 0 z testframework ( error ) : if this failure happened unexpectedly or intermittently , please file a bug and provide a link or upload of the combined log . <number> - <number> - 1 6 t <time> . 8 6 7 0 0 0 z testframework ( error ) : <url> <number> - <number> - 1 6 t <time> . 8 6 7 0 0 0 z testframework ( error )",0
bitcoin/bitcoin,"syscall sandbox termination i was testing v23 . 0 rc2 compiled . ` . / configure - - without - miniupnpc - - without - natpmp - - enable - hardening - - without - bdb - - with - qrencode - - with - zmq - - with - sqlite = yes - - disable - external - signer ` bitcoin . conf : > assumevalid = <number> > blockfilterindex = <number> > coinstatsindex = <number> > dbcache = <number> > prune = <number> > sandbox = log - and - abort > txindex = <number> > cjdnsreachable = <number> > discover = <number> > i2psam = <number> . <number> : <number> > listen = <number> > listenonion = <number> > networkactive = <number> > peerblockfilters = <number> > proxy = <number> . <number> : <number> > addresstype = bech32m > avoidpartialspends = <number> > changetype = bech32m > maxapsfee = <number> > walletrbf = <number> > shrinkdebugfile = <number> i deleted my data directory ( / home / user / . bitcoin ) to start a fresh download of the blockchain to test any errors . ran out of space , and after deleting more and trying to start bitcoin - qt again : > error : the syscall "" linkat "" ( syscall number <number> ) is not allowed by the syscall sandbox in thread "" main "" . please report . > terminate called without an active exception > aborted and in debug . log : > <number> - <number> - 1 1 t <time> z init message : verifying blocks … > <number> - <number> - 1 1 t <time> z verifying last <number> blocks at level <number> > <number> - <number> - 1 1 t <time> z [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ <percent> ] . <repeated> [ done ] . > <number> - <number> - 1 1 t <time> z no coin database inconsistencies in last <number> blocks ( <number> transactions ) > <number> - <number> - 1 1 t <time> z block index 4 9 6 3 ms > <number> - <number> - 1 1 t <time> z opening leveldb in / home / user / . bitcoin / indexes / txindex > <number> - <number> - 1 1 t <time> z opened leveldb successfully > <number> - <number> - 1 1 t <time> z using obfuscation key for / home / user / . bitcoin / indexes / txindex : <number> > <number> - <number> - 1 1 t <time> z opening leveldb in / home / user / . bitcoin / indexes / blockfilter / basic / db > <number> - <number> - 1 1 t <time> z txindex thread start > <number> - <number> - 1 1 t <time> z txindex is enabled at height <number> > <number> - <number> - 1 1 t <time> z txindex thread exit > <number> - <number> - 1 1 t <time> z opened leveldb successfully > <number> - <number> - 1 1 t <time> z using obfuscation key for / home / user / . bitcoin / indexes / blockfilter / basic / db : <number> > <number> - <number> - 1 1 t <time> z opening leveldb in / home / user / . bitcoin / indexes / coinstats / db > <number> - <number> - 1 1 t <time> z basic block filter index thread start > <number> - <number> - 1 1 t <time> z basic block filter index is enabled at height <number> > <number> - <number> - 1 1 t <time> z basic block filter index thread exit > <number> - <number> - 1 1 t <time> z opened leveldb successfully > <number> - <number> - 1 1 t <time> z using obfuscation key for / home / user / . bitcoin / indexes / coinstats / db : <number> > <number> - <number> - 1 1 t <time> z error : init : cannot read current coinstatsindex state ; index may be corrupted > <number> - <number> - 1 1 t <time> z shutdown : in progress . <repeated> > <number> - <number> - 1 1 t <time> z scheduler thread exit > <number> - <number> - 1 1 t <time> z shutdown : done > <number> - <number> - 1 1 t <time> z error syscall "" linkat "" ( syscall number <number> ) is not allowed by the syscall sandbox in thread "" main "" . please report . this was done on a qubes <number> machine in a debian <number> vm .",0
bitcoin/bitcoin,"automatic wallet rescan skipped after abort i ran bitcoin - qt with an old wallet , causing it to rescan , then stopped it with a sigint signal , resulting in the following log . nothing unexpected , so far : ` ` ` <number> - <number> - 0 5 t <time> z init message : loading wallet … <number> - <number> - 0 5 t <time> z berkeleyenvironment : : open : logdir = … / . bitcoin / database errorfile = … / . bitcoin / db . log <number> - <number> - 0 5 t <time> z [ walletname . dat ] wallet file version = <phone> - <number> - 0 5 t <time> z [ walletname . dat ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records : <number> <number> - <number> - 0 5 t <time> z [ walletname . dat ] wallet completed loading in 6 5 ms <number> - <number> - 0 5 t <time> z init message : rescanning … <number> - <number> - 0 5 t <time> z [ walletname . dat ] rescanning last <number> blocks ( from block <number> ) . <repeated> <number> - <number> - 0 5 t <time> z [ walletname . dat ] rescan started from block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 5 fcc1872da61f45bcfd0e0bb36b7c8cb45e7a328ad41 . <repeated> <number> - <number> - 0 5 t <time> z [ walletname . dat ] still rescanning . at block <number> . progress = <number> . <phone> - <number> - 0 5 t <time> z [ walletname . dat ] still rescanning . at block <number> . progress = <number> . <phone> - <number> - 0 5 t <time> z [ walletname . dat ] rescan interrupted by shutdown request at block <number> . progress = <number> . <phone> - <number> - 0 5 t <time> z error : failed to rescan the wallet during initialization <number> - <number> - 0 5 t <time> z gui : initializeresult : initialization result : false <number> - <number> - 0 5 t <time> z gui : requestshutdown : requesting shutdown <number> - <number> - 0 5 t <time> z gui : running shutdown in thread <number> - <number> - 0 5 t <time> z shutdown : in progress . <repeated> <number> - <number> - 0 5 t <time> z scheduler thread exit <number> - <number> - 0 5 t <time> z shutdown : done <number> - <number> - 0 5 t <time> z gui : shutdown finished <number> - <number> - 0 5 t <time> z gui : ~ initexecutor : stopping thread <number> - <number> - 0 5 t <time> z gui : ~ initexecutor : stopped thread ` ` ` however , the next time it was launched , the rescan did not continue , nor did it start over . it seems to have been skipped ? ` ` ` <number> - <number> - 0 5 t <time> z init message : loading wallet … <number> - <number> - 0 5 t <time> z berkeleyenvironment : : open : logdir = … / . bitcoin / database errorfile = … / . bitcoin / db . log <number> - <number> - 0 5 t <time> z [ walletname . dat ] wallet file version = <phone> - <number> - 0 5 t <time> z [ walletname . dat ] keys : <number> plaintext , <number> encrypted , <number> w / metadata , <number> total . unknown wallet records <number> - <number> - 0 5 t <time> z [ walletname . dat ] wallet completed loading in 9 1 ms <number> - <number> - 0 5 t <time> z [ walletname . dat ] setkeypool . size ( ) = <number> <number> - <number> - 0 5 t <time> z [ walletname . dat ] mapwallet . size ( ) = <number> <number> - <number> - 0 5 t <time> z [ walletname . dat ] m_address_book . size ( ) = <number> <number> - <number> - 0 5 t <time> z loaded <number> addresses from "" anchors . dat "" ` ` ` i did not investigate deeply , but could it be that despite the failed rescan , the new tip block was stored in the wallet ? if so , this would be confusing .",0
bitcoin/bitcoin,"application aborted i receive this error when trying to open ` bitcoin - qt ` when compiling from ` master ` : > terminate called after throwing an instance of ' std : : runtime_error ' > what ( ) value is not a string as expected > aborted no debug info is generated since the application is not started . i am running qubes <number> fully updated , in a debian - <number> vm with normal networking . intel x86_64",0
bitcoin/bitcoin,clang - <number> ubsan new thread to continue the discussion from <url>,0
bitcoin/bitcoin,"build : fail to build ` libmultiprocess ` for the ` x86_64 - w64 - mingw32 ` target on master ( <url> building of ` libmultiprocess ` fails for the ` x86_64 - w64 - mingw32 ` target : ` ` ` $ make - c depends libmultiprocess multiprocess = <number> host =x 8 6 _64 - w64 - mingw32 . <repeated> configuring libmultiprocess . <repeated> cmake warning : no source or binary directory provided . both will be assumed to be the same as the current working directory , but note that this warning will become a fatal error in future cmake releases . - - the cxx compiler identification is gnu <number> . <number> - - check for working cxx compiler : / usr / bin / x86_64 - w64 - mingw32 - g + + - posix - - check for working cxx compiler : / usr / bin / x86_64 - w64 - mingw32 - g + + - posix - - broken cmake error at / usr / share / cmake - <number> / modules / cmaketestcxxcompiler . cmake : <number> ( message ) : the c + + compiler "" / usr / bin / x86_64 - w64 - mingw32 - g + + - posix "" is not able to compile a simple test program . it fails with the following output : change dir : / home / hebasto / github / bitcoin / depends / work / build / x86_64 - w64 - mingw32 / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - 7 e18b85317d / cmakefiles / cmaketmp run build command ( s ) <annoyed> usr / bin / make cmtc_14f5f / fast & & make [ <number> <sad> entering directory ' / home / hebasto / github / bitcoin / depends / work / build / x86_64 - w64 - mingw32 / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - 7 e18b85317d / cmakefiles / cmaketmp ' / usr / bin / make - f cmakefiles / cmtc_14f5f . dir / build . make cmakefiles / cmtc_14f5f . dir / build make [ <number> <sad> entering directory ' / home / hebasto / github / bitcoin / depends / work / build / x86_64 - w64 - mingw32 / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - 7 e18b85317d / cmakefiles / cmaketmp ' building cxx object cmakefiles / cmtc_14f5f . dir / testcxxcompiler . cxx . o / usr / bin / x86_64 - w64 - mingw32 - g + + - posix - i / home / hebasto / github / bitcoin / depends / x86_64 - w64 - mingw32 / include - pipe - o2 - o cmakefiles / cmtc_14f5f . dir / testcxxcompiler . cxx . o - c / home / hebasto / github / bitcoin / depends / work / build / x86_64 - w64 - mingw32 / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - 7 e18b85317d / cmakefiles / cmaketmp / testcxxcompiler . cxx linking cxx executable cmtc_14f5f / usr / bin / cmake - e cmake_link_script cmakefiles / cmtc_14f5f . dir / link . txt - - verbose = <number> / usr / bin / x86_64 - w64 - mingw32 - g + + - posix - i / home / hebasto / github / bitcoin / depends / x86_64 - w64 - mingw32 / include - pipe - o2 - l / home / hebasto / github / bitcoin / depends / x86_64 - w64 - mingw32 / lib - rdynamic cmakefiles / cmtc_14f5f . dir / testcxxcompiler . cxx . o - o cmtc_14f5f x86_64 - w64 - mingw32 - g + + - posix : error : unrecognized command line option ‘ - rdynamic ’ make [ <number> <sad> * * * [ cmakefiles / cmtc_14f5f . dir / build . make : <number> : cmtc_14f5f ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / github / bitcoin / depends / work / build / x86_64 - w64 - mingw32 / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - 7 e18b85317d / cmakefiles / cmaketmp ' make [ <number> <sad> * * * [ makefile : <number> : cmtc_14f5f / fast ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / github / bitcoin / depends / work / build / x86_64 - w64 - mingw32 / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - 7 e18b85317d / cmakefiles / cmaketmp ' cmake will not be able to correctly generate this project . call stack ( most recent call first ) ( project ) - - configuring incomplete , errors occurred ` ` `",0
bitcoin/bitcoin,"build : fail to build ` libmultiprocess ` for the ` arm - linux - gnueabihf ` target on master ( a6c3da131c855650e8888a9403776cfda0d0ee2e ) , building of ` libmultiprocess ` fails for the ` arm - linux - gnueabihf ` target : ` ` ` $ make - c depends libmultiprocess multiprocess = <number> host = arm - linux - gnueabihf make : entering directory ' / home / hebasto / github / bitcoin / depends ' building libmultiprocess . <repeated> make [ <number> <sad> entering directory ' / home / hebasto / github / bitcoin / depends / work / build / arm - linux - gnueabihf / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - e5741e5a04d ' make [ <number> <sad> entering directory ' / home / hebasto / github / bitcoin / depends / work / build / arm - linux - gnueabihf / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - e5741e5a04d ' make [ <number> <sad> entering directory ' / home / hebasto / github / bitcoin / depends / work / build / arm - linux - gnueabihf / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - e5741e5a04d ' [ <percent> ] compiling cap ' n proto schema include / mp / proxy . capnp / lib / ld - linux - armhf . so . <number> : no such file or directory make [ <number> <sad> * * * [ cmakefiles / multiprocess . dir / build . make : <number> : include / mp / proxy . capnp . c + + ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / github / bitcoin / depends / work / build / arm - linux - gnueabihf / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - e5741e5a04d ' make [ <number> <sad> * * * [ cmakefiles / makefile <time> <number> : cmakefiles / multiprocess . dir / all ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / github / bitcoin / depends / work / build / arm - linux - gnueabihf / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - e5741e5a04d ' make [ <number> <sad> * * * [ makefile : <number> : all ] error <number> make [ <number> <sad> leaving directory ' / home / hebasto / github / bitcoin / depends / work / build / arm - linux - gnueabihf / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - e5741e5a04d ' make : * * * [ funcs . mk : <number> : / home / hebasto / github / bitcoin / depends / work / build / arm - linux - gnueabihf / libmultiprocess / d576d975debdc9090bd2582f83f49c76c0061698 - e5741e5a04d / . / . stamp_built ] error <number> make directory ' / home / hebasto / github / bitcoin / depends ' ` ` `",0
bitcoin/bitcoin,"syscall sandbox fails on ubuntu <number> it does not even specify which "" invalid syscall "" . ` ` ` $ src / bitcoind - sandbox = log - and - abort <number> - <number> - 1 7 t <time> z bitcoin core version v22 . <number> - b223c3c21e89 ( release build ) <number> - <number> - 1 7 t <time> z assuming ancestors of block 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 a89e854d57e5667df88f1cdef6fde2fbca1de5b639ad have valid signatures . <number> - <number> - 1 7 t <time> z setting nminimumchainwork = 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 fa4663bbbe19f82de <phone> - <number> - 1 7 t <time> z experimental syscall sandbox enabled ( - sandbox = log - and - abort ) : bitcoind will terminate if an unexpected ( not allowlisted ) syscall is invoked . <number> - <number> - 1 7 t <time> z using the ' sse4 ( 1 way ) , sse41 ( 4 way ) , avx2 ( 8 way ) ' sha256 implementation <number> - <number> - 1 7 t <time> z default data directory / … / . bitcoin <number> - <number> - 1 7 t <time> z using data directory / … / . bitcoin <number> - <number> - 1 7 t <time> z config file : / … / . bitcoin / bitcoin . conf ( not found , skipping ) <number> - <number> - 1 7 t <time> z command - line arg <number> - <number> - 1 7 t <time> z using at most <number> automatic connections ( <number> file descriptors available ) <number> - <number> - 1 7 t <time> z using <number> mib out of <number> / <number> requested for signature cache , able to store <number> elements <number> - <number> - 1 7 t <time> z using <number> mib out of <number> / <number> requested for script execution cache , able to store <number> elements <number> - <number> - 1 7 t <time> z script verification uses <number> additional threads bad system call ( core dumped ) ` ` ` nothing in ` dmesg ` either .",0
bitcoin/bitcoin,"add descriptor_tests covering tr ( ) , and fix minor bugs this fixes two bugs in the current logic for ` tr ( ) ` descriptors toprivatestring does not always work , because the provided private key may mismatch the parity of the x - only public key . * the descriptors inferred for ` pk ( ) ` inside ` tr ( ) ` have the wrong x - only flag , leading to such descriptors generating the wrong scriptpubkey ( roundtripping through tostring does fix it however , so this seems unobservable in the current code ) . these were discovered while adding unit tests to descriptor_tests that cover various aspects of ` tr ( ) ` descriptors , which are now also added here .",0
bitcoin/bitcoin,"release process : "" does not appear to be a git repository "" the ` release - process . md ` docs erroneously omit the remote name from ` git fetch ` . * * expected behavior * * ` git fetch ` should complete without errors . * * actual behavior * * ~ ~ ~ fatal : ' v22 . <number> ' does not appear to be a git repository fatal : could not read from remote repository . ~ ~ ~ * * to reproduce * * follow steps in ` release - process . md ` through this line fetch "" v ${ version } "" ` * * system information * * bitcoin core b6b7815ddcff53177bb1f6318b39a4134cf42cb1 , self - compiled . whonix <number> inside qubes <number> , intel haswell , hdd . git v2 . <number> . replacing the offending line with ` git fetch origin "" v ${ version } "" ` works fine .",0
bitcoin/bitcoin,"bionic with system libs does not link steps to reproduce on a fresh install of ubuntu bionic : ` ` ` export debian_frontend = noninteractive & & apt update & & apt install curl wget htop git vim ccache - y & & git clone <url> . / bitcoin - core & & cd bitcoin - core & & apt install build - essential libtool autotools - dev automake pkg - config bsdmainutils python3 - zmq libevent - dev libboost - system - dev libboost - filesystem - dev libboost - test - dev libboost - thread - dev libsqlite3 - dev libdb + + - dev gcc - <number> g + + - <number> - y & & . / autogen . sh & & cxx = g + + - <number> cc = gcc - <number> . / configure - - without - incompatible - bdb & & make - j $( nproc ) ` ` ` output : ` ` ` cxxld bitcoind libbitcoin_util . a ( libbitcoin_util_a - system . o ) : in function ` boost : : system : : error_category : : std_category : : equivalent ( std : : error_code const & , int ) const ' : / usr / include / boost / system / error_code . hpp : <number> : undefined reference to ` boost : : system : : generic_category ( ) ' / usr / include / boost / system / error_code . hpp : <number> : undefined reference to ` boost : : system : : generic_category ( ) ' / usr / include / boost / system / error_code . hpp : <number> : undefined reference to ` boost : : system : : generic_category ( ) ' libbitcoin_util . a ( libbitcoin_util_a - system . o ) : in function ` boost : : system : : error_category : : std_category : : equivalent ( int , std : : error_condition const & ) const ' : / usr / include / boost / system / error_code . hpp : <number> : undefined reference to ` boost : : system : : generic_category ( ) ' / usr / include / boost / system / error_code . hpp : <number> : undefined reference to ` boost : : system : : generic_category ( ) ' libbitcoin_util . a ( libbitcoin_util_a - system . o ) <annoyed> usr / include / boost / system / error_code . hpp : <number> : more undefined references to ` boost : : system : : generic_category ( ) ' follow libbitcoin_util . a ( libbitcoin_util_a - system . o ) : in function ` __static_initialization_and_destruction_0 ' : / usr / include / boost / system / error_code . hpp : <number> : undefined reference to ` boost : : system : : system_category ( ) ' libbitcoin_util . a ( libbitcoin_util_a - system . o ) : in function ` _global__sub_i_bitcoin_conf_filename ' : / usr / include / boost / asio / error . hpp : <number> : undefined reference to ` boost : : system : : system_category ( ) ' collect2 : error : ld returned <number> exit status makefile : <number> : recipe for target ' bitcoind ' failed make [ <number> <sad> * * * [ bitcoind ] error <number> make [ <number> <sad> leaving directory ' / bitcoin - core / src ' makefile : <number> : recipe for target ' all - recursive ' failed make [ <number> <sad> * * * [ all - recursive ] error <number> make [ <number> <sad> leaving directory ' / bitcoin - core / src ' makefile : <number> : recipe for target ' all - recursive ' failed make [ all - recursive ] error <number> ` ` ` initial report by <user> in <url>",0
bitcoin/bitcoin,"cirrus ci / win64 does not print assert errors from test_bitcoin . exe cirrus ci / win64 build does not seem to print errors from test_bitcoin . exe if an ` assert ` statement fails . i saw this recently in <url> from # <number> , and reproduced it locally running ` file_env = . / ci / test / 0 0 _setup_env_win64 . sh . / ci / test_run_all . sh ` . if i run ` test_bitcoin . exe ` manually with ` docker exec ` i can see : ` ` ` test / util_tests . cpp ( <number> <sad> entering test case "" util_datadir "" assertion failed path ) , file util / system . cpp , line <number> ` ` ` but the default docker / cirrus output just shows the test_bitcoin . exe process exiting without any information about a failing assert . i do not know if this is a known limitation , but it would be helpful if windows ci builds were able to print why they are failing in cases like this .",0
bitcoin/bitcoin,"` getblocktemplate ` returns a standard p2pkh with <number> sigops ( testnet ) < - - this issue tracker is only for technical issues related to bitcoin core . general bitcoin questions and / or support requests are best directed to the bitcoin stackexchange at <url> for reporting security issues , please read instructions at <url> if the node is "" stuck "" during sync or giving "" block checksum mismatch "" errors , please ensure your hardware is stable by running memtest and observe cpu temperature with a load - test tool such as linpack before creating an issue ! - - > i noticed a standard <number> sigops transaction when calling getblocktemplate , but that transaction turned out to be p2pkh of course * with <emphasis> * ` op_checksig ` < ! - - describe the issue - - > * * expected behavior * * ` "" sigops "" : <number> , ` in block template json < ! - - - what behavior did you expect ? - - > * * actual behavior * * ` ` ` . <repeated> "" txid "" : "" 5 4 eee291ec73fcc3faf496cf90ffc9b6faa57940234802bdae58c51540016853 "" , "" hash "" : "" 5 4 eee291ec73fcc3faf496cf90ffc9b6faa57940234802bdae58c51540016853 "" , "" depends "" : [ ] , "" fee "" : <number> , "" sigops "" : <number> , < - - here "" weight "" . <repeated> ` ` ` < ! - - - what was the actual behavior ( provide screenshots if the issue is gui - related ) ? - - > * * to reproduce * * < ! - - - how reliably can you reproduce the issue , what are the steps to do so ? - - > somehow get the sigop count of ` 5 4 eee291ec73fcc3faf496cf90ffc9b6faa57940234802bdae58c51540016853 ` ( testnet ) * * system information * * bitcoin . org binary v22 . <number> < ! - - what version of bitcoin core are you using , where did you get it ( website , self - compiled , etc ) ? - - > < ! - - what type of machine are you observing the error on ( os / cpu and disk type ) ? - - > < ! - - gui - related issue ? what is your operating system and its version ? if linux , what is your desktop environment and graphical shell ? - - > < ! - - any extra information that might be useful in the debugging process . - - > < ! - - - this is normally the contents of a ` debug . log ` or ` config . log ` file . raw text or a link to a pastebin type site are preferred . - - >",0
bitcoin/bitcoin,"invalid sha256sums . asc <url> does not seem valid ( no hashes or files included ) . ` ` ` ~ $ curl - slo <url> ~ $ cat sha256sums . asc - - - - - begin pgp signature - - - - - iqizbaabcaadfieedmuq / xai7olm0xqd4v / vsdimqx0fame7qy0acgkq4v / vsdim . <repeated> n + msw3q5hoyg / c9vlv / am4nm8lxem9bwz / 6 xbpvofbkicq8d3a0 = = mc + w - - - - - end pgp signature - - - - - - - - - - begin pgp signature - - - - - . <repeated> ` ` ` compared to <number> and prior . ` ` ` ~ $ curl - slo <url> ~ $ cat sha256sums . asc - - - - - begin pgp signed message - - - - - hash : sha256 4 3 4 1 6 8 5 4 3 3 0 9 1 4 9 9 2 bbba2d0e9adf2a6fff4130be9af8ae2ef1186e743d9a3fe bitcoin - <number> . <number> - aarch64 - linux - gnu . tar . gz . <repeated> da7766775e3f9c98d7a9145429f2be8297c2672fe5b118fd3dc2411fb48e0032 bitcoin - <number> . <number> - x86_64 - linux - gnu . tar . gz - - - - - begin pgp signature - - - - - version v1 . <number> ( gnu / linux ) iqicbaebcaagbqjgadqtaaojejdiaz42wulkjtkqajwlstdinksxzimky3mevhwb . <repeated> ka8z9klt / n0ziabbexaw = bi4p - - - - - end pgp signature - - - - - ` ` ` maybe related ( or not ) , it seems to verify the v22 file above , you need laanwj . asc and not laanwj - releases . asc ( not that it matters because i think the sha256sums . asc is incorrect ) .",0
opencv/opencv,"ci : tests on ubuntu2004 - x64 are automatically cancelled for some reasons after the ubuntu2004 - x64 - openvino is added # # # system information n / a # # # detailed description see this with ubuntu2004 - x64 - openvino : <url> see this without ubuntu2004 - x64 - openvino maybe the jobs is capped due to too many are assgined on a single machine ( or it exceeds the number of workers that we set ) ? # # # steps to reproduce push new commits and trigger ubuntu2004 - x64 - openvino , then jobs of ubuntu2004 - x6 are cancelled instantly . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"dnn : opencl fp16 tests are failed with einsum layer ( <number> - <number> - <number> ) opencl : intel igpu relates # <number> - windows : <url> - linux ( similar problem ) : <url> ` ` ` [ failed ] <number> tests , listed below failed ] test_onnx_conformance . layer_test / test_einsum_batch_matmul_ocv_ocl_fp16 , where getparam ( ) = ( test_einsum_batch_matmul , ocv / ocl_fp16 ) [ failed ] test_onnx_conformance . layer_test / test_einsum_sum_ocv_ocl_fp16 , where getparam ( ) = ( test_einsum_sum , ocv / ocl_fp16 ) [ failed ] test_onnx_layers . einsum_2d / <number> , where getparam ( ) = ocv / ocl_fp16 [ failed ] test_onnx_layers . einsum_3d / <number> , where getparam ( ) = ocv / ocl_fp16 [ failed ] test_onnx_layers . einsum_4d / <number> , where getparam ( ) = ocv / ocl_fp16 [ failed ] test_onnx_layers . einsum_5d / <number> , where getparam ( ) = ocv / ocl_fp16 [ failed ] test_onnx_layers . einsum_sum / <number> , where getparam ( ) = ocv / ocl_fp16 ` ` `",0
opencv/opencv,"dnn onnx : invalid shape dimension and wrong results in test case test_onnx_layers . openai_clip_head # # # system information latest opencv and lastest onnxruntime # # # detailed description related pr : <url> and <url> in the above pr , several fixes are indtroduced for the clip head . those fixes are fine , but the manually generated onnx model named "" clip - vit - base - head . onnx "" is invalid and * * cannot be run by onnxruntime * * : <number> . in the expand operator , ` shape ` input should be of type ` int64 ` instead of ` int32 ` . please use ` onnx . checker . check_model ( model ) ` ( it checks operator definitions and so on ) before saving a manually generated onnx model . <number> . having that fixed , onnxruntime still complains invalid shape in the expand operator . changing the shape value from [ <number> , <number> , - <number> ] to [ <number> , <number> , <number> ] fixes the problem . please run the manually generated onnx model with onnxruntime to check whether it is all valid . cc <user> # # # steps to reproduce install onnxruntime , then ` ` ` import numpy as np from onnxruntime import inferencesession net = inferencesession ( "" . / clip - vit - base - head . onnx "" ) out = net . run ( [ ] , { "" input "" <number> , <number> ) . astype ( np . float32 ) } ) print ( out [ <number> ] . shape ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"findopenblas does not find openblas due to incorrect filename # # # system information opencv version <number> . <number> ( commit 7 2 5 e440d278aca07d35a5e8963ef990572b07316 ) , but same behaviour in latest version windows <number> cmake <number> . <number> # # # detailed description <url> contains the line find_library ( openblas_lib names openblas paths ${ open_blas_lib_search_paths } no_default_path ) which looks for a library called openblas . lib on windows . the windows release of openblas ( <url> however contains ` libopenblas ` which is not recognized by cmake . changing the line to find_library ( openblas_lib names openblas libopenblas paths ${ open_blas_lib_search_paths } no_default_path ) makes sure that the windows release of openblas can also be found # # # steps to reproduce ` ` ` set openblas_home = % current_dir %\\ dependencies \ \ openblas - <date> - x64 git clone <url> git clone <url> cd opencv mkdir build cd build cd opencv mkdir build_binary_openblas cd build_binary_openblas <hashtag> build </hashtag> opencv in debug config rm - r * "" c :\\ program files (x 8 6 ) \ \ microsoft visual studio \ \ <number> \ \ professional \ \ vc \ \ auxiliary \ \ build \ \ vcvars64 . bat "" cmake - g "" visual studio <number> <number> "" - dcmake_build_type = debug ^ - dpython3_executable = % py_three % ^ - dpython2_executable = % py_two % ^ - dwith_opencl = true ^ - dwith_qt = false ^ - dwith_ffmpeg = false ^ - dwith_gstreamer = false ^ - dwith_dshow = false ^ - dbuild_opencv_dnn = off ^ - dbuild_opencv_video = on ^ - dbuild_opencv_videoio = on ^ - dbuild_opencv_python2 = off ^ - dbuild_opencv_python3 = off ^ - dwith_protobuf = off ^ - dcmake_install_prefix = . <repeated> \ \ . <repeated> \ \ build_binary_openblas ^ - dopencv_extra_modules_path = . <repeated> \ \ . <repeated> \ \ opencv_contrib \ \ modules ^ - dbuild_opencv_ = off ^ - dbuild_opencv_alphamat = off ^ - dbuild_opencv_aruco = off ^ - dbuild_opencv_bgsegm = off ^ - dbuild_opencv_bioinspired = off ^ - dbuild_opencv_ccalib = off ^ - dbuild_opencv_cnn_3dobj = off ^ - dbuild_opencv_cvv = on ^ - dbuild_opencv_datasets = off ^ - dbuild_opencv_dnn_objdetect = off ^ - dbuild_opencv_dnn_superres = off ^ - dbuild_opencv_dnns_easily_fooled = off ^ - dbuild_opencv_dpm = off ^ - dbuild_opencv_face = off ^ - dbuild_opencv_freetype = off ^ - dbuild_opencv_fuzzy = off ^ - dbuild_opencv_hdf = off ^ - dbuild_opencv_hfs = off ^ - dbuild_opencv_img_hash = off ^ - dbuild_opencv_intensity_transform = off ^ - dbuild_opencv_julia = off ^ - dbuild_opencv_line_descriptor = off ^ - dbuild_opencv_matlab = off ^ - dbuild_opencv_mcc = off ^ - dbuild_opencv_optflow = off ^ - dbuild_opencv_ovis = off ^ - dbuild_opencv_phase_unwrapping = off ^ - dbuild_opencv_plot = off ^ - dbuild_opencv_quality = off ^ - dbuild_opencv_rapid = off ^ - dbuild_opencv_reg = off ^ - dbuild_opencv_rgbd = off ^ - dbuild_opencv_saliency = off ^ - dbuild_opencv_sfm = off ^ - dbuild_opencv_shape = off ^ - dbuild_opencv_stereo = off ^ - dbuild_opencv_structured_light = off ^ - dbuild_opencv_superres = off ^ - dbuild_opencv_surface_matching = off ^ - dbuild_opencv_text = off ^ - dbuild_opencv_tracking = off ^ - dbuild_opencv_videostab = off ^ - dbuild_opencv_viz = off ^ - dbuild_opencv_world = on ^ - dbuild_opencv_wechat_qrcode = off ^ - dbuild_opencv_xfeatures2d = off ^ - dbuild_opencv_ximgproc = on ^ - dbuild_opencv_xobjdetect = off ^ - dbuild_opencv_xphoto = off . <repeated> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"dnn : opencl fp16 test is broken ( test_caffe_nets . fasterrcnn_vgg16 ) ( <number> - <number> - <number> ) opencl device : intel igpu nightly builds : - linux : <url> ` ` ` [ run ] test_caffe_nets . fasterrcnn_vgg16 / <number> , where getparam ( ) = ocv / ocl_fp16 unmatched prediction : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] highest iou : <number> / build / 4 _x - lin64 / opencv / modules / dnn / test / test_common . impl . hpp : <number> : failure value of : matched actual : false expected : true model name : vgg16_faster_rcnn_final . caffemodel unmatched prediction : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] highest iou : <number> / build / 4 _x - lin64 / opencv / modules / dnn / test / test_common . impl . hpp : <number> : failure value of : matched actual : false expected : true model name : vgg16_faster_rcnn_final . caffemodel unmatched reference : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] iou diff : <number> / build / 4 _x - lin64 / opencv / modules / dnn / test / test_common . impl . hpp : <number> : failure expected : ( refscores [ i ] ) <= ( confthreshold ) , actual : <number> vs <number> model name : vgg16_faster_rcnn_final . caffemodel unmatched reference : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] iou diff : <number> / build / 4 _x - lin64 / opencv / modules / dnn / test / test_common . impl . hpp : <number> : failure expected : ( refscores [ i ] ) <= ( confthreshold ) , actual : <number> vs <number> model name : vgg16_faster_rcnn_final . caffemodel [ info : <number> <user> . <number> ] global ts . cpp : <number> testteardown memory_usage ( opencl ) : <number> ( base = <number> current = <number> ) [ failed ] test_caffe_nets . fasterrcnn_vgg16 / <number> , where getparam ( ) = ocv / ocl_fp16 ( <number> ms ) ` ` ` - windows : <url> ` ` ` [ run ] test_caffe_nets . fasterrcnn_vgg16 / <number> , where getparam ( ) = ocv / ocl_fp16 unmatched prediction : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] highest iou : <number> c :\\ build \ \ precommit_opencl \ \ <number> . x\\ opencv \ \ modules \ \ dnn \ \ test \ \ test_common . impl . hpp ( <number> <sad> error : value of : matched actual : false expected : true model name : vgg16_faster_rcnn_final . caffemodel unmatched prediction : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] highest iou : <number> c :\\ build \ \ precommit_opencl \ \ <number> . x\\ opencv \ \ modules \ \ dnn \ \ test \ \ test_common . impl . hpp ( <number> <sad> error : value of : matched actual : false expected : true model name : vgg16_faster_rcnn_final . caffemodel unmatched reference : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] iou diff : <number> c :\\ build \ \ precommit_opencl \ \ <number> . x\\ opencv \ \ modules \ \ dnn \ \ test \ \ test_common . impl . hpp ( <number> <sad> error : expected : ( refscores [ i ] ) <= ( confthreshold ) , actual : <number> vs <number> model name : vgg16_faster_rcnn_final . caffemodel unmatched reference : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] iou diff : <number> c :\\ build \ \ precommit_opencl \ \ <number> . x\\ opencv \ \ modules \ \ dnn \ \ test \ \ test_common . impl . hpp ( <number> <sad> error : expected : ( refscores [ i ] ) <= ( confthreshold ) , actual : <number> vs <number> model name : vgg16_faster_rcnn_final . caffemodel [ info : <number> <user> . <number> ] global ts . cpp : <number> cvtest : : testteardown memory_usage ( opencl ) ( base = <number> current = <number> ) [ failed ] test_caffe_nets . fasterrcnn_vgg16 / <number> , where getparam ( ) = ocv / ocl_fp16 ( <number> ms ) ` ` `",0
opencv/opencv,"error c2819 : type ' ov : : output < ov : : node > ' does not have an overloaded member ' operator - > ' # # # system information ` ` ` - - detected processor : amd64 - - found zlib : optimized ;c <annoyed> install / zlib / lib / zlib . lib ; debug ;c <annoyed> install / zlib / lib / zlibd . lib ( found suitable version "" <date> "" , minimum required is "" <number> . <number> "" ) - - libjpeg - turbo : version = <number> . <number> , build = opencv - <number> . <number> - dev - libjpeg - turbo - - libjpeg - turbo ( simd ) : simd extensions disabled : could not find nasm compiler . performance will suffer . - - could not find openjpeg ( minimal suitable version : <number> , recommended version >= <number> . <number> ) . openjpeg will be built from sources - - openjpeg : version = <number> . <number> , build = opencv - <number> . <number> - dev - openjp2 - <number> . <number> - - openjpeg libraries will be built from sources : libopenjp2 ( version "" <number> . <number> "" ) - - found zlib : optimized ;c <annoyed> install / zlib / lib / zlib . lib ; debug ;c <annoyed> install / zlib / lib / zlibd . lib ( found version "" <date> "" ) - - found tbb ( cmake ) : c <annoyed> install / openvino / runtime / 3 rdparty / tbb / bin / tbb . dll - - found intel ipp ( icv version ) : <number> . <number> [ <number> ] - - at : c <annoyed> lib / build / opencv / 3 rdparty / ippicv / ippicv_win / icv - - found intel ipp integration wrappers sources : <number> . <number> - - at : c <annoyed> lib / build / opencv / 3 rdparty / ippicv / ippicv_win / iw - - cuda detected : <number> - - cuda : using cuda_arch_bin = <number> - - cuda nvcc target flags : - gencode ; arch = compute_86 , code = sm_86 ; - d_force_inlines - - cuda : msvs generator is detected . disabling cmake re - run checks ( cmake_suppress_regeneration = on ) . you need to run cmake manually if updates are required . - - found mkl <number> . <number> at : c <annoyed> program files (x 8 6 ) / intel / oneapi / mkl / <number> . <number> - - lapack ( mkl ) : lapack_libraries : c <annoyed> program files (x 8 6 ) / intel / oneapi / mkl / <number> . <number> / lib / intel64 / mkl_intel_lp64 . lib ;c <annoyed> program files (x 8 6 ) / intel / oneapi / mkl / <number> . <number> / lib / intel64 / mkl_tbb_thread . lib ;c <annoyed> prograore . lib ; tbb - - lapack ( mkl ) : can not build lapack check code . this lapack version is not supported . - - could not find openblas include . turning openblas_found off - - could not find openblas lib . turning openblas_found off - - could not find blas ( missing : blas_libraries ) - - could not find lapack ( missing : lapack_libraries ) reason given by package : lapack could not be found because dependency blas could not be found . - - found apache ant : c <annoyed> apache - ant - <date> / bin / ant . bat ( <date> ) - - openvino found : <number> . <number> - - found vtk <number> . <number> - - freetype2 : no - - harfbuzz : no - - julia not found . not compiling julia bindings . - - module opencv_ovis disabled because ogre3d was not found - - ceres support is disabled . ceres solver for reconstruction api is required . - - tesseract : yes ( ver <number> . <number> - <number> - gae3bf ) - - allocator metrics storage type : ' long long ' - - excluding from source files list : modules / imgproc / src / imgwarp . lasx . cpp - - excluding from source files list : modules / imgproc / src / resize . lasx . cpp - - registering hook ' init_module_sources_opencv_dnn ' : c <annoyed> lib / opencv / modules / dnn / cmake / hooks / init_module_sources_opencv_dnn . cmake - - excluding from source files list : <build> / modules / dnn / layers / layers_common . rvv . cpp - - excluding from source files list : <build> / modules / dnn / layers / layers_common . lasx . cpp - - excluding from source files list : <build> / modules / dnn / int8layers / layers_common . lasx . cpp - - excluding from source files list : <build> / modules / dnn / layers / cpu_kernels / conv_depthwise . rvv . cpp - - excluding from source files list : <build> / modules / dnn / layers / cpu_kernels / conv_depthwise . lasx . cpp - - imgcodecs : openexr codec is disabled in runtime . details : <url> - - highgui : using builtin backend : win32ui - - ceres support is disabled . ceres solver for reconstruction api is required . - - building with nvidia optical flow api <number> - - found ' misc ' python modules from c <annoyed> lib / opencv / modules / python / package / extra_modules - - found ' mat_wrapper ; utils ' python modules from c <annoyed> lib / opencv / modules / core / misc / python / package - - found ' gapi ' python modules from c <annoyed> lib / opencv / modules / gapi / misc / python / package - - found ' misc ' python modules from c <annoyed> lib / opencv / modules / python / package / extra_modules - - found ' mat_wrapper ; utils ' python modules from c <annoyed> lib / opencv / modules / core / misc / python / package - - found ' gapi ' python modules from c <annoyed> lib / opencv / modules / gapi / misc / python / package - - dnnl_configuration : cpu_dpcpp_gpu_dpcpp - - sycl / opencl samples are skipped : sycl sdk is required - - - check configuration of sycl_dir / sycl_root / cmake_module_path - - - ensure that right compiler is selected from sycl sdk ( e . g , clang + + <sad> cmake_cxx_compiler =c <annoyed> program files / microsoft visual studio / <number> / community / vc / tools / msvc / <number> . <number> / bin / hostx64 / x64 / cl . exe - - registered ' check_pylint ' target : using c <annoyed> users / laurent / appdata / roaming / python / python310 / scripts / pylint . exe ( ver : <number> . <number> ) , checks : <number> - - registered ' check_flake8 ' target : using c <annoyed> users / laurent / appdata / roaming / python / python310 / scripts / flake8 . exe ( ver : <number> . <number> ) cmake warning at cmake / opencvgensetupvars . cmake : <number> ( message ) : configuration is not supported : validate setupvars script in install directory call stack ( most recent call first ) : cmakelists . txt : <number> ( include ) - - - - general configuration for opencv <number> . <number> - dev = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - version control : <number> . <number> - <number> - g1a8d37d19e - - - - extra modules : - - location ( extra ) : c <annoyed> lib / opencv_contrib / modules - - version control ( extra ) : <number> . <number> - <number> - g9e134699 - - - - platform : - - timestamp : <number> - <number> - 0 9 t <time> z - - host : windows <number> . <number> amd64 - - cmake : <number> . <number> - - cmake generator : visual studio <number> <number> - - cmake build tool : c <annoyed> program files / microsoft visual studio / <number> / community / msbuild / current / bin / amd64 / msbuild . exe - - msvc : <number> - - configuration : debug release - - - - cpu / hw features : - - baseline : sse sse2 sse3 - - requested : sse3 - - dispatched code generation : sse4_1 sse4_2 fp16 avx avx2 avx512_skx - - requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx - - sse4_1 ( <number> files ) : + ssse3 sse4_1 - - sse4_2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 - - fp16 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 avx - - avx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 avx - - avx2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 - - avx512_skx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 avx_512f avx512_common avx512_skx - - - - c / c + + : - - built as dynamic libs ? : yes - - c + + standard : <number> - - c + + compiler : c <annoyed> program files / microsoft visual studio / <number> / community / vc / tools / msvc / <number> . <number> / bin / hostx64 / x64 / cl . exe ( ver <number> . <number> ) - - c + + flags ( release ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / / dndebug - - c + + flags ( debug ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / / od / rtc1 - - c compiler : c <annoyed> program files / microsoft visual studio / <number> / community / vc / tools / msvc / <number> . <number> / bin / hostx64 / x64 / cl . exe - - c flags ( release ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / md / o2 / ob2 / dndebu - - c flags ( debug ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / mdd / zi / ob0 / od / rtc - - linker flags ( release ) : / machine <kiss> 6 4 / incremental : no - - linker flags ( debug ) : / machine <kiss> 6 4 / debug / incremental - - ccache : no - - precompiled headers : yes - - extra dependencies : cudart_static . lib nppc . lib nppial . lib nppicc . lib nppidei . lib nppif . lib nppig . lib nppim . lib nppist . lib nppisu . lib nppitc . lib npps . lib cublas . lib cudnn . lib cufft . lib - liv12 . <number> / lib / x64 - - 3 rdparty dependencies : - - - - opencv modules : - - to be built : alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudasperres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform java line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg superres surface_matching text tracking ts video videoio videostab viz wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto - - disabled : world - - disabled by dependency : - - - unavailable : cvv freetype hdf julia matlab ovis python2 - - applications : tests perf_tests examples apps - - documentation : doxygen python javadoc - - non - free algorithms : yes - - - - windows rt support : no - - - - gui : win32ui - - win32 ui : yes - - opengl support : yes ( opengl32 glu32 ) - - vtk support : yes ( ver <number> . <number> ) - - - - media i / <surprise> - - zlib : optimized c <annoyed> install / zlib / lib / zlib . lib debug c <annoyed> install / zlib / lib / zlibd . lib ( ver <date> ) - - jpeg : build - libjpeg - turbo ( ver <number> . <number> - <number> ) - - simd support request : yes - - simd support : no - - webp : build ( ver encoder : 0x0 2 0 f ) - - png : optimized c <annoyed> install / libpng / lib / libpng16 . lib debug c <annoyed> install / libpng / lib / libpng16d . lib ( ver <date> ) - - tiff : build ( ver <number> - <number> . <number> ) - - jpeg <number> : build ( ver <number> . <number> ) - - openexr : build ( ver <number> . <number> ) - - hdr : yes - - sunraster : yes - - pxm : yes - - pfm : yes - - - - video i / <surprise> - - dc1394 : no - - ffmpeg : yes ( prebuilt binaries ) - - avcodec : yes ( <number> . <number> ) - - avformat : yes ( <number> . <number> ) - - avutil : yes ( <number> . <number> ) - - swscale : yes ( <date> ) - - avresample : yes ( <number> . <number> ) - - gstreamer : no - - directshow : yes - - media foundation : yes - - dxva : yes - - - - parallel framework : tbb ( ver <number> interface <number> ) - - - - other third - party libraries : - - intel ipp : <number> [ <number> . <number> ] - - at : c <annoyed> lib / build / opencv / 3 rdparty / ippicv / ippicv_win / icv - - intel ipp iw : sources ( <number> . <number> ) - - at : c <annoyed> lib / build / opencv / 3 rdparty / ippicv / ippicv_win / iw - - lapack : no - - openvino : yes ( <number> . <number> ) - - default dnn backend : dnn_backend_opencv - - eigen : yes ( ver . <repeated> ) - - custom hal : no - - protobuf : build ( <number> . <number> ) - - flatbuffers : builtin / 3 rdparty ( <number> . <number> ) - - - - nvidia cuda : yes ( ver <number> , cufft cublas ) - - nvidia gpu arch : <number> - - nvidia ptx archs : - - - - cudnn : yes ( ver <number> . <number> ) - - - - opencl : yes ( nvd3d11 ) - - include path : c <annoyed> lib / opencv / 3 rdparty / include / opencl / <number> - - link libraries : dynamic load - - - - python <number> : - - interpreter : c <annoyed> program files / python310 / python . exe ( ver <date> ) - - libraries : optimized c <annoyed> program files / python310 / libs / python310 . lib debug c <annoyed> program files / python310 / libs / python310_d . lib ( ver <date> ) - - numpy : c <annoyed> users / laurent / appdata / roaming / python / python310 / site - packages / numpy / core / include ( ver <number> . <number> ) - - install path : c <annoyed> users / laurent / appdata / roaming / python / python310 / site - packages / cv2 / python - <number> - - - - python ( for build ) : c <annoyed> program files / python310 / python . exe - - - - java : - - ant : c <annoyed> apache - ant - <date> / bin / ant . bat ( ver <date> ) - - java : no - - jni : c <annoyed> program files / java / jdk - <number> / include c <annoyed> program files / java / jdk - <number> / include / win32 c <annoyed> program files / java / jdk - <number> / include - - java wrappers : yes ( ant ) - - java tests : yes - - - - install to : c <annoyed> install / opencv - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - configuring done ( <number> . 2 s ) - - generating done ( <number> . 2 s ) - - build files have been written to : c <annoyed> lib / build / opencv ` ` ` # # # detailed description i cannot build opencv dnn module . ` ` ` <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ net_openvino . cpp ( <number> <sad> error c2819 : type ' ov : : output < ov : : node > ' does not have an overloaded member ' operator - > ' <number> > c :\\ install \ \ openvino \ \ runtime \ \ include \ \ openvino / core / node_output . hpp ( <number> <sad> message : see declaration of ' ov : : output < ov : : node > ' <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ net_openvino . cpp ( <number> <sad> message : did you intend to use ' . ' instead ? <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ net_openvino . cpp ( <number> <sad> error c2039 : ' get_friendly_name ' : is not a member of ' ov : : output < ov : : node > ' <number> > c :\\ install \ \ openvino \ \ runtime \ \ include \ \ openvino / core / node_output . hpp ( <number> <sad> message : see declaration of ' ov : : output < ov : : node > ' ` ` ` full build build started . <repeated> ` ` ` <number> > - - - - - - build started : project : opencv_dnn , configuration : debug x64 - - - - - - <number> > processing opencl kernels ( dnn ) <number> > - - c <annoyed> lib / build / opencv / modules / dnn / opencl_kernels_dnn . hpp contains the same content <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_activation_eltwise . cu . obj <number> > activation_eltwise . cu <number> > activation_eltwise . cu <number> > tmpxft_00004d60_00000000 - 1 0 _activation_eltwise . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_activations . cu . obj <number> > activations . cu <number> > activations . cu <number> > tmpxft_0000286c_00000000 - 1 0 _activations . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_bias_activation . cu . obj <number> > bias_activation . cu <number> > bias_activation . cu <number> > tmpxft_000008e8_00000000 - 1 0 _bias_activation . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_bias_activation_eltwise . cu . obj <number> > bias_activation_eltwise . cu <number> > bias_activation_eltwise . cu <number> > tmpxft_00004584_00000000 - 1 0 _bias_activation_eltwise . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_bias_eltwise_activation . cu . obj <number> > bias_eltwise_activation . cu <number> > bias_eltwise_activation . cu <number> > tmpxft_00001984_00000000 - 1 0 _bias_eltwise_activation . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_concat . cu . obj <number> > concat . cu <number> > concat . cu <number> > tmpxft_00003f44_00000000 - 1 0 _concat . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_crop_and_resize . cu . obj <number> > crop_and_resize . cu <number> > crop_and_resize . cu <number> > tmpxft_00000b5c_00000000 - 1 0 _crop_and_resize . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_detection_output . cu . obj <number> > detection_output . cu <number> > detection_output . cu <number> > tmpxft_0000619c_00000000 - 1 0 _detection_output . cudafe1 . cpp <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ cuda \ \ detection_output . cu ( <number> <sad> warning c4805 : ' |': unsafe mix of type ' int ' and type ' bool ' in operation <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ cuda \ \ detection_output . cu ( <number> <sad> note : see reference to function template instantiation ' void cv : : dnn : : cuda4dnn : : kernels : : decode_bboxes <__half> ( const cv : : dnn : : cuda4dnn : : csl : : stream & , cv : : dnn : : cuda4dnn : : csl : : span <__half> , cv : : dnn : : cuda4dnn : : csl : : span < const __half > , cv : : dnn : : cuda4dnn : : csl : : span < const __half > , size_t , bool , size_t , bool , bool , bool , bool , bool , float , float ) ' being compiled <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_eltwise_activation . cu . obj <number> > eltwise_activation . cu <number> > eltwise_activation . cu <number> > tmpxft_00003ed0_00000000 - 1 0 _eltwise_activation . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_eltwise_ops . cu . obj <number> > eltwise_ops . cu <number> > eltwise_ops . cu <number> > tmpxft_00004e1c_00000000 - 1 0 _eltwise_ops . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_fill_copy . cu . obj <number> > fill_copy . cu <number> > fill_copy . cu <number> > tmpxft_00001d8c_00000000 - 1 0 _fill_copy . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_fp_conversion . cu . obj <number> > fp_conversion . cu <number> > fp_conversion . cu <number> > tmpxft_000035fc_00000000 - 1 0 _fp_conversion . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_grid_nms . cu . obj <number> > grid_nms . cu <number> > grid_nms . cu <number> > tmpxft_00003cc8_00000000 - 1 0 _grid_nms . cudafe1 . cpp <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ cuda \ \ grid_nms . cu ( <number> <sad> warning c4189 : ' items_per_thread ' : local variable is initialized but not referenced <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ cuda \ \ grid_nms . cu ( <number> <sad> note : see reference to function template instantiation ' void cv : : dnn : : cuda4dnn : : kernels : : grid_nms <__half> ( const cv : : dnn : : cuda4dnn : : csl : : stream & , cv : : dnn : : cuda4dnn : : csl : : span < unsigned int > , cv : : dnn : : cuda4dnn : : csl : : tensorspan <int> , cv : : dnn : : cuda4dnn : : csl : : tensorspan <int> , cv : : dnn : : cuda4dnn : : csl : : tensorview <__half> , int , bool , float ) ' being compiled <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_max_unpooling . cu . obj <number> > max_unpooling . cu <number> > max_unpooling . cu <number> > tmpxft_000060ec_00000000 - 1 0 _max_unpooling . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_mvn . cu . obj <number> > mvn . cu <number> > mvn . cu <number> > tmpxft_00004f48_00000000 - 1 0 _mvn . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_normalize . cu . obj <number> > normalize . cu <number> > normalize . cu <number> > tmpxft_00003c28_00000000 - 1 0 _normalize . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_padding . cu . obj <number> > padding . cu <number> > padding . cu <number> > tmpxft_00005010_00000000 - 1 0 _padding . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_permute . cu . obj <number> > permute . cu <number> > permute . cu <number> > tmpxft_000067c8_00000000 - 1 0 _permute . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_prior_box . cu . obj <number> > prior_box . cu <number> > prior_box . cu <number> > tmpxft_0000293c_00000000 - 1 0 _prior_box . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_region . cu . obj <number> > region . cu <number> > region . cu <number> > tmpxft_00003b00_00000000 - 1 0 _region . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_resize . cu . obj <number> > resize . cu <number> > resize . cu <number> > tmpxft_00006588_00000000 - 1 0 _resize . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_roi_pooling . cu . obj <number> > roi_pooling . cu <number> > roi_pooling . cu <number> > tmpxft_00005d70_00000000 - 1 0 _roi_pooling . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_scale_shift . cu . obj <number> > scale_shift . cu <number> > scale_shift . cu <number> > tmpxft_00000bb0_00000000 - 1 0 _scale_shift . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_shortcut . cu . obj <number> > shortcut . cu <number> > shortcut . cu <number> > tmpxft_00003830_00000000 - 1 0 _shortcut . cudafe1 . cpp <number> > building nvcc ( device ) object modules / dnn / cmakefiles / cuda_compile_1 . dir / src / cuda / debug / cuda_compile_1_generated_slice . cu . obj <number> > slice . cu <number> > slice . cu <number> > tmpxft_00000c34_00000000 - 1 0 _slice . cudafe1 . cpp <number> > cmake_pch . cxx <number> > opencv - caffe . pb . cc <number> > opencv - onnx . pb . cc <number> > attr_value . pb . cc <number> > function . pb . cc <number> > graph . pb . cc <number> > op_def . pb . cc <number> > tensor . pb . cc <number> > tensor_shape . pb . cc <number> > types . pb . cc <number> > versions . pb . cc <number> > caffe_importer . cpp <number> > caffe_io . cpp <number> > caffe_shrinker . cpp <number> > darknet_importer . cpp <number> > darknet_io . cpp <number> > debug_utils . cpp <number> > dnn . cpp <number> > dnn_read . cpp <number> > dnn_utils . cpp <number> > graph_simplifier . cpp <number> > halide_scheduler . cpp <number> > ie_ngraph . cpp <number> > init . cpp <number> > quantization_utils . cpp <number> > layer . cpp <number> > layer_factory . cpp <number> > accum_layer . cpp <number> > arg_layer . cpp <number> > blank_layer . cpp <number> > concat_layer . cpp <number> > const_layer . cpp <number> > correlation_layer . cpp <number> > conv_depthwise . cpp <number> > conv_winograd_f63 . cpp <number> > convolution . cpp <number> > crop_and_resize_layer . cpp <number> > cumsum_layer . cpp <number> > detection_output_layer . cpp <number> > flatten_layer . cpp <number> > flow_warp_layer . cpp <number> > gather_layer . cpp <number> > layer_norm . cpp <number> > layers_common . cpp <number> > lrn_layer . cpp <number> > max_unpooling_layer . cpp <number> > mvn_layer . cpp <number> > nary_eltwise_layers . cpp <number> > normalize_bbox_layer . cpp <number> > not_implemented_layer . cpp <number> > padding_layer . cpp <number> > permute_layer . cpp <number> > prior_box_layer . cpp <number> > proposal_layer . cpp <number> > recurrent_layers . cpp <number> > reduce_layer . cpp <number> > region_layer . cpp <number> > reorg_layer . cpp <number> > reshape_layer . cpp <number> > resize_layer . cpp <number> > scatternd_layer . cpp <number> > scatter_layer . cpp <number> > shuffle_channel_layer . cpp <number> > slice_layer . cpp <number> > split_layer . cpp <number> > tile_layer . cpp <number> > legacy_backend . cpp <number> > model . cpp <number> > net . cpp <number> > net_cann . cpp <number> > net_impl . cpp <number> > net_impl_backend . cpp <number> > net_impl_fuse . cpp <number> > net_openvino . cpp <number> > net_quantization . cpp <number> > nms . cpp <number> > common . cpp <number> > math_functions . cpp <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ net_openvino . cpp ( <number> <sad> error c2819 : type ' ov : : output < ov : : node > ' does not have an overloaded member ' operator - > ' <number> > c :\\ install \ \ openvino \ \ runtime \ \ include \ \ openvino / core / node_output . hpp ( <number> <sad> message : see declaration of ' ov : : output < ov : : node > ' <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ net_openvino . cpp ( <number> <sad> message : did you intend to use ' . ' instead ? <number> > c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ net_openvino . cpp ( <number> <sad> error c2039 : ' get_friendly_name ' : is not a member of ' ov : : output < ov : : node > ' <number> > c :\\ install \ \ openvino \ \ runtime \ \ include \ \ openvino / core / node_output . hpp ( <number> <sad> message : see declaration of ' ov : : output < ov : : node > ' <number> > ocl4dnn_conv_spatial . cpp <number> > ocl4dnn_inner_product . cpp <number> > ocl4dnn_lrn . cpp <number> > ocl4dnn_pool . cpp <number> > ocl4dnn_softmax . cpp <number> > onnx_graph_simplifier . cpp <number> > onnx_importer . cpp <number> > op_cann . cpp <number> > op_cuda . cpp <number> > op_halide . cpp <number> > op_inf_engine . cpp <number> > op_timvx . cpp <number> > op_vkcom . cpp <number> > op_webnn . cpp <number> > registry . cpp <number> > tf_graph_simplifier . cpp <number> > tf_importer . cpp <number> > tf_io . cpp <number> > tflite_importer . cpp <number> > thdiskfile . cpp <number> > thfile . cpp <number> > thgeneral . cpp <number> > torch_importer . cpp <number> > conv_1x1_fast_spv . cpp <number> > conv_depthwise_3x3_spv . cpp <number> > conv_depthwise_spv . cpp <number> > conv_implicit_gemm_spv . cpp <number> > gemm_spv . cpp <number> > spv_shader . cpp <number> > buffer . cpp <number> > command . cpp <number> > context . cpp <number> > fence . cpp <number> > internal . cpp <number> > op_base . cpp <number> > op_conv . cpp <number> > op_matmul . cpp <number> > pipeline . cpp <number> > tensor . cpp <number> > vk_functions . cpp <number> > vk_loader . cpp <number> > opencl_kernels_dnn . cpp <number> > opencv_dnn_main . cpp <number> > done building project "" opencv_dnn . vcxproj "" - - failed . = = = = = = = = = = build succeeded , <number> failed , <number> up - to - date , <number> skipped = = = = = = = = = = ` ` ` = = = = = = = = = = build started at <time> and took <time> , <number> minutes = = = = = = = = = = # # # steps to reproduce no revelvant # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"check that cv : : merge input matrices are not empty resolves # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"fix extenddictionary fixes <url> now , if the size of base dictionary is higher than markers , only the first markers in base dictionary are taken and no new marker is added . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"incorrect dictionary size returned from cv : : aruco : : extenddictionary # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version <number> # # # detailed description according to the documentation for extenddictionary , if the size of basedictionary is higher than nmarkers , only the first nmarkers in basedictionary are taken and no new marker is added . however , if nmarkers is smaller than the size of basedictionary , the complete basedictionary will be returned . ` ` ` /* * <user> extend base dictionary by new nmarkers * * <user> nmarkers number of markers in the dictionary * <user> markersize number of bits per dimension of each markers * <user> basedictionary include the markers in this dictionary at the beginning ( optional ) * <user> randomseed a user supplied seed for therng ( ) * * this function creates a new dictionary composed by nmarkers markers and each markers composed * by markersize x markersize bits . if basedictionary is provided , its markers are directly * included and the rest are generated based on them . if the size of basedictionary is higher * than nmarkers , only the first nmarkers in basedictionary are taken and no new marker is added . */ cv_exports_w dictionary extenddictionary ( int nmarkers , int markersize , const dictionary & basedictionary = dictionary ( ) , int randomseed = <number> ); ` ` ` # # # steps to reproduce ` ` ` cv : : aruco : : dictionary base_dictionary = cv : : aruco : : getpredefineddictionary ( cv : : aruco : : dict_4x4_250 ) ; cv : : aruco : : dictionary custom_dictionary = cv : : aruco : : extenddictionary ( <number> , <number> , base_dictionary ) ; ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"distancetransform for inputs with large step and height # # # pull request readiness checklist resolves <url> see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"fix "" use after free "" issue in ` essential_solver . cpp ` the address sanitizer highlighted this issue in our code base . it looks like the code is currently grabbing a pointer to a temporary object and then performing operations on it . i printed some information right before the asan crash : eigensolver address : 0x 7 f0ad95032f0 eigensolver size : <number> eig_vecs_ ptr : 0x 7 f0ad95045e0 eig_vecs_ offset : <number> this shows that ` eig_vecs_ ` points past the end of ` eigensolver ` . in other words , it points at the temporary object created by the ` eigensolver . eigenvectors ( ) ` call . compare the docs for ` . eigenvalues ( ) ` : <url> to the docs for ` . eigenvectors ( ) ` : <url> the difference in return types is interesting . ` . eigenvalues ( ) ` returns a reference . but ` . eigenvectors ( ) ` returns a matrix . this patch here fixes the problem by saving the temporary object and then grabbing a pointer into it . this is a curated snippet of the original asan failure : = = <number> = = error : addressanitizer <elongated> : stack - use - after - scope on address 0x 7 fc633704640 at pc 0x 7 fc64f7f1593 bp 0x 7 ffe8875fc90 sp 0x 7 ffe8875fc88 read of size <number> at 0x 7 fc633704640 thread t0 # <number> 0x 7 fc64f7f1592 in cv : : usac : : essentialminimalsolverstewenius5ptsimpl : : estimate ( std : : __1 : : vector < int , std : : __1 : : allocator <int> > const & , std : : __1 : : vector < cv : : mat , std : : __1 : : allocator < cv : : mat > > & ) const / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / usac / essential_solver . cpp : <number> <time> # <number> 0x 7 fc64f915d92 in cv : : usac : : essentialestimatorimpl : : estimatemodels ( std : : __1 : : vector < int , std : : __1 : : allocator <int> > const & , std : : __1 : : vector < cv : : mat , std : : __1 : : allocator < cv : : mat > > & ) const / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / usac / estimator . cpp : <number> <time> # <number> 0x 7 fc64fa74fb0 in cv : : usac : : ransac : : run ( cv : : ptr < cv : : usac : : ransacoutput > & ) / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / usac / ransac_solvers . cpp : <number> <time> # <number> 0x 7 fc64fa6cd8e in cv : : usac : : run ( cv : : ptr < cv : : usac : : model const > const & , cv : : _inputarray const & , cv : : _inputarray const & , int , cv : : ptr < cv : : usac : : ransacoutput > & , cv : : _inputarray const & , cv : : _inputarray const & , cv : : _inputarray const & , cv : : _inputarray const & ) / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / usac / ransac_solvers . cpp : <number> <time> # <number> 0x 7 fc64fa6fb46 in cv : : usac : : findessentialmat ( cv : : _inputarray const & , cv : : _inputarray const & , cv : : _inputarray const & , int , double , double , cv : : _outputarray const & ) / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / usac / ransac_solvers . cpp : <number> : <number> # <number> 0x 7 fc64f3b5522 in cv : : findessentialmat ( cv : : _inputarray const & , cv : : _inputarray const & , cv : : _inputarray const & , int , double , double , int , cv : : _outputarray const & ) / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / five - point . cpp : <number> <time> # <number> 0x 7 fc64f3b7e00 in cv : : findessentialmat ( cv : : _inputarray const & , cv : : _inputarray const & , cv : : _inputarray const & , int , double , double , cv : : _outputarray const & ) / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / five - point . cpp : <number> <time> . <repeated> address 0x 7 fc633704640 is located in stack of thread t0 at offset <number> in frame # <number> 0x 7 fc64f7ed4ff in cv : : usac : : essentialminimalsolverstewenius5ptsimpl : : estimate ( std : : __1 : : vector < int , std : : __1 : : allocator <int> > const & , std : : __1 : : vector < cv : : mat , std : : __1 : : allocator < cv : : mat > > & ) const / proc / self / cwd / external / com_github_opencv_opencv / modules / calib3d / src / usac / essential_solver . cpp : <number> this frame has <number> object ( s ) : [ <number> , <number> ) ' coefficients ' ( line <number> ) [ <number> , <number> ) ' ee ' ( line <number> ) . <repeated> [ <number> , <number> ) ' eigensolver ' ( line <number> ) [ <number> , <number> ) ' ref . tmp518 ' ( line <number> ) [ <number> , <number> ) ' ref . tmp523 ' ( line <number> ) [ <number> , <number> ) ' ref . tmp524 ' ( line <number> ) <== memory access at offset <number> is inside this variable [ <number> , <number> ) ' ref . tmp532 ' ( line <number> ) . <repeated> the crash report says that we are accessing a temporary object from line <number> when we should not be . line <number> looks like this : <url> const auto * const eig_vecs_ = ( double <wink> eigensolver . eigenvectors ( ) . real ( ) . data ( ); we are using version <number> . <number> for this , but the problem is present on the <number> . x branch . note that i am dropping the ` . real ( ) ` call here . i think that is safe because of the code further down ( line <number> in the most recent version ) const int eig_i = <number> * i + <number> ; / / eigen stores imaginary values too ` ` ` the code appears to expect to have to skip doubles for the imaginary parts of the complex numbers . admittedly , i could not find a test case that exercised this code path to validate correctness .",0
opencv/opencv,"cv : : max function in - place operation gets wrong result # # # system information opencv version : <number> . <number> operating system / platform : windows <number> compiler & compiler version <number> # # # detailed description given cv : : mat a and a b ( b is a 1 x1x1 mat ) , calling function cv : : max ( a , b , a ) and cv : : max ( a , b , b ) gets different result . it seems that the former calling is right . the latter calling results in b is set to the same size with a , however , every pixel of b will be set to <number> ( 0 xcd ) . # # # steps to reproduce ` ` ` cv : : mat a = cv : : mat : : ones ( <number> , <number> , cv_8uc1 ) * <number> ; cv : : mat b ( <number> , <number> , cv_8uc1 ) ; b . setto ( <number> ); cv : : max ( a , b , a ) ; cv : : max ( a , b , b ) ;// wrong ` ` ` i checked source code , seems to cause by line <number> in [ <url> wondering it is count for a bug ? # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fix compilation on arm64 with fp16 when disabled if building with - mcpu = native or any other setting which implies the current cpu has fp16 but with intrinsics disabled , we mistakenly try to use it even though convolution . hpp conditionally defines it correctly based on whether we should * use it * . convolution . cpp on the other hand was mismatched and trying to use it if the cpu supported it , even if not enabled in the build system . make the guards match . bug # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"fix compilation when forcing later c + + . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch",0
opencv/opencv,"fixed the channels when capturing yuv422 with v4l2 backend example to reproduce the problem ` ` ` cpp <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> < opencv2 / core . hpp > <hashtag> include </hashtag> < opencv2 / highgui . hpp > <hashtag> include </hashtag> < opencv2 / imgproc . hpp > <hashtag> include </hashtag> < opencv2 / videoio . hpp > using namespace cv ; using namespace std ; void help_func ( videocapture & cap ) { int height = cap . get ( cv : : cap_prop_frame_height ) ; int width = cap . get ( cv : : cap_prop_frame_width ) ; int pixel_type = cap . get ( cv : : cap_prop_format ) ; int channels = cv_mat_cn ( pixel_type ) ; int pixel_bytes = cv_elem_size ( pixel_type ) ; bool to_bgr = static_cast <bool> ( cap . get ( cv : : cap_prop_convert_rgb ) ); std : : cout < < "" backend : "" < < cap . getbackendname ( ) < < std : : endl ; std : : cout < < std : : hex < < "" fourcc : "" < < static_cast <int> ( cap . get ( cv : : cap_prop_fourcc ) ) < < std : : endl ; std : : cout < < std : : boolalpha < < "" to_bgr : "" < < to_bgr < < std : : endl ; std : : cout < < std : : dec < < "" height : "" < < height < < "" width : "" < < width < < "" channels : "" < < channels < < "" pixel_bytes : "" < < pixel_bytes < < std : : endl ; std : : cout < < "" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "" < < std : : endl ; } int main ( int , char * <wink> { videocapture cap ; cap . open ( "" / dev / video0 "" ); if ( cap . isopened ( ) ) { cerr < < "" error ! unable to open camera \ \ n "" ; return - <number> ; } { help_func ( cap ) ; } { cap . set ( cv : : cap_prop_frame_height , <number> ); cap . set ( cv : : cap_prop_frame_width , <number> ); cap . set ( cv : : cap_prop_convert_rgb , <number> ); help_func ( cap ) ; } / / { / / cap . set ( cv : : cap_prop_convert_rgb , <number> ); / / cap . set ( cv : : cap_prop_frame_height , <number> ); / / cap . set ( cv : : cap_prop_frame_width , <number> ); / / help_func ( cap ) ; / / } mat frame ; int frame_idx = <number> ; while ( cap . read ( frame ) ) { std : : cout < < "" frame index : "" < < frame_idx + + < < std : : endl ; help_func ( cap ) ; if ( frame . empty ( ) ) { cerr < < "" error ! blank frame grabbed \ \ n "" ; break ; } mat bgr ; if ( cap . get ( cv : : cap_prop_convert_rgb ) ) { bgr = frame ; } else { cv : : cvtcolor ( frame , bgr , cv : : color_yuv2bgr_yuyv ) ; } imshow ( "" frame "" , bgr ) ; if ( waitkey ( <number> ) >= <number> ) { break ; } } return <number> ; } ` ` ` the above code will get the wrong channels . by changing lines <number> - <number> like below , can get the correct channels . < img width = "" <number> "" alt = "" code "" src = "" <url> this is because ` cap . set ( cv : : cap_prop_frame_height , <number> ); ` and ` cap . set ( cv : : cap_prop_frame_width , <number> ); ` reinitialize the ` frame ` , but ` cap . set ( cv : : cap_prop_convert_rgb , <number> ); ` not . log info . < img width = "" <number> "" alt = "" log "" src = "" <url> we can also observe that we get the correct channels in the while loop . this is because reinitialize the ` frame ` .",0
opencv/opencv,"cv : : videowriter with cap_opencv_mjpeg api creates broken ( or just unfinished ) video file . # # # system information opencv version : <number> . <number> windows <number> microsoft visual studio <number> 6 4 bit # # # detailed description if i create a certain video using cv : : videowriter with cap_opencv_mjpeg api , i can load the video correctly using cv : : videocapture , but i get an error message during loading . ` ` ` [ mjpeg @ 0 0 0 0 0 1 5 a20f1df00 ] error count [ mjpeg @ 0 0 0 0 0 1 5 a20f1df00 ] error y = <number> x= <number> ` ` ` also i can watch the created video using windows media player without any errors . if i create the same video using cap_ffmpeg api , i do not get error messages . the error reproduces only on a certain video content , so i can create a different video with the same size without error messages . # # # steps to reproduce ` ` ` <hashtag> include </hashtag> < opencv2 / highgui . hpp > <hashtag> include </hashtag> < opencv2 / imgcodecs . hpp > <hashtag> include </hashtag> < opencv2 / imgproc . hpp > <hashtag> include </hashtag> <iostream> int w = <number> ; int h = <number> ; int num_frames = <number> ; void savevideo ( std : : string filename , cv : : videocaptureapis api , long base_color ) { cv : : videowriter writer ( filename , api , cv : : videowriter : : fourcc ( ' m ' , ' j ' , ' p ' , ' g ' ) , <number> , cv : : size ( w , h ) , true ) ; for ( long i = <number> ; i < num_frames ; + + i ) { cv : : mat frame1 ( h , w , cv_8uc3 ) ; for ( long x = <number> ; x < w ; x + + ) { for ( long y = <number> ; y < h ; y + + ) { frame1 . at < cv : : vec3b > ( y , x) = cv : : vec3b ( ( base_color * x) % <number> , base_color + <number> , base_color + <number> ); } } writer . write ( frame1 ) ; } writer . release ( ); } void loadvideo ( std : : string filename ) { std : : cout < < "" = = = = = loading "" < < filename < < std : : endl < < std : : flush ; cv : : videocapture cap ( filename , cv : : cap_ffmpeg ) ; if ( cap . isopened ( ) ) { std : : cout < < "" no video stream detected "" < < std : : endl ; return ; } cv : : mat frame ; uint32_t frame_cnt = <number> ; while ( true ) { cap > > frame ; if ( frame . empty ( ) ) { break ; } } cap . release ( ); std : : cout < < "" = = = = = loaded "" < < filename < < std : : endl < < std : : flush ; } int main ( int argc , char * argv [ ] ) { savevideo ( "" out1 . avi "" , cv : : cap_ffmpeg , <number> ); savevideo ( "" out2 . avi "" , cv : : cap_ffmpeg , <number> ); savevideo ( "" out3 . avi "" , cv : : cap_opencv_mjpeg , <number> ); savevideo ( "" out4 . avi "" , cv : : cap_opencv_mjpeg , <number> ); loadvideo ( "" out1 . avi "" ); loadvideo ( "" out2 . avi "" ); loadvideo ( "" out3 . avi "" ); loadvideo ( "" out4 . avi "" ); / / prints error message } ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"add missing include # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work ( <url>",0
opencv/opencv,"error in python but not in c + + # # # system information opencv <number> even with branch <number> . x python binding build using this branch i changed source code of void net : : setinput ( inputarray blob , const string & name , double scalefactor , const scalar & mean ) to whatch data new source code is ` ` ` void net : : setinput ( inputarray blob , const string & name , double scalefactor , const scalar & mean ) { cv_trace_function ( ); cv_trace_arg_value ( name , "" name "" , name . c_str ( )); cv_assert ( impl ) ; mat blobx = blob . getmat ( ); std : : cout < < name < < "" layer \ \ n "" ; std : : cout < < blobx . channels ( ) < < "" channel \ \ n "" ; for ( int i = <number> ; i < blobx . dims ; i + + ) { std : : cout < < "" dim "" < < i < < "" : "" < < blobx . size [ i ] < < "" \ \ t "" ; } std : : cout < < "" \ \ n "" ; return impl - > setinput ( blob , name , scalefactor , mean ) ; } ` ` ` # # # detailed description when i run my python code i have got an error : ` ` ` image_embeddings layer <number> channel dim <number> : <number> dim <number> : <number> dim <number> : <number> dim <number> : <number> coord shape : ( <number> , <number> , <number> ) point_coords layer <number> channel dim <number> : <number> dim <number> : <number> * * point_labels layer <number> channel dim <number> : <number> dim <number> : <number> mask_input layer <number> channel dim <number> : <number> dim <number> : <number> dim <number> : <number> dim <number> : <number> <number> channel dim <number> : <number> dim <number> : <number> [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively opencv / dnn : [ innerproduct ] <sad> onnx_node / matmul ) : getmemoryshapes ( ) throws exception . inputs = <number> outputs = <number> / <number> blobs = <number> [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively input [ <number> ] = [ <number> <number> ] [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively blobs [ <number> ] = cv_32fc1 [ <number> <number> ] [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively exception message : opencv ( <number> . <number> - dev ) c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ include \ \ opencv2 / dnn / shape_utils . hpp : <number> : error : ( - <number> : unspecified error ) in function ' int __cdecl cv : : dnn : : dnn4_v20230620 : : normalize_axis ( int , int ) ' > : > ' axis >= - dims & & axis < dims ' > where > ' axis ' is <number> traceback ( most recent call last ) : file "" <stdin> "" , line <number> , in <module> file "" <string> "" , line <number> , in <module> cv2 . error : opencv ( <number> . <number> - dev ) c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ include \ \ opencv2 / dnn / shape_utils . hpp : <number> : error : ( - <number> : unspecified error ) in function ' int __cdecl cv : : dnn : : dnn4_v20230620 : : normalize_axis ( int , int ) ' > : > ' axis >= - dims & & axis < dims ' > where > ' axis ' is <number> ` ` ` <s> i think problem is ` ` ` coord shape : ( <number> , <number> , <number> ) point_coords layer <number> channel dim <number> : <number> dim <number> : <number> ` ` ` why dim size is not <number> , <number> , <number> </s> when i run same code in c + + result is ` ` ` image_embeddings layer <number> channel dim <number> : <number> dim <number> : <number> dim <number> : <number> dim <number> : <number> point_coords layer <number> channel dim <number> : <number> dim <number> : <number> dim <number> : <number> point_labels layer <number> channel dim <number> : <number> dim <number> : <number> mask_input layer <number> channel dim <number> : <number> dim <number> : <number> dim <number> : <number> dim <number> : <number> has_mask_input layer <number> channel dim <number> : <number> dim <number> : <number> ` ` ` dim size for point_coords is point_coords layer <number> channel dim <number> : <number> dim <number> : <number> dim <number> : <number> that ' s good in c + + # # # steps to reproduce python code ` ` ` import numpy as np import cv2 as cv input_point = np . array ( [ [ <number> , <number> ] ] ) input_label = np . array ( [ <number> ] ) coord = np . concatenate ( [ input_point , np . zeros ( ( <number> ) ) ] , axis = <number> ) [ none , :, <happy> . astype ( np . float32 ) label = np . concatenate ( [ input_label , np . array ( [ - <number> ] ) ] , axis = <number> ) [ none , <happy> . astype ( np . float32 ) mask_input = np . zeros ( ( <number> , <number> , <number> , <number> ) , dtype = np . float32 ) has_mask_input = np . zeros ( <number> , dtype = np . float32 ) decoder_onnx_ocv__name = "" sam_vit_b . fixed . nopost . sim . onnx "" net_decoder = cv . dnn . readnet ( decoder_onnx_ocv__name ) net_decoder . setinput ( np . zeros ( ( <number> , <number> , <number> , <number> ) , dtype = np . float32 ) , "" image_embeddings "" ) print ( "" coord shape net_decoder . setinput ( coord , "" point_coords "" ) net_decoder . setinput ( label , "" point_labels "" ) net_decoder . setinput ( mask_input , "" mask_input "" ) net_decoder . setinput ( has_mask_input , "" has_mask_input "" ) net_decoder . setpreferablebackend ( cv . dnn . dnn_backend_opencv ) net_decoder . setpreferabletarget ( cv . dnn . dnn_target_cpu ) output = net_decoder . forward ( [ "" iou_predictions "" , "" low_res_masks "" ] ) ` ` ` c + + code ` ` ` net netmask = readnet ( "" sam_vit_b . fixed . nopost . sim . onnx "" ); mat blob ( vector <int> { <number> , <number> , <number> , <number> } , cv_32fc1 , scalar : : all ( <number> )); netmask . setinput ( blob , "" image_embeddings "" ); mat inputpoint = ( mat_ <float> ( <number> , <number> ) < < <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> ); vector <int> dimpoint { <number> , <number> , <number> }; mat blobpoint = inputpoint . reshape ( <number> , dimpoint ) ; netmask . setinput ( blobpoint , "" point_coords "" ); mat bloblabel ( <number> , <number> , cv_32fc1 , scalar ( - <number> )); bloblabel . at <float> ( <number> , <number> ) = <number> ; netmask . setinput ( bloblabel , "" point_labels "" ); mat maskinput ( vector <int> { <number> , <number> , <number> , <number> } , cv_32fc1 ) ; netmask . setinput ( maskinput , "" mask_input "" ); mat hasmaskinputmat ( vector <int> { <number> } , cv_32fc1 , scalar : : all ( <number> )); netmask . setinput ( hasmaskinputmat , "" has_mask_input "" ); vector <mat> blobout ( <number> ); const vector <string> outputname { "" iou_predictions "" , "" low_res_masks "" }; netmask . setpreferablebackend ( dnn_backend_opencv ) ; netmask . setpreferabletarget ( dnn_target_cpu ) ; netmask . forward ( blobout , outputname ) ; return <number> ; ` ` ` model is [ here ] ( <url> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"how to use ipp_minmaxidx ? # # # system information opencv version : <number> . <number> operating system / platform : centos <number> compiler & compiler version <number> . <number> # # # detailed description minmaxidx function takes a long time in opencv <number> . <number> ， but opencv <number> . <number> very fast # # # steps to reproduce i noticed that in modules / core / src / minmax . cpp head ` ` ` cpp <hashtag> un def </hashtag> have_ipp <hashtag> un def </hashtag> cv_ipp_run_fast <hashtag> define </hashtag> cv_ipp_run_fast ( f , . <repeated> ) <hashtag> un def </hashtag> cv_ipp_run <hashtag> define </hashtag> cv_ipp_run ( c , f , . <repeated> ) ` ` ` what problem to fix ? when can we push it # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fixed buffer overrun ; removed the last two uses of sprintf prefer snprintf , which can never overflow . in one case i cheated and used strcpy , because i cannot figure out the buffer size at that point in the code .",0
opencv/opencv,"python3_packages_path converted to absolute path on first cmake run # # # system information opencv version : <number> . <number> operation system / patform : windows <number> compiler & compiler version : visual studio <number> # # # detailed description the cmake scripts to configure the ` python3_packages_path ` generally support both , absolute and relative paths for the latter . in particular , the generated ` config . py ` of the cv2 module will contain the correct path pointing to the opencv libraries in both cases , either as an absolute or relative path , respectively , depending on an absolute or relative prefix . however , running cmake with a user - defined , relative ` python3_packages_path ` always replaces it with an absolute path during the first run : ` ` ` git clone <url> opencv cmake - s . - b build - d "" python3_packages_path = python "" ` ` ` this generates the following build configuration : ` ` ` - - python <number> : - - interpreter : c <annoyed> program files / python / python . exe ( ver <date> ) - - libraries : c <annoyed> program files / python / libs / python310 . lib ( ver <date> ) - - numpy : c <annoyed> program files / python / lib / site - packages / numpy / core / include ( ver <number> . <number> ) - - install path : c <annoyed> opencv / python / cv2 / python - <number> ` ` ` note that the install path defined by ` python3_packages_path ` contains the * * source directoy * * as a prefix , ` c <annoyed> opencv ` here . after re - running cmake with the same arguments , the relative path is set correctly : ` ` ` cmake - s . - b build - d "" python3_packages_path = python "" ` ` ` ` ` ` - - python <number> : - - interpreter : c <annoyed> program files / python / python . exe ( ver <date> ) - - libraries : c <annoyed> program files / python / libs / python310 . lib ( ver <date> ) - - numpy : c <annoyed> program files / python / lib / site - packages / numpy / core / include ( ver <number> . <number> ) - - install path ` ` ` we investigated the issue already . here , ` python3_packages_path ` is set by ` find_python ( ) ` inside ` opencvdetectpython . cmake ` and it seems that this function does not properly handle absolute and relative prefixes . still , we wanted to report this bug first . we think that something needs to be fixed here , running cmake twice is a rather unsatisfying workaround . or does somebody know a different solution for this issue ? # # # steps to reproduce <number> . clone the repository <number> . run cmake first with ` python3_packages_path ` set to a relative path converts the path to an absolute path . <number> . re - run cmake with the same commands and the path correctly remains relative . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"videoio : fix camera opening with gstreamer plugin related # <number> , # <number> , # <number> steps to reproduce : * build opencv with gstreamer backend as plugin ( ` - dvideoio_plugin_list = gstreamer ` ) * open camera by index using gstreamer backend ( ` videocapture cap ( <number> , cap_gstreamer ) ` ) result capture is not opened , when using gstreamer backend as built - in camera can be opened this was happening due to bug in plugin wrapper .",0
opencv/opencv,"fix bug at blobfromimageswithparams # # ` blobfromimageswithparams ` ( image - s ) apply swap scalefactor for every images when swaprb is true . this patch moves the swap scalefactor code out of the loop , that fix the above issue . we would like to improve the recently introduced function ` blobfromimageswithparams ` with respect to three minor issues that we noticed : - currently , ` mean ` and ` scalefactor ` are recreated for every image , even though they should be reused . maybe the compiler is smart enough to optimize this , still we think the variable should be created / swapped before the main loop . - next , we would like to improve the function ' s robustness with respect to inconsistent arguments , i . e . if a single - channel image is passed but ` swaprb ` is true , as explained below . - finally , we made some minor modifications to follow the coding guidelines ( ` if - else if - else ` instead of nested else ) . function wise , there are two improvements from this : <number> . currently , if the user passes a single - channel image in combination with ` mean ` and ` scalefactor ` values , but unintentionally sets ` swaprb ` to true , the whole result can be silently zeroed . the ` mean ` and ` scalefactor ` arrays will only contain a single value ( whereas the other indices ' values remain <number> ) , but ` swaprb ` will swap out the true mean / scalefactor values and swap in zeros for these instead . there is no warning or assertion , only the whole image will be zeroed by the following multiplication . therefore , we suggest to only swap these values if the image is not a single - channel image , i . e . ` mean ` and ` scalefactor ` contain correct values for all channels , therefore add ` if ( nch > <number> ) ` . <number> . next , a related issue exists in combination with ` dnn_layout_nhwc ` . if the user passes this in combination with a single - channel image and ` swaprb ` is true , the function produces the following error : ` ` ` opencv \ \ modules \ \ core \ \ src \ \ copy . cpp : <number> : error failed ) channels ( ) = = cv_mat_cn ( dtype ) in function ' cv : : mat : : copyto ' ` ` ` this results from first converting the image to rgb ( even though it is grayscale instead of the expected bgr layout ) and , thereafter , copying the resulting three - channel image into the single - channel blob . this is avoided by checking ` nch > <number> ` here , too , which is also consistent to the function ' s implementation of the ` dnn_layout_nchw ` case . both changes can be summarized such that ` swaprb ` only has an effect if the image has at least three channels . most importantly , nothing changes at all if the arguments are consistent . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"fix charuco checkboard fixes # <number> checkboard ( ) is an internal function that checks that the found board has the correct structure <number> . fixed a bug with checking extraneous markers : ` ` ` if ( find ( boardids . begin ( ) , boardids . end ( ) , idmaker ) = = boardids . end ( ) ) continue ; ` ` ` <number> . fixed an indexing bug const int nearestmarkerid1 = boardids [ nearestmarkeridx [ chid ] [ <number> ]]; const int nearestmarkerid2 = boardids [ nearestmarkeridx [ chid ] [ <number> ]]; ` ` ` <number> . updated docs for getnearestmarkeridx ( ) / getnearestmarkercorners ( ) <number> . added ` checkboardstructure ` flag , this flag allows you to return the old behavior or use your custom board structure check . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"ocl_fp16 matmul with large batch # # # pull request readiness checklist * resolves <url> * updates required for actual models from <url> * * merge with extra * * see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders = linux opencl , win64 opencl buildworker : linux opencl = linux - <number> ` ` `",0
opencv/opencv,"dnn : opencl fp16 tests are broken ( test_onnx_layers . matmul_init_bcast ) ( <number> - <number> - <number> ) opencl device : intel igpu nightly builds : - linux : <url> ` ` ` [ run ] test_onnx_layers . matmul_init_bcast / <number> , where getparam ( ) = ocv / ocl_fp16 [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> populatenet dnn / onnx : loading onnx v8 model produced by ' matmul_init_bcast ' . number of nodes = <number> , initializers = <number> , inputs = <number> , outputs = <number> [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> parseoperatorset dnn / onnx : onnx opset version = <number> [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ matmul ] <sad> onnx_node_output_0output ) from domain = ' ai . onnx ' / build / 4 _x - lin64 / opencv / modules / dnn / test / test_common . impl . hpp : <number> : failure expected : ( norml1 ) <= ( l1 ) , actual : <number> vs <number> matmul_init_bcast | ref | = <number> / build / 4 _x - lin64 / opencv / modules / dnn / test / test_common . impl . hpp : <number> : failure expected : ( norminf ) <= ( linf ) , actual : <number> vs <number> matmul_init_bcast | ref | = <number> [ info : <number> <user> . <number> ] global ts . cpp : <number> testteardown memory_usage ( opencl ) : <number> ( base = <number> current = <number> ) [ failed ] test_onnx_layers . matmul_init_bcast / <number> , where getparam ( ) = ocv / ocl_fp16 ( <number> ms ) ` ` ` - windows : <url> ` ` ` [ run ] test_onnx_layers . matmul_init_bcast / <number> , where getparam ( ) = ocv / ocl_fp16 [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20230620 : : onnximporter : : populatenet dnn / onnx : loading onnx v8 model produced by ' matmul_init_bcast ' . number of nodes = <number> , initializers = <number> , inputs = <number> , outputs = <number> [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20230620 : : onnximporter : : parseoperatorset dnn / onnx : onnx opset version = <number> [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20230620 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ matmul ] <sad> onnx_node_output_0 ! output ) from domain = ' ai . onnx ' c :\\ build \ \ 4 _x - win64 - vc16 \ \ opencv \ \ modules \ \ dnn \ \ test \ \ test_common . impl . hpp ( <number> <sad> error : expected : ( norml1 ) <= ( l1 ) , actual : <number> vs <number> matmul_init_bcast | ref | = <number> c :\\ build \ \ 4 _x - win64 - vc16 \ \ opencv \ \ modules \ \ dnn \ \ test \ \ test_common . impl . hpp ( <number> <sad> error : expected : ( norminf ) <= ( linf ) , actual : <number> vs <number> matmul_init_bcast | ref | = <number> [ info : <number> <user> . <number> ] global ts . cpp : <number> cvtest : : testteardown memory_usage ( opencl ) ( base = <number> current = <number> ) [ failed ] test_onnx_layers . matmul_init_bcast / <number> , where getparam ( ) = ocv / ocl_fp16 ( <number> ms ) ` ` `",0
opencv/opencv,"add a test for backends on retrieving intermediate blobs in any order # # # system information opencv version : <number> . <number> # # # detailed description observed with openvino backend that it cannot feed output tensors properly in case of wrong order during the execution . # # # steps to reproduce related ( see ` test_tflite . max_unpooling ` ) # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"macos fullscreen broken # # # # # system information ( version ) - opencv => <number> ( python ) - operating system / platform => macos ventura ( <number> ) # # # # # details the details can be found here # # # # # fix i am working on a fix in [ 0 xmihir / opencv ] ( <url> and i am going to open a draft pr , but i noticed that whenever i create a window , and set it to fullscreen , i have to call waitkey for a few seconds until the title bar hides .",0
opencv/opencv,"dnn module does not use openvino backend by default # # # system information opencv version : <number> . <number> operating system / platform : windows <number> compiler & compiler version : vs <number> ( <number> . <number> ) python version : <date> # # # detailed description opencv supports openvino as a backend to speedup dnns at inference time , which requires to compile with openvino support . excerpt from the build config : ` ` ` general configuration for opencv <number> . <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = . <repeated> parallel framework : tbb ( ver <number> interface <number> ) . <repeated> other third - party libraries : openvino : yes ( <number> . <number> ) ` ` ` so openvino is available . thereafter , the documentation states ` ` ` if opencv is compiled with intel ' s inference engine library , dnn_backend_default means dnn_backend_inference_engine . otherwise it equals to dnn_backend_opencv . ` ` ` to us , this reads as that by default openvino / dnn_backend_inference_engine should be used by default in this build configuration . however , performing some tests using a resnet model from the model zoo shows a different image : ` ` ` # test script : import os import time import numpy as np import cv2 as cv # download link : <url> model = cv . dnn . readnet ( os . path . join ( os . path . dirname ( __file__ ) , ' image_classification_ppresnet50_2022jan . onnx ' ) ) # optionally select a backend <hashtag> model </hashtag> . setpreferablebackend ( cv . dnn . dnn_backend_inference_engine ) <hashtag> model </hashtag> . setpreferablebackend ( cv . dnn . dnn_backend_opencv ) <hashtag> model </hashtag> . setpreferablebackend ( cv . dnn . dnn_backend_default ) # test prediction time model . setinput ( cv . dnn . blobfromimage ( np . ones ( ( <number> , <number> ) , dtype = np . float32 ) ) ) for i in range ( <number> <sad> # warmup out = model . forward ( ) # test <number> predictions t1 = time . time ( ) for i in range ( <number> ) = model . forward ( ) t2 = time . time ( ) print ( t2 - t1 ) input ( ) ` ` ` running this script this way ( i . e . no explicit backend ) or setting either ` cv . dnn . dnn_backend_opencv ` or ` cv . dnn . dnn_backend_default ` requires about <number> - <number> seconds on the testing machine ( i7 - 1 0 5 1 0 u cpu ) but only about <number> seconds with setting ` cv . dnn . dnn_backend_inference_engine ` . thus , our conclusion is that openvino is actually not <emphasis> used by default and requires an explicit setting of the respective backend . furthermore , checking the integer values of the backends shows ` ` ` > > > cv . dnn . dnn_backend_default <number> > > > cv . dnn . dnn_backend_opencv <number> > > > cv . dnn . dnn_backend_inference_engine <number> ` ` ` which means that the default values do not align with the ones explained in documentation . # # # steps to reproduce running the provided code with enabling openvino , i . e . adding the line ` ` ` model . setpreferablebackend ( cv . dnn . dnn_backend_inference_engine ) ` ` ` is significantly faster than any of the other options . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"inconsistency when using opencl # # # system information opencv version : <number> . <number> and latest master operating system / platform : arch linux compiler & compiler version : gcc ( gcc ) <number> . <number> <number> # # # detailed description using the attached code for image translation led to two different results : <number> . when not using opencl , the translation is correct . <number> . however , when using ` opencl - nvidia ` , the translation degrades the image if the output and input are the same ` umat ` in ` warpaffine ` . [ registered_screenshot_29 <number> <number> ] ( <url> # # # steps to reproduce ` ` ` cpp <hashtag> include </hashtag> < opencv2 / highgui . hpp > <hashtag> include </hashtag> < opencv2 / imgproc . hpp > using namespace cv ; int main ( ) { umat frame , out ; imread ( "" astro . jpg "" , imread_grayscale ) . copyto ( frame ) ; mat h = ( mat_ <float> ( <number> , <number> ) < < <number> , <number> , <number> , <number> , <number> , <number> ); warpaffine ( frame , frame , h , frame . size ( )); imshow ( "" frame "" , frame ) ; / / this will fix the problem out , h , frame . size ( )); imshow ( "" frame "" , out ) ;* / waitkey ( ); } ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"python typing refinement for dnn_registerlayer / dnn_unregisterlayer functions this patch introduces typings generation for ` dnn_registerlayer ` / ` dnn_unregisterlayer ` manually defined in [ ` cv2 / modules / dnn / misc / python / pyopencv_dnn . hpp ` ] ( <url> updates : - add ` layerprotocol ` to ` cv2 / dnn / __init__ . pyi ` : ` ` ` python class layerprotocol ( protocol ) : def __init__ ( self , params : dict [ str , dictvalue ] , blobs : typing . sequence [ cv2 . typing . matlike ] ) - > none : . <repeated> def getmemoryshapes ( self , inputs : typing . sequence [ typing . sequence [ int ] ] ) - > typing . sequence [ typing . sequence [ int ] <sad> . <repeated> def forward ( self , inputs : typing . sequence [ cv2 . typing . matlike ] ) - > typing . sequence [ cv2 . typing . matlike ] : . <repeated> ` ` ` - add ` dnn_registerlayer ` function to ` cv2 / __init__ . pyi ` : ` ` ` python def dnn_registerlayer ( layertypename : str , layerclass : typing . type [ layerprotocol ] ) - > none : . <repeated> ` ` ` - add ` dnn_unregisterlayer ` function to ` cv2 / __init__ . pyi ` : ` ` ` python def dnn_unregisterlayer ( layertypename : str ) - > none ` ` ` # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"feat : add typing stub for redirecterror ` redirecterror ` is defined in ` cv2_util . cpp ` and manually exported in ` cv2 . cpp ` python interface for ` redirecterror ` : ` ` ` python def redirecterror ( onerror : callable [ [ int , str , str , str , int ] , none ] | none ) - > none ` ` ` # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"[ build ] popcnt is not supported on windows arm # # # system information opencv version : <number> . <number> operating system : windows <number> arm64 compiler : msvc v143 - vs <number> # # # detailed description error building opencv on windows arm ` libopenjpg2 . lib ( ht_dec . obj ) : error lnk2019 : unresolved external symbol __popcnt referenced in function opt_t1_ht_decode_cblk ` # # # steps to reproduce to reproduce install : ` ` ` <number> . msvc v143 - vs <number> c + + arm64 / arm64ec build tools ( latest ) <number> . msvc v143 - vs <number> c + + arm64 / arm64ec spectre - mitigated libs ( latest ) <number> . windows <number> sdk ( <number> . <number> ) <number> . c + + atl for latest v143 build tools with spectre mitigations ( arm64 / arm64ec ) <number> . c + + atl for latest v143 build tools ( arm64 / arm64ec ) ` ` ` then run setup . py bdist_wheel ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"inference with onnx and opencv gives different results # # # system information ` ` ` general configuration for opencv <number> . <number> - dev = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = version control : <number> . <number> - <number> - g1f7025f028 - dirty extra modules : location ( extra ) : c <annoyed> lib / opencv_contrib / modules version control ( extra ) : <number> . <number> - <number> - gd89b2b9b platform : timestamp : <number> - <number> - 2 9 t <time> z host : windows <number> . <number> amd64 cmake : <number> . <number> cmake generator : visual studio <number> <number> cmake build tool : c <annoyed> program files / microsoft visual studio / <number> / community / msbuild / current / bin / amd64 / msbuild . exe msvc : <number> configuration : debug release cpu / hw features : baseline : sse sse2 sse3 requested : sse3 dispatched code generation : sse4_1 sse4_2 fp16 avx avx2 avx512_skx requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx sse4_1 ( <number> files ) : + ssse3 sse4_1 sse4_2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 avx avx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 avx avx2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 avx512_skx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 avx_512f avx512_common avx512_skx c / c + + : built as dynamic libs ? : yes c + + standard : <number> c + + compiler : c <annoyed> program files / microsoft visual studio / <number> / community / vc / tools / msvc / <number> . <number> / bin / hostx64 / x64 / cl . exe ( ver <number> . <number> ) c + + flags ( release ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / wd4324 / wd4275 / wd4512 / wd4589 / wd4819 / mp / md / o2 / ob2 / dndebug c + + flags ( debug ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / wd4324 / wd4275 / wd4512 / wd4589 / wd4819 / mp / mdd / zi / ob0 / od / rtc1 c compiler : c <annoyed> program files / microsoft visual studio / <number> / community / vc / tools / msvc / <number> . <number> / bin / hostx64 / x64 / cl . exe c flags ( release ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / md / o2 / ob2 / dndebug c flags ( debug ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / mdd / zi / ob0 / od / rtc1 linker flags ( release ) : / machine <kiss> 6 4 / incremental : no linker flags ( debug ) : / machine <kiss> 6 4 / debug / incremental ccache : no precompiled headers : yes extra dependencies : cudart_static . lib nppc . lib nppial . lib nppicc . lib nppidei . lib nppif . lib nppig . lib nppim . lib nppist . lib nppisu . lib nppitc . lib npps . lib cublas . lib cudnn . lib cufft . lib - libpath <sad> <annoyed> program files / nvidia gpu computing toolkit / cuda / v12 . <number> / lib / x64 3 rdparty dependencies : opencv modules : to be built : alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform java line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab viz wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto disabled : world disabled by dependency : - unavailable : cvv freetype hdf julia matlab ovis python2 applications : tests perf_tests examples apps documentation : doxygen python javadoc non - free algorithms : yes windows rt support : no gui : win32ui win32 ui : yes opengl support : yes ( opengl32 glu32 ) vtk support : yes ( ver <number> . <number> ) media i / <surprise> zlib : optimized c <annoyed> install / zlib / lib / zlib . lib debug c <annoyed> install / zlib / lib / zlibd . lib ( ver <date> ) jpeg : build - libjpeg - turbo ( ver <number> . <number> - <number> ) simd support request : yes simd support : no webp : build ( ver encoder : 0x0 2 0 f ) png : optimized c <annoyed> install / libpng / lib / libpng16 . lib debug c <annoyed> install / libpng / lib / libpng16d . lib ( ver <date> ) tiff : build ( ver <number> - <number> . <number> ) jpeg <number> : build ( ver <number> . <number> ) openexr : build ( ver <number> . <number> ) hdr : yes sunraster : yes pxm : yes pfm : yes video i / <surprise> dc1394 : no ffmpeg : yes ( prebuilt binaries ) avcodec : yes ( <number> . <number> ) avformat : yes ( <number> . <number> ) avutil : yes ( <number> . <number> ) swscale : yes ( <date> ) avresample : yes ( <number> . <number> ) gstreamer : no directshow : yes media foundation : yes dxva : yes parallel framework : concurrency other third - party libraries : intel ipp : <number> [ <number> . <number> ] at : c <annoyed> lib / build / opencv / 3 rdparty / ippicv / ippicv_win / icv intel ipp iw : sources ( <number> . <number> ) at : c <annoyed> lib / build / opencv / 3 rdparty / ippicv / ippicv_win / iw lapack : yes ( c <annoyed> program files (x 8 6 ) / intel / oneapi / mkl / <number> . <number> / lib / intel64 / mkl_intel_lp64 . lib c <annoyed> program files (x 8 6 ) / intel / oneapi / mkl / <number> . <number> / lib / intel64 / mkl_sequential . lib c <annoyed> program files (x 8 6 ) / intel / oneapi / mkl / <number> . <number> / lib / intel64 / mkl_core . lib ) openvino : yes ( <number> . <number> ) eigen : yes ( ver . <repeated> ) custom hal : no protobuf : build ( <number> . <number> ) flatbuffers : builtin / 3 rdparty ( <number> . <number> ) nvidia cuda : yes ( ver <number> , cufft cublas ) nvidia gpu arch : <number> nvidia ptx archs : cudnn : yes ( ver <number> . <number> ) opencl : yes ( nvd3d11 ) include path : c <annoyed> lib / opencv / 3 rdparty / include / opencl / <number> link libraries : dynamic load python <number> : interpreter : c <annoyed> program files / python310 / python . exe ( ver <date> ) libraries : optimized c <annoyed> program files / python310 / libs / python310 . lib debug c <annoyed> program files / python310 / libs / python310_d . lib ( ver <date> ) numpy : c <annoyed> users / laurent / appdata / roaming / python / python310 / site - packages / numpy / core / include ( ver <number> . <number> ) install path : c <annoyed> users / laurent / appdata / roaming / python / python310 / site - packages / cv2 / python - <number> python ( for build ) : c <annoyed> program files / python310 / python . exe java : ant : c <annoyed> apache - ant - <date> / bin / ant . bat ( ver <date> ) java : no jni : c <annoyed> program files / java / jdk - <number> / include c <annoyed> program files / java / jdk - <number> / include / win32 c <annoyed> program files / java / jdk - <number> / include java wrappers : yes ( ant ) java tests : yes install to : c <annoyed> install / opencv - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ` ` ` # # # detailed description [ pytorch and onnx gives same results ] ( <url> opencv does not give good results results onnx result [ [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] ] opencv [ [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] [ <number> <number> <number> <number> <number> <number> ] ] <number> <number> # # # steps to reproduce simplified model can be loaded [ here ] ( <url> image is [ here ] ( <url> ` ` ` import onnx import onnxruntime as rt import numpy as np import cv2 as cv onnx_name = "" adabins_kitti_sim . onnx "" image = cv . imread ( cv . samples . findfile ( "" classroom__rgb_00283 . jpg "" ) ) # data for onnx and opencv blob = np . transpose ( image . astype ( np . float32 ) , [ <number> , <number> , <number> ] ) / <number> blob = blob . reshape ( ( <number> , <number> , <number> ) ) # onnx inference sess = rt . inferencesession ( onnx_name ) input_name = sess . get_inputs ( ) [ <number> ] . name output_name = sess . get_outputs ( ) [ <number> ] . name predonnx = sess . run ( [ sess . get_outputs ( ) [ <number> ] . name , sess . get_outputs ( ) [ <number> ] . name , ] , { input_name : blob } ) print ( "" onnx result "" ) disparity_onnx = predonnx [ <number> ] [ <number> , <number> , : , <happy> bins_onnx = predonnx [ <number> ] print ( disparity_onnx [ <number> <time> <number> , <time> : <number> ] ) # opencv inference net = cv . dnn . readnet ( onnx_name ) net . setinput ( blob ) pred_opencv = net . forward ( [ sess . get_outputs ( ) [ <number> ] . name , sess . get_outputs ( ) [ <number> ] . name , ] ) print ( "" opencv "" ) disparity_opencv = pred_opencv [ <number> ] [ <number> , <number> , bins_opencv = pred_opencv [ <number> ] print ( disparity_opencv [ <number> <time> <number> , <time> : <number> ] ) print ( np . mean ( ( disparity_onnx - disparity_opencv ) * * <number> ) ) print ( np . max ( ( disparity_onnx - disparity_opencv ) * * <number> ) ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"open cv will not infere more than <number> models when cv : : utils : : logging : : setloglevel ( cv : : utils : : logging : : log_level_verbose ) ; is set # # # system information opencv <number> . <number> and <number> . <number> compiled from source operating system : various linux versions compiler : gcc5 , gcc7 and gcc11 # # # detailed description took me a whole week to investigate <url> and found a very bizzare behaviour that nobody will easily expect . when infering dnns everything is ok , as long as i infere the same model several times ( i tried up to <number> ) . however , the problem start when infering different models . with standard logging , still , everything works fine . however , when ` ` ` cv : : utils : : logging : : setloglevel ( cv : : utils : : logging : : log_level_verbose ) ; ` ` ` is used ( i use that to ensure my build of opencv is actually multi - threading on various platforms ) , the third inference stops working reproducibly . the provided code as <number> net and commenting inferences shows that the concrete model does not seem to matter . # # # steps to reproduce the problem is reproducible and enforceable . the code used : ` ` ` <hashtag> include </hashtag> "" opencv2 / opencv . hpp "" <hashtag> include </hashtag> "" opencv2 / core / utils / logger . hpp "" cv : : utils : : logging : : setloglevel ( cv : : utils : : logging : : log_level_verbose ) ; std : : string alexnetmodelconfiguration = r "" ( / build / uk / source / ovtest / deploy_alexnet_places365 . prototxt ) "" ; std : : string alexnetmodelweights = r "" ( / build / uk / source / ovtest / alexnet_places365 . caffemodel ) "" ; / / load the network cv : : dnn : : net alexnetnet = cv : : dnn : : readnetfromcaffe ( alexnetmodelconfiguration , alexnetmodelweights ) ; alexnetnet . setpreferablebackend ( cv : : dnn : : dnn_backend_opencv ) ; alexnetnet . setpreferabletarget ( cv : : dnn : : dnn_target_cpu ) ; std : : string googlenetmodelconfiguration = r "" ( / build / uk / source / ovtest / deploy_googlenet_places365 . prototxt ) "" ; std : : string googlenetmodelweights = r "" ( / build / uk / source / ovtest / googlenet_places365 . caffemodel ) "" ; / / load the network cv : : dnn : : net googlenetnet = cv : : dnn : : readnetfromcaffe ( googlenetmodelconfiguration , googlenetmodelweights ) ; googlenetnet . setpreferablebackend ( cv : : dnn : : dnn_backend_opencv ) ; googlenetnet . setpreferabletarget ( cv : : dnn : : dnn_target_cpu ) ; std : : string resnet152modelconfiguration = r "" ( / build / uk / source / ovtest / deploy_resnet152_places365 . prototxt ) "" ; std : : string resnet152modelweights = r "" ( / build / uk / source / ovtest / resnet152_places365 . caffemodel ) "" ; / / load the network cv : : dnn : : net resnet152net = cv : : dnn : : readnetfromcaffe ( resnet152modelconfiguration , resnet152modelweights ) ; resnet152net . setpreferablebackend ( cv : : dnn : : dnn_backend_opencv ) ; resnet152net . setpreferabletarget ( cv : : dnn : : dnn_target_cpu ) ; std : : string vgg16modelconfiguration = r "" ( / build / uk / source / ovtest / deploy_vgg16_places365 . prototxt ) "" ; std : : string vgg16modelweights = r "" ( / build / uk / source / ovtest / vgg16_places365 . caffemodel ) "" ; / / load the network cv : : dnn : : net vgg16net = cv : : dnn : : readnetfromcaffe ( vgg16modelconfiguration , vgg16modelweights ) ; vgg16net . setpreferablebackend ( cv : : dnn : : dnn_backend_opencv ) ; vgg16net . setpreferabletarget ( cv : : dnn : : dnn_target_cpu ) ; std : : string inputfile = r "" ( / build / uk / source / ovtest / beach . png ) "" ; cv : : mat image = cv : : imread ( inputfile , cv : : imread_unchanged ) ; cv : : mat blob227 = cv : : dnn : : blobfromimage ( image , <number> , cv : : size ( <number> , <number> ) , cv : : scalar ( <number> , <number> , <number> ) , true , false ) ; cv : : mat blob224 = cv : : dnn : : blobfromimage ( image , <number> , cv : : size ( <number> , <number> ) , cv : : scalar ( <number> , <number> , <number> ) , true , false ) ; std : : vector < cv : : mat > ret ; alexnetnet . setinput ( blob227 ) ; alexnetnet . forward ( ret ) ; std : : cout < < ret . size ( ) < < "" "" < < ret [ <number> ] . rows < < "" "" < < ret [ <number> ] . cols < < std : : endl ; googlenetnet . setinput ( blob227 ) ; googlenetnet . forward ( ret ) ; std : : cout < < ret . size ( ) < < "" "" < < ret [ <number> ] . rows < < "" "" < < ret [ <number> ] . cols < < std : : endl ; resnet152net . setinput ( blob224 ) ; resnet152net . forward ( ret ) ; std : : cout < < ret . size ( ) < < "" "" < < ret [ <number> ] . rows < < "" "" < < ret [ <number> ] . cols < < std : : endl ; vgg16net . setinput ( blob224 ) ; vgg16net . forward ( ret ) ; std : : cout < < ret . size ( ) < < "" "" < < ret [ <number> ] . rows < < "" "" < < ret [ <number> ] . cols < < std : : endl ; ` ` ` error message : ` ` ` opencv ( <number> . <number> ) error : requested object was not found ( required argument "" operation "" not found into dictionary ) in get , file / build / uk / source / <number> . 0 _trial / source / lib / modules / dnn / include / opencv2 / dnn / dnn . inl . hpp , line <number> [ debug : <number> <user> . <number> ] global system . cpp : <number> restorefpdenormalsstate core : restore fp mxcsr flags = 0x0 0 0 0 1 fa0 error : caught an exception ` ` ` i used the following files for the nets <url> - <url> - <url> - <url> - <url> - <url> - <url> - <url> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"programs that link opencv wont start # # # system information opencv version : latest <number> ; latest <number> os : macos compiler # # # detailed description programs that link opencv wont execute . running them results in no output ; the main function never gets called , the program hangs indefinitely . # # # steps to reproduce install opencv with brew and compile anything that links both it and protobuf . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"inconsistent shape for concatlayer in function ' cv : : dnn : : concatlayerimpl : : getmemoryshapes ' # # # system information python <date> general configuration for opencv <number> . <number> - dev = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = version control : <number> . <number> - <number> - g1f7025f028 - dirty extra modules : location ( extra ) : c <annoyed> lib / opencv_contrib / modules version control ( extra ) : <number> . <number> - <number> - gd89b2b9b platform : timestamp : <number> - <number> - 2 9 t <time> z host : windows <number> . <number> amd64 cmake : <number> . <number> cmake generator : visual studio <number> <number> cmake build tool : c <annoyed> program files / microsoft visual studio / <number> / community / msbuild / current / bin / amd64 / msbuild . exe msvc : <number> configuration : debug release # # # detailed description this issue follow this [ one ] ( <url> simplified model can be loaded [ here ] ( <url> i downloaded model and make inference with onnx no problem i donwloaded model with opencv and i have got an error : ` ` ` [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively opencv / dnn : [ concat ] <sad> onnx_node / decoder / up1 / concat_2 ) : getmemoryshapes ( ) throws exception . inputs = <number> outputs = <number> / <number> blobs = <number> [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively input [ <number> ] = [ <number> <number> <number> <number> ] [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively input [ <number> ] = [ <number> <number> <number> <number> ] [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively output [ <number> ] = [ <number> <number> <number> <number> ] [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20230620 : : net : : impl : : getlayershapesrecursively exception message : opencv ( <number> . <number> - dev ) c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ layers \ \ concat_layer . cpp : <number> : error : ( - <number> : incorrect size of input array ) inconsistent shape for concatlayer in function ' cv : : dnn : : concatlayerimpl : : getmemoryshapes ' traceback ( most recent call last ) : file "" <stdin> "" , line <number> , in <module> cv2 . error : opencv ( <number> . <number> - dev ) c :\\ lib \ \ opencv \ \ modules \ \ dnn \ \ src \ \ layers \ \ concat_layer . cpp : <number> : error : ( - <number> : incorrect size of input array ) inconsistent shape for concatlayer in function ' cv : : dnn : : concatlayerimpl : : getmemoryshapes ' ` ` ` # # # steps to reproduce simplified model can be loaded [ here ] ( <url> ` ` ` import onnx import onnxscript import onnxruntime as rt import numpy as np import cv2 as cv onnx_name = "" c <annoyed> users / laurent / desktop / adabins_kitty / adabins_kitti_sim . onnx "" image = cv . imread ( cv . samples . findfile ( "" right . jpg "" ) ) img = cv . resize ( image , ( <number> , <number> ) ) img = cv . cvtcolor ( img , cv . color_bgr2rgb ) img = img . astype ( np . float32 ) / <number> blob = np . transpose ( img , [ <number> , <number> , <number> ] ) sess = rt . inferencesession ( onnx_name ) input_name = sess . get_inputs ( ) [ <number> ] . name output_name = sess . get_outputs ( ) [ <number> ] . name pred = sess . run ( [ sess . get_outputs ( ) [ <number> ] . name , sess . get_outputs ( ) [ <number> ] . name , ] , { input_name net = cv . dnn . readnet ( onnx_name ) paramadabins = cv . dnn . image2blobparams ( ) paramadabins . datalayout = cv . dnn . dnn_layout_nchw ; paramadabins . ddepth = cv . cv_32f ; paramadabins . mean = ( <number> , <number> ); paramadabins . scalefactor = ( <number> / <number> . , <number> / <number> . , <number> / <number> . ); paramadabins . size = ( <number> , <number> ); paramadabins . swaprb = true ; paramadabins . paddingmode = cv . dnn . dnn_pmode_null ; blob = cv . dnn . blobfromimagewithparams ( image , paramadabins ) net . setinput ( blob ) net . forward ( ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fix flann python bindings as a side - effect this patch improves reporting errors by flann ` get_param ` . resolves # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"python typing magic constants this patch adds typing stubs generation for ` __all__ ` and ` __version__ ` constants . introduced ` __all__ ` is intentionally empty for all generated modules stubs . type hints will not work for star imports resolves # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"test_caffe_nets . fasterrcnn_zf fails with enable_fast_math option # # # system information opencv : current <number> . x ( <number> . <number> - dev ) platform : ubuntu <number> , gcc <number> hardware : core i5 2 5 0 0 k ( no avx2 and no avx512 ) # # # detailed description net inference accuracy issue is raised . # # # steps to reproduce ` ` ` cmake - denable_fast_math = <number> . <repeated> / opencv make - j4 . / bin / opencv_test_dnn - - gtest_filter = "" test_caffe_nets . fasterrcnn_zf / * "" ` ` ` log : ` ` ` [ run ] test_caffe_nets . fasterrcnn_zf / <number> , where getparam ( ) = ocv / cpu unmatched prediction : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] highest iou : <number> / home / alexander / projects / opencv / opencv - master / modules / dnn / test / test_common . impl . hpp : <number> : failure value of : matched actual : false expected : true model name : zf_faster_rcnn_final . caffemodel unmatched reference : class <number> score <number> box [ <number> x <number> from ( <number> , <number> ) ] iou diff : <number> / home / alexander / projects / opencv / opencv - master / modules / dnn / test / test_common . impl . hpp : <number> : failure expected : ( refscores [ i ] ) <= ( confthreshold ) , actual : <number> vs <number> model name [ failed ] test_caffe_nets . fasterrcnn_zf / <number> , where getparam ( ) = ocv / cpu ( <number> ms ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"pods / opencv2_ios / opencv2 . framework / opencv2 ( opencl_kernels_calib3d . o ) , building for ios simulator , but linking in object file built for ios # # # system information pods / opencv2_ios / opencv2 . framework / opencv2 ( opencl_kernels_calib3d . o ) , building for ios simulator , but linking in object file built for ios # # # detailed description i am getting when i use openc depencdency . # # # steps to reproduce create a new project add opencv through pod and build the project . . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"` skiptestexception ` is not handled in cuda tests # # # system information opencv version # # # detailed description as observed in <url> when a ` skiptestexception ` is thrown the test is incorrectly marked as failed . it look like all that is required to fix this is updating the definition of [ gtest_test_class_name_ ( test_case_name , test_name ) : : testbody ( ) ] ( <url> to handle this type of exception in the same way as [ ` cv__test_body_impl ( name ) ` ] ( <url> does . # # # steps to reproduce throw a ` skiptestexception ` anywhere in a cuda test . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"issue loading tflite net # # # # # system information ( version ) - opencv => <number> . <number> - operating system / platform => windows <number> <number> bit - compiler => visual studio <number> # # # # # detailed description so , i saw that tflite support has been added , but when i try readnetfromtflite ( detect . tflite ) ;, i get : ` ` ` [ error : <number> <user> . <number> ] global tflite_importer . cpp : <number> cv : : dnn : : dnn4_v20230620 : : tfliteimporter : : populatenet dnn / tflite : problem during import of operator [ pack ] <sad> ssd_mobile_net_v2_fpn_keras_feature_extractor / featuremaps / top_down / nearest_neighbor_upsampling / nearest_neighbor_upsampling / w_stack ) ( <number> / <number> ) . exception : opencv ( <number> . <number> ) g :\\ opencv \ \ opencv - <number> . <number> \ \ modules \ \ dnn \ \ src \ \ tflite \ \ tflite_importer . cpp : <number> : error : ( - <number> : the function / feature is not implemented ) unsupported operator type pack in function ' cv : : dnn : : dnn4_v20230620 : : tfliteimporter : : populatenet ' opencv ( <number> . <number> ) g :\\ opencv \ \ opencv - <number> . <number> \ \ modules \ \ dnn \ \ src \ \ tflite \ \ tflite_importer . cpp : <number> : error function / feature is not implemented ) unsupported operator type pack in function ' cv : : dnn : : dnn4_v20230620 : : tfliteimporter : : populatenet ' ` ` ` the model was trained and converted by following [ this tutorial ] ( <url>",0
opencv/opencv,"c + + version of opencv <number> will not load caffe model # # # system information opencv <number> . <number> operating system : centos compiler : gcc11 opencv - python - rolling - <number> . <number> windows <number> # # # detailed description i am loading the same model with opencv python ok and fail to load the model with a compiled version of opencv <number> . this used to work fine for opencv <number> . <number> and fails for <number> and <number> . the compile machine is offline and i provided the correct version of ade by hand . other dnn models load and work fine . find the model here <url> and <url> . # # # steps to reproduce compile opencv <number> offline using the following configuartion : ` ` ` cmake3 - dcmake_build_type = debug - dcmake_install_prefix <annoyed> build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - default - debug - install verbose = <number> - dopencv_extra_modules_path = ~ / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / - dcpu_baseline = avx2 - denable_omit_frame_pointer = off - dbuild_tests = off - dbuild_perf_tests = off - dbuild_examples = off - dbuild_opencv_apps = off ~ / local / frameworks / opencv / <number> . 0 _trial / source / lib - - ocv_init_download : opencv source tree is not fetched as git repository . 3 rdparty resources will be downloaded from github . com by default . - - detected processor : x86_64 python <number> . <number> - - looking for ccache - not found cleaning internal cached variable : zlib_library cleaning internal cached variable : zlib_include_dir - - could not find zlib ( missing : zlib_library zlib_include_dir ) ( required is at least version "" <number> . <number> "" ) cleaning internal cached variable : jpeg_library cleaning internal cached variable : jpeg_include_dir - - could not find jpeg ( missing : jpeg_library jpeg_include_dir ) - - libjpeg - turbo : version = <number> . <number> , build = opencv - <number> . <number> - libjpeg - turbo - debug cleaning internal cached variable : tiff_library cleaning internal cached variable : tiff_include_dir - - could not find tiff ( missing : tiff_library tiff_include_dir ) cleaning internal cached variable : webp_library cleaning internal cached variable : webp_include_dir - - could not find openjpeg ( minimal suitable version : <number> , recommended version >= <number> . <number> ) . openjpeg will be built from sources - - openjpeg : version = <number> . <number> , build = opencv - <number> . <number> - openjp2 - <number> . <number> - debug - - openjpeg libraries will be built from sources : libopenjp2 ( version "" <number> . <number> "" ) cleaning internal cached variable : png_library cleaning internal cached variable : png_include_dir - - could not find png ( missing : png_library png_png_include_dir ) - - ippicv : downloading ippicv_2021 . 8 _lnx_intel64_20230330_general . tgz from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at cmake / opencvdownload . cmake : <number> ( message ) : ippicv : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : 3 rdparty / ippicv / ippicv . cmake : <number> ( ocv_download ) cmake / opencvfindipp . cmake : <number> ( download_ippicv ) cmake / opencvfindlibsperf . cmake : <number> ( include ) cmakelists . txt : <number> ( include ) - - could not find openblas include . turning openblas_found off - - could not find openblas lib . turning openblas_found off - - could not find atlas ( missing : atlas_cblas_include_dir atlas_clapack_include_dir atlas_cblas_library atlas_blas_library atlas_lapack_library ) - - could not find blas ( missing : blas_libraries ) - - lapack requires blas - - a library with lapack api not found . please specify library location . - - could not find java ( missing : java_jar_executable java_javac_executable java_javah_executable java_javadoc_executable ) ( found version "" <number> . 0 _372 "" ) - - could not find jni ( missing : java_include_path java_include_path2 java_awt_include_path ) - - vtk is not found . please set - dvtk_dir in cmake to vtk build directory , or to vtk install subdirectory with vtkconfig . cmake file - - checking for module ' gtk + - <number> ' - - no package ' gtk + - <number> ' found - - checking for module ' gtk + - <number> ' - - no package ' gtk + - <number> ' found - - checking for module ' gthread - <number> >= <number> ' - - no package ' gthread - <number> ' found - - checking for modules ' libavcodec ; libavformat ; libavutil ; libswscale ' - - no package ' libavcodec ' found - - no package ' libavformat ' found - - no package ' libavutil ' found - - no package ' libswscale ' found - - ffmpeg is disabled . required libraries : libavcodec ; libavformat ; libavutil ; libswscale . missing libraries : libavcodec ; libavformat ; libavutil ; libswscale - - checking for module ' gstreamer - base - <number> ' - - no package ' gstreamer - base - <number> ' found - - checking for module ' gstreamer - app - <number> ' - - no package ' gstreamer - app - <number> ' found - - checking for module ' gstreamer - riff - <number> ' - - no package ' gstreamer - riff - <number> ' found - - checking for module ' gstreamer - pbutils - <number> ' - - no package ' gstreamer - pbutils - <number> ' found - - checking for module ' gstreamer - video - <number> ' - - no package ' gstreamer - video - <number> ' found - - checking for module ' gstreamer - audio - <number> ' - - no package ' gstreamer - audio - <number> ' found - - checking for module ' libdc1394 - <number> ' - - no package ' libdc1394 - <number> ' found - - module opencv_alphamat disabled because the following dependencies are not found : eigen - - checking for module ' freetype2 ' - - no package ' freetype2 ' found - - checking for module ' harfbuzz ' - - no package ' harfbuzz ' found - - freetype2 : no - - harfbuzz : no - - could not find hdf5 ( missing : hdf5_libraries hdf5_include_dirs ) ( found version "" "" ) - - julia not found . not compiling julia bindings . - - module opencv_ovis disabled because ogre3d was not found - - no preference for use of exported gflags cmake configuration set , and no hints for include / library directories provided . defaulting to preferring an installed / exported gflags cmake configuration if available . - - failed to find installed gflags cmake configuration , searching for gflags build directories exported with cmake . - - failed to find gflags - failed to find an installed / exported cmake configuration for gflags , will perform search for installed gflags components . - - failed to find gflags - could not find gflags include directory , set gflags_include_dir to directory containing gflags / gflags . h - - failed to find glog - could not find glog include directory , set glog_include_dir to directory containing glog / logging . h - - module opencv_sfm disabled because the following dependencies are not found : eigen glog / gflags - - checking for module ' tesseract ' - - no package ' tesseract ' found - - tesseract : no - - allocator metrics storage type : ' long long ' - - excluding from source files list : modules / imgproc / src / imgwarp . lasx . cpp - - excluding from source files list : modules / imgproc / src / resize . lasx . cpp - - registering hook ' init_module_sources_opencv_dnn ' : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / modules / dnn / cmake / hooks / init_module_sources_opencv_dnn . cmake - - opencv_dnn : filter out cuda4dnn source code - - excluding from source files list : <build> / modules / dnn / layers / layers_common . rvv . cpp - - excluding from source files list : <build> / modules / dnn / layers / layers_common . lasx . cpp - - excluding from source files list : <build> / modules / dnn / int8layers / layers_common . lasx . cpp - - excluding from source files list : <build> / modules / dnn / layers / cpu_kernels / conv_depthwise . rvv . cpp - - excluding from source files list : <build> / modules / dnn / layers / cpu_kernels / conv_depthwise . lasx . cpp - - imgcodecs : openexr codec is disabled in runtime . details : <url> - - highgui : using builtin backend : none - - rgbd : eigen support is disabled . eigen is required for posegraph optimization - - wechat_qrcode : downloading detect . caffemodel from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : wechat_qrcode : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( ocv_download ) cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( message ) : wechatqrcode : can not get detect caffemodel file for wechat qrcode . - - wechat_qrcode : downloading detect . prototxt from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : wechat_qrcode : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( ocv_download ) cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( message ) : wechatqrcode : can not get detect prototxt file for wechat qrcode . - - wechat_qrcode : downloading sr . caffemodel from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : wechat_qrcode : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( ocv_download ) cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( message ) : wechatqrcode : can not get sr caffemodel file for wechat qrcode . - - wechat_qrcode : downloading sr . prototxt from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : wechat_qrcode : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( ocv_download ) cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / wechat_qrcode / cmakelists . txt : <number> ( message ) : wechatqrcode : can not get sr prototxt file for wechat qrcode . - - xfeatures2d / boostdesc : downloading boostdesc_bgm . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / boostdesc : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_boostdesc . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_boost_descriptors ) - - xfeatures2d / boostdesc : downloading boostdesc_bgm_bi . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / boostdesc : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_boostdesc . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_boost_descriptors ) - - xfeatures2d / boostdesc : downloading boostdesc_bgm_hd . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / boostdesc : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_boostdesc . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_boost_descriptors ) - - xfeatures2d / boostdesc : downloading boostdesc_binboost_064 . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / boostdesc : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_boostdesc . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_boost_descriptors ) - - xfeatures2d / boostdesc : downloading boostdesc_binboost_128 . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / boostdesc : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_boostdesc . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_boost_descriptors ) - - xfeatures2d / boostdesc : downloading boostdesc_binboost_256 . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / boostdesc : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_boostdesc . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_boost_descriptors ) - - xfeatures2d / boostdesc : downloading boostdesc_lbgm . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / boostdesc : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_boostdesc . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_boost_descriptors ) - - xfeatures2d / vgg : downloading vgg_generated_48 . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / vgg : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_vgg . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_vgg_descriptors ) - - xfeatures2d / vgg : downloading vgg_generated_64 . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / vgg : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_vgg . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_vgg_descriptors ) - - xfeatures2d / vgg : downloading vgg_generated_80 . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / vgg : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_vgg . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_vgg_descriptors ) - - xfeatures2d / vgg : downloading vgg_generated_120 . i from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : xfeatures2d / vgg : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmake / download_vgg . cmake : <number> ( ocv_download ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( download_vgg_descriptors ) cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( message ) : features2d : boost descriptor implementation is not available due to missing data ( download failed : <url> cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / xfeatures2d / cmakelists . txt : <number> ( message ) : features2d : vgg descriptor implementation is not available due to missing data ( download failed : <url> - - data : downloading face_landmark_model . dat from <url> - - try <number> failed - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = could not download files from the internet . please check the internet access on this host . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / cmake / opencvdownload . cmake : <number> ( message ) : data : download failed : <number> ; "" could not resolve host name "" for details please refer to the download log file : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug / cmakedownloadlog . txt call stack ( most recent call first ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / face / cmakelists . txt : <number> ( ocv_download ) cmake warning at / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules / face / cmakelists . txt : <number> ( message ) : face : can not get model file for face alignment . - - found ' misc ' python modules from / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / modules / python / package / extra_modules - - found ' mat_wrapper ; utils ' python modules from / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / modules / core / misc / python / package - - found ' gapi ' python modules from / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / modules / gapi / misc / python / package - - - - general configuration for opencv <number> . <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - version control : unknown - - - - extra modules : - - location ( extra ) : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / contrib / modules - - version control ( extra ) : unknown - - - - platform : - - timestamp : <number> - <number> - 1 2 t <time> z - - host : linux <date> - <number> . el7 . elrepo . x86_64 x86_64 - - cmake : <number> . <number> - - cmake generator : unix makefiles - - cmake build tool : / usr / bin / gmake - - configuration : debug - - - - cpu / hw features : - - baseline : sse sse2 sse3 ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 - - requested : avx2 - - dispatched code generation : avx512_skx - - requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx - - avx512_skx ( <number> files ) : + avx_512f avx512_common avx512_skx - - - - c / c + + : - - built as dynamic libs ? : yes - - c + + standard : <number> - - c + + compiler : / ovde_plugins / gcc11 / linux / bin / g + + ( ver <number> . <number> ) - - c + + flags ( release ) : - fsigned - char - w - wall - wreturn - type - wnon - virtual - dtor - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fno - omit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - mssse3 - msse4 . <number> - mpopcnt - msse4 . <number> - mf16c - mfma - mavx - mavx2 - fvisibility = hidden - fvisibility - inlines - hidden - o2 - dndebug - dndebug - - c + + flags ( debug ) : - fsigned - char - w - wall - wreturn - type - wnon - virtual - dtor - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fno - omit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - mssse3 - msse4 . <number> - mpopcnt - msse4 . <number> - mf16c - mfma - mavx - mavx2 - fvisibility = hidden - fvisibility - inlines - hidden - g - o0 - ddebug - d_debug - - c compiler : / ovde_plugins / gcc11 / linux / bin / gcc - - c flags ( release ) : - fsigned - char - w - wall - wreturn - type - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fno - omit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - mssse3 - msse4 . <number> - mpopcnt - msse4 . <number> - mf16c - mfma - mavx - mavx2 - fvisibility = hidden - o2 - dndebug - dndebug - - c flags ( debug ) : - fsigned - char - w - wall - wreturn - type - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fno - omit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - mssse3 - msse4 . <number> - mpopcnt - msse4 . <number> - mf16c - mfma - mavx - mavx2 - fvisibility = hidden - g - o0 - ddebug - d_debug - - linker flags ( release ) : - wl , - - gc - sections - wl , - - as - needed - wl , - - no - undefined - - linker flags ( debug ) : - wl , - - gc - sections - wl , - - as - needed - wl , - - no - undefined - - ccache : no - - precompiled headers : no - - extra dependencies : dl m pthread rt - - 3 rdparty dependencies : - - - - opencv modules : - - to be built : aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto - - disabled : world - - disabled by dependency : - - - unavailable : alphamat cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv freetype hdf java julia matlab ovis python2 python3 sfm ts viz - - applications : - - - documentation : no - - non - free algorithms : no - - - - gui : none - - gtk + : no - - vtk support : no - - - - media i / <surprise> - - zlib : zlib ( ver <date> ) - - jpeg : libjpeg - turbo ( ver <number> . <number> - <number> ) - - webp : build ( ver encoder : 0x0 2 0 f ) - - png : build ( ver <date> ) - - tiff : build ( ver <number> - <number> . <number> ) - - jpeg <number> : build ( ver <number> . <number> ) - - openexr : build ( ver <number> . <number> ) - - hdr : yes - - sunraster : yes - - pxm : yes - - pfm : yes - - - - video i / <surprise> - - dc1394 : no - - ffmpeg : no - - avcodec : no - - avformat : no - - avutil : no - - swscale : no - - avresample : no - - gstreamer : no - - v4l / v4l2 : yes ( linux / videodev2 . h ) - - - - parallel framework : pthreads - - - - trace : yes ( with intel itt ) - - - - other third - party libraries : - - va : yes - - lapack : no - - eigen : no - - custom hal : no - - protobuf : build ( <number> . <number> ) - - flatbuffers : builtin / 3 rdparty ( <number> . <number> ) - - - - opencl : yes ( intelva ) - - include path : / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / 3 rdparty / include / opencl / <number> - - link libraries : dynamic load - - - - python ( for build ) : / usr / bin / python2 . <number> - - - - java : - - ant : no - - java : no - - jni : no - - java wrappers : no - - java tests : no - - - - install to : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - default - debug - install - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - configuring done - - generating done - - build files have been written to : / build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - pthreads - openmp - debug ` ` ` compile the test using the following configuration : ` ` ` cmake3 - dcmake_build_type = debug - dcmake_install_prefix <annoyed> build / uk / frameworks / opencv - <number> . <number> -ov - avx2 - default - debug - install verbose = <number> ~ / local / frameworks / opencv / <number> . 0 _trial / source / ovtest ` ` ` this is the code used to load the model : ` ` ` std : : string googlenetmodelconfiguration = r "" ( deploy_googlenet_places365 . prototxt ) "" ; std : : string googlenetmodelweights = r "" ( googlenet_places365 . caffemodel ) "" ; / / load the network cv : : dnn : : net googlenetnet = cv : : dnn : : readnetfromcaffe ( googlenetmodelconfiguration , googlenetmodelweights ) ; googlenetnet . setpreferablebackend ( cv : : dnn : : dnn_backend_opencv ) ; googlenetnet . setpreferabletarget ( cv : : dnn : : dnn_target_cpu ) ; ` ` ` the error message when running the code ( same for opencv <number> . <number> ) ` ` ` starting subtest : exception free test execution opencv_unittests [ <number> <sad> error : printandlog . cpp : <number> loginfo : failed : last chance exception handler stopping test . caught the following std : : exception cv : : exception : failed : last chance exception handler ! stopping test . caught the following std : : exception cv : : exception : opencv ( <number> . <number> ) / net / subnet - homes / development / user / ukoehler / local / frameworks / opencv / <number> . 0 _trial / source / lib / modules / dnn / include / opencv2 / dnn / dnn . inl . hpp : <number> : error object was not found ) required argument "" operation "" not found into dictionary in function ' get ' ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"risc - v : fix unaligned loads and stores we experienced segmentation fault errors in _core_ ` flip ` and _imgproc_ ` bayer ` tests . debugging has shown that issues are caused by an unaligned memory access in rvv code . this pr fixes them . below are quick performance comparison <summary> x86_64 performance results </summary> * * core i5 - <number> * * | name of test | before | after |( x - factor ) | | - - - <sad> - <sad> : - <sad> : - <sad> | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | name of test | before | after |( x - factor ) | | - - - <sad> - <sad> : - <sad> : - <sad> | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2gray ) | <number> | <number> | <number> | </details> <details> <summary> aarch64 performance results </summary> * rk3588 <emphasis> * | name of test | before | after |( x - factor ) | | - - - <sad> - <sad> : - <sad> : - <sad> | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 6 4 0 x480 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 2 8 0 x720 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 1 9 2 0 x1080 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc1 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc1 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc1 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 8 uc4 , flip_rows ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc4 , flip_both ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc4 , flip_cols ) | <number> | <number> | <number> | | flip : : ocl_flipfixture : : ( 3 8 4 0 x2160 , 3 2 fc4 , flip_rows ) | <number> | <number> | <number> | | name of test | before | after |( x - factor ) | | - - - <sad> - <sad> : - <sad> : - <sad> | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerbg2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergb2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayergr2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 1 2 7 x61 , color_bayerrg2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerbg2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergb2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayergr2gray ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2bgr ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2bgra ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2bgr_vng ) | <number> | <number> | <number> | | cvtcolorbayer8u : : size_cvtmode_bayer : : ( 6 4 0 x480 , color_bayerrg2gray ) | <number> | <number> | <number> | </details>",0
opencv/opencv,"fix : recursively re - export nested submodules in typing stubs addresses the same issue as # <number> , but also handles nested modules case e . g . adds the following section to ` cv2 / gapi / __init__ . pyi ` from cv2 . gapi import core as core from cv2 . gapi import ie as ie from cv2 . gapi import imgproc as imgproc from cv2 . gapi import oak as oak from cv2 . gapi import onnx as onnx from cv2 . gapi import ov as ov from cv2 . gapi import own as own from cv2 . gapi import render as render from cv2 . gapi import streaming as streaming from cv2 . gapi import video as video from cv2 . gapi import wip as wip ` ` ` # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"python type stubs : ` __all__ ` and ` __version__ ` dunders are missing # # # system information opencv python : opencv - python - headless = = <number> . <number> operating system / platform : <number> . <number> build <number> python version : <date> # # # detailed description ` cv2 . __all__ ` and ` cv2 . __version__ ` are missing from the stubs . ` cv2 . __version__ ` is useful for compatibility checks . ` cv2 . __all__ ` is important <emphasis> for type checkers to know which symbols are . without ` __all__ ` specified : [ image ] ( <url> with ` __all__ = [ ] ` specified : ! [ image ] ( <url> runtime : ` ` ` py > > > from cv2 import * > > > sort_every_row traceback ( most recent call last ) : file "" <stdin> "" , line <number> , in <module> nameerror ' sort_every_row ' is not defined ` ` ` # # # steps to reproduce ` ` ` py > > > import cv2 > > > [x for x in dir ( cv2 ) if x . startswith ( "" __ "" ) and x . endswith ( "" __ "" ) ] [ ' __all__ ' , ' __builtins__ ' , ' __cached__ ' , ' __doc__ ' , ' __file__ ' , ' __loader__ ' , ' __name__ ' , ' __package__ ' , ' __path__ ' , ' __spec__ ' , ' __version__ ' ] ` ` ` ` ` ` py import cv2 cv2 . __all__ # "" __all__ "" is not a known member of module "" cv2 "" cv2 . __builtins__ cv2 . __cached__ cv2 . __doc__ cv2 . __file__ cv2 . __loader__ cv2 . __name__ cv2 . __package__ cv2 . __path__ cv2 . __spec__ cv2 . __version__ # "" __version__ "" is not a known member of module "" cv2 "" ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"python type stubs generator fails on contrib / cudaoptflow module # # # system information platform : cuda python : <number> + # # # detailed description ` ` ` typing_stubs_generation . nodes . type_node . typeresolutionerror : failed to resolve "" cv2 "" namespace against "" none "" . errors : [ ' failed to resolve "" cv2 . cuda "" namespace against "" cv2 "" . errors : [ \ \ ' failed to resolve "" cv2 . cuda . nvidiaopticalflow_1_0 "" class against "" cv2 "" . errors : [ \ \ \ \ \ \ ' failed to resolve "" cv2 . cuda . nvidiaopticalflow_1_0 . create "" function against "" cv2 "" . errors : [ <number> <sad> failed to resolve "" perfpreset "" argument : failed to resolve "" cuda_nvidiaopticalflow_1_0_nvidia_of_perf_level "" exposed as "" cuda_nvidiaopticalflow_1_0_nvidia_of_perf_level "" \ \ \ \ \ \ ' ] \ \ ' , \ \ ' failed to resolve "" cv2 . cuda . nvidiaopticalflow_2_0 "" class against "" cv2 "" . errors : [ \ \ \ \ \ \ ' failed to resolve "" cv2 . cuda . nvidiaopticalflow_2_0 . create "" function against "" cv2 "" . errors : [ <number> <sad> failed to resolve "" perfpreset "" argument : failed to resolve "" cuda_nvidiaopticalflow_2_0_nvidia_of_perf_level "" exposed as "" cuda_nvidiaopticalflow_2_0_nvidia_of_perf_level "" , [ <number> <sad> failed to resolve "" outputgridsize "" argument : failed to resolve "" cuda_nvidiaopticalflow_2_0_nvidia_of_output_vector_grid_size "" exposed as "" cuda_nvidiaopticalflow_2_0_nvidia_of_output_vector_grid_size "" , [ <number> <sad> failed to resolve "" hintgridsize "" argument : failed to resolve "" cuda_nvidiaopticalflow_2_0_nvidia_of_hint_vector_grid_size "" exposed as "" cuda_nvidiaopticalflow_2_0_nvidia_of_hint_vector_grid_size "" , [ <number> <sad> failed to resolve "" perfpreset "" argument : failed to resolve "" cuda_nvidiaopticalflow_2_0_nvidia_of_perf_level "" exposed as "" cuda_nvidiaopticalflow_2_0_nvidia_of_perf_level "" , [ <number> <sad> failed to resolve "" outputgridsize "" argument : failed to resolve "" cuda_nvidiaopticalflow_2_0_nvidia_of_output_vector_grid_size "" exposed as "" cuda_nvidiaopticalflow_2_0_nvidia_of_output_vector_grid_size "" , [ <number> <sad> failed to resolve "" hintgridsize "" argument to resolve "" cuda_nvidiaopticalflow_2_0_nvidia_of_hint_vector_grid_size "" exposed as "" cuda_nvidiaopticalflow_2_0_nvidia_of_hint_vector_grid_size "" \ \ \ \ \ \ ' ] \ \ ' ] ' , ` ` ` # # # steps to reproduce ` cmake - dbuild_opencv_cudacodec = off - dpython3_executable = ` which python3 . <number> ` - dpython_default_executable = ` which python3 . <number> ` - dwith_cuda = on - dcuda_arch_bin = <number> - dopencv_extra_modules_path = . <repeated> / opencv_contrib / modules / . <repeated> / opencv - master ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fix checksignature not thread safe for avif . a common decoder cannot be shared with checksignature which is used like a static function ( on a static ist of decoders ) . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,videoio cap_images with non - numbered file resolves # <number> diff looks slightly complex because i moved out common part ( ` grabframe ` call ) and realigned the code . actual fix is added ` return false ` to the ` if ( haveimagereader ( . <repeated> ) ) ` block . also unified log messages .,0
opencv/opencv,"videoio_dynamic . basic_write sporadically fails on ci # # # system information platform : ubuntu <number> arm64 opencv version : <number> . <number> - dev # # # detailed description ` ` ` [ run ] videoio_dynamic . basic_write ( opencv_test_videoio : <number> <sad> gstreamer - critical * * : <time> . <number> : gst_element_make_from_uri : assertion ' gst_uri_is_valid ( uri ) ' failed [ error : <number> <user> . <number> ] global cap . cpp : <number> open videoio ( cv_images ) : raised opencv exception : opencv ( <number> . <number> - dev ) / home / ci / opencv / modules / videoio / src / cap_images . cpp : <number> : error : ( - <number> : assertion failed ) filename_pattern . empty ( ) in function ' open ' ( opencv_test_videoio : <number> <sad> gstreamer - critical * * : <time> . <number> : gst_query_set_position : assertion ' format = = g_value_get_enum ( gst_structure_id_get_value ( s , gst_quark ( format ) ) ) ' failed [ warn : <number> <user> . <number> ] global cap_gstreamer . cpp : <number> open opencv | gstreamer warning : cannot query video position : status = <number> , value = - <number> , duration = <number> [ warn : <number> <user> . <number> ] global cap . cpp : <number> open videoio ( v4l2 ) : backend is generally available but can not be used to capture by name / home / ci / opencv / modules / videoio / test / test_dynamic . cpp : <number> : failure expected equality of these values : count which is : <number> frame_count which is : <number> corrupt jpeg data : premature end of data segment corrupt jpeg data : premature end of data segment corrupt jpeg data : premature end of data segment corrupt jpeg data : premature end of data segment corrupt jpeg data : premature end of data segment [ failed ] videoio_dynamic . basic_write ( <number> ms ) ` ` ` # # # steps to reproduce ci example # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fixed possible out - of - bound access in circles drawing # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"python typing stub missing matrix type constants like cv_32f # # # system information opencv python version : <number> . <number> os : windows <number> 2 2 h2 python version : <number> . <number> # # # detailed description where and how should we report issues with the typing ? it seems all ` cv_ . <repeated> ` constants are missing . _originally posted by <user> in <url> the commit in question is missing the ` cv_ . <repeated> ` constants as stated by the comment i quoted , causing cannot find reference errors in pycharm and failing to autocorrect . # # # steps to reproduce open any python file in pycharm or create a new one . type the following to the top of the file : ` ` ` import cv2 test = cv2 . cv_32f ` ` ` observe the yellow squiggly line below the cv_32f part . hover the mouse cursor over that part to observe the warning find reference ' cv_32f ' in ' __init__ . pyi ' ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"problem of install opencv to openvino # # # system information / / example for python user opencv python version : <number> operating system / platform : ubuntu <number> python version : <number> . <number> # # # detailed description since the exmaple model on * openvino <emphasis> * rquire me to install * opencv <emphasis> * , and i follow the intstrucion of this links : ` <url> , but it shows the below error message . i do not know how to fix it , it seems like a bug ? or what version of opencv i should install to solve this problem ? ` ` ` in file included from / home / chen / opencv / modules / objdetect / test / test_qrcode . cpp : <number> : / home / chen / opencv / modules / objdetect / test / test_qr_utils . hpp : in function ‘ void opencv_test : : check_qr ( const string & , const string & , const string & , const std : : vector < cv : : point_ <int> > & , const std : : vector < std : : __cxx11 : : basic_string <char> > & , int , bool ) ’ : / home / chen / opencv / modules / objdetect / test / test_qr_utils . hpp : <time> : warning : unused parameter ‘ decoded_info ’ [ - wunused - parameter ] <number> | const std : : vector <string> & decoded_info , const int max_pixel_error , | ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / home / chen / opencv / modules / objdetect / test / test_qrcode . cpp : in member function ‘ virtual void opencv_test : : { anonymous } : : objdetect_qrcode_multi_regression_test : : body ( ) ’ : / home / chen / opencv / modules / objdetect / test / test_qrcode . cpp : <number> : <number> : error : ‘ decoded_info ’ was not declared in this scope <number> | check_qr ( root , name_current_image , "" multiple_images "" , corners , decoded_info , pixels_error , true ) ; | ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / home / chen / opencv / modules / objdetect / test / test_qrcode . cpp : in member function ‘ virtual void opencv_test : : { anonymous } : : objdetect_qrcode_detect_flipped_regression_23249_test : : body ( ) ’ : / home / chen / opencv / modules / objdetect / test / test_qrcode . cpp : <number> <time> : warning : unused variable ‘ expect_msg ’ [ - wunused - variable ] <number> | const std : : string & expect_msg = flipped_image . second ; | ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ [ <percent> ] building cxx object modules / video / cmakefiles / opencv_perf_video . dir / perf / opencl / perf_dis_optflow . cpp . o make [ <number> <sad> * * * [ modules / objdetect / cmakefiles / opencv_test_objdetect . dir / build . make : <number> error <number> ` ` ` # # # steps to reproduce ` ` ` ` ` ` cpp cmake \ \ - d build_info_skip_extra_modules = on \ \ - d build_examples = off \ \ - d build_jasper = off \ \ - d build_java = off \ \ - d build_jpeg = on \ \ - d build_apps_list = version \ \ - d build_opencv_apps = on \ \ - d build_opencv_java = off \ \ - d build_openexr = off \ \ - d build_png = on \ \ - d build_tbb = off \ \ - d build_webp = off \ \ - d build_zlib = on \ \ - d with_1394 = off \ \ - d with_cuda = off \ \ - d with_eigen = off \ \ - d with_gphoto2 = off \ \ - d with_gstreamer = on \ \ - d opencv_gapi_gstreamer = off \ \ - d with_gtk_2_x = off \ \ - d with_ipp = on \ \ - d with_jasper = off \ \ - d with_lapack = off \ \ - d with_matlab = off \ \ - d with_mfx = on \ \ - d with_openclamdblas = off \ \ - d with_openclamdfft = off \ \ - d with_openexr = off \ \ - d with_openjpeg = off \ \ - d with_quirc = off \ \ - d with_tbb = off \ \ - d with_tiff = off \ \ - d with_vtk = off \ \ - d with_webp = off \ \ - d cmake_use_relative_paths = on \ \ - d cmake_skip_install_rpath = on \ \ - d enable_build_hardening = on \ \ - d enable_config_verification = on \ \ - d enable_precompiled_headers = off \ \ - d enable_cxx11 = on \ \ - d install_pdb = on \ \ - d install_tests = on \ \ - d install_c_examples = on \ \ - d install_python_examples = on \ \ - d cmake_install_prefix = install \ \ - d opencv_skip_pkgconfig_generation = on \ \ - d opencv_skip_python_loader = off \ \ - d opencv_skip_cmake_root_config = on \ \ - d opencv_generate_setupvars = off \ \ - d opencv_bin_install_path = bin \ \ - d opencv_include_install_path = include \ \ - d opencv_lib_install_path = lib \ \ - d opencv_config_install_path = cmake \ \ - d opencv_3p_lib_install_path <laugh> rdparty \ \ - d opencv_samples_src_install_path = samples \ \ - d opencv_doc_install_path = doc \ \ - d opencv_other_install_path = etc \ \ - d opencv_licenses_install_path = etc / licenses \ \ - d opencv_install_ffmpeg_download_script = on \ \ - d build_opencv_world = off \ \ - d build_opencv_python2 = off \ \ - d build_opencv_python3 = on \ \ - d python3_packages_path = install / python / python3 \ \ - d python3_limited_api = on \ \ - d highgui_plugin_list = all \ \ - d opencv_python_install_path = python \ \ - d cpu_baseline = sse4_2 \ \ - d opencv_ipp_gaussian_blur = on \ \ - d with_openvino = on \ \ - d videoio_plugin_list = ffmpeg , gstreamer , mfx \ \ - d cmake_exe_linker_flags = - wl , - - allow - shlib - undefined \ \ - d cmake_build_type = release \ \ - s ~ . / opencv \ \ - b ~ / build - opencv & & \ \ cmake - - build ~ / build - opencv - - parallel $( nproc ) & & cmake - - install ~ / build - opencv ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"possible memory leak in cv : : resize in multithread environment # # # expected behaviour memory usage to remain constant as the program runs # # # actual behaviour memory usage steadily increases over time around ~ <number> kb / sec ( seen in windows task manager ) # # # steps to reproduce i am running this in python <number> with opencv - python - <number> . <number> on windows , i have also seen this also seems to happen on ubuntu machines this piece of code reproduces the issue , it is not exclusive to resize , it seems that any function that returns data from cv2 causes leaked memory ` ` ` import threading import cv2 import numpy as np import gc class memleak_test : def __init__ ( self ) : self . thread = none def test ( self ) : frame = np . zeros ( ( <number> , <number> , <number> ) ) . astype ( np . uint8 ) frame = cv2 . resize ( frame , ( <number> , <number> ) ) def run_threaded ( self ) : self . thread = threading . thread ( target = self . test ) self . thread . start ( ) def test_memleak ( self ) : if self . thread is not none : self . thread . join ( ) self . run_threaded ( ) # leaks memory return none m = memleak_test ( ) while true gc . collect ( ) ` ` ` i have seen some mention of similar issues being related to tls ( thread local state ) but have supposedly been fixed a long time ago <url>",0
opencv/opencv,"g - api async inference for openvino backend # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"dnn overflow in sigmoid layer for <number> fixes # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"float overflow and nans in sigmoidlayer ( yolov5n detection , cpu ) # # # system information opencv versions <number> . <number> , <number> . 0 _dev os ubuntu <number> g + + ( ubuntu <number> . <number> - 1 ubuntu1 ~ <number> . <number> ) <number> . <number> # # # detailed description greetings , colleagues i use the yolov5n neural network in my project . after training and exporting to onnx , i upload it using cv : : dnn : : readnetfromonnx ( path to . onnx ) . if i use dnnbackend cuda i have detections , when switching to dnnbackend default and dnntarget cpu detections disappear . i started comparing the conclusions from the layers of the model . in the output of the last layer , when using the cpu , there were a lot of nan ( more than half of the values ) . when using cuda , there were the usual floats . the first nan appeared after the sigmoidlayer in the first layers of the model . i created a c + + script with a sigmoid formula and tried to get nan in it . in the model , the input values are - <number> . x <elongated> . <repeated> - <number> . x <elongated> , but the script gave out <number> . 0 f all the time . i did not understand why it turned out to be nan , and negative ( "" - nan "" ) . but the solution to my problem was the modification of the sigmoidlayer implementation in modules / dnn / src / layers / elementwise_layers . cpp ( lines <number> - <number> ) instead of ` ` ` inline float calculate ( float x) const { return <number> . f / ( <number> . f + exp ( - x)) ; } ` ` ` i did ` ` ` inline float calculate ( float x) const { double <sad> = double ( x ) ; double sigm = <number> / ( <number> + exp ( - <sad> ) ); return static_cast <float> ( sigm ) ; } ` ` ` nan disappeared , detections appeared . # # # steps to reproduce ` ` ` <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> <cmath> <hashtag> include </hashtag> <typeinfo> using namespace std ; inline long double sigmoid ( float x) { return <number> . / ( <number> . + exp ( - x)) ; } int main ( ) { float x = - <number> ; double <sad> = double ( x ) ; double sig = <number> / ( <number> + exp ( - <sad> ) ); std : : cout < < "" double sigmoid = "" < < sig < < ' \ \ n ' ; std : : cout < < typeid ( sig ) . name ( ) < < ' \ \ n ' ; float sigm = static_cast \ \ < float \ \ > ( sig ) ; std : : cout < < "" float sigmoid = "" < < sigm < < ' \ \ n ' ; std : : cout < < typeid ( sigm ) . name ( ) < < ' \ \ n ' ; std : : cout < < "" \ \ n \ \ n "" ; double * p_x = & <sad> ; sig = <number> / ( <number> + exp ( - ( *p _x ) )); double * p_sig = & sig ; cout < < "" \ \ nsigmoid ( "" < < *p _x < < "" ) = "" < < *p _sig < < "" \ \ n \ \ n "" ; / / double dsqrtvalue = sqrt ( - <number> ); / / an image processing algorithm may eventually invoke sqrt ( ) with - <number> as its input . / / double dresult = - dsqrtvalue ; / / an image processing algorithm may involve taking the negative of another value . / / / / std : : cout < < dresult < < ' \ \ n ' ; / / / / float s; / / if ( dresult = = dresult ) / / s = sig ; / / else / / s = <number> . 0 f ; / / std : : cout < < "" else "" < < s < < ' \ \ n ' ; double tmp1 = exp ( - ( *p _x ) ); double * p_tmp1 = & tmp1 ; cout < < "" float ( exp ( x ) ) = "" < < *p _tmp1 < < ' \ \ n ' ; double tmp2 = <number> + *p _tmp1 ; double * p_tmp2 = & tmp2 ; cout < < "" ( <number> + exp ( x ) ) = "" < < *p _tmp2 < < ' \ \ n ' ; double tmp3 = <number> / *p _tmp2 ; double * p_tmp3 = & tmp3 ; cout < < "" ( <number> / ( <number> + exp ( - x))) = "" < < *p _tmp3 < < ' \ \ n ' ; cout < < sigmoid ( x ) < < ' \ \ n ' ; return <number> ; } ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fix detect diamonds api ` detectdiamonds ` cannot be called from python , reproducer import numpy as np import cv2 as cv detector = cv . aruco . charucodetector ( cv . aruco . charucoboard ( ( <number> , <number> ) , <number> , <number> , cv . aruco . getpredefineddictionary ( cv . aruco . dict_4x4_250 ) ) ) image = np . zeros ( ( <number> , <number> , <number> ) , dtype = np . uint8 ) res = detector . detectdiamonds ( image ) print ( res ) ` ` ` the error in ` detectdiamonds ` api fixed by replacing ` inputoutputarrayofarrays markerids ` with ` inputoutputarray markerids ` . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,g - api : fix static build with openvino need to register external dependency if dnn module is not used - dwith_openvino = on - dbuild_opencv_dnn = off - dbuild_shared_libs = off ` ` ` similar to <url>,0
opencv/opencv,"linux docker simd build fails # # # system information opencv - <number> . <number> emscripten / emsdk : <date> docker version <date> , build 2 9 7 e128 [ image ] ( <url> # # # detailed description want to build opencv <number> . <number> using docker with build . js and - - simd flag . * * end of error log : * * ! [ image ] ( <url> # # # errors log ( <number> lines ) [ errors . txt ] ( <url> # # # build log ( <number> lines ) [ build . txt ] ( <url> # # # steps to reproduce cd into opencv - <number> . <number> folder and docker run - - rm - v $( pwd ) <annoyed> src - u $( id - u ) :$ ( id - g ) - e emscripten <annoyed> emsdk / upstream / emscripten emscripten / emsdk : <date> python3 . / platforms / js / build_js . py build_simd - - build_wasm - - simd ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"force mat_wrapper import to satisfy dependencies for matlike alias solves : ` ` ` python <number> . <number> ( default , <date> , <time> ) [ gcc <number> . <number> ] on linux type "" help "" , "" copyright "" , "" credits "" or "" license "" for more information . > > > import cv2 traceback ( most recent call last ) : file "" <stdin> "" , line <number> , in <module> file "" / home / ksenia / projects / opencv - build - <number> / install / lib / python3 . <number> / site - packages / cv2 / __init__ . py "" , line <number> , in <module> bootstrap ( ) file "" / home / ksenia / projects / opencv - build - <number> / install / lib / python3 . <number> / site - packages / cv2 / __init__ . py "" , line <number> , in bootstrap if __load_extra_py_code_for_module ( "" cv2 "" , submodule , debug ) : file "" / home / ksenia / projects / opencv - build - <number> / install / lib / python3 . <number> / site - packages / cv2 / __init__ . py "" , line <number> , in __load_extra_py_code_for_module py_module = importlib . import_module ( module_name ) file "" / usr / lib / python3 . <number> / importlib / __init__ . py "" , line <number> , in import_module return _bootstrap . _gcd_import ( name [ level <happy> , package , level ) file "" / home / ksenia / projects / opencv - build - <number> / install / lib / python3 . <number> / site - packages / cv2 / typing / __init__ . py "" , line <number> , in <module> matlike = typing . union [ cv2 . mat_wrapper . mat , numpy . ndarray [ typing . any , numpy . dtype [ numpy . generic ] ] ] attributeerror initialized module ' cv2 ' has no attribute ' mat_wrapper ' ( most likely due to a circular import ) ` ` ` # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"fix : typing module enums references enum names exist only during type checking . during runtime they should be denoted as named integral types this patch fixes circular import issue introduced by # <number> . before patch ` termcriteria ` was defined as follows : ` ` ` python termcriteria = typing . tuple [ cv2 . termcriteria_type , int , float ] "" "" "" any type providing sequence protocol is supported "" "" "" ` ` ` which works fine during type checking , but introduces runtime failure : ` ` ` python > > > import cv2 . <repeated> termcriteria = tuple [ cv2 . termcriteria_type , int , float ] # any type providing sequence protocol is supported ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ attributeerror : partially initialized module ' cv2 ' has no attribute ' termcriteria_type ' ( most likely due to a circular import ) ` ` ` generated ` __init__ . py ` after patch will hide ` cv2 . termcriteria_type ` enumeration by ` typing . type_checknig ` guard . ` ` ` python if typing . type_checking : termcriteria_type = cv2 . termcriteria_type else = int termcriteria = typing . tuple [ termcriteria_type , int , float ] "" "" "" any type providing sequence protocol is supported "" "" "" ` ` ` so everything can be imported without any issues ` ` ` python > > > import cv2 > > > import cv2 . typing > > > cv2 . typing . termcriteria typing . tuple [ int , int , float ] > > > ` ` ` # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"change scalar assignment in python from single value # # # pull request readiness checklist resolves <url> i do not think that ` scalefactor ` as a ` scalar ` is a good idea . is there models with different scales for channels ? see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"type stubs : missing the ` cv2 . error ` class # # # system information opencv python : opencv_python_headless - <number> . <number> + 7 7 2 5 9 9 a - cp37 - abi3 - win_amd64 . whl operating system / platform : <number> . <number> build <number> python version : <date> # # # detailed description the ` cv2 . error ` class is missing from the generated stubs , it ' s an important one to catch cv2 errors . # # # steps to reproduce ` ` ` py import cv2 try : cv2 . videocapture ( ) . read ( ) # "" error "" is not a known member of module "" cv2 "" pylance ( reportgeneraltypeissues ) # type of "" error "" is unknown pylance ( reportunknownvariabletype ) except cv2 . error as error : pass ` ` ` runtime > > > import cv2 > > > from cv2 import error > > > cv2 . error < class ' cv2 . error ' > > > > error < class ' cv2 . error ' > ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"type stubs : ` optional ` parameters incorrectly marked as not - none in ` cv2 . calchist ` and ` cv2 . resize ` # # # system information opencv python : opencv_python_headless - <number> . <number> + 7 7 2 5 9 9 a - cp37 - abi3 - win_amd64 . whl operating system / platform : <number> . <number> build <number> python version : <date> # # # detailed description ` cv2 . calchist ` : the ` mask ` parameter should accept ` none ` ` cv2 . resize ` ` dsize ` parameter should accept ` none ` # # # steps to reproduce ` ` ` py import cv2 image = cv2 . imread ( "" some_path "" , cv2 . imread_unchanged ) # argument of type "" none "" cannot be assigned to parameter "" dsize "" of type "" size "" in function "" resize "" # type "" none "" cannot be assigned to type "" size "" pylancereportgeneraltypeissues cv2 . resize ( image , dsize = none ) # argument of type "" none "" cannot be assigned to parameter "" mask "" of type "" umat "" in function "" calchist "" # type "" none "" cannot be assigned to type "" umat "" pylancereportgeneraltypeissues cv2 . calchist ( [ image ] , [ <number> , <number> , <number> ] , none , [ <number> , <number> , <number> ] , [ <number> , <number> , <number> , <number> , <number> , <number> ] ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"type stubs : cv2 . error is missing all_caps constants # # # system information opencv python : opencv_python_headless - <number> . <number> + 7 7 2 5 9 9 a - cp37 - abi3 - win_amd64 . whl operating system / platform : <number> . <number> build <number> python version # # # detailed description cv2 . error is missing all_caps constants , which is the norm for python constants / final , and * do <emphasis> * exists at runtime . see steps below for an example . it ' s likely other modules are also missing their all_caps variants , i have only noticed ` cv2 . error ` because i am using it . # # # steps to reproduce ` ` ` py import cv2 . error cv2 . error . sts_error # "" sts_error "" is not a known member of module "" cv2 . error "" pylance ( reportgeneraltypeissues ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,build ( ios ) workaround for cmake <number> . <number> + fixes # <number>,0
opencv/opencv,"dnn bug for x86 winograd address <url> the patch aims to add a runtime check for x86 platform without avx ( <number> ) . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"winograd convolution fails with assertion on cpu without avx # # # system information opencv : <number> . x ( before <number> . <number> ) os : ubuntu linux <number> cpu : core <number> duo <number> # # # detailed description cpu features : ` ` ` cat / proc / cpuinfo processor : <number> vendor_id : genuineintel cpu family : <number> model : <number> model name : intel ( r ) core ( tm ) <number> cpu <number> @ <number> . 4 0 ghz stepping : <number> microcode : 0 xd0 cpu mhz : <number> cache size : <number> kb physical id : <number> siblings : <number> core id : <number> cpu cores : <number> apicid : <number> initial apicid : <number> fpu : yes fpu_exception : yes cpuid level : <number> wp : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl cpuid aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm lahf_lm pti tpr_shadow dtherm vmx flags : tsc_offset vtpr bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit mmio_unknown bogomips : <number> clflush size : <number> cache_alignment : <number> address sizes : <number> bits physical , <number> bits virtual power management : ` ` ` opencv optimizations : ` ` ` "" cpu / hw features :\\ n "" "" baseline : sse sse2 sse3 \ \ n "" "" requested : sse3 \ \ n "" "" dispatched code generation : sse4_1 sse4_2 fp16 avx avx2 avx512_skx \ \ n "" "" requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx \ \ n "" "" sse4_1 ( <number> files ) : + ssse3 sse4_1 \ \ n "" "" sse4_2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 \ \ n "" "" fp16 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 avx \ \ n "" "" avx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 avx \ \ n "" "" avx2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 \ \ n "" "" avx512_skx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 avx_512f avx512_common avx512_skx \ \ n "" ` ` ` # # # steps to reproduce tested with core <number> duo <number> and ubuntu <number> found some issue with latest convolution optimizations in dnn : ` ` ` . / bin / opencv_test_dnn ctest_full_output opencv version : <number> . <number> - dev opencv vcs version : <number> . <number> - <number> - gd3e7968927 build type : release compiler : / usr / bin / c + + ( ver <number> . <number> ) parallel framework : pthreads ( nthreads = <number> ) cpu features : sse sse2 sse3 * sse4 . <number> ? * sse4 . <number> ? * fp16 ? * avx ? * avx2 ? * avx512 - skx ? intel ( r ) ipp version : disabled opencl is disabled test : skip tests with tags : ' mem_6gb ' , ' verylong ' , ' dnn_skip_opencv_backend ' , ' dnn_skip_cpu ' , ' dnn_skip_cpu_fp16 ' , ' dnn_skip_ocl ' , ' dnn_skip_ocl_fp16 ' , ' dnn_skip_onnx_conformance ' , ' dnn_skip_parser ' . <repeated> [ - - - - - - - - - - ] <number> tests from dnntestnetwork [ run ] dnntestnetwork . alexnet / <number> , where getparam ( ) = ocv / cpu unknown file : failure c + + exception with description "" opencv ( <number> . <number> - dev ) / home / arina / projects / opencv / modules / dnn / src / layers / cpu_kernels / conv_winograd_f63 . cpp : <number> : error : ( - <number> : assertion failed ) conv_wino_iblock = = <number> & & conv_wino_kblock = = <number> & & conv_wino_atom_f32 = = <number> in function ' winofunc_btxb_8x8_f32 ' "" thrown in the test body . [ failed ] dnntestnetwork . alexnet / <number> , where getparam ( ) = ocv / cpu ( <number> ms ) [ run ] dnntestnetwork . resnet_50 / <number> , where getparam ( ) = ocv / cpu [ skip ] opencv tests : can not find data file : dnn / resnet - <number> - model . caffemodel [ ok ] dnntestnetwork . resnet_50 / <number> ( <number> ms ) [ run ] dnntestnetwork . squeezenet_v1_1 / <number> , where getparam ( ) = ocv / cpu unknown file : failure c + + exception with description "" opencv ( <number> . <number> - dev ) / home / arina / projects / opencv / modules / dnn / src / layers / cpu_kernels / conv_winograd_f63 . cpp : <number> : error : ( - <number> : assertion failed ) conv_wino_iblock = = <number> & & conv_wino_kblock = = <number> & & conv_wino_atom_f32 = = <number> in function ' winofunc_btxb_8x8_f32 ' "" thrown in the test body . [ failed ] dnntestnetwork . squeezenet_v1_1 / <number> , where getparam ( ) = ocv / cpu ( <number> ms ) [ run ] dnntestnetwork . googlenet / <number> , where getparam ( ) = ocv / cpu unknown file : failure c + + exception with description "" opencv ( <number> . <number> - dev ) / home / arina / projects / opencv / modules / dnn / src / layers / cpu_kernels / conv_winograd_f63 . cpp : <number> : error : ( - <number> : assertion failed ) conv_wino_iblock = = <number> & & conv_wino_kblock = = <number> & & conv_wino_atom_f32 = = <number> in function ' winofunc_btxb_8x8_f32 ' "" thrown in the test body . [ failed ] dnntestnetwork . googlenet / <number> , where getparam ( ) = ocv / cpu ( <number> ms ) [ run ] dnntestnetwork . inception_5h / <number> , where getparam ( ) = ocv / cpu unknown file : failure c + + exception with description "" opencv ( <number> . <number> - dev ) / home / arina / projects / opencv / modules / dnn / src / layers / cpu_kernels / conv_winograd_f63 . cpp : <number> : error failed ) conv_wino_iblock = = <number> & & conv_wino_kblock = = <number> & & conv_wino_atom_f32 = = <number> in function ' winofunc_btxb_8x8_f32 ' "" thrown in the test body . [ failed ] dnntestnetwork . inception_5h / <number> , where getparam ( ) = ocv / cpu ( <number> ms ) [ run ] dnntestnetwork . enet / <number> , where getparam ( ) = ocv / cpu double free or corruption ( prev ) segmentation fault ( core dumped ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"please do not hard - code cmake_cxx_standard # # # system information opencv version : <number> . <number> for redistribution across several platforms in [ conda - forge ] ( <url> # # # detailed description hi , i am a volunteer in conda - forge , the volunteer - driven packaging effort for conda / mamba ( which i see is [ mentioned ] ( <url> here already ) . we have been shipping opencv for about <number> years through the so - called [ feedstock ] ( <url> and packages can be installed like : ` ` ` conda install - c conda - forge opencv # or mamba instead of conda ` ` ` we have builds for linux - { <number> , aarch64 , ppc64le } , osx - { <number> , arm64 } , win - <number> , multiplied by ( currently ) cpython <number> - <number> as well as pypy <number> & <number> , multiplied by ( currently ) ffmpeg <number> & <number> , multiplied by protobuf <number> & <number> [ < - in progress ] . now to the actual issue : - - - - - - - there are various [ places ] ( <url> where opencv hard - codes the c + + standard , rather than respecting a user input like cmake [ options ] - dcmake_cxx_standard = <number> . <repeated> ` ` ` this is problematic because abseil ( which opencv now depends on through protobuf , as of their <number> . x series ) has an abi that ' s sensitive to the standard version and does not support any mixing of artefacts compiled with different versions . for distribution purposes , we therefore absolutely need to ensure that everything gets compiled consistently , and that currently means patching out these hard - coded ` <number> ` s and replacing them with ` <number> ` s . it would be much nicer ( and not just for us , i ' d argue ) , to be able to set ` cmake_cxx_standard ` once . that would likely involve some cmake if - conditions depending on whether ` cmake_cxx_standard ` is set , and / or erroring out if it ' s set lower than what you require as a minimum . # # # steps to reproduce use the following code [ search ] ( <url> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"topk layer not implemented # # # system information system : ubuntu <number> complier : gcc <number> . <number> opencv version : <number> . <number> ( build from source ) torch version : <number> . <number> + cpu torchvision version : <number> . <number> + cpu onnx version : <number> . <number> # # # detailed description following assertion in raised when topk layer is being parsed . it seems that topk layer in c + + is absent . ` ` ` console [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ topk ] <sad> onnx_node / topk ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> parsecustomlayer dnn / onnx : unknown node type , try using custom handler for node with <number> inputs and <number> outputs : [ topk ] <sad> onnx_node ! / topk ) opencv ( <number> . <number> - dev ) error : unspecified error ( can not create layer "" onnx_node ! / topk "" of type "" topk "" ) in getlayerinstance , file opencv / modules / dnn / src / net_impl . hpp , line <number> [ error : <number> <user> . <number> ] global onnx_importer . cpp : <number> handlenode dnn / onnx : error during processing node with <number> inputs and <number> outputs : [ topk ] <sad> onnx_node ! / topk ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> handlenode input [ <number> ] = ' input ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> handlenode input [ <number> ] = ' / constant_output_0 ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> handlenode output [ <number> ] = ' output ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> handlenode output [ <number> ] = ' <number> ' opencv ( <number> . <number> - dev ) error : unspecified error ( > node [ <email> <sad> ( onnx_node ! / topk ) parse error : opencv ( <number> . <number> - dev ) opencv / modules / dnn / src / net_impl . hpp : <number> : error : ( - <number> : unspecified error ) can not create layer "" onnx_node ! / topk "" of type "" topk "" in function ' getlayerinstance ' > ) in handlenode , file opencv / modules / dnn / src / onnx / onnx_importer . cpp , line <number> [ debug : <number> <user> . <number> ] global system . cpp : <number> restorefpdenormalsstate core : restore fp mxcsr flags = 0x0 0 0 0 1 fa3 traceback ( most recent call last ) : file "" topk . py "" , line <number> , in <module> opencv_net = cv2 . dnn . readnetfromonnx ( full_model_path ) cv2 . error : opencv ( <number> . <number> - dev ) opencv / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' handlenode ' ` ` ` # # # steps to reproduce ` ` ` python import cv2 import onnx , os import torch import torch . nn as nn from onnx import shape_inference from onnxsim import simplify class topk ( nn . module ) : def forward ( self , x) : return torch . topk ( x , <number> ) if __name__ = = "" __main__ "" = "" models "" onnx_model_name = "" topk . onnx "" full_model_path = os . path . join ( onnx_model_path , onnx_model_name ) topk = topk ( ) x = torch . arange ( <number> . , <number> . ) v , i = topk ( x ) torch . onnx . export ( topk , x , full_model_path , verbose = false , input_names =[ "" input "" ] , output_names =[ "" output "" ] , opset_version = <number> ) onnx_model = onnx . load ( full_model_path ) onnx . checker . check_model ( onnx_model ) onnx_model = shape_inference . infer_shapes ( onnx_model ) onnx . save ( onnx_model , full_model_path ) opencv_net = cv2 . dnn . readnetfromonnx ( full_model_path ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"unable to compile opencv <number> . <number> on ubuntu <number> # # # system information os : ubuntu <number> opencv version <number> . <number> compiler version : cmake version <number> . <number> , gcc version <number> . <number> ( ubuntu <number> . <number> - 1 ubuntu1 ~ <number> . <number> ) # # # detailed description i am trying to compile opencv for use with c + + and python with cuda enabled . for this , i cloned the opencv as well as the opencv - contrib repositories and tried to compile . i get no errors or warnings when running cmake , but the compilation breaks at around <percent> with the following last output lines : ` ` ` … [ <percent> ] building cxx object modules / dnn / cmakefiles / opencv_dnn . dir / int8layers / layers_common . avx2 . cpp . o [ <percent> ] building cxx object modules / dnn / cmakefiles / opencv_dnn . dir / layers / layers_common . avx512_skx . cpp . o [ <percent> ] building cxx object modules / dnn / cmakefiles / opencv_dnn . dir / int8layers / layers_common . avx512_skx . cpp . o [ <percent> ] linking cxx shared library . <repeated> / . <repeated> / lib / libopencv_dnn . so [ <percent> ] linking cxx executable . <repeated> / . <repeated> / bin / opencv_test_imgproc [ <percent> ] built target opencv_dnn [ <percent> ] built target opencv_test_imgproc [ <percent> ] building cxx object modules / cudev / test / cmakefiles / opencv_test_cudev . dir / test_main . cpp . o [ <percent> ] linking cxx executable . <repeated> / . <repeated> / . <repeated> / bin / opencv_test_cudev [ <percent> ] built target opencv_test_cudev [ <percent> ] linking cxx executable . <repeated> / . <repeated> / bin / opencv_test_core [ <percent> ] built target opencv_test_core make : * * * [ makefile : <number> : all ] error <number> ` ` ` # # # steps to reproduce i ran the following commands git clone <url> git clone <url> cd opencv mkdir build cd build cmake - d cmake_build_type = release - d cmake_install_prefix <annoyed> usr / local - d with_cuda = on - d with_cudnn = on - d with_cublas = on - d with_tbb = on - d opencv_dnn_cuda = on - d opencv_enable_nonfree = on - d cuda_arch_bin = <number> - d opencv_extra_modules_path <annoyed> home / luiz / downloads / opencv_contrib / modules - d build_examples = off - d have_opencv_python3 = on - d enable_fast_math = <number> - d cuda_fast_math = <number> - d with_cublas = <number> - d with_ffmpeg = <number> . <repeated> make - j <number> ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fix missuse of try_gpu in stitching / featherblender removed passing try_gpu parameter to featherblender constructor because it only has sharpness parameter and does not support gpu branch , # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"torch interpolate ' s onnx graph fails while parsing # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version : gcc <number> . <number> python version : <number> . <number> # # # detailed description trying to read ` . onnx ` file created using ` torch . nn . functional . interpolate ` . i get this error ` ` ` console opencv_net = cv2 . dnn . readnetfromonnx ( full_model_path ) cv2 . error : opencv ( <number> . <number> - dev ) / opencv / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' handlenode ' > node [ <email> <sad> ( onnx_node / floor ) parse error : opencv ( <number> . <number> - dev ) / opencv / modules / dnn / src / layers / elementwise_layers . cpp : <number> : error : ( - <number> : assertion failed ) src . size = = dst . size & & src . type ( ) = = dst . type ( ) & & src . iscontinuous ( ) & & dst . iscontinuous ( ) & & src . type ( ) = = cv_32f in function ' forward ' ` ` ` # # # steps to reproduce ` ` ` python import torch import torch . nn as nn import torch . nn . functional as f import os import onnx import cv2 from onnx import shape_inference class resizer ( nn . module ) : def forward ( self , image : torch . tensor ) : image = f . interpolate ( image , size = none , scale_factor = <number> , mode = "" bilinear "" , recompute_scale_factor = <number> , align_corners = false , ) return image if __name__ = = "" __main__ "" : resize = resizer ( ) x = torch . ones ( ( <number> , <number> , <number> , <number> ) ) print ( f "" <kiss> {x . shape } "" ) x_r = resize ( x ) print ( f "" x_r onnx_model_path = "" models "" # define the name of further converted model onnx_model_name = "" resize . onnx "" os . makedirs ( onnx_model_path , exist_ok = true ) full_model_path = os . path . join ( onnx_model_path , onnx_model_name ) print ( "" \ \ t \ \ t - - - > exporting < - - - "" ) # model export into onnx format torch . onnx . export ( resize , x , full_model_path , verbose = false , input_names =[ "" input "" ] , output_names =[ "" output "" ] , opset_version = <number> ) print ( "" \ \ t \ \ t - - - > reading onnx file in onnx < - - - "" ) onnx_model = onnx . load ( full_model_path ) onnx . checker . check_model ( onnx_model ) onnx_model = shape_inference . infer_shapes ( onnx_model ) onnx . save ( onnx_model , full_model_path ) print ( "" \ \ t \ \ t - - - > reading onnx in opencv file < - - - "" ) opencv_net = cv2 . dnn . readnetfromonnx ( full_model_path ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,build regression after openjpeg upgrade relates # <number> ci logs <url> - <url> - <url>,0
opencv/opencv,"update setup . py fix error : unboundlocalerror variable ' typing_stub_files ' referenced before assignment # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"image must be cloned in text spotting # # # system information same problem in scene_text_spotting than in <url> # # # detailed description image where result are printed must be a clone when - - rgb is set to <number> <url> <url> # # # steps to reproduce scene_text_spotting - - rgb = <number> - i =""c :\\ lib \ \ opencv_zoo \ \ models \ \ text_detection_db \ \ examples \ \ gsoc . jpg "" - - dmp =c :\\ dnn_models \ \ db_ic15_resnet50 . onnx - - rmp =c :\\ dnn_models \ \ crnn_cs . onnx <number> : ' program ' * * <number> : ' broar ' * * <number> : ' view ' <number> : ' announced ' <number> : ' program ' <number> : ' <number> ' <number> : ' code ' <number> : ' summer ' <number> : ' google ' result with clone <number> : ' program ' * * <number> : ' page ' * * <number> : ' view ' <number> : ' announced ' <number> : ' program ' <number> : ' <number> ' <number> : ' code ' <number> : ' summer ' <number> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fixed fps computation on some videos for ffmpeg backend address # <url> introduced in <url> most probably a typo . # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"added check that yuyv input of cvtcolor has even width . resolves <url> # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"update matchtemplate with mask docstring * update the documentation * minor optimizations to mask2 calculation resolves <url> alternatively to <url> docs preview # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"add charuco board check added charuco board checking to avoid detection of incorrect board . fixes # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"proposed solution for issue # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work [ <url> - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"opencv - python memory leak caused by failed cvtcolor ( ) calls # # # system information opencv python version : <number> . <number> operating system : ubuntu <number> python version : <number> . <number> # # # detailed description in my application frames are received from multiple sensors and processed as fast as possible . the processing step is designed in a way , that some exceptions can occur in small number and are ignored in order to keep the system running . multiple mistakes resulted that following case : some frames got passed to process using wrong ` dtype ` and caused an error at ` cvtcolor ( ) ` function . the exception got logged but ignored , the frame was dropped and the process kept running . and i noticed unusual memory usage in the long run . # # # steps to reproduce # # # sample code to present the failed conversion : ` ` ` python import cv2 import numpy as np if __name__ = = "" __main__ "" : frame1 = np . zeros ( ( <number> , <number> , <number> ) , dtype = np . uint8 ) gray1 = cv2 . cvtcolor ( frame1 , cv2 . color_bgr2gray ) print ( "" frame1 succesfully converted \ \ n "" ) frame2 = np . zeros ( ( <number> , <number> , <number> ) , dtype = np . float64 ) gray2 = cv2 . cvtcolor ( frame2 , cv2 . color_bgr2gray ) print ( "" frame2 succesfully converted \ \ n "" ) ` ` ` produces the following output : ` ` ` frame1 succesfully converted traceback ( most recent call last ) : file "" cv_memory_leak_test . py "" , line <number> , in <module> gray2 = cv2 . cvtcolor ( frame2 , cv2 . color_bgr2gray ) cv2 . error : opencv ( <number> . <number> ) / io / opencv / modules / imgproc / src / color . simd_helpers . hpp : <number> : error : ( - <number> : unspecified error ) in function ' cv : : impl : : { anonymous } : : cvthelper < vscn , vdcn , vdepth , sizepolicy > : : cvthelper ( cv : : inputarray , cv : : outputarray , int ) [ with vscn = cv : : impl : : { anonymous } : : set < <number> , <number> >; vdcn = cv : : impl : : { anonymous } : : set < <number> >; vdepth = cv : : impl : : { anonymous } : : set < <number> , <number> , <number> >; cv : : impl : : { anonymous } : : sizepolicy sizepolicy = cv : : impl : : <unnamed> : : none ; cv : : inputarray = const cv : : _inputarray & ; cv : : outputarray = const cv : : _outputarray & ] ' > unsupported depth of input image : > ' vdepth : : contains ( depth ) ' > where > ' depth ' is <number> ( cv_64f ) ` ` ` # # # sample code to reproduce noticeable memory usage : this code simulates what would happen if the conversion would fail a lot of times . in this code memory usage is measured by using a terminal command , if you are not using ubuntu , you might want to use a different method to track memory usage . note that the memory * * does get * * cleaned up , but just after the program is terminated . ` ` ` python import os import cv2 import numpy as np if __name__ = = "" __main__ "" : # frame = np . zeros ( ( <number> , <number> , <number> ) , dtype = np . uint8 ) # no memory leaks , successful conversion frame = np . zeros ( ( <number> , <number> , <number> ) , dtype = np . float64 ) # memory leak , failed conversion n = 1 _000_000 # n = 1 _000_000 will result ( ~ <number> gb reserved memory ) for i in range ( n ) : # measure memory usage if ( i % ( n / / <number> ) = = <number> <sad> memory_usage = os . popen ( ' free - h ' ) . readlines ( ) [ <number> ] . split ( ) print ( ( "" i = % 0 6 d | memory used %s from %s "" )% ( i , memory_usage [ <number> ] , memory_usage [ <number> ] ) ) # attempt conversion try : gray = cv2 . cvtcolor ( frame , cv2 . color_bgr2gray ) except exception as e : pass # for the sake of simplicity i pass here , the exception did get logged in the actual application ` ` ` possible output i = <number> | memory used <number> , 7 g from 1 5 g i = <number> | memory used <number> , 8 g from 1 5 g i = <number> | memory used <number> , 0 g from 1 5 g i = <number> | memory used <number> , 1 g from 1 5 g i = <number> | memory used <number> , 3 g from 1 5 g i = <number> | memory used <number> , 4 g from 1 5 g i = <number> | memory used <number> , 5 g from 1 5 g i = <number> | memory used <number> , 7 g from 1 5 g i = <number> | memory used <number> , 8 g from 1 5 g i = <number> | memory used <number> , 0 g from 1 5 g ` ` ` i checked some memory leak related issues in the repo , but not all of them . please tag , if some issues relate . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"ios <number> . <number> release zip file layout changed without version bump # # # system information opencv version : <number> . <number> operating system / platform : macos <number> . <number> compiler & compiler version : apple clang version <number> . <number> ( clang - <number> . <number> . <number> ) # # # detailed description not sure if this is the best place to surface this issue , happy to move the discussion elsewhere with the maintainers . we noticed that for the <number> . <number> , the zipfile layout for the ios framework has changed without version bump on may <number> , <number> . it ' s quite annoying that our ci and all of our developers ' laptop were just mysterious broken this morning . in general , we would really appreciate it any changes to the release is associated with a different minor version bump , instead of directly editing the same release . before ` ` ` $ unzip - l opencv - <number> . <number> - ios - framework . zip [ <time> ] archive : opencv - <number> . <number> - ios - framework . zip length date time name - - - - - - - - - - - - - - - - - - - - - - - - - - - - <number> <date> <time> opencv2 . framework / <number> <date> <time> opencv2 . framework / resources <number> <date> <time> opencv2 . framework / versions / <number> <date> <time> opencv2 . framework / versions / a / <number> <date> <time> opencv2 . framework / versions / a / resources / <number> <date> <time> opencv2 . framework / versions / a / resources / info . plist <number> <date> <time> opencv2 . framework / versions / a / headers / <number> <date> <time> opencv2 . framework / versions / a / headers / imgproc . hpp <number> <date> <time> opencv2 . framework / versions / a / headers / video / <number> <date> <time> opencv2 . framework / versions / a / headers / video / tracking . hpp <number> <date> <time> opencv2 . framework / versions / a / headers / video / tracking_c . h <number> <date> <time> opencv2 . framework / versions / a / headers / video / background_segm . hpp <number> <date> <time> opencv2 . framework / versions / a / headers / video / video . hpp <number> <date> <time> opencv2 . framework / versions / a / headers / world . hpp <number> <date> <time> opencv2 . framework / versions / a / headers / shape / <number> <date> <time> opencv2 . framework / versions / a / headers / shape / emdl1 . hpp <number> <date> <time> opencv2 . framework / versions / a / headers / shape / shape_distance . hpp . <repeated> ( more ) ` ` ` after ` ` ` $ unzip - l opencv - <number> . <number> - ios - framework . zip [ <time> ] archive length date time name - - - - - - - - - - - - - - - - - - - - - - - - - - - - <number> <date> <time> opencv - <number> . x - ios - framework . zip - - - - - - - - - - - - - - - - <number> <number> file ` ` ` # # # steps to reproduce compare the ` opencv - <number> . <number> - ios - framework . zip ` prior to may 1 5 th , <number> ( md5 checksum 9 2 7 5 0 cd0089e03b9991bb6cbaf113c49 ) to ` opencv - <number> . <number> - ios - framework . zip ` after may 1 5 th , <number> ( md5 checksum 4 8 5 5 d3d7ad34e6ec6761a3df56999c58 ) # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"remove unused var # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work <url> - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"qrcodedetector floodfill with outside - of - image seedpoint naive change for the # <number> issue . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"lstm layer with ` batch_firs = true ` fails # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version : gcc <number> . <number> python version : <date> # # # detailed description when i convert lstm torch model with ` batch_first = true ` and run it in opencv it fails with the following error : ` ` ` bash opencv ( <number> . <number> - dev ) error : assertion failed ( ( int ) _numaxes = = inputs [ <number> ] . size ( ) ) in getmemoryshapes , file / home / abduragim / projects / opencv_proj / opencv / modules / dnn / src / layers / permute_layer . cpp , line <number> [ error : <number> <user> . <number> ] global net_impl . cpp : <number> getlayershapesrecursively opencv / dnn : [ permute ] <sad> onnx_node / rnns / transpose ) : getmemoryshapes ( ) throws exception . inputs = <number> outputs = <number> / <number> blobs = <number> [ error : <number> <user> . <number> ] global net_impl . cpp : <number> getlayershapesrecursively input [ <number> ] = [ <number> <number> <number> <number> ] [ error : <number> <user> . <number> ] global net_impl . cpp : <number> getlayershapesrecursively exception message : opencv ( <number> . <number> - dev ) / home / abduragim / projects / opencv_proj / opencv / modules / dnn / src / layers / permute_layer . cpp : <number> : error : ( - <number> : assertion failed ) ( int ) _numaxes = = inputs [ <number> ] . size ( ) in function ' getmemoryshapes ' traceback ( most recent call last ) : file "" test_lstm . py "" , line <number> , in <module> out_opencv = net . forward ( ) cv2 . error : opencv ( <number> . <number> - dev ) / home / abduragim / projects / opencv_proj / opencv / modules / dnn / src / layers / permute_layer . cpp : <number> : error : ( - <number> : assertion failed ) ( int ) _numaxes = = inputs [ <number> ] . size ( ) in function ' getmemoryshapes ' ` ` ` # # # steps to reproduce ` ` ` python import torch import torch . nn as nn import onnxruntime import numpy as np import cv2 import random # set random seeds seed = <number> random . seed ( seed ) np . random . seed ( seed ) torch . manual_seed ( seed ) torch . cuda . manual_seed_all ( seed ) torch . backends . cudnn . deterministic = true torch . backends . cudnn . benchmark = false np . set_printoptions ( precision = <number> ) class layerlstm ( nn . module ) : def __init__ ( self , features , hidden_size , layers = <number> , batch_first = false ) : super ( layerlstm , self ) . __init__ ( ) self . rnns = nn . lstm ( input_size = features , hidden_size = hidden_size , num_layers = layers , batch_first = batch_first ) self . set_weights_to_ones ( ) def forward ( self , x , hx , cx ) : x , ( hx , cx ) = self . rnns ( x , ( hx , cx ) ) return x , ( hx , cx ) def set_weights_to_ones ( self ) : with torch . no_grad ( <sad> for name , param in self . rnns . named_parameters ( <sad> if ' weight ' in name or ' bias ' in name : param . fill_ ( <number> ) if __name__ = = "" __main__ "" : features = <number> hidden_size = <number> batch_size = <number> seq_len = <number> layout = true model = layerlstm ( features , hidden_size , batch_first = layout ) with torch . no_grad ( <sad> if layout : x = torch . ones ( batch_size , seq_len , features ) else = torch . ones ( seq_len , batch_size , features ) hx = torch . ones ( <number> , batch_size , hidden_size ) cx = torch . ones ( <number> , batch_size , hidden_size ) print ( x . shape , hx . shape , cx . shape , sep ='\\ n ' ) out , ( hn , cn ) = model ( x , hx , cx ) torch . onnx . export ( model , (x , hx , cx ) , ' . / sample_lstm . onnx ' , verbose = true , input_names =[ ' x', ' hx ' , ' cx ' ] , output_names =[ ' output ' ] ) net = cv2 . dnn . readnetfromonnx ( ' . / sample_lstm . onnx ' ) x_opencv = x . numpy ( ) [ . <repeated> , none ] hx_opencv = hx . numpy ( ) [ . <repeated> , none ] cx_opencv = cx . numpy ( ) [ . <repeated> , none ] # set input data net . setinput ( x_opencv ) net . setinput ( hx_opencv , name = "" hx "" ) net . setinput ( cx_opencv , name = "" cx "" ) out_opencv = net . forward ( ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"crash in net . forward ( ) # # # system information opencv version : <number> . <number> operating system / platform : windows10 x64 compiler & compiler version : code : : blocks <number> gcc <number> . <number> # # # detailed description software crash in net . forward ( ) function and show this : process returned - <phone> ( 0 xc0000005 ) execution time s # # # steps to reproduce ` ` ` net = cv : : dnn : : readnetfromcaffe ( caffeconfigfile , caffeweightfile ) ; net . setpreferablebackend ( dnn_target_cpu ) ; source . read ( frame ) ; inputblob = cv : : dnn : : blobfromimage ( frame , inscalefactor , cv : : size ( inwidth , inheight ) , meanval , false , false ) ; net . setinput ( inputblob , "" data "" ); cv : : mat detection = net . forward ( "" detection_out "" ); ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"reformulated some pointer arithmetic to avoid ( unsigned ) overflow although unsigned overflow is well - defined by the c + + standard , it is often unintentional or confusing and so ubsan has an option to warn about it . it warned here of unsigned offset to 0x0 0 0 1 7 fd31b97 overflowed to 0x0 0 0 1 7 fd30c97 ` in my own use of opencv at least , this is the only case of unsigned overflow . i reformunated the pointer arithmetic to either add or subtract based on the sign of y . it ' s easier to understand this way vs always adding and wrapping around to an address smaller <emphasis> than the base address .",0
opencv/opencv,"dnn / cuda the bug of same shape broadcast with cuda merged after <url> fix yolo regression error mentioned in <url> after fix this bug , the brute force test mentioned in <url> will all passed with cuda . ( different shape broadcast will fallback to cpu ) test is added in pr <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"fix nary elementwise bug in cpu after fix this bug , the brute force test mentioned in <url> will all passed in cpu . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"do not ignore documentation for cv : : format in doxygen see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work issue <url> - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"` videocapture ` opencv / contrib / # <number> fix [ opencv / contrib / # <number> ] ( <url> by allowing the bitstream filter to be applied to all h264 / <number> raw streams . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"can not infer a dim denoted by - <number> in function ' cv : : dnn : : computeshapebyreshapemask ' # # # system information opencv version : <number> . x operating system / platform : windows <number> python version : <date> # # # detailed description related issue : <url> reading [ this onnx model ] ( <url> is correct , this model can be forwarded on cpu . however , it cannot be forwarded on cuda . seems like reshape layer have a bug . ` ` ` shell [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : populatenet dnn / onnx : loading onnx v7 model produced by ' tf2onnx ' : <number> . <number> 2 c1db5 . number of nodes = <number> , initializers = <number> , inputs = <number> , outputs = <number> [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : parseoperatorset dnn / onnx : onnx opset version = <number> [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : parseoperatorset dnn / onnx : unknown domain = ' ai . onnx . ml ' version = <number> . no dispatch map , you may need to register ' custom ' layers . [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_noderesnet18 / 0 _conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / 0 _prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / 0 _prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / 0 _prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / 0 _prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / 0 _prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack1_block1_shortcut_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack1_block1_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack1_block1_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack1_block1_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack1_block1_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack1_block1_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack1_block1_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack1_block1_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack1_block1_2_prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack1_block1_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack1_block1_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack1_block2_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack1_block2_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack1_block2_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack1_block2_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack1_block2_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack1_block2_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack1_block2_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack1_block2_2_prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack1_block2_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack1_block2_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack2_block1_shortcut_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack2_block1_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack2_block1_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack2_block1_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack2_block1_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack2_block1_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack2_block1_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack2_block1_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack2_block1_2_prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack2_block1_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack2_block1_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack2_block2_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack2_block2_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack2_block2_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack2_block2_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack2_block2_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack2_block2_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack2_block2_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack2_block2_2_prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack2_block2_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack2_block2_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack3_block1_shortcut_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack3_block1_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack3_block1_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack3_block1_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack3_block1_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack3_block1_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack3_block1_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack3_block1_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack3_block1_2_prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack3_block1_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack3_block1_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack3_block2_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack3_block2_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack3_block2_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack3_block2_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack3_block2_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack3_block2_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack3_block2_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack3_block2_2_prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack3_block2_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack3_block2_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack4_block1_shortcut_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack4_block1_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack4_block1_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack4_block1_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack4_block1_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack4_block1_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack4_block1_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack4_block1_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack4_block1_2_prelu / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack4_block1_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack4_block1_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack4_block2_1_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack4_block2_1_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / stack4_block2_2_bn / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack4_block2_2_prelu / relu ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ neg ] <sad> onnx_node ! resnet18 / stack4_block2_2_prelu / neg_1 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ relu ] <sad> onnx_node ! resnet18 / stack4_block2_2_prelu / relu_1 ) from domain = ' ai . onnx ' [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20221220 : : net : : impl : : getlayershapesrecursively opencv / dnn : [ reshape ] <sad> onnx_node ! resnet18 / e_flatten / reshape ) : getmemoryshapes ( ) throws exception . inputs = <number> outputs = <number> / <number> blobs = <number> [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / stack4_block2_2_prelu / mul ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack4_block2_2_prelu / add ) from domain = ' ai . onnx ' [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20221220 : : net : : impl : : getlayershapesrecursively input [ <number> ] = [ <number> <number> <number> <number> ] [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ conv ] <sad> onnx_node ! resnet18 / stack4_block2_2_conv / conv2d ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ add ] <sad> onnx_node ! resnet18 / stack4_block2_add / add ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ batchnormalization ] <sad> onnx_node ! resnet18 / e_batchnorm / fusedbatchnormv3 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ transpose ] <sad> onnx_node ! resnet18 / e_batchnorm / fusedbatchnormv3__210 ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ reshape ] <sad> onnx_node ! resnet18 / e_flatten / reshape ) from domain = ' ai . onnx ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ matmul ] <sad> onnx_node ! resnet18 / e_dense / matmul ) from domain = ' ai . onnx ' [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20221220 : : net : : impl : : getlayershapesrecursively output [ <number> ] = [ <number> <number> ] [ error : <number> <user> . <number> ] global net_impl . cpp : <number> cv : : dnn : : dnn4_v20221220 : : net : : impl : : getlayershapesrecursively exception message : opencv ( <number> . <number> - dev ) c :\\ users \ \ zoom \ \ desktop \ \ opencv_china \ \ opencv \ \ modules \ \ dnn \ \ src \ \ layers \ \ reshape_layer . cpp : <number> : error : ( - <number> : backtrace ) can not infer a dim denoted by - <number> in function ' cv : : dnn : : computeshapebyreshapemask ' [ info : <number> <user> . <number> ] global onnx_importer . cpp : <number> cv : : dnn : : dnn4_v20221220 : : onnximporter : : handlenode dnn / onnx : processing node with <number> inputs and <number> outputs : [ mul ] <sad> onnx_node ! resnet18 / pre_embedding / batchnorm / mul_1 ) from domain = ' ai . onnx ' unknown file : error : c + + exception with description "" opencv ( <number> . <number> - dev ) c :\\ users \ \ zoom \ \ desktop \ \ opencv_china \ \ opencv \ \ modules \ \ dnn \ \ src \ \ layers \ \ reshape_layer . cpp : <number> : error can not infer a dim denoted by - <number> in function ' cv : : dnn : : computeshapebyreshapemask ' "" thrown in the test body . process finished with exit code <number> ` ` ` # # # steps to reproduce ` ` ` cpp auto imagetotest = "" path / to / img "" ; auto modeltotest = "" path / to / model "" ; int modelinputwidth = <number> ; int modelinputheight = <number> ; cv : : size currsize = cv : : size ( modelinputwidth , modelinputheight ) ; std : : string modeltotestonnx = modeltotest ; std : : string imagefilename = imagetotest ; unsigned int num_inferences = <number> ; cv : : dnn : : net net = cv : : dnn : : readnetfromonnx ( modeltotestonnx ) ; net . setpreferablebackend ( cv : : dnn : : dnn_backend_cuda ) ; net . setpreferabletarget ( cv : : dnn : : dnn_target_cuda ) ; cv : : mat img = cv : : imread ( imagefilename , cv : : imread_anycolor ) ; cv : : mat resized ; cv : : resize ( img , resized , currsize ) ; std : : vector < cv : : mat > imgbatch = { resized }; bool swaprbchannels = false ; cv : : mat blob = cv : : dnn : : blobfromimages ( imgbatch , <number> . 0 f / <number> . 0 f , cv : : size ( ) , cv : : scalar ( ) , swaprbchannels , false , cv_32f ) ; net . setinput ( blob ) ; std : : vector < cv : : string > unconnectedoutlayernames = net . getunconnectedoutlayersnames ( ); std : : vector < cv : : mat > outputs ; outputs . clear ( ); auto timeloadmodelplusinference1 = std : : chrono : : high_resolution_clock : : now ( ); net . forward ( outputs , unconnectedoutlayernames ) ; ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"charucodetector : : detectboard returns garbadge in case of board parameters mismatch # # # system information opencv version : <number> . <number> + # # # detailed description issue origin : <url> in case if board width and height are swapped the method detects board , but result is inadequate . marker ids and corners coordinates looks realistic , but does not match actual board layout . # # # steps to reproduce board : from pr : <url> how to reproduce : - with interactive calibration tool ( copy interactive - calibration / defaultconfig . xml to current dir and replace charuco_dict value to <number> <sad> . / bin / opencv_interactive - calibration - w = <number> - h = <number> - t = charuco - with calibration . cpp ( pr <url> ` . / example_cpp_calibration - w = <number> - h = <number> - pt = charucoboard - ad = <number> ` proposed behaviour return empty list for ids and coordinates - add return value and return false # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"dnn : try to fix the sporadic crashes in perf_dnn address <url> merge with test # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",0
opencv/opencv,"more sprintf removals this first <number> commits are from <url> ( i will rebase this after that is merged ) . the last commit is an incomplete proposal to deprecated ` converttypestr ` and make a new variant using ` std : : string ` . if it ' s acceptable , i will complete the pr to use the new method everywhere . ` ` ` force_builders = linux opencl , win64 opencl ` ` `",0
opencv/opencv,"cv2 . aruco . calibratecameracharuco does not exist # # # system information opencv python version : <number> . <number> operating system / platform : ubuntu <number> python version : <number> # # # detailed description i am working on calibrating a camera with a charuco board . i ported my pre - opencv <number> code to <number> now , but i am stuck at actually calibrating the camera using the detected points since a necessary function is apparently not included in the generated python bindings : ` ` ` traceback ( most recent call last ) : file "" / home / fe / korjakow / projects / intrinsic_calibrator / install / camera_calibration / lib / python3 . <number> / site - packages / camera_calibration / camera_calibrator . py "" , line <number> , in on_mouse self . c . do_calibration ( ) file "" / home / fe / korjakow / projects / intrinsic_calibrator / install / camera_calibration / lib / python3 . <number> / site - packages / camera_calibration / calibrator . py "" , line <number> , in do_calibration self . cal_fromcorners ( self . good_corners ) file "" / home / fe / korjakow / projects / intrinsic_calibrator / install / camera_calibration / lib / python3 . <number> / site - packages / camera_calibration / calibrator . py "" , line <number> , in cal_fromcorners reproj_err , self . intrinsics , self . distortion , rvecs , tvecs = cv2 . aruco . calibratecameracharuco ( attributeerror : module ' cv2 . aruco ' has no attribute ' calibratecameracharuco ' ` ` ` according to the docs the function should exist though would it be possible to add it back in ? # # # steps to reproduce ` ` ` python import cv2 cv2 . aruco . calibratecameracharuco ( none , none , none , none , none , none ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",0
opencv/opencv,"fix onnx parser for single - layer lstm hidden and cell states # # # fix onnx parser for single - layer lstm hidden and cell states # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake this pr addresses # <number> [ issue ] ( <url> the problem is that the onnx parser is unable to read the hidden state and cell state for single - layer lstms . this pr fixes the issue by updating the parser to correctly read hidden and cell states .",0
opencv/opencv,"allow find_package ( opencv ) in cmake to return paths without versions on linux # # # describe the feature and motivation allow applications finding opencv by cmake to specify , whether they want to link to the path containing opencv version , e . g . ` / usr / lib / libopencv_imgproc . so . <number> ` or to version - less file , such as ` / usr / lib / libopencv_imgproc . so ` . this could be done by setting a cmake variable before calling ` find_package ` , like so : ` ` ` cmake set ( opencv_use_paths_with_versions <number> ) find_package ( opencv ) ` ` ` to keep compatibility , the default value should be ` <number> ` . note : i ' d be happy to prepare a pr and implement this , but i ' d need a confirmation from someone on the team , that this is desired , so i do not waste my time <happy> # # # additional context on my system ( arch linux ) the path to actual ` . so ` is assigned to opencv cmake targets in ` / usr / lib / cmake / opencv4 / opencvmodules - release . cmake ` file : ` ` ` cmake . <repeated> # import target "" opencv_imgproc "" for configuration "" release "" set_property ( target opencv_imgproc append property imported_configurations release ) set_target_properties ( opencv_imgproc properties imported_location_release "" ${ _import_prefix } / lib / libopencv_imgproc . so . <number> . <number> "" imported_soname_release "" libopencv_imgproc . so . <number> "" ) . <repeated> ` ` ` because the full path is being hardcoded here , applications link to a very specific library version . when opencv is upgraded , the applications can no longer find the version and fail to load . an example of this happening often is a ` nomacs ` package ( see comments ) . i encounter this problem regularly and have to recompile ` nomacs ` each time opencv is upgraded on my machine .",2
opencv/opencv,"installing opencv by conda makes pytorch cuda not available # # # system information opencv python version : <number> . <number> operating system / platform : ubuntu <number> python version ( conda env ) : <number> . <number> gpu : nvidia geforce rtx <number> gpu driver version : <number> . <number> # # # detailed description after installing opencv by this command though conda , pytorch cuda is not available anymore : ` ` ` conda install - c conda - forge opencv ` ` ` this command replaced the cuda - enabled pytorch with cpu - enabled - only pytroch : < img width = "" <number> "" alt = "" image "" src = "" <url> results in : ` ` ` ( mouse ) $ python - c "" import torch ; print ( torch . cuda . is_available ( ) ) "" false ` ` ` # # # steps to reproduce <number> . install pytorch following the official instruction : ` conda install pytorch torchvision torchaudio pytorch - cuda = <number> - c pytorch - c nvidia ` <number> . install opencv install - c conda - forge opencv ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"bug , the video is being displayed accelerated # # # system information windows <number> python <number> . <number> opencv version = name : opencv - python version : <number> . <number> summary : wrapper package for opencv python bindings . home - page : <url> author : author - email : license : apache <number> location : c :\\ users \ \ administrator \ \ desktop \ \ all - in - <number> - varejo \ \ venv \ \ lib \ \ site - packages requires : numpy , numpy , numpy , numpy , numpy required - by : cvzone , openvino - dev , ultralytics # # # detailed description # # <hashtag> the </hashtag> video shown is being accelerated import cv2 cap = cv2 . videocapture ( ' contador_pessoas / pessoas1 . mp4 ' ) while ( true ) : ret , frame = cap . read ( ) if not ret : print ( "" leitura não bem sucedida . saindo do loop . "" ) break cv2 . imshow ( ' frame ' , frame ) if cv2 . waitkey ( <number> ) & 0 xff = = ord ( ' q ' <sad> break cap . release ( ) cv2 . destroyallwindows ( ) <url> # # # steps to reproduce # # <hashtag> the </hashtag> video shown is being accelerated import cv2 cap = cv2 . videocapture ( ' contador_pessoas / pessoas1 . mp4 ' ) while ( true ) : ret , frame = cap . read ( ) if not ret : print ( "" leitura não bem sucedida . saindo do loop . "" ) break cv2 . imshow ( ' frame ' , frame ) if cv2 . waitkey ( <number> ) & 0 xff = = ord ( ' q ' ) cap . release ( ) cv2 . destroyallwindows ( ) <url> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"resize ( ) function interface # # # system information / / for c + + user opencv version : <number> . <number> operating system / platform : windows10 compiler & compiler version : vs2017 # # # detailed description 我在使用resize时 ， 遇到问题 ， 我不确定这算不算bug . 对同一幅图片中的相同roi区域 ： 当背景区域像素值为0 、 前景区域像素值为1时 ， 我进行resize后得到结果 当背景区域像素值为0 、 前景区域像素值为255时 ， 我进行resize后得到结果 这两种结果有时差别非常大 。 我想请问 ： 这是什么原因造成的 ？ 为什么 ？ 我在resize时 ， 使用的默认的双线性插值 ( inter_linear ) # # # steps to reproduce eg src0 ; / / src0 is a image which pixel value of foreground is <number> , and pixel value of background is <number> . cv : : dst0 ; cv : : resize ( src0 , dst0 , cv : : size ( width , height ) ); cv : : mat src1 ; / / src1 is a image which pixel value of foreground is <number> , and pixel value of background is <number> . cv : : dst1 ; cv : : resize ( src1 , dst1 , cv : : size ( width , height ) ); wherein , src0 and src1 are the same image with only different pixel value of foreground at the same roi region . but , there is a big difference between dst0 and dst1 , why ? # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"about installing mediapipe i want to use the compiled opencv with cuda ( including contrib ) to install mediapipe , but it cannot be installed . it can only be successfully installed through pip ' s opencv python installation . how should we solve it .",2
opencv/opencv,"undefined symbols for architecture arm64 : "" cv : : disopticalflow : : create ( int ) "" , referenced from : . <repeated> hi , i am on mac m2 pro and try to build using opencv and got this result , is this means disopticalflow is not available for arm64 ? or i make some mistakes ? here ' s what my compile command g + + disflow . cpp - o disflow - o2 - std =c + + <number> - i / usr / local / include / opencv4 / || { echo "" compilation failed "" ; exit <number> ; } ` ` ` tia",2
opencv/opencv,"pods / opencv2_ios / opencv2 . framework / opencv2 ( opencl_kernels_calib3d . o ) , building for ios simulator , but linking in object file built for ios # # # system information opencv version : <number> . <number> operating system / platform m1 pro / ios xcode version - <number> . <number> # # # detailed description after adding opencv through pod i am getting this issue . # # # steps to reproduce create new project and add opencv dependency . pod ' opencv2 ' # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"segmentation fault in cv : : imwrite # # # system information opencv version : <number> . <number> ubuntu <number> gcc ( ubuntu <number> . <number> - 1 ubuntu1 ~ <number> . <number> ) <number> . <number> # # # detailed description here is the core dump info terminated with signal sigsegv , segmentation fault . # <number> 0x0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 f in ? <repeated> ( ) [ current thread is <number> ( thread 0x 7 f7c5719b700 ( lwp <number> ) ) ] ( gdb ) bt # <number> 0x0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 f in ? <repeated> ( ) # <number> 0x0 0 0 0 7 f7c7821329a in findencoder ( ) at / opt / vcpkg / buildtrees / opencv4 / src / <number> . <number> - 9 2 3 3 2 5 adf5 . clean / modules / imgcodecs / src / loadsave . cpp : <number> # <number> 0x0 0 0 0 7 f7c78213f1a in imwrite_ ( ) at / opt / vcpkg / buildtrees / opencv4 / src / <number> . <number> - 9 2 3 3 2 5 adf5 . clean / modules / imgcodecs / src / loadsave . cpp : <number> # <number> cv : : imwrite ( ) at / opt / vcpkg / buildtrees / opencv4 / src / <number> . <number> - 9 2 3 3 2 5 adf5 . clean / modules / imgcodecs / src / loadsave . cpp : <number> # # # steps to reproduce it ' s not easy to reproduce . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"unknown cmake command "" ocv_add_application "" # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version : gcc <number> . <number> # # # detailed description haadi <user> : ~ / opencv / apps / interactive - calibration $ cmake . cmake warning ( dev ) in cmakelists . txt : no project ( ) command is present . the top - level cmakelists . txt file must contain a literal , direct call to the project ( ) command . add a line of code such as project ( projectname ) near the top of the file , but after cmake_minimum_required ( ) . cmake is pretending there is a "" project ( project ) "" command on the first line . this warning is for project developers . use - wno - dev to suppress it . cmake error at cmakelists . txt : <number> ( ocv_add_application ) : unknown cmake command "" ocv_add_application "" . cmake warning ( dev ) in cmakelists . txt cmake_minimum_required command is present . a line of code such as cmake_minimum_required ( version <number> ) should be added at the top of the file . the version specified may be lower if you wish to support older cmake versions for this project . for more information run "" cmake - - help - policy cmp0000 "" . this warning is for project developers . use - wno - dev to suppress it . - - configuring incomplete , errors occurred see also "" / home / haadi / opencv / apps / interactive - calibration / cmakefiles / cmakeoutput . log "" . # # # steps to reproduce i am trying to use the interactive camera calibration app provided by the opencv . but when i run the cmake . inside the interactive_camera_calibration , it ' s showing the above error . please , can someone help me asap , i need to submit the work and this is an integeral part of it . i would highly appreciate any kind of help , # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"how to feed mat of <number> * <number> * <number> , cv_32fc ( <number> ) into cvdnn ? how to feed mat of 6 x224x224 , cv_32fc ( <number> ) into cvdnn ? my deep learning model input size is 1 x6x224x224 using the cv : : merge method to merge <number> mats of type cv_32fc1 , the size is 2 2 4 x224x6 , how to quickly change the data dimension to 6 x224x224",2
opencv/opencv,"cv2 videowriter generated video fail to display in html code and broswer ` ` ` # # # system information video = cv2 . videocapture ( "" . / atpsingle34yoshihitonishioka . mp4 "" ) ret , frame = video . read ( ) fps , w , h = <number> , frame . shape [ <number> ] , frame . shape [ <number> ] result = cv2 . videowriter ( ' filename . mp4 ' , cv2 . videowriter_fourcc ( * ' mp4v ' ) , fps , ( w , h ) ) while ( true ) : ret , frame = video . read ( ) if ret = = true : result . write ( frame ) cv2 . imshow ( ' frame ' , frame ) if cv2 . waitkey ( <number> ) & 0 xff = = ord ( ' s ' <sad> break # break the loop else : break # when everything done , release # the video capture and video # write objects video . release ( ) result . release ( ) # closes all the frames cv2 . destroyallwindows ( ) print ( "" the video was successfully saved "" ) ` ` ` # # # detailed description video is <url> you can download an try to put it in the browser i also try to put it in firefox , the error is no video with supported format and mime type found # # # steps to reproduce ` ` ` video = cv2 . videocapture ( "" . / atpsingle34yoshihitonishioka . mp4 "" ) ret , frame = video . read ( ) fps , w , h = <number> , frame . shape [ <number> ] , frame . shape [ <number> ] result = cv2 . videowriter ( ' filename . mp4 ' , cv2 . videowriter_fourcc ( * ' mp4v ' ) , fps , ( w , h ) ) while ( true ) : ret , frame = video . read ( ) if ret = = true : result . write ( frame ) cv2 . imshow ( ' frame ' , frame ) if cv2 . waitkey ( <number> ) & 0 xff = = ord ( ' s ' <sad> break # break the loop else # when everything done , release # the video capture and video # write objects video . release ( ) result . release ( ) # closes all the frames cv2 . destroyallwindows ( ) print ( "" the video was successfully saved "" ) ` ` `",2
opencv/opencv,"rotatedrect . getvertices ( ) sometimes gives wrong vertices # # # system information opencv version : <number> . <number> operating system / platform <number> # # # detailed description if you have two rotatedrects , one sloping left and the other sloping right , getvertices function returns the wrong order of vertices for one of them . in addition to the order of the vertices being wrong , the function jumbles up x and y coordinates of the actual vertices ( joins x coordinate of a vertex with y coordinate of another vertex , and says that ' s one vertex ) # # # steps to reproduce if you have two rotatedrects , one sloping left and the other sloping right , getvertices function returns the wrong order of vertices for one of them . in addition to the order of the vertices being wrong , the function jumbles up x and y coordinates of the actual vertices ( joins x coordinate of a vertex with y coordinate of another vertex , and says that ' s one vertex ) # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"rebuild the library with windows , gtk + <number> . x or cocoa support # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version : gcc <number> . <number> pkg - config gtk + - <number> - - modversion （ <date> ） pkg - config gtk + - <number> - - modversion （ <date> ） pkg - config gthread - <number> - - modversion （ <number> . <number> ） # # # detailed description terminate called after throwing an instance of ' cv : : exception ' what ( <sad> opencv ( <number> . <number> ) / usr / src / opencv - <number> . <number> / modules / highgui / src / window . cpp : <number> : error : ( - <number> : unspecified error ) the function is not implemented . rebuild the library with windows , gtk + <number> . x or cocoa support . if you are on ubuntu or debian , install libgtk2 . <number> - dev and pkg - config , then re - run cmake or configure script in function ' cvshowimage ' # # # steps to reproduce in opencv - <number> . <number> dir mkdir build cd build sudo cmake - d cmake_build_type = release - d cmake_install_prefix <annoyed> usr / local - d opencv_extra_modules_path <annoyed> usr / src / opencv - <number> . <number> / opencv_contrib - <number> . <number> / modules - d with_cuda = on - d enable_fast_math = <number> - d cuda_fast_math = <number> - d with_cublas = <number> - d with_cudnn = <number> - dwith_gtk = on . <repeated> sudo make - j32 sudo make install i have turned on the support for gpu and dnn modules in my compilation options , and i can compile successfully , but when i use cv : : imshow ( ) in the code , it will throw a display error , just like the error error message i provided , could you please help me to see how i can fix this problem ? thank you # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,stitching images # # # describe the feature and motivation - images not stitched sequentially . - how to stitch sequentially . - first image in right site and last image in left site stitch . - i am using this code [ stitching_detailed . cpp ] ( <url> # # # additional context _no response_,2
opencv/opencv,"mat pointsmat = mat ( points ) . reshape ( <number> ) ; and pointsmat . u = = nullptr # # # system information / / example for c + + user opencv version : <number> . <number> operating system / platform : 版本 windows <number> 专业版 版本号 2 2 h2 安装日期 ‎ <number> / ‎ <number> / ‎ <number> 操作系统内部版本 <number> 序列号 5 cd1430ktf 体验 windows feature experience pack <number> . <number> compiler & compiler version : qt6 . <number> mingw1120_64 # # # detailed description compile reference ： <url> bug is pointsmat . u = = nullptr the code from <url> void mainwindow : : on_mat_operations_clicked ( ) { qstring filename = "" <annoyed> data / lena . jpg "" ; qmessagebox : : information ( this , "" 图像读取操作 "" , "" 按任意键继续 . <repeated> "" ); { mat src = loadfromqrc ( filename ) ; imshow ( "" src "" , src ); cv : : waitkey ( ); } { mat src = loadfromqrc ( filename , imread_grayscale ) ; imshow ( "" src "" , src ); cv : : waitkey ( ); } { qmessagebox : : information ( this , "" 图像保存操作 "" , "" 按任意键继续 . <repeated> "" ); mat img ( <number> , cv_8u ) ; / / [ save image ] qstring filepath = qfiledialog : : getsavefilename ( this , tr ( "" 保存文件 "" ) , "" . "" , tr ( "" (* . png ) "" )); if ( ! filepath . isempty ( ) ) { imwrite ( filepath . tostdstring ( ) , img ) ; / / ! [ save image ] } } / / 访问像素值 { qmessagebox : : information ( this , "" 图像像素访问 "" , "" 按任意键继续 . <repeated> "" ); mat img ( <number> , cv_8u ) ;// 未初始化赋值 int y = <number> , x = <number> ; { scalar intensity = img . at <uchar> ( y , x) ; cout < < "" ( "" < < y < < "" , "" <<x< < "" ) "" < < "" point : "" < < intensity < < endl ; } { scalar intensity = img . at <uchar> ( point ( x , y ) ); cout < < "" ( "" <<x< < "" , "" < < y < < "" ) "" < < "" point : "" < < intensity < < endl ; } { vec3b intensity = img . at <vec3b> ( y , x) ; uchar blue = intensity . val [ <number> ]; uchar green = intensity . val [ <number> ]; uchar red = intensity . val [ <number> ]; /* * * 由于uchar是无符号整数类型 ， 因此我们需要使用int ( ) 函数将其转换为整型 ， 以便正确打印 */ cout < < "" ( "" < < y < < "" , "" <<x< < "" ) "" < < "" point : "" < < intensity < < "" , blue = "" < < int ( blue ) < < "" , green = "" < < int ( green ) < < "" , red = "" < < int ( red ) < < endl ; } { vec3f intensity = img . at <vec3f> ( y , x) ; float blue = intensity . val [ <number> ]; float green = intensity . val [ <number> ]; float red = intensity . val [ <number> ]; cout < < "" float : ( "" < < y < < "" , "" <<x< < "" ) "" < < "" point : "" < < intensity < < "" , blue = "" < < blue < < "" , green = "" < < green < < "" , red = "" < < red < < endl ; } { img . at <uchar> ( y , x) = <number> ; cout < < "" img . at ( <sad> ( "" < < y < < "" , "" <<x< < "" ) "" < < "" point : "" < < ( int ) img . at <uchar> ( y , x)<< endl ; } { int i = <number> ; / / 点向量集合构造mat std : : vector <point2f> points ;// 2 维点坐标 / / . <repeated> fill the array points . push_back ( cv : : point2f ( <number> . 0 f , <number> . 0 f ) ); points . push_back ( cv : : point2f ( <number> . 0 f , <number> . 0 f ) ); points . push_back ( cv : : point2f ( <number> . 0 f , <number> . 0 f ) ); mat pointsmat = mat ( points ) ; / / ! [ point access ] point2f point = pointsmat . at <point2f> ( i , <number> ); / / ! [ point access ] cout < < "" point : "" < < point < < endl ; } } / / 内存管理和引用计数 { qmessagebox : : information ( this , "" 内存管理和引用计数 "" , "" 按任意键继续 . <repeated> "" ); / / ! [ reference counting <number> ] std : : vector <point3f> points ; / / . <repeated> fill the array points . push_back ( cv : : point3f ( <number> . 0 f , <number> . 0 f , <number> . 0 f ) ); points . push_back ( cv : : point3f ( <number> . 0 f , <number> . 0 f , <number> . 0 f ) ); points . push_back ( cv : : point3f ( <number> . 0 f , <number> . 0 f , <number> . 0 f ) ); mat pointsmat = mat ( points ) . reshape ( <number> ); std : : cout < < "" pointsmat = "" < < std : : endl < < pointsmat < < std : : endl ; cout < < "" pointsmat size : "" < < pointsmat . size ( ) < < endl ; umatdata * u = pointsmat . u ; if ( u ! = nullptr ) { cout < < "" refcount : "" < < u - > refcount < < endl ; cv : : waitkey ( ); } else { cout < < "" u = = nullptr "" < < endl ;// u = = nullptr } } { / / ! [ reference counting <number> ] mat img = loadfromqrc ( filename ) ; umatdata * u = img . u ; if ( u ! = nullptr ) { cout < < "" imginit : refcount : "" < < u - > refcount < < endl ; cv : : waitkey ( ); } else { cout < < "" imginit : u = = nullptr "" < < endl ;// u = = nullptr } mat img1 = img . clone ( ); / / ! [ reference counting <number> ] u = img . u ; if ( u ! = nullptr ) { cout < < "" img : refcount : "" < < u - > refcount < < endl ; cv : : waitkey ( ); } else { cout < < "" img : u = = nullptr "" < < endl ;// u = = nullptr } u = img1 . u ; if ( u ! = nullptr ) { cout < < "" img1 : refcount : "" < < u - > refcount < < endl ; cv : : waitkey ( ); } else { cout < < "" img1 : u = = nullptr "" < < endl ;// u = = nullptr } cout < < "" img refcount : "" < < img . u - > refcount < < endl ; cout < < "" img1 refcount : "" < < img1 . u - > refcount < < endl ; cv : : waitkey ( ); } return ; { / / ! [ reference counting <number> ] mat img = imread ( "" image . jpg "" ); mat sobelx ; /* * * sobel算子边缘检测的函数 * <user> sobel */ sobel ( img , sobelx , cv_32f , <number> , <number> ); cout < < "" img refcount : "" < < img . u - > refcount < < endl ; cout < < "" img1 refcount : "" < < sobelx . u - > refcount < < endl ; cv : : waitkey ( ); } / / 基本操作 { qmessagebox : : information ( this , "" 基本操作 "" , "" 按任意键继续 . <repeated> "" ); mat img ; { / / ! [ set image to black ] img = scalar ( <number> ); imshow ( "" img "" , img ); / / ! [ set image to black ] cout < < "" blackimag "" < < endl ; cv : : waitkey ( ); } { / / ! [ select roi ] rect r ( <number> , <number> , <number> , <number> ); mat smallimg = img ( r ) ; / / ! [ select roi ] cout < < "" select roi "" < < endl ; imshow ( "" smallimg "" , smallimg ) ; cv : : waitkey ( ); } } { qmessagebox : : information ( this , "" bgr to gray "" , "" 按任意键继续 . <repeated> "" ); / / ! [ bgr to gray ] / / mat img = imread ( "" image . jpg "" ); / / loading a 8 uc3 image mat img = loadfromqrc ( filename ) ; / / loading a 8 uc3 image imshow ( "" src "" , img ) ; mat grey ; cvtcolor ( img , grey , color_bgr2gray ) ; imshow ( "" grey "" , img ) ; / / ! [ bgr to gray ] cv : : waitkey ( ); } { qmessagebox : : information ( this , "" convert to cv_32f "" , "" 按任意键继续 . <repeated> "" ); mat dst , src ; src = loadfromqrc ( filename ) ; / / ! [ convert to cv_32f ] src . convertto ( dst , cv_32f ) ; imshow ( "" src "" , src ) ; imshow ( "" dst "" , dst ) ; / / ! [ convert to cv_32f ] cv : : waitkey ( ); } / / 可视化图像 { qmessagebox : : information ( this , "" 可视化图像 "" , "" 按任意键继续 . <repeated> "" ); / / ! [ imshow <number> ] mat img = loadfromqrc ( filename ) ; namedwindow ( "" image "" , window_autosize ) ; imshow ( "" image "" , img ) ; waitkey ( ); / / ! [ imshow <number> ] } { / / ! [ imshow <number> ] mat img = loadfromqrc ( filename ) ; mat grey ; cvtcolor ( img , grey , color_bgr2gray ) ; mat sobelx ; sobel ( grey , sobelx , cv_32f , <number> , <number> ); double minval , maxval ; minmaxloc ( sobelx , & minval , & maxval ) ; / / find minimum and maximum intensities mat draw ; sobelx . convertto ( draw , cv_8u , <number> / ( maxval - minval ) , - minval * <number> / ( maxval - minval ) ); namedwindow ( "" image "" , window_autosize ) ; imshow ( "" image "" , draw ) ; waitkey ( ); / / ! [ imshow <number> ] } } / / there are debug info ( <number> ) point : [ <number> , <number> , <number> , <number> ] ( <number> ) point : [ <number> , <number> , <number> , <number> ] ( <number> ) point : [ <number> , <number> , <number> ] , blue = <number> , green = <number> , red = <number> float : ( <number> ) point : [ <number> , <number> , <number> ] , blue = <number> , green = <number> , red = <number> img . at ( <sad> ( <number> ) point : <number> point : [ <number> , <number> ] pointsmat = [ <number> , <number> , <number> ; <number> , <number> , <number> ; <number> , <number> , <number> ] pointsmat size : [ <number> x <number> ] u = = nullptr imginit : refcount : <number> img : refcount : <number> img1 : refcount : <number> img refcount : <number> img1 refcount # # # steps to reproduce i think that ' s enough information ! [ image ] ( <url> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"ann_mlp - large dataset results in stack overflow and other errors # # # system information opencv version : <number> . <number> operating system : windows <number> compiler : latest visual studio <number> # # # detailed description increasing input dataset size past certain point results in stack overflow . using provided code everything works fine with ` datasetsize ` ( line <number> ) up until <number> past which it results in stack overflow on ` train ` call . # # # steps to reproduce ` ` ` cpp <hashtag> include </hashtag> < opencv2 / core . hpp > <hashtag> include </hashtag> < opencv2 / imgcodecs . hpp > <hashtag> include </hashtag> < opencv2 / highgui . hpp > <hashtag> include </hashtag> < opencv2 / imgproc / imgproc . hpp > <hashtag> include </hashtag> < opencv2 / ml / ml . hpp > <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> <iomanip> using namespace cv ; using namespace ml ; using namespace std ; void print ( mat & mat , int prec ) { for ( int i = <number> ; i < mat . size ( ) . height ; i + + ) { cout < < "" [""; for ( int j = <number> ; j < mat . size ( ) . width ; j + + ) { cout < < fixed < < setw ( <number> ) < < setprecision ( prec ) < < mat . at <float> ( i , j ) ; if ( j = mat . size ( ) . width - <number> ) cout < < "" , "" ; else cout < < "" ] "" < < endl ; } } } int main ( ) { try { const int inputsize = <number> * <number> ; const int hiddenlayersize = inputsize * inputsize ; const int datasetsize = <number> ; float inputtrainingdataarray [ datasetsize ] [ inputsize ] ; float outputtrainingdataarray [ datasetsize ] [ <number> ]; std : : cout < < "" init \ \ n "" ; for ( int i = <number> ; i < datasetsize ; i + + ) { int value = i < datasetsize / <number> ? <number> : <number> ; for ( int j = <number> ; j < inputsize ; j + + ) inputtrainingdataarray [ i ] [ j ] = value ; if ( value ) { outputtrainingdataarray [ i ] [ <number> ] = <number> ; outputtrainingdataarray [ i ] [ <number> ] = <number> ; } else { outputtrainingdataarray [ i ] [ <number> ] = <number> ; outputtrainingdataarray [ i ] [ <number> ] = <number> ; } } std : : cout < < "" loop passed \ \ n "" ; mat inputtrainingdata = mat ( datasetsize , inputsize , cv_32f , inputtrainingdataarray ) ; mat outputtrainingdata = mat ( datasetsize , <number> , cv_32f , outputtrainingdataarray ) ; std : : cout < < "" mat \ \ n "" ; ptr <ann_mlp> mlp = ann_mlp : : create ( ); mat layerssize = mat ( <number> , <number> , cv_16u ) ; layerssize . row ( <number> ) = scalar ( inputtrainingdata . cols ) ; layerssize . row ( <number> ) = scalar ( hiddenlayersize ) ; layerssize . row ( <number> ) = scalar ( outputtrainingdata . cols ) ; mlp - > setlayersizes ( layerssize ) ; mlp - > setactivationfunction ( ann_mlp : : activationfunctions : : sigmoid_sym ) ; termcriteria termcrit = termcriteria ( / / termcriteria : : type : : count + termcriteria : : type : : eps , termcriteria : : type : : max_iter + termcriteria : : type : : eps , <number> , <number> ); mlp - > settermcriteria ( termcrit ) ; mlp - > settrainmethod ( ann_mlp : : trainingmethods : : backprop ) ; ptr <traindata> trainingdata = traindata : : create ( inputtrainingdata , sampletypes : : row_sample , outputtrainingdata ); auto start = std : : chrono : : high_resolution_clock : : now ( ); mlp - > train ( trainingdata ) ; auto stop = std : : chrono : : high_resolution_clock : : now ( ); cout < < "" elapsed : "" < < static_cast <double> ( std : : chrono : : duration_cast < std : : chrono : : microseconds > ( stop - start ) . count ( ) ) / <number> < < "" ms "" < < endl ; for ( int i = <number> ; i < inputtrainingdata . rows ; i + + ) { mat sample = mat ( <number> , inputtrainingdata . cols , cv_32f , inputtrainingdataarray [ i ] ); mat result ; mlp - > predict ( sample , result ) ; if ( i = = <number> || i = = inputtrainingdata . rows - <number> ) { cout < < inputtrainingdataarray [ i ] [ <number> ] < < "" - > "" ;// < < result < < endl ; print ( result , <number> ); cout < < endl ; } } } catch ( const std : : runtime_error & runtimeerror ) { std : : cerr < < "" runtime error : "" < < runtimeerror . what ( ) < < std : : endl ; } catch ( const std : : exception & exception ) { std : : cerr < < "" error occurred < < exception . what ( ) < < std : : endl ; } catch ( . <repeated> ) { std : : cerr < < "" unknown failure occurred . possible memory corruption "" < < std : : endl ; } return <number> ; } ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"error lnk2001 unresolved external symbol < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> . <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => : grey_question : - operating system / platform => : grey_question : - compiler => : grey_question : # # # # # detailed description ! [ d79b809b247345e62efcd346762576e ] ( <url> # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file ' ' ' ' ' ' - - > # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"undefined reference to ` pow <user> . <number> ' at arm64 # # # system information opencv version : <number> . <number> distribution : ubuntu <number> focal ( aarch64 ) compiler & compiler version : gcc <number> . <number> # # # detailed description ` ` ` / usr / bin / ld : / usr / local / opencv - <number> . <number> / lib / libopencv_imgproc . so : undefined reference to ` pow <user> . <number> ' / usr / bin / ld : / usr / local / opencv - <number> . <number> / lib / libopencv_core . so : undefined reference to ` exp <user> . <number> ' / usr / bin / ld : / usr / local / opencv - <number> . <number> / lib / libopencv_core . so : undefined reference to ` log <user> . <number> ' collect2 : error returned <number> exit status ` ` ` # # # steps to reproduce <number> . compile opencv - <number> . <number> source and install <number> . add its ' include and library to cmakelist . txt <number> . compile my project with cmake and make command <number> . try add ` lm ` to "" target_compile_options "" in cmakelists . txt but still . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"opencv build - cmake do not recognize gtk2 or gtk3 # # # # # system information ( version ) - opencv => <number> . <number> - operating system / platform => ubuntu <number> - compiler => g + + ( ubuntu <number> . <number> - 1 ubuntu1 ~ <number> . <number> ) <number> . <number> - c + + standard : <number> # # # # # detailed description i am trying to create opencv with the gtk gui . i have ` gtk2 ` and ` gtk3 ` installed on the system , but neither version is recognised by cmake . [ image ] ( <url> ! [ image ] ( <url> the output after executing cmake remains * * gui : none * * * * gtk + : no * * i execute the cmake command as follows - dpython_default_executable =$( which python3 ) - dwith_gtk = on . <repeated> / opencv ` or ` cmake - dpython_default_executable =$( which python3 ) - dwith_gtk = on - dwith_gtk_2_x = on . <repeated> / opencv ` # # # # # steps to reproduce git clone <url> mkdir - p build & & cd build cmake . <repeated> / opencv ( default , custom look above ) thank you for your help",2
opencv/opencv,"can not import cv2 : dll is missing and so on # # # system information hello , as many people , i tried to compile opencv with some options ( like cuda , gstreamer , etc . ) . my system : windows <number> laptop python <number> . <number> visual studio <number> i successfully compiled opencv <number> . <number> and <number> . <number> with cuda and gstreamer . but , when i try to import cv2 , for sure , i get an issue : dll is missing or things like that . i saw topics about that kind of errors . it seems they are quite common . as for me , i give up , after trying many things with always the same result fail . i would like to say that it is really boring to spend so many time waiting for compilation result and seeing the issue when importing cv2 . i do like opencv but it is really strange to have to compile opencv for very common extension like cuda or gsttreamer . and of course , it is also more strange to spend hour in order to always get an issue . really boring . so , i have uninstalled everything ( so i will not be able to reproduce the issue ) and i use very standard opencv version without gpu acceleration and with crappy video encode . too bad . please , try to make something more usable and more user friendly . many thanks in advance . alain # # # detailed description can not import cv2 # # # steps to reproduce just compile opencv with cuda & gstreamer and to to import cv2 with python <number> you will get the issue . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"need help to find the correct parameters for amd optimizing cpu libraries # # # # # system information ( version ) - opencv => <number> - operating system / platform => windows <number> <number> bit - compiler => visual studio <number> - cuda <number> - nvidia rtx <number> - amd ryzen <number> # # # # # detailed description hello to all , i am new to opencv and all related stuff like tbb , blas , lapack etc . i have been forced to build it from scratch in order to take advantage of all the capabilities of my cpu / gpu . although i managed to get over around for the gpu side , i am completely stuck for the cpu side , mainly because i can not find any documentation for amd cpus . i have read that for amd are recommended the [ amd optimizing cpu libraries ( aocl ) ] ( <url> but i have no idea even on how to start . i can not find even a single option variable in cmake that refers to such kind of configuration . i would really appreciate if someone could offer some help and let me know the right configuration ( cmake parameters , dependencies etc ) . thanks",2
opencv/opencv,"how to cross compile the harmonyos opencv ？ # # # descripe the feature and motivation how to cross compile the harmonyos opencv , run on harmonyos . app / . hap # # # additional context _no response_",2
opencv/opencv,"error : ‘ phase_unwrapping ’ in namespace ‘ cv ’ does not name a type < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => : grey_question : - operating system / platform => : grey_question : - compiler => : grey_question : # # # # # detailed description < ! - - your description - - > # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"opencv <number> cuda <number> vs <number> lnk2019 error # # # system information opencv version : <number> operation system : windows <number> cuda : <number> visual studio : <number> # # # detailed description getting lnk errors when using opencv with cuda : i have no issue with cuda , but when i try to add opencv with cuda i encounterd the following problem . is there something missing in my cmakelist to link it correctly ? error : lnk2019 unresolved external symbol "" void __cdecl cv : : cuda : : printcudadeviceinfo ( int ) "" ( ? printcudadeviceinfo <user> <user> @ <user> <user> ) referenced in function main thanks # # # steps to reproduce follow this setup guide for opencv <url> with version <number> vs22 and without dnn main . cpp ` ` ` <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> < opencv2 / dnn . hpp > <hashtag> include </hashtag> < opencv2 / imgproc . hpp > <hashtag> include </hashtag> < opencv2 / highgui . hpp > <hashtag> include </hashtag> < opencv2 / core . hpp > <hashtag> include </hashtag> < opencv2 / core / cuda . hpp > <hashtag> include </hashtag> < opencv2 / cudaimgproc . hpp > using namespace std ; using namespace cv ; using namespace cuda ; int main ( int , char * <wink> { printcudadeviceinfo ( <number> ); cout < < "" hello world ! \ \ n "" ; } ` ` ` cmakelists . txt ` ` ` cmake_minimum_required ( version <number> ) set ( cmake_configuration_types debug release cache type internal force ) project ( opencvtest languages c cxx cuda ) # # cuda find_package ( cudatoolkit required ) # opencv # optional opencv_dir if you want to use a custom version of opencv set ( "" opencv_dir "" "" c <annoyed> development / libs / opencv - <number> . <number> / build "" ) find_package ( opencv <number> required components core highgui ) include_directories ( ${ opencv_include_dirs } ) # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - add_executable ( opencvtest src / main . cpp ) target_link_libraries ( opencvtest $( opencv_libs ) ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"cv2 returns black image # # # system information ` ` ` python - c ' import cv2 as cv ; print ( cv . getbuildinformation ( ) ) ' general configuration for opencv <number> . <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = version control : <number> . <number> - dirty platform : timestamp : <number> - <number> - 2 9 t <time> z host : linux <number> . <number> - <number> - generic aarch64 cmake : <number> . <number> cmake generator : unix makefiles cmake build tool : / bin / gmake configuration : release cpu / hw features : baseline : neon fp16 c / c + + : built as dynamic libs ? : no c + + standard : <number> c + + compiler : / opt / rh / devtoolset - <number> / root / usr / bin / c + + ( ver <number> . <number> ) c + + flags ( release ) : - wl , - strip - all - fsigned - char - w - wall - wreturn - type - wnon - virtual - dtor - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - fvisibility = hidden - fvisibility - inlines - hidden - o3 - dndebug - dndebug c + + flags ( debug ) : - wl , - strip - all - fsigned - char - w - wall - wreturn - type - wnon - virtual - dtor - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - fvisibility = hidden - fvisibility - inlines - hidden - g - o0 - ddebug - d_debug c compiler : / opt / rh / devtoolset - <number> / root / usr / bin / cc c flags ( release ) : - wl , - strip - all - fsigned - char - w - wall - wreturn - type - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - fvisibility = hidden - o3 - dndebug - dndebug c flags ( debug ) : - wl , - strip - all - fsigned - char - w - wall - wreturn - type - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - fvisibility = hidden - g - o0 - ddebug - d_debug linker flags ( release ) : - l / ffmpeg_build / lib - wl , - - gc - sections - wl , - - as - needed - wl , - - no - undefined linker flags ( debug ) : - l / ffmpeg_build / lib - wl , - - gc - sections - wl , - - as - needed - wl , - - no - undefined ccache : yes precompiled headers : no extra dependencies : / lib64 / libopenblas . so qt5 : : core qt5 : : gui qt5 : : widgets qt5 : : test qt5 : : concurrent / usr / local / lib / libpng . so / usr / local / lib / libz . so dl m pthread rt 3 rdparty dependencies : libprotobuf ade ittnotify libjpeg - turbo libwebp libtiff libopenjp2 ilmimf quirc tegra_hal opencv modules : to be built : calib3d core dnn features2d flann gapi highgui imgcodecs imgproc ml objdetect photo python3 stitching video videoio disabled : world disabled by dependency : - unavailable : java python2 ts applications : - documentation : no non - free algorithms : no gui : qt5 qt : yes ( ver <number> . <number> ) qt opengl support : no gtk + : no vtk support : no media i / <surprise> zlib : / usr / local / lib / libz . so ( ver <date> ) jpeg : libjpeg - turbo ( ver <number> . <number> - <number> ) webp : build ( ver encoder : 0x0 2 0 f ) png : / usr / local / lib / libpng . so ( ver <date> ) tiff : build ( ver <number> - <number> . <number> ) jpeg <number> : build ( ver <number> . <number> ) openexr : build ( ver <number> . <number> ) hdr : yes sunraster : yes pxm : yes pfm : yes video i / <surprise> dc1394 : no ffmpeg : yes avcodec : yes ( <number> . <number> ) avformat : yes ( <number> . <number> ) avutil : yes ( <number> . <number> ) swscale : yes ( <date> ) avresample : no gstreamer : no v4l / v4l2 : yes ( linux / videodev2 . h ) parallel framework : pthreads trace : yes ( with intel itt ) other third - party libraries : lapack : yes ( / lib64 / libopenblas . so ) eigen : no custom hal : yes ( carotene ( ver <number> . <number> ) ) protobuf : build ( <number> . <number> ) opencl : yes ( no extra features ) include path : / io / opencv / 3 rdparty / include / opencl / <number> link libraries : dynamic load python <number> : interpreter : / opt / python / cp37 - cp37m / bin / python3 . <number> ( ver <date> ) libraries : libpython3 . 7 m . a ( ver <date> ) numpy : / home / ci / . local / lib / python3 . <number> / site - packages / numpy / core / include ( ver <number> . <number> ) install path : python / cv2 / python - <number> python ( for build ) : / bin / python2 . <number> java : ant : no jni : no java wrappers : no java tests : no install to : / io / _skbuild / linux - aarch64 - <number> / cmake - install - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ` ` ` # # # detailed description the following piece of code returns a black image on my raspi . attached is a usb webcam . ` ` ` ffmpeg - f video4linux2 - s 6 4 0 x480 - i / dev / video0 - ss 5 0 0 ms - frames <number> ffmpeg . png ` ` ` creates the correct picture though # # # steps to reproduce ` ` ` python #/ bin / python import cv2 import sys import time cam_port = <number> #/ dev / video0 cam = cv2 . videocapture ( cam_port ) time . sleep ( <number> ) outpath = sys . argv [ <number> ] if len ( sys . argv ) > <number> else "" out . png "" result , image = cam . read ( ) if result image ) ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"opencv erosion - function affecting not only edges i run the cv2 . erode function on the left image below , and get the right image as a result . as expected , the edges of the object in the right image has been eroded compared to the left . but what is not expected is that areas within the object - far from the edges - also is affected . the most obvious part is the dark vertical area in the bottom left in the image . as seen , this dark area has grown bigger in the right image , even though erosion is only supposed to affect the edges of the object . why is this happening ? ` ` ` kernel_size = <number> kernel = np . ones ( ( kernel_size , kernel_size ) , np . uint8 ) im_eroded = cv2 . erode ( im , kernel , iterations = <number> ) ` ` ` [ image ] ( <url>",2
opencv/opencv,"frequent use of cmake_install_prefix and cmake_binary_dir will cause very serious errors # # # system information opencv version ： <number> . <number> use aarach64 - musl # # # detailed description frequent use of cmake_install_prefix and cmake_binary_dir will cause very serious errors when compiling multiple files . if you want to modify it , where should you start ? # # # steps to reproduce . <repeated> # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"error : ‘ gaussianblur ’ is not a member of ‘ cv : : cuda ’ # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version : gcc <number> . <number> # # # detailed description does gaussianblur ( ) support running on gpu ？ an error was reported when i compiled ( cv : : cuda : : gaussianblur ( src , dst , cv : : size ( <number> ) , <number> ); ) error is not a member of ‘ cv : : cuda ’ # # # steps to reproduce this is my codel ： cv : : cuda : : gpumat dst , src ; src . upload ( newdensity ) ; cv : : cuda : : gaussianblur ( src , dst , cv : : size ( <number> ) , <number> ); dst . download ( densitymap ) ; # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"yolov7 produces different results for opencv - python = = <number> . <number> and onnxruntime - gpu = = <number> . <number> # # # system information opencv - python = = <number> . <number> onnxruntime - gpu = = <number> . <number> operating system / platform : windows <number> # # # detailed description hey guys , i was trying to implement yolov7 using opencvdnn in python , based on this sample : <url> after running one inference using the provided onnxruntime python script : <url> and one inference using a custom opencvdnn python script ( using the same onnx model ) : [ main_onnx_opencvdnn460 . zip ] ( <url> scores and box coordinates ( output array ) are different from one script to another . you can see down bellow the first <number> float values from each script inference : first <number> float values ( onnxruntime python script ) : <number> <number> <number> <number> <number> . 0 7 9 6 7 3 8 e - <number> <number> <number> . <phone> <number> <number> . <phone> <number> . <phone> first <number> float values ( opencvdnn python script ) : <number> <number> <number> <number> <number> . 8 9 1 6 1 e - <number> <number> <number> <number> <number> <number> i know that using two different frameworks can generate slightly different results , but in this case , this change in results generates significant changes in the confidence of the boxes generated by each model . do you have any hint on why this is happening ? thanks , césar . # # # steps to reproduce script python onnxrutime : <url> script python opencvdnn ( using readfromonnx ) : [ main_onnx_opencvdnn460 . zip ] ( <url> yolov7 model used yolov7 - tiny_256x320 . zip … ] ( ) # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"open the camera always hangs up # # # system information opencv python version : <number> . <number> operating system / platform : windows <number> python version : <date> # # # detailed description i turn on the camera and display the image through cv2 , but there is no response ： [ <number> ] ( <url> # # # steps to reproduce requirements . txt ` ` ` mediapipe = = <number> . <number> pyqt5 - tools = = <number> . <number> . <number> opencv - python = = <number> . <number> ` ` ` example . py ` ` ` # importing required libraries import cv2 import numpy as np # taking the input from webcam vid = cv2 . videocapture ( <number> ) # running while loop just to make sure that # our program keep running until we stop it while true : # capturing the current frame _ , frame = vid . read ( ) # displaying the current frame cv2 . imshow ( "" frame "" , frame ) # setting values for base colors b = frame [ :, :, : <number> ] g = frame [ :, :, <number> : <number> ] r = frame [ :, :, <number> <happy> # computing the mean b_mean = np . mean ( b ) g_mean = np . mean ( g ) r_mean = np . mean ( r ) print ( ' r { } , g { } , b { } ' . format ( r_mean , g_mean , b_mean ) ) # displaying the most prominent color if b_mean > g_mean and b_mean > r_mean : print ( "" blue "" ) if g_mean > r_mean and g_mean > b_mean : print ( "" green "" ) else ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,how to print login statment # # # descripe the feature and motivation try to print some logs but not understand how to enable logs so help me print logs print # # # additional context _no response_,2
opencv/opencv,"i build static opencv still get undefined errors # # # system information macos # # # detailed description ` ` ` showing recent messages "" _gzclose "" , referenced from < img width = "" <number> "" alt = "" image "" src = "" <url> # # # steps to reproduce build static lib and link error got # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"can not save video format as "" . mp4 "" . it seems that videowriter not support format mp4 , i can only save the video as format “ . avi ” . someone can give me some advice ?",2
opencv/opencv,"null pointer ( null window : ' tracker ' ) in cvgetmodewindow_w32 ？ # # # system information opencv version : <number> . <number> operating system / platform : win10 compiler & compiler version : vc15 # # # detailed description when i have used so method to close window ： the bug happend : opencv : terminate handler is called the last opencv error is : opencv ( <number> . <number> ) error : null pointer ( null window in cvgetmodewindow_w32 , file c :\\ build \ \ master_winpack - build - win64 - vc15 \ \ opencv \ \ modules \ \ highgui \ \ src \ \ window_w32 . cpp , line <number> but the bug is no happend in opencv <number> , just in opencv4 . <number> ! # # # steps to reproduce namedwindow ( "" test "" , window_normal ) ; videocapture capture ; capture . open ( "" test . mp4 "" ); mat frame ; while ( true ) { capture > > frame ; if ( frame . empty ( ) ) break ; / / 判断是否点击窗口关闭按钮 if ( cv : : getwindowproperty ( "" test "" , window_normal ) = = - <number> ) break ; cv : : imshow ( "" test "" , frame ) ; if ( waitkey ( <number> ) = = <number> ) break ; } # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"cv2 does not detect and decode qr - code # # # system information / / example for python user opencv python version : <number> . <number> operating system / platform : windows <number> enterprise python version : <number> . <number> # # # detailed description i try to create a qr code and decode that using cv2 . the tutorials says the exact same below but i could not reproduce the code . the problem persists for both small and large data . i looked any tutorials but any does not work . i have attached a small code for your information . thank you # # # steps to reproduce import cv2 import qrcode import matplotlib . pyplot as plt # create a qr code test = "" hello world "" qr = qrcode . qrcode ( version = none , error_correction = qrcode . constants . error_correct_l , box_size = <number> , border = <number> , ) qr . add_data ( test ) qr . make ( fit = true ) img = qr . make_image ( fill_color = "" white "" , back_color = "" black "" ) img . save ( "" test . png "" ) # plot the generated qr code im = plt . imread ( "" test . png "" ) implot = plt . imshow ( im ) # read and decode the qr code img = cv2 . imread ( "" test . png "" ) qcd = cv2 . qrcodedetector ( ) retval , decoded_info , points , straight_qrcode = qcd . detectanddecodemulti ( img ) print ( retval ) output # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"opencv c + + sample error # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version : riscv - gnu - gcc # # # detailed description i am following this tutorial for executing c + + opencv googlenet code with riscv but always get the constant error . ` root <user> <annoyed> home / anil / desktop / googlenet # riscv64 - unknown - linux - gnu - g + + main . cpp - o sone - i / home / anil / desktop / project / opencv / include / - i / home / anil / desktop / project / opencv / modules / core / include - i / home / anil / desktop / project / opencv / build / install / include / opencv4 - i / home / anil / desktop / project / opencv / modules / core / include / opencv2 - i / home / anil / desktop / project / riscv - gnu - toolchain / gdb / zlib - i / home / anil / desktop / deneme / gitdene / cnpy / - i / usr / include / mkl - l / home / anil / desktop / project / opencv / build / lib - lopencv_core - lopencv_imgcodecs - lopencv_imgproc - - static - i / home / anil / desktop / project / opencv / build / install / include / opencv4 / opencv2 / core / cuda - i / usr / local / cuda / include ` ` ` ` main . cpp : in function ' int main ( int , char * <wink> ' : main . cpp : <number> <time> : error : ' genpreprocarguments ' was not declared in this scope <number> | keys + = genpreprocarguments ( modelname , zoofile ) ; | ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ main . cpp : <number> <time> : error : ' findfile ' was not declared in this scope ; did you mean ' cv : : samples : : findfile ' ? <number> | string model = findfile ( parser . get <string> ( "" model "" )); | ^ ~ ~ ~ ~ ~ ~ ~ | cv : : samples : : findfile in file included from / home / anil / desktop / project / opencv / include / opencv2 / core . hpp : <number> , from / home / anil / desktop / project / opencv / build / install / include / opencv4 / opencv2 / dnn / dnn . hpp : <number> , from / home / anil / desktop / project / opencv / build / install / include / opencv4 / opencv2 / dnn . hpp : <number> , from main . cpp : <number> : / home / anil / desktop / project / opencv / modules / core / include / opencv2 / core / utility . hpp : <number> <time> : note : ' cv : : samples : : findfile ' declared here <number> | cv_exports_w cv : : string findfile ( const cv : : string & relative_path , bool required = true , bool silentmode = false ) ; ` ` ` is there a problem in the documentation ? # # # steps to reproduce the sample code is same with this link # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"opencv <number> . <number> cannot build # # # system information / / example for c + + user opencv version : <number> . <number> operating system / platform : debian <date> compiler & compiler version : gcc ( debian <number> . <number> - <number> ) <number> . <number> # # # detailed description i was following this link to build opencv <number> . <number> : <url> when i ran "" make - j7 "" , i got this error message in the console : . <repeated> / lnli / opencv - <number> . <number> / modules / core / src / persistence_base64 . cpp : in function ‘ bool base64 : : base64_valid ( const uint8_t * , size_t , size_t ) ’ : / usr / local / google / home / lnli / opencv - <number> . <number> / modules / core / src / persistence_base64 . cpp : <number> <time> : error the result of pointer addition ‘ ( src + ( ( sizetype ) off ) ) ’ and null [ - werror = address ] <number> | if ( src = = <number> || src + off = = <number> ) | ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ^ ~ ~ ~ # # # steps to reproduce described in the detailed description section . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"/ opencv / modules / dnn / src / dnn . cpp ( <number> ) : setupnet dnn module was not built with cuda backend ; switching to cpu # # # # # system information * * - opencv = <number> . <number> - operating system / platform => nvidia jetson orin ( tegra ) - compiler => visual studio <number> cudnn <number> and cuda <number> . * * # # # # # i have configured the opencv with cmake - gui , enabling , * * opencv_dnn_cuda , build_opencv_cuda , with_cuda , with_cudnn , with_cublas . * * i also linked ln - s / usr / local / lib / python3 / dist - packages / cv2 / python - <number> / [ cv2 . cpython - <number> - aarch64 - linux - gnu . so ] ( <url> cv2 . so the opencv test : import cv2 also works . i use this segment in my code . cout < < "" using gpu device "" < < endl ; net . setpreferablebackend ( dnn_backend_cuda ) ; net . setpreferabletarget ( dnn_target_cuda ) ; when run , it switches to cpu and compiles giving the result in <number> milliseconds . the issue is displayed as below : * *[ warn : <number> ] global / home / ubuntu / build_opencv / opencv / modules / dnn / src / dnn . cpp ( <number> ) setupnet dnn module was not built with cuda backend ; switching to cpu * * * * my directory structure is ( i cloned the opencv into my tk_ws workspace ) tk_ws / build / bin tk_ws / opencv - <number> . <number> tk_ws / opencv_contrib - <number> . <number> also , in the dnn . cpp is in the path while as per the instructions on <url> i can see the opencv_test_dnn in green i could not figure out why i am repeatedly failing . i would be immensely grateful if you could help me , please . warm regards , karishma",2
opencv/opencv,"cannot open bigtiff file # # # system information opencv version : <number> . <number> operating system : windows <number> x64 # # # detailed description i use opencv_java . jar and opencv_java . dll to work with images in java - project . error occuries when i try to open bigtiff images . * * example <number> * * : image size > <number> . 5 gb , resolution 9 4 0 1 2 x16837 pixels . > cvexception [ org . opencv . core . cvexception : cv : : exception : opencv ( <number> . <number> ) c :\\ build \ \ master_winpack - bindings - win64 - vc14 - static \ \ opencv \ \ modules \ \ imgcodecs \ \ src \ \ loadsave . cpp : <number> : error : ( - <number> : assertion failed ) pixels <= cv_io_max_image_pixels in function ' cv : : validateinputimagesize ' * * example <number> * * : image size 2 gb , resolution 6 2 6 7 5 x11224 pixels . > imread_ ( ' d :\\ temp \ \ testfiles \ \ sample_bigtif_small . tif ' <sad> can not read data : opencv ( <number> . <number> ) c :\\ build \ \ master_winpack - bindings - win64 - vc14 - static \ \ opencv \ \ modules \ \ imgcodecs \ \ src \ \ grfmt_tiff . cpp : <number> : error : ( - <number> : assertion failed ) ( ( uint64_t ) tile_width0 * tile_height0 * ncn * std : : max ( <number> , ( int ) ( bpp / bitsperbyte ) ) < max_tile_size ) & & "" tiff tile size is too large : >= 1 gb "" in function ' cv : : tiffdecoder : : readdata ' images were created in photoshop using <url> moreover i tried to load tiff files with big resolution ( 1 0 0 0 0 0 0 x12000 px ) , created in paint . net . and the same error occurred . seems like not all assertions improved in # <number> # # # steps to reproduce <number> . create simple java maven project . <number> . put opencv_java . jar into lib folder and set up as system - scope dependency <number> . put opencv_java . dll into src / main / resources / meta - inf / native / windows64 <number> . setup dependency for hawtjni - runtime : ` <dependency> <groupid> org . fusesource . hawtjni </groupid> <artifactid> hawtjni - runtime </artifactid> <version> <number> </version> </dependency> ` <number> . try to load image with this code sample : public static void main ( string [ ] args ) { library library = new library ( "" opencv_java "" , "" <number> . <number> "" , loader . class . getclassloader ( )); library . load ( ); string absolutepath = "" d :\\\\ temp \ \ \ \ testfiles \ \ \ \ sample_bigtif . tif "" ; mat mat = imgcodecs . imread ( absolutepath ) ; if ( mat . dataaddr ( ) = = <number> ) { throw new runtimeexception ( "" opencv can not load image + absolutepath ) ; } } # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"resize source code hi , i trained the neural network with resize image , and then i would like to run the same procedure in embedded mcu . i tried to implement my own resize , however , the output of my resize is always slightly different from the resize of opencv . furthermore , the resize source code in opencv is very tough to be run in embedded mcu as there is parallel and c + + feature in the code . is there any substitute resize code that outputs the same result as opencv ?",2
opencv/opencv,"videowriter libraryload load opencv_videoio_ffmpeg460_64d . dll # # # descripe the feature and motivation can i get opencv_videoio_ffmpeg460_64d . dll and opencv_videoio_ffmpeg460_64d . dll ? ( shared libraries for debugging ) thank you # # # additional context i try to create video file by videowriter but failed , information like following ( <number> ) cv : : impl : : getplugincandidates found <number> plugin ( s ) for ffmpeg opencv - <number> . <number> \ \ modules \ \ core \ \ src \ \ utils \ \ plugin_loader . impl . hpp ( <number> ) cv : : plugin : : impl : : dynamiclib : : libraryload load d :\\ develop \ \ opencv - <number> . <number> \ \ vs2017_x64 \ \ bin \ \ debug \ \ opencv_videoio_ffmpeg460_64d . dll => failed opencv - <number> . <number> \ \ modules \ \ core \ \ src \ \ utils \ \ plugin_loader . impl . hpp ( <number> ) cv : : plugin : : impl : : dynamiclib : : libraryload load opencv_videoio_ffmpeg460_64d . dll => failed opencv - <number> . <number> \ \ modules \ \ core \ \ src \ \ utils \ \ plugin_loader . impl . hpp ( <number> ) cv : : plugin : : impl : : dynamiclib : : libraryload load opencv_videoio_ffmpeg460_64 . dll => failed opencv - <number> . <number> \ \ modules \ \ videoio \ \ src \ \ backend_plugin . cpp ( <number> ) cv : : impl : : getplugincandidates found <number> plugin ( s ) for intel_mfx opencv - <number> . <number> \ \ modules \ \ core \ \ src \ \ utils \ \ plugin_loader . impl . hpp ( <number> ) cv : : plugin : : impl : : dynamiclib : : libraryload load opencv - <number> . <number> \ \ vs2017_x64 \ \ bin \ \ debug \ \ opencv_videoio_intel_mfx460_64d . dll => failed [ info : <number> <user> . <number> ] \ \ opencv - <number> . <number> \ \ modules \ \ core \ \ src \ \ utils \ \ plugin_loader . impl . hpp ( <number> ) cv : : plugin : : impl : : dynamiclib : : libraryload load opencv_videoio_intel_mfx460_64d . dll => failed",2
opencv/opencv,"about like opencv_videoio_ffmpeg450_64 . dll for ubuntu # # # descripe the feature and motivation hello when i run a demo to read video in ubuntu , i find that the demo has many dependent libraries , such as libavcodec libswscale libx264 libavformat and so on . it is very hard to put this demo to another pc because of too many dependent libraries should be copy for it . then whether has some ideas like "" opencv_videoio_ffmpeg450_64 . dll "" for windows to reduce dependent libraries for ubuntu ? i use "" sudo apt - get install libavcodec libswscale libavformat ffmpeg "" to build opencv for reading video # # # additional context _no response_",2
opencv/opencv,"opencv dnn build error # # # system information opencv version : <number> . <number> operating system / platform : ubuntu <number> compiler & compiler version : gcc <number> . <number> # # # detailed description it seems the protocol buffer headers are not compatible with mine . it builds fine if i remove "" dnn "" from - dbuild_list , but the "" libopencv_dnn . so "" was not built . how should i address the protocol buffer version difference ? what is dnn using ? ` ` ` [ <percent> ] building cxx object modules / dnn / cmakefiles / opencv_dnn . dir / misc / tensorflow / function . pb . cc . o in file included from / home / wxin / code / shared / temp / opencv / modules / dnn / misc / tensorflow / attr_value . pb . cc : <number> : / home / wxin / code / shared / temp / opencv / modules / dnn / misc / tensorflow / attr_value . pb . h : <number> : <number> : error : <hashtag> error </hashtag> this file was generated by an older version of protoc which is <number> | <hashtag> error </hashtag> this file was generated by an older version of protoc which is | ^ ~ ~ ~ ~ / home / wxin / code / shared / temp / opencv / modules / dnn / misc / tensorflow / attr_value . pb . h : <number> : <number> : error : <hashtag> error </hashtag> incompatible with your protocol buffer headers . please <number> | <hashtag> error </hashtag> incompatible with your protocol buffer headers . please | ^ ~ ~ ~ ~ / home / wxin / code / shared / temp / opencv / modules / dnn / misc / tensorflow / attr_value . pb . h : <number> : <number> : error : <hashtag> error </hashtag> regenerate this file with a newer version of protoc . ` ` ` . <repeated> . <repeated> ` ` ` / home / wxin / code / shared / temp / opencv / modules / dnn / misc / tensorflow / op_def . pb . h : <number> : <number> : error : <hashtag> error </hashtag> regenerate this file with a newer version of protoc . <number> | <hashtag> error </hashtag> regenerate this file with a newer version of protoc . | ^ ~ ~ ~ ~ in file included from / home / wxin / code / shared / temp / opencv / modules / dnn / misc / tensorflow / attr_value . pb . h : <number> , from / home / wxin / code / shared / temp / opencv / modules / dnn / misc / tensorflow / attr_value . pb . cc : <number> : / opt / 3 p / include / google / protobuf / generated_message_table_driven . h : <number> <time> : error : ‘ mapentryhelper ’ does not name a type ; did you mean ‘ mapentrylite ’ ? <number> | bool operator ( ) ( const mapentryhelper <t> & a , | ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ | mapentrylite / opt / 3 p / include / google / protobuf / generated_message_table_driven . h : <number> <time> : error ‘ , ’ or ‘ . <repeated> ’ before ‘ < ’ token <number> | bool operator ( ) ( const mapentryhelper <t> & a , | ^ ` ` ` # # # steps to reproduce git clone <email> : opencv / opencv . git mkdir build cd build / opt / 3 p / bin / cmake - dbuild_list = "" dnn "" - dcmake_prefix_path <annoyed> opt / 3 p - dcmake_install_prefix <annoyed> tmp / opencv - dcmake_build_type = release . <repeated> make - j4 install # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [ ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,import module error ! <repeated> i am using anaconda to install opencv . after success of installation in the anaconda i go to the jupyter notebook in venv created in the anaconda . in the anaconda terminal the importing is successful but in the jupyter notebook it is not successful . please se the image attached for more information . ! [ image ] ( <url>,2
opencv/opencv,"linking issues with cv : : # # # system information opencv <number> . <number> ubuntu <number> gcc + <number> # # # detailed description i have built the latest stable opencv version <number> . <number> . now i am trying to build rtabmap with that but i am having linking issues here how i built opencv4 . <number> ` ` ` cmake - d cmake_build_type = release \ \ - d cmake_install_prefix <annoyed> usr / local \ \ - d install_python_examples = off \ \ - d install_c_examples = off \ \ - d opencv_enable_nonfree = on \ \ - d opencv_extra_modules_path = ~ / opencv_contrib - <number> . <number> / modules ` ` ` # # # steps to reproduce git clone <url> cd rtabamp mkdir build cmake - dwith_depthai = on . <repeated> make - j4 ` ` ` cmakefiles / imagesjoiner . dir / main . cpp . <surprise> in function ` main ' : main . cpp <sad> . text . startup + 0x3 f5 ) : undefined reference to ` cv : : mat : : mat ( cv : : size_ <int> , int ) ' main . cpp <sad> . text . startup + 0x 5 1 8 ) : undefined reference to ` cv : : imwrite ( std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , cv : : _inputarray const & , std : : vector < int , std : : allocator <int> > const & ) ' main . cpp <sad> . text . startup + 0 xa3f ) : undefined reference to ` cv : : imread ( std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , int ) ' main . cpp <sad> . text . startup + 0 xac4 ) : undefined reference to ` cv : : imread ( std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , int ) ' collect2 : error : ld returned <number> exit status tools / imagesjoiner / cmakefiles / imagesjoiner . dir / build . make : <number> : recipe for target ' bin / rtabmap - imagesjoiner ' failed make [ <number> <sad> * * * [ bin / rtabmap - imagesjoiner ] error <number> cmakefiles / makefile <time> <number> : recipe for target ' tools / imagesjoiner / cmakefiles / imagesjoiner . dir / all ' failed make [ <number> <sad> * * * [ tools / imagesjoiner / cmakefiles / imagesjoiner . dir / all ] error <number> make [ <number> ] waiting for unfinished jobs . <repeated> ` ` ` # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"cv2 . error : opencv ( <number> . <number> ) / io / opencv / modules / imgcodecs / src / loadsave . cpp : <number> : error : ( - <number> : assertion failed ) buf . empty ( ) in function ' imdecode_ ' # # # system information * * system information * * opencv python version : <number> . <number> . operating system / platform : ubuntu <number> python version : <date> ( anaconda env ) torch version : <number> . <number> + cu113 , cuda version : <number> also , i am using linux server gpus of type tesla v100 - sxm2 # # # detailed description ` ` ` file "" train . py "" , line <number> , in <module> main ( opt ) file "" train . py "" , line <number> , in main train ( opt . hyp , opt , device , callbacks ) file "" train . py "" , line <number> , in train for i , ( imgs , targets , paths , _ ) in pbar : # batch - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / tqdm / std . py "" , line <number> , in __iter__ for obj in iterable : file "" / home / yolov5 / utils / dataloaders . py "" , line <number> , in __iter__ yield next ( self . iterator ) file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / torch / utils / data / dataloader . py "" , line <number> , in __next__ data = self . _next_data ( ) file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / torch / utils / data / dataloader . py "" , line <number> , in _next_data return self . _process_data ( data ) file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / torch / utils / data / dataloader . py "" , line <number> , in _process_data data . reraise ( ) file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / torch / _utils . py "" , line <number> , in reraise raise exception cv2 . error : caught error in dataloader worker process <number> . original traceback ( most recent call last ) : file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / torch / utils / data / _utils / worker . py "" , line <number> , in _worker_loop data = fetcher . fetch ( index ) file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / torch / utils / data / _utils / fetch . py "" , line <number> , in fetch data = [ self . dataset [ idx ] for idx in possibly_batched_index ] file "" / home / anaconda3 / envs / yolov5 / lib / python3 . <number> / site - packages / torch / utils / data / _utils / fetch . py "" , line <number> , in <listcomp> data = [ self . dataset [ idx ] for idx in possibly_batched_index ] file "" / home / yolov5 / utils / dataloaders . py "" , line <number> , in __getitem__ img , labels = self . load_mosaic ( index ) file "" / home / yolov5 / utils / dataloaders . py "" , line <number> , in load_mosaic img , _ , ( h , w ) = self . load_image ( index ) file "" / home / yolov5 / utils / dataloaders . py "" , line <number> , in load_image im = cv2 . imread ( f ) # bgr file "" / home / yolov5 / utils / general . py "" , line <number> , in imread return cv2 . imdecode ( np . fromfile ( path , np . uint8 ) , flags ) cv2 . error : opencv ( <number> . <number> ) / io / opencv / modules / imgcodecs / src / loadsave . cpp : <number> : error failed ) ! buf . empty ( ) in function ' imdecode_ ' ` ` ` # # # steps to reproduce the below command is for training a custom dataset with a well - known [ yolov5 ] ( <url> ` python - m torch . distributed . run - - nproc_per_node <number> train . py - - data data / data . yaml - - weights yolov5l6 . pt - - img <number> - - batch - size <number> - - device <number> - - rect ` to my surprise , i used the same system environment yesterday and it finished the training successfully . this is happening like in <percent> of my training attempts . # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",2
opencv/opencv,"face example error error : undefined reference to ` cv : : facedetectoryn : : create ( std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , system information ( version ) - opencv => <number> . <number> - operating system / platform => ubuntu <number> + ros - compiler => qt <number> ` ` ` <hashtag> include </hashtag> < opencv2 / dnn . hpp > <hashtag> include </hashtag> < opencv2 / imgproc . hpp > <hashtag> include </hashtag> < opencv2 / highgui . hpp > <hashtag> include </hashtag> < opencv2 / objdetect . hpp > <hashtag> include </hashtag> < opencv2 / objdetect / face . hpp > <hashtag> include </hashtag> < opencv2 / core / cvstd . hpp > <hashtag> include </hashtag> <iostream> using namespace cv ; using namespace std ; static void visualize ( mat & input , int frame , mat & faces , double fps , int thickness = <number> ) { std : : string fpsstring = cv : : format ( "" fps : % . 2 f "" , ( float ) fps ) ; if ( frame >= <number> ) cout < < "" frame "" < < frame < < "" , "" ; cout < < "" fps : "" < < fpsstring < < endl ; for ( int i = <number> ; i < faces . rows ; i + + ) { / / print results cout < < "" face "" < < i < < "" , top - left coordinates : ( "" < < faces . at <float> ( i , <number> ) < < "" , "" < < faces . at <float> ( i , <number> ) < < "" ) , "" < < "" box width : "" < < faces . at <float> ( i , <number> ) < < "" , box height : "" < < faces . at <float> ( i , <number> ) < < "" , "" < < "" score : "" < < cv : : format ( "" % . 2 f "" , faces . at <float> ( i , <number> ) ) < < endl ; / / draw bounding box rectangle ( input , rect2i ( int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) ) , scalar ( <number> , <number> , <number> ) , thickness ) ; / / draw landmarks circle ( input , point2i ( int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) ) , <number> , scalar ( <number> , <number> , <number> ) , thickness ) ; circle ( input , point2i ( int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) ) , <number> , scalar ( <number> , <number> , <number> ) , thickness ) ; circle ( input , point2i ( int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) ) , <number> , scalar ( <number> , <number> , <number> ) , thickness ) ; circle ( input , point2i ( int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) ) , <number> , scalar ( <number> , <number> , <number> ) , thickness ) ; circle ( input , point2i ( int ( faces . at <float> ( i , <number> ) ) , int ( faces . at <float> ( i , <number> ) ) ) , <number> , scalar ( <number> , <number> , <number> ) , thickness ) ; } puttext ( input , fpsstring , point ( <number> , <number> ) , font_hershey_simplex , <number> , scalar ( <number> , <number> , <number> ) , <number> ); } int main ( int argc , char * * argv ) { commandlineparser parser ( argc , argv , "" { help h | | print this message } "" "" { image1 i1 | | path to the input image1 . omit for detecting through videocapture } "" "" { image2 i2 | | path to the input image2 . when image1 and image2 parameters given then the program try to find a face on both images and runs face recognition algorithm } "" "" { video v | <number> | path to the input video } "" "" { scale sc | <number> | scale factor used to resize input video frames } "" "" { fd_model fd | face_detection_yunet_2021dec . onnx | path to the model . download yunet . onnx in <url> "" { fr_model fr | face_recognition_sface_2021dec . onnx | path to the face recognition model . download the model at <url> "" { score_threshold | <number> | filter out faces of score < score_threshold } "" "" { nms_threshold | <number> | suppress bounding boxes of iou >= nms_threshold } "" "" { top_k | <number> | keep top_k bounding boxes before nms } "" "" { save s | false | set true to save results . this flag is invalid when using camera } "" ); if ( parser . has ( "" help "" ) ) { parser . printmessage ( ); return <number> ; } cv : : string fd_modelpath = parser . get < cv : : string > ( "" fd_model "" ); cv : : string fr_modelpath = parser . get < cv : : string > ( "" fr_model "" ); float scorethreshold = parser . get <float> ( "" score_threshold "" ); float nmsthreshold = parser . get <float> ( "" nms_threshold "" ); int topk = parser . get <int> ( "" top_k "" ); bool save = parser . get <bool> ( "" save "" ); float scale = parser . get <float> ( "" scale "" ); double cosine_similar_thresh = <number> ; double l2norm_similar_thresh = <number> ; / / initialize facedetectoryn ptr <facedetectoryn> detector = facedetectoryn : : create ( fd_modelpath , "" "" , size ( <number> , <number> ) , scorethreshold , nmsthreshold , topk ) ; / / ptr <facedetectoryn> detector ; tickmeter tm ; / / if input is an image if ( parser . has ( "" image1 "" ) ) { string input1 = parser . get <string> ( "" image1 "" ); mat image1 = imread ( samples : : findfile ( input1 ) ); if ( image1 . empty ( ) ) { std : : cerr < < "" cannot read image : "" < < input1 < < std : : endl ; return <number> ; } int imagewidth = int ( image1 . cols * scale ) ; int imageheight = int ( image1 . rows * scale ) ; resize ( image1 , image1 , size ( imagewidth , imageheight ) ); tm . start ( ); / / set input size before inference detector - > setinputsize ( image1 . size ( )); mat faces1 ; detector - > detect ( image1 , faces1 ) ; if ( faces1 . rows < <number> ) { std : : cerr < < "" cannot find a face in "" < < input1 < < std : : endl ; return <number> ; } tm . stop ( ); / / draw results on the input image visualize ( image1 , - <number> , faces1 , tm . getfps ( )); / / save results if save is true if ( save ) { cout < < "" saving result . jpg . <repeated> \ \ n "" ; imwrite ( "" result . jpg "" , image1 ) ; } / / visualize results imshow ( "" image1 "" , image1 ) ; pollkey ( ); / / handle ui events to show content if ( parser . has ( "" image2 "" ) ) { string input2 = parser . get <string> ( "" image2 "" ); mat image2 = imread ( samples : : findfile ( input2 ) ); if ( image2 . empty ( ) ) { std : : cerr < < "" cannot read image2 : "" < < input2 < < std : : endl ; return <number> ; } tm . reset ( ); tm . start ( ); detector - > setinputsize ( image2 . size ( )); mat faces2 ; detector - > detect ( image2 , faces2 ) ; if ( faces2 . rows < <number> ) { std : : cerr < < "" cannot find a face in "" < < input2 < < std : : endl ; return <number> ; } tm . stop ( ); visualize ( image2 , - <number> , faces2 , tm . getfps ( )); if ( save ) { cout < < "" saving result2 . jpg . <repeated> \ \ n "" ; imwrite ( "" result2 . jpg "" , image2 ) ; } imshow ( "" image2 "" , image2 ) ; pollkey ( ); / / initialize facerecognizersf / / ptr <facerecognizersf> facerecognizer = facerecognizersf : : create ( fr_modelpath , "" "" ); ptr <facerecognizersf> facerecognizer ; / / aligning and cropping facial image through the first face of faces detected . mat aligned_face1 , aligned_face2 ; facerecognizer - > aligncrop ( image1 , faces1 . row ( <number> ) , aligned_face1 ) ; facerecognizer - > aligncrop ( image2 , faces2 . row ( <number> ) , aligned_face2 ) ; / / run feature extraction with given aligned_face mat feature1 , feature2 ; facerecognizer - > feature ( aligned_face1 , feature1 ) ; feature1 = feature1 . clone ( ); facerecognizer - > feature ( aligned_face2 , feature2 ) ; feature2 = feature2 . clone ( ); double cos_score = facerecognizer - > match ( feature1 , feature2 , facerecognizersf : : distype : : fr_cosine ) ; double l2_score = facerecognizer - > match ( feature1 , feature2 , facerecognizersf : : distype : : fr_norm_l2 ) ; if ( cos_score >= cosine_similar_thresh ) { std : : cout < < "" they have the same identity ; "" ; } else { std : : cout < < "" they have different identities ; "" ; } std : : cout < < "" cosine similarity : "" < < cos_score < < "" , threshold : "" < < cosine_similar_thresh < < "" . ( higher value means higher similarity , max <number> ) \ \ n "" ; if ( l2_score <= l2norm_similar_thresh ) { std : : cout < < "" they have the same identity ; "" ; } else { std : : cout < < "" they have different identities . "" ; } std : : cout < < "" norml2 distance : "" < < l2_score < < "" , threshold : "" < < l2norm_similar_thresh < < "" . ( lower value means higher similarity , min <number> ) \ \ n "" ; } cout < < "" press any key to exit . <repeated> "" < < endl ; waitkey ( <number> ); } / / else / / { / / int framewidth , frameheight ; / / videocapture capture ; / / std : : string video = parser . get <string> ( "" video "" ); / / if ( video . size ( ) = = <number> & & isdigit ( video [ <number> ] ) ) / / capture . open ( parser . get <int> ( "" video "" )); / / else / / capture . open ( samples : : findfileorkeep ( video ) ); / / keep gstreamer pipelines / / if ( capture . isopened ( ) ) / / { / / framewidth = int ( capture . get ( cap_prop_frame_width ) * scale ) ; / / frameheight = int ( capture . get ( cap_prop_frame_height ) * scale ) ; / / cout < < "" video "" < < video / / < < "" : width = "" < < framewidth / / < < "" , height = "" < < frameheight / / < < endl ; / / } / / else / / { / / cout < < "" could not initialize video capturing : "" < < video < < "" \ \ n "" ; / / return <number> ; / / } / / detector - > setinputsize ( size ( framewidth , frameheight ) ); / / cout < < "" press ' space ' to save frame , any other key to exit . <repeated> "" < < endl ; / / int nframe = <number> ; / / for (; <wink> / / { / / / / get frame / / mat frame ; / / if ( capture . read ( frame ) ) / / { / / cerr < < "" can not grab frame ! stop \ \ n "" ; / / break ; / / } / / resize ( frame , frame , size ( framewidth , frameheight ) ); / / / / inference / / mat faces ; / / tm . start ( ); / / detector - > detect ( frame , faces ) ; / / tm . stop ( ); / / mat result = frame . clone ( ); / / / / draw results on the input image / / visualize ( result , nframe , faces , tm . getfps ( )); / / / / visualize results / / imshow ( "" live "" , result ) ; / / int key = waitkey ( <number> ); / / bool saveframe = save ; / / if ( key = = ' ' ) / / { / / saveframe = true ; / / key = <number> ; / / handled / / } / / if ( saveframe ) / / { / / std : : string frame_name = cv : : format ( "" frame_ % 0 5 d . png "" , nframe ) ; / / std : : string result_name = cv : : format ( "" result_ % 0 5 d . jpg "" , nframe ) ; / / cout < < "" saving ' "" < < frame_name < < "" ' and ' "" < < result_name < < "" ' . <repeated> \ \ n "" ; / / imwrite ( frame_name , frame ) ; / / imwrite ( result_name , result ) ; / / } / / + + nframe ; / / if ( key > <number> ) / / break ; / / } / / cout < < "" processed "" < < nframe < < "" frames "" < < endl ; / / } cout < < "" done . "" < < endl ; return <number> ; } ` ` ` cmakelists . txt ` ` ` cmake_minimum_required ( version <number> . <number> ) set ( cmake_cxx_standard <number> ) set ( cmake_cxx_standard_required on ) project ( dog_pose ) # # compile as c + + <number> , supported in ros kinetic and newer # add_compile_options ( - std =c + + <number> ) # # find catkin macros and libraries # # if components list like find_package ( catkin required components xyz ) # # is used , also find other catkin packages find_package ( catkin required components rospy roscpp sensor_msgs <hashtag> std msgs </hashtag> pcl_ros pcl_conversions cv_bridge sensor_msgs visualization_msgs tf cmake_modules geometry_msgs pcl_msgs kdl_parser ) find_package ( boost required ) find_package ( eigen required ) find_package ( octomap required ) link_libraries ( ${ octomap_libraries } ) catkin_package ( include_dirs catkin_depends roscpp rospy orocos_kdl kdl_parser # intera_core_msgs depends system_lib ) set ( pcl_dir "" / home / zs / pcl - <number> / share / pcl - <number> "" ) find_package ( pcl <number> required ) <hashtag> find package </hashtag> ( pcl required ) include_directories ( ${ pcl_include_dirs } ) link_directories ( ${ pcl_library_dirs } ) find_package ( opencv paths / usr / local / opencv454 / lib / cmake / opencv4 ) include_directories ( include ${ catkin_include_dirs } / usr / local / opencv454 / include / opencv4 ) link_directories ( / usr / local / opencv454 / lib ) <hashtag> find package </hashtag> ( opencv <number> required ) <hashtag> set </hashtag> ( opencv_dir / usr / local / opencv455 / lib / cmake / opencv4 ) <hashtag> find package </hashtag> ( opencv required ) <hashtag> find package </hashtag> ( opencv <number> required ) <hashtag> include directories </hashtag> ($ { opencv_include_dirs } ) # # system dependencies are found with cmake ' s conventions # find_package ( boost required components system ) # # uncomment this if the package has a setup . py . this macro ensures # # modules and global scripts declared therein get installed # # see <url> # catkin_python_setup ( ) # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # declare ros messages , services and actions # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # to declare and build messages , services or actions from within this # # package , follow these steps : # # * let msg_dep_set be the set of packages whose message types you use in # # your messages / services / actions ( e . g . std_msgs , actionlib_msgs , . <repeated> ) . # # * in the file package . xml : # # * add a build_depend tag for "" message_generation "" # # * add a build_depend and a run_depend tag for each package in msg_dep_set # # * if msg_dep_set is not empty the following dependency has been pulled in # # but can be declared for certainty nonetheless : # # * add a run_depend tag for "" message_runtime "" # # * in this file ( cmakelists . txt ) : # # * add "" message_generation "" and every package in msg_dep_set to # # find_package ( catkin required components . <repeated> ) # # * add "" message_runtime "" and every package in msg_dep_set to # # catkin_package ( catkin_depends . <repeated> ) # # * uncomment the add_*_files <censored> sections below as needed # # and list every . msg / . srv / . action file to be processed # # * uncomment the generate_messages entry below # # * add every package in msg_dep_set to generate_messages ( dependencies . <repeated> ) # # generate messages in the ' msg ' folder # add_message_files ( # files # message1 . msg # message2 . msg # ) # # generate services in the ' srv ' folder # add_service_files ( # files # service1 . srv # service2 . srv # ) # # generate actions in the ' action ' folder # add_action_files ( # files # action1 . action # action2 . action # ) # # generate added messages and services with any dependencies listed here # generate_messages ( # dependencies # std_msgs # ) # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # declare ros dynamic reconfigure parameters # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # to declare and build dynamic reconfigure parameters within this # # package , follow these steps : # # * in the file package . xml : # # * add a build_depend and a run_depend tag for "" dynamic_reconfigure "" # # * in this file ( cmakelists . txt ) : # # * add "" dynamic_reconfigure "" to # # find_package ( catkin required components . <repeated> ) # # * uncomment the "" generate_dynamic_reconfigure_options "" section below # # and list every . cfg file to be processed # # generate dynamic reconfigure parameters in the ' cfg ' folder # generate_dynamic_reconfigure_options ( # cfg / dynreconf1 . cfg # cfg / dynreconf2 . cfg # ) # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # catkin specific configuration # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # the catkin_package macro generates cmake config files for your package # # declare things to be passed to dependent projects # # include_dirs : uncomment this if you package contains header files # # libraries : libraries you create in this project that dependent projects also need # # catkin_depends : catkin_packages dependent projects also need # # depends : system dependencies of this project that dependent projects also need catkin_package ( catkin_depends pcl_conversions pcl_msgs pcl_ros sensor_msgs # depends system_libcatkin_depends depends boost eigen pcl orocos_kdl kdl_parser <hashtag> kdl parser </hashtag> depends system_lib # libraries project_1 # catkin_depends rospy std_msgs # depends system_lib ) # # # # # # # # # # # # # build # # # # # # # # # # # # # # # specify additional locations of header files # # your package locations should be listed before other locations # include_directories ( include ) include_directories ( ${ catkin_include_dirs } # / home / zs / pcl_ws / src / pcl_object_tracking / project_1 / include ) # # declare a c + + library # add_library ( project_1 # src / ${ project_name } / project_1 . cpp # ) # # add cmake target dependencies of the library # # as an example , code may need to be generated before libraries # # either from message generation or dynamic reconfigure # add_dependencies ( project_1 ${ ${ project_name } _exported_targets } ${ catkin_exported_targets } ) # # declare a c + + executable # add_executable ( project_1_node src / project_1_node . cpp ) # # add cmake target dependencies of the executable # # same as for the library above # add_dependencies ( project_1_node ${ ${ project_name } _exported_targets } ${ catkin_exported_targets } ) # # specify libraries to link a library or executable target against # target_link_libraries ( project_1_node # ${ catkin_libraries } # ) # # # # # # # # # # # # # # # install # # # # # # # # # # # # # # # # all install targets should use catkin destination variables # see <url> # # mark executable scripts ( python etc . ) for installation # # in contrast to setup . py , you can choose the destination # install ( programs # scripts / my_python_script # destination ${ catkin_package_bin_destination } # ) # # mark executables and / or libraries for installation # install ( targets project_1 project_1_node # archive destination ${ catkin_package_lib_destination } # library destination ${ catkin_package_lib_destination } # runtime destination ${ catkin_package_bin_destination } # ) # # mark cpp header files for installation # install ( directory include / ${ project_name } / # destination ${ catkin_package_include_destination } # files_matching pattern "" * . h "" # pattern "" . svn "" exclude # ) # # mark other files for installation ( e . g . launch and bag files , etc . ) # install ( files # # myfile1 # # myfile2 # destination ${ catkin_package_share_destination } # ) # # # # # # # # # # # # # # # testing # # # # # # # # # # # # # # # <hashtag> add executable </hashtag> ( face_3d_pose src / face_3d_pose . cpp ) <hashtag> target link libraries </hashtag> ( face_3d_pose ${ catkin_libraries } ${ opencv_libraries } ) add_executable ( face_detection src / face_detection . cpp ) target_link_libraries ( face_detection ${ catkin_libraries } ${ opencv_libraries } / usr / local / opencv454 / lib / libopencv_highgui . so / usr / local / opencv454 / lib / libopencv_core . so / usr / local / opencv454 / lib / libopencv_imgproc . so / usr / local / opencv454 / lib / libopencv_imgcodecs . so / usr / local / opencv454 / lib / libopencv_dnn . so / usr / local / opencv454 / lib / libopencv_dnn . so ) ` ` ` error output face_detection . cpp : <number> : error reference to ` cv : : facedetectoryn : : create ( std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , std : : __cxx11 : : basic_string < char , std : : char_traits <char> , std : : allocator <char> > const & , cv : : size_ <int> const & , float , float , int , int , int ) '",2
opencv/opencv,what are the requirements for the videocapture url ? what are the requirements for the videocapture url ? <number> . <url> <number> . <url> why <number> reads null,2
opencv/opencv,"map score i am using [ ssd mobilenet v2 fpnlite 3 2 0 x320 ] to train my model . i have chest x - ray to detect covid - <number> . there <number> normal chest x - rays and <number> covid - <number> chest x - rays . i have used different augmentations to increase my normal chest - xray from <number> to <number> . and pneumonia images from <number> to <number> . i have trained my model <number> training steps , and it has training loss of <number> and evaluation loss of <number> . i am confused that i have gotten <number> map . is it a good result ? i need to compare my results with some other papers , but they have accuracy nearest <number> or <number> . there result is in accuracy and mine is in map . how am i going to compare them ? <repeated> [ image ] ( <url> another question is that most of the tensorflow object detection api has map between <number> to <number> , but mine is <number> . so is their some issue with my model or its fine ? because it is detecting and classifying most of the images accurately . please please any expert guide me regarding all of the issues i have asked .",2
opencv/opencv,"unable to build ios framework for opencv <number> . <number> # # # # # system information ( version ) - opencv => <number> . <number> - operating system / platform => mac / ios - compiler => xcode # # # # # detailed description i checked out opencv ( and contrib ) version <number> . <number> . trying to run python ` opencv / platforms / ios / build_framework . py ios ` but getting following error : ` ` ` using iphoneos_deployment_target = <number> using iphoneos archs =[ ' armv7 ' , ' armv7s ' , ' arm64 ' ] using iphonesimulator archs =[ ' i386 ' , ' x86_64 ' ] = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = error : cannot use a string pattern on a bytes - like object = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = traceback ( most recent call last ) : file "" opencv / platforms / ios / build_framework . py "" , line <number> , in build self . _build ( outdir ) file "" opencv / platforms / ios / build_framework . py "" , line <number> , in _build xcode_ver = getxcodemajor ( ) file "" opencv / platforms / ios / build_framework . py "" , line <number> , in getxcodemajor m = re . match ( r ' xcode \ \ s + ( \ \ d + ) \ \ . <repeated> *', ret , flags = re . ignorecase ) file "" / library / frameworks / python . framework / versions / <number> / lib / python3 . <number> / re . py "" , line <number> , in match return _compile ( pattern , flags ) . match ( string ) typeerror use a string pattern on a bytes - like object ` ` `",2
opencv/opencv,"problem with opencv and jupyterhub < hi everyone , i am new in python and object detection . i have followed the instruction about object detection and yolov4 [ <url> i applied everything same on colab and it was working good . however , when i change the datasource and parameter to fit to my project . i have run on jupyterhub server docker and got the problem with opencv and build darknet . [ image ] ( <url> opencv is already installed on jupyterhub . ` package version oauth2client <number> . <number> oauthlib <number> . <number> object - detection <number> opencv - python <number> . <number> opencv - python - headless <number> . <number> openpyxl <date> ` have anyone know the solution for this ? thank you so much . >",2
opencv/opencv,"why the method be finished ? # # # # # system information ( version ) - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - the api no saved in opencv <number> ? while ( <number> ) { namedwindow ( "" exit window "" , window_autosize ) ; / / 绘制窗口 imshow ( "" exit window "" , frame ) ; / / 显示当前帧 waitkey ( <number> ); / / 延时30ms if ( getwindowproperty ( "" exit window "" , wnd_prop_autosize ) = <number> ) / / 判断是否点击窗口关闭按钮 break ; }",2
opencv/opencv,"error : assertion failed ( elemsize ( ) = = sizeof ( _tp ) ) in cv : : mat : : at <pre> resized_img . convertto ( final_img , cv_32f , <number> . f / <number> ); cout < < "" image pixels are rescaled . "" < < endl ; int dims [ <number> ] = { channel , height , width }; cv : : mat mat_nchw = cv : : mat ( <number> , dims , cv_32f ) ; for ( int i = <number> ; i < height ; i + + ) { for ( int j = <number> ; j < width ; j + + ) { for ( int k = <number> ; k < channel ; k + + ) { float temp = [ final_img . at ] ( <url> j , k ) ; [ mat_nchw . at ] ( <url> i , j ) = temp ; } } } </pre> i am getting error message like this : opencv ( <number> . <number> ) error : assertion failed ( elemsize ( ) iss = = sizeof ( _tp ) ) in cv : : mat : : at , file c :\\ lib \ \ install \ \ opencv \ \ include \ \ opencv2 / core / mat . inl . hpp , line <number> exception ocurs exception i want to convert my matrix from h x w x c to c x h x w , at first i tried reshape ( ) but it ' s not working and then i have tried to construct a new matrix by positioning each element at propoer position of new matrix . although all of matrices are cv_32f in data type and i have also used float for type casting in at ( ) but still i am getting some data type mismatching error . can anyone help me with this issue ?",2
opencv/opencv,"choosing ` patternsize ` parameter in ` findchessboardcorners ` hello , quick question here on the ` patternsize ` parameter of ` findchessboardcorners ( ) ` — i need to know how to properly define the number of "" inner corner points "" along the rows , cols of a simple 2 d chessboard calibration target . here ' s one of the calibration target images i am using : [ gopr0059 ] ( <url> and how i assume the inner corner coordinates should be mapped : ! [ <number> - <number> - <number> - figure - <number> - chessboard - corners ] ( <url> resulting in a ` patternsize = ( <number> ) ` which i assume is the correct inner point count ( starting at <number> , not zero ) . however , in the opencv [ ` py_calibration . markdown ` ] ( <url> tutorial , the calibration pattern of ` patternsize = ( <number> ) ` ( but actually ` ( <number> ) ` by my logic ) has the following detected inner points which seem to only include the second - to - last corner of each square ( shown as the lower corner point in the upper - most row of black squares , but not <emphasis> the upper corner points ) . can you help clarify this in the context of my calibration pattern ? thanks !",2
opencv/opencv,"is opencv . js supports dft and dct now ? < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => <number> . <number> - operating system / platform => web ( opencv . js ) - compiler => # # # # # detailed description < ! - - your description - - > is ` opencv . js ` supports ` dft ` and ` dct ` on web now ? # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > i was using opencv . js to perform ` dft ` and ` dct ` , but it raise an exception . here is my code ` ` ` javascript let src = cv . imread ( imgelement ) ; let dst = new cv . mat ( ); let dft = new cv . mat ( ); / / to distinguish the input and output , we graying the image . / / you can try different conversions . cv . cvtcolor ( src , dst , cv . color_rgba2gray ) ; cv . dft ( dst , dft ) cv . imshow ( ' canvasoutput ' , dft ) ; src . delete ( ); dst . delete ( ); dft . delete ( ); ` ` ` ! [ image ] ( <url> # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"input size not specified in function ' processframe ' pencv - python / opencv - python / opencv / modules / dnn / src / model . cpp : <number> : error : ( - <number> : incorrect size of input array ) input size not specified in function ' processframe ' # # # # # system information ( version ) - opencv => opencv - python <number> . <number> - operating system / platform => mac os - compiler => python <date> # # # # # detailed description ` ` ` im = cv . imread ( src123 ) db_td500_resnet50 = "" . / pre - trained_models / db_td500_resnet50 . onnx "" detector = dnn . textdetectionmodel_db ( db_td500_resnet50 ) detector . setbinarythreshold ( <number> ) detector . setpolygonthreshold ( <number> ) detector . setunclipratio ( <number> ) detector . setmaxcandidates ( <number> ) detections = detector . detect ( im ) # error size of input array ) input size not specified in function ' processframe ' ` ` `",2
opencv/opencv,"how to understand the function fastx : : calcfeaturemap in chessboard . cpp ` ` ` for ( float * pout = out . ptr <float> ( <number> ) ; pout = pout_end ; + + pout ) { / / reset values rating = <number> ; count1 = <number> ; noise = <number> ; signal = <number> ; / / calc rating pend = pimages + channels ; val1 = *( pend - <number> ); / / wrap around ( last value ) wrap_around = pimages + + ; / / store for wrap around ( first value ) val2 = * wrap_around ; / / first value for ( ; pimages ! = pend ; + + pimages ) { val3 = * pimages ; if ( val1 <= val2 ) { if ( val3 < val2 ) / / maxima { if ( signal < val2 ) signal = val2 ; + + count1 ; } } else if ( val1 > val2 & & val3 >= val2 ) / / minima { if ( noise > val2 ) noise = val2 ; + + count1 ; } val1 = val2 ; val2 = val3 ; } / / wrap around if ( val1 <= val2 ) / / maxima { if ( * wrap_around < val2 ) { if ( signal < val2 ) signal = val2 ; + + count1 ; } } else if ( val1 > val2 & & * wrap_around >= val2 ) / / minima { if ( noise > val2 ) noise = val2 ; + + count1 ; } / / store rating if ( count1 = = parameters . branches ) { rating = signal - noise ; * pout = rating*rating <censored> ; / / store rating in the feature map } } ` ` ` < ! - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => : grey_question : - operating system / platform => : grey_question : - compiler => : grey_question : # # # # # detailed description < ! - - your description - - > # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"parse error . expected a command name , got unquoted argument with text ""        |"". hi , i have a question when i click the configure button on cmake - <number> . <number> . the log is as following : ` ` ` selecting windows sdk version <number> . <number> to target windows <number> . <number> . the cxx compiler identification is msvc <number> . <number> the c compiler identification is msvc <number> . <number> check for working cxx compiler : d <annoyed> vs2017_community / vc / tools / msvc / <number> . <number> / bin / hostx86 / x64 / cl . exe check for working cxx compiler : d <annoyed> vs2017_community / vc / tools / msvc / <number> . <number> / bin / hostx86 / x64 / cl . exe - - works detecting cxx compiler abi info detecting cxx compiler abi info - done detecting cxx compile features detecting cxx compile features - done check for working c compiler : d <annoyed> vs2017_community / vc / tools / msvc / <number> . <number> / bin / hostx86 / x64 / cl . exe check for working c compiler : d <annoyed> vs2017_community / vc / tools / msvc / <number> . <number> / bin / hostx86 / x64 / cl . exe - - works detecting c compiler abi info detecting c compiler abi info - done detecting c compile features detecting c compile features - done detected processor : amd64 performing test have_cxx11 ( check file : cmake / checks / cxx11 . cpp ) performing test have_cxx11 - success found pythoninterp : d <annoyed> anaconda / python . exe ( found suitable version "" <date> "" , minimum required is "" <number> "" ) cmake warning at cmake / opencvdetectpython . cmake : <number> ( message ) : cmake ' s ' find_host_package ( pythoninterp <number> ) ' found wrong python version : python_executable = d <annoyed> anaconda / python . exe python_version_string = <date> consider providing the ' python2_executable ' variable via cmake command line or environment variables call stack ( most recent call first ) : cmake / opencvdetectpython . cmake : <number> ( find_python ) cmakelists . txt : <number> ( include ) could not find python2 ( missing : python2_executable interpreter ) found pythoninterp : d <annoyed> anaconda / python . exe ( found suitable version "" <date> "" , minimum required is "" <number> "" ) found pythonlibs : d <annoyed> anaconda / libs / python39 . lib ( found suitable exact version "" <date> "" ) performing test have_cxx_fp : precise performing test have_cxx_fp : precise - success performing test have_c_fp : precise performing test have_c_fp : precise - success performing test have_cpu_sse3_support ( check file : cmake / checks / cpu_sse3 . cpp ) performing test have_cpu_sse3_support - success performing test have_cpu_ssse3_support ( check file : cmake / checks / cpu_ssse3 . cpp ) performing test have_cpu_ssse3_support - success performing test have_cpu_sse4_1_support ( check file : cmake / checks / cpu_sse41 . cpp ) performing test have_cpu_sse4_1_support - success performing test have_cpu_popcnt_support ( check file : cmake / checks / cpu_popcnt . cpp ) performing test have_cpu_popcnt_support - success performing test have_cpu_sse4_2_support ( check file : cmake / checks / cpu_sse42 . cpp ) performing test have_cpu_sse4_2_support - success performing test have_cxx_arch : avx ( check file : cmake / checks / cpu_fp16 . cpp ) performing test have_cxx_arch : avx - success performing test have_cxx_arch : avx2 ( check file : cmake / checks / cpu_avx2 . cpp ) performing test have_cxx_arch : avx2 - success performing test have_cxx_arch : avx512 ( check file : cmake / checks / cpu_avx512 . cpp ) performing test have_cxx_arch : avx512 - success performing test have_cpu_baseline_flags performing test have_cpu_baseline_flags - success performing test have_cpu_dispatch_flags_sse4_1 performing test have_cpu_dispatch_flags_sse4_1 - success performing test have_cpu_dispatch_flags_sse4_2 performing test have_cpu_dispatch_flags_sse4_2 - success performing test have_cpu_dispatch_flags_fp16 performing test have_cpu_dispatch_flags_fp16 - success performing test have_cpu_dispatch_flags_avx performing test have_cpu_dispatch_flags_avx - success performing test have_cpu_dispatch_flags_avx2 performing test have_cpu_dispatch_flags_avx2 - success performing test have_cpu_dispatch_flags_avx512_skx performing test have_cpu_dispatch_flags_avx512_skx - success performing test have_cxx_w15240 performing test have_cxx_w15240 - success performing test have_c_w15240 performing test have_c_w15240 - success looking for malloc . h looking for malloc . h - found looking for _aligned_malloc looking for _aligned_malloc - found check if the system is big endian searching <number> bit integer looking for sys / types . h looking for sys / types . h - found looking for stdint . h looking for stdint . h - found looking for stddef . h looking for stddef . h - found check size of unsigned short check size of unsigned short - done using unsigned short check if the system is big endian - little endian looking for fseeko looking for fseeko - not found check size of off64_t check size of off64_t - failed libjpeg - turbo : version = <number> . <number> , build = opencv - <number> . <number> - libjpeg - turbo check size of size_t check size of size_t - done check size of unsigned long check size of unsigned long - done looking for include file intrin . h looking for include file intrin . h - found looking for assert . h looking for assert . h - found looking for fcntl . h looking for fcntl . h - found looking for inttypes . h looking for inttypes . h - found looking for io . h looking for io . h - found looking for limits . h looking for limits . h - found looking for memory . h looking for memory . h - found looking for search . h looking for search . h - found looking for string . h looking for string . h - found performing test c_has_inline performing test c_has_inline - success check size of signed short check size of signed short - done check size of unsigned short check size of unsigned short - done check size of signed int check size of signed int - done check size of unsigned int check size of unsigned int - done check size of signed long check size of signed long - done check size of signed long long check size of signed long long - done check size of unsigned long long check size of unsigned long long - done check size of unsigned char * check size of unsigned char * - done check size of ptrdiff_t check size of ptrdiff_t - done looking for memmove looking for memmove - not found looking for setmode looking for setmode - found looking for strcasecmp looking for strcasecmp - not found looking for strchr looking for strchr - found looking for strrchr looking for strrchr - found looking for strstr looking for strstr - found looking for strtol looking for strtol - found looking for strtol looking for strtol - found looking for strtoull looking for strtoull - found looking for lfind looking for lfind - found performing test have_snprintf performing test have_snprintf - success check if the system is big endian searching <number> bit integer using unsigned short check if the system is big endian - little endian performing test have_c_std_c99 performing test have_c_std_c99 - failed could not find openjpeg ( minimal suitable version : <number> , recommended version >= <number> . <number> ) . openjpeg will be built from sources openjpeg : version = <number> . <number> , build = opencv - <number> . <number> - openjp2 - <number> . <number> check if the system is big endian searching <number> bit integer using unsigned short check if the system is big endian - little endian looking for stdlib . h looking for stdlib . h - found looking for stdio . h looking for stdio . h - found looking for math . h looking for math . h - found looking for float . h looking for float . h - found looking for time . h looking for time . h - found looking for stdarg . h looking for stdarg . h - found looking for ctype . h looking for ctype . h - found looking for stdint . h looking for stdint . h - found looking for inttypes . h looking for inttypes . h - found looking for strings . h looking for strings . h - not found looking for sys / stat . h looking for sys / stat . h - found looking for unistd . h looking for unistd . h - not found looking for include file malloc . h looking for include file malloc . h - found looking for _aligned_malloc looking for _aligned_malloc - found looking for posix_memalign looking for posix_memalign - not found looking for memalign looking for memalign - not found openjpeg libraries will be built from sources : libopenjp2 ( version "" <number> . <number> "" ) cmake error at 3 rdparty / ippicv / ippicv . cmake : <number> : parse error . expected a command name , got unquoted argument with text ""        |"". call stack ( most recent call first ) ( include ) cmake / opencvfindlibsperf . cmake : <number> ( include ) cmakelists . txt : <number> ( include ) configuring incomplete , errors occurred see also "" d <annoyed> opencv - <number> . <number> / opencv / cpu_build / cmakefiles / cmakeoutput . log "" . see also "" d <annoyed> opencv - <number> . <number> / opencv / cpu_build / cmakefiles / cmakeerror . log "" . ` ` ` please help me , thank you very much !",2
opencv/opencv,"error : null pointer ( null window : ' test program ' ) in cvgetpropwindowautosize_w32 # # # # # system information ( version ) - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> # # # # # detailed description when i take windowpropertyflags that no work after opencv <number> , but is normal work in opencv4 . <number> . tips : error : null pointer ( null window : ' test program ' ) in cvgetpropwindowautosize_w32 example code <hashtag> include </hashtag> < opencv2 / opencv . hpp > <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> < opencv2 / highgui / highgui_c . h > using namespace cv ; using namespace std ; int main ( ) { videocapture capture ( <number> ); while ( <number> ) { mat frame ; capture > > frame ; if ( frame . empty ( ) ) break ; namedwindow ( "" test program "" , window_autosize ) ; imshow ( "" test program "" , frame ) ; waitkey ( <number> ); if ( getwindowproperty ( "" test program "" , wnd_prop_autosize ) = <number> ) break ; } capture . release ( ); destroyallwindows ( ); return <number> ; } ` ` `",2
opencv/opencv,"why do not rectangle box in opencv4 . <number> ? - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - opencv => : grey_question : # # # # # detailed description i just try inference yolov5s . onnx by opencv4 . <number> , but the opencv <number> do not rectangle box ? but the opencv <number> . <number> is normal . that is inference api have changed about opencv4 . <number> ? this is infer code exp",2
opencv/opencv,"< class ' cv2 . videocapture ' > returned a result with an error set and my camera and videos can not be read import cv2 cv2 . namedwindow ( ' video ' , cv2 . window_normal ) cv2 . resizewindow ( ' video ' , <number> , <number> ) cap = cv2 . videocapture ( <number> ) while true : ret , frame = cap . read ( ) cv2 . imshow ( ' video ' , frame ) key = cv2 . waitkey ( <number> ) if key & 0 xff = = ord ( ' q ' <sad> print ( ' 退出成功 ' ) break cap . read ( ) cv2 . destroyallwindows ( ) my code is above and the error shows as follows : d :\\ python \ \ anaconda \ \ envs \ \ opencv \ \ python . exe c <annoyed> users / yyl47 / desktop / pythonproject / test . py cv2 . error : invalid stoull argument the above exception was the direct cause of the following exception : traceback ( most recent call last ) : file "" c :\\ users \ \ yyl47 \ \ desktop \ \ pythonproject \ \ test . py "" , line <number> , in <module> cap = cv2 . videocapture ( <number> ) systemerror ' cv2 . videocapture ' > returned a result with an error set process finished with exit code <number> anyone can help me ? my python version is <number> , the operating system is windows10 and it is a laptop , the camera works well in other app .",2
opencv/opencv,"where are the build instructions for opencv <number> sorry , i tried signing up to <url> to ask this question but did not receive an activation email . sorry again , if this is a stupid question but i cannot find any build instructions for opencv <number> . could someone advise please ? marc",2
opencv/opencv,"cv : : norm ( . <repeated> , . <repeated> , cv : : norm_l2sqr ) is 1 0 x slower than calling cv : : norml2sqr ( . <repeated> ) used version : opencv <number> . <number> and opencv <number> . <number> calling cv : : norm is 1 0 x slower than calling cv : : norml2sqr directly . i tested measured the time with <number> million float vectors with <number> dimensions . cv : : norml2sqr : 3 0 8 ms cv : : norm : 3 0 9 2 ms im wondering how there can be such an performance loss . there is also no avx optimization in opencv for cv : : norm , but i found some implementations <url> maybe somebody with avx knowledge wants to take this over ?",2
opencv/opencv,( roi & image_roi ) . empty ( ) in function error ! [ image ] ( <url> now i am having this error while making opencv kcf_tracker . any help plz ?,2
opencv/opencv,"no codec available in video i / o . < - - # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => <number> . <number> & & <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> # # # # # detailed description hi , i am trying to save video with ` cv : : videowriter ` on either windows and unix system . everything is working fine except for one particular computer ( win10 , the two other windows computer are ok ) where no codecs or apipreference are working ( ` bool cv : : videowriter : : open ( . <repeated> ) ` outputs ` false ` for every combination , on opencv <number> . <number> ) . so i tried to rebuild opencv <number> and it outputs a weird message saying that no video i / o is available . <repeated> i [ cmake_output . txt ] ( <url> ` ` ` media i / <surprise> zlib : build ( ver <date> ) jpeg : build - libjpeg - turbo ( ver <number> . <number> - <number> ) webp : build ( ver encoder : 0x0 2 0 f ) png : build ( ver <date> ) tiff : build ( ver <number> - <number> . <number> ) jpeg <number> : build ( ver <number> . <number> ) openexr : build ( ver <number> . <number> ) hdr : yes sunraster : yes pxm : yes pfm : yes video i / <surprise> dc1394 : no ffmpeg : no avcodec : no avformat : no avutil : no swscale : no avresample : no gstreamer : no directshow : no media foundation : no dxva : no ` ` ` i retried the same steps on two others windows computer , and they show yes to everything ( except dc1394 ) . can you help me to understand why opencv cannot detect directshow and what ' s wrong with my setup ( i assume it ' s here natively on a windows computer ) ? thanks ! # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > ` cmake - gui ` # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [x ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [x ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"cannot choose which qt to use as the title says . with qt5 alone installed opencv - <number> . <number> compiles just fine finding what it needs for qt5 . however with qt5 and <number> installed the configuration stage defaults to qt6 . i have not seen a way in the scripts to jiggle things back to using qt5 . obviously my issue is telling opencv which qt i want it to use . i have qt5 installed in / usr / include / qt5 , / usr / lib / qt5 , etc and qt6 installed in / usr / lib / qt6 and / usr / include / qt6 , etc , that is they all live in their own areas . looking at # <number> , # <number> and a few others they do not appear to take in account the ability to choose . choice would be appreciated . btw , in my case since it picks up qt6 instead , the compile fails here ; [ <percent> ] building cxx object modules / calib3d / cmakefiles / opencv_calib3d . dir / undistort . avx2 . cpp . o [ <percent> ] linking cxx shared library . <repeated> / . <repeated> / lib / libopencv_calib3d . so [ <percent> ] built target opencv_calib3d [ <percent> ] automatic moc for target opencv_cvv [ <percent> ] built target opencv_cvv_autogen [ <percent> ] building cxx object modules / cvv / cmakefiles / opencv_cvv . dir / opencv_cvv_autogen / mocs_compilation . cpp . o in file included from / usr / src / opencv - <number> . <number> / opencv - oosb / modules / cvv / opencv_cvv_autogen / mxuweoxilk / moc_call_tab . cpp : <number> , from / usr / src / opencv - <number> . <number> / opencv - oosb / modules / cvv / opencv_cvv_autogen / mocs_compilation . cpp : <number> : / usr / src / opencv - <number> . <number> / opencv - oosb / modules / cvv / opencv_cvv_autogen / mxuweoxilk / . <repeated> / . <repeated> / . <repeated> / . <repeated> / . <repeated> / opencv_contrib - <number> . <number> / modules / cvv / src / gui / call_tab . hpp : <time> : fatal error : qstring : no such file or directory <number> | <hashtag> include </hashtag> <qstring> | ^ ~ ~ ~ ~ ~ ~ ~ ~ compilation terminated . make [ <number> <sad> * * * [ modules / cvv / cmakefiles / opencv_cvv . dir / build . make : <number> : modules / cvv / cmakefiles / opencv_cvv . dir / opencv_cvv_autogen / mocs_compilation . cpp . o ] error <number> make [ <number> <sad> * * * [ cmakefiles / makefile <time> <number> : modules / cvv / cmakefiles / opencv_cvv . dir / all ] error <number> make : * * * [ makefile : <number> error <number>",2
opencv/opencv,"how can i put opencv - tracker in yolov5 ? hi . i have to put opencv - tracker ( maybe kcf ) in yolov5 . um , if you have used opencv - tracker before , you know about this . i do not want to selectroi with my mouse . i just want to put detected bbox coordinates from detect . py and i want to track every frames in video . [ image ] ( <url> so this is my code ( this is plots . py ) i am having error argument ) one or more matrix operands are empty . in function ' checkoperandsexist ' error . plz help me . i want how to wirte the code .",2
opencv/opencv,"typeerror : imwrite ( ) takes <number> positional arguments but <number> were given < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < - - example - opencv => <number> . <number> - operating system / platform => docker ( ubuntu <number> ) - compiler => gcc <number> . <number> - python <number> . <number> - - > # # # # # detailed description i am trying to save jpg image with quality <number> by opencv . here is the python script i tried : ` cv2 . imwrite ( isdocker . docker_prefix + im . path + im . name , im . data , [ ( int ( cv2 . imwrite_jpeg_quality ) , <number> ) ] ) ` it pops up with an error ' typeerror takes <number> positional arguments but <number> were given ' . i know a similar post in [ [ here ] ( <url> but i think its different issue . i have read the [ documentation ] ( <url> from opencv and it seems you have changed something . please help me .",2
opencv/opencv,"when i use libopencv_java3 . so in android projetc , and run android <number> phone ， phone crashes automatically after <number> seconds i use android ndk cross - platform call c + + ， use ` ` ` cv : : gaussianblur ( images . fimorig , fimseg , cv : : size ( <number> , <number> ) , <number> , <number> , <number> ); ` ` ` phone crashes automatically after <number> seconds i do not reason ， can you help me why ?",2
opencv/opencv,"usb设备 ： 不能打开设备 ， 请检查设备是否安装 。 <kiss> <number> , y : <number> usb设备 ： 不能打开设备 ， 请检查设备是否安装 。 <kiss> <number> , y : <number>",2
opencv/opencv,opencv was ist die unterschied zwischen opencv und openai,2
opencv/opencv,"how to convert a cv : : mat to ffmpeg avframe ? < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => : grey_question : - operating system / platform => : grey_question : - compiler => : grey_question : # # # # # detailed description < ! - - your description - - > # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"how to remove distortion in opencv . js < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => : grey_question : - operating system / platform => : grey_question : - compiler => : grey_question : # # # # # detailed description < ! - - your description - - > # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"multiple values appear when binary images are imwrite as jpg < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > - opencv - python => <number> . <number> - operating system / platform => windows <number> bit - python version : <date> # # # # # detailed description i binarized an image and saved it as jpg . when i re - read the image , there are more than two values . png images do not have this problem . # # # # # steps to reproduce ` ` ` python img_path = r "" temp . tif "" png_path = r "" temp . png "" jpg_path = r "" temp . jpg "" ` ` ` ` ` ` python gray = cv2 . imread ( img_path , cv2 . imread_grayscale ) print ( "" gray shape : { } , values : { } "" . format ( gray . shape , np . unique ( gray ) ) ) ` ` ` output : gray shape : ( <number> , <number> ) , values : [ <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> ] ` ` ` python _ , thresh = cv2 . threshold ( gray , <number> , <number> , cv2 . thresh_binary ) print ( "" thresh shape : { } , values : { } "" . format ( thresh . shape , np . unique ( thresh ) ) ) cv2 . imwrite ( jpg_path , thresh ) cv2 . imwrite ( png_path , thresh ) jpg = cv2 . imread ( jpg_path , cv2 . imread_unchanged ) png = cv2 . imread ( png_path , cv2 . imread_unchanged ) print ( "" jpg shape : { } , values : { } "" . format ( jpg . shape , np . unique ( jpg ) ) ) print ( "" png shape : { } , values : { } "" . format ( png . shape , np . unique ( png ) ) ) ` ` ` output : thresh shape : ( <number> , <number> ) , values : [ <number> <number> ] jpg shape : ( <number> , <number> ) , values : [ <number> * * <number> <number> <number> <number> <number> <number> <number> <number> <number> <number> * * <number> ] png shape : ( <number> , <number> ) , values : [ <number> <number> ] # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution this is where i found a similar problem on stackoverflow : python - saving and reading binary image - stack overflow : < <url> < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [x ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [x ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"[ <percent> ] built target opencv_cudaarithm make : * * * [ makefile : <number> : all ] error <number> in ubantu20 . <number> cuda <number> cudnn <number> . <number> hi : when i install opencv <number> . <number> on ubuntu20 . <number> with gpu . but i get some error . determining if the include file sys / videoio . h exists failed with the following output : ` ` ` change dir : / home / anthony / downloads / opencvgpu / opencv / build / cmakefiles / cmaketmp run build command ( s ) <annoyed> usr / bin / make - f makefile cmtc_17c3f / fast & & / usr / bin / make - f cmakefiles / cmtc_17c3f . dir / build . make cmakefiles / cmtc_17c3f . dir / build make [ <number> <sad> entering directory ' / home / anthony / downloads / opencvgpu / opencv / build / cmakefiles / cmaketmp ' building c object cmakefiles / cmtc_17c3f . dir / checkincludefile . c . o / usr / bin / cc - fsigned - char - ffast - math - w - wall - wreturn - type - waddress - wsequence - point - wformat - wformat - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - fopenmp - o3 - dndebug - dndebug - fpie - o cmakefiles / cmtc_17c3f . dir / checkincludefile . c . o - c / home / anthony / downloads / opencvgpu / opencv / build / cmakefiles / cmaketmp / checkincludefile . c in file included from / home / anthony / downloads / opencvgpu / opencv / build / cmakefiles / cmaketmp / checkincludefile . c : <number> : <number> : / usr / include / sys / videoio . h : <number> <time> : fatal error : opencv2 / core / core_c . h : no such file or directory <hashtag> include </hashtag> "" opencv2 / core / core_c . h "" ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ compilation terminated . make [ <number> <sad> * * * [ cmakefiles / cmtc_17c3f . dir / build . make : <number> : cmakefiles / cmtc_17c3f . dir / checkincludefile . c . o ] error <number> make [ <number> <sad> leaving directory ' / home / anthony / downloads / opencvgpu / opencv / build / cmakefiles / cmaketmp ' make : * * * [ makefile : <number> : cmtc_17c3f / fast ] error <number> when i made it , error is <percent> ] linking cxx shared library . <repeated> / . <repeated> / lib / libopencv_cudawarping . so [ <percent> ] built target opencv_cudawarping [ <percent> ] building cxx object modules / cudaarithm / cmakefiles / opencv_cudaarithm . dir / src / arithm . cpp . o [ <percent> ] building cxx object modules / cudaarithm / cmakefiles / opencv_cudaarithm . dir / src / core . cpp . o [ <percent> ] building cxx object modules / cudaarithm / cmakefiles / opencv_cudaarithm . dir / src / element_operations . cpp . o [ <percent> ] building cxx object modules / cudaarithm / cmakefiles / opencv_cudaarithm . dir / src / lut . cpp . o [ <percent> ] building cxx object modules / cudaarithm / cmakefiles / opencv_cudaarithm . dir / src / reductions . cpp . o [ <percent> ] linking cxx shared library . <repeated> / . <repeated> / lib / libopencv_cudaarithm . so [ <percent> ] built target opencv_cudaarithm make : * * * [ makefile : <number> error <number> ` ` `",2
opencv/opencv,"what is the difference between "" import cv2 "" and "" import cv2 . cv2 "" i have two questions . one : the difference between ` import cv2 ` and ` import cv2 . cv2 ` the other : cv2 . error : opencv ( <number> . <number> ) c :\\ users \ \ appveyor \ \ appdata \ \ local \ \ temp \ \ <number> \ \ pip - req - build - memyuvq3 \ \ opencv \ \ modules \ \ highgui \ \ src \ \ window . cpp : <number> : error error ) the function is not implemented . rebuild the library with windows , gtk + <number> . x or cocoa support . if you are on ubuntu or debian , install libgtk2 . <number> - dev and pkg - config , then re - run cmake or configure script in function ' cvshowimage ' in response to question <number> , i have installed opencv - python and opencv - contrib - python",2
opencv/opencv,"python warped prespective - opencv => <number> . <number> - operating system / platform => windows <number> bit - compiler => pycharm <number> . <number> # # # # # detailed description i need to implement a warp perspective , and the following error happens : traceback ( most recent call last ) : file "" c <annoyed> users / diogo alpendre / onedrive - ipleiria / para arrumar / documentos / github / t22_ad_detection / perspective transormation . py "" , line <number> , in <module> result = cv2 . warpperspective ( frame , pts1 , ( <number> , <number> ) ) cv2 . error : opencv ( <number> . <number> ) c :\\ ci \ \ opencv - suite_1573470242804 \ \ work \ \ modules \ \ imgproc \ \ src \ \ imgwarp . cpp : <number> : error : ( - <number> : assertion failed ) ( m0 . type ( ) = = cv_32f || m0 . type ( ) = = cv_64f ) & & m0 . rows = = <number> & & m0 . cols = = <number> in function ' cv : : warpperspective ' [ warn : <number> ] terminating async callback process finished with exit code <number> # # # # # steps to reproduce < - - my code import cv2 import numpy as np # turn on laptop ' s webcam cap = cv2 . videocapture ( <number> ) width = cap . get ( cv2 . cap_prop_frame_width ) height = cap . get ( cv2 . cap_prop_frame_height ) print ( width , height ) while true : ret , frame = cap . read ( ) # locate points of the documents # or object which you want to transform pts1 = np . float32 ( [ [ <number> , <number> ] , [ <number> , <number> ] , [ <number> , <number> ] , [ <number> , <number> ] ] ) pts2 = np . float32 ( [ [ <number> , <number> ] , [ <number> , <number> ] , [ <number> , <number> ] , [ <number> , <number> ] ] ) # apply perspective transform algorithm matrix = cv2 . getperspectivetransform ( pts1 , pts2 ) result = cv2 . warpperspective ( frame , pts1 , ( <number> , <number> ) ) cv2 . imshow ( ' frame ' , frame ) # initial capture cv2 . imshow ( ' frame1 ' , result ) # transformed capture if cv2 . waitkey ( <number> ) = = <number> cap . release ( ) cv2 . destroyallwindows ( ) - - >",2
opencv/opencv,"libopencv_core . a ( matrix . cpp . o ) is referenced by dso ? - opencv => <number> - operating system / platform => linux <number> bit - compiler => cmake # # # # # detailed description < - - your description - - > # # # # # i build opencv by staticly and install it to / usr / local / opencv_aarch64 ( for cross compile ) , but when i build my project , it report : [ <percent> ] linking cxx executable snpe - sample2 / usr / lib / gcc - cross / aarch64 - linux - gnu / <number> / . <repeated> / . <repeated> / . <repeated> / . <repeated> / aarch64 - linux - gnu / bin / ld : snpe - sample2 : hidden symbol ` _zn2cv3matc1eiii ' in / home / white / build_aarch64 / install / lib / libopencv_core . a ( matrix . cpp . o ) is referenced by dso / usr / lib / gcc - cross / aarch64 - linux - gnu / <number> / . <repeated> / . <repeated> / . <repeated> / . <repeated> / aarch64 - linux - gnu / bin / ld : 最后的链结失败 : 错误的值 collect2 : error : ld returned <number> exit status cmakefiles / snpe - sample2 . dir / build . make : <number> : recipe for target ' snpe - sample2 ' failed make [ <number> <sad> * * * [ snpe - sample2 ] error <number> cmakefiles / makefile <time> <number> : recipe for target ' cmakefiles / snpe - sample2 . dir / all ' failed make [ <number> <sad> * * * [ cmakefiles / snpe - sample2 . dir / all ] error <number> makefile : <number> : recipe for target ' all ' failed make [ all ] error <number> all thing is right , but linking is wrong , and when i re - build opencv to shared libs , it ' s nothing happend , however , i do not want to use shared libs how should i do ?",2
opencv/opencv,"how to contriube opencv if the algorithm needs gram - shmidt process ? hey , i want to contribute an algorithm to the library . i just read that i can not use extra dependencies . do i have to write all the math operations from scratch ( like gram - shmidt and so on ) for the algorithm ? thanks .",2
opencv/opencv,"videocapture hardware acceleration seem not working hi am using ubuntu and trying to use the hardware acceleration in my python code of video capture . i had compiled a opencv <number> . <number> ensuring cuda is on . cap = cv2 . videocapture ( < rtsp address > , cv2 . cap_ffmpeg , ( cv2 . cap_prop_hw_acceleration , cv2 . video_acceleration_any ) ) however , when i do a nvidia - smi dmon command , i noted that the nvdec is not processing anything . it works well for command line e . g . ffmpeg - hwaccel . <repeated> may i check is there any working example that i can refer to in ubuntu environment ? thank you",2
opencv/opencv,error : cannot declare variable ‘ dflow ’ to be of abstract type ‘ cv : : cuda : : farnebackopticalflow ’ cv : : cuda : : farnebackopticalflow dflow ; opencv version3 . <number> ` ` ` / / create the optical flow object cv : : cuda : : farnebackopticalflow dflow ; dflow . numlevels = numlevels ; dflow . pyrscale = pyrscale ; dflow . fastpyramids = fastpyramids ; dflow . winsize = winsize ; dflow . numiters = numiters ; dflow . polyn = polyn ; dflow . polysigma = polysigma ; ` ` ` error declare variable ‘ dflow ’ to be of abstract type ‘ cv : : cuda : : farnebackopticalflow ’ cv : : cuda : : farnebackopticalflow dflow ;,2
opencv/opencv,building opencv . js from : ` git clone <url> when i build with : ` python3 . / opencv / platforms / js / build_js . py . / build_wasm - - build_wasm ` it generates opencv . js but i must replace in the latest lines : ` ` ` return cv . ready } ` ` ` by return cv } ` ` ` to use it . what is wrong ?,2
opencv/opencv,"cv : : dnn : : dnn_backend_cuda is not supporting error . - opencv => <number> . <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> # # # # # detailed description i have built opencv with cuda enabled successfully , and works well , but when i am using cuda with dnn model , it throws the following error : > the error : opencv ( <number> . <number> - dev ) d :\\ opencv \ \ opencv \ \ modules \ \ dnn \ \ src \ \ dnn . cpp : <number> : error : ( - <number> : the function / feature is not implemented ) layer "" detection_out "" of type "" "" unsupported on opencv backend in function ' cv : : dnn : : dnn4_v20211220 : : net : : impl : : forwardlayer ' code cv : : dnn : : net net = cv : : dnn : : net : : readfrommodeloptimizer ( xml , bin ) ; / / or / / cv : : dnn : : net net = cv : : dnn : : readnet ( bin , xml ) ; / / this is working / / net . setpreferablebackend ( cv : : dnn : : dnn_backend_inference_engine ) ; / / net . setpreferabletarget ( cv : : dnn : : dnn_target_opencl ) ; / / this is not working net . setpreferablebackend ( cv : : dnn : : dnn_backend_cuda ) ; net . setpreferabletarget ( cv : : dnn : : dnn_target_cuda ) ; ` ` `",2
opencv/opencv,"build opencv for ios in mac environment : - opencv => <number> . x - operating system / platform => mac monterey ( <number> ) - compiler => xcode <number> - python <number> . <number> fllowing the document , when execute command "" python opencv / platform / ios / build_framework . py build_ios "" , error occur ! error log : compilec / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / objects - normal / armv7 / tokenizer . o / users / xuhx3 / lenovo / opencv_env / opencv / 3 rdparty / protobuf / src / google / protobuf / io / tokenizer . cc normal armv7 c + + com . apple . compilers . llvm . clang . 1 _0 . compiler ( in target ' libprotobuf ' from project ' opencv ' ) cd / users / xuhx3 / lenovo / opencv_env / opencv export lang \ \ = en_us . us - ascii / applications / xcode . app / contents / developer / toolchains / xcodedefault . xctoolchain / usr / bin / clang - x c + + - target armv7 - apple - ios8 . <number> - fmessage - length \ \= <number> - fdiagnostics - show - note - include - stack - fmacro - backtrace - limit \ \= <number> - fcolor - diagnostics - wno - trigraphs - fpascal - strings - o3 - wno - missing - field - initializers - wno - missing - prototypes - wno - return - type - wno - non - virtual - dtor - wno - overloaded - virtual - wno - exit - time - destructors - wno - missing - braces - wparentheses - wswitch - wno - unused - function - wno - unused - label - wno - unused - parameter - wno - unused - variable - wunused - value - wno - empty - body - wno - uninitialized - wno - unknown - pragmas - wno - shadow - wno - four - char - constants - wno - conversion - wno - constant - conversion - wno - int - conversion - wno - bool - conversion - wno - enum - conversion - wno - float - conversion - wno - non - literal - null - conversion - wno - objc - literal - conversion - wno - shorten - <number> - to - <number> - wno - newline - eof - wno - c + + <number> - extensions - dcmake_intdir \ \= \ \ "" release - iphoneos \ \ "" - dhave_pthread \ \= <number> - isysroot / applications / xcode . app / contents / developer / platforms / iphoneos . platform / developer / sdks / iphoneos15 . <number> . sdk - fstrict - aliasing - wdeprecated - declarations - winvalid - offsetof - wno - sign - conversion - wno - infinite - recursion - wno - move - wno - comma - wno - block - capture - autoreleasing - wno - strict - prototypes - wno - range - loop - analysis - wno - semicolon - before - method - body - fembed - bitcode - i / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / lib / release / include - isystem / users / xuhx3 / lenovo / opencv_env / opencv / 3 rdparty / protobuf / src - isystem / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos - i / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / derivedsources - normal / armv7 - i / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / derivedsources / armv7 - i / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / derivedsources - f / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / lib / release - fembed - bitcode - fsigned - char - w - wall - wreturn - type - wnon - virtual - dtor - waddress - wsequence - point - wformat - wformat - security - wstrict - prototypes - winit - self - wpointer - arith - wuninitialized - wno - delete - non - virtual - dtor - wno - unnamed - type - template - args - wno - comment - fdiagnostics - show - option - qunused - arguments - wno - semicolon - before - method - body - fvisibility \ \ = hidden - fvisibility - inlines - hidden - wno - deprecated - wno - missing - prototypes - wno - missing - declarations - wno - shadow - wno - unused - parameter - wno - unused - local - typedefs - wno - sign - compare - wno - sign - promo - wno - undef - wno - tautological - undefined - compare - wno - ignored - qualifiers - wno - extra - wno - unused - function - wno - unused - const - variable - wno - shorten - <number> - to - <number> - wno - invalid - offsetof - wno - enum - compare - switch - wno - suggest - override - wno - inconsistent - missing - override - wno - implicit - fallthrough - wno - array - bounds - dndebug - dndebug - fpic - std \ \ =c + + <number> - mmd - mt dependencies - mf / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / objects - normal / armv7 / tokenizer . d - - serialize - diagnostics / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / objects - normal / armv7 / tokenizer . dia - c / users / xuhx3 / lenovo / opencv_env / opencv / 3 rdparty / protobuf / src / google / protobuf / io / tokenizer . cc - o / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / objects - normal / armv7 / tokenizer . o / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / 3 rdparty / protobuf / opencv . build / release - iphoneos / libprotobuf . build / objects - normal / armv7 / tokenizer . dia : <number> : <number> : warning : could not read serialized diagnostics file : error ( "" failed to open diagnostics file "" ) ( in target ' libprotobuf ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' ade ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' libjpeg - turbo ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' libpng ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' opencv_objc ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' gen_opencv_objc_source ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' all_build ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' opencv_world ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' zlib ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' quirc ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' gen_opencv_objc_source_ios ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' zero_check ' from project ' opencv ' ) / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / opencv . xcodeproj : warning : the ios deployment target ' iphoneos_deployment_target ' is set to <number> , but the range of supported deployment target versions is <number> to <date> . ( in target ' libprotobuf ' from project ' opencv ' ) * * build failed * * the following build commands failed : phasescriptexecution generate \ \ cmakefiles / dephelper / gen_opencv_objc_source_ios / users / xuhx3 / lenovo / opencv_env / build_ios / build / build - armv7 - iphoneos / modules / objc_bindings_generator / opencv . build / release - iphoneos / gen_opencv_objc_source_ios . build / script - 6 2 4 ac68ac6f221e65cfc8166 . sh ( in target ' gen_opencv_objc_source_ios ' from project ' opencv ' ) ( <number> failure ) = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = error : command ' [ ' xcodebuild ' , ' bitcode_generation_mode = bitcode ' , ' iphoneos_deployment_target = <number> ' , ' archs = armv7 ' , ' - sdk ' , ' iphoneos ' , ' - configuration ' , ' release ' , ' - parallelizetargets ' , ' - jobs ' , ' <number> ' , ' - target ' , ' all_build ' , ' build ' ] ' returned non - zero exit status <number> . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = traceback ( most recent call last ) : file "" opencv / platforms / ios / build_framework . py "" , line <number> , in build self . _build ( outdir ) file "" opencv / platforms / ios / build_framework . py "" , line <number> , in _build self . buildone ( target [ <number> ] , target [ <number> ] , main_build_dir , cmake_flags ) file "" opencv / platforms / ios / build_framework . py "" , line <number> , in buildone execute ( buildcmd + [ "" - target "" , "" all_build "" , "" build "" ] , cwd = builddir ) file "" / users / xuhx3 / lenovo / opencv_env / opencv / platforms / apple / cv_build_utils . py "" , line <number> , in execute retcode = check_call ( cmd , cwd = cwd ) file "" / applications / xcode . app / contents / developer / library / frameworks / python3 . framework / versions / <number> / lib / python3 . <number> / subprocess . py "" , line <number> , in check_call raise calledprocesserror ( retcode , cmd ) subprocess . calledprocesserror ' [ ' xcodebuild ' , ' bitcode_generation_mode = bitcode ' , ' iphoneos_deployment_target = <number> ' , ' archs = armv7 ' , ' - sdk ' , ' iphoneos ' , ' - configuration ' , ' release ' , ' - parallelizetargets ' , ' - jobs ' , ' <number> ' , ' - target ' , ' all_build ' , ' build ' ] ' returned non - zero exit status <number> .",2
opencv/opencv,"setmousecallback gives null pointer error in opencv <number> . <number> and later versions < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> . <number> - operating system / platform => windows <number> bit - compiler => installed using opencv - contrib - python version = <number> . <number> - - > - opencv => <number> . <number> - operating system / platform => windows <number> bit - compiler => visual studio - - installed using opencv - contrib - python version = <number> . <number> # # # # # detailed description using setmousecallback gives following error in opencv - contrib - python = <number> . <number> : ` cv2 . error : opencv ( <number> . <number> ) d :\\ a \ \ opencv - python \ \ opencv - python \ \ opencv \ \ modules \ \ highgui \ \ src \ \ window_w32 . cpp : <number> : error : ( - <number> : null pointer ) null window : ' frame ' in function ' cvsetmousecallback ' ` i tested the following versions : <number> . <number> - good <number> . <number> - good <number> . <number> - error <number> . <number> - error <number> . <number> - error error seems to have appeared in opencv version <number> . <number> . build information for last known good version and current version included below : <number> . <number> <details> ` ` ` general configuration for opencv <number> . <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = version control : <number> . <number> extra modules : location ( extra ) : c <annoyed> users / runneradmin / appdata / local / temp / pip - req - build - 1 hfhc_rd / opencv_contrib / modules version control ( extra ) : <number> . <number> platform : timestamp : <number> - <number> - 0 7 t <time> z host : windows <number> . <number> amd64 cmake : <number> . <number> cmake generator : visual studio <number> <number> win64 cmake build tool : msbuild . exe msvc : <number> configuration : debug release cpu / hw features : baseline : sse sse2 sse3 requested : sse3 dispatched code generation : sse4_1 sse4_2 fp16 avx avx2 requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx sse4_1 ( <number> files ) : + ssse3 sse4_1 sse4_2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 avx avx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 avx avx2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 c / c + + : built as dynamic libs ? : no c + + standard : <number> c + + compiler : c <annoyed> program files (x 8 6 ) / microsoft visual studio <number> / vc / bin / x86_amd64 / cl . exe ( ver <number> . <number> ) c + + flags ( release ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / wd4324 / wd4275 / wd4512 / wd4589 / mp / mt / o2 / ob2 / dndebug c + + flags ( debug ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / wd4324 / wd4275 / wd4512 / wd4589 / mp / mtd / zi / ob0 / od / rtc1 c compiler : c <annoyed> program files (x 8 6 ) / microsoft visual studio <number> / vc / bin / x86_amd64 / cl . exe c flags ( release ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / mt / o2 / ob2 / dndebug c flags ( debug ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / mtd / zi / ob0 / od / rtc1 linker flags ( release ) : / machine <kiss> 6 4 / nodefaultlib : atlthunk . lib / incremental : no / nodefaultlib : libcmtd . lib / nodefaultlib : libcpmtd . lib / nodefaultlib : msvcrtd . lib linker flags ( debug ) : / machine <kiss> 6 4 / nodefaultlib : atlthunk . lib / debug / incremental / nodefaultlib : libcmt . lib / nodefaultlib : libcpmt . lib / nodefaultlib : msvcrt . lib ccache : no precompiled headers : yes extra dependencies : wsock32 comctl32 gdi32 ole32 setupapi ws2_32 3 rdparty dependencies : ittnotify libprotobuf ade libjpeg - turbo libwebp libpng libtiff libopenjp2 ilmimf zlib quirc ippiw ippicv opencv modules : to be built : aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto disabled : freetype world disabled by dependency : - unavailable : alphamat cnn_3dobj cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv hdf java julia matlab ovis python2 sfm ts viz applications : - documentation : no non - free algorithms : no windows rt support : no gui : win32 ui : yes vtk support : no media i / <surprise> zlib : build ( ver <date> ) jpeg : build - libjpeg - turbo ( ver <number> . <number> - <number> ) webp : build ( ver encoder : 0x0 2 0 f ) png : build ( ver <date> ) tiff : build ( ver <number> - <number> . <number> ) jpeg <number> : build ( ver <number> . <number> ) openexr : build ( ver <number> . <number> ) hdr : yes sunraster : yes pxm : yes pfm : yes video i / <surprise> dc1394 : no ffmpeg : yes ( prebuilt binaries ) avcodec : yes ( <number> . <number> ) avformat : yes ( <number> . <number> ) avutil : yes ( <number> . <number> ) swscale : yes ( <date> ) avresample : yes ( <number> . <number> ) gstreamer : no directshow : yes media foundation : yes dxva : yes parallel framework : concurrency trace : yes ( with intel itt ) other third - party libraries : intel ipp : <number> . <number> gold [ <number> . <number> ] at : c <annoyed> users / runneradmin / appdata / local / temp / pip - req - build - 1 hfhc_rd / _skbuild / win - amd64 - <number> / cmake - build / 3 rdparty / ippicv / ippicv_win / icv intel ipp iw : sources ( <number> . <number> ) at : c <annoyed> users / runneradmin / appdata / local / temp / pip - req - build - 1 hfhc_rd / _skbuild / win - amd64 - <number> / cmake - build / 3 rdparty / ippicv / ippicv_win / iw lapack : no eigen : no custom hal : no protobuf : build ( <number> . <number> ) opencl : yes ( nvd3d11 ) include path : c <annoyed> users / runneradmin / appdata / local / temp / pip - req - build - 1 hfhc_rd / opencv / 3 rdparty / include / opencl / <number> link libraries : dynamic load python <number> : interpreter : c <annoyed> hostedtoolcache / windows / python / <number> . <number> /x 6 4 / python . exe ( ver <number> . <number> ) libraries : c <annoyed> hostedtoolcache / windows / python / <number> . <number> /x 6 4 / libs / python39 . lib ( ver <number> . <number> ) numpy : c <annoyed> users / runneradmin / appdata / local / temp / pip - build - env - xfmlpevn / overlay / lib / site - packages / numpy / core / include ( ver <number> . <number> ) install path : python python ( for build ) : c <annoyed> hostedtoolcache / windows / python / <date> /x 6 4 / python . exe java : ant : no jni : c <annoyed> hostedtoolcache / windows / java_adopt_jdk / <date> - <number> /x 6 4 / include c <annoyed> hostedtoolcache / windows / java_adopt_jdk / <date> - <number> /x 6 4 / include / win32 c <annoyed> hostedtoolcache / windows / java_adopt_jdk / <date> - <number> /x 6 4 / include java wrappers : no java tests : no install to : c <annoyed> users / runneradmin / appdata / local / temp / pip - req - build - 1 hfhc_rd / _skbuild / win - amd64 - <number> / cmake - install - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ` ` ` </details> <number> . <number> <details> ` ` ` general configuration for opencv <number> . <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = version control : <number> . <number> extra modules : location ( extra ) : d <annoyed> a / opencv - python / opencv - python / opencv_contrib / modules version control ( extra ) : <number> . <number> platform : timestamp : <number> - <number> - 0 4 t <time> z host : windows <number> . <number> amd64 cmake : <number> . <number> cmake generator : visual studio <number> <number> cmake build tool : msbuild . exe msvc : <number> configuration : debug release cpu / hw features : baseline : sse sse2 sse3 requested : sse3 dispatched code generation : sse4_1 sse4_2 fp16 avx avx2 requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx sse4_1 ( <number> files ) : + ssse3 sse4_1 sse4_2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 avx avx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 avx avx2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 c / c + + : built as dynamic libs ? : no c + + standard : <number> c + + compiler : c <annoyed> program files (x 8 6 ) / microsoft visual studio <number> / vc / bin / x86_amd64 / cl . exe ( ver <number> . <number> ) c + + flags ( release ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / wd4324 / wd4275 / wd4512 / wd4589 / mp / mt / o2 / ob2 / dndebug c + + flags ( debug ) : / dwin32 / d_windows / w4 / gr / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / eha / wd4127 / wd4251 / wd4324 / wd4275 / wd4512 / wd4589 / mp / mtd / zi / ob0 / od / rtc1 c compiler : c <annoyed> program files (x 8 6 ) / microsoft visual studio <number> / vc / bin / x86_amd64 / cl . exe c flags ( release ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / mt / o2 / ob2 / dndebug c flags ( debug ) : / dwin32 / d_windows / w3 / d _crt_secure_no_deprecate / d _crt_nonstdc_no_deprecate / d _scl_secure_no_warnings / gy / bigobj / oi / fp : precise / mp / mtd / zi / ob0 / od / rtc1 linker flags ( release ) : / machine <kiss> 6 4 / nodefaultlib : atlthunk . lib / incremental : no / nodefaultlib : libcmtd . lib / nodefaultlib : libcpmtd . lib / nodefaultlib : msvcrtd . lib linker flags ( debug ) : / machine <kiss> 6 4 / nodefaultlib : atlthunk . lib / debug / incremental / nodefaultlib : libcmt . lib / nodefaultlib : libcpmt . lib / nodefaultlib : msvcrt . lib ccache : no precompiled headers : yes extra dependencies : wsock32 comctl32 gdi32 ole32 setupapi ws2_32 3 rdparty dependencies : libprotobuf ade ittnotify libjpeg - turbo libwebp libpng libtiff libopenjp2 ilmimf zlib quirc ippiw ippicv opencv modules : to be built : aruco barcode bgsegm bioinspired calib3d ccalib core datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto disabled : world disabled by dependency : - unavailable : alphamat cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv freetype hdf java julia matlab ovis python2 sfm ts viz applications : - documentation : no non - free algorithms : no windows rt support : no gui : win32ui win32 ui : yes vtk support : no media i / <surprise> zlib : build ( ver <date> ) jpeg : build - libjpeg - turbo ( ver <number> . <number> - <number> ) webp : build ( ver encoder : 0x0 2 0 f ) png : build ( ver <date> ) tiff : build ( ver <number> - <number> . <number> ) jpeg <number> : build ( ver <number> . <number> ) openexr : build ( ver <number> . <number> ) hdr : yes sunraster : yes pxm : yes pfm : yes video i / <surprise> dc1394 : no ffmpeg : yes ( prebuilt binaries ) avcodec : yes ( <number> . <number> ) avformat : yes ( <number> . <number> ) avutil : yes ( <number> . <number> ) swscale : yes ( <date> ) avresample : yes ( <number> . <number> ) gstreamer : no directshow : yes media foundation : yes dxva : yes parallel framework : concurrency trace : yes ( with intel itt ) other third - party libraries : intel ipp : <number> . <number> gold [ <number> . <number> ] at : d <annoyed> a / opencv - python / opencv - python / _skbuild / win - amd64 - <number> / cmake - build / 3 rdparty / ippicv / ippicv_win / icv intel ipp iw : sources ( <number> . <number> ) at : d <annoyed> a / opencv - python / opencv - python / _skbuild / win - amd64 - <number> / cmake - build / 3 rdparty / ippicv / ippicv_win / iw lapack : no eigen : no custom hal : no protobuf : build ( <number> . <number> ) opencl : yes ( nvd3d11 ) include path : d <annoyed> a / opencv - python / opencv - python / opencv / 3 rdparty / include / opencl / <number> link libraries : dynamic load python <number> : interpreter : c <annoyed> hostedtoolcache / windows / python / <number> . <number> /x 6 4 / python . exe ( ver <number> . <number> ) libraries : c <annoyed> hostedtoolcache / windows / python / <number> . <number> /x 6 4 / libs / python36 . lib ( ver <number> . <number> ) numpy : c <annoyed> hostedtoolcache / windows / python / <number> . <number> /x 6 4 / lib / site - packages / numpy / core / include ( ver <number> . <number> ) install path : python / cv2 / python - <number> python ( for build ) : c <annoyed> hostedtoolcache / windows / python / <date> /x 6 4 / python . exe java : ant : no jni : c <annoyed> hostedtoolcache / windows / java_temurin - hotspot_jdk / <date> - <number> /x 6 4 / include c <annoyed> hostedtoolcache / windows / java_temurin - hotspot_jdk / <date> - <number> /x 6 4 / include / win32 c <annoyed> hostedtoolcache / windows / java_temurin - hotspot_jdk / <date> - <number> /x 6 4 / include java wrappers : no java tests : no install to : d <annoyed> a / opencv - python / opencv - python / _skbuild / win - amd64 - <number> / cmake - install - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ` ` ` </details> # # # # # steps to reproduce python version = <number> test code : ` ` ` import cv2 def mouse_callback ( event , x , y , flags , param ) : if event = = cv2 . event_lbuttondblclk : print ( x , y ) cap = cv2 . videocapture ( <number> ) if not cap . isopened ( <sad> print ( "" could not open camera "" ) while true : ret , frame = cap . read ( ) cv2 . setmousecallback ( ' frame ' , mouse_callback ) cv2 . imshow ( ' frame ' , frame ) if cv2 . waitkey ( <number> ) & 0 xff = = ord ( "" q "" <sad> break ` ` ` # # # # # issue submission checklist - [ ✔️ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [ ✔️ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ✔️ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ✔️ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"building opencv on windows with vs , opengl , gstreamer : missing libraries in project files # # # # # system information ( version ) - opencv => <number> . <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> # # # # # detailed description modul opencv_videoio : there is to add gstaudio - <number> . lib ( gstreamer audio ) to the linked libraries , linker missing symbols from this modul opencv_highgui is to add opengl32 . lib ( opengl on windows ) to the linked libraries , linker missing symbols from this # # # # # steps to reproduce create opencv <number> . <number> visual project files per cmake with opengl and gstreamer support , build library",2
opencv/opencv,"cap_prop_pos_msec to frame_number hi i am given some timestamps for a video . i want to do in place changes to a frame on that particular timestamp of a video . how can i achieve that ? for reading the frame at a given timestamp v = cv2 . videocapture ( videofile ) v . set ( cv2 . cap_prop_pos_msec , row [ ' frame_timestamp ' ] * 1 e3 ) _ , frame = v . read ( ) ` ` ` how to write at a particular timestamp ?",2
opencv/opencv,"opencv <number> . <number> not building with openvino - toolkit <number> . <number> < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> . <number> - dev - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => <number> . <number> - dev - operating system / platform => windows <number> bit - compiler => visual studio <number> # # # # # detailed description i am trying to build opencv with inference - engine support , but what i experienced is : - here in cmake gui , i cannot find the * with_inf_engine <emphasis> * flag as before there was this flag , but in the latest source which i downloaded there is no this flag . but i found another flag which is : * with_openvino <emphasis> * , i do not know if this is a replacement for the * with_inf_engine <emphasis> * flag , anyway . - when i use the flag * with_openvino <emphasis> * , then it shows : ` openvino_dir - notfound ` as well as ` inferenceengine_dir - notfound ` , but i have tried to direct this path to the following paths , but no one was working c :\\ program files (x 8 6 ) \ \ intel \ \ openvino_2021 \ \ inference_engine <number> . c :\\ program files (x 8 6 ) \ \ intel \ \ openvino_2021 <number> . c :\\ program files (x 8 6 ) \ \ intel \ \ openvino_2021 \ \ deployment_tools \ \ inference_engine so now what should i do to solve this problem ? * * note : * * i have installed openvino - toolkit as it was instructed on the official page , and also i am not new with opencv and openvino before it was built successfully , but in new releases , it does not .",2
opencv/opencv,"cv : : videocapture set cv : : cap_prop_fps is not working # # # # # system information ( version ) - opencv => <number> . <number> - operating system / platform => ubuntu20 . <number> - compiler => qt creator <number> . <number> ( gcc <number> . <number> , <number> bit ) # # # # # detailed description i am using opencv library to capture the images from web cameras , and i am able to do that with different capture format ( cv : : cap_prop_fourcc ) . but i am facing an issue with setting up frame per second value . here is the sample code i tried : ` ` ` <hashtag> include </hashtag> "" opencv2 / videoio . hpp "" cv : : videocapture capture ; capture . open ( "" / dev / video0 "" ); bool success = capture . isopened ( ); if ( success ) { capture . set ( cv : : cap_prop_fps , <number> ); } ` ` ` but after setting up the fps value <number> , the camera still shows the fps value as <number> . i did some googling before creating this task , but did not find any useful information . so i wanted to know anything i am missing or is there any other methods to setup the fps . thanks in advance . # # # # # steps to reproduce please try to use some sample code to setup the fps for web cameras , like : ` ` ` <hashtag> include </hashtag> "" opencv2 / videoio . hpp "" cv : : videocapture capture ; capture . open ( "" / dev / video0 "" ); bool success = capture . isopened ( ); if ( success ) { capture . set ( cv : : cap_prop_fps , <number> ); } ` ` ` # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question < - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [x ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [x ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"does support torch . matmul ? < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => : grey_question : - operating system / platform => : grey_question : - compiler => : grey_question : # # # # # detailed description < ! - - your description - - > # # # # # steps to reproduce < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [ ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [ ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",2
opencv/opencv,"issue using functions from opencv shared libraries cross compiled for android hi team , i was trying to build and execute a cpp code that links few opencv shared libraries that i had cross compiled for android but while trying to utilize the namespace cv or trying to use a function of opencv , it says undeclared identifier . i did try this documentation here : <url> but was unable to get it working . also i referred to another stackoverflow question for reference here : [ opencv with android ndk undefined references ] ( <url> as well . any guidance on how to link them and import opencv functions properly which i am probably missing out here would be really helpful . * * trial_onnx . cpp file * * ` ` ` <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> <fstream> <hashtag> include </hashtag> <cstring> <hashtag> include </hashtag> < opencv2 / ml / ml . hpp > <hashtag> include </hashtag> < opencv2 / dnn / dnn . hpp > <hashtag> include </hashtag> < opencv2 / imgcodecs / imgcodecs . hpp > <hashtag> include </hashtag> < opencv2 / imgproc / imgproc . hpp > <hashtag> include </hashtag> < opencv2 / core / core . hpp > <hashtag> include </hashtag> < opencv2 / core / mat . hpp > <hashtag> include </hashtag> "" trial_onnx . h "" using namespace std ; void execute_main ( ) { std : : cout < < "" hello world "" < < std : : endl ; cv : : mat mat1 ; } ` ` ` * * trial_onnx . h file * * ` ` ` <hashtag> if def </hashtag> __cplusplus extern "" c "" { <hashtag> end if </hashtag> / / __cplusplus void execute_main ( ); <hashtag> if def </hashtag> __cplusplus } <hashtag> end if </hashtag> / / __cplusplus ` ` ` * * android . mk file * * ` ` ` local_path : = $( call my - dir ) include $( clear_vars ) local_module : = opencv_ml local_src_files : = / home / ubuntu / trial / opencv - <number> . <number> - android - sdk / opencv - android - sdk / sdk / native / libs / arm64 - v8a / libopencv_ml . so include $( prebuilt_shared_library ) include $( clear_vars ) local_module : = opencv_dnn local_src_files : = / home / ubuntu / trial / opencv - <number> . <number> - android - sdk / opencv - android - sdk / sdk / native / libs / arm64 - v8a / libopencv_dnn . so include $( prebuilt_shared_library ) include $( clear_vars ) <hashtag> local path </hashtag> : = $( call my - dir ) local_module : = opencv_imgcodecs local_src_files : = / home / ubuntu / trial / opencv - <number> . <number> - android - sdk / opencv - android - sdk / sdk / native / libs / arm64 - v8a / libopencv_imgcodecs . so include $( prebuilt_shared_library ) include $( clear_vars ) <hashtag> local path </hashtag> : = $( call my - dir ) local_module : = opencv_imgproc local_src_files : = / home / ubuntu / trial / opencv - <number> . <number> - android - sdk / opencv - android - sdk / sdk / native / libs / arm64 - v8a / libopencv_imgproc . so include $( prebuilt_shared_library ) include $( clear_vars ) <hashtag> local path </hashtag> : = $( call my - dir ) local_module : = opencv_core local_src_files : = / home / ubuntu / trial / opencv - <number> . <number> - android - sdk / opencv - android - sdk / sdk / native / libs / arm64 - v8a / libopencv_core . so include $( prebuilt_shared_library ) include $( clear_vars ) local_module : = opencv_highgui local_src_files : = / home / ubuntu / trial / opencv - <number> . <number> - android - sdk / opencv - android - sdk / sdk / native / libs / arm64 - v8a / libopencv_highgui . so include $( prebuilt_shared_library ) include $( clear_vars ) local_shared_libraries = opencv_ml opencv_dnn opencv_imgcodecs opencv_highgui opencv_imgproc opencv_core opencv local_arm_mode : = arm local_module : = libtrial local_src_files : = inc / trial_onnx . h src / trial_onnx . cpp local_c_includes : = ${ local_path } / inc local_ldlibs + = - llog - ldl ` ` ` * output <emphasis> * ` ` ` [ arm64 - v8a ] install : libopencv_core . so => libs / arm64 - v8a / libopencv_core . so [ arm64 - v8a ] install : libopencv_dnn . so => libs / arm64 - v8a / libopencv_dnn . so [ arm64 - v8a ] install : libopencv_highgui . so => libs / arm64 - v8a / libopencv_highgui . so [ arm64 - v8a ] install : libopencv_imgcodecs . so => libs / arm64 - v8a / libopencv_imgcodecs . so [ arm64 - v8a ] install : libopencv_imgproc . so => libs / arm64 - v8a / libopencv_imgproc . so [ arm64 - v8a ] install : libopencv_ml . so => libs / arm64 - v8a / libopencv_ml . so [ arm64 - v8a ] compile + + : trial <= trial_onnx . cpp [ arm64 - v8a ] sharedlibrary : lib_trial . so . / obj / local / arm64 - v8a / objs / trial / src / trial_onnx . <surprise> in function ` execute_main ' : / home / ubuntu / / trial / . / src / trial_onnx . cpp : <number> : undefined reference to ` cv : : mat : : mat ( ) ' / home / ubuntu / trial / . / src / trial_onnx . cpp : <number> : undefined reference to ` cv : : mat : : ~ mat ( ) ' clang + + : error : linker command failed with exit code <number> ( use - v to see invocation ) make : * * * [ obj / local / arm64 - v8a / lib_trial . so ] error <number> ` ` ` if i skip using cv : : in the cpp file the following outputs pops up , this does make sense but its able to identify the cv : : mat type is present in core / mat . hpp then why not identify cv : : mat in other case baffles me : ` ` ` [ arm64 - v8a ] install : libopencv_core . so => libs / arm64 - v8a / libopencv_core . so [ arm64 - v8a ] install : libopencv_dnn . so => libs / arm64 - v8a / libopencv_dnn . so [ arm64 - v8a ] install : libopencv_highgui . so => libs / arm64 - v8a / libopencv_highgui . so [ arm64 - v8a ] install : libopencv_imgcodecs . so => libs / arm64 - v8a / libopencv_imgcodecs . so [ arm64 - v8a ] install : libopencv_imgproc . so => libs / arm64 - v8a / libopencv_imgproc . so [ arm64 - v8a ] install : libopencv_ml . so => libs / arm64 - v8a / libopencv_ml . so [ arm64 - v8a ] compile + + : trial <= trial_onnx . cpp [ arm64 - v8a ] sharedlibrary : lib_trial . so . / src / trial_onnx . cpp : <number> : <number> : error : unknown type name ' mat ' ; did you mean ' cv : : mat ' ? mat mat1 ; ^ ~ ~ cv : : mat . / opencv2 / core / mat . hpp : <number> <time> : note declared here class cv_exports mat ^ <number> error generated . ` ` `",2
opencv/opencv,"issue linking opencv ' s shared library with android . mk hi opencv team i have cross compiled opencv for android and was trying to link the shared libraries generated with a simple script , but somehow the linking seems to have an issue . i tried linking static library as well ( commenting the shared library part ) but again facing the same issue . any help will be appreciated . thank you . android . mk file contents ` ` ` local_path : = $( call my - dir ) include $( clear_vars ) local_module : = libtrial local_arm_mode : = arm local_src_files : = inc / trial_onnx . h local_src_files : = src / trial_onnx . cpp include $( clear_vars ) local_module : = opencv_core local_src_files : = cross_compiled / libopencv_core . so include $( prebuilt_shared_library ) <hashtag> include </hashtag> $( clear_vars ) <hashtag> local module </hashtag> : = opencv_core <hashtag> local src files </hashtag> : = libopencv_core . a <hashtag> include </hashtag> $( prebuilt_static_library ) local_c_includes : = ${ local_path } / inc local_ldlibs + = - landroid - llog - ldl include $( build_shared_library ) ` ` ` trial_onnx . cpp contents ` ` ` <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> "" wasabeef_onnx . h "" <hashtag> include </hashtag> "" stdlib . h "" using namespace std ; void execute_main ( ) { std : : cout < < "" hello world "" ; const std : : string filename1 = "" input . raw "" ; float * input1 = new float [ <number> * <number> * <number> ]; cv : : mat mat1 ; } ` ` ` trial_onnx . h contents ` ` ` <hashtag> if def </hashtag> __cplusplus extern "" c "" { <hashtag> end if </hashtag> / / __cplusplus void execute_main ( ); <hashtag> if def </hashtag> __cplusplus } <hashtag> end if </hashtag> / / __cplusplus ` ` ` upon building , its getting terminated with the log as below - already defined",2
opencv/opencv,"opencv cuda gives low fps - opencv => <number> . <number> - operating system / platform => ubuntu <number> - compiler => cmake - gpu => nvidia corporation / geforce rtx <number> ti laptop gpu / pcie / sse2 - cpu => amd ® ryzen <number> 5 6 0 0 h with radeon graphics × <number> hello everyone . firstly , this topic is not about either opencv or cuda . this problem is about me but i did not find answer anywhere . i built opencv <number> . <number> with cuda <number> and cudnn <number> . <number> . i installed built successfully but i can not get enough fps from this built . for example , when i run my code with cpu it gives me 1 5 fps when i use cuda backend it gives me <number> fps . where did i miss ? what do i have to do ? i am using very basic yolov3 object detection algorithm . here are my files . it is about traffic signs . you can test it with stop sign etc . ( not all signs are included ) <url> here are my files . here are my opencv getbuildinformation output ` general configuration for opencv <number> . <number> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = version control : unknown extra modules : location ( extra ) : / home / rota / downloads / opencv_contrib - <number> . <number> / modules version control ( extra ) : unknown platform : timestamp : <number> - <number> - 3 1 t <time> z host : linux <number> . <number> - <number> - generic x86_64 cmake : <number> . <number> cmake generator : unix makefiles cmake build tool : / usr / bin / make configuration : release cpu / hw features : baseline : sse sse2 sse3 requested : sse3 dispatched code generation : sse4_1 sse4_2 fp16 avx avx2 avx512_skx requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx sse4_1 ( <number> files ) : + ssse3 sse4_1 sse4_2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 avx avx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 avx avx2 ( <number> files ) : + ssse3 sis : pr is : open se4_1 popcnt sse4_2 fp16 fma3 avx avx2 avx512_skx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 avx_512f avx512_common avx512_skx c / c + + : built as dynamic libs ? : yes c + + standard : <number> c + + compiler : / usr / bin / c + + ( ver <number> . <number> ) c + + flags ( release ) : - fsigned - char - ffast - math - w - wall - werror = return - type - werror = non - virtual - dtor - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - fvisibility - inlines - hidden - o3 - dndebug - dndebug c + + flags ( debug ) : - fsigned - char - ffast - math - w - wall - werror = return - type - werror = non - virtual - dtor - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - fvisibility - inlines - hidden - g - o0 - ddebug - d_debug c compiler : / usr / bin / cc c flags ( release ) : - fsigned - char - ffast - math - w - wall - werror = return - type - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - o3 - dndebug - dndebug c flags ( debug ) : - fsigned - char - ffast - math - w - wall - werror = return - type - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - g - o0 - ddebug - d_debug linker flags ( release ) : - wl , - - exclude - libs , libippicv . a - wl , - - exclude - libs , libippiw . a - wl , - - gc - sections - wl , - - as - needed linker flags ( debug ) : - wl , - - exclude - libs , libippicv . a - wl , - - exclude - libs , libippiw . a - wl , - - gc - sections - wl , - - as - needed ccache : no precompiled headers : no extra dependencies : m pthread cudart_static dl rt nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas cudnn cufft - l / usr / local / cuda - <number> / lib64 - l / usr / lib / x86_64 - linux - gnu 3 rdparty dependencies : opencv modules : to be built : aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann freetype fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto disabled : cudacodec world disabled by dependency : - unavailable : alphamat cnn_3dobj cvv hdf java julia matlab ovis python2 sfm viz applications : tests perf_tests apps documentation : no non - free algorithms : yes gui : gtk + : yes ( ver <date> ) gthread : yes ( ver <number> . <number> ) gtkglext : no opengl support : no vtk support : no media i / <surprise> zlib : / usr / lib / x86_64 - linux - gnu / libz . so ( ver <date> ) jpeg : / usr / lib / x86_64 - linux - gnu / libjpeg . so ( ver <number> ) webp : build ( ver encoder : 0x0 2 0 f ) png : / usr / lib / x86_64 - linux - gnu / libpng . so ( ver <date> ) tiff : / usr / lib / x86_64 - linux - gnu / libtiff . so ( ver <number> / <number> . <number> ) jpeg <number> : build ( ver <number> . <number> ) openexr : build ( ver <number> . <number> ) hdr : yes sunraster : yes pxm : yes pfm : yes video i / <surprise> dc1394 : no ffmpeg : no avcodec : no avformat : no avutil : no swscale : no avresample : no gstreamer : yes ( <number> . <number> ) v4l / v4l2 : yes ( linux / videodev2 . h ) parallel framework : pthreads trace : yes ( with intel itt ) other third - party libraries : intel ipp : <number> . <number> gold [ <number> . <number> ] at : / home / rota / downloads / opencv - <number> . <number> / build / 3 rdparty / ippicv / ippicv_lnx / icv intel ipp iw : sources ( <number> . <number> ) at : / home / rota / downloads / opencv - <number> . <number> / build / 3 rdparty / ippicv / ippicv_lnx / iw va : no lapack : no eigen : no custom hal : no protobuf : build ( <number> . <number> ) nvidia cuda : yes ( ver <number> , cufft cublas fast_math ) nvidia gpu arch : <number> nvidia ptx archs : cudnn : yes ( ver <number> . <number> ) opencl : yes ( no extra features ) include path : / home / rota / downloads / opencv - <number> . <number> / 3 rdparty / include / opencl / <number> link libraries : dynamic load python <number> : interpreter : / usr / bin / python3 ( ver <date> ) libraries : / usr / lib / x86_64 - linux - gnu / libpython3 . <number> . so ( ver <date> ) numpy : / usr / local / lib / python3 . <number> / dist - packages / numpy / core / include ( ver <number> . <number> ) install path : / usr / lib / python3 / dist - packages / cv2 / python - <number> python ( for build ) : / usr / bin / python2 . <number> java : ant : no jni : no java wrappers : no java tests : no install to - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - `",2
opencv/opencv,cv2 . error : opencv ( <number> . <number> - pre ) / home / pi / opencv / modules / core / src / persistence . cpp : <number> : error argument ) input file is invalid in function ' open ' i want to use opencv ( cv2 ) to read the . tflite file but it cannot open . is the cv2 can only read . yml file ? how can i read the . tflite file succesfully ? or can i change the tflite to yml ? i can not find the way . [ image ] ( <url>,2
opencv/opencv,"include gapi always equires openvino dll ? # # # # # system information ( version ) - opencv = <number> . <number> - operating system / platform => windows <number> bit - opencv package from => <url> # # # # # detailed description i apply opencv gapi with the following simple image processing . ` ` ` cv : : gapi : : convertto ( ); cv : : gapi : : resize ( ); cv : : gapi : : blur ( ); cv : : gapi : : mul ; ` ` ` after compiling the c + + application , it requires the following dll to run inference_engine . dll ngraph . dll opencv_dnn454 . dll opencv_features2d454 . dll opencv_flann454 . dll inference_engine_transformations . dll ` ` ` are these dlls really used in such a simple gapi graph ?",2
opencv/opencv,videoio capgstreamer introducing <number> - <number> s latecy # # # # videoio capgstreamer introducing <number> - <number> s latecy # # # # # versions - opencv => <number> - operating system / platform => linux tegra r32 . <number> ( ubuntu <number> ) / nv xavieragx ( arm64 ) - compiler => gcc ( ubuntu / linaro <number> . <number> - 3 ubuntu1 ~ <number> ) <number> . <number> - module => videoio - file => capgstreamer . cpp - gstreamer version => <number> . <number> # # # # # detailed description gstreamer capture through appsink introduces high latency on frame retrieval . average latencies of <number> s with <number> s peak found with cpu load less than <percent> . latency tested using glass to glass method . pipeline is emitter ( videosrc omxh264enc ! rtph264pay ! udpsink ) - receiver ( udpsrc ! nvv4l2dec ! appsink ) appsink is read with a dedicated thread to flush the pipeline when changing appsink for display glass to glass latency falls to < <number> ms . seems like a buffering problem or bottleneck on gst sample retrieve but i am not sure . video does not seem to be downsampled and latency remains lowering framerate .,2
opencv/opencv,please ask how to solve this problem [ - 1 9 0 d273a8698af7b ] ( <url> please ask how to solve this problem,2
opencv/opencv,"status - <number> - cl - no - subgroup - ifp - d amd_device my computer has two gpu [ image ] ( <url> how can i use my intel gpu accelerate my project , amd gpu is slower ! [ image ] ( <url>",2
opencv/opencv,"cmake configuration fails for building opencv <number> . <number> with onnx using cmake - gui to build opencv with onnx results in configuration report stating "" onnx : no "" . # # # # # system information - opencv => <number> . <number> - dev - onnx => microsoft / onnxruntime v1 . <number> - operating system => ubuntu <number> lts ( linux <number> . <number> - microsoft - standard - wsl2 x86_64 ) - cmake => cmake - <number> . <number> - linux - x86_64 - cmake build tool & generator => ninja <number> . <number> # # # # # steps to reproduce these are the options in the cmake configuration : > onnxrt_root_dir : / opt / opencv455 / onnxruntime > ort_include : / opt / opencv455 / onnxruntime / include / onnxruntime / core / session > with_onnx : checked # # # # # detailed description this is my folder structure ( opencv and onnxruntime were git cloned in there ) : / opt / opencv455 / > build > > 3 rdparty > > cmakecache . txt > > cmakedownloadlog . txt > > cmakefiles > > cmakevars . txt > > cpackconfig . cmake > > cpacksourceconfig . cmake > > opencvconfig - version . cmake > > opencvconfig . cmake > > apps > > cmake_uninstall . cmake > > configured > > custom_hal . hpp > > cv_cpu_config . h > > cvconfig . h > > data > > doc > > include > > modules > > opencv2 > > opencv_data_config . hpp > > opencv_python_tests . cfg > > opencv_tests_config . hpp > > python_loader > > setup_vars . sh > > test - reports > > tmp > > unix - install > > version_string . tmp > onnxruntime > > citation . cff > > codeowners > > contributing . md > > license > > nuget . config > > readme . md > > thirdpartynotices . txt > > version_number > > build . amd64 . <number> . bat > > build . bat > > build . sh > > cgmanifests > > cmake > > csharp > > dockerfiles > > docs > > include > > java > > js > > objectivec > > onnxruntime > > ort . wprp > > orttraining > > package > > packages . config > > requirements - dev . txt > > requirements - doc . txt > > requirements - training . txt > > requirements . txt . in > > samples > > server > > setup . py > > tools > > winml > opencv > > 3 rdparty > > cmakelists . txt > > contributing . md > > copyright > > license > > readme . md > > security . md > > apps > > cmake > > data > > doc > > include > > modules > > platforms > > samples when generating , this is the output : > detected processor : x86_64 > could not find pythoninterp ( missing : python_executable ) ( required is at least version "" <number> "" ) > looking for ccache - not found > cleaning internal cached variable : zlib_library > cleaning internal cached variable : zlib_include_dir > could not find zlib ( missing : zlib_library zlib_include_dir ) ( required is at least version "" <number> . <number> "" ) > cleaning internal cached variable : jpeg_library > cleaning internal cached variable : jpeg_include_dir > could not find jpeg ( missing : jpeg_library jpeg_include_dir ) > libjpeg - turbo : version = <number> . <number> , build = opencv - <number> . <number> - dev - libjpeg - turbo > cleaning internal cached variable : tiff_library > cleaning internal cached variable : tiff_include_dir > could not find tiff ( missing : tiff_library tiff_include_dir ) > cleaning internal cached variable : webp_library > cleaning internal cached variable : webp_include_dir > could not find openjpeg ( minimal suitable version : <number> , recommended version >= <number> . <number> ) . openjpeg will be built from sources > openjpeg : version = <number> . <number> , build = opencv - <number> . <number> - dev - openjp2 - <number> . <number> > openjpeg libraries will be built from sources : libopenjp2 ( version "" <number> . <number> "" ) > cleaning internal cached variable : png_library > cleaning internal cached variable : png_include_dir > could not find png ( missing : png_library png_png_include_dir ) > libva : missing va . h header ( va_include_dir ) > found intel ipp ( icv version ) : <number> . <number> [ <number> . <number> gold ] > at : / opt / opencv455 / build / 3 rdparty / ippicv / ippicv_lnx / icv > found intel ipp integration wrappers sources : <number> . <number> > at : / opt / opencv455 / build / 3 rdparty / ippicv / ippicv_lnx / iw > could not find openblas include . turning openblas_found off > could not find openblas lib . turning openblas_found off > could not find atlas ( missing : atlas_cblas_include_dir atlas_clapack_include_dir atlas_cblas_library atlas_blas_library atlas_lapack_library ) > could not find blas ( missing : blas_libraries ) > could not find lapack ( missing : lapack_libraries ) > reason given by package : lapack could not be found because dependency blas could not be found . > > could not find jni ( missing : java_awt_library java_jvm_library java_include_path java_include_path2 java_awt_include_path ) > vtk is not found . please set - dvtk_dir in cmake to vtk build directory , or to vtk install subdirectory with vtkconfig . cmake file > allocator metrics storage type : ' long long ' > registering hook ' init_module_sources_opencv_dnn ' : / opt / opencv455 / opencv / modules / dnn / cmake / hooks / init_module_sources_opencv_dnn . cmake > opencv_dnn : filter out cuda4dnn source code > excluding from source files list : <build> / modules / dnn / layers / layers_common . rvv . cpp > imgcodecs : openexr codec is disabled in runtime . details : <url> > highgui : using builtin backend : none > > general configuration for opencv <number> . <number> - dev = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = > version control : <number> . <number> - <number> - ga1143c4ea0 > > platform : > timestamp : <number> - <number> - 0 6 t <time> z > host : linux <number> . <number> - microsoft - standard - wsl2 x86_64 > cmake : <number> . <number> > cmake generator : ninja > cmake build tool : / usr / bin / ninja > configuration : release > > cpu / hw features : > baseline : sse sse2 sse3 > requested : sse3 > dispatched code generation : sse4_1 sse4_2 fp16 avx avx2 avx512_skx > requested : sse4_1 sse4_2 avx fp16 avx2 avx512_skx > sse4_1 ( <number> files ) : + ssse3 sse4_1 > sse4_2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 > fp16 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 avx > avx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 avx > avx2 ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 > avx512_skx ( <number> files ) : + ssse3 sse4_1 popcnt sse4_2 fp16 fma3 avx avx2 avx_512f avx512_common avx512_skx > > c / c + + : > built as dynamic libs ? : yes > c + + standard : <number> > c + + compiler : / usr / bin / c + + ( ver <number> . <number> ) > c + + flags ( release ) : - fsigned - char - w - wall - werror = return - type - werror = non - virtual - dtor - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - fvisibility - inlines - hidden - o3 - dndebug - dndebug > c + + flags ( debug ) : - fsigned - char - w - wall - werror = return - type - werror = non - virtual - dtor - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wundef - winit - self - wpointer - arith - wshadow - wsign - promo - wuninitialized - wsuggest - override - wno - delete - non - virtual - dtor - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - fvisibility - inlines - hidden - g - o0 - ddebug - d_debug > c compiler : / usr / bin / cc > c flags ( release ) : - fsigned - char - w - wall - werror = return - type - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - o3 - dndebug - dndebug > c flags ( debug ) : - fsigned - char - w - wall - werror = return - type - werror = address - werror = sequence - point - wformat - werror = format - security - wmissing - declarations - wmissing - prototypes - wstrict - prototypes - wundef - winit - self - wpointer - arith - wshadow - wuninitialized - wno - comment - wimplicit - fallthrough = <number> - wno - strict - overflow - fdiagnostics - show - option - wno - long - long - pthread - fomit - frame - pointer - ffunction - sections - fdata - sections - msse - msse2 - msse3 - fvisibility = hidden - g - o0 - ddebug - d_debug > linker flags ( release ) : - wl , - - exclude - libs , libippicv . a - wl , - - exclude - libs , libippiw . a - wl , - - gc - sections - wl , - - as - needed > linker flags ( debug ) : - wl , - - exclude - libs , libippicv . a - wl , - - exclude - libs , libippiw . a - wl , - - gc - sections - wl , - - as - needed > ccache : no > precompiled headers : no > extra dependencies : dl m pthread rt > 3 rdparty dependencies : > > opencv modules : > to be built : calib3d core dnn features2d flann gapi highgui imgcodecs imgproc ml objdetect photo stitching ts video videoio > disabled : python_bindings_generator python_tests world > disabled by dependency : - > unavailable : java python2 python3 > applications : tests perf_tests apps > documentation : no > non - free algorithms : no > > gui : none > gtk + : no > vtk support : no > > media i / <surprise> > zlib : zlib ( ver <date> ) > jpeg : libjpeg - turbo ( ver <number> . <number> - <number> ) > webp : build ( ver encoder : 0x0 2 0 f ) > png : build ( ver <date> ) > tiff : build ( ver <number> - <number> . <number> ) > jpeg <number> : build ( ver <number> . <number> ) > openexr : build ( ver <number> . <number> ) > hdr : yes > sunraster : yes > pxm : yes > pfm : yes > > video i / <surprise> > dc1394 : no > ffmpeg : no > avcodec : no > avformat : no > avutil : no > swscale : no > avresample : no > gstreamer : no > v4l / v4l2 : yes ( linux / videodev2 . h ) > > parallel framework : pthreads > > trace : yes ( with intel itt ) > > other third - party libraries : > intel ipp : <number> . <number> gold [ <number> . <number> ] > at : / opt / opencv455 / build / 3 rdparty / ippicv / ippicv_lnx / icv > intel ipp iw : sources ( <number> . <number> ) > at : / opt / opencv455 / build / 3 rdparty / ippicv / ippicv_lnx / iw > va : no > lapack : no > eigen : no > custom hal : no > protobuf : build ( <number> . <number> ) > > opencl : yes ( no extra features ) > include path : / opt / opencv455 / opencv / 3 rdparty / include / opencl / <number> > link libraries : dynamic load > > onnx : no > > python ( for build ) : / usr / bin / python3 > > java : > ant : no > jni : no > java wrappers : no > java tests : no > > install to : / usr / local > - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - > > configuring done # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question < - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with question without real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch - - > - [x ] i updated to latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only latest release for each branch . the ticket is closed , if the problem is not reproduced with modern version . - - >",2
opencv/opencv,"bug compiling opencv - <number> . <number> on raspios_bullseye64 with "" / usr / include / c + + / <number> / complex "" hi , after installing opencv - <number> . <number> on raspios64 with libcamera and gstreamer in place , i wanted to compile the example <url> / main . zip . i had an error on including opencv ( first line of main . cpp ) with "" / usr / include / c + + / <number> / complex , line <number> "" if i remember correctly . i uninstalled <number> . <number> to put <number> . <number> which does not include this file and had no problems compiling .",2
opencv/opencv,"javascript lut support resolves # <number> - [x ] validated with emsdk <number> . <number> ` ` ` force_builders = custom build_image : docs = docs - js : <number> build_image : custom = javascript buildworker : custom = linux - <number> , linux - <number> , linux - f1 ` ` `",1
opencv/opencv,"get mat in a blob # # # describe the feature and motivation i think it could be usefull to get a specific mat in a blob to read or write data # # # additional context code could be ` ` ` /* * * return a specific mat in a blob . * if dims blob is less or equal to <number> ( n rows x m columns ) blob is return * if dims blob is <number> blob is blob is ( h x n x m array ) mat at ( coord ( <number> ) , <number> , <number> ) is returned . * if dims blob is r blob is blob is ( t x h x n x m array ) mat at ( coord ( <number> ) , coord ( <number> ) , <number> , <number> ) is returned . * */ mat getmatinblob ( mat blob , vector <int> coord , int poschannel = dnn_layout_nchw ) { } ` ` `",1
opencv/opencv,"g - api cuda & tensort execution providers for onnxrt backend # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"g - api openvino execution provider for onnxrt backend # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"core : add broadcast should work as [ ` np . broadcast_to ` ] ( <url> # # benchmarks results on m1 src | dst | v1 ( mean , ms ) | v2 ( mean , ms ) | | - | - | - | - | | [ <number> , <number> , <number> , <number> ] | [ <number> , <number> , <number> , <number> ] | <number> | <number> | | [ <number> , <number> , <number> , <number> ] | [ <number> , <number> , <number> , <number> ] | <number> | <number> | | [ <number> , <number> , <number> , <number> ] | [ <number> , <number> , <number> , <number> ] | <number> | <number> | | [ <number> , <number> , <number> , <number> ] | [ <number> , <number> , <number> , <number> ] | <number> | <number> | # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders = win32 , linux32 , linux avx2 ` ` `",1
opencv/opencv,"license for cnn models of wechat_qrcode ? # # # describe the feature and motivation hi , "" recently opencv add to opencv_contrib "" cnn models for wechat_qrcode module , including the detector model and the super scale model . "" <url> cnn models is about "" object detection using cnns "" <url> i proposed add the models <url> the lack of information of the license of these "" models "" , make me think that i should ask to fedora legal , if we can bundle these binaries that are in a 3 rdparty repo ? in the opencv_contrib code , we have this license information <url> "" after write above , fedora legal team or others suggested to me to make a pull request to add the same license in the 3 rdparty repo and here it is",1
opencv/opencv,how to use opencv to erase text from images and restore the background # # # describe the feature and motivation how to use opencv to erase text from images and restore the background # # # additional context how to use opencv to erase text from images and restore the background,1
opencv/opencv,"consider half pixel mode in onnx resize # # # pull request readiness checklist resolves <url> merge with extra [ image ] ( <url> see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"type stubs : make ` cv2 . typing ` type aliases comments actual docstrings # # # describe the feature and motivation the comments in ` cv2 / typing / __init__ . pyi ` would be beneficial as actual docstrings vs ! [ image ] ( <url> # # # additional context this may be useful in other stubs too where there ' s comments , * * as long as it does not override existing docstrings * *",1
opencv/opencv,"check type in blobfromimages and blobfromimageswithparams # # # describe the feature and motivation everything is described here <url> # # # additional context i propose to check inputarraysofarray type in blobfromimages and blobfromimagewithparams ( images_ . kind ( ) = _inputarray : : std_vector_mat & & images_ . kind ( ) ! = _inputarray : : std_array_mat & & images_ . kind ( ) ! = _inputarray : : std_vector_vector ) { string error_message = "" the data is expected as inputarray : : std_vector_mat ( a std : : vector <mat> ) or _inputarray : : std_vector_vector ( a std : : vector < std : : vector < . <repeated> > > ) . "" ; cv_error ( error : : stsbadarg , error_message ) ; }",1
opencv/opencv,"do you have any plans to add a generic pre - trained model to opencv , just like using a dnn pre - trained model ? # # # describe the feature and motivation such as lara , aigc and segment - anything , and so on ? # # # additional context _no response_",1
opencv/opencv,"import and export np . float16 in python # # # pull request readiness checklist * also , fixes ` cv : : norm ` with ` norm_inf ` and ` cv_16f ` resolves <url> see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"softmaxint8 is implemented but onnx importer does not parse qlinearsoftmax # # # describe the feature and motivation [ ` qlinearsoftmax ` ] ( <url> is an operator from domain ` com . microsoft ` , which is not part of the standard onnx opset . we have ` softmaxint8 ` implemented in <url> and ` qlinearsoftmax ` should be mapped to ` softmaxint8 ` , but there is no parser for ` qlinearsoftmax ` in the [ onnx importer ] ( <url> model is attached here [ qlinearsoftmax . zip ] ( <url> network arch is as below # # # additional context _no response_",1
opencv/opencv,"lstm onnx layout attribute support # # # explanation this pr contains necessary changes to support ` layout ` attribute . this attributes is present in [ onnx ] ( <url> and [ torch ] ( <url> ( in touch it is name as ` batch_first = true ` ) libraries . when ` layout = <number> ` input to lstm layer is expected to have batch dimension first - > ` [ batch_size , sequence_length , features ] ` vs ` layout = <number> ` - default ` [ sequence_length , batch_size , features ] ` resolves <url> # # # test data test data and data generator for pr located here [# <number> ] ( <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"build dnn without protobuf # # # pull request readiness checklist dnn module can be built without protobuf for darknet , tflite , openvino , torch ( not pytorch ) models . ` ` ` cmake \ \ - dcmake_build_type = release \ \ - dbuild_list = dnn \ \ - dwith_protobuf = off \ \ - dwith_opencl = off <number> . 1 m lib / libopencv_dnn . so . <number> . <number> ` ` ` ` ` ` cmake \ \ - dcmake_build_type = release \ \ - dbuild_list = dnn \ \ - dwith_opencl = off <number> . 9 m lib / libopencv_dnn . so . <number> . <number> ` ` ` see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"[ g - api ] implement openvino <number> backend # # # pull request readiness checklist implemented basic functionality for ` openvino ` <number> g - api backend . # # # # overview - [x ] implement ` infer ` kernel with some of essential configurable parameters + ir / blob models format support . - [ ] implement the rest of kernels ` inferroi ` , ` infer2 ` + other configurable params ( e . g reshape ) - [x ] asyncrhonous execution support - [ ] remote context support see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"opencv dnn poor performance on web # # # descripe the feature and motivation hello i have c + + code that i compile using emscripten and deploy it for browser usage . now i have new feature to release and it involves running inference on small lightweight network . i decided to use opencv dnn for that since i already have opencv dependency and opencv dnn has a very convenient public api . on desktop my network runs incredibly fast , just below <number> ms . but when i put my code on the web , network runs around <number> - <number> times slower . i decomposed an issue and i noticed that the problem is in convolution blocks . when linear blocks are processed lighting fast by opencv dnn on wasm , very small and simple convolution blocks take roughly ` <number> - <number> ms ` to process . is there any way to improve opencv dnn performance on wasm ? # # # additional context _no response_",1
opencv/opencv,"[ g - api ] handle meta from multiple inputs in ie backend # # # overview since ` ie backend ` implements "" streaming "" [ ` run ( iinput & , ioutput & ) ` ] ( <url> it must take care of propagating meta from inputs . the handling implemented the same way as for the default ` gislandmodel : : run ` since ` post ` is done in ` postoutputs ` / ` postoutputslist ` callback functions , meta collected and moved to ` iecallcontext ` . # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"cannot load yolov8n - pose onnx model # # # descripe the feature and motivation ultralytics has just released yolov8 - pose estimation models . but i cannot load them in opencv dnn . it ' d be really nice to support their models - i am forced to use onnxruntime . here is the model i exported from their ` yolov8n - pose . pt ` with default parameters : [ yolov8n - pose . onnx ] ( <url> the error i am getting : ` ` ` file "" / home / dizcza / projects / airtouch / edgeai - yolov5 / onnx_inference / yolo_pose_onnx_inference . py "" , line <number> , in inference_video net = cv2 . dnn . readnet ( model_path ) cv2 . error : opencv ( <number> . <number> ) / io / opencv / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' handlenode ' > node [ <email> <sad> ( onnx_node / model . <number> / dfl / reshape ) parse error : opencv ( <number> . <number> ) / io / opencv / modules / dnn / src / layers / reshape_layer . cpp : <number> : error failed ) total ( srcshape , srcrange . start , srcrange . end ) = = masktotal in function ' computeshapebyreshapemask ' ` ` ` # # # additional context i am marking the issue as a feature request cause i am aware of onnx not fully supported by opencv dnn module .",1
opencv/opencv,"imgcodecs : tiff to encode for cv_32s with compression params fix <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"dnn : support more operators in cann backend this pr adds the support of following layers : - [x ] sub - [x ] prelu - [x ] deconv - [x ] also warn users if backend is switched back to default if some of the layers are not supported . - [ ] [ dropped ] lstm hacks ( adding layers ) were introduced which makes it even harder to build the graph for cann backend . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"load image in tutorials # # # descripe the feature and motivation some images are in tutorials but not in samples / data . findfiles cannot be used source code example doc / tutorials / imgproc / histograms / back_projection / images this [ sample ] ( <url> be changed int main ( int argc , char * argv [ ] ) { / / [ read the image ] commandlineparser parser ( argc , argv , "" { <user> | back_projection_theory0 . jpg | input image } "" ); samples : : addsamplesdatasearchsubdirectory ( "" . / doc / tutorials / imgproc / histograms / back_projection / images "" ); mat src = imread ( samples : : findfile ( parser . get <string> ( "" <user> "" ) ) ); ` ` ` is it a good idea ? # # # additional context _no response_",1
opencv/opencv,"support videocapture cap_prop_auto_wb and cv_cap_prop_white_balance_blue_u for dshow # # # pull request readiness checklist see details at <url> - [ ok ] i agree to contribute to the project under apache <number> license . - [ ok ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ok ] the pr is proposed to the proper branch - [ ok ] there is a reference to the original bug report and related work <url> <url> # # # before apply this pull request console output . before awb setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb : - <number> after awb disable setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb : - <number> after awb enable setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb : - <number> after manual wb ( and disable awb ) setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb : - <number> # # # after apply this pull request console output . before awb setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb : <number> after awb disable setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb : <number> after awb enable setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb : <number> after manual wb ( and disable awb ) setting cap_prop_white_balance_blue_u : <number> cap_prop_auto_wb # # # test code [ opencvvideocaptest . zip ] ( <url>",1
opencv/opencv,"added qr_code data flip support , flip and retry after first ecc failure * * merge with extra * * fixes # <number> , fixes # <number> , fixes # <number> added quirc_flip ( ) method to horizontally flip the data . when the decoder fails to ecc the data we flip the image , and try one more time . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"add detect qr with aruco using aruco to detect finder patterns to search qr codes . todo ( in next pr ) add single qr detect ( update ` detect ( ) ` and ` detectanddecode ( ) ` ) - need reduce full enumeration of finder patterns - need add finder pattern info to ` decode ` step - need to merge the pipeline of the old and new algorithm [ current results :]( <url> + <percent> total detect , + <percent> total decode in opencv [ qr benchmark ] ( <url> [ res1 ] ( <url> <percent> detect , <percent> decode vs <number> detect , <percent> decode in default [ main . py . txt ] ( <url> ! [ res2 ] ( <url> add new info to [ google docs ] ( <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"proposal : delay load option for opencv modules ? # # # descripe the feature and motivation in # <number> it was discussed to optionally enable a delay load option of opencv ' s modules on windows . this means that modules with heavy dependencies - for example the python bindings with enabled cuda support and contrib build - could delay load their dependencies . this yields a more flexible library distribution process by allowing the user to only distribute the actually needed instead of all modules , i . e . ignore unused dlls . as we recently worked on integrating the delay load option for cuda libraries ( cf . # <number> and # <number> ) , it is relatively straightforward to integrate this the ` / delayload : opencv_ <module> <version> . dll ` flag for all enabled modules ( exepct core as this is always required ) and introduce a cmake variable ` opencv_enable_delayload ` that controls whether these flags are set or not . still , we wanted to propose / discuss this feature before implementing it . if you think this is a useful feature , the main question is in which cmake script it should be implemented . # # # additional context _no response_",1
opencv/opencv,"add gelu layer for vision transformers this pr adds the cpu and ocl kernels of gelu and gelu - approximation layers . merge with <url> references <url> - <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"added argument to print notice in ` roiselector . cpp ` related issue i have added a printnotice argument to ` selectroi ` ( and it ' s overload ) and ` selectrois ` functions . i have also updated the function declarations in ` highgui . hpp ` . tested by building locally . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"adding hevc / h265 fourcc support to msmf video writer adding hevc / h265 fourcc support to msmf video writer . i have verified it with my own video input stream , and it works well on my workstation . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"charuco pre460 pattern support add support for certain charuco board patterns as they had been generated with opencv contrib version prior <number> . <number> . the pull request adds a ` setlegacyparameter ( bool ) ` method to the charuco class to allow switching to the old board design as described in <url> default setting for this parameter is ` false ´ to remain compatible with opencv contrib <number> . <number> and opencv <number> . <number> . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"draw multiple boxes in one shot # # # descripe the feature and motivation with the current development of a lot of object detection models , sometimes drawing many boxes like <number> or <number> boxes could be time - consuming in python . i wonder if opencv would like to consider a function to draw many boxes in one shot . so it will speed up the process instead of drawing one by one using for loop . # # # additional context _no response_",1
opencv/opencv,"python bindings : overload resolution failed , "" data type = <number> "" , should be called out as numpy array of ` dtype = object ` # # # describe the feature and motivation overload resolution should check a numpy array ' s ` dtype ` for being ` object ` , and in that case emit a useful error message like > numpy array dtype is ` object ` , which is not supported . check array contents . # # # additional context beginners often have trouble with ` imread ( ) ` . it will not throw an exception but return ` none ` , silently , and most tutorials do not bother checking for that . further processing may produce numpy arrays of ` dtype = object ` . ` ` ` python img = none # cv . imread ( "" does_not_exist . png "" ) res = np . hstack ( [ img , img ] ) # put side by side cv . imwrite ( "" foo . png "" , res ) ` ` ` ( [ source ] ( <url> calling ` imwrite ( ) ` with a numpy array of ` dtype = object ` will throw this mysterious error that says : ` ` ` text cv2 . error : opencv ( <number> . <number> ) : - <number> : error : ( - <number> : bad argument ) in function ' imwrite ' > overload resolution failed - img data type = <number> is not supported > - expected ptr < cv : : umat > for argument ' img ' ` ` ` ( behavior exists with v4 . <number> and v4 . <number> at least ) * * this does not help . * * data type <number> would decode to be ` cv_8sc3 ` , which this obviously * is not * . mentioning the ` ptr < cv : : umat > ` strikes me as irrelevant since the overload resolution already accepted the numpy array , merely complains about its element type .",1
opencv/opencv,"update usac # # # pull request readiness checklist - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"dnn : add layer normalization for vision transformers merge with <url> - [x ] add layer norm onnx parser - [x ] add layer norm impl - [x ] add layer norm onnx simplifier for both cases of constants being constant and initializer - [x ] add test model generation code for layer_norm_expanded and layer_norm_expanded_initializer benchmark : | layer | mean ( ms ) | median ( ms ) | min ( ms ) | | - | - | - | - | | layer norm expanded | <number> | <number> | <number> | | layer norm ( this pr ) | <number> | <number> | <number> | * with size 1 x50x768 on apple m1 . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders = linux opencl ` ` `",1
opencv/opencv,"switch to new openvino api after <number> release * use openvino runtime api ( aka tensor api or api <number> ) which has been introduces in <number> * remove ` inferenceengine : : dataptr ` completely * internal dynamism feature works only with a new api . actual for faster - * family models and with layers such as nonzero , top - k and others . this feature may improve performance . - [x ] tested with openvino <number> ( [ ci ] ( <url> - [x ] tested with openvino <number> ( [ ci ] ( <url> - [ ] tested with old openvino ( for example , <number> ) - (* alalek <emphasis> * : older versions are not supported on <number> . x branch ) # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders = custom xbuild_image : custom = ubuntu - openvino - <number> . <time> . <number> build_image : custom = ubuntu - openvino - <number> . <time> . <number> test_modules : custom = dnn , python2 , python3 , java , gapi , video buildworker : custom = linux - <number> # disabled due high memory usage test_opencl : custom = on test_bigdata : custom = <number> test_filter : custom =* allow_multiple_commits = <number> ` ` `",1
opencv/opencv,"added cv : : hasnonzero ( ) ` cv : : hasnonzero ( ) ` is semantically equivalent to ( ` cv : : countnonzero ( ) > <number> ` ) but stops parsing the image when a non - zero value is found , for a performance gain - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake this pull request might be refused , but i submit it to know if further work is needed or if i just stop working on it . the idea is only a performance gain vs ` countnonzero ( ) > <number> ` at the cost of more code . reasons why it might be refused : - this is just more code - the execution time is "" unfair "" / "" unpredictable "" since it depends on the position of the first non - zero value - the user must be aware that default search is from first row / col to last row / col and has no way to customize that , even if his use case lets him know where a non zero could be found - the pr in its current state is using , for the ocl implementation , a mere ` countnonzero ( ) > <number> ` ; there is not much sense in trying to break early the ocl kernel call when non - zero is encountered . so the ocl implementation does not bring any improvement . - there is no ipp function that can help ( ` countnonzero ( ) ` is based in ` ippcountinrange ` ) - the pr in its current state might be slower than a call to ` countnonzero ( ) > <number> ` in some cases ( see "" challenges "" below ) reasons why it might be accepted : - the performance gain is huge on average , if we consider that "" on average "" means "" non zero in the middle of the image "" - the "" missing "" ipp implementation is replaced by an "" open - cv universal intrinsics "" implementation - the pr in its current state is almost always faster than a call to ` countnonzero ( ) > <number> ` , is only slightly slower in the worst cases , and not even for all matrices * challenges <emphasis> * the worst case is either an all - zero matrix , or a non - zero at the very last position . in such a case , the ` hasnonzero ( ) ` implementation will parse the whole matrix like ` countnonzero ( ) ` would do . but we expect the performance to be the same in this case . and ` ippcountinrange ` is hard to beat there is also the case of very small matrices (<= 3 2 x32 . <repeated> ) in 8 b , where the simd can be hard to feed . for all cases but the worse , my custom ` hasnonzero ( ) ` performs better than ` ippcountinrange ( ) ` for the worst case , my custom ` hasnonzero ( ) ` performs better than ` ippcountinrange ( ) ` * except for large matrices of type cv_32s or cv_64f * ( but surprisingly , not cv_32f ) . the difference is small , but it exists ( and i do not understand why ) . for very small cv_8u matrices ` ippcountinrange ( ) ` seems unbeatable . here is the code that i use to check timings ` ` ` / / test cv : : hasnonzero ( ) vs ( cv : : countnonzero ( ) > <number> ) for different matrices sizes , types , strides . <repeated> { cv : : setrngseed ( <number> ); const std : : vector < cv : : size > sizes = { { <number> , <number> } , { <number> , <number> } , { <number> , <number> } , { <number> , <number> } , { <number> , <number> } , { <number> , <number> } , { <number> , <number> } , { <number> , <number> } , { <number> , <number> }}; const std : : vector <int> types = { cv_8u , cv_16u , cv_32s , cv_32f , cv_64f } ; const size_t iterations = <number> ; for ( const cv : : size & size : sizes ) { for ( const int type : types ) { for ( int c = <number> ; c < <number> ; + + c ) { const bool continuous = ! c ; for ( int i = <number> ; i < <number> ; + + i ) { cv : : mat m = continuous ? cv : : mat : : zeros ( size , type ) : cv : : mat ( cv : : mat : : zeros ( cv : : size ( <number> * size . width , size . height ) , type ) , cv : : rect ( cv : : point ( <number> , <number> ) , size ) ); const bool nz = ( i <= <number> ); const unsigned int nzoffsetrange = <number> ; const unsigned int nzoffset = cv : : randu < unsigned int > ( ) % nzoffsetrange ; const cv : : point pos = ( i = = <number> ) ? cv : : point ( nzoffset , <number> ) : ( i = = <number> ) ? cv : : point ( size . width / <number> - nzoffsetrange / <number> + nzoffset , size . height / <number> ) : ( i = = <number> ) ? cv : : point ( size . width - <number> - nzoffset , size . height - <number> ) : cv : : point ( <number> , <number> ); std : : cout < < "" = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = "" < < std : : endl ; std : : cout < < "" size : "" < < size < < "" type : "" < < type < < "" continuous = "" < < ( continuous ? "" true "" : "" false "" ) < < "" iterations : "" < < iterations < < "" nz = "" < < ( nz ? "" true "" : "" false "" ); std : : cout < < "" pos = "" < < ( ( i = = <number> ) ? "" begin "" : ( i = = <number> ) ? "" middle "" : ( i = = <number> ) ? "" end "" : "" none "" ); std : : cout < < std : : endl ; cv : : mat mask = cv : : mat : : zeros ( size , cv_8uc1 ) ; mask . at < unsigned char > ( pos ) = 0 xff ; m . setto ( cv : : scalar : : all ( <number> )); m . setto ( cv : : scalar : : all ( nz ? <number> : <number> ) , mask ) ; std : : vector <bool> results ; std : : vector <double> timings ; { bool res = false ; auto ref = cv : : gettickcount ( ); for ( size_t k = <number> ; k < iterations ; + + k ) res = cv : : hasnonzero ( m ) ; auto now = cv : : gettickcount ( ); const bool error = ( res ! = nz ) ; if ( error ) printf ( "" ! <repeated> error ! <repeated> \ \ r \ \ n "" ); results . push_back ( res ) ; timings . push_back ( <number> . *( now - ref ) / cv : : gettickfrequency ( )); } { bool res = false ; auto ref = cv : : gettickcount ( ); for ( size_t k = <number> ; k < iterations ; + + k ) res = ( cv : : countnonzero ( m ) > <number> ); auto now = cv : : gettickcount ( ); const bool error = ( res ! = nz ) ; if ( error ) printf ( "" ! <repeated> error ! <repeated> \ \ r \ \ n "" ); results . push_back ( res ) ; timings . push_back ( <number> . *( now - ref ) / cv : : gettickfrequency ( )); } const size_t besttimingindex = ( std : : min_element ( timings . begin ( ) , timings . end ( ) ) - timings . begin ( )); if ( ( besttimingindex ! = <number> ) || ( std : : find_if_not ( results . begin ( ) , results . end ( ) , [ & ] ( bool r ) { return ( r = = nz ) ;}) ! = results . end ( ) ) ) { std : : cout < < "" cv : : hasnonzero \ \ t \ \ t => "" < < results [ <number> ] < < ( ( results [ <number> ] ! = nz ) ? "" error "" : "" "" ) < < "" perf : "" < < timings [ <number> ] < < "" ms => "" < < ( iterations / timings [ <number> ]* <number> ) < < "" im / s "" < < ( ( besttimingindex = = <number> ) ? "" * "" : "" "" ) < < std : : endl ; std : : cout < < "" cv : : countnonzero \ \ t => "" < < results [ <number> ] < < ( ( results [ <number> ] ! = nz ) ? "" error "" : "" "" ) < < "" perf : "" < < timings [ <number> ] < < "" ms => "" < < ( iterations / timings [ <number> ]* <number> ) < < "" im / s "" < < ( ( besttimingindex = = <number> ) ? "" * "" < < std : : endl ; } } } } } } ` ` ` here is a report of this benchmark ( it only reports timings when ` cv : : countnonzero ( ) ` is faster ) my cpu is an intel core i7 <number> @ <number> . 6 0 ghz ` ` ` = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle cv : : hasnonzero => <number> perf : <number> . 3 5 3 7 6 4 ms => <number> . 8 2 6 7 4 e + <number> im / s cv : : countnonzero => <number> perf : <number> . 2 8 2 0 4 4 ms => <number> . 5 4 5 5 5 e + <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end cv : : hasnonzero => <number> perf : <number> . 6 1 0 4 7 8 ms => <number> . 6 3 8 0 6 e + <number> im / s cv : : countnonzero => <number> perf : <number> . 2 8 3 1 8 2 ms => <number> . 5 3 1 3 e + <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none cv : : hasnonzero => <number> perf : <number> . 6 3 0 1 1 5 ms => <number> . 5 8 7 0 1 e + <number> im / s cv : : countnonzero => <number> perf : <number> . 2 8 2 0 4 4 ms => <number> . 5 4 5 5 5 e + <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end cv : : hasnonzero => <number> perf : <number> . 6 0 7 3 4 7 ms => <number> . 6 4 6 5 1 e + <number> im / s cv : : countnonzero => <number> perf : <number> . 4 6 7 0 3 7 ms => <number> . 1 4 1 1 6 e + <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none cv : : hasnonzero => <number> perf : <number> . 6 1 8 1 6 2 ms => <number> . 6 1 7 7 e + <number> im / s cv : : countnonzero => <number> perf : <number> . 4 6 8 1 7 5 ms => <number> . 1 3 5 9 5 e + <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end cv : : hasnonzero => <number> perf : <number> . 3 8 1 ms => <number> im / s cv : : countnonzero => <number> perf : <number> . 5 6 9 ms => <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none cv : : hasnonzero => <number> perf : <number> . 5 3 ms => <number> im / s cv : : countnonzero => <number> perf : <number> . 8 9 4 ms => <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end cv : : hasnonzero => <number> perf : <number> . 9 2 ms => <number> im / s cv : : countnonzero => <number> perf : <number> . 3 7 ms => <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none cv : : hasnonzero => <number> perf : <number> . 8 7 ms => <number> im / s cv : : countnonzero => <number> perf : <number> . 7 8 ms => <number> im / s * = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = true iterations : <number> nz = false pos = none = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = begin = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = middle = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = true pos = end = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = size <sad> <number> x <number> ] type : <number> continuous = false iterations : <number> nz = false pos = none done ` ` `",1
opencv/opencv,"support one - time audio video reading added to gsrtreamer audio + video capturing - added audio video samples synchronization <cut/> ` ` ` # linux opencl force_builders = linux , docs , linux x64 debug , custom build_image : linux opencl = ubuntu : <number> buildworker : linux opencl = linux - <number> build_image : custom = gstreamer : <number> buildworker : custom = linux - <number> ` ` `",1
opencv/opencv,"timeouts support for gstreamer backend address <url> used the same defaults as it ' s done for ffmpeg # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders = custom build_image : custom = gstreamer : <number> buildworker : custom = linux - <number> ` ` `",1
opencv/opencv,"videoio / ffmpeg : added cv_16uc1 read / write support partially resolves # <number> replaces # <number> and # <number> * _videocapture_ : we can now disable bgr conversion using parameter for the ffmpeg backend and return image in original format , straight from decoder . however this feature has many limitations , for example it is not possible to return multiplanar images yet - new interface or additional processing is necessary for this . so i added a warning with some details which will be printed when this feature is enabled . basically 8 uc1 and 1 6 uc1 can now be returned from _videocapture_ in addition to bgr . * _videowriter_ : we can set depth using parameter during object initialization . it can be 8 u or 1 6 u . in combination with _iscolor_ it gives us three supported formats : 8 uc3 , 8 uc1 and 1 6 uc1 ; and one unsupported : 1 6 uc3 . 1 6 uc1 can be handled by the ` ffv1 ` codec . * several debug and warning log messages have been added for convenience and safety * the new test writes a video and then reads it back , frames are not compared with the original , only format and count is verified . unsupported format combination is also checked in this test which is not very good , but i believe is fine for now . * ffv1 codec / container has been added to generic ffmpeg and videoio tests ( regular bgr ) note : some other codecs had _hidden_ support for 1 6 uc1 , but i did not test them ( png and rawvideo ) . note i wanted to modify # <number> - add a test , fix minor issues , but it turned out that i had to rewrite <percent> of changes made in that pr , so i decided to publish it as a brand new one . ` ` ` buildworker : custom = linux - <number> build_image : custom = ffmpeg - master ` ` `",1
opencv/opencv,"dnn : let matmul can work when both two inputs are const * * merge with extra * * this pr is try to solve the ` matmul ` node problem of <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"support ffmpeg command line syntax with ffmpeg backend # # # describe the feature and motivation to support complex stream specifiers for videowriter / videocapture , conversion options and filter graphs with the ffmpeg - backend , i would like to introduce a syntax similar ( or identical ? ) to what ffmpeg ( <url> offers . a simple example of what i have in mind : ` ` ` c + + videocapture ( "" - v trace - f v4l2src - input_format mjpeg - i / dev / video0 - vf scale = <number> <time> <number> "" , cap_ffmpeg ) cap ; ` ` ` before i implement this is it a good idea ? * what should be the limits ? i am ( sadly ) aware i can not simply use the ffmpeg code . # # # additional context _no response_",1
opencv/opencv,"dnn batched nms resolves # <number> . merge with <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"feature request within usac framework : allow setting polishingmethod to nonepolisher within usac framework , a final refinement of the best estimated model is always done using all the inliers found . however , in the case that only the inliers need to be known ( or when a non - refined model suffices ) , this last refinement is not needed . the motivation behind this resides in infering the previous quantities ( inliers and / or non - refined model ) faster . the increase in execution speed can be significant . for instance , when solving the perspective - n - point problem , usac uses dls ( [ j . hesch , <number> ] ( <url> as the non - minimal solver which has significant execution time w . r . t . the number of points ( e . g . see fig . <number> of ( [ s . urban , <number> ] ( <url> in this specific case , this also would allow to consider different pnp methods for the last refinement . within my little knowledge of usac ' s implementation , i think that this could be done by allowing to set ` poilishingmethod ` to ` nonepolisher ` ( defined [ here ] ( <url> since this is checked when deciding to polish the model : <url> which i believe the previous condition will always hold , since the polishing method is hard coded here and seems to not be reassigned after . thanks in advance ,",1
opencv/opencv,"can opencv support to push video streams to video server , like rtsp / rtmp . <repeated> ? # # # descripe the feature and motivation nowadays , video live is popular , opencv can receive rtsp / rtmp / usb . etc ， but it cloudn ' t support to transform / push video stream to video server . it ' s possible to add this new feature ? # # # additional context _no response_",1
opencv/opencv,"is it possible to pass in multiple conf_thres in cv : : dnn : : nmsboxes ？ # # # descripe the feature and motivation now i want to pass in multiple conf_thres for each label , set different conf_thres for different labels , i found this feature to be implemented in the python version , but i can not find anything related to the c + + version , i wonder if this is achievable and how to do ? # # # additional context _no response_",1
opencv/opencv,"dnn : support onnx tile fixes # <number> merge with <url> onnx doc for tile : - opset <number> : <number> inputs ( <url> - opset <number> : <number> inputs ( <url> - opset <number> inputs ( <url> - opset <number> is basically the same as opset <number> for inference . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"opencv cannot import onnx model : step >= <number> in function ' cv : : dnn : : slicelayerimpl : : slicelayerimpl ' # # # system information opencv => python opencv - python - rolling <number> . <number> operating system / platform windows <number> <number> bit python => <number> . <number> # # # detailed description i converted the decoupledseg from paddleseg to onnx : <url> this fails to load in opencv <number> pre - release : ` ` ` [ error : <number> <user> . <number> ] global d :\\ a \ \ opencv - python \ \ opencv - python \ \ opencv \ \ modules \ \ dnn \ \ src \ \ onnx \ \ onnx_importer . cpp ( <number> ) cv : : dnn : : dnn4_v20220524 : : onnximporter : : handlenode dnn / onnx : error during processing node with <number> inputs and <number> outputs : [ slice ] <sad> onnx_nodep2o . slice . <number> ) from domain = ' ai . onnx ' traceback ( most recent call last ) : file "" d :\\ local \ \ devel \ \ python \ \ opencv \ \ dnn_segmentation_paddle_decoupledseg_cityscapes \ \ inference . py "" , line <number> , in <module> model = cv2 . dnn . readnet ( model_path ) cv2 . error : opencv ( <number> . <number> - dev ) d :\\ a \ \ opencv - python \ \ opencv - python \ \ opencv \ \ modules \ \ dnn \ \ src \ \ onnx \ \ onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' cv : : dnn : : dnn4_v20220524 : : onnximporter : : handlenode ' > node [ <email> <sad> ( onnx_node ! p2o . slice . <number> ) parse error : opencv ( <number> . <number> - dev ) d :\\ a \ \ opencv - python \ \ opencv - python \ \ opencv \ \ modules \ \ dnn \ \ src \ \ layers \ \ slice_layer . cpp : <number> : error : ( - <number> : assertion failed ) step >= <number> in function ' cv : : dnn : : slicelayerimpl : : slicelayerimpl ' ` ` ` # # # steps to reproduce ` ` ` model = cv2 . dnn . readnet ( model_path ) ` ` ` find the onnx file here # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [x ] there is reproducer code and related data files ( videos , images , onnx , etc )",1
opencv/opencv,"openexr encoder capability to set the dwa compression level extracted from # <number> ( cherry picked from commit aa276ece66265dcf07af5f840933377d2106c871 ) # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"opencv dnn net = cv2 . dnn . readnetfromonnx ( w ) # # # system information python <number> . <number> opencv version : ' <number> . <number> ' os : windows10 # # # detailed description i trained the yolov5 model on my own custom dataset . i converted "" . pt "" file to onnx file . the onnx model i created works fine . i converted onnx file to quantize onnx file . it cannot read the file "" yolov5n_quant . onnx "" that i created . the error is as follows . onnx for onnx opencv dnn inference . <repeated> [ error : <number> <user> . <number> ] global d :\\ a \ \ opencv - python \ \ opencv - python \ \ opencv \ \ modules \ \ dnn \ \ src \ \ onn_importer . cpp ( <number> ) cv : : dnn : : dnn4_v20220524 : : onnximporter : : handlenode dnn / onnx : euring processing node with <number> inputs and <number> outputs : [ dynamicquantizelinear ] <sad> onnx_nages_quantizelinear ) from domain = ' ai . onnx ' traceback ( most recent call last ) : file "" g <annoyed> yolov5 - master / detect . py "" , line <number> , in <module> main ( opt ) file "" g <annoyed> yolov5 - master / detect . py "" , line <number> , in main run ( * * vars ( opt ) ) file "" c :\\ users \ \ anaconda3 \ \ envs \ \ yolov5 \ \ lib \ \ site - packages \ \ torch \ \ autograd \ \ gradpy "" , line <number> , in decorate_context __init__ net = cv2 . dnn . readnetfromonnx ( w ) cv2 . error : opencv ( <number> . <number> ) d :\\ a \ \ opencv - python \ \ opencv - python \ \ opencv \ \ modules \ \ dnn \ \ src \ \ o > node [ <email> <sad> ( onnx_nodeimages_quantizelinear ) parse errscale not found in const blobs in function ' cv : : dnn : : dnnscale not found in const b4_v20220524 : : onnximporter : : getblob ' # # # steps to reproduce model input : ! [ image ] ( <url> model output # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files ( videos , images , onnx , etc )",1
opencv/opencv,"npnp solver # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"dnn : add new api blobfromimageparam the purpose of this pr add new api ` blobfromimageparam ` to extend ` blobfromimage ` api . it can support the different datalayout ( nchw or nhwc ) , and letter_box . <number> . ~ ~ ` blobfromimage ` can output ` cv_16f ` ~ ~ # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"g - api expose all imgproc operations to python # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake # # # motivation python bindings are available since a long time , but only a few operations ( ` operation : : on ( . <repeated> ) ` wrappers ) were exposed . there was a great plan to implement feature in python parser that could automatically detect ` g - api ` operation ( via ` gapi_typed_kernel ` macro or so ) and expose it into python , but this functionality is more about giving an opportunity to user to implement python ` kernels ` for already existing in g - api operations . this pr is going to expose just ` operation : : on ` wrappers to python in order to give user everything that is available from c + + , because now , for developers who do not build from source and change the code only available a small amount of functionality . since a lot of developers use ` opencv ` from ` pip ` let us expose it once and forever . great example of g - api usage : <url> todo list : - [x ] expose ` core ` - [x ] expose ` imgproc ` - [ ] expose ` video ` - [ ] expose ` stereo ` - [ ] other stuff ( e . g constant initialization for ` g - type ` ' s & some compiler args ) # # # problems some of ` imgproc ` operations are still not exposed because of complexity of wrapping their return types to python . * ` garray < garray <point> > findcontours ( . <repeated> ) ` - <number> overloads * ` std : : tuple < garray < garray <point> > , garray <vec4i> > findcontoursh ( . <repeated> ) ` - <number> overloads * ` gopaque <vec4f> fitline2d ( . <repeated> ) ` - <number> overloads * ` gopaque <vec6f> fitline3d ( . <repeated> ) ` - <number> overloads * ` gmatp nv12torgbp ( . <repeated> ) ` * ` gmatp nv12tobgrp ( . <repeated> ) ` * ` gmatp resizep ( . <repeated> ) ` issue",1
opencv/opencv,"introduce libavdevice to make v4l2 available to the ffmpeg backend # # # descripe the feature and motivation you can follow my struggle to get ffmpeg to capture from a v4l2 device while accepting my precise options , here by including libavdevice and calling ` ` ` avdevice_register_all ( ); ` ` ` in my own code i was finally able to do it . anyway , i think that call belongs into the ffmpeg backend ( ` ` ` void cvcapture_ffmpeg : : init ( ) ` ` ` ? ) . # # # additional context _no response_",1
opencv/opencv,"log a debug message if a capture backend is generally available but is not capabable of either capture by index or capture by filename # # # descripe the feature and motivation i am working on a few issues pertaining hw accelerated videoio and i experimented with the different backends and settings to get my application to capture from v4l2 while using vaapi for decoding among a few other things . anyway it took me considerable time to realize that e . g . the ffmpeg backend does not support selecting the capture device by index . i would like to have at least debug message in place to alert the user to as why capturing failed . # # # additional context ` ` ` c + + videocapture cap ( <number> , cap_ffmpeg ) ; ` ` ` the above line fails without a hint on why .",1
opencv/opencv,"dnn : add the cann backend merge with adding a wiki page : <url> # # benchmark environment ( provided by ascend ) : <number> . cpu : <number> - core aarch64 , freq unknown <number> . npu : ascend <number> time is in millisecond . the time of first run is excluded . | model | cpu backend | cann backend ( this pr ) | native cann | | - | - | - | - | | pp - resnet50 | <number> | <number> | <number> | | mobilenetv1 | <number> | <number> | <number> | | yolox | <number> | <number> | <number> | | alexnet | <number> | <number> | <number> | * notes <emphasis> * : <number> . ` pp - resnet50 ` , ` mobilenetv1 ` and ` yolox ` are from <url> <number> . ` native cann ` stands for loading and inferring a atc - converted om model with cann interfaces . atc is the model conversion from onnx / tf / caffe to om tool provided by cann . ` native cann ` only measures the time of ` aclmdlexecute ` . <number> . ` cann backend ( this pr ) ` stands for loading onnx / tf / caffe models with opencv parsers and inferring the om model built by cann backend . ` cann backend ( this pr ) ` measures the time of ` net . forward ( ) ` , including ` aclmdlexecute ` and some other overheads . models built by cann backend and converted by atc have the same time of ` aclmdlexecute ` . <number> . differences between the implementations of this pr and the previous one : - this pr : use ` aclgrphbuildmodel ` to fully optimize the graph and use ` aclmdlexecute ` to forward the graph directly . - previous ` aclopcompileandexecute ` to call and run operator on the fly . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,dnn : need support of the greaterorequal operator from onnx # # # descripe the feature and motivation there is a contributor trying to contribute a model to opencv zoo . link to the pull request and this model requires the support of greaterorequal operator from onnx . # # # additional context there might be other operators that are not supported in the current version of opencv . need to generate a list of operators to check whether there are other unsupported operators .,1
opencv/opencv,"dnn : add enablewinograd api for net two task in the pr add ` enablewinograd ` api for net <number> . disable winograd branch in try quantize func . winograd convolution will effect the accuracy , which may lead to more errors in the calibration process of dnn on - fly - quantize ( ` net . quantize ( ) ` ) . this pr wants to disable the winograd branch in convolution computation . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"enable issue template chooser this pull request enables template chooser with templates for bug report and feature request . see my fork for the effect : <url> note these changes only take effect if they are put in the default branch . github documentation for configuring issue templates # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"stereo calibration rotation and transformation vectors for each calibration object # # # motivation for feature extension of stereocalibrate function for both , pinhole and fisheye model , to return the translation and rotation vectors between each calibration object and the coordinate system of the first camera of the stereo pair . this feature is helpful to evaluate the individual image pairs used for calibration . this feature is in particular interesting for the fisheye model since its stereocalibrate function has not provided a parameter to obtain the reprojection errors per stereo image pair . with these per - view transformations available , it is now possible to calculate these reprojection errors . in addition , for the pinhole model , it is also interesting to not only get the per - view rms errors , but also statistics within one view . for the implementation , the single camera calibration methods were used as example and all previous available function calls should still work . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"extracted matches_confindece_thresh as stitching matcher parameter . fixes # <number> replacement for <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"ffmpeg / <number> . <kiss> update ffmpeg wrapper <number> * * merge with 3 rdparty * * : <url> - ffmpeg <number> . <number> - added av1 support through aom <number> . <number> : <url> - use ubuntu <number> => <number> as build image resolves # <number> previous update ` ` ` force_builders = win64 , win32 ` ` `",1
opencv/opencv,"android video writter support for h264 / h265 currently on android only mjpg encoder . i would be nice to support more formats ( h264 / h265 ) . # # # # # system information ( version ) - opencv => <number> . x - operating system / platform => android - compiler => clang # # # # # detailed description usually android devices have hardware accelerated encoders for h264 / h265 . i would be great to have from in opencv . # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files images , onnx , etc",1
opencv/opencv,"g - api : introduce abstract base classes for gexecutor and gstreamingexecutor the classes are ` gabstractexecutor ` and ` gabstractstreamingexecutor ` , respectively . the idea behind this simple refactoring is to introduce other execution policies ( implemented by executors ) in the near future . note pr replaces obsolete # <number> and # <number> - - which now can be closed . - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"tiff support <number> - bit palette requires <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake opencv_extra = <number> - bit_palette_color",1
opencv/opencv,"darknet_io . cpp : <number> : error : ( - <number> : parsing error ) unsupported activation : silu in function ' setactivation ' < - - if you have a question rather than reporting a bug please go to <url> where you get much faster responses . if you need further assistance please read [ how to contribute ] ( <url> this is a template helping you to create an issue which can be processed as quickly as possible . this is the bug reporting section for the opencv library . - - > # # # # # system information ( version ) < ! - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => <number> . <number> - operating system / platform => ubuntu <number> - compiler => gcc10 # # # # # detailed description using opencv <number> . <number> and the new yolov7 . weights and config ( . cfg ) from <url> causes the error - > cv2 / opencv - <number> . <number> / modules / dnn / src / darknet / darknet_io . cpp : <number> : error : ( - <number> : parsing error ) unsupported activation : silu in function ' setactivation ' weights - > <url> config - > <url> alternate config - > <url> # # # # # steps to reproduce ` ` ` # python3 . <number> code import cv2 # # ommited irrelevant code , the readnet method is where the issue occurs . model_input_file = "" path / to / yolov7x . weights "" model_config_file = "" path / to / yolov7x_darknet . cfg "" or "" path / to / yolov7x . cfg "" try : net = cv2 . dnn . readnet ( model_input_file , model_config_file ) except exception as e : print ( f "" exception when loading in weights and config - > { e } "" ) # # # # code continues ` ` ` < ! - - to add code example fence it with triple backticks and optional file extension ` ` ` . cpp / / c + + code example ` ` ` or attach as . txt or . zip file - - > # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [x ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [x ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",1
opencv/opencv,"remove asymmetric padding in conv layer since it is supported in cpu backend in <url> fast convolution is introduced with support for asymmetric padding in calculation . so there is no need to keep a separate padding layer for asymmetric padding in convolution layer . # # regression test for convolution layer with asymmetric padding openvino , default cpu ( cpu , ocl , tengine ) , vulkan , cuda , webnn are registered for this test . # # checks on different backends - [x ] opencv cpu - [x ] opencl - [x ] openvino ( should be good since it builds its padding from pads_begin & pads_end , see code [ here ] ( <url> and [ here ] ( <url> - [x ] cuda - [ ] ~ vulkan ~ i am getting segmentation fault regardless my changes - [ ] webnn ( should be good since it builds its padding from pads_begin & pads_end , see code [ here ] ( <url> - [x ] tengine ( failed at ` test_onnx_layers . convolution_variable_weight_bias / <number> ` but should not be related to this patch ) # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"changes separated from mat 1 d support in core # <number> changes separated from # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"dnn : fp16 support on convolution 2 d # # fp16 support on arm platform this pr proposes to support fp16 backend in convolution . for now , we only support fp16 at arm aarch64 . in addition to adding fp16 , i also added ` seperateim2col ` optimization in this patch . # # how to use fp16 to speed up convolution ? ` ` ` net net = readnet ( modelpath ) ; net . setpreferabletarget ( dnn_target_cpu_fp16 ) ; net . setinput ( blob ) ; mat output = net . forward ( ); ` ` ` # # # todo list | task | status | remarks | <sad> - - - - - - - <sad> : - - - - - - - - <sad> : - - - - - - - - - - - - <sad> | convolution 2 d fp16 | : heavy_check_mark : | done | | winograd fp16 | because the current modification has reached 2 k lines , winograd fp16 will be completed in the next pr . | | | accuracy test | : heavy_check_mark : | done | | performance test | : heavy_check_mark : | done | | compiler bug | : heavy_check_mark : | done | # # # speed test for fp <number> . * * test on m1 chip , <number> threads . * * | model name | fp32 ( conv + wino ) | conv ( fp16 ) + wino ( fp <number> ) | <sad> - - - - - - - <sad> : - - - - - - - - <sad> : - - - - - - - - - - - - <sad> | resenet <number> | <number> ms | * * <number> ms * * ( <percent> speed up ) | | mobilenet v2 | <number> ms | * * <number> ms ( <percent> speed up ) * * | # # # speed test for ` seperateim2col ` trick on x86 . * * test on amd 5 6 0 0 x , <number> threads . * * | model name | <number> . x | patch | <sad> - - - - - - - <sad> : - - - - - - - - <sad> : - - - - - - - - - - - - <sad> | mobilenet v2 | <number> ms | * * <number> ms ( <percent> speed up ) * * | # # # performance test # # # # performance test of x86 platform : amd 5 6 0 0 x , with ` - perf_threas = <number> ` | name of test | <number> . x| patch | patch vs <number> . x (x - factor ) | | - - - <sad> - <sad> : - <sad> : - <sad> | name of test | <number> . x <number> | fp16pr final | fp16pr final vs <number> . x <number> (x - factor ) | | - - - <sad> - <sad> : - <sad> : - <sad> | conv1d : : conv1d : : ( gflops = <number> , k =[ <number> ] , in ={ <number> , <number> , <number> } , ocn = <number> , g = <number> , s= <number> , p =( <number> , <number> ) , bias , ocv / cpu ) | <number> | <number> | <number> | | conv1d : : conv1d : : ( gflops = <number> , k =[ <number> ] , in ={ <number> , <number> , <number> } , ocn = <number> , g = <number> , p =( <number> , <number> ) , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv1d : : conv1d : : ( gflops = <number> , k =[ <number> ] , in ={ <number> , <number> , <number> } , ocn = <number> , pm = valid , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = valid , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , s= [ <number> x <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = valid , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = valid , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = valid , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , d =[ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | # # # # performance test of arm platform m1 , with ` - perf_threas = <number> ` min ( ms ) | name of test | <number> . x| patch | <number> . x vs patch (x - factor ) | | - - - <sad> - <sad> : - <sad> : - <sad> | conv1d : : conv1d : : ( gflops = <number> , k =[ <number> ] , in ={ <number> , <number> , <number> } , ocn = <number> , g = <number> , s= <number> , p =( <number> , <number> ) , bias , ocv / cpu ) | <number> | <number> | <number> | | conv1d : : conv1d : : ( gflops = <number> , k =[ <number> ] , in ={ <number> , <number> , <number> } , ocn = <number> , g = <number> , p =( <number> , <number> ) , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv1d : : conv1d : : ( gflops = <number> , k =[ <number> ] , in ={ <number> , <number> , <number> } , ocn = <number> , pm = valid , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = valid , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , s= [ <number> x <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = valid , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = valid , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , p =( <number> , <number> ) x ( <number> , <number> ) x ( <number> , <number> ) , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv3d : : conv3d : : ( gflops = <number> , k =[ <number> x <number> x <number> ] , in ={ <number> , <number> , <number> , <number> , <number> } , ocn = <number> , pm = valid , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , p =[ <number> x <number> ] , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , g = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , d =[ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , d =[ <number> x <number> ] , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , s= [ <number> x <number> ] , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , p =[ <number> x <number> ] , bias , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu ) | <number> | <number> | <number> | | conv : : conv : : ( gflops = <number> , k =[ <number> x <number> ] , in ={ <number> , <number> , <number> , <number> } , ocn = <number> , pm = same , ocv / cpu_fp16 ) |-| <number> |-| # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"unable to load model onnx <number> . <number> or <number> . <number> # # # # # system information ( version ) - opencv => <number> . <number> / <number> . <number> - operating system / platform => macos <number> ( 2 1 f79 ) apple m1 pro - compiler => visual studio code / python / c + + # # # # # detailed description ` ` ` python : <number> . <number> [ error : <number> <user> . <number> ] global / users / runner / work / opencv - python / opencv - python / opencv / modules / dnn / src / onnx / onnx_importer . cpp ( <number> ) handlenode dnn / onnx : error during processing node with <number> inputs and <number> outputs : [ clip ] <sad> onnx_nodestatefulpartitionedcall / center_net_mobile_net_v2fpn_feature_extractor / model_1 / model / conv1_relu / relu6 ) from domain = ' ai . onnx ' traceback ( most recent call last ) : file "" / users / tony / documents / works / project / nts / cpp / python / pose . py "" , line <number> , in <module> net = cv2 . dnn . readnetfromonnx ( "" . / model_pb . onnx "" ) # 加载训练好的识别模型 cv2 . error : opencv ( <number> . <number> ) / users / runner / work / opencv - python / opencv - python / opencv / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' handlenode ' > node [ <email> <sad> ( onnx_node ! statefulpartitionedcall / center_net_mobile_net_v2fpn_feature_extractor / model_1 / model / conv1_relu / relu6 ) parse error : opencv ( <number> . <number> ) / users / runner / work / opencv - python / opencv - python / opencv / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' void cv : : dnn : : dnn4_v20220524 : : onnximporter : : parseclip ( cv : : dnn : : dnn4_v20220524 : : layerparams & , const opencv_onnx : : nodeproto & ) ' > > ( expected : ' node_proto . input_size ( ) = = <number> ' ) , where > > ' node_proto . input_size ( ) ' is <number> > > must be equal to > > ' <number> ' is <number> > ` ` ` ` ` ` c + + : 版本 : <number> . <number> [ error : <number> <user> . <number> ] global / tmp / opencv - <number> - <number> - 1 8 1 ywau / opencv - <number> . <number> / modules / dnn / src / onnx / onnx_importer . cpp ( <number> ) handlenode dnn / onnx : error during processing node with <number> inputs and <number> outputs : [ clip ] <sad> statefulpartitionedcall / center_net_mobile_net_v2fpn_feature_extractor / model_1 / model / conv1_relu / relu6 : <number> ) from domain = ' ai . onnx ' opencv ( <number> . <number> ) / tmp / opencv - <number> - <number> - 1 8 1 ywau / opencv - <number> . <number> / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' handlenode ' > node [ <email> <sad> ( statefulpartitionedcall / center_net_mobile_net_v2fpn_feature_extractor / model_1 / model / conv1_relu / relu6 : <number> ) parse error : opencv ( <number> . <number> ) / tmp / opencv - <number> - <number> - 1 8 1 ywau / opencv - <number> . <number> / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : unspecified error ) in function ' void cv : : dnn : : dnn4_v20211220 : : onnximporter : : parseclip ( cv : : dnn : : dnn4_v20211220 : : layerparams & , const opencv_onnx : : nodeproto & ) ' > > ( expected : ' node_proto . input_size ( ) = = <number> ' ) , where > > ' node_proto . input_size ( ) ' is <number> > > must be equal to > > ' <number> ' is <number> > ` ` ` # # # # # steps to reproduce <number> . download model : <url> <number> . convert model : python - m tf2onnx . convert - - saved - model . / movenet_singlepose_thunder_4 - - output model_pb . onnx <number> . load model the follow code : ` ` ` # python import cv2 print ( cv2 . __version__ ) net = cv2 . dnn . readnetfromonnx ( "" . / model_pb . onnx "" ) image = cv2 . imread ( "" person . jpeg "" ) blob = cv2 . dnn . blobfromimage ( image ) net . setinput ( blob ) out = net . forward ( ) ` ` ` ` ` ` <hashtag> include </hashtag> < opencv2 / opencv . hpp > <hashtag> include </hashtag> <iostream> <hashtag> include </hashtag> <stdexcept> using namespace cv ; using namespace cv : : dnn ; using namespace std ; int main ( ) try { system ( "" color f0 "" ); cout < < "" version : "" < < cv : : getversionstring ( ) < < endl ; string model = "" . <repeated> / model / model_pb . onnx "" ; net net = dnn : : readnet ( model ) ; if ( net . empty ( ) ) { cout < < "" 确认是否输入了空的模型文件 "" < < endl ; return - <number> ; } vector <string> layernames = net . getlayernames ( ); for ( size_t i = <number> ; i < layernames . size ( ); i + + ) { int id = net . getlayerid ( layernames [ i ] ); ptr <layer> layer = net . getlayer ( id ) ; cout < < "" 网络层数 "" < < id < < "" 网络层名称 "" < < layernames [ i ] < < "" 类型 "" < < layer - > type . c_str ( ) < < endl ; } cout < < "" ok "" < < endl ; } catch ( std : : exception const & ex ) { cerr < < ex . what ( ) < < endl ; } ` ` ` # # # # # issue submission checklist - [ ] i report the issue , it ' s not a question - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution - [x ] i updated to the latest opencv version and the issue is still there - [ ] there is reproducer code and related data files images , onnx , etc",1
opencv/opencv,"[ gsoc <number> ] spng encoder / decoder added as optional png codec * * merge with extra * * this pull request contains the implementation of pngencoder using spng library . one thing that i am not sure about is the cmake configuration . i appreciate any help on cmake configuration # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"yolov4 - csp inference on opencv <number> . <number> provides different results to native darknet inference . # # # # # system information ( version ) - opencv => <number> . <number> - operating system / platform => ubuntu <number> - source => inference on python , opencv from pip3 install opencv - python # # # # # detailed description i have a yolov4 - csp based ocr model trained from darknet ( the model was trained for a short time , just for testing purposes ) , running inference on native darknet ( <url> gets acceptable results [ darknet_inference ] ( <url> however running the same using opencv dnn gets results , which are quite different and not acceptable in this case . ! [ opencv_inference ] ( <url> as mentioned here ( <url> opencv <number> . <number> or greater should support yolov4 - csp , this was why i tested it on the latest version <number> . <number> . # # # # # steps to reproduce to reproduce i will provide google drive zip file with all the weights and python script for opencv inference . ( <url> below i will also provide the python inference script ` import cv2 import time confidence_threshold = <number> nms_threshold = <number> colors = [ ( <number> , <number> , <number> ) , ( <number> , <number> , <number> ) , ( <number> , <number> , <number> ) , ( <number> , <number> , <number> ) ] print ( "" cv2 version "" , cv2 . __version__ ) class_names = [ ] with open ( "" ocr - yolov4 - csp / classes . txt "" , "" r "" ) as f : class_names = [ cname . strip ( ) for cname in f . readlines ( ) ] frame = cv2 . imread ( "" ocr - yolov4 - csp / test1 . jpg "" ) net = cv2 . dnn . readnet ( "" ocr - yolov4 - csp / yolov4 - csp_best . weights "" , "" ocr - yolov4 - csp / yolov4 - csp . cfg "" ) <hashtag> net </hashtag> . setpreferablebackend ( cv2 . dnn . dnn_backend_cuda ) <hashtag> net </hashtag> . setpreferabletarget ( cv2 . dnn . dnn_target_cuda_fp16 ) model = cv2 . dnn_detectionmodel ( net ) model . setinputparams ( size =( <number> , <number> ) , scale = <number> / <number> , swaprb = true ) classes , scores , boxes = model . detect ( frame , confidence_threshold , nms_threshold ) end = time . time ( ) start_drawing = time . time ( ) for ( classid , score , box ) in zip ( classes , scores , boxes ) : color = colors [ int ( classid ) % len ( colors ) ] label = "" %s : % f "" % ( class_names [ classid ] , score ) cv2 . rectangle ( frame , box , color , <number> ) cv2 . puttext ( frame , label , ( box [ <number> ] , box [ <number> ] - <number> ) , cv2 . font_hershey_simplex , <number> , color , <number> ) cv2 . imwrite ( "" opencv_inference . jpg "" , frame ) ` # # # # # issue submission checklist - [ ✓ ] i report the issue , it ' s not a question - [ ✓ ] i checked the problem with documentation , faq , open issues , - [ ✓ ] i updated to the latest opencv version and the issue is still there - [ ✓ ] there is reproducer code and related data files images , onnx , etc",1
opencv/opencv,"[ gsoc ] new universal intrinsic backend for rvv this is a patch of my gsoc project whose goal is to make the existing universal intrinsic compatible with variable - length backends . thereby improving the performance of the risc - v vector ( rvv ) backend . in this patch , <number> . we added a new rvv backend . unlike the current implementation , we used the rvv type directly instead of the wrapper class , which will improve performance . currently only the necessary functions are included , mainly v_setall , v_load , v_lut for compatibility with vx_xxx and v_min , v_max for the medianblur example . <number> . to be compatible with other backends that use wrapper classes , we had to modify the existing universal intrinsic interfaces , including vtraits and function compatibility layers . the documentation has not been updated yet , we will update it when changes of api are finalized . <number> . we modified some of the existing simd code to ensure compilation , mainly by adding the packaging of the cv_simd macro <number> . we enabled the new rvv backend implementation for the imgproc module ' s medianblur as an example of how to reuse existing ui - optimized code blocks . run the opencv_test_imgproc , the test passed and result are promising ms by new implentation vs . <number> ms by current one . ` $ qemu - riscv64 - cpu rv64 , x - v = true . / bin / opencv_test_imgproc - - gtest_filter = "" imgproc_medianblur * "" ` # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"v4l2 multi planar - v4l2 : add multi - planar capture support - v4l2 data order of conversion from nv [ <number> | <number> ] to rgb ( relates # <number> ) # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders = custom build_image : custom = centos : <number> buildworker : custom = linux - f1 ` ` `",1
opencv/opencv,"add symmetric circles board support to interactive calibration app # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"add option to force reopen camera in interactive calibration tool # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"fix issue <number> , let clip layer support <number> - <number> inputs * * merge with extra * * : <url> this pr will fix the issue # <number> the essence of the issue is that the ` clip layer ` is supposed to accept <number> - <number> inputs , but the implementation here is based on ` relu6 ` , which only supports attributes as parameters . <url> solution parsing the ` clip layer ` , the ` min ` and ` max ` obtained from ` node_proto . input ( ) ` , instead of from ` layerparams ` , are passed as parameters to the ` relu6 ` . this allows the ` clip layer ` to support <number> - <number> inputs .",1
opencv/opencv,"apps / opencv_visualisation : configurable video codec problem : the ` model_visualization . avi ` with ` xvid ` codec did ( silently ) not work whereas ` model_visualization . mp4 ` with ` h264 ` does work . proposed solution the video codec configurable ( defaulting to existing behaviour ) and error - log - and - exit if the output video file could not be opened . # # # # usage example ( the "" happy fish "" image does not have the 2 0 x20 size of the "" profile face "" model but it seems nonetheless suitable for smoke test use . ) ` ` ` opencv_build / bin / opencv_visualisation \ \ - - image = opencv / samples / data / happyfish . jpg \ \ - - model = opencv / data / haarcascades / haarcascade_profileface . xml \ \ - - data = temp_data / \ \ - - ext = mp4 - - fourcc = h264 - - fps = <number> ` ` ` # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"[ request ] new parameter to imwrite jpeg to disable chroma subsampling # # # # # system information ( version ) < - - example - opencv => <number> - operating system / platform => windows <number> bit - compiler => visual studio <number> - - > - opencv => all versions and os ' s # # # # # detailed description ` cv : : imwrite ( ) ` has several jpeg quality - related parameters but i often miss a flag to * disable chroma subsampling * . this can make a significant difference in images with pure color details ( e . g . with superimposed red , green or blue lines or circles where features have been found ) . just setting jpeg quality to <number> does not help because standard chroma subsampling comes before and can ruin the image ( chroma subsampling is good for real photographic content ) . this is a normal jpeg ( q <number> ) ( uses yuv <number> : <number> : <number> subsampling ) . see the fuzzy borders on the red and magenta lines . ! [ q95 - normal ] ( <url> this is the same jpeg without chroma subsampling ( uses rgb color space with no subsampling ) ! [ q95 - no_subsampling ] ( <url> the file grows a little , but can improve significantly in some kinds of images . a png would be better of course , but is usually much larger and slower to compress . # # # # # implementation i have looked at the code of ` grfmt_jpeg . cpp ` and libjpeg and i think i have found how to do this . it would be a very little change , with a new parameter that i ' d call ` imwrite_jpeg_full_color ` or ` imwrite_jpeg_no_subsample ` . possibly just adding something like this after the line ` jpeg_set_defaults ( & cinfo ) ; ` ( and something more to get the flag value from the params list ) ` ` ` . cpp if ( imwrite_jpeg_no_subsample & & channels > <number> ) jpeg_set_colorspace ( & cinfo , jcs_rgb ) ; ` ` ` i have not tried yet . and i am not sure i would know how to do it and create a pull request but i will try . # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question < ! - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [x ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",1
opencv/opencv,"add python bindings for g - api onnx # # # motivation i think that the feature to run modle on onnxruntime is worth exposing to python g - api considering that * onnxruntime supports many ml runtimes * onnxruntime itself is very easy to install this pr is the first step to expose onnxruntime features to python and support of execution providers will follow later . this pr is draft , so let us have a discussion if necessary : slightly_smiling_face remaining tasks - [x ] adding python unit test for onnx runtime - [x ] create the same preprocess as openvino one to be able to accept the input with same shape as openvino . currently transposing and reshaping is necessary like [ this ] ( <url> in the user code . - > i will not implement this because it seems that the implementation in the onnx seems right from [ this line ] ( <url> # # # questions - how do you manage models for testing in opencv ? i coudln ' t find the model used in infer_ssd_onnx . cpp test . # # # example code <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work there ' s no bug report . - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . i do not thik performance test is necessary this time , because it ' s just a binding . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"support asymmetric paddings for qconv in onnx we have a model in <url> which has asymmetric paddings in convolution layers . the model is managed to be quantized , but the current version of opencv does not support asymmetric paddings in quantized int8 convolution layer . so this pr adds the asymmetric padding support for quantized int8 convolution layer in onnx importer . test data # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"imgproc : optimise local cost computation in intelligentscissorsmb : : buildmap when reading the code i noticed a ` todo ( opt ) ` comment , this pull request is for that . <url> ` ` ` float cost = cost_q + local_cost ( q , r ) ; / / todo ( opt ) partially until cost < cost_r ` ` ` # # # notes * <url> and this pull request change the same non - test files . however , the changes themselves do not overlap i . e . there should be no merge conflicts . * based on <url> this pull request here could be for <number> instead of <number> . x branch . however , it is for <number> . x since <number> does not have the intelligent scissors code . # # # test run snippet ` ` ` $ export opencv_test_data_path = . <repeated> / opencv_extra / testdata $ . / bin / opencv_perf_imgproc - - gtest_filter = "" testintelligentscissorsmb * "" . <repeated> [ run ] testintelligentscissorsmb_buildmap_setcomputefulllocalcost . buildmap_setcomputefulllocalcost / <number> , where getparam ( ) = false . <repeated> [ perfstat ] ( samples = <number> mean = <number> median = <number> min = <number> stddev = <number> ( <percent> ) ) [ ok ] testintelligentscissorsmb_buildmap_setcomputefulllocalcost . buildmap_setcomputefulllocalcost / <number> ( <number> ms ) [ run ] testintelligentscissorsmb_buildmap_setcomputefulllocalcost . buildmap_setcomputefulllocalcost / <number> , where getparam ( ) = true . <repeated> [ perfstat ] ( samples = <number> mean = <number> median = <number> min = <number> stddev = <number> ( <percent> ) ) [ ok ] testintelligentscissorsmb_buildmap_setcomputefulllocalcost . buildmap_setcomputefulllocalcost / <number> ( <number> ms ) . <repeated> ` ` ` # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"add undistortimagepoints function ` cv : : undistortpoints ( ) ` has unclear interface and additional functionality . new function computes only undistorted image points position # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"to extract frame type ( i , p , b ) info for better post - process without ffmpeg / ffprobe # # # # # system information ( version ) - opencv => opencv - python <number> . <number> - operating system / platform => win10 - compiler => pre - compiled # # # # # detailed description currently , it always needs ffmpeg / ffprobe to extract frame type info before any future processing , but calling a new process is slow and complex for other codes . i , p , b frame type info could be useful to do some scene - change detection . but opencv currently misses the function to get that info , but it should be there when opencv reads the video files . could opencv enhance this feature ? thanks # # # # # steps to reproduce n / a # # # # # issue submission checklist - [x ] i report the issue , it ' s not a question < - - opencv team works with forum . opencv . org , stack overflow and other communities to discuss problems . tickets with questions without a real issue statement will be closed . - - > - [x ] i checked the problem with documentation , faq , open issues , forum . opencv . org , stack overflow , etc and have not found any solution < ! - - places to check : * opencv documentation : <url> * faq page : <url> * opencv forum : <url> * opencv issue tracker : <url> * stack overflow branch : <url> - - > - [x ] i updated to the latest opencv version and the issue is still there < ! - - master branch for opencv <number> . x and <number> branch for opencv <number> . x releases . opencv team supports only the latest release for each branch . the ticket is closed if the problem is not reproduced with the modern version . - - > - [ ] there is reproducer code and related data files : videos , images , onnx , etc < ! - - the best reproducer - - test case for opencv that we can add to the library . recommendations for media files and binary files try to reproduce the issue with images and videos in opencv_extra repository to reduce attachment size * use png for images , if you report some cv related bug , but not image reader issue * attach the image as an archive to the ticket , if you report some reader issue . image hosting services compress images and it breaks the repro code . * provide onnx file for some public model or onnx file with random weights , if you report onnx parsing or handling issue . architecture details diagram from netron tool can be very useful too . see <url> - - >",1
opencv/opencv,"python bindings for videocapture : : waitany related : <url> everything in ` videocapture ` has python bindings except for the new ` waitany ` facility . i think that would be generally useful to have in python too . if the bindings generation does not imply a regular signature , i ' d propose ` ` ` python waitany ( streams , timeoutns = <number> ) - > readyindex ` ` ` where ` streams ` is a list of videocapture instances and ` readyindex ` is a python _list_ of indices into ` streams ` . no need to preserve the boolean return value . it ' s only false if the list is empty . nb are inconsistent in their naming . single mention of "" streamready "" . "" readyindex "" was probably intended . it ' s not a singular value either ( "" index "" ) , it ' s a vector / list ( indices ) .",1
opencv/opencv,"g - api source turn on linux cpu version fix compilation vpl streaming source for linux add stub for vaapi acceleration which uses accel for decode but produces mediaframe in cpu memory fix ut of existing functionalities # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake # # # build configuration ` ` ` force_builders = custom , custom win , custom mac build_gapi_standalone : linux x64 = ade - <number> . 1 f build_gapi_standalone : win64 = ade - <number> . 1 f build_gapi_standalone : mac = ade - <number> . 1 f build_gapi_standalone : linux x64 debug = ade - <number> . 1 f buildworker : custom = linux - <number> build_gapi_standalone : custom = ade - <number> . 1 f build_image : custom = onevpl - <number> . <number> test_opencl : custom = off xbuild_image : custom = ubuntu - openvino - <number> . <time> . <number> xbuild_image : custom win = openvino - <number> . <number> build_image : custom mac = openvino - <number> . <number> test_modules : custom = gapi , python2 , python3 , java test_modules : custom win = gapi , python2 , python3 , java test_modules : custom mac = gapi , python2 , python3 , java build_image : custom win = gapi - onevpl - <number> . <number> buildworker : custom win = windows - <number> build_contrib : custom win = off ` ` `",1
opencv/opencv,"dnn : add plugin support for openvino todo : - [x ] fix windows build scripts for plugin : disable pch - [x ] fix windows build scripts for plugin : . simd . hpp support - [ ] ( postpone ) build_plugin - > opencv_build_plugin ( backlog , to be done as separate pr - need to fix other modules too ) - [x ] myriad detection ( ncs / ncs2 ) - <number> + supports only ncs2 <cut/> ` ` ` force_builders = custom , custom win xforce_builders = linux , docs , custom , custom win xbuild_image : custom = ubuntu - openvino - <number> . <time> . <number> build_image : custom = ubuntu - openvino - <number> . <time> . <number> xbuild_image : custom = ubuntu - openvino - <number> . <number> . dev2022013 <time> . <number> build_image : custom win = openvino - <number> . <number> build_image : custom mac = openvino - <number> . <number> test_modules : custom = dnn , gapi , python2 , python3 , java test_modules : custom win = dnn , gapi , python2 , python3 , java test_modules : custom mac = dnn , gapi , python2 , python3 , java buildworker : custom = linux - <number> # disabled due high memory usage test_opencl : custom = on test_bigdata : custom = <number> test_filter : custom =* buildworker : custom win = windows - <number> test_bigdata : custom win = <number> test_filter : custom win =* test_opencl : custom win = on build_contrib : custom win = off allow_multiple_commits = <number> ` ` `",1
opencv/opencv,"android require deprecated tools checking for these deprecated is no longer necessary , and infact broken on fresh android sdk installs . remove the check . resolves # <number> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders_only = android armeabi - v7a , docs ` ` `",1
opencv/opencv,"add <number> - <number> - 1 4 bit ( integer ) tiff decoding support * * merge with extra * * proposal for # <number> a ( slow ) unpacking step is inserted when the native bpp is not equal to the dst_bpp currently , i do not know if there can be several packing flavours in tiff data . see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work",1
opencv/opencv,"add apply softmax option to classificationmodel fix <url> ` ` ` cpp / / model does not contain softmax layer cv : : dnn : : classificationmodel classification_model = cv : : dnn : : classificationmodel ( model , config ); / / not apply softmax post process ( default ) bool apply_softmax = classification_model . getsoftmaxpostprocessing ( ); / / false / / apply softmax post process apply_softmax = true ; classification_model . setenablesoftmaxpostprocessing ( apply_softmax ); / / if enable softmax post process is true , confidences range is [ <number> - <number> ] / / if enable softmax post process is false , confidences range is varies by model auto [ classid , confidence ] = model . classify ( image ); ` ` ` # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [x ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"g - api vpp preproc cpu / gpu dispatcher added vpp preproc dispatcher / facade implements the same ipreprocengine interface and aggregates cpu & gpu preproc engine and switch implementation by actual mediaframe type . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake # # # build configuration ` ` ` force_builders = xcustom , custom win , custom mac build_gapi_standalone : linux x64 = ade - <number> . 1 f build_gapi_standalone : win64 = ade - <number> . 1 f build_gapi_standalone : mac = ade - <number> . 1 f build_gapi_standalone : linux x64 debug = ade - <number> . 1 f xbuild_image : custom = centos : <number> xbuildworker : custom = linux - <number> build_gapi_standalone : custom = ade - <number> . 1 f build_image : custom = ubuntu - openvino - <number> . <time> . <number> xbuild_image : custom win = openvino - <number> . <number> build_image : custom mac = openvino - <number> . <number> test_modules : custom = gapi , python2 , python3 , java test_modules : custom win = gapi , python2 , python3 , java test_modules : custom mac = gapi , python2 , python3 , java buildworker : custom = linux - <number> test_opencl : custom = off test_bigdata : custom = <number> test_filter : custom =* build_image : custom win = gapi - onevpl - <number> . <number> buildworker : custom win = windows - <number> build_contrib : custom win = off ` ` `",1
opencv/opencv,error while loading yolor_p6 . onnx : expand op does not support multiple axes for constant input i am trying to load yolor after i converted it from pytorch to onnx . buti get this error : node [ <email> <sad> ( <number> ) parse error : opencv ( <number> . <number> ) / io / opencv / modules / dnn / src / onnx / onnx_importer . cpp : <number> : error : ( - <number> : the function / feature is not implemented ) expand op does not support multiple axes for constant input in function ' parseexpand ' my code cv2 ` ` onnx_model = cv2 . dnn . readnetfromonnx ( ' yolor_p6 . onnx ' ) `,1
opencv/opencv,"dnn depth2space and space2depth layer for onnx importer hi , i implement the ` depth2space ` and ` space2depth ` layers by the ` reshape ` and ` permute ` layer , instead of creating a new layer . is it necessary to create a separate layer for ` depth2space ` and ` space2depth ` ? [ relate issue ] ( <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"fallback to vacreateimage + vaputimage when vaderiveimage fails per intel docs for libva , when vaderiveimage fails vacreateimage + vaputimage should be tried . this is important as mesa with amd hw will always fail because the image is interlaced , but the hw capability still exists fixes <url> # # # pull request readiness checklist see details at <url> - [ x ] i agree to contribute to the project under apache <number> license . - [ x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [ x ] the pr is proposed to the proper branch - [ x ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ x ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"support downloading 3 rdparty resources from gitcode & gitlab - style mirrors # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [x ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders_only = linux , docs ` ` `",1
opencv/opencv,"add resize layer compatible with onnx opset13 version * * merge with extra * * opset13 has changed resize layer mapping . and there may the empty input in the resize node . happened when exporting the onnx model with the <number> or later version of pytorch with opset <number> , for example the "" resize "" in [ animeganv2 model ] ( <url> more details can be found in the [ test data ] ( <url> # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or another license that is incompatible with opencv - [x ] the pr is proposed to the proper branch - [ ] there is a reference to the original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake ` ` ` opencv_extra = resize_onnx_opset13 ` ` `",1
opencv/opencv,task <number> support support compilation with gcc <number> and fix tests - # <number> ( persistence_base64 . cpp compilation error ` - werror = address ` ) - # <number> ( ppc64le compilation ) - # <number> ( build warnings ),1
opencv/opencv,"audioio dnn speech recognition sample on c + + # # # pull request readiness checklist see details at <url> - [ ] i agree to contribute to the project under apache <number> license . - [ ] to the best of my knowledge , the proposed patch is not based on a code under gpl or other license that is incompatible with opencv - [ ] the pr is proposed to proper branch - [ ] there is reference to original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake",1
opencv/opencv,"use modern openvino package interface * new cmake options : ` with_openvino ` , ` opencv_gapi_with_openvino ` , old options are deprecated * old options will be ignored if new options have been set * tested with current openvino <user> notes : * openvino version will be autodetected , can not be changed manually anymore ( ` inf_engine_release ` ) * not possible to disable ngraph integration when openvino is enabled ( is it necessary ? ) validation : - [x ] [ build ] ( <url> with openvino pre - release [ <number> . <number> . dev20220131 ] ( <url> <cut/> ` ` ` force_builders = custom , custom win , custom mac xbuild_image : custom = ubuntu - openvino - <number> . <time> . <number> build_image : custom = ubuntu - openvino - <number> . <number> . dev2022013 <time> . <number> build_image : custom win = openvino - <number> . <number> build_image : custom mac = openvino - <number> . <number> test_modules : custom = dnn , gapi , python2 , python3 , java test_modules : custom win = gapi , python2 , python3 , java test_modules : custom mac = gapi , python2 , python3 , java buildworker : custom = linux - <number> # disabled due high memory usage test_opencl : custom = off test_bigdata : custom = <number> test_filter : custom =* ` ` `",1
opencv/opencv,"tiffencoder write support more depth type * * merge with extra * * # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or other license that is incompatible with opencv - [ ] the pr is proposed to proper branch - [ ] there is reference to original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake ` ` ` opencv_extra = master ` ` `",1
opencv/opencv,"tiff need check tifftag_sampleformat , should not always use unsigned . # # # pull request readiness checklist see details at <url> - [x ] i agree to contribute to the project under apache <number> license . - [x ] to the best of my knowledge , the proposed patch is not based on a code under gpl or other license that is incompatible with opencv - [ ] the pr is proposed to proper branch - [ ] there is reference to original bug report and related work - [ ] there is accuracy test , performance test and test data in opencv_extra repository , if applicable patch to opencv_extra has the same branch name . - [ ] the feature is well documented and sample code can be built with the project cmake ` ` ` force_builders = linux , win64 , mac , docs ` ` `",1
