repo,created_at,label,title,body
facebook/react,2023-08-26 06:33:37,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

Private repo cannot give access to application

### Repro steps

1. Run application

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.28.0-035a41c4e

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:28171:41
    at Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24827:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24996:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:57406:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-07-28 05:16:12,bug,[DevTools Bug]: Devtools extension build failing in windows and ubuntu ,"### Website or app

N/A

### Repro steps

Been working on react devtools extension for a while now, my mac got some issue so i switched to a windows machine but currently i am unable to build the react devtool extension and run it locally here is the napshot of the error
![Windows PowerShell 7_28_2023 10_43_05 AM](https://github.com/facebook/react/assets/72331432/b6487d72-4c4f-46e2-b04e-0469de33e50b)



### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-07-13 21:58:31,bug,[DevTools Bug]: Deprecated __REACT_DEVTOOLS_GLOBAL_HOOK__ ????,"### Website or app

https://github.com/open-source-labs/reactime/tree/master/src

### Repro steps

Hi, I have heard that the new versions of React will not support the REACT_DEVTOOLS_GLOBAL_HOOK. If there any information about this update that you can share. Is there a new way to achieve the same result of using the REACT_DEVTOOLS_GLOBAL_HOOK but with a different method? What is the future of React without the REACT_DEVTOOLS_GLOBAL_HOOK?

Reactime and React Inspector in the Chrome store use this hook

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-06-14 02:31:20,bug,"[DevTools Bug] Cannot remove node ""0"" because no matching node was found in the Store.","### Website or app

local

### Repro steps

open react-devtools

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.27.8-2468a8735

### Error message (automated)

Cannot remove node ""0"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at /Users/wangx/.config/yarn/global/node_modules/react-devtools-core/dist/standalone.js:39:338605
    at f.emit (/Users/wangx/.config/yarn/global/node_modules/react-devtools-core/dist/standalone.js:39:283790)
    at /Users/wangx/.config/yarn/global/node_modules/react-devtools-core/dist/standalone.js:39:285331
    at /Users/wangx/.config/yarn/global/node_modules/react-devtools-core/dist/standalone.js:39:677861
    at Array.forEach (<anonymous>)
    at Lh.e.onmessage (/Users/wangx/.config/yarn/global/node_modules/react-devtools-core/dist/standalone.js:39:677845)
    at A.t (/Users/wangx/.config/yarn/global/node_modules/react-devtools-core/dist/standalone.js:39:2836)
    at A.emit (node:events:513:28)
    at e.exports.F (/Users/wangx/.config/yarn/global/node_modules/react-devtools-core/dist/standalone.js:3:38972)
    at e.exports.emit (node:events:513:28)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-06-03 11:29:44,bug,"[DevTools Bug] Cannot remove node ""103"" because no matching node was found in the Store.","### Website or app

localhost

### Repro steps

-

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.8-2468a8735

### Error message (automated)

Cannot remove node ""103"" because no matching node was found in the Store.

### Error call stack (automated)

```text
emit@moz-extension://a02c2c83-f439-4a45-972b-928bb0916901/build/main.js:27059:22
bridge_Bridge/this._wallUnlisten<@moz-extension://a02c2c83-f439-4a45-972b-928bb0916901/build/main.js:27228:14
listener@moz-extension://a02c2c83-f439-4a45-972b-928bb0916901/build/main.js:57497:41
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-05-26 12:03:19,bug,"[DevTools Bug]: App not recognized in Firefox, but works in Chrome","### Website or app

-

### Repro steps

On both Firefox 103 and 104 the react devtools extension says: ""This page doesn't appear to be using React"".

On the most recent version of Chrome it's working just fine.

I cannot share the project since it's a private project unfortunately, but I suspect this is a regression introduced with the recent https://github.com/facebook/react/pull/26765

Especially since the devtools were working perfectly fine until maybe one or two weeks ago.

It _does_ work in incognito mode in Firefox.

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-05-09 15:33:15,bug,[DevTools Bug]: Using different React instances across multiple frames throws errors,"### Website or app

https://codepen.io/mesoptier/pen/qBJopod

### Repro steps

1. Visit the codepen linked above.
2. Be sure to open the Debug View, so codepen doesn't add any additional iframes ([more info](https://blog.codepen.io/documentation/debug-view/)).
3. Observe:
   - Warning in the Console tab: `Invalid renderer id ""1""`.
   - Error in the Components tab: `Uncaught Error: Cannot add node ""3"" because a node with that id is already in the Store`.
   - After dismissing the error, all components seem to be accounted for (you might need to adjust the ""Hide components where..."" option).

In my actual application the error pops up for every change in the tree, making the devtools virtually unusable.

Note: This only seems to happen if the iframe is added some time after the initial React tree was mounted in the parent window. When I remove the `setTimeout` so the iframe is added synchronously, I no longer see any warnings.

Related issues:
- https://github.com/facebook/react/issues/26787
- https://github.com/facebook/react/issues/26793

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version ~(automated)~ (manual)

4.27.7 (5/7/2023) in Google Chrome Version 112.0.5615.165 (Official Build) (64-bit)

### Error message ~(automated)~ (manual)

Cannot add node ""3"" because a node with that id is already in the Store.

### Error call stack ~(automated)~ (manual)

```
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:29031:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27054:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27223:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:57493:39)
```

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-05-08 06:59:51,bug,"[DevTools Bug] Cannot remove node ""226752"" because no matching node was found in the Store.","### Website or app

https://travel.testsigma.com/

### Repro steps

https://travel.testsigma.com/

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.6-7f8c501f6

### Error message (automated)

Cannot remove node ""226752"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:28710:43
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26606:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26775:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:57029:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-05-02 13:23:54,bug,"[DevTools Bug] Cannot remove node ""197"" because no matching node was found in the Store.","### Website or app

http://localhost:3000/

### Repro steps

1. accessing react dev from a local app''


### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.6-7f8c501f6

### Error message (automated)

Cannot remove node ""197"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:28710:43
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26606:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26775:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:57029:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-04-25 04:16:47,bug,[DevTools Bug]: Unable to build the extension locally,"### Website or app

N/A

### Repro steps

I am trying to build the chrome extension for react dev tools locally to test changes as i am looking forward to fix this issue https://github.com/facebook/react/issues/26200, but there seem to be some error with the packages! looking forward to get some help
![Windows PowerShell 4_25_2023 9_44_03 AM](https://user-images.githubusercontent.com/72331432/234173125-657274ae-9d5b-41b6-bf34-ed148625f73f.png)


### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-04-21 21:27:01,bug,"[DevTools Bug]: can not build react devtools for local development, instructions lead to error","### Website or app

https://github.com/facebook/react/tree/main/packages/react-devtools-extensions

### Repro steps

Follow the instructions here to build local version of react devtools extension: https://github.com/facebook/react/tree/main/packages/react-devtools-extensions

```
git clone https://github.com/facebook/react.git 
cd react
yarn install
yarn build-for-devtools
```

Stuck on this step everytime `yarn build-for-devtools`:
```
D:\\Other\\react\\node_modules\\flow-parser\\flow_parser.js:807
throw a}function
^

Error: SignedSource.signFile(...): Cannot sign file without token: <<SignedSource::*O*zOeWoEQle#+L!plEphiEmie@IsG>>
    at Object.<anonymous> (D:\\Other\\react\\node_modules\\signedsource\\index.js:20:28)
    at Module._compile (node:internal/modules/cjs/loader:1196:14)
    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1250:10)
    at Module.load (node:internal/modules/cjs/loader:1074:32)
    at Function.Module._load (node:internal/modules/cjs/loader:909:12)
    at Module.require (node:internal/modules/cjs/loader:1098:19)
    at require (node:internal/modules/cjs/helpers:108:18)
    at Object.<anonymous> (D:\\Other\\react\\scripts\\rollup\\packaging.js:18:37)
    at Module._compile (node:internal/modules/cjs/loader:1196:14)
    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1250:10)
```

Is there anything else I need to set up in order to make this work?

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-04-05 14:03:28,bug,"[DevTools Bug] Could not find node with id ""364"" in commit tree","### Website or app

private

### Repro steps

private

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.3-28ce1c171

### Error message (automated)

Could not find node with id ""364"" in commit tree

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27480:13
    at Map.forEach (<anonymous>)
    at RankedChartBuilder_getChartData (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27476:24)
    at ProfilingCache_ProfilingCache.getRankedChartData (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27592:11)
    at CommitRankedAutoSizer (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:45996:32)
    at mf (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:13756:7)
    at qk (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18405:11)
    at mk (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:17982:11)
    at lk (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:17871:23)
    at Sj (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:17851:5)
```


### Error component stack (automated)

```text
at CommitRankedAutoSizer (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:45975:34)
    at div
    at div
    at div
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37999:3)
    at Profiler_Profiler (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:55844:34)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39532:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39704:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39734:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39704:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44994:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44422:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32227:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32872:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40129:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56352:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Could not find node with id  in commit tree in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-03-28 19:02:59,bug,[DevTools Bug]: copy operations don't work in Chrome,"### Website or app

https://react.dev

### Repro steps

1. Go to components tab.
2. For any component, try to copy the value in props, hooks etc. to clipboard.

![image](https://user-images.githubusercontent.com/75756768/228340421-a901498a-1308-4e8f-b502-989f4c60331f.png)


### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-03-17 16:54:47,bug,[DevTools Bug]: ,"### Website or app

localhost

### Repro steps

In react router's latest version.  Inside the loader or action function one is not able to use reduxjs functions like useselector,usedispatch

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-03-14 14:03:16,bug,Bug: Component is not a function when using Suspense and forwardRef,"React version: 18.3.0-next-3ba7add60-20221201

## Steps To Reproduce

I haven't been able to create a minimal example yet, if needed I will spend more time on it. However, it only seems to occur when Suspending components rerender in a specific order.

## Description

The `Component is not a function` error is thrown when using Suspense and forwardRef together in a specific way.

It seems like react-reconciler doesn't properly handle forwardRefs in either `renderWithHooksAgain`, `replaySuspendedComponentWithHooks`, `replayFunctionComponent` or `replaySuspendedUnitOfWork`. The `Component` variable is not a function in this case, but a `{ $$typeof: Symbol(react.forward_ref), render: (props, ref) => any }`. `renderWithHooksAgain` tries to execute `Component(props, secondArg)`, which throws this error.

I'm not too familiar with React internals, if you can tell me how to trigger this codepath I can make a minimal reproduction more easily.

<img width=""1303"" alt=""Screenshot 2023-03-14 at 14 55 13"" src=""https://user-images.githubusercontent.com/5406212/225024052-635c6639-8617-45a7-b6ce-c606d2ce3d90.png"">"
facebook/react,2023-02-24 04:32:07,bug,Bug: Nested useTransition makes isPending of outer one always false,"Nested `startTransition` call ""takes over"" and makes parent `startTransition` unable to track `isPending`.

Seb says it's a bug.

Repro:

https://codesandbox.io/s/pensive-breeze-rg70wn?file=/IndexPage.js:192-288

1. Click the button
2. `isPending` in `IndexPage.js` is `true`

However, `isPending` in `App.js` is `false`.

Expected: `isPending` in `App.js` is also `true`."
facebook/react,2023-02-16 13:31:28,bug,"[DevTools Bug] Cannot add node ""792"" because a node with that id is already in the Store.","### Website or app

https://chat.openai.com/chat

### Repro steps

log in to chatGPT

### How often does this bug happen?

Often

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.1-47f63dc54

### Error message (automated)

Cannot add node ""792"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
emit@moz-extension://ce8dcc20-3b2d-4cfe-b13e-34da2aa8e2c3/build/main.js:25895:22
bridge_Bridge/this._wallUnlisten<@moz-extension://ce8dcc20-3b2d-4cfe-b13e-34da2aa8e2c3/build/main.js:26064:14
listener@moz-extension://ce8dcc20-3b2d-4cfe-b13e-34da2aa8e2c3/build/main.js:56299:41
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-02-08 15:00:05,bug,Bug(@next): legacy `ReactDOM.render` crashes when rendering into `document` container,"<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version: 18.3.0-next-4bf2113a1-20230206

## Steps To Reproduce

1. `ReactDOM.render` into a `document` container

<!--
  Your bug will get fixed much faster if we can run your code and it doesn't
  have dependencies other than React. Issues without reproduction steps or
  code examples may be immediately closed as not actionable.
-->

Link to code example: https://codesandbox.io/s/react-next-legacy-render-crashes-when-rendering-html-jqdut3?file=/src/index.js

## The current behavior

Throws with 

```
React expected an <html> element (document.documentElement) to exist in the Document but one was not found. React never removes the documentElement for any Document it renders into so the cause is likely in some other script running on this page.
```

`ReactDOM.render` clears the container before rendering into it. But with the new HostSingletons (https://github.com/facebook/react/pull/25426) we expect an existing `documentElement`.

The odd part is that it seems like https://github.com/facebook/react/pull/25426 affected the `@next` release even though `enableHostSingletons` is disabled for that release.

/cc @gnoff

## The expected behavior

No crash like in `react-dom@18.2.0`: https://codesandbox.io/s/react-next-legacy-render-crashes-when-rendering-html-forked-977biy"
facebook/react,2023-02-02 08:53:46,bug,Bug: useSyncExternalStore will cause hydration missmatch in `StrictMode` if `serverSnapshot` is different from `snapshot`,"## React version
React version: 18.3.0-next-b0671f9ea-20230130

## Problem
In `StrictMode`,  when using hydrateRoot to render a component that using `useSyncExternalStore` it seems that useSES will do hydration twice. 

But in second hydration process,  useSES does not use the result of `getServerSnapshot` as initial state, which will cause hydration error.

This problem will only happen in `development` mode, 

## Reproduce
Link to code example:
https://codesandbox.io/s/useses-18-3-rojznv

It works well in react 18.2
https://codesandbox.io/s/useses-18-2-13iskc



"
facebook/react,2023-01-26 00:43:30,bug,"[DevTools Bug]: Can not work on devtools, instructions lead to error","### Website or app

https://chrome.google.com/webstore/detail/react-developer-tools/fmkadmapgofadopljbjfkapdkoienihi?hl=en

### Repro steps

Because react requires java, not on macos (but assumes brew installed!):
```
brew update && brew install java
sudo ln -sfn /usr/local/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk
export PATH=""/usr/local/opt/openjdk/bin:$PATH""' >> ~/.zshrc
export PATH=""/usr/local/opt/openjdk/bin:$PATH"" >> ~/.zshrc
export PATH=""/usr/local/opt/openjdk/bin:$PATH""
```

Because react requires node before v17 (but assuming you have nvm installed!):
```
nvm install 16
```

then the real stuff (directions inside folders like ./chrome/ are quite wrong):
```
git clone https://github.com/facebook/react.git
cd react
yarn install
yarn build-for-devtools
cd packages/react-devtools-extensions
yarn build:chrome
yarn build:chrome:local
yarn run test:chrome
```

Now inside devtools:

```
Uncaught EvalError: Refused to evaluate a string as JavaScript because 'unsafe-eval' is not an allowed source of script in the following Content Security Policy directive: ""script-src 'self' 'wasm-unsafe-eval'"".

    at ./src/contentScripts/prepareInjection.js (prepareInjection.js:133:1)
    at __webpack_require__ (prepareInjection.js:20:30)
    at prepareInjection.js:84:18
    at prepareInjection.js:87:10
```

What exactly are you doing that works in order to build, test, and develop this extension?

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-01-25 07:31:53,bug," ERROR  TypeError: Cannot read property 'createElement' of undefined, js engine: hermes","### App

using flipper dor react devtools

### Repro steps

migrate to current version of  RN-0.71.1
using flipper 
enable hermes engine
run the app




### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

ERROR  TypeError: Cannot read property 'createElement' of undefined, js engine: hermes 

### Error call stack (automated)

```text
ERROR  TypeError: Cannot read property 'createElement' of undefined, js engine: hermes 

this is related to --->> path: node_modules/react-devtools-core/dist/backend.js
function initialize() {
  canvas = window.document.createElement('canvas');
  canvas.style.cssText = ""\\n    xx-background-color: red;\\n    xx-opacity: 0.5;\\n    bottom: 0;\\n    left: 0;\\n    pointer-events: none;\\n    position: fixed;\\n    right: 0;\\n    top: 0;\\n    z-index: 1000000000;\\n  "";
  var root = window.document.documentElement;
  root.insertBefore(canvas, root.firstChild);
}
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2023-01-11 16:52:42,bug,"[DevTools Bug] Cannot remove node ""0"" because no matching node was found in the Store.","### Website or app

app

### Repro steps

1.react-native run android 
2.react-devtools
3.adb reverse tcp:8097 tcp:8097
4.open dev tools on phone
5.Error

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.27.1-47f63dc54

### Error message (automated)

Cannot remove node ""0"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at C:\\Users\\gimpl\\AppData\\Roaming\\npm\\node_modules\\react-devtools\\node_modules\\react-devtools-core\\dist\\standalone.js:48:336132
    at f.emit (C:\\Users\\gimpl\\AppData\\Roaming\\npm\\node_modules\\react-devtools\\node_modules\\react-devtools-core\\dist\\standalone.js:48:281406)
    at C:\\Users\\gimpl\\AppData\\Roaming\\npm\\node_modules\\react-devtools\\node_modules\\react-devtools-core\\dist\\standalone.js:48:282947
    at C:\\Users\\gimpl\\AppData\\Roaming\\npm\\node_modules\\react-devtools\\node_modules\\react-devtools-core\\dist\\standalone.js:48:673319
    at Array.forEach (<anonymous>)
    at A.e.onmessage (C:\\Users\\gimpl\\AppData\\Roaming\\npm\\node_modules\\react-devtools\\node_modules\\react-devtools-core\\dist\\standalone.js:48:673303)
    at A.t (C:\\Users\\gimpl\\AppData\\Roaming\\npm\\node_modules\\react-devtools\\node_modules\\react-devtools-core\\dist\\standalone.js:39:2836)
    at A.emit (events.js:315:20)
    at e.exports.L (C:\\Users\\gimpl\\AppData\\Roaming\\npm\\node_modules\\react-devtools\\node_modules\\react-devtools-core\\dist\\standalone.js:3:58894)
    at e.exports.emit (events.js:315:20)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-16 16:09:56,bug,[DevTools Bug]: The extension brokes some JavaScripts - React is not used.,"### Website or app

https://codesandbox.io/s/condescending-solomon-465djc?file=/index.html

### Repro steps

With the code in the sandbox (but in a real page), when the extension is enabled, the tree is expanded, and cannot be collapsed anymore.

![image](https://user-images.githubusercontent.com/408368/208140548-61ae786b-b712-40eb-a64b-b4f814e6965b.png)

There are no errors in the console of the page, but many in the extension. I don't know if it's correlated. 


Note: This code is provided by Symfony, a popular PHP framework. So many developer faces this issue

Note 2: This issue is quite new

I also created an [issue in Symfony](https://github.com/symfony/symfony/issues/48545).

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-12-11 20:37:37,bug,"[DevTools Bug] Element ""1307"" not found","### Website or app

no source code available publically

### Repro steps

Working on my local react project

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.1-47f63dc54

### Error message (automated)

Element ""1307"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39543:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40918:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39222:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39756:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42414:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35065:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37690:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44490:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39222:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39394:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39424:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39394:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44671:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44100:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31925:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32569:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39819:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56024:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-09 00:22:26,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

Personal

### Repro steps

Go on a React App. Open panel. Observe Error

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.1-47f63dc54

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27865:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:25895:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26064:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56299:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-06 00:35:54,bug,Bug: use() causes nested Suspense boundaries to not reveal ,"Nested Suspense boundaries should reveal as the content becomes ready. However, this doesn't seem to work with `use`.

Repro case: https://codesandbox.io/embed/festive-archimedes-sihgkb?file=/ArtistPage.js:338-346

Expected: Suspense boundaries reveal separately
Actual: it waits for everything before revealing anything"
facebook/react,2022-12-05 11:14:05,bug,"[DevTools Bug] Element ""51"" not found","### Website or app

local app

### Repro steps

working on the browser Presentation API
not really sure what i did to make this happen

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.0-bd2ad89a4

### Error message (automated)

Element ""51"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40933:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39771:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42429:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35080:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37705:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44505:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39439:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44686:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44115:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31940:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32584:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39834:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56039:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-05 07:33:55,bug,"[DevTools Bug] Element ""744"" not found","### Website or app

https://codesandbox.io/s/data-grid-community-forked-ff6d2j

### Repro steps

Occurred during Mui Datagrid setup

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.0-bd2ad89a4

### Error message (automated)

Element ""744"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40933:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39771:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42429:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35080:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37705:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44505:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39439:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44686:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44115:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31940:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32584:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39834:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56039:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-04 14:37:52,bug,"[DevTools Bug] Cannot remove node ""0"" because no matching node was found in the Store.","### Website or app

.

### Repro steps

[DevTools Bug] Cannot remove node ""0"" because no matching node was found in the Store.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.26.1-44e2ca393

### Error message (automated)

Cannot remove node ""0"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at /Users/300073191/.nvm/versions/node/v14.17.1/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:335672
    at f.emit (/Users/300073191/.nvm/versions/node/v14.17.1/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:281031)
    at /Users/300073191/.nvm/versions/node/v14.17.1/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:282572
    at /Users/300073191/.nvm/versions/node/v14.17.1/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:672375
    at Array.forEach (<anonymous>)
    at A.e.onmessage (/Users/300073191/.nvm/versions/node/v14.17.1/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:672359)
    at A.t (/Users/300073191/.nvm/versions/node/v14.17.1/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:39:2836)
    at A.emit (events.js:315:20)
    at e.exports.L (/Users/300073191/.nvm/versions/node/v14.17.1/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:3:58894)
    at e.exports.emit (events.js:315:20)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-04 04:50:33,bug,"[DevTools Bug] Element ""12"" not found","### Website or app

Chrome

### Repro steps

Went to check react component dev tools for state values and got error

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.0-bd2ad89a4

### Error message (automated)

Element ""12"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40933:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39771:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42429:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35080:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37705:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44505:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39439:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44686:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44115:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31940:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32584:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39834:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56039:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-02 11:52:24,bug,"[DevTools Bug] Element ""3"" not found","### Website or app

https://github.com/BlakeMack/quiz-app-react

### Repro steps

-As soon as the < App/> component is rendered (as soon as the application is loaded) I get the Element 3 error above, which stays consistent throughout every state change in my application 
start
quizdata
score
isScored
But I am not getting any console errors and the app is working as expected, but I have no access to my react components or any visibility of the state changes occurring within the app 

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.0-bd2ad89a4

### Error message (automated)

Element ""3"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40933:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39771:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42429:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35080:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37705:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44505:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39439:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44686:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44115:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31940:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32584:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39834:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56039:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-01 18:35:20,bug,"[DevTools Bug] Element ""9"" not found | Also ""Element ""10"" not found"" / ""Element ""12"" not found""...","### Website or app

https://github.com/arbocobra/redux-minesweeper

### Repro steps

On first load I get multiple Error warnings on all app components from `<Game/>` down. They are identified with different Element numbers but appear to be directed to the same issue 
""The error was thrown at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15"" 

If you select 'Begin Game' in app the error in component` <Game />` can be dismissed but new Errors appear on all newly rendered components below (once again all have different Element numbers directed to the same location (../main.js:39558:15)

//

This is issue is probably related to [[DevTools Bug] Element ""41"" not found](https://github.com/facebook/react/issues/25755)

Chrome is up to date (Version 108.0.5359.71 (Official Build) (x86_64)), and restarted. 
I also tried reinstalling React extension (running 4.27.0).

The app is using Redux, which one commenter in other thread mentioned might be a commonality. 

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.0-bd2ad89a4

### Error message (automated)

Element ""9"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40933:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39771:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42429:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35080:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37705:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44505:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39439:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44686:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44115:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31940:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32584:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39834:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56039:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-01 05:41:21,bug,"[DevTools Bug] Element ""20"" not found","### Website or app

Website

### Repro steps

Added a useEffect to a functional component.

### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.0-bd2ad89a4

### Error message (automated)

Element ""20"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40933:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39771:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42429:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35080:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37705:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44505:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39439:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44686:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44115:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31940:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32584:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39834:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56039:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-12-01 01:49:52,bug,"[DevTools Bug] Element ""41"" not found","### Website or app

https://github.com/Afrokk/litmus.tools

### Repro steps

In branch litmus.tools -> feature/LIT-5: 
I just run the app and it throws this error.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.27.0-bd2ad89a4

### Error message (automated)

Element ""41"" not found

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39558:15
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40933:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39771:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42429:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35080:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37705:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44505:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39237:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39439:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39409:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44686:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:44115:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31940:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:32584:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:39834:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:56039:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-11-02 15:46:40,bug,"[DevTools Bug] Cannot add node ""47"" because a node with that id is already in the Store.","### Website or app

private

### Repro steps

when we have multiple react application in the same page

### How often does this bug happen?

Often

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.25.0-336ac8ceb

### Error message (automated)

Cannot add node ""47"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
emit@moz-extension://36392081-5ec8-d94c-b8d5-869fc97bdf34/build/main.js:24626:22
bridge_Bridge/this._wallUnlisten<@moz-extension://36392081-5ec8-d94c-b8d5-869fc97bdf34/build/main.js:24795:14
listener@moz-extension://36392081-5ec8-d94c-b8d5-869fc97bdf34/build/main.js:54959:41
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-10-16 08:35:57,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

local personal app

### Repro steps

I was using Global context

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.25.0-336ac8ceb

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26596:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24626:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24795:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:54959:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-09-11 10:20:47,bug,[DevTools Bug]: react-devtools standalone launching and quitting after 2 seconds with no errors on Ubuntu 22.04,"### Website or app

https://www.facebook.com

### Repro steps

Run `react-devtools` in the terminal.

An empty window appears for maybe 2 seconds and then disappears. The terminal doesn't show any messages whatsoever.

There is another issue here regarding react-devtools failing silently on Debian, where the submitter alleged that it was related to insufficient permissions to run electron. Not sure if that's related to this issue, but I can run electron just fine, it's just react-devtools that are failing.

OS is Ubuntu 22.04 (Kubuntu), Node is v16.16.0, react-devtools 4.25.0

(Updated to add URL)

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-09-06 20:59:52,bug,[DevTools Bug] Cannot read properties of undefined (reading 'isCollapsed'),"### Website or app

https://github.com/alissonally

### Repro steps

3

### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.25.0-336ac8ceb

### Error message (automated)

Cannot read properties of undefined (reading 'isCollapsed')

### Error call stack (automated)

```text
at store_Store.getElementAtIndex (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27340:35)
    at store_Store.getElementIDAtIndex (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:27356:26)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37091:63
    at List.render (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:29207:18)
    at Uj (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:16359:76)
    at Sj (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:16350:10)
    at Gl (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:19332:86)
    at Fl (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18930:11)
    at El (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18922:23)
    at tl (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18906:5)
```


### Error component stack (automated)

```text
at List (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:28902:30)
    at div
    at AutoSizer (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:4235:5)
    at div
    at div
    at Tree_Tree (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36841:47)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:33778:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36399:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:43155:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37920:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38092:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38122:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38092:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:43336:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42781:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30676:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:31302:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38517:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:54684:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot read properties of undefined (reading 'isCollapsed') in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-09-03 02:10:05,bug,Bug: useReducer bail-out w/ useEffect + Suspense causes infinite loop (StrictMode error with next/experimental builds),"I just found our lib doesn't pass tests with latest build (unreleased ones). https://github.com/pmndrs/jotai/issues/1370

React version: 18.3.0-next-3d443cad7-20220823

## Steps To Reproduce

```jsx
const Component = () => {
  const [count, dispatch] = useReducer((prev) => prev, 0);
  useEffect(() => {
    dispatch();
  }, []);
  return <>{count}</>;
};

const App = () => (
  <Suspense>
    <Component />
  </Suspense>
);
```

> Maximum update depth exceeded. This can happen when a component repeatedly calls setState inside componentWillUpdate or componentDidUpdate. React limits the number of nested updates to prevent infinite loops.

Link to code example: https://codesandbox.io/s/focused-andras-p9qyxu?file=/src/App.js

## The current behavior

Warning in StrictMode.

## The expected behavior

No warning in StrictMode.

#25049 seems related. I'm not sure if it's a bug or a misusage."
facebook/react,2022-08-12 09:17:28,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

website

### Repro steps

Refresh page..

### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.25.0-336ac8ceb

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26596:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24626:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24795:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:54959:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-08-08 08:11:43,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

react developer tools

### Repro steps

Open Components in Web Developer Tools

### How often does this bug happen?

Only once

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.25.0-336ac8ceb

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
emit@moz-extension://6f15f1d5-602a-4a38-8422-c9e5075b7456/build/main.js:24626:22
bridge_Bridge/this._wallUnlisten<@moz-extension://6f15f1d5-602a-4a38-8422-c9e5075b7456/build/main.js:24795:14
listener@moz-extension://6f15f1d5-602a-4a38-8422-c9e5075b7456/build/main.js:54959:41
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-07-24 12:53:21,bug,"[DevTools Bug]: ""Hook parsing failed"" Components tab","### Website or app

https://studio-test-2.netlify.app/

### Repro steps

click ""Components"" tab
click on component
click ""parse hook names""


### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

4.25.0

### Error message (automated)

""Hook parsing failed""

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-07-18 06:27:41,bug,"[DevTools Bug] Cannot remove node ""20025"" because no matching node was found in the Store.","### Website or app

https://dev.threemad.com

### Repro steps

On inspecting comment modal

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.25.0-336ac8ceb

### Error message (automated)

Cannot remove node ""20025"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26725:43
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24626:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24795:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:54959:39)
```


### Error component stack (automated)

```text
comment
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-07-07 20:18:39,bug,"[DevTools Bug] Cannot remove node ""1390"" because no matching node was found in the Store.","### Website or app

https://github.com/OfficielSalah/marsamaroc

### Repro steps

1. create account
2. redirect to verify email page
3. copy otp from email
4. paste it in email page
5. redirect login
6. keep redirecting between login page and verify email page

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.24.7-7f673317f

### Error message (automated)

Cannot remove node ""1390"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26516:43
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24434:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24603:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:54566:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-07-06 23:05:13,bug,Possible Suspense bug,"I think I've trapped a bug where– after React suspends and the data has resolved, React bails out before re-rendered some of the Suspended components. (It's possible the bug is in my Suspense cache logic. I realize I'm working with un-finalized APIs.)

Here is a Loom walk through of the code in question:
https://www.loom.com/share/e356cf5d261e49f4b9f724a123349db9

Here is a Replay recording of the bug with annotations from myself and @Andarist:
https://app.replay.io/recording/cffed6a1-297e-428c-83a6-3a86451d0128

To reproduce the bug directly:
1. Checkout Replay commit [`22a07dbb294e0381d371cb744ac1ea2031edf9d6`](https://github.com/replayio/devtools/commit/22a07dbb294e0381d371cb744ac1ea2031edf9d6)
1. In the main directory run `yarn install`
1. In `packages/bvaughn-architecture-demo` run `yarn dev`
1. Open localhost:3000/tests/object-inspector and scroll down until you see ""Loading..."" (below the entry containing ""htmlElementWithAttributes"")

cc @acdlite who seemed interested in looking into this sometime (obviously no hurry) 😄 "
facebook/react,2022-06-30 06:01:54,bug,"[DevTools Bug] Cannot remove node ""0"" because no matching node was found in the Store.","### Website or app

React Native App

### Repro steps

1. Run react native app
2. npx react-devtools
3. adb reverse tcp:8097 tcp:8097
4. reload the app, this error should come as mentioned below

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.24.7-7f673317f

### Error message (automated)

Cannot remove node ""0"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at /Users/300037427/.npm/_npx/64332/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:333971
    at f.emit (/Users/300037427/.npm/_npx/64332/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:279464)
    at /Users/300037427/.npm/_npx/64332/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:281005
    at /Users/300037427/.npm/_npx/64332/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:667650
    at Array.forEach (<anonymous>)
    at A.e.onmessage (/Users/300037427/.npm/_npx/64332/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:667634)
    at A.t (/Users/300037427/.npm/_npx/64332/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:39:2838)
    at A.emit (events.js:315:20)
    at e.exports.L (/Users/300037427/.npm/_npx/64332/lib/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:3:58322)
    at e.exports.emit (events.js:315:20)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-06-23 17:43:19,bug,[DevTools Bug]: Selecting/deselecting boolean from DevTools Component props causing loss of class functions,"### Website or app

https://github.com/a-gehlot/react-error

### Repro steps

1) Install webpack, react, babel with ""npm install"" in terminal. 

2) Bundle app with webpack via ""webpack --watch --mode=developement"" in terminal.

3) Open up ""index.html"" in Chrome and open React DevTools. Under Components, there should be a Dog component within a Person component, where the Person is passed as a prop to the Dog.

4) Under Dog props, there should be a person object with a value of present being true. If you click the button, the value of present should change to false, the number should switch to 0, and the checkbox should get deselected. However, if you manually select the checkbox to change between true/false, the prop seems to lose its prototype references to the original JS class, as an error stating it cannot find the function will be shown.

https://user-images.githubusercontent.com/52260394/175361370-b6ff5dea-788f-4564-a279-57e3cae11a4d.mov

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-06-07 23:04:48,bug,"[DevTools Bug] Cannot remove node ""1168"" because no matching node was found in the Store.","### Website or app

1

### Repro steps

1

### How often does this bug happen?

Often

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.24.7-7f673317f

### Error message (automated)

Cannot remove node ""1168"" because no matching node was found in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26516:43
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24434:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24603:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:54566:39)
```


### Error component stack (automated)

```text
1
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot remove node  because no matching node was found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-05-26 22:56:27,bug,[DevTools Bug]: Component tree panel becomes unresponsive after clicking on a few components,"### Website or app

Multiple; but you can check at https://react-bootstrap.github.io/

### Repro steps

1. Access a website in Chrome that uses React.
2. Open Chrome Developer Tools
3. Open the React Developer Tools Components tab/panel
4. Click on 5 - 10 components in the component tree individually to inspect them

Notes: 

- This started happening on all React-based websites after updating to Chrome Version 102.0.5005.61 on my work MacBook (x86_64) and my personal MacBook (arm64). Reverting back to Chrome 100 seems to help.
- I had a co-worker test as well, with the same result.
- You can still select individual components using the picker, even after the panel locks up.
- The lock-up seems to happen quicker when `Expand component tree by default` is selected in the `Components` tab in the panel settings, but will still lock up if you manually expand enough components.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.24.6 (5/12/2022)

### Error message (automated)

None

### Error call stack (automated)

N/A

### Error component stack (automated)

N/A

### GitHub query string (automated)

N/A"
facebook/react,2022-05-23 20:29:50,bug,"[DevTools Bug]: ""Reload and profile"" aways disabled on Timeline tab","### Website or app

beta.reactjs.org (local development)

### Repro steps

1. https://github.com/reactjs/reactjs.org/tree/main/beta
2. `yarn dev`

""Reload and profile"" is enabled for Flamegraph:

<img width=""724"" alt=""Screenshot 2022-05-23 at 21 28 07"" src=""https://user-images.githubusercontent.com/810438/169900687-7c62d7c5-34ad-43c0-b1fa-ca45c8e16dba.png"">

But disabled for Timeline:

<img width=""671"" alt=""Screenshot 2022-05-23 at 21 28 12"" src=""https://user-images.githubusercontent.com/810438/169900693-ba60f1f4-3b37-4141-993a-70bac5647b01.png"">

And yet I can ""reload and profile"" in Flamegraph, then switch to Timeline and it works. So this doesn't add up.

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-05-14 15:57:43,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

[expo init](https://codesandbox.io/s/new)

### Repro steps

All you have to do is use 'expo init' or 'npx create-react-native-app' and make a fresh app with a blank template. When I open it with 'expo start' or 'npm start' I get this message every time in the debugger.

When I press the 'dismiss' button, I get a box that says:
'Unsupported DevTools backend version
You are running react-devtools version 4.14.0-d0ec283819.
This requires bridge protocol version 1. However the current backend version uses bridge protocol version 2.
To fix this, upgrade the DevTools NPM package: npm i -g react-devtools@^4.22.0'

I follow all the steps I can find to solve the issue (including yarn resolutions, updating node.js and packages, etc.) but nothing works at all.

I cannot initialize new apps without getting the error. I really want this debugger to work again.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.14.0-d0ec283819

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:140545
    at c.emit (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:89515)
    at G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:90986
    at G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:347787
    at Array.forEach (<anonymous>)
    at S.Gc.e.onmessage (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:347771)
    at S.n (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:40:3009)
    at S.emit (events.js:315:20)
    at e.exports.P (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:9318)
    at e.exports.emit (events.js:315:20)
    at e.exports.dataMessage (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:15409)
    at e.exports.getData (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:14651)
    at e.exports.startLoop (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:12066)
    at e.exports._write (G:\\Workspace\\rn-debugger-windows-x64\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:11421)
    at doWrite (_stream_writable.js:403:12)
    at writeOrBuffer (_stream_writable.js:387:5)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-05-12 16:28:24,bug,[DevTools Bug]: console.log() crashes the app,"### Website or app

Local development

### Repro steps

In order to reproduce it, type `console.log(*any variable or functionality)`
If using console log for printing string, it works with not errors

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-05-11 10:41:10,bug,"[DevTools Bug]: When inspecting with DevTools, it fails to select correct react component when there are multiple react-dom instances in the application","### Website or app

https://codesandbox.io/s/jtiw8m

### Repro steps

When using devtools in the linked codesandbox, I am not able to select react components that are rendered by the micro-fe using the inspect tool.

Steps to reproduce:
1. Go to https://jtiw8m.csb.app/ 
2. Open React DevTools and click on Inspect icon with the ""Select an element on the page to inspect it""  tooltip
3. Inspect the component with the pink background and text ""micro-fe example heading""
4. Devtools selects `App` as the component (or if the component type filter is disabled, it selects the `div` where the micro-fe is mounted)

Ideally it would actually select either the `MicroFeRoot` component (or the corresponding html node if the filter is disabled).

I was able to get it working by doing [the following change](https://github.com/facebook/react/compare/main...danielkutt:devtools-microfe-bug) in the `react-devtools-backend/src/backend/agent.js`



### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-05-07 00:26:58,bug,[DevTools Bug]: I believe that UI and UX from React DevTools is a big bug,"### Website or app

https://all.apllications.com

### Repro steps

Hello, community! ✌

I have an big question about the React DevTools, why is so different in comparasion with Vue DevTools ? all is more hard...

See the context, indentify the state's, the components.... 😒

In comparasion with Vue DevTools, the React DevToosl don't have a pretty and functional UI and UX. The context's, state's and components don't have a UI ogarnized  to easy indentification. On Vue DevTools there tabs to components, store (context's), events and some other features, see below:

![image](https://user-images.githubusercontent.com/92554215/167229861-13410a8e-74dd-4d6a-9b65-772e1beedbd0.png)

The vuex (context's in React environment)

![image](https://user-images.githubusercontent.com/92554215/167230399-5c5e7cfd-6431-4205-bec8-97a09191e84c.png)

Timeline of events 😍👍👍

![image](https://user-images.githubusercontent.com/92554215/167230442-44e2bbdf-00f6-42f8-aaa8-872c83fab05b.png)



### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-04-26 14:07:21,bug,"[DevTools Bug]: TreeContext error: Can't access property ""id"" in undefined","### Website or app

https://app.replay.io/

### Repro steps

Unfortunately I don't know how to reproduce this bug. It was just logged to Sentry.

It seems like there's a logic bug here though:
https://github.com/facebook/react/blob/bd4784c8f8c6b17cf45c712db8ed8ed19a622b26/packages/react-devtools-shared/src/devtools/views/Components/TreeContext.js#L386-L416

If `selectedElementIndex` is null or `elementIndicesWithErrorsOrWarnings` is empty, then `flatIndex` would be 0 still– and this statement would result in an undefined entry:
```js
prevEntry =
  elementIndicesWithErrorsOrWarnings[
    elementIndicesWithErrorsOrWarnings.length - 1
  ];
```

### How often does this bug happen?

Only once

### DevTools package (automated)

react-devtools-inline

### DevTools version (automated)

4.24.4

### Error message (automated)

Error: can't access property ""id"", n is undefined

### Error call stack (automated)

```text
React ErrorBoundary Error: can't access property ""id"", n is undefined
  at TreeContextController(./node_modules/react-devtools-inline/dist/frontend.js:20793:10)
  at SettingsContextController(./node_modules/react-devtools-inline/dist/frontend.js:21419:10)
  at ModalDialogContextController(./node_modules/react-devtools-inline/dist/frontend.js:28526:10)
  at DevTools_DevTools(./node_modules/react-devtools-inline/dist/frontend.js:44535:10)
  at useMemo(./src/ui/components/SecondaryToolbox/ReactDevTools.tsx:269:1)
  at ConnectFunction(./node_modules/react-redux/es/components/connectAdvanced.js:220:22)
  at Redacted(./src/ui/components/Redacted.tsx:5:83)
  at SecondaryToolbox(./src/ui/components/SecondaryToolbox/index.tsx:119:25)
  at useGetShowVideo(./src/devtools/client/shared/components/splitter/SplitBox.tsx:25:37)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-04-23 16:38:15,bug,"[DevTools Bug]: forwardRef components not marked as ""rendered"" if context changed","### Website or app

https://codesandbox.io/s/forwardref-context-change-did-not-render-lpdk4t?file=/src/index.js

### Repro steps

1. Goto https://lpdk4t.csb.app/
1. Start profiling
3. Enter ""a"" into the input
4. Stop profiling
![forwardRef-did-not-render](https://user-images.githubusercontent.com/12292047/164915101-f28f305a-2c51-4b89-8515-da073e5551c9.png)



### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

4.24.3-46a98cff2

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-04-21 14:05:31,bug,[DevTools Bug]: Error in event handler: Error: Attempting to use a disconnected port object,"### Website or app

https://codesandbox.io/s/blissful-raman-2on7k2

### Repro steps

1. Create a react app 
```
yarn create react-app test-react
cd test-react
yarn start
```
2. Create `.env.development` file in root.
```
HTTPS=true
PORT=4100
BROWSER=none
```
3. Visit https://localhost:4100/ in Chrome v100.0.4896.127
4. Open React Devtools by inspecting page, some times it shows `Components` tab but in large application it does not show the `Components` tab. If it shows the tab the error message is sent to dev tools every second.
5. See error message in [chrome://extensions/](chrome://extensions/)
6. This is not reproducible in Firefox v99.0.1.

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

`4.24.3 (3/30/2022)`

### Error message (automated)

`Error in event handler: Error: Attempting to use a disconnected port object`

### Error call stack (automated)
`build/background.js:139 (lOne)`

```
/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = ""/build/"";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 115);
/******/ })
/************************************************************************/
/******/ ({

/***/ 115:
/***/ (function(module, exports, __webpack_require__) {

""use strict"";
/* global chrome */


const ports = {};
const IS_FIREFOX = navigator.userAgent.indexOf('Firefox') >= 0;
chrome.runtime.onConnect.addListener(function (port) {
  let tab = null;
  let name = null;

  if (isNumeric(port.name)) {
    tab = port.name;
    name = 'devtools';
    installContentScript(+port.name);
  } else {
    tab = port.sender.tab.id;
    name = 'content-script';
  }

  if (!ports[tab]) {
    ports[tab] = {
      devtools: null,
      'content-script': null
    };
  }

  ports[tab][name] = port;

  if (ports[tab].devtools && ports[tab]['content-script']) {
    doublePipe(ports[tab].devtools, ports[tab]['content-script']);
  }
});

function isNumeric(str) {
  return +str + '' === str;
}

function installContentScript(tabId) {
  chrome.tabs.executeScript(tabId, {
    file: '/build/contentScript.js'
  }, function () {});
}

function doublePipe(one, two) {
  one.onMessage.addListener(lOne);

  function lOne(message) {
    two.postMessage(message);
  }

  two.onMessage.addListener(lTwo);

  function lTwo(message) {
    one.postMessage(message);
  }

  function shutdown() {
    one.onMessage.removeListener(lOne);
    two.onMessage.removeListener(lTwo);
    one.disconnect();
    two.disconnect();
  }

  one.onDisconnect.addListener(shutdown);
  two.onDisconnect.addListener(shutdown);
}

function setIconAndPopup(reactBuildType, tabId) {
  chrome.browserAction.setIcon({
    tabId: tabId,
    path: {
      '16': 'icons/16-' + reactBuildType + '.png',
      '32': 'icons/32-' + reactBuildType + '.png',
      '48': 'icons/48-' + reactBuildType + '.png',
      '128': 'icons/128-' + reactBuildType + '.png'
    }
  });
  chrome.browserAction.setPopup({
    tabId: tabId,
    popup: 'popups/' + reactBuildType + '.html'
  });
}

function isRestrictedBrowserPage(url) {
  return !url || new URL(url).protocol === 'chrome:';
}

function checkAndHandleRestrictedPageIfSo(tab) {
  if (tab && isRestrictedBrowserPage(tab.url)) {
    setIconAndPopup('restricted', tab.id);
  }
} // update popup page of any existing open tabs, if they are restricted browser pages.
// we can't update for any other types (prod,dev,outdated etc)
// as the content script needs to be injected at document_start itself for those kinds of detection
// TODO: Show a different popup page(to reload current page probably) for old tabs, opened before the extension is installed


if (!IS_FIREFOX) {
  chrome.tabs.query({}, tabs => tabs.forEach(checkAndHandleRestrictedPageIfSo));
  chrome.tabs.onCreated.addListener((tabId, changeInfo, tab) => checkAndHandleRestrictedPageIfSo(tab));
} // Listen to URL changes on the active tab and update the DevTools icon.


chrome.tabs.onUpdated.addListener((tabId, changeInfo, tab) => {
  if (IS_FIREFOX) {
    // We don't properly detect protected URLs in Firefox at the moment.
    // However we can reset the DevTools icon to its loading state when the URL changes.
    // It will be updated to the correct icon by the onMessage callback below.
    if (tab.active && changeInfo.status === 'loading') {
      setIconAndPopup('disabled', tabId);
    }
  } else {
    // Don't reset the icon to the loading state for Chrome or Edge.
    // The onUpdated callback fires more frequently for these browsers,
    // often after onMessage has been called.
    checkAndHandleRestrictedPageIfSo(tab);
  }
});
chrome.runtime.onMessage.addListener((request, sender) => {
  var _request$payload, _ports$id;

  const tab = sender.tab;

  if (tab) {
    const id = tab.id; // This is sent from the hook content script.
    // It tells us a renderer has attached.

    if (request.hasDetectedReact) {
      // We use browserAction instead of pageAction because this lets us
      // display a custom default popup when React is *not* detected.
      // It is specified in the manifest.
      setIconAndPopup(request.reactBuildType, id);
    } else {
      switch ((_request$payload = request.payload) === null || _request$payload === void 0 ? void 0 : _request$payload.type) {
        case 'fetch-file-with-cache-complete':
        case 'fetch-file-with-cache-error':
          // Forward the result of fetch-in-page requests back to the extension.
          const devtools = (_ports$id = ports[id]) === null || _ports$id === void 0 ? void 0 : _ports$id.devtools;

          if (devtools) {
            devtools.postMessage(request);
          }

          break;
      }
    }
  }
});

/***/ })

/******/ });
```

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-04-13 19:42:01,bug,"[DevTools Bug] Cannot add child ""foo"" to parent ""bar"" because parent node was not found in the Store.","### Website or app

https://github.com/abybaddi009/react-bug-report

### Repro steps

Steps to reproduce:

1. Install all dependencies
2. Run the project with `npm start`
3. Navigate to http://localhost:3000/login
4. Enter any number into _phone number_ and click on **GET OTP**.
5. Enter any number into the text boxes and click on **SIGN IN**.
6. Allow access to location.
7. Check the Dev Tools for the error


### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.24.3-46a98cff2

### Error message (automated)

Cannot add child ""986"" to parent ""985"" because parent node was not found in the Store.

### Error call stack (automated)

```text
emit@moz-extension://33a37ecb-24c1-4ab5-9400-2d8a276f2472/build/main.js:24430:22
bridge_Bridge/this._wallUnlisten<@moz-extension://33a37ecb-24c1-4ab5-9400-2d8a276f2472/build/main.js:24599:14
listener@moz-extension://33a37ecb-24c1-4ab5-9400-2d8a276f2472/build/main.js:54423:41
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add child  to parent  because parent node was not found in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-04-07 20:49:39,bug,Console dimming on second StrictMode render forces string cast,"<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version: 18.0.0 (congrats on the release ☺️)

## Steps To Reproduce

1. During rendering of a component, log something that doesn't naturally cast to a string (e.g., `console.log(new Set())`).
2. Wrap the tree in `StrictMode`.
3. Observe the console.

Link to code example: https://codesandbox.io/s/magical-roman-wyeud7?file=/src/App.js

Note that the console dimming isn't applied to the inline CodeSandbox dev tools, so to see the issue, you need to visit the ""fullscreen view"" here: https://wyeud7.csb.app

## The current behavior

In Chrome:

<img width=""479"" alt=""Screen Shot 2022-04-07 at 4 19 09 PM"" src=""https://user-images.githubusercontent.com/1158733/162289676-bb6ba95f-4f85-4ce3-a179-10dfed3d5ad1.png"">

As expected, there are two console logs, one dimmed. Unfortunately, the way that the dimming works forces the second log to be serialized to a string. This has two issues:
1. It can result in two of the ""same"" logs looking very ""different"" from each other, which is confusing to developers. For example, in the screenshot above, it's pretty surprising that those two console lines occur from the same `console.log` call.
2. It prevents browser dev tools introspection. This can make it inconvenient or impossible to compare the two values if the string cast doesn't include the value, as in the screenshot above. This is problematic because a key use case of printing both values is to check whether they're the same.

You can kind of work around the second issue by writing your own string cast at the log callsite, but you lose the DX of introspection, which is pretty unfortunate especially in the case of large/deeply-nested objects, etc. Easier to compare two native console values than two `JSON.stringify` dumps.

## The expected behavior

While there is a new (appreciated!) dev tools option to suppress logging for the second render entirely, there is no way to disable the dimming feature.

Any of the following options would solve the issue:
1. Provide a dev tools option to disable dimming.
2. Remove the dimming feature entirely. (So that both logs are always printed the same way.)
3. Update the dimming implementation so that it doesn't force a string cast. (Guessing this isn't possible.)
4. Improve serialization of complex values. (IMO this isn't a great option because it doesn't solve the issue of consistency/confusion, but it would be better than the current behavior if all other options are ruled out.)

Thanks for considering."
facebook/react,2022-04-05 13:03:48,bug,Bug: [eslint-plugin-exhaustive-deps] hook wrongly marked as conditional (at exact number of conditionals in FC),"<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

When using an exact number of conditionals before and after a react hook, the `React Hook ""hook_name"" is called conditionally. React Hooks must be called in the exact same order in every component render` rule is wrongly flagged as being violated. This is a really weird bug and it's kind of hard to explain. Just take a look at the code and watch as ESLint flags the hook as somehow being conditional. While this may seem like a huge edge case, this actually triggered in our code base and caused all hooks in the component to be flagged as conditional.

React version: 18.0.0 (doesn't seem to matter)

## Steps To Reproduce

1. Check out [this project](https://github.com/SanderRonde/eslint-hook-bug), run `yarn` and run `yarn eslint app/foo.tsx`.
2. Watch as the hook is incorrectly flagged as conditional.
3. Removing **or adding** one of the conditionals in the return statement makes the bug go away. The same goes for removing one of the conditionals above the hook.

Link to code example: https://github.com/SanderRonde/eslint-hook-bug
Unfortunately I couldn't get it to work online (because of a lack of terminals)

## The current behavior
Hook is incorrectly flagged as conditional

![image](https://user-images.githubusercontent.com/5385012/161759839-c3ba7be0-d708-4eb3-975a-bcd08317bd45.png)


## The expected behavior
Hook should not be conditional
"
facebook/react,2022-04-03 15:14:27,bug,Bug: [eslint-plugin-exhaustive-deps] can't find unstable value.,"<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version: 18.0.0 (not important)

## Steps To Reproduce
I'll show as a code.
<img width=""593"" alt=""스크린샷 2022-04-04 오전 12 01 05"" src=""https://user-images.githubusercontent.com/65149763/161434194-868b7fbb-9571-40d8-a4e3-2b261506d9ac.png"">

Link to code example:
https://codesandbox.io/s/stupefied-raman-g6j3fi?file=/src/App.js
<!--
  Please provide a CodeSandbox (https://codesandbox.io/s/new), a link to a
  repository on GitHub, or provide a minimal code example that reproduces the
  problem. You may provide a screenshot of the application if you think it is
  relevant to your bug report. Here are some tips for providing a minimal
  example: https://stackoverflow.com/help/mcve.
-->

## The current behavior
exhaustive-deps can't found unstable dependency.

## The expected behavior
Warn lint message.

## Opinion
I know this code is super weird but This code may be improved. something like
- Add more core lint rule like 'useState is always declared as a const'
- eslint-plugin-exhaustive-deps should find reallocation value. and calculate real value.
- Or just stay it.

I just wonder what is your opinion. thank you."
facebook/react,2022-03-30 17:31:05,bug,React DOM UMD always warns in React 18,"This is a false positive.

<img width=""952"" alt=""Screenshot 2022-03-30 at 18 25 00"" src=""https://user-images.githubusercontent.com/810438/160895998-70db1fa4-e4f2-4289-9688-1822b6fb7dc6.png"">
"
facebook/react,2022-03-29 23:03:55,bug,Bug: No warning on infinite useEffect loop in React 18,"https://codesandbox.io/s/elastic-mayer-rzz4h2?file=/package.json

This is supposed to `console.error` but it doesn't.

17 warns: https://codesandbox.io/s/admiring-minsky-sze07m?file=/src/App.js"
facebook/react,2022-03-25 13:05:28,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

http://bestellen-a.cito.nl

### Repro steps

Just opening the console and going to Components or Profiler shows this error.

I noticed that in the console there are two warnings for contentScript.js (I am assuming this file is part of this extension):
﻿
contentScript.js:113 [Violation] 'message' handler took 210ms
contentScript.js:113 [Violation] 'message' handler took 891ms

### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.24.0-82762bea5

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26326:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24400:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24566:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:54300:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-03-20 08:18:43,bug,[DevTools Bug]: Error occurs when installing react-devtools in yarn berry project,"### Website or app

https://github.com/facebook/react

### Repro steps

I tried to install react-devtools with yarn berry, so i encountered this error log.

 yarn add react-devtools -D
➤ YN0000: ┌ Resolution step
➤ YN0002: │ @react-native-aria/combobox@npm:0.2.4-alpha.1 [d995e] doesn't provide react-dom (pd70ba), requested by @react-aria/overlays
➤ YN0002: │ @react-native-aria/combobox@npm:0.2.4-alpha.1 [d995e] doesn't provide react-dom (pa0a11), requested by @react-aria/live-announcer
➤ YN0002: │ @react-native-aria/combobox@npm:0.2.4-alpha.1 [d995e] doesn't provide react-dom (pd5c9c), requested by @react-aria/combobox
➤ YN0002: │ babel-preset-expo@npm:9.0.2 doesn't provide @babel/core (pff6e6), requested by @babel/plugin-proposal-decorators
➤ YN0002: │ babel-preset-expo@npm:9.0.2 doesn't provide @babel/core (p4f633), requested by @babel/plugin-transform-react-jsx
➤ YN0002: │ babel-preset-expo@npm:9.0.2 doesn't provide @babel/core (pa1fad), requested by @babel/preset-env
➤ YN0002: │ devfeed@workspace:. doesn't provide @types/react (p5404d), requested by native-base
➤ YN0002: │ devfeed@workspace:. doesn't provide react-dom (pf66e9), requested by native-base
➤ YN0002: │ devfeed@workspace:. doesn't provide react-dom (pfc556), requested by react-use
➤ YN0060: │ devfeed@workspace:. provides react-native-safe-area-context (p3bb21) with version 4.2.1, which doesn't satisfy what native-base requests
➤ YN0060: │ devfeed@workspace:. provides react-native-svg (pc0baf) with version 12.3.0, which doesn't satisfy what native-base requests
➤ YN0002: │ react-native-codegen@npm:0.0.8 doesn't provide @babel/preset-env (p1529d), requested by jscodeshift
➤ YN0000: │ Some peer dependencies are incorrectly met; run yarn explain peer-requirements <hash> for details, where <hash> is the six-letter p-prefixed code
➤ YN0000: └ Completed
➤ YN0000: ┌ Fetch step
➤ YN0000: └ Completed in 0s 393ms
➤ YN0000: ┌ Link step
➤ YN0001: │ Error: While cloning /Users/jihoon.lim/dev/devfeed/node_modules/string_decoder/node_modules/safe-buffer -> /Users/jihoon.lim/dev/devfeed/node_modules/registry-auth-token/node_modules/safe-buffer ENOENT: no such file or directory, scandir '/Users/jihoon.lim/dev/devfeed/node_modules/string_decoder/node_modules/safe-buffer'
➤ YN0000: └ Completed in 3s 361ms
➤ YN0000: Failed with errors in 3s 927ms

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-03-13 23:31:26,bug,React Devtools won't connect to Application running on iOS Simulator,"React Devtools doesn't connect to the instance running in the iOS Simulator.

React DevTools Screenshot

![image](https://user-images.githubusercontent.com/542948/158083928-0be956e7-6357-4308-8990-55cd3d0a8565.png)

iOS Simulator Screenshot

![image](https://user-images.githubusercontent.com/542948/158083953-c61f5079-78a9-4424-bae9-c7dfbd633404.png)

React Native appears to have some interactivity as you can see ""DevTools initialized"" and the inspector on the iOS Simulator is running in the condensed mode.

OS: macOS Monterey (12.2.1)
Chip: Apple M1 Pro"
facebook/react,2022-02-26 13:41:36,bug,[DevTools Bug] Cannot read properties of undefined (reading 'split'),"### Website or app

https://next-rsc-notes.vercel.app/

### Repro steps

1. enter the site
2. open react-devtools
3. select We(maybe suspense's child component)
4. and show following errors.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.23.0-e28a0db22

### Error message (automated)

Cannot read properties of undefined (reading 'split')

### Error call stack (automated)

```text
at getDerivedStateFromError (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37414:114)
    at ErrorBoundary_ErrorBoundary.c.payload (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:16143:14)
    at Gg (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:14571:47)
    at Dj (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:16788:5)
    at jl (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:19204:86)
    at il (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18756:11)
    at hl (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18748:23)
    at Wk (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18732:5)
    at al (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18393:37)
    at Uk (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:18314:51)
```


### Error component stack (automated)

```text
at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37375:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37864:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40513:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:33354:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35975:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42520:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37375:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37518:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37548:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37518:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42700:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42146:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30256:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30878:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37927:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:53807:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot read properties of undefined (reading 'split') in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-02-16 04:09:44,bug,"[DevTools Bug] Unsupported Bridge operation ""0""","### Website or app

local app development

### Repro steps

just install react devtools and downgrade to 4.11.0 

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.23.0-e28a0db22

### Error message (automated)

Unsupported Bridge operation ""0""

### Error call stack (automated)

```text
at /Users/softwaremac/Desktop/Users/JigneshJani/RNProjects/WifiSwitch/WifiSwitchV2_29_5/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:53:333837
    at c.emit (/Users/softwaremac/Desktop/Users/JigneshJani/RNProjects/WifiSwitch/WifiSwitchV2_29_5/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:53:277732)
    at /Users/softwaremac/Desktop/Users/JigneshJani/RNProjects/WifiSwitch/WifiSwitchV2_29_5/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:53:279273
    at /Users/softwaremac/Desktop/Users/JigneshJani/RNProjects/WifiSwitch/WifiSwitchV2_29_5/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:53:659742
    at Array.forEach (<anonymous>)
    at A.e.onmessage (/Users/softwaremac/Desktop/Users/JigneshJani/RNProjects/WifiSwitch/WifiSwitchV2_29_5/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:53:659726)
    at A.t (/Users/softwaremac/Desktop/Users/JigneshJani/RNProjects/WifiSwitch/WifiSwitchV2_29_5/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:44:3009)
    at A.emit (events.js:315:20)
    at e.exports.L (/Users/softwaremac/Desktop/Users/JigneshJani/RNProjects/WifiSwitch/WifiSwitchV2_29_5/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:8:13567)
    at e.exports.emit (events.js:315:20)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Unsupported Bridge operation  in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-02-13 08:52:26,bug,[DevTools Bug]: DevTools failed to load source map,"### Website or app

Inital React App -> npm create-react-app

### Repro steps

1. Created initial react app
2. Typed ""npm start"" inside app folder
3. Check console of Chrome browser

This is what I get on my console in Chrome ""Version 98.0.4758.82 (Official Build) (64-bit)"":
![image](https://user-images.githubusercontent.com/17859431/153745907-5822f5f2-4bb4-43d7-b03b-d42edd5d64a7.png)

As these messages are annoying, please let me know how to fix this?

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

4.23.0

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-02-09 05:24:38,bug,"[DevTools Bug] Unsupported Bridge operation ""0""","### Website or app

none

### Repro steps

gaolinxiong

### How often does this bug happen?

Only once

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.23.0-e28a0db22

### Error message (automated)

Unsupported Bridge operation ""0""

### Error call stack (automated)

```text
at /usr/local/lib/node_modules/react-devtools/node_modules/_react-devtools-core@4.23.0@react-devtools-core/dist/standalone.js:53:333837
    at c.emit (/usr/local/lib/node_modules/react-devtools/node_modules/_react-devtools-core@4.23.0@react-devtools-core/dist/standalone.js:53:277732)
    at /usr/local/lib/node_modules/react-devtools/node_modules/_react-devtools-core@4.23.0@react-devtools-core/dist/standalone.js:53:279273
    at /usr/local/lib/node_modules/react-devtools/node_modules/_react-devtools-core@4.23.0@react-devtools-core/dist/standalone.js:53:659742
    at Array.forEach (<anonymous>)
    at A.e.onmessage (/usr/local/lib/node_modules/react-devtools/node_modules/_react-devtools-core@4.23.0@react-devtools-core/dist/standalone.js:53:659726)
    at A.t (/usr/local/lib/node_modules/react-devtools/node_modules/_react-devtools-core@4.23.0@react-devtools-core/dist/standalone.js:44:3009)
    at A.emit (events.js:315:20)
    at e.exports.L (/usr/local/lib/node_modules/react-devtools/node_modules/_react-devtools-core@4.23.0@react-devtools-core/dist/standalone.js:8:13567)
    at e.exports.emit (events.js:315:20)
```


### Error component stack (automated)

```text
123
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Unsupported Bridge operation  in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2022-01-21 15:54:01,bug,DevTools should not crawl unmounted subtrees when profiling starts,"Previously we crawled all subtrees, even not-yet-mounted ones, to initialize context values. This was not only unecessary, but it also caused an error to be thrown. This commit adds a test and fixes that behavior.

Resolves #22970

### Test (before)

![Screen Shot 2022-01-21 at 10 51 54 AM](https://user-images.githubusercontent.com/29597/150558047-142daef9-8566-497e-be1f-0d1fdd38ced9.png)

### Test (after)

![Screen Shot 2022-01-21 at 10 52 03 AM](https://user-images.githubusercontent.com/29597/150558049-e6dc7ecc-d7d6-4723-b0a9-ea8f73bbae64.png)

"
facebook/react,2022-01-18 20:59:20,bug,[DevTools Bug]: Chrome Dev Tools extension shows websites built with other framework as React web sites,"### Website or app

https://angular.io/start

### Repro steps

1. Go to https://angular.io/start or https://vuejs.org/
2. Click on React Dev Tools extension
3. You should see message **This page is using the production build of React. ✅**


### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-01-15 21:52:53,bug,[DevTools Bug]: Highlight updates when components render.,"### Website or app

nothing

### Repro steps

create a component list memoized (React.memo), and if you only modify 1 of them, this will mark that all are rendered, but if they are memoized the report says ""not re-renders"" detected

![Screenshot from 2022-01-15 21-51-08](https://user-images.githubusercontent.com/86263126/149638836-1d12c2e2-ea81-42fd-9aef-4fd43ba1424d.png)

if you see near to `typography` all those children are memoized and they arent re-rendering (expected) but devtools still highliting them if u see those `yellow boxes`

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-01-14 05:36:41,bug,[DevTools Bug]: 'This page is using the react build message' in every site,"### Website or app

youtube.com, github.com, gmail.com, lucidchart.app

### Repro steps

1. Open any web app not made with React (e.g.: youtube.com, amazon.com, github.com, gmail.com, lucidchart.app)
2.  The react icon is ON and the popover message says:
 'This page is using the production build of React. ✅'


### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2022-01-10 17:54:13,bug,React 18: Context providers are reset to initial value in SSR during rendering,"<!--
  Ask a question or share feedback about the React 18 release here.
-->

While testing SSR streaming in latest React 18 experimental and alpha versions, [we noticed](https://github.com/Shopify/hydrogen/issues/415) that context providers are reset to their initial values during rendering under certain conditions.
It works well when handling 1 request at a time. However, when the server gets 2 or more requests at the same time, the context providers seem to get confused. The context is correct at the beginning of the rendering for each request but it gets lost after a while.

There's a reproduction here using @gaearon 's demo: https://codesandbox.io/s/keen-snowflake-8nyo8?file=/src/data.js:1035-1082

To my understanding, since the React tree is wrapped in a provider in SSR, `useContext` should never return `null` in the server. Have a look at the terminal and see how it actually logs `null` sometimes when getting multiple requests.


```
[0] This should never be null: { read: [Function: read] }
[0] This should never be null: { read: [Function: read] }
[0] This should never be null: null
[0] This should never be null: null
```

Run the following code from the console to simulate multiple requests:

```js
function doRequest() { return fetch('https://8nyo8.sse.codesandbox.io/', {headers: {accept:'text/html'}}).then(r => r.text()) }
await Promise.all([doRequest(), doRequest()])
```

We saw this same issue in different setups, using both Webpack and Vite.

Thanks!
"
facebook/react,2021-12-30 21:12:29,bug,"[DevTools Bug]: Error: Could not find ID for Fiber ""...""","### Website or app

https://github.com/d-pollard/react-konva-devtools-issue

### Repro steps

1. Install repo
2. run repo
3. visit `/playground` in your browser of choice. 
4. Navigate to the dev tools, and you should see the error

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-12-25 22:22:58,bug,[DevTools Bug] Cannot read properties of undefined (reading 'push'),"### Website or app

https://nickretallack.github.io/nameless-language/

### Repro steps

Just view the components tab.

This site is written in Rescript.

Actually, this is all the Rescript code you need to break devtools:

```rescript
@react.component
let make = () => {
  let _ = ReactUpdate.useReducer((_: unit, _: unit) => ReactUpdate.NoUpdate, ())
  React.useEffect(() => None)
  <div />
}
```

`ReactUpdate` is provided by [`rescript-react-update`](https://github.com/bloodyowl/rescript-react-update)


### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.22.0-0229baee2

### Error message (automated)

Cannot read properties of undefined (reading 'push')

### Error call stack (automated)

```text
at F (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13216:7)
    at H (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13250:10)
    at exports.inspectHooksOfFiber (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13310:12)
    at inspectElementRaw (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:8067:65)
    at Object.inspectElement (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:8350:38)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:10183:56
    at Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:4225:18)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:4868:14
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:12176:9)
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38950:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37307:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37796:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40436:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:33294:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35907:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42439:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37307:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37450:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37480:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37450:3)
    at TimelineContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42619:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42065:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30204:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30826:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37859:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:53732:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot read properties of undefined (reading 'push') in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-12-18 07:08:12,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

app

### Repro steps

1. run npm start for native.
2. run android for native.
3. run react native debugger

and thats how happened.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.14.0-d0ec283819

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at /usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:48:140545
    at c.emit (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:48:89515)
    at /usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:48:90986
    at /usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:48:347787
    at Array.forEach (<anonymous>)
    at S.Gc.e.onmessage (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:48:347771)
    at S.n (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:40:3009)
    at S.emit (events.js:315:20)
    at e.exports.P (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:8:9318)
    at e.exports.emit (events.js:315:20)
    at e.exports.dataMessage (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:8:15409)
    at e.exports.getData (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:8:14651)
    at e.exports.startLoop (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:8:12066)
    at e.exports._write (/usr/lib/react-native-debugger/resources/app.asar/node_modules/react-devtools-core/dist/standalone.js:8:11421)
    at doWrite (_stream_writable.js:403:12)
    at writeOrBuffer (_stream_writable.js:387:5)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-12-15 22:22:47,bug,Bug: ,"Using `react-dom@^18.0.0-rc.0` inside a nextjs project(`next@12.0.7`), then opening a [antd](https://ant.design/) dropdown, will cause page to be deadly frozen. After downgraded react to `17.0.2`, the issue disappears.

My wild guess: this issue caused by some conflict btw dom manipulation and animation.

I'm happy to show detailed stuff if the React team needs. 

React version:
18.0.0-rc.0
"
facebook/react,2021-12-15 06:16:59,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

https://github.com/TheRitual/ByHeart

### Repro steps

Accualy this bug appears only on React Native debugger. The web version of debugger doesn't show any errors. The project is new and i just installed packages
```
$ expo install react-navigation
$ expo install react-navigation-stack
$ expo install expo-app-loading
$ expo install react-native-screens
$ expo install react-native-safe-area-context
```

so my dependencies are:

```json
""dependencies"": {
    ""expo"": ""~43.0.2"",
    ""expo-status-bar"": ""~1.1.0"",
    ""react"": ""17.0.1"",
    ""react-dom"": ""17.0.1"",
    ""react-native"": ""0.64.3"",
    ""react-native-web"": ""0.17.1"",
    ""react-navigation"": ""^4.4.4"",
    ""react-navigation-stack"": ""^2.10.4"",
    ""expo-app-loading"": ""~1.2.1"",
    ""react-native-screens"": ""~3.8.0"",
    ""react-native-safe-area-context"": ""3.3.2""
  },
```

I checked and now this bug appears in every new expo init even if it is just blank project. Old projects work fine.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.14.0-d0ec283819

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:140545
    at c.emit (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:89515)
    at C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:90986
    at C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:347787
    at Array.forEach (<anonymous>)
    at S.Gc.e.onmessage (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:48:347771)
    at S.n (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:40:3009)
    at S.emit (events.js:315:20)
    at e.exports.P (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:9318)
    at e.exports.emit (events.js:315:20)
    at e.exports.dataMessage (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:15409)
    at e.exports.getData (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:14651)
    at e.exports.startLoop (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:12066)
    at e.exports._write (C:\\Users\\Ritual\\AppData\\Local\\react_native_debugger\\app-0.12.1\\resources\\app.asar\\node_modules\\react-devtools-core\\dist\\standalone.js:8:11421)
    at doWrite (_stream_writable.js:403:12)
    at writeOrBuffer (_stream_writable.js:387:5)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-12-15 03:33:08,bug,react-devtools report Error: Cannot find module './app',"react-devtools version: 4.22.0
npm -g install react-devtools
react-devtools

```
internal/modules/cjs/loader.js:905
  throw err;
  ^

Error: Cannot find module './app'
Require stack:
- /Users/foo/.nvm/versions/node/v14.18.1/lib/node_modules/react-devtools/bin.js
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:902:15)
    at Function.resolve (internal/modules/cjs/helpers.js:99:19)
    at Object.<anonymous> (/Users/foo/.nvm/versions/node/v14.18.1/lib/node_modules/react-devtools/bin.js:32:46)
    at Module._compile (internal/modules/cjs/loader.js:1085:14)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1114:10)
    at Module.load (internal/modules/cjs/loader.js:950:32)
    at Function.Module._load (internal/modules/cjs/loader.js:790:12)
    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:76:12)
    at internal/main/run_main_module.js:17:47 {
  code: 'MODULE_NOT_FOUND',
  requireStack: [
    '/Users/foo/.nvm/versions/node/v14.18.1/lib/node_modules/react-devtools/bin.js'
  ]
}
```"
facebook/react,2021-12-12 22:54:31,bug,"[DevTools Bug]: Fetch API cannot load webpack-internal:///... URL scheme ""webpack-internal"" is not supported","### Website or app

https://prnt.sc/22rtnf0

### Repro steps

Most actions in DevTools (search for component, click on component, hook parsing, profile record, etc) cause this error.

I am using Next.JS 12 within a NX monorepo.

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-12-03 22:06:42,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

https://pasteboard.co/6Ec3lSzDE4Yz.png

### Repro steps

1. Open Chrome with 50+ tabs.
2. Run React-based website locally.
3. Open Chrome Dev Tools to investigate [ActiveLink component](https://pasteboard.co/6Ec3lSzDE4Yz.png) hierarchy inside [Navbar component](https://pasteboard.co/ab8kgmDNgn1I.png). 
4. ActiveLink component from [Next](https://github.com/vercel/next.js/tree/canary/examples/active-class-name) was used.
5. Get uncaught error [Screenshot](https://pasteboard.co/3ugPX34TF2Xr.png)

### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.21.0-2f8f60ca8

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:26134:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24349:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24509:12
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:53230:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-11-22 22:10:53,bug,Bug: Error checking code is skipped for async useEffect argument,"<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->
React no longer complains when the function passed to `useEffect` returns a Promise (either directly or by being labeled `async`). I'm not in the habit of doing this, so it was only when I watched someone else make the function `async` and there were no errors that I realized that something had changed since 6.13.1 (the newest version I could find that still complained).

I can see the functionality is still present in `commitHookEffectListMount` in react-dom.development.js, but when I trace through it, the `effect.tag` is set to a different value and the test is skipped.

I realize that we now have an ESLint rule that provides the same message, but the lack of warning caused confusion about whether asynchronous functions were now allowed. 




React version: 17.0.2 

## Steps To Reproduce

1. Write a `useEffect` that has an `async` function
2. Open the console and observe that it doesn't complain

<!--
  Your bug will get fixed much faster if we can run your code and it doesn't
  have dependencies other than React. Issues without reproduction steps or
  code examples may be immediately closed as not actionable.
-->

Link to code example: https://codesandbox.io/s/winter-wind-l33bi

<!--
  Please provide a CodeSandbox (https://codesandbox.io/s/new), a link to a
  repository on GitHub, or provide a minimal code example that reproduces the
  problem. You may provide a screenshot of the application if you think it is
  relevant to your bug report. Here are some tips for providing a minimal
  example: https://stackoverflow.com/help/mcve.
-->

## The current behavior
The code runs with no complaints, and the cleaner function is ignored. 

## The expected behavior
The console should show the warning:

```
Warning: An effect function must not return anything besides a function, which is used for clean-up.

It looks like you wrote useEffect(async () => ...) or returned a Promise. Instead, write the async function inside your effect and call it immediately:

useEffect(() => {
  async function fetchData() {
    // You can await here
    const response = await MyAPI.getData(someId);
    // ...
  }
  fetchData();
}, [someId]); // Or [] if effect doesn't need props or state
```"
facebook/react,2021-11-20 12:40:28,bug,"React 18 Bug: react-dom/server ""Detected multiple renderers..."" if preceeded by react-test-renderer","<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version: 18.0.0-beta-149b420f6-20211119

## Steps To Reproduce

1. render a context with `react-test-renderer` (wrapped in act)
2. render the same context with `react-dom/server`

<!--
  Your bug will get fixed much faster if we can run your code and it doesn't
  have dependencies other than React. Issues without reproduction steps or
  code examples may be immediately closed as not actionable.
-->

Link to code example: https://codesandbox.io/s/react-18-react-test-renderer-react-dom-server-forked-lbs7j?file=/package.json:189-219
```js
const Context = React.createContext(null);

function Component({ renderer }) {
  return (
    <Context.Provider value={renderer}>
      <div />
    </Context.Provider>
  );
}

let testRendererRoot;
ReactTestRenderer.act(() => {
  testRendererRoot = ReactTestRenderer.create(
    <Component renderer=""react-test-renderer"" />
  );
});
ReactTestRenderer.act(() => {
  testRendererRoot.unmount();
});

ReactDOMServer.renderToString(<Component renderer=""react-dom/server"" />);
```

## The current behavior

`renderToString` results in the console error ""Warning: Detected multiple renderers concurrently rendering the same context provider. This is currently unsupported.""


## The expected behavior

No error like in React 17 (https://codesandbox.io/s/react-17-react-test-renderer-react-dom-server-yr8gx).
Considering all renders are wrapped in their corresponding `act` I don't expect that I'm concurrently rendering. 

I tried to understand when we reset the `rendererSigil` (responsible for checking if we ""concurrently rendering"") is reset and it seems like we never reset it but only initialize it when creating the context (`createContext`)
So it either seems like multiple renderers in the same module are not supported anymore or the reset is missing.

"
facebook/react,2021-11-15 21:35:11,bug,[DevTools Bug] Cannot read properties of undefined (reading 'push'),"### Website or app

https://codesandbox.io/s/react-devtools-weird-bug-o3sib?file=/src/App.js

### Repro steps

I stumbled across the weirdest bug with React DevTools and hooks that causes it to error out when inspecting a component. A minimal test case is documented in the Code Sandbox link, along with more details on the behavior and seemingly-arbitrary fixes. This does not affect the actual functionality of the app itself in any way, it behaves exactly as expected.

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.21.0-2f8f60ca8

### Error message (automated)

Cannot read properties of undefined (reading 'push')

### Error call stack (automated)

```text
at J (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13006:7)
    at L (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13040:10)
    at exports.inspectHooksOfFiber (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13101:12)
    at inspectElementRaw (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:7732:65)
    at Object.inspectElement (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:8004:38)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:9837:56
    at Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:4257:18)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:10500:12
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:11737:9)
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38726:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37092:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37572:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40146:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35254:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35695:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42085:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37092:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37222:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37256:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37222:3)
    at SchedulingProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:43423:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:41711:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30116:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30727:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37635:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:53004:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot read properties of undefined (reading 'push') in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-11-11 08:34:48,bug,"Bug: React instrumentation encountered an error: Error: Could not find ID for Fiber ""Portal""","<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version:  17.0.2

## Steps To Reproduce
1. 
> when i execute `Modal.hide()` 

2.
![image](https://user-images.githubusercontent.com/36684351/141264440-be0f55b9-4aa8-4ff4-a9de-1c8c0291f813.png)

<!--
  Your bug will get fixed much faster if we can run your code and it doesn't
  have dependencies other than React. Issues without reproduction steps or
  code examples may be immediately closed as not actionable.
-->

Link to code example:
![image](https://user-images.githubusercontent.com/36684351/141264419-bcb20cd5-8f69-44d8-a8b2-2cf5c64882b8.png)

<!--
  Please provide a CodeSandbox (https://codesandbox.io/s/new), a link to a
  repository on GitHub, or provide a minimal code example that reproduces the
  problem. You may provide a screenshot of the application if you think it is
  relevant to your bug report. Here are some tips for providing a minimal
  example: https://stackoverflow.com/help/mcve.
-->

## The current behavior


## The expected behavior
"
facebook/react,2021-11-03 18:31:39,bug,[DevTools Bug] dispatcher.useId is not a function,"### Website or app

https://c8wik.csb.app/

### Repro steps

1. open https://c8wik.csb.app/
2. Inspect `App`

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.21.0-2f8f60ca8

### Error message (automated)

dispatcher.useId is not a function

### Error call stack (automated)

```text
at useId (https://c8wik.csb.app/node_modules/react/cjs/react.development.js:1707:21)
    at App (https://c8wik.csb.app/src/index.js:15:31)
    at L (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13032:5)
    at exports.inspectHooksOfFiber (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:13101:12)
    at inspectElementRaw (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:7732:65)
    at Object.inspectElement (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:8004:38)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:9837:56
    at Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:4257:18)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:10500:12
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/react_devtools_backend.js:11737:9)
```


### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38726:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37092:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37572:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40146:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35254:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:35695:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42085:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37092:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37222:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37256:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37222:3)
    at SchedulingProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:43423:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:41711:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30116:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:30727:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37635:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:53004:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=dispatcher.useId is not a function in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-11-03 14:06:08,bug,Bug: use-sync-external-store fails to install via npm,"When trying to install the `use-sync-external-store` package via npm, I receive an error that it depends on a version of React that doesn't seem to exist.

React version: 17

## Steps To Reproduce

1. `mkdir example && cd example && npm init`
2. `npm i react react-dom use-sync-external-store`

## The current behavior

npm fails to install the `use-sync-external-store` package with the following error:

```
npm i use-sync-external-store
npm ERR! code ERESOLVE
npm ERR! ERESOLVE unable to resolve dependency tree
npm ERR!
npm ERR! While resolving: example@1.0.0
npm ERR! Found: react@17.0.2
npm ERR! node_modules/react
npm ERR!   react@""^17.0.2"" from the root project
npm ERR!
npm ERR! Could not resolve dependency:
npm ERR! peer react@""0.0.0-experimental-45898dacb2-20210828"" from use-sync-external-store@0.0.0-experimental-45898dacb2-20210828
npm ERR! node_modules/use-sync-external-store
npm ERR!   use-sync-external-store@""*"" from the root project
npm ERR!
npm ERR! Fix the upstream dependency conflict, or retry
npm ERR! this command with --force, or --legacy-peer-deps
npm ERR! to accept an incorrect (and potentially broken) dependency resolution.
npm ERR!
```

## The expected behavior

It successfully installs the package and I can use it in React v17 and the latest alpha version."
facebook/react,2021-10-21 16:24:25,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","
![Screen Shot 2021-10-21 at 12 23 23 PM](https://user-images.githubusercontent.com/10363251/138318510-7806a238-ff15-4ce9-87d6-5a8304e503f4.png)
![Screen Shot 2021-10-21 at 12 22 57 PM](https://user-images.githubusercontent.com/10363251/138318511-04e41128-632c-4045-8129-5f07b6729f16.png)
### Website or app

daily harvest

### Repro steps

1. Enable debug on the IOS emulator.
2. Enable Inspector.
3. Disable inspector, navigate to a different screen.
4. Try enabling inspector again. 

### How often does this bug happen?

Every time

### DevTools package (automated)

react-devtools-core

### DevTools version (automated)

4.18.0-f58bbcf9a

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at /Users/krishnagaurav/mobile-app/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:344699
    at c.emit (/Users/krishnagaurav/mobile-app/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:280870)
    at /Users/krishnagaurav/mobile-app/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:282341
    at /Users/krishnagaurav/mobile-app/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:650666
    at Array.forEach (<anonymous>)
    at A.e.onmessage (/Users/krishnagaurav/mobile-app/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:48:650650)
    at A.t (/Users/krishnagaurav/mobile-app/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:40:3009)
    at A.emit (events.js:315:20)
    at e.exports.F (/Users/krishnagaurav/mobile-app/node_modules/react-devtools/node_modules/react-devtools-core/dist/standalone.js:8:9731)
    at e.exports.emit (events.js:315:20)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-10-20 08:46:39,bug,[DevTools Bug]: Blank tools localhost - react_devtools_backend.js:5821 Uncaught Error: Could not find ID for Fiber,"### Website or app

www.google.com

### Repro steps

React Devtools - 4.20.0
React - 16.8.6

Not sure if relevant but:
react-scripts 4.0.3

First I get an blank devtools (components) but when picking select element arrow and hover over elements a lot of errors like this one shows up in the console:

```
react_devtools_backend.js:5821 Uncaught Error: Could not find ID for Fiber ""Context.Provider""
    at getFiberIDThrows (react_devtools_backend.js:5821)
    at Object.getFiberIDForNative (react_devtools_backend.js:7257)
    at Overlay_Overlay.inspect (react_devtools_backend.js:9158)
    at showOverlay (react_devtools_backend.js:9286)
    at onPointerOver (react_devtools_backend.js:9445)
getFiberIDThrows @ react_devtools_backend.js:5821
getFiberIDForNative @ react_devtools_backend.js:7257
inspect @ react_devtools_backend.js:9158
showOverlay @ react_devtools_backend.js:9286
onPointerOver @ react_devtools_backend.js:9445
```
No other errors occur. Devtools works fine on deployed version. Eg. https://reactjs.org/ works fine. 

PR and issue that could be related?
[Issue 22577](https://github.com/facebook/react/issues/22577
)
[PR 22527](https://github.com/facebook/react/pull/22527
)

Maybe relevant comment from author and maintainer of React DevTools:
[Earlier fiber problem](https://stackoverflow.com/questions/67623677/warning-react-instrumentation-encountered-an-error-error-could-not-find-id-fo)

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-10-18 10:24:54,bug,[DevTools Bug]: Blank tools localhost only,"### Website or app

google.com

### Repro steps

This started after last update 4.20.0
![image](https://user-images.githubusercontent.com/11052469/137713404-e6702959-7870-46a6-8566-4cfe61d25309.png)
![image](https://user-images.githubusercontent.com/11052469/137713464-c5e478d2-4e9e-4ee4-abdf-83d23c04704b.png)


### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-10-15 19:16:38,bug,"[DevTools Bug] Cannot add node ""1"" because a node with that id is already in the Store.","### Website or app

https://wayray.com/#how-we-work

### Repro steps

not able to see

### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.19.2-20ca9b565

### Error message (automated)

Cannot add node ""1"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:25708:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:23923:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24083:12
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:52511:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-10-08 13:01:20,bug,"[DevTools Bug] Cannot add node ""2934"" because a node with that id is already in the Store.","### Website or app

http:localhost:3000/

### Repro steps

When I was using react select and dropdown. I clicked on and before opening the dropdown this error showed up and react dev tools stopped working

### How often does this bug happen?

Sometimes

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.19.0-2178a831a

### Error message (automated)

Cannot add node ""2934"" because a node with that id is already in the Store.

### Error call stack (automated)

```text
at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:25701:41
    at bridge_Bridge.emit (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:23916:22)
    at chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:24076:12
    at listener (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:52332:39)
```


### Error component stack (automated)

_No response_

### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Cannot add node  because a node with that id is already in the Store. in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-10-01 13:24:11,bug,"[DevTools Bug] Could not inspect element with id ""15"". Error thrown:Cached data for element ""15"" not found","### Website or app

https://github.com/santhosh-reddy03/react_practice

### Repro steps

$cd repo
and then start the server using npm start

in browser(mozilla firefox)
when i try to add the user and age, and trying to debug the output in ListUsers component, I m facing this error
![Screenshot from 2021-10-01 18-52-36](https://user-images.githubusercontent.com/53914022/135627139-ca7132b6-f39d-4330-8b7d-0cc5281ab552.png)


### How often does this bug happen?

Only once

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.19.0-2178a831a

### Error message (automated)

Could not inspect element with id ""15"". Error thrown:Cached data for element ""15"" not found

### Error call stack (automated)

_No response_

### Error component stack (automated)

```text
InspectedElementContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:38121:43
Suspense
ErrorBoundary_ErrorBoundary@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:36518:5
div
InspectedElementErrorBoundaryWrapper@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:36967:46
NativeStyleContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:39541:38
div
div
OwnersListContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:34741:37
SettingsModalContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:35182:40
Components_Components@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:41481:52
ErrorBoundary_ErrorBoundary@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:36518:5
div
div
ThemeProvider@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:36635:23
PortaledContent@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:36669:34
div
div
div
ThemeProvider@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:36635:23
SchedulingProfilerContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:42673:45
ProfilerContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:41106:35
TreeContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:29603:31
SettingsContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:30214:35
ModalDialogContextController@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:37030:38
DevTools_DevTools@moz-extension://8a220e8e-c7fe-42e7-9ec5-0b6e67ae5dd5/build/main.js:52130:27
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Could not inspect element with id . Error thrown:
Cached data for element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2021-09-24 20:15:48,bug,[DevTools Bug]: Emoji as visual helper produce strange symbole,"### Website or app

https://codesandbox.io/s/react-playground-forked-j4niq

### Repro steps

Emoji seem supported but produce strange symbole

![image](https://user-images.githubusercontent.com/24865815/133793744-55a55582-90ad-425f-8a40-4c061a3c1d80.png)

To test emoji on Window Os, use `[win]+[.]` 🟩


### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-09-17 13:52:27,bug,[DevTools Bug]:  Emoji seem supported but produce strange symbole,"### Website or app

????

### Repro steps


Emoji seem supported but produce strange symbole

![image](https://user-images.githubusercontent.com/24865815/133793744-55a55582-90ad-425f-8a40-4c061a3c1d80.png)

Very low priority maybe because it affect nothing .

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-09-15 19:15:59,bug,[DevTools Bug]: Hook parsing fails with fetch error,"### Website or app

https://p181.p1.n0.cdn.getcloudapp.com/items/4gulW8Wo/3bba0881-ee74-4478-8cb8-68370b878855.jpg?v=ab371b6e8fca2cee905d1b9f828ac0d8

### Repro steps

have a webpack project that uses a domain mapped to your local IP such as (appx.whenidev.net) in my case that's served with https
try to resolve hook names
check console and observe the million errors

https://p181.p1.n0.cdn.getcloudapp.com/items/4gulW8Wo/3bba0881-ee74-4478-8cb8-68370b878855.jpg?v=ab371b6e8fca2cee905d1b9f828ac0d8 shows my console

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-09-14 15:08:34,bug,DevTools: Backend console settings reportedly not synced to RN backend,"@feedthejim reported that disabling the ""Break on Warning"" feature does not update the backend settings (in memory, without a reload) for React Native:
![Screen Shot 2021-09-14 at 11 07 04 AM](https://user-images.githubusercontent.com/29597/133283506-88094c34-7251-461e-af3b-67f83e9804fd.png)

I believe the new settings should be updated here:
https://github.com/facebook/react/blob/263cfa6ecb9879ecb629d4e04a8c26422b4c4ff9/packages/react-devtools-shared/src/backend/console.js#L133-L138

But it sounds like they aren't. We should investigate."
facebook/react,2021-09-08 07:31:12,bug,"[DevTools Bug] Could not inspect element with id ""28"". Error thrown:Cached data for element ""28"" not found","### Website or app

website URL (localhost)

### Repro steps

Clicked the ""Reload Devtools"" button to turn devtools in light mode.
Devtools were already in light mode.

### How often does this bug happen?

Only once

### DevTools package (automated)

react-devtools-extensions

### DevTools version (automated)

4.18.0-f58bbcf9a

### Error message (automated)

Could not inspect element with id ""28"". Error thrown:Cached data for element ""28"" not found

### Error call stack (automated)

_No response_

### Error component stack (automated)

```text
at InspectedElementContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:37563:3)
    at Suspense
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36097:5)
    at div
    at InspectedElementErrorBoundaryWrapper (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36542:3)
    at NativeStyleContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:38972:3)
    at div
    at div
    at OwnersListContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:34323:3)
    at SettingsModalContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:34764:3)
    at Components_Components (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40911:52)
    at ErrorBoundary_ErrorBoundary (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36097:5)
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36215:3)
    at PortaledContent (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36249:5)
    at div
    at div
    at div
    at ThemeProvider (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36215:3)
    at SchedulingProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:42093:3)
    at ProfilerContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:40537:3)
    at TreeContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:29185:3)
    at SettingsContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:29796:3)
    at ModalDialogContextController (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:36605:3)
    at DevTools_DevTools (chrome-extension://fmkadmapgofadopljbjfkapdkoienihi/build/main.js:51354:3)
```


### GitHub query string (automated)

```text
https://api.github.com/search/issues?q=Could not inspect element with id . Error thrown:
Cached data for element  not found in:title is:issue is:open is:public label:""Component: Developer Tools"" repo:facebook/react
```
"
facebook/react,2023-03-08 23:01:21,feature,[DevTools Bug]: provide an icon to Edge devtools?,"### Website or app

Website: https://reactjs.org/

### Repro steps

1. open developer tools in Edge
2. go to settings -> experiment -> enable Focus Mode -> reload DevTools
3. we can see the react extension is loaded as below in devtools:
![image](https://user-images.githubusercontent.com/108438266/223870494-509d7658-220c-45e5-8399-05a0fa1e6171.png)

4. since the react extension doesn't provide the icon when it's created, devtools fallback to use the default icon to represent the extension. However, we've received couple of requests from users that they'd like to see the icon in the panel.
for instance:
![image](https://user-images.githubusercontent.com/108438266/223870622-a68fa934-4ba0-450b-aa02-96c66ccab1cb.png)

Wondering if it's possible to provide an icon to Edge in the `chrome.devtools.panels.create()`?
Thank you for your support.

### How often does this bug happen?

Every time

### DevTools package (automated)

_No response_

### DevTools version (automated)

_No response_

### Error message (automated)

_No response_

### Error call stack (automated)

_No response_

### Error component stack (automated)

_No response_

### GitHub query string (automated)

_No response_"
facebook/react,2021-07-27 18:34:14,feature,Bug: `onResize` media event is missing,"Note: I’m happy to make a pull request to fix this, I just wanted to log it first to ensure there’s interest.

---

React’s [synthetic media events](https://reactjs.org/docs/events.html#media-events) contain several [existing media events](https://html.spec.whatwg.org/multipage/media.html#mediaevents), for instance `onLoadedMetadata` and `onVolumeChange`. But there is no `onResize` handler.

[`resize` is a standard media event](https://html.spec.whatwg.org/multipage/media.html#event-media-resize) that triggers when one or both of the `videoWidth` and `videoHeight` attributes have just been updated. It’s useful for responding to resolution changes in video players.

React version: 17.0.2 (latest release as of initial issue report)

## Steps To Reproduce

1. Create a `<video>` element with an `onResize` prop.
2. Check the console for the following warning:

```
 Warning: Unknown event handler property `onResize`. It will be ignored.
```

Link to code example: https://codesandbox.io/s/musing-snowflake-zb0qh?file=/src/App.js

## The current behavior

`onResize` handlers are ignored on `<video>` elements.

## The expected behavior

`onResize` handlers are valid on `<video>` elements."
facebook/react,2020-12-11 09:37:45,feature,Feature Request(devtools): `launch-editor` for selected component,"### Why: 

User can open the source file in editor/ide by one-click.

It' is a useful feature in `vue-devtools`.

---

### How: 

Add a click event on here:

https://github.com/facebook/react/blob/cdfde3ae110844baf068706e7ed3fe97ec15f1d7/packages/react-devtools-shared/src/devtools/views/Components/InspectedElementView.js#L226-L228

call ```fetch(`/__open-in-editor?file=${fileName}:${lineNumber}`)```

Add [launch-editor-middleware](https://github.com/yyx990803/launch-editor) to dev-server(or any scaffold handle by himself)

---

Before anyone(maybe me) sends a PR, I want to know how do the react-team thinks about it?"
facebook/react,2020-07-04 14:22:02,feature,Feature proposal: Hook equivalent to createSlice from Redux Toolkit?,"Would this be useful?

> A function that accepts an initial state, an object full of reducer functions, and a ""slice name"", and automatically generates action creators and action types that correspond to the reducers and state.

From [createSlice](https://redux-toolkit.js.org/api/createSlice)."
facebook/react,2020-05-29 18:28:30,feature,[DevTools Feature Request] Break on Warnings,"It'd be nice to have a toggle to pause the debugger when warnings fire so you can inspect the stack as it's happening.

```
console.error = function() {
  ...
  if (isBreakOn) {
    debugger;
  }
}
```

See https://github.com/facebook/react/pull/19044"
facebook/react,2020-04-16 16:13:34,feature,Allow opting out of invokeGuardedCallbackDev,"At the moment, when in development mode, React uses a special workflow for callbacks, to avoid using `try...catch`.

It works well. So well that several testing frameworks also get their uncaught exception handling triggered.

**Example with mocha:**
```js
import React from 'react';
import { render } from '@testing-library/react';

function MyComponent({ doThrow }) {
    if (doThrow) { throw new Error('I'm bad'); }
    return <div></div>;
}

it('should throw', function () {
    expect(() => {
        render(<MyComponent doThrow/>);
    }).to.throw();
});
```
**Behavior:**
- When running the test with the production build of react/react-dom, the test passes (with the usual warning of act being unsupported in prod build).
- When running the test with the development build of react-/react-dom, the test fails with `Error: Uncaught Error: I'm bad`.

The root cause is `invokeGuardedCallbackDev` runs the callback in an event to avoid using a `try...catch` block… and trips Mocha.js uncaught exception detector.

*Note: I am aware of error boundaries, I removed it from the example because the behavior is identical with it.*

*Note: I used testing-library for clarity, but using `act` and `RenderDOM` manually yields the same result.*

**Expected behavior:**
- Either make it work out of the box, or have the possibility to opt out of `invokeGuardedCallbackDev` and force the use of the regular `try...catch` implementation in development too.
"
facebook/react,2020-04-02 23:13:49,feature,"DevTools: Hovering ""Rendered by"" list should highlight elements","This list is pretty awesome:

<img width=""390"" alt=""Screenshot 2020-04-03 at 00 12 08"" src=""https://user-images.githubusercontent.com/810438/78308234-e0047780-753f-11ea-9d4f-1e2d31e5baa0.png"">

But always struggle to guess which component in the owner list I need to jump to.

We should make hovering the owner list highlight components, just like the main tree view does.

@hristo-kanchev, interested?"
facebook/react,2019-12-29 13:28:56,feature,Add colors to component's name ( in Component tree ) for visual feedback about type of Component or Node,"**What is the current behavior?**

All the components name  in the Component tree are of the same color

**What is the expected behavior?**

It would be helpful if they have different colors indicating the type of Component (whether its native HTML node or Contexts or simple react component) I know we can filter it, but visual indication will be helpful too.
"
facebook/react,2019-10-31 12:41:06,feature,react-refresh: add options to override $RefreshReg$ and $RefreshSig$ for better System.js integration,"**Do you want to request a *feature* or report a *bug*?**
Feature

Right now babel plugin emits globals: https://github.com/facebook/react/issues/16604

```js
window.$RefreshReg$ = () => {};
window.$RefreshSig$ = () => type => type;
```

It would be nice to have them configurable. That would allow to use `import.meta` in environments like SystemJS and have simpler implementation:

```js
import runtime from 'react-refresh/runtime'
runtime.injectIntoGlobalHook(window)

System.constructor.prototype.createContext = function (url) {
  return {
    url,
    $RefreshSig$: runtime.createSignatureFunctionForTransform,
    $RefreshReg$: (type, id) => {
      id = url + ' ' + id
      runtime.register(type, id)
    }
  };
};
```

If you don't mind I could create PR with changes to react-refresh/babel next week.

environment:
```js
{
    ""systemjs"": ""^6.1.4"",
    ""react"": ""^16.11.0"",
    ""react-dom"": ""^16.11.0"",
    ""react-refresh"": ""^0.6.0""
 }
```"
facebook/react,2019-10-08 13:18:53,feature,Apply props/state/hooks edits on blur,"**Do you want to request a *feature* or report a *bug*?**
feature
**What is the current behavior?**
trigger by press enter button
**What is the expected behavior?**
trigger by out of focus or pressing enter button
"
facebook/react,2019-10-01 04:14:04,feature,React DevTools force re-render button,"I'd like to have a button that forces a re-render of the selected component when clicked. For example, adding a button like this on the right of the component controls:

![image](https://user-images.githubusercontent.com/1500684/65933573-35b06980-e3cf-11e9-8245-e5bedac5c552.png)

This can be accomplished today by adding a new prop and changing the prop, but it's more work than I want to do.

This would be useful for use while profiling how a component performs with unnecessary re-renders. Right now I just have a button that's tied to a ""forceRender"" function:

```jsx
function useForceRerender() {
  const [, set] = React.useState()
  return React.useCallback(() => set({}), [])
}

function FilterComponent() {
  const forceRerender = useForceRerender()
 
  return (
    <>
      <button onClick={forceRerender}>force rerender</button>
      {/* more JSX */}
    </>
  )
}
```

Would be cool to have this built-in :)"
facebook/react,2019-08-30 15:30:57,feature,"Enhance React DevTools ""Why did this render?"" for values nested in prop objects","
**Do you want to request a *feature* or report a *bug*?**
*feature*

**What is the current behavior?**
[as demonstrated here, ""Why did this render?""](https://github.com/facebook/react/issues/16437#issuecomment-524892514) does a great job reporting what prop changed, but it does not yet report which _nested_ value changed for props that are comprised of nested objects.

**What is the expected behavior?**
The ""why did this render?"" shows a collapsible tree with the ""leaf"" value that changed inside the prop object displayed.

A couple use cases this would benefit:
In some cases, it is most convenient creating props that are nested objects. For instance, maybe you need to pass an object to a library, and you'd like to avoid storing the individual object items as separate prop variables such that you don't need to redefine them together as a dict later on, but changes are due to a single element in the dict that you'd like visibility on in react devTools.

In rarer cases, it is unavoidable having props that aren't nested objects. For instance, how could I preserve the `.prototype` key of my `props` object without react stripping it? If I wrap my props inside an object, that key can be preserved. But now *all* my props are considered 1 prop to the profiler and I have no visibility on which prop changed. With this change, I could expand the tree and drill down to which individual values changed.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

New feature never before released in React DevTools. I am using `16.8.6`
"
facebook/react,2019-08-22 14:37:38,feature,"Show property type of value (string,int,etc) on state/props.","**feature**

**What is the current behavior?**
On the new developer tool you are unable to see what property type the value. You used to be able to see if the value was a string or int because of the quotation marks (for example id: ""1"" (string) or id: 1 (int)). Both string and int are shown without quotes.

**What is the expected behavior?**
I want to see if the value inside the prop or state is an string or integer by using quotation marks on the value.
`id: ""1""`

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
I'm using version:
4.0.5 (8/19/2019)

Did this work in previous versions of React?
Yes, 3.*"
facebook/react,2019-08-17 09:45:03,feature,Devtools V4: Where is Highlight Updates?,"If I understood correctly, this is the correct repository for devtools v4, right?

I just noticed that react devtool were updated. I'm missing the ""Highlight Updates"" function.
How can I activate it?

![image](https://user-images.githubusercontent.com/12381373/63209674-4ab58f80-c0e4-11e9-8134-40789625c81e.png)

![image](https://user-images.githubusercontent.com/12381373/63209676-543ef780-c0e4-11e9-8128-a73c4b6bf8f7.png)

Version: 4.0.2 (8/15/2019)
"
facebook/react,2019-08-16 19:59:04,feature,New Devtools Cannot Expand Obervables,"**Do you want to request a *feature* or report a *bug*?**
Bug

**What is the current behavior?**
Devtools used to be able to expand observables created by Mobx. With the new update that is no longer possible.
![image](https://user-images.githubusercontent.com/3083189/63194767-18495b00-c02e-11e9-95d2-1c83edbf2f26.png)

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**
https://codesandbox.io/embed/clever-blackwell-h0nzb

Check the props of the wrappedComponent in devtools. store.things does not expand.

**What is the expected behavior?**
Devtools should expand Observables as it does any other object.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
This only seems to be an issue with Observables created by Mob v4. v5 works as expected.
"
facebook/react,2019-08-08 15:43:18,feature,[Feature Request] Finish/normalize Portal API,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

feature

**What is the expected behavior?**

Portals are in a weird state. The core `react` knows about them but you can only create them from other libs (e.g. `ReactDOM`). You have to branch your code because they can’t be server-side rendered. And so on.

This is just a pre-RFC to brainstorm ways that Portals can become first-class citizens:

* Extend `React.createRef()` to allow an optional renderer-specific argument (e.g. the DOM element), matching `useRef()`
* Add `React.createPortal(child, ref)` (*note the use of `ref` rather than a e.g. a direct DOM element*)
* Deprecate `ReactDOM.createPortal()`

Now with some thought into the structure of your app with modals, they could be e.g. server-side rendered with:

```
function App(props) {
  const modal = useRef(null)
  return (
    <div>
      <ModalContext.Provider value={modal}>
        <div>{props.content}</div>
      </ModalContext.Provider>
      <div ref={modal} />
    </div>
  )
}

function Modal(props) {
  const modal = useContext(ModalContext)
  return React.createPortal(
    props.children,
    modal,
  )
}

// Somewhere in {props.content} tree...
return (
  <>
    {visible && (
      <Modal>
        Hello, World!
      </Modal>
    )}
  </>
)
```

After `ReactDOM.createPortal(...)` is deprecated, legacy web or those with no need to SSR portals can simply upgrade with:

```
this.el = React.createRef(document.createElement('div'))
```

for the same behavior.

As an initial version, React can error if `ref.current` is null when it goes to mount the portal. Some sort of dirty flag could be considered separately if proven necessary, but with the pattern proposed above, it shouldn’t be necessary as the portal host would *always* be mounted first as a natural consequence of how React works."
facebook/react,2019-04-26 16:51:51,feature,Allow ReactNode as a type for the child of <option/>,"**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
Currently, the options element only allows types number and string. 

**What is the expected behavior?**
An option should allow for a ReactNode as a child in addition to a number + string. 

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
All versions.
All browser types.
To the best of my knowledge, no.

p.s. This is my first feature request here, so let me know if I need to adjust the feature request in any way. "
facebook/react,2019-04-11 23:18:44,feature,Provide withHooks HOC to decouple hooks and components,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
Currently the recommended way to use hooks involves coupling them with components. By this I mean that components are aware of the hooks they consume and depend on them explicitly.
This [issue thread on the recompose repo](https://github.com/acdlite/recompose/issues/756) discusses this issue in some detail and how recompose favored keeping components dumb, but wraps them in HOC's to make them smart. Hooks promote baking the smartness right into the component itself.

**What is the expected behavior?**
React should offer a way to decouple components from the hooks they consume. I suggest a `withHooks` HOC that maps hooks to props. This will be a familiar model for those who have used redux with react.

```jsx
const withHooks = mapHooksToProps => WrappedComponent => {
  return props => {
    let hookProps = mapHooksToProps(props);
    return <WrappedComponent {...hookProps} {...props} />;
  };
};

const Counter = props => {
  return (
    <div>
      <div>Counter: {props.counter}</div>
      <button onClick={props.increment}>Increment</button>
      <button onClick={props.decrement}>Decrement</button>
    </div>
  );
};

const mapHooksToProps = props => {
  let [counter, setCounter] = useState(0);

  return {
    counter,
    increment: () => setCounter(prev => prev + 1),
    decrement: () => setCounter(prev => prev - 1)
  };
};

const EnhancedCounter = withHooks(mapHooksToProps)(Counter);
```

Demo:
https://codesandbox.io/s/ympq0rlv79

Some reasons why this is nice:

1) It decouples components from the things that make them smart. Some examples of things that could make dumb components smart include hooks, redux, and good ol' parent components. By mapping hooks to props, we make it very easy to swap a dumb component's hook-powered 'brain' for a new 'brain', say a redux-powered 'brain'.

2) Not sure if it's a good idea, but i know several people trying to replace redux with hooks in their applications. For these people, migrations from redux to hooks would be dead simple because they could replace `mapStateToProps` and `mapDispatchToProps` with `mapHooksToProps` and wouldn't have to worry about touching the underlying component.
 
3) Testing is also easier because we can test the component in isolation without the hooks baked in.

4) It makes prop overrides possible. In the case of our EnhancedCounter, we could override the counter prop by doing `<EnhancedCounter counter={10} />`. A real world example of hooks making things harder to override includes material-ui's [new styling approach via hooks](https://material-ui.com/css-in-js/basics/#hook-api). Because classes are provided via hook and no longer via props, we would need custom logic to override classes via props with the new hook-based approach:
```jsx
export default function Hook(props) {
  let classes = useStyles();
  classes = {...classes, ...props.classes};
  return <Button className={classes.root}>Hook</Button>;
}
```
**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
For versions of react >= 16.8"
facebook/react,2019-04-05 02:01:02,feature,feature request: export of ReactDOM libraries,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

it's a *feature*.

**What is the current behavior?**

[Internal shared libraries of ReactDOM](https://github.com/facebook/react/tree/master/packages/react-dom/src/shared) is not exported.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

n/a

**What is the expected behavior?**

It is great that some shared libraries such as [`isCustomComponent`](https://github.com/facebook/react/blob/master/packages/react-dom/src/shared/isCustomComponent.js) or [`DOMNamespaces`](https://github.com/facebook/react/blob/master/packages/react-dom/src/shared/DOMNamespaces.js) are exported from `react-dom` and available externally.

They are useful to know what types of HTML tags are regarded to be valid one by React, for example, with static analysis issued at https://github.com/yannickcr/eslint-plugin-react/issues/1752.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

n/a"
facebook/react,2019-03-31 01:39:03,feature,Add option in shallow renderer to run effects/componentDidUpdate/componentDidMount,"**Do you want to request a *feature* or report a *bug*?**
feature

**What is the current behavior?**
the shallow renderer does not run componentDidUpdate, componentDidMount, or useEffect functions. (I'll call them effect functions for short)

**What is the expected behavior?**
See [this enzyme issue](https://github.com/airbnb/enzyme/issues/1938#issuecomment-476137018) for more details about where this request is coming from. But the general idea is that it is often nice to run effect functions even when shallow rendering, rather than having to use full rendering on those specific tests. 

If the shallow renderer provided an option to run the effect functions, it would allow people who test with shallow rendering to more easily test their components. Enzyme currently supports this in class components by calling componentDidUpdate/mount directly on the component instance, but this would be a much harder thing to do for hooks, since they are usually anonymous.

Enzyme used to not allow this at all, but then added an option to turn on this behavior in their shallow renderer, before finally turning it on by default and then adding an option to turn it off. It didn't seem to cause too many issues for them, so I think this approach could work well for the React shallow renderer as well. Obviously I'm only asking for an option to turn it on now, not to change the default or anything.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
All and no it was never supported AFAIK"
facebook/react,2019-03-25 16:40:16,feature,Using context to pass down mount order to children with concurrent,"**Do you want to request a *feature* or report a *bug*?**

Feature / use case

**What is the current behavior?**

It seems currently there is no way to get the order of children from the children themselves with context.

**What is the expected behavior?**

I've run into this now in three use cases when building a style system: Breadcrumbs, Segmented views, and Text rhythm/spacing.

Example 1, breadcrumbs. You want to show an arrow on all but the last breadcrumb, but they may be deeply nested:

```ts
let BreadcrumbOrder = createContext({ index: -1, total: -1 })

let Button = props => {
  let order = useContext(BreadcrumbOrder)
  return <div style={{ borderRight: order.index > total ? '1px solid red' : 'none' }} {...props} />
}

let MyView = () => {
  return (
    <BreadcrumbProvider>
      <Button />
      <Button />
      <div><Button /></div>
    </BreadcrumbProvider>
  )
}
```

Where MyView should provide the ordering so that the sub-views can access `total` and `index` and properly style.

The other use cases are basically identical, but for different patterns. One is for joining together buttons that are in a row in the interface (Segmented), and the other is for collapsing margins when you have text elements in a vertical column.

Really this ticket encompasses more of a question or request for documentation clarity here. I'm not sure how it is not pre-concurrent, but I'm assuming mount-order will be non-deterministic if not now then shortly. Is there any reference to a pattern that works for this use case?

Namely: how children can access their mount order / total children. I can do it now useReducer/context, but I've seen it mount in a weird order at least once and think it was due to a suspense type thing, and would be curious a better practice for this."
facebook/react,2019-03-20 06:42:44,feature,[useContext] Throw error if 'useContext' is used outside function components,"**Do you want to request a *feature* or report a *bug*?**
Feature (need better errors)

**What is the current behavior?**
Consider the following functional component
```
import React, { useContext } from ""React""

const myFunctionComponent = props => <div>Hello useContext</div>
```

The immediate reaction for most of us (newbies to hooks) to refactor the above code to accomodate `useContext` is as follows

```
import React, { useContext } from ""React""
import MyContext from ""./MyContext""

// React does not throw error
const { myContextValue } = useContext(MyContext)

const myFunctionComponent = props => <div>Hello useContext - {myContextValue}</div>
```

The way to actually refactor is to explictly convert the arrow function return expression into a function body and then accomodate `useContext` inside along with a return statement, like this

```
import React, { useContext } from ""React""
import MyContext from ""./MyContext""

const myFunctionComponent = props => {
 const { myContextValue } = useContext(MyContext)
 return (<div>Hello useContext - {myContextValue}</div>)
}
```

Not only, react **does not throw error**, React app actually compiles, while the component in question fails to load with no information. This is very difficult to pin the reason to this specific issue.


**What is the expected behavior?**

React should ideally throw some kind of error, when `useContext` is used outside of function components. This lack of error really bites us for people who are refactoring function components without a return statement.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

React `16.8.x` with hooks support
"
facebook/react,2019-02-26 11:20:48,feature,[ESLint] Hardcore rule allowing default hooks using only inside custom ones,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
feature

**What is the current behavior?**
There is no rule

**What is the expected behavior?**
We have some hardcore plugins like `eslint-plugin-lodash-fp`.
Why not have ESLint hardcore rule allowing default hooks using only inside custom ones?
"
facebook/react,2019-02-12 14:02:43,feature,Pass dependencies to `useMemo` callback as arguments,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

Feature

**What is the current behavior?**

The `useMemo` factory function does not receive any arguments.

**What is the desired behavior?**

The `useMemo` factory function would receive the dependencies as arguments.

**Why?**

This would allow more compact syntax for memoizing components because of implicit returns and desctructuring. This came to mind after experiencing some of the issues in #14110. There may be other potential use cases too 

**Example of current behavior**

```jsx
const Avatar = () => {
  const [src] = useSomeGlobalState([
    state => state.user.avatar.src
  ]);
  return useMemo(() => <img src={src} />, [src])
}
```

**Example of proposed behavior**

```jsx
const Avatar = () => 
  useMemo(
    (src) => <img src={src} />,
    useSomeGlobalState([state => state.user.avatar.src])
  );
```

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

React 16.8.1
"
facebook/react,2019-02-06 15:22:53,feature,Unhelpful warning for `act` for react-dom@16.8,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

Feature/Improvement

**What is the current behavior?**

If there is test code that should be wrapped in `act(...)` then the current warning is given:

```
 console.error node_modules/react-dom/cjs/react-dom.development.js:506
    Warning: An update to null inside a test was not wrapped in act(...).

    When testing, code that causes React state updates should be wrapped into act(...):

    act(() => {
      /* fire events that update state */
    });
    /* assert on the output */

    This ensures that you're testing the behavior the user would see in the browser. Learn more at https://fb.me/react-wrap-tests-with-act
```

When upgrading a large code base, this is basically useless.

**What is the expected behavior?**

Provide at least the test name if not the line number of code that triggered the warning.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

react@16.8.0
react-dom@16.8.0"
facebook/react,2019-02-03 00:52:14,feature,adding if directive ,"if you added if directive to any element for showing the element or not that would be better than making a js expression in my opinion 

**regular way**
```js
const App = (props) => {reactif={true}
    let name = props.name;
    return (
        <div >
            {name === 'koko' ? <div className=""yousef"">{name}</div> : null}
        </div>
    )
}

ReactDOM.render(<App name=""koko"" />, document.getElementById('app'))
```
**my way** ( i edited the react file btw and it worked )
```js
const App = (props) => {
    let name = props.name;
    return (
        <div >
            <div className=""yousef"" reactif={name === 'koko'}>{name}</div> 
        </div>
    )
}

ReactDOM.render(<App name=""koko"" />, document.getElementById('app'))
```
**mmm**
i hope you talk that into consideration 
i mean less than 1kb will not make difference :""D

**React code**
```js
var RESERVED_PROPS = {
  key: true,
  ref: true,
  __self: true,
  __source: true,
  reactif: true
};

if (config != null) {
    if (hasValidRef(config)) {
      ref = config.ref;
    }
    if (hasValidKey(config)) {
      key = '' + config.key;
    }
    // i added that
    if (config.reactif){
      reactif = config.reactif
      if (reactif === false){
        return null
      } else if (reactif !== true || reactif !== false){
        console.error('reactif expression didn\\'t return bolean value')
      }
    }

    self = config.__self === undefined ? null : config.__self;
    source = config.__source === undefined ? null : config.__source;
    // Remaining properties are added to a new props object
    for (propName in config) {
      if (hasOwnProperty$1.call(config, propName) && !RESERVED_PROPS.hasOwnProperty(propName)) {
        props[propName] = config[propName];
      }
    }
 }
```"
facebook/react,2019-01-27 06:20:31,feature,Support Proxy as child,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
Objects are not valid as a React child

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**
N/A

**What is the expected behavior?**
I'm trying to build a system that auto-detects if data is used in a React component. To do this, I detect usage during `render()` by using Proxies, which can register all access. This data, in turn, is used to prevent needless re-renders.

A parent component can pass a Proxy which represents a string, for example, to a child component, which, without knowing it is a Proxy, can use this value in a calculation (e.g. `props.value + 1` or `` `The value is ${props.value}` ``). This can be handled with `proxy[Symbol.toPrimitive]()`, which is called by JS automatically when used in this sort of expression.

However, this doesn't work if the child now passes the proxy directly to React as a child:
```jsx
  return (<span>{this.props.childValue</span>);
```
React will do a `typeof` on the child, find it is an object, and report `Objects are not valid as a React child`. Unfortunately, `typeof` cannot be spoofed with Proxy, and it will always return `'object'`.

The relevant code is found [here](https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/react/src/ReactChildren.js#L189-L204). The alternative could be for React to check if there's a `child[Symbol.tpPrimitive]` and, if so, evaluate it to find the intended value, and to retry with this value as the child.
It could be as simple as inserting the following code [here](https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/react/src/ReactChildren.js#L189):
```js
  if (typeof Symbol !== 'undefined') {
    const toPrimitive = children[Symbol.toPrimitive];
    if (toPrimitive) {
      const value = toPrimitive('string');
      if (typeof value !== 'object') {
		return traverseAllChildrenImpl(
		  value,
		  nameSoFar,
		  callback,
		  traverseContext,
		)
      }
    }
  }
```

It would be great if React would support this use-case. The alternative is for parent components to resolve the value, which would attribute the access to the parent component, instead of the child, where it's really being used. This in turn would cause the parent to be rerendered when only the child is being changed.

If the child is aware it may be receiving Proxy objects, it can resolve the value itself. However, the whole point of using Proxies is to automate all the refresh logic (like `shouldComponentUpdate`). Also, not needing to resolve the value would allow the value to propagate through to descendant components which may be wholly unaware of the proxy. 

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
All version, never worked before."
facebook/react,2018-12-29 21:32:16,feature,Make it easier to debug when Context uses defaultValue accidentally due to no provider,"I just spend several hours debugging app blaming everything except me ofc.
I am using this useTheme Hook.

```ts
import React from 'react';
import ThemeContext from '../contexts/ThemeContext';

const useTheme = () => {
  const theme = React.useContext(ThemeContext);
  //if (theme == null)
  //  throw Error('useTheme: Please provide ThemeContext value.');
  return theme;
};

export default useTheme;
```

Some styles were light while other dark. Very strange.
Then I found the bug in my code, `ThemeContext.Provider` was sometimes used after using useTheme.
ThemeContext had an initial value different than provided.

While it's probably fine that React allows us to use default context value without a parent provider, it can lead to hard to find bugs.

Therefore, I decided to never provide default context value and throw an exception in useFooContext hook to warn about it.

Because of DX, React should reconsider default / initial context values. In my humble opinion.


"
facebook/react,2018-12-08 04:31:01,feature,eslint-plugin-react-hooks should report errors inside unnamed functions,"I want to report a bug for the hooks plugin.

**What is the current behavior?**
There was no error report after running eslint, but the component failed when running in the browser.
From the chrome dev console it reported ""Uncaught Error: Rendered fewer hooks than expected. This may be caused by an accidental early return statement."" 

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React.
Here is a link to the github repo:
https://github.com/paboulos/react-hooks-eslint

**What is the expected behavior?**
Followed The Hooks API guide which says React hooks provides a linter plugin to enforce these rules automatically.Therefore it should have reported a usage violation when the eslint hooks plugin is specified. 
**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
Using window 10 OS and Chrome browser.
1. First ran npx create-react-app Hooks
2. Installed react 16.7.0-alpha.2 and react-dom 16.7.0-alpha.2
3. Installed eslint dev dependencies:
 ""babel-eslint"": ""9.0.0"",
    ""babel-loader"": ""8.0.4"",
    ""eslint"": ""5.9.0"",
    ""eslint-config-airbnb"": ""17.1.0"",
    ""eslint-loader"": ""2.1.1"",
    ""eslint-plugin-import"": ""2.14.0"",
    ""eslint-plugin-jsx-a11y"": ""6.1.2"",
    ""eslint-plugin-react"": ""7.11.1"",
    ""eslint-plugin-react-hooks"": ""0.0.0""
4. Created the .eslintrc.json following the instructions from the Hooks API Doc
Then ran package script lint as follows: ""npm run lint""
no errors reported.
Then ran package script start as follows: ""npm start""
The React component CountHooks calls useState incorrectly and reports error in the browser dev console."
facebook/react,2018-11-28 13:34:22,feature,Feature Idea: useError hook,"**Do you want to request a *feature* or report a *bug*?** 

Feature idea

**What is the current behavior?**

Currently there is no hook for dealing with errors in a component's sub-tree.

**What is the expected behavior?**

Have a hook that allows for functional components to act as Error Boundaries.

Example:

```
function myErrorBoundary() {
  const caughtError = useErrorCatching();
  if (caughtError !== null) { return <ErrorHandler error={caughtError} />; }
  return <RegularContent />;
}
```

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
n/a"
facebook/react,2018-11-19 20:28:56,feature,react-is memo,"Feature request

**What is the current behavior?**
`react-is` now doesn't have method to check if element is `memo`(like `isForwardRef`).
Maybe there are some reasons why it's not implemented?
"
facebook/react,2018-11-15 23:18:21,feature,Support reporting Suspense loading indicator outside of the suspended tree,"Cryptic title I can imagine, but I am not aware that something like this would have been mentioned anywhere so far.

I have a page showing some statistics and it's split into two even panels. The left panel is showing some numbers and contains a form to set necessary filters. The right panel is showing some other details about filtered data. Initially, only filter form is visible, nothing else.

The user sets the filter and hits the ""filter"" button to send out a request. There is a requirement to show a text loader in the left panel and the right panel should be showing content loader animation. Too many loaders perhaps? Well, it kinda makes sense in this context :)

Now my confusion is how to achieve that. Obviously, I don't want each panel to run the same query on its own. I would like to do that once in the upper level. I can surely pass down the `isLoading` prop to both panels. However, I am not too happy about it, because once there will be a fully fledged data fetching relying on the Suspense, it would mean that for such scenarios I will need to fall back to a regular solution. Am I misunderstanding something in here?"
facebook/react,2018-11-05 16:28:51,feature,Synthetic KeyboardEvent should support KeyboardEvent.code,"**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
The current synthetic keyboard event does not support the [`KeyboardEvent.code`](https://www.w3.org/TR/uievents/#dom-keyboardevent-code) property.

**What is the expected behavior?**
The synthetic keyboard event should pass along the [`KeyboardEvent.code`](https://www.w3.org/TR/uievents/#dom-keyboardevent-code) property. This is currently in the WD of DOM Events but is part of replacing `keyCode` and `charCode` and is much more consistent and easy to use. This is currently only supported by FF and Chrome ([CanIUse](https://caniuse.com/#feat=keyboardevent-code)) so it may be a bit premature to fully integrate. However `keyCode`, `charCode` and `which` are being deprecated so this will eventually need to be added.

Edit: I spoke too quickly, CanIUse shows that FF, Chrome, Safari and Opera support it. IE, Edge and most mobile browsers do not.
"
facebook/react,2018-10-31 21:53:53,feature,Provide a way to trigger useEffect from tests,"Hello,

I tried testing components that use the cool new hooks API, but `useEffect` doesn't seem to work with the test renderer.

Here's a small failling Jest test:

```js
import React, { useEffect } from ""react"";
import { create as render } from ""react-test-renderer"";

it(""calls effect"", () => {
  return new Promise(resolve => {
    render(<EffectfulComponent effect={resolve} />);
  });
});

function EffectfulComponent({ effect }) {
  useEffect(effect);

  return null;
}
```

And here's a minimal reproducing repo: https://github.com/skidding/react-test-useeffect

> Note that other _use_ APIs seemed to work (eg. `useContext`)."
facebook/react,2018-10-25 17:04:42,feature,16.6 contextType + getDerivedStateFromProps,"**Do you want to request a *feature* or report a *bug*?** Feature

**What is the current behavior?**

Context not passed into getDerivedStateFromProps:

```
static getDerivedStateFromProps(props, state, context) {}
```

Just curious with the new `static contextType`, it would save a lot of nesting if I could access context now from getDerivedStateFromProps when using this pattern. I gave it a shot assuming it may work already but I get undefined from the third argument.

Just curious if there's been any discussion on this."
facebook/react,2018-10-03 12:13:22,feature,Conditional Components,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

Feature

**What is the current behavior?**

Often we will use expressions like this:

`{ !x ? null : <Component title={x.title} /> }`

**What is the desired behavior?**

We would like to have expressive components such as

```
<When c={x}>
   <Component title={x.title} />
</When>
```

In many cases this generic syntax is preferred over an explicit child component or pure function which knows about what it is supposed to render.

The issue is that this will evaluate the children, even if they ultimately are not returned (since they are passed as children to the When component).

What is desired is for the syntax above to be able to behave exactly like a conditional expression, in that the contained children are not actually processed at all unless a condition is met.  In reality the component could be something else entirely such as `<SuperUser />` which will only process and render the children if the current user is a super user, or `<Morning />` to only process and render items between 8 AM and 11 AM (or similar).  The key thing is that we do not want the props passed into the children, or the children themselves produced, unless a condition has been satisfied.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

Presumably any version of React."
facebook/react,2018-09-17 17:32:15,feature,Is it possible to use Profiler server side?,"I'm trying to use the Profiler server side rendering with `renderToString` but the onRender callbacks are not getting called.

Is there a way to do it?
I'm using 16.5.1, NODE_ENV === ""development"".

My code looks like this, works fine client side:
```javascript
import React, { unstable_Profiler } from 'react';

const profilerCallback = (id, phase, actualTime, baseTime, startTime, commitTime) => {
        console.log(`${id}'s ${phase} phase:`);
        console.log(`Actual time: ${actualTime}`);
        console.log(`Base time: ${baseTime}`);
        console.log(`Start time: ${startTime}`);
        console.log(`Commit time: ${commitTime}`);
};

const MyComponent = () => (
    <Profiler id=""card"" onRender={profilerCallback}>
        ...
    </Profiler>
)
```"
facebook/react,2018-08-19 16:58:06,feature,Cache Provider: Add hooks to read and preload in dev mode,"This topic originally came up in a `react-devtools` discussion: https://github.com/facebook/react-devtools/issues/1099#issuecomment-414138771.

**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
The package `simple-cache-provider` does not presently provide hooks to understand when we've pulled a resource for the first time, hit the cache, or dropped something from the cache due to `MAX_SIZE`.

Due to this, tools such as `react-devtools` cannot provide an interface around our cached resources which makes debugging / inspection harder.

**What is the expected behavior?**
It would be great if there was a way to expose callbacks / events for when the cache resource has resolved. An idea would be to fire these callbacks / events in the existing switch statement in `read` / `preload` if we are in `__DEV__` mode.

With this information we could have a ""redux-devtools""-esque interface to better understand where our data is coming from and when we're hitting the cache in dev mode.

Tools like this would also be useful to people new to the Suspend API to visually see their resources transition between the various record states.

"
facebook/react,2018-08-13 14:39:15,feature,Provide a `testInstance.context` property to facilitate context testing,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
Feature Request

**What is the current behavior?**
`testInstance` provides a `props` property, but does not provide a `context` property allowing for context tests.

**What is the expected behavior?**
`testInstance.context` should return an object containing the instance's current context

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
At least 16.4.1"
facebook/react,2018-08-09 15:39:29,feature,Ability to use return value of React.Children.map with React.Children.only,"As stated in the docs and shown in #4410, the return value of `React.Children.map` is incompatible with the `React.Children.only` function, and will return with the error message:
> Invariant Violation: Invariant Violation: React.Children.only expected to receive a single React element child.

if used. 

This incompatibility causes some fairly annoying restrictions, however. From what I understand, this means that you can't edit the properties of a component's children at runtime if they contain any component that requires a single child. (eg. you can't dynamically set the disabled prop of a child `TouchableNativeFeedback` component in the parent).

I believe this is due to the type differences between the `this.props.children` parameter and the `React.Children.map` return value, the former being a valid element and the latter not (see #4424 and https://github.com/reactjs/reactjs.org/issues/87). 

I'd like to make a request to have the return type of `React.Children.map` be the same as the type of `this.props.children`, which will fix these quirks and be much more intuitive. A separate static function that converts the return type of `React.Children.map` to the same type as `this.props.children` would also solve the issue. It feels like some sort of fix is in order, since it's a broad and strange restriction on the components you can use."
facebook/react,2018-07-17 12:18:10,feature,Identify different instances of react component in performance measures,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
**feature**

Can fiber._debugID also be part of performance measure [label](https://github.com/facebook/react/blob/master/packages/react-reconciler/src/ReactDebugFiberPerf.js#L91) along with component name/displayName?

to distinguish/track multiple instances of a react component in performance measures, please let me know if there is any other way already available to achieve this."
facebook/react,2018-06-13 08:58:57,feature,Add a way to compare relative positions of deep children,"Hey,

It seems like there is currently no way to take two mounted component instances and tell which one of them is coming earlier in the application structure (they could have been mounted asynchronously, and tracking the instantiation/render/mount time is not enough). Ideologically I cannot traverse the application tree, that is understandable.

Though, the relative positions are needed sometimes. My use case — I track focusable elements in the application using context (each focusable element reports of its existence to a focus manager which is provided by the context). This is needed to be able to limit the focusablility/accessibility of all elements which are outside of the currently shown modal dialog/popup so that the focus is trapped inside. For the sake of better accessibility, I need to automatically focus first focusable in the modal dialog when I'm in the keyboard navigation mode. So, I have the references to all focusable elements inside the dialog, but I cannot tell which one comes first using public React API. For web there is a workaround to findDOMNode and compareDocumentPosition(), but that doesn't work with React Native.

Can we have something similar to compareDocumentPosition() but for React component instances?

Thanks!
"
facebook/react,2018-05-24 20:33:03,feature,Synthetic (keyboard) events don't implement the .code property,"**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
`<event>.code` is undefined

**What is the expected behavior?**
`.code` is a very useful part of the KeyboardEvent spec: https://www.w3.org/TR/uievents/#dom-keyboardevent-code

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
I am on React 16.3, but I saw no mention of this in today's 16.4 changelog.
"
facebook/react,2018-05-18 18:21:52,feature,Provide HOC for new context API,"I find myself needing a higher-order component every once in a while when using render props, so I can get stuff from context in my lifecycle methods. It's pretty easy to create a HOC from a render prop, so I was wondering how open y'all would be to adding a HOC to the new context API?

We can already do this in userland with a little `withContext` helper:

```js
function withContext(Context, Component) {
  return props => {
    return (
      <Context.Consumer>
        {context => <Component {...props} context={context} />}
      </Context.Consumer>
    );
  }
}

const AppWithContext = withContext(MyContext, App);
```

It would be useful to have this built-in to the new context API, something like:

```js
const MyContext = React.createContext();

const AppWithContext = MyContext.provide(App, 'optionalNameOfTheProp');
```

The second argument to `provide` (the prop name) could default to `context`.

Anyway, just thought I'd open this up for discussion before making an actual PR that adds this. Thanks for your consideration 😅

[EDIT: Removed example using `this.context`]"
facebook/react,2018-05-08 08:54:03,feature,Cursor jumps to end of input when onChange doesn't call setState,"[Edit]: **I'm asking for a feature**.

**Current Behaviour**
An input `onChange` function that returns a value equalling the prior value causes the cursor to jump to the end of the input. This is the same as [this comment from #995](https://github.com/facebook/react/issues/955#issuecomment-327069204) formally raised as a feature request. 

Repro sandbox: https://codesandbox.io/s/n4k3yx47j
That same code:  
```javascript
import React from ""react"";
import { render } from ""react-dom"";

class Input extends React.Component {
  state = { value: ""TypeANumber"" };

  onChange = e => {
    let nextValue = e.target.value;

    if (/[0-9]/.test(nextValue)) {
      nextValue = this.state.value;
    }
    this.setState({ value: nextValue });
  };

  render() {
    return (
      <input
        type=""text""
        value={this.state.value}
        onChange={this.onChange}
      />
    );
  }
}

render(<Input />, document.getElementById(""root""));
```

**What is the expected behavior?**
I'd like the cursor not to jump in the special case where the returned changed value is a rejected change i.e. the 'noop' change. 

I understand fully that react cannot predict cursor position if the value is _changed_ in `onChange`, ~however I cannot currently find an npm module that allows free-length regex filters (vs a fixed length mask)~ or a way to implement a filter myself, without the cursor jumping in this case. 

[Edit]: 
Since raising I now fully see this as a feature request for handling a special case of a behaviour that indeed is not a bug, differently. It would be a nice to have as it would allow very straightforward implementation of filters. 

Regarding the non-clarity of how to deal with the general case of non-jumping cursors I think a modernized best practice example would be ideal, but that discussion still lives at #955.  

I'd be totally fine with this issue being closed by assisting instead with the education of handling the general case. Though, this would still be a nice to have for the API, if possible. 
"
facebook/react,2018-04-26 09:52:26,feature,Allow to specify displayName for createContext() providers and consumers,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
bug

**What is the current behavior?**
in React tree name of a Context must be like its name in code

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**
```js
const MyContext = React.createContext(null);
```
```js
   <MyContext.Consumer>
   { data => ... }
   </MyContext.Consumer>
```
let's have a look at React tree in Chrome extention's page

here is Context - not MyContext

**What is the expected behavior?**

expexted to see MyContext

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

16.3.2"
facebook/react,2018-04-16 15:06:02,feature,Don't call getDerivedStateFromProps on a PureComponent if props are the same?,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
`getDerivedStateFromProps` is called on a PureComponent even if the props haven't changed

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

**What is the expected behavior?**
As is

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
All

I was hoping `getDerivedStateFromProps` wouldn't be called on a PureComponent if the props hadn't changed. Any reason why this shouldn't/couldn't be the case?
"
facebook/react,2018-04-04 14:13:55,feature,Support hydration after HTML minification,"**Do you want to request a *feature* or report a *bug*?**
Report a bug

**What is the current behavior?**
`React.hydrate` replaces the DOM after a SSR page is served, and two sibling links in the page have the `href` attributes wrongly set.

I did a little repl to replicate this behaviour [here](https://repl.it/@EnoahNetzach/SSR-whitespace-mismatch).

When the server responds, the HTML is correct:

![screen shot 2018-04-04 at 16 08 06](https://user-images.githubusercontent.com/663755/38312693-b1167650-3822-11e8-85f3-0f100caf8a50.png)

but right after hydration, the first `href` is changed: 

![screen shot 2018-04-04 at 16 08 20](https://user-images.githubusercontent.com/663755/38312738-c96e1b4a-3822-11e8-9e7e-0d6a9fa24ed2.png)
and whitespace artifacts are added.

**What is the expected behavior?**
The first `href` should not be changed.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
React v16.2
Chrome 65.0
macOS
"
facebook/react,2018-03-30 06:21:12,feature,Provide a better error on React.cloneElement(null/undefined),"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

**What is the current behavior?**

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

**What is the expected behavior?**

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
![image](https://user-images.githubusercontent.com/5977311/38124026-a0984a98-3411-11e8-838f-2d6f3dc97046.png)
"
facebook/react,2018-03-28 20:54:22,feature,Issues with ReactControlledValuePropTypes,"**Do you want to request a *feature* or report a *bug*?**

See below.

**What is the current behavior?**

1. (Bug / Inconsistency)
```jsx
<input type=""radio"" checked={false} />
```
No Warning.

2. (Feature Request)
```jsx
<input type=""radio"" checked={true} onChange={undefined} />
```
`Warning: Failed prop type: You provided a 'checked' prop to a form field without an 'onChange' handler. This will render a read-only field. If the field should be mutable use 'defaultChecked'. Otherwise, set either 'onChange' or 'readOnly'.'`

3. (Bug?)
```jsx
<select value=""foo"" readOnly={true}>...</select>
```
No warning.

**What is the expected behavior?**

1. Passing a falsy `value` or `checked` attribute will not trigger a warning, but a truthy value does.

2. If onChange is passed as undefined (or null?) this should be considered as an acknowledgement and silence the warning. I have a case where I split the render method from the component and use it as a preview. When the component is interactive I use the component. When doing a preview I pass undefined as my change handler. A warning is shown to tell me I ""forgot"" it, but I intended it to be this way.

3. Going along with 2, I can pass `readOnly={!handleChange}`, but according to DefinitelyTyped this isn't a valid attribute for select. I can't use disabled because it changes the appearance of the field.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

16.2.0
Chrome 65

**Other**

A proposed ""fix"" would be to change:

https://github.com/facebook/react/blob/37e4329bc81def4695211d6e3795a654ef4d84f5/packages/react-dom/src/shared/ReactControlledValuePropTypes.js#L27-L33

to:

```js
if ( 
    !(propName in props) || // Fixes 1
    hasReadOnlyValue[props.type] || 
    ""onChange"" in props ||  // Fixes 2
    props.readOnly || 
    props.disabled 
 ) { 
```

And:

https://github.com/facebook/react/blob/37e4329bc81def4695211d6e3795a654ef4d84f5/packages/react-dom/src/shared/ReactControlledValuePropTypes.js#L44-L49

to:

```js
if (
    !(propName in props[propName]) || // Fixes 1
    ""onChange"" in props || // Fixes 2
    props.readOnly ||
    props.disabled
) {
```"
facebook/react,2018-03-05 23:44:49,feature,Production reconciler Instrumentation,"_Apologies if this is documented somewhere, but I was unable to find anything related after a pretty exhaustive search of docs + code._

Are there any production instrumentation hooks for the reconciler?  Specifically, I'm looking for callbacks/events that would allow me to track overall reconciliation time spans (nothing more granular).  E.g. equivalent to the `(React Tree Reconciliation)` span.

As best I can tell, there are `performance.timings` spans reported as of Fiber (and `ReactPerf` prior), but those are only enabled in development mode."
facebook/react,2018-02-20 05:09:50,feature,Does react still require non-toplevel submit handler?,"**Do you want to request a *feature* or report a *bug*?**

bug? Maybe.

**What is the current behavior?**

Using non-delegated handler for submit event.

**What is the expected behavior?**

After IE9, at least I know, submit event bubbled up.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

16.2.0"
facebook/react,2018-02-16 00:04:58,feature,Extracting a Context Stack,"A useful feature of context is creating a custom stack of things to see what your component is embedded in side.

I think the primary use case is logging explicitly.

Currently that is pretty expensive to maintain just *in case* you need it. See #12234 as an example.

We could provide an API that lazily extracts a whole path of contexts from the tree.

```js
<FooContext.Provider value={""foo""}>
  <FooContext.Provider value={""bar""}>
    <FooContext.Provider value={""baz""}>
      <App />
    </FooContext.Provider>
  </FooContext.Provider>
</FooContext.Provider>
```

```js
class App extends React.Component {
  log() {
    var stack = this.getContextStack(FooContext);
    logToServer(stack); // [""foo"", ""bar"", ""baz""]
  }
  render() {
    return <div onClick={this.log} />;
  }
}
```

It would basically synchronously rerender the shortest path to recreate the context at the time of the call to create the stack lazily.

cc @acdlite "
facebook/react,2018-02-14 19:41:49,feature,Provide a way to perform a synchronous render into another root during the commit phase,"**Do you want to request a *feature* or report a *bug*?**

Bug

**What is the current behavior?**

Reentrancy checks prevent synchronous `ReactDOM.render` in a nested React component. This used to work before React 16, and [seems related to this issue about nested ReactDOM renders](https://github.com/facebook/react/issues/12034)

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

Here's a [JSFiddle](https://jsfiddle.net/e5hbzc1r/14/) that documents the problem, with a simulation of the external dependency where this manifests.

**What is the expected behavior?**

I'm running into what I think is a [similar problem to this one](https://github.com/facebook/react/issues/12034), with a nested `ReactDOM.render`, except where the difference is that I don't think we can use portals to address our use-case.

We have a component which manages the DOM tree for all nodes below it outside of React — it's a contenteditable node and uses the best-in-class [ProseMirror](https://prosemirror.net/) library to manage its children. The component looks something like this:

```javascript
class ProseMirror extends Component {
	componentDidMount() {
		// ProseMirror manages the DOM for all nodes below this.el.
	}

	setRef(el) {
		this.el = el;
	}

	render() {
		return (<div ref={this.setRef} />);
	}
}
```

As part of its render cycle, our configuration of ProseMirror ends up calling:

```javascript
ReactDOM.render(<CrucialSubComponent />, someDivManagedByProseMirror);
```

to render an isolated child node of `<ProseMirror />`, and wants to be able to immediately afterwards be able to leverage:

```javascript
this.el.querySelector('.my-subcomponent')
```

...but this piece of the DOM is no longer available synchronously, and it looks like this is because of the re-entrancy change that came about in React 16. Portals don't work for us, because the site where the `ReactDOM.render` is being called isn't itself directly part of the root React tree (this is [clearer to observe in the fiddle](https://jsfiddle.net/e5hbzc1r/14/)). The hierarchy is something like `<ProseMirror /> ---> (opaque ProseMirror rendering code) --> <CrucialSubComponent />`. Is there a way to skip these re-entrancy checks in these cases where there's an isolated React render happening in a grandchild of a component, but where the React tree isn't the immediate parent?

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

Querying the DOM immediately after ReactDOM.render worked in versions prior to React 16. We're excited about the async possibilities for our main React tree, but curious if there are workarounds where we can ignore the reentrancy checks for these isolated renders."
facebook/react,2018-02-08 21:09:50,feature,Add oldProps as additional argument to getDerivedStateFromProps ?,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

feature

**What is the current behavior?**

`getDerivedStateFromProps` only receives the nextProps and previousState as arguments.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

The deprecated `componentWillReceiveProps(nextProps)` used to allow code like `this.props.foo !== nextProps.foo`. With the new `getDerivedStateFromProps` function, there's no choice (because it is a static method) but to constantly copy `nextProps.foo` into state in order to access it later.

This is illustrated in the example posted to twitter by @gaearon: https://twitter.com/dan_abramov/status/953612246634188800?lang=en

**What is the expected behavior?**

Ideally (if it's not difficult to implement!) the `getDerivedStateFromProps` would also take the current (previous/old) props as an argument, something like:

`getDerivedStateFromProps(nextProps, prevState, prevProps)`

This would eliminate the need to constantly assign props to state purely for comparison purposes...

A quick look at the source doesn't make it clear to me how easy this would be though...

https://github.com/facebook/react/blob/4a20ff26ecfe9bc66941d79f7fce2c67be8ee236/packages/react-dom/src/server/ReactPartialRenderer.js#L456

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

16.3.0"
facebook/react,2018-01-18 13:02:31,feature,can React support feature like keep-alive in Vue?,"i found this issue: https://github.com/facebook/react/issues/4770,  and @sophiebits said that React never reuses an instance after it's been unmounted. 

does it means that React will never support feature like keep-alive in Vue? or there is other way to maintain component's state?
"
facebook/react,2018-01-13 04:15:48,feature,Have Fragments support dangerouslySetInnerHTML,"The addition of the `Fragment` in 16.2.0 is fantastic and helps keep our HTML semantic and clean. Unfortunately there is still no way to inject HTML without a wrapping tag.

```jsx
const HTML = <span>Hello World</span>;

<div key={ ID } dangerouslySetInnerHTML={ { __html: HTML } } />
```

which will render:

```html
<div><span>Hello World</span></div>
```

It would be mostly helpful for rendering HTML from jsx on the back end rather than in the SPA context. To me `Fragment` seems to be the ideal candidate to support `dangerouslySetInnerHTML` so that you may inject HTML without wrapping elements.

```jsx
const HTML = <span>Hello World</span>;

<Fragment key={ ID } dangerouslySetInnerHTML={ { __html: HTML } } />
```

would render:

```jsx
<span>Hello World</span>
```

Simple, obvious and aligned with the current API."
facebook/react,2018-01-09 10:35:40,feature,Symbols as keys in children as arrays or iterators,"**Do you want to request a *feature* or report a *bug*?**

I want to request a feature

**What is the current behavior?**

Using `Symbols` as element keys throws a type error.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

When using `key={Symbol('myKeySymbol')}` we get the following `TypeError: Cannot convert a Symbol value to a string at Object.ReactElement.createElement`

[codesandbox here](https://codesandbox.io/s/733pypz57j)

**What is the expected behavior?**
Using `Symbols` as keys should work seamlessly, in my opinion element keys are a perfect use-case for `Symbols`.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

Using React `16.0.0` and the browsers affected are Safari, Chrome and Firefox on OSX, but I'm pretty sure this is not browser dependent but a matter of implementation.

~~~

Thanks.
"
facebook/react,2018-01-05 17:04:10,feature,Add React.createRef() as the migration path for string refs,"Creating this issue to track https://github.com/facebook/react/pull/11555. I intend to close the PR as it's outdated, but we probably want to turn it into a real RFC and potentially get it in during 16.x."
facebook/react,2017-12-13 21:24:31,feature,Lifecycle method to build initial state for classes,"**Feature request**
We need to have a way to build the initial state of ReactComponent in case of usage of classes.

**What is the current behavior?**
Warning in case this.state modified in willComponentMount.

Access to partially constructed object in case of somewhat complex state building logic in the constructor.

For example, if we have a hierarchy of classes with the _buildState method called in the constructor to generate an initial state.
Derived class overrides the _buildState method to have a richer state. In result, part of the object related to the derived class won't be constructed yet and can't be accessed in the _buildState.

The buildState approach is currently used in ReSub framework:
https://github.com/Microsoft/ReSub

**What is the expected behavior?**
Rather no warning in case of this.state modification or new Lifecycle method which is called right after constructor call which returns the state.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
React 16+ is affected.
"
facebook/react,2017-12-08 08:31:37,feature,Feature request: Global state at the render/hydrate level,"This is a feature request. It relates to https://discuss.reactjs.org/t/suggestion-for-global-context/9035

This has been a pain point for me, and I'm sure we can do better. The issue: How to have some state available to all components without passing everything down on props through the component tree.

I'm speaking about global state. So why not use context? I have a couple of issue with it.

1. It's not the root component's job to receive and disseminate state. The root component is just some component. It shouldn't care if it's root or not. Maybe you have (example using Express):

    `res.render('homepage.jsx', {});`

But some other page might just as well have:

    res.render('otherpage.jsx', {}) where otherpage has:

    <div>
      <Something />
      <Homepage />
    </div>

Components can be composed however you like, they shouldn't care what depth they're at.

2. Above is talking about a multipage app. The thinking around React seems to be so skewed toward to the special case of Single Page App. SPA is sometimes the right choice. If you're Google Maps it's clearly right. If you're something broader in scope like Amazon.com it's clearly not. The general case is much more interesting to solve.

3. Having every root component wrapped in some `<Provider>` that publishes context downwards, and every non-root component wrapped in some ""receiver"" higher level component that declares context is just boilerplate. It's not expressive, it's bookkeeping.

4. Alternatives: There aren't any as far as I know. Each component only knows about the props (and possibly context) passed in, it doesn't have any handle on data for the current render() call. Simply importing global state through CommonJS or ES6 modules is impossible on the serverside for anything request scoped (like query params, route params, cookies, headers, anything generated by middleware based on these things).

-- PROPOSAL --

Why not just handle global state at a higher level than props passed component to component? Why not extend ReactDOM.render to take a 4th argument for global context? It would just make everyone's life easier. Don't even worry about changes firing componentWillReceiveProps, at least as a first version.

Think of it as analogous to Express and the ""req"" object that's passed around. One should always have access to some ""per request"" object. So many things would be useful to put in there (authenticated user, geolocation, ""store"" from Redux, query and route params, etc, etc).

It would look like:

    ReactDOM.render(rootComponent, someDiv, callback, {... request specific data ...})

Where request specific data might have things that are truly request specific and also things that are the same across requests. The latter can be done with imports but it's a bit messy -- you end up with code like:

    if (typeof window != 'undefined') {
      // Client, get value from window object
    } else {
      // Server, get value from filesystem or wherever
    }

Just having global data available to all components in the tree simplifies things a lot. Don't you think?
"
facebook/react,2017-11-27 16:28:49,feature,Add hooks to ReactDOMServer to support caching,"**Do you want to request a *feature* or report a *bug*?**
feature

**What is the current behavior?**
react-dom SSR performance could be improved using server-side cache, but currently the
ReactPartialRenderer is currently not accessible from the `react-dom` package.

**Desired behavior**
On the **server** only, it would be nice if _plugins_ could be used to improve render performance. Currently the only way to do this would be to externally maintain a renderer implementation. However, the `ReactPartialRenderer` already contains all the behavior required to support plugins - with a little refactoring. 

I've refactored the `ReactPartialRenderer` and created a **proof of concept** for supporting _plugins_ for react server side rendering. You can see the [ReactPartialPluginRenderer](https://github.com/adam-26/react/commits/pluginRenderer) in this fork, its comprised of 3 different commits:
* [#1](https://github.com/adam-26/react/commit/0b2f7852a19ffabac6b83581f6821f0346434ef0): Strict refactoring of `ReactPartialRenderer`, the only addition is exporting the `ReactPartialRenderer` from the react-dom server package
* [#2](https://github.com/adam-26/react/commit/d30792a8ba42d50188c0dd1fddbc73275b8ff91f): Create the `ReactPartialPluginRenderer` by extending the refactored `ReactPluginRenderer`, and introduce a plugin interface
* [#3](https://github.com/adam-26/react/commit/d4f01973d535c9eb34ba450190b7c8205fe593df): Proof of concept plugin implementations and application example.

You can [view instructions for running the example in the repo](https://github.com/adam-26/react/tree/pluginRenderer/fixtures/ssrPlugins).

I understand that exporting `ReactPartialRenderer` exposes the internal API, which is far from ideal. Is there any scenario in which `ReactPartialRenderer` would be made to be accessible from the `react-dom` package? Or would a plugin implementation similar to above be required to maintain its own forked `ReactPartialRenderer`? Maintaining the plugin renderer in its own repo isn't a problem, but It would be great if plugins could be used without needing to maintain the core server renderer.

Thanks, Adam.


"
facebook/react,2017-11-13 20:51:46,feature,stopImmediatePropagation is not available for synthetic events,"In order to call this method, you'd have to access it via `event.nativeEvent.stopImmediatePropagation()`: https://developer.mozilla.org/en-US/docs/Web/API/Event/stopImmediatePropagation

It'd be awesome if this was supported on `event` itself. I did see a [prior issue](https://github.com/facebook/react/issues/1734) for this, but it was for a use case that sIP wasn't required for.

For a specific use case: if you want to kill hover events for touch input, `onTouchStart` will trigger `onMouseOver` and `stopImmediatePropagation` cancels that internal cascade."
facebook/react,2017-10-26 11:13:56,feature,Add a way to opt out of User Timing API calls,"**Do you want to request a *feature* or report a *bug*?**  

bug or v16 feature (dont know)

**What is the current behavior?**  

When building in dev environment, performance timeline measures appear by default,  
ie. without `?react_perf` query string as in v15 described [here](https://reactjs.org/docs/optimizing-performance.html#profiling-components-with-the-chrome-performance-tab)

`react@16.0.0`

if it's not a bug, then what's the way to disable `react` perf measures?  

Need a way to clear timeline to focus on my own custom perf measures.
"
facebook/react,2017-10-22 18:42:36,feature,Release a tool for statistical perf analysis (a replacement for ReactPerf),"**Do you want to request a *feature* or report a *bug*?**
A feature

**What is the current behavior?**
N/A

**What is the expected behavior?**
It's great that React 16 integrates with the timeline in browsers dev tools and that is very helpful in cases where you are trying to fix the performance of a specific thing. However I do miss the perf tool from previous versions and could not find any issue tracking a re-implementation of such a tool.

What was great in the perf tool that is not covered as well with timeline integration?
 - Easily see which components render needlessly and therefore should be easily eliminated with sCU (and what impact it will give)
 - Easily see the collective render time of a component. I might for example have a component that renders very fast but which have very many instances and thus contribute to a significant render time anyway.
 - Give an overview of which components are slow by themselves and which are fast by themselves but render slow components. The flamegraph shows this, but I find it to specific in some scenarios with too much detail that can distract.

Basically the wasted, exclusive and inclusive tables. The DOM table I feel is much better represented by the timeline integration.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
16, yes the perf addon in 15 was good."
facebook/react,2017-10-20 21:34:42,feature,Add `code` property to `SyntheticKeyboardEvent`,"**Do you want to request a *feature* or report a *bug*?**

Improvement

**What is the current behavior?**

[`SyntheticKeyboardEvent`](https://github.com/facebook/react/blob/e779c39dfeb41ae8f6611dc4f9830d1b1ac64f9b/packages/react-dom/src/events/SyntheticKeyboardEvent.js) does not currently support the `code` property.

`code` ([MDN](https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent/code)) is nice to have when you want to write key-specific handling—rather than input-specific (dependent on layout and modifier keys) handling.

**What is the expected behavior?**

`SyntheticKeyboardEvent` already exposes a `keyCode` property. It should have a `code` property as well.

Currently, if you want to use the `keyboardEvent`'s  `code`, you must access it through `SyntheticKeyboardEvent`'s `nativeEvent`.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

Affects React 16 and earlier (I assume).
"
facebook/react,2017-10-14 00:28:00,feature,Async componentWillReceiveProps to allow state update,"**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
An (almost) immediate re-render is due after `componentWillReceiveProps` is called, unless `shouldComponentUpdate` says otherwise.

**What is the expected behavior?**
If new props in `componentWillReceiveProps` cause an async call that's soon going to update the state anyway, won't it be cool if React might as well wait for that async call to do it's thing (which calls `setState`) and do one render instead of two?

Potential solution: React can see if `componentWillReceiveProps` returns a `Promise`. If it does it defers the re-render until it `resolves`.

```javascript
async componentWillReceiveProps(nextProps) {
    const { postId } = nextProps;
    const postTitle = await fetch(`https://api.example.com/posts/${postId}`);
    this.setState({ postTitle });
    return;
}
```
"
facebook/react,2017-10-10 19:25:21,feature,React16 not compatible with x3dom,"** This is both bug / feature
https://www.x3dom.org/

I used to be able to use x3dom with React. It was great.

** React ^15 I was able to use the **is** property to generate custom elements and custom attributes that could be picked up by x3dom i.e. <shape is render=""true""/>

Now with React16 i get many warning messages for all of the custom x3dom tag elements. Likewise it seems that certain attributes aren't getting rendered either. For instance if I do x3dom elements like so:

`<fontstyle size=""0.6""/>` I'll get `<fontstyle/>` output without the size attribute.

I don't think React should have to know what x3dom tags are, nor should they be hard-coded into React. There has got to be a way to have React output custom tags without throwing warning messsages. Why not just re-introduce the **is** attribute to indicate that it's a custom tag with custom attributes? "
facebook/react,2017-10-02 14:44:19,feature,Loosen up type requirements for event handlers,"**Do you want to request a *feature* or report a *bug*?**

Feature

**What is the current behavior?**

When adding event handlers, it is common practice to do something like:

```js
const MyButton = ({ canClick, onClick }) =>
  <div onClick={canClick && onClick}></div>
```

This was fine in React 15.x, but in 16 it reports a warning, which is technically correct:

> Expected `onClick` listener to be a function, instead got a value of `boolean` type.

However, this now forces you to use the more verbose variant:

```js
const MyButton = ({ canClick, onClick }) =>
  <div onClick={(canClick && onClick) ? onClick : undefined}></div>
```

**What is the expected behavior?**

I think it makes sense to allow `null`, `false`, and `undefined` in addition to function types for event handlers. Or just anything ""falsy"", although that may be too much to ask.

I definitely understand the rationale from a type safety perspective, but this does make it less pragmatic. I am personally a huge fan of how JS evaluates `null`, `0`, `""""` and `undefined` to `false`, and it reduces the amount of boilerplate needed to conditionally wire up handlers.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

React 16, all browsers. This did not emit a warning in React 15 and below.
"
facebook/react,2017-09-28 20:34:07,feature,Production Check in react-test-renderer,"When upgrading to 16.0.0 from 15.6.1, react-test-renderer started failing on my tests with the message:
> test renderer is not available in production mode.

I have in fact been running unit tests using this renderer during my production build.

I'm trying to understand: why was this restriction introduced?  I saw the change was made in #9514 but couldn't find any explanation on the pull request or the documentation as to why production mode is now disallowed for this renderer.

Thanks,
Alex"
facebook/react,2017-09-27 15:55:53,feature,"""Did not expect server HTML to contain the text node"" due to whitespace in React 16","We have updated our React v15 Application to v16. Everything seems to work fine instead the fact that this error appears:

`Warning: Did not expect server HTML to contain the text node ""
  "" in <div>.`

We are using ReactDOM.hydrate and our App was completely SSR Ready in v15. I've found an old issue on Stackoverflow where someone wrote that this could be a problem with the markup which is send from Server -> Client, but as far as we can see the HTML code is the same without any markup problem."
facebook/react,2017-09-18 13:39:07,feature,Attach third-party tools to monitor component state updates,"**Do you want to request a *feature* or report a *bug*?**
feature, that exists in previous releases of react

**What is the current behavior?**
feature is not implemented

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?** React 16, worked in previous versions

Hey,
We would really like to be able to use ReactInstrumentation with Fiber. I have found @gaearon 's pull request, but work on it was stopped. Would like to know why? and if we can pick this up and implement it.

https://github.com/facebook/react/pull/8152
(I have also asked why in the pull request, but figured it might get ignored since it is a closed pull request)

Omer
"
facebook/react,2017-09-13 09:06:11,feature,`select` should warn if `value` is not available,"IMO, 
```
<select value=""foo"" onChange={...}>
  <option value=""yes"">Yes</option>
  <option value=""no"">No</option>
</select>
```
should warn because there is no ""foo"" option. It should probably also warn if `value` is not specified, because there is no ""empty"" option either.
One could also argue that the change handler should be called with {value: 'yes'} when the component renders and the first option is selected instead of an invalid/non-existing one."
facebook/react,2017-08-31 02:56:51,feature,Accept Ref Objects as Refs?,"[Reason React](https://github.com/reasonml/reason-react) uses first class OCaml refs to store mutable values (instead of on `this` instances).

These are basically just an object with a mutable `contents` property. These can be updated with callback refs `n => ref.contents = n` but it would be a nice convenience feature to just have that built-in.

We could also make these first class objects on isomorphic React.

```js
React.createRef = () => ({ contents: null });
```

```js
class Foo extends React.Component {
  state = {
    myDiv: React.createRef()
  };
  componentDidMount() {
    if (myDiv.contents) {
      myDiv.contents.focus();
    }
  }
  render() {
    return <div ref={this.state.myDiv} />;
  }
}
```

Basically the implementation would just be:

```js
if (typeof ref === 'function') {
  ref(newValue);
} else if (typeof ref === 'object') {
  ref.contents = newValue;
} else if (typeof ref === 'string') {
  owner.refs[ref] = newValue;
}
```

This is something that needs to be implemented in the core runtime and not as part of any particular component API since refs cross that boundary.

cc @adamjernst
"
facebook/react,2017-08-03 04:36:26,feature,Async Top-level Hook Before Commit,"_(This isn't needed for 16.0.)_

I think we're missing a top-level API. If you want to integrate with non-React code around you in an async way, then you probably have some parents around you. It's not always the case that you want to show those parents before React is done. Maybe you can hide them and then show them at the callback time.

However, it would be better if you could start building the tree async with React, and then get a callback *before* we trigger life-cycles so that you can insert the tree into the actual DOM and do whatever manipulation you need. Only after that do we trigger the life-cycles. That way they will have the CSS and layout information available to them by virtue of being in the document already.

I see two possible routes:

a) We just call out for this hook and then commit immediately after.

b) We invoke a callback and pass another function. That function, when invoked, does the actual commit. This approach has precedence in the DOM with ""append async"" and offscreen canvas.

The second option is probably preferable but we should only do that if we can do it efficiently and cleanly."
facebook/react,2017-07-12 22:38:53,feature,[Feature Suggestion] Publish react also as ES2015 code,"**Do you want to request a *feature* or report a *bug*?**
*feature*

**What is the current behavior?**
React is published to NPM only as ES5 code

**What is the expected behavior?**
Publish react also in es2015, with es2015 entry point in the package.json

Motivation: Performance. leverage the targeted client native ES features 
Its part of the angular 4 package format
https://docs.google.com/document/d/1CZC2rcpxffTDfRDs6p1cfbmKNLA6x5O-NtkJglDaBVs/edit#heading=h.jt2mvxhyrshv
http://2ality.com/2017/04/setting-up-multi-platform-packages.html"
facebook/react,2017-07-01 00:58:07,feature,Nicer Formatting of SSR Validation,"The new validation in #10026 only issues a warn for the first difference found in a HTML hydration scenario. Ideally it should instead queue up all the differences and then at the end (commit) issue a single warning with a nicely formatted diff.

1) Instead of warning add [these warn calls](https://github.com/facebook/react/blob/8d61138186e79e1e719786c8c76186e64b603bd5/src/renderers/dom/fiber/ReactDOMFiberComponent.js#L74-L115) to a global buffer (array, map, set, whatever).

2) Inside [prepareForCommit](https://github.com/facebook/react/blob/8d61138186e79e1e719786c8c76186e64b603bd5/src/renderers/dom/fiber/ReactDOMFiberEntry.js#L190), issue all the currently batched up warnings as a single message. 

3) Format that message in terms of a JSX diff in a nicely formatted way. With only the relevant nodes (parent and child with changes). Irrelevant child content can be replaced with ellipsis. E.g.

```
...
<div className=""unchanged"">
- <div className=""foo"" />
+ <div className=""bar"">…</div>
+ <span />
</div>
...
<div className=""another_unchanged"">
- <span />
</div>
...
```

This strategy won't yield perfect results because if we're asynchronously hydrating, and it gets interrupted by another tree, we'll flush a warning before the actual hydrating particular tree is flushed. So we might show a partial diff in that case. This is probably. It's just a warning."
facebook/react,2017-06-28 21:15:30,feature,"Feature request: Support server-side rendering of non-standard DOM attribute names (eg. AMP's [prop]=""value"")","**Do you want to request a *feature* or report a *bug*?**
Request a feature

I am working on project to build AMP page with React Server Side Rendering. I am having an issue to add custom attribute to built-in AMP element. In order to be able to use [amp-bind](https://www.ampproject.org/docs/reference/components/amp-bind#bindings) we need to be able to output “bindings”, which are special attributes of the form `[attribute]`, eg. `[slide]=""selectedSlide""`. 

```
<amp-carousel 
    layout={layout}
    height={height}
    width={width}
    [slide]={slide}
>
        ...
</amp-carousel>
```

Here is AMP carousel example that work with [amp-bind](https://ampbyexample.com/advanced/image_galleries_with_amp-carousel/#linking-carousels-with-amp-bind).

**What is the current behavior?**
- Parsing error: Unexpected token [ (Fatal) 

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
- All

For more information, you can read all the discussion in this [PR](https://github.com/facebook/react/pull/7311#issuecomment-311516763)."
facebook/react,2017-06-21 20:40:15,feature,Feature request: renderTypes,"**Do you want to request a *feature* or report a *bug*?**
Request a feature

Per some discussion today with @tomocchino and @thejameskyle, I'd like a non-Flow mechanism to annotate what type(s) of elements a component expects to render.

Here's some examples, with Flow types for comparison (that I realize may not be currently checked in Flow, yet):
```jsx
function Foo({ yes }){
  return yes ? <Bar /> : <div />;
}
Foo.renderTypes = [Bar, 'div'];


class Bar extends React.Component {
  static renderTypes = [Button];

  render() {
    return <Button />;
  }
}
```
```jsx
function Foo({ yes }): React.Element<Bar | 'div'> {
  return yes ? <Bar /> : <div />;
}

class Bar extends React.Component {
  render(): React.Element<Button> {
    return <Button />;
  }
}
```

Inside @Airbnb, we have lots of use cases where we have container components in a separate package - say, a `<ButtonRow>`, and we have intentionally restrictive propTypes on its `children` prop, to only allow a `Button` (also in the same package). However, in an app that consumes this component library package, a dev may want to create a `<SpecialProductButton />` that in turn renders a `<Button>` - however, they're unable to pass it into `ButtonRow` (our propType warnings fail tests), even though conceptually it should be permitted.

Having `.renderTypes` would allow us to widen our `children` propType to allow for either a `<Button>`, or *anything that renders a `<Button>`*, which helps us maintain separation of concerns (the package doesn't have to know about `<SpecialProductButton>` to accept it) as well as maintain strictness (the package doesn't have to allow any wacky element inside `<ButtonRow>`).

I imagine the implementation to be:
 1. when render() is called or an SFC is invoked, (in async rendering, it'd be when the component resolves, i suppose)
 1. in development only and if `.renderTypes` exists on the component
 1. evaluate the equivalent of [`elementType`](https://www.npmjs.com/package/airbnb-prop-types)`(...Component.renderTypes)({ children: renderedValue }, 'children', ...)`,
 1. just like propTypes, log the error if one is returned

(cc @spicyj)"
facebook/react,2017-06-01 21:35:31,feature,Add React.Children.find,"I think a `React.Children.find` method would be really useful in situations where you need to iterate over your children and find just one that satisfies a particular condition. I'm running into this situation more and more often in my React code. A few examples:

- In [React Router](https://reacttraining.com/react-router), the `<Switch>` component [iterates over its children](https://github.com/ReactTraining/react-router/blob/c46e51bfd61343611ddbc173207952e980b81aec/packages/react-router/modules/Switch.js#L38-L49) to figure out which `<Route>` matches the URL.
- In [a `<Select>` component we use in our training workshops](https://github.com/ReactTraining/react-subjects/blob/44614bc3c6c8ca1de813e0bd1e14f86a74a5c0fb/subjects/Select/solution.js#L24-L37), we need to iterate over the `<Option>`s to figure out which label we should show in the select box.

I wonder if there would be any interest from others in seeing something like this."
facebook/react,2017-05-06 12:20:06,feature,Warn when `static propTypes/static defaultProps` in ES6 class is a function,"**Do you want to request a *feature* or report a *bug*?**
Bug

**What is the current behavior?**
```
class TestWrongPropTypes extends Component {
    static propTypes() {
        return {
            children: PropTypes.string,
            missing: PropTypes.string.isRequired
        };
    }

    static defaultProps() {
        return { children: 'Default props via static function' };
    }

    render() {
        return <p>{this.props.children}</p>;
    }
}
```

In this example React will silently skip `propTypes` checking and default props setting for `TestWrongPropTypes` component.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem via https://jsfiddle.net or similar (template: https://jsfiddle.net/84v837e9/).**
https://jsbin.com/jidupehebu/edit?js,console
https://jsfiddle.net/84v837e9/30/

**What is the expected behavior?**
I know that in order to work, propTypes definition should be `static get propTypes = {...}` or `TestWrongPropTypes.propTypes = {...}`. But I'd like to have warning like ""propTypes/defaultProps is function but should be either property or getter"" to prevent such errors.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
Discovered in React 15.X, but probably the same behavior will be also in earlier versions."
facebook/react,2017-04-23 22:49:34,feature,[RFC] Add traversal utility to ReactTestUtils matching toTree shape,"### Problem

The `ReactTestRenderer` now supports a new API, [`toTree`](https://github.com/facebook/react/blob/master/src/renderers/testing/ReactTestRendererFiber.js#L350-L355), which returns an easily traversed tree representing the internal state of the instance and its rendered nodes.

The existing solution for this in `TestUtils` is `findAllInRenderedTree` which traverses the root and lets you provide a test function it will call to reduce a tree based on a predicate. The predicate function is passed the public instance for the node.

The issue with that is that it makes the predicate function polymorphic and requires every consuming utility to check if it's being passed a component instance or a DOM node. 


### Solution

I propose that we implement a new API similar to `findAllInRendererdTree` that calls the predicate function with the result of calling `toTree` on the internal instance instead of the public instance. This would mean:

* the predicate function will always be called with the same data structure (a tree node)
* third-party traversal utilities can be shared between `ReactTestRenderer` and `ReactTestUtils`, since they would operate on the same tree structure
* You could actually assert on functional components, which currently have no instance and just call the predicate with `null`

This new API could just be a pure traversal utility, leaving it up to the consumer to accumulate results.

```js
import { renderIntoDocument, traverseTree } from 'react-dom/test-utils';
var root = renderIntoDocument(<App />);
var results = [];
traverseTree(root, node => {
  if (somePredicate(node) { results.push(node) }
})
```
 
## Implementation

With a brief review, it looks like we could just export the `toTree` function that is currently inlined in `ReactTestRenderer` and provide a way to change:

```js
 var publicInst = node.stateNode;
      if (test(publicInst)) {
        ret.push(publicInst);
      }
```

to:
```js
 var treeNode = toTree(node);
      if (test(treeNode)) {
        ret.push(treeNode);
      }
```

cc @gaearon @bvaughn @lelandrichardson "
facebook/react,2017-03-15 23:11:13,feature,Expose DEV-mode warnings in devtools UI,"React has made recent developer experience improvements to lifecycle error handling and logging. Errors thrown during render can be recovered from using ~~`unstable_handleError`~~ `componentDidCatch`. Errors thrown during lifecycle methods are also automatically logged to the console with the component stack location to make them easier to identify (see #8785).

The team has discussed similar improvements for warnings- such as using a ""yellow box"" approach to make warnings stand out more in developer mode (see PRs #7360 and #8861). There has been some pushback though to the idea of React modifying the DOM for warning purposes (see issue #8784). I'm not sure how that will play out yet- but in the meanwhile, could we improve at least some of these use cases by making better use of the devtools?

For example, what if React exposed a new API that allowed associating a warning with one or more components in the devtools panel? (eg a method that- when called- recorded the current component stack and notified devtools if present) React could use this for things like missing or non-unique keys. 3rd party libraries may also benefit from this (eg react-virtualized could use this to warn about missing or incomplete positioning styles for cells).

Here's a rough outline of some of the features:
* Components with warnings could be highlighted in some emphasized way (eg yellow background) in devtools to make them easier to spot.
* A new toolbar option could be added to ""Show All Warnings"" (eg filter the tree view to show only components with warnings).
* Warning message could be shown inline in the settings panel for the selected component.

Here's a rough mockup: 
![screen shot 2017-03-15 at 3 47 31 pm](https://cloud.githubusercontent.com/assets/29597/23974108/bc3dabd6-0996-11e7-8d2a-e058c4cafe41.png)

Limitations:
* Not everyone uses devtools so this would not help a lot of people.
* This would not address issues like using the development mode of React for production sites.

Thoughts? Ideas? Suggestions?"
facebook/react,2017-03-03 18:30:15,feature,RFC: ReactFiberReconciler release artifact,"This issue is intended to be a discussion for how to distribute the ReactFiberReconciler.js file and dependencies for custom renderers.

Currently first-class renderers within the React codebase/Facebook ecosystem do not have any concerns for this because of Haste / access to the React.js build + publish tooling within this codebase.

3rd party renderers are currently adding `react-dom` to their dependency list and requiring `react-dom/lib/ReactFiberReconciler.js` to build and expose their custom renderer.

Ideally, `ReactFiberReconciler.js` would be distributed with the `react` package or as a standalone `react-fiber-reconciler` package. Whether this is at `react/reconciler.js` or `react/lib/reconciler.js` idk. I think at the root is better to continue the discouragement of looking in `react/lib/*` for anything.

I understand flat bundles are coming, too. I don’t know if that should block this or if this could be a flat bundle, or any other alternative.

Is this something the team is ready to commit to and support if we came to a decision on approach and I put together a PR?

 Related issues:

* #6795 Create Separate Copies of Each Renderer
* #5472 Include flow type definitions (flow type distribution proposal at https://github.com/facebook/react/issues/5472#issuecomment-282394248)

+ @sebmarkbage @spicyj "
facebook/react,2016-12-08 21:45:39,feature,Provide a way for external tools to list nodes with event info,"I would like to add React event bubbles to the markup tree of Firefox Developer Tools. To do this I need a way to get a list of nodes and their attached event listeners.

If somebody can provide a way for me to do this it will be added within a day.

Is this possible at the moment and, if not, what can be done to make this possible?"
facebook/react,2016-09-16 23:21:25,feature,[RFC] Idea: forceDeepUpdate() and forceDeepUpdateWithScope(scope),"_Just going to put it out there for feedback..._
## Motivation

Subscription management comes with a cost and that eats into the wins of async rendering since it needs to be managed synchronously. Not just managing the direct subscriptions themselves but managing the dynamic dependency graph so that it can be invalidated.

Meanwhile, most of what subscriptions are used for is data that will never update. At least in our apps. It is a pure loss.

The use case is when you're connecting to third party systems that aren't as easily connected to the top level data tree.
## Proposal

``` js
this.forceDeepUpdate();
```

Same use case as `forceUpdate`, if you are reading from global mutable state for some reason, you can use this to by-pass `shouldComponentUpdate` in an entire subtree. Basically rerender everything. When combined with Fiber this can be a low-priority update so it's not so bad for things that change a lot of things.

A good example would be changing the locale. Regardless if you read a global mutable locale (like AirBnB does) or a context locale (like Yahoo) does, this lets you change it when you need to. Without needing to manage subscriptions for all those cases when you don't need it.

``` js
this.forceDeepUpdateWithScope(scope);
```

``` js
class Foo extends React.Component {
  shouldComponentUpdateForScope(scope) {
    return scope.store === UserStore && scope.id === this.props.userID;
  }
  render() {
    ...
  }
}
```

`forceDeepUpdateWithScope` would traverse the subtree and only start rendering if `shouldComponentUpdateForScope` returns `true` for the arbitrary `scope` argument. This allows for a bit more of a targeted update with some convenience overhead.

Additionally, React would cache the pair of `scope` and `components` that responded. For some number of scopes back. If a new component gets mounted with a `shouldComponentUpdateForScope` we might check it against the cache to see if we need to add it to the cache.

Effectively this creates **lazy subscriptions**.

The use case is something like typing into an input field that then updates some global store which immediately displays in a completely different place on the page. The first character might be a bit slower but still with responsive levels and the subsequent characters are fast to update.
## Caveat

The major downside of this proposal is that it relies on mutation. As we know, React doesn't really like mutation for many more reasons than just `shouldComponentUpdate`.

The effect in Fiber for example, is that any component that gets a higher priority update will start using the new value. Components that rely on mutable state effectively become up-prioritized which is not good. 1) It can temporarily show inconsistent data. 2) The point of making this kind of update lower priority is because it is likely to be large. Larger updates will stall the page if they take the same priority as higher priority updates. Thereby defeating the benefits of Fiber anyway.

I'd like to try to come up with a variant of this API that doesn't rely on mutation.
"
facebook/react,2016-08-30 11:08:45,feature,ReactTestRenderer custom depth rendering,"**Do you want to request a _feature_ or report a _bug_?**
Feature

**What is the current behavior?**

``` jsx
// MyComponent.js
import React from ""react"";
import ThirdPartyComponent from 'third-party-component';

function MyInternalComponent() {
  return <div>test</div>;
}

export default function MyComponent() {
  return <div>
    <MyInternalComponent></MyInternalComponent>
    <ThirdPartyComponent someProp={true}></ThirdPartyComponent>
  </div>;
}

// test.js
import ReactTestRenderer from ""react-test-renderer"";
import React from ""react"";
import MyComponent from ""./MyComponent.js"";

const renderer = ReactTestRenderer.create(<MyComponent/>);

console.log(renderer.toJSON());
```

This renders whole tree of DOM which is actually expected behaviour. The problem is, that I dont want render `ThirdPartyComponent`, only `MyInternalComponent`.  Shallow renderer isnt answer because shallow would not render `MyInternalComponent` at all. Which is problem because it's hard to divide component into smaller, internal chunks.

I have done some work in order to achieve this in #5513. It was fully working patch. It was done as part of ShallowRenderer but now we have TestRenderer. Besides this patch is pretty old so resolving conflicts would be very hard.

**What is the expected behavior?**

I would love to provide ""blacklist"" of components which I don't want to render:

``` js
import ThirdPartyComponent from 'third-party-component';
//...

const renderer = ReactTestRenderer.create(
    <MyComponent/>, 
    {
        dontRender: [ThirdPartyComponent]
    }
);
```

This would return jsx:

``` js
<div>
    <div>test</div>
    <ThirdPartyComponent someProp={true}></ThirdPartyComponent>
</div>
```

So we can test props returned for `ThirdPartyComponent` and internal logic.

It's combine of full and shallow renderer.

I have some ideas of implementation but i dont want waste my time writing code which won't be marged into master anyway. 

This possibly would allow to resolve https://github.com/airbnb/enzyme/issues/250.
"
facebook/react,2016-08-03 12:08:31,feature,shouldComponentUpdate doesn't work well if component accepts children,"React's shouldComponentUpdate based performance improvements work great for improving the performance of medium-weight components with large numbers of instances. They even work well with event handlers, as you can ignore event handler changes and instead pass a locally bound method that'll access `this.props.on*` on demand. However this all fails apart you start passing react elements to pure components.

``` js
'use strict';
import React, {Component, PropTypes} from 'react';
import ReactDOM from 'react-dom';
import shallowEqual from 'recompose/shallowEqual';
// shallowEqualExcluding: Fictional function that works like shallowEqual, but ignores changes to a list of props passed as the third argument

class Button extends Component {
    static propTypes = {
        icon: PropTypes.node.isRequired,
        onClick: PropTypes.func
    };

    onClick = (e) => {
        this.props.onClick(e);
    };

    shouldComponentUpdate(nextProps) {
        // @note Doesn't actually work
        return shallowEqualExcluding(this.props, nextProps, ['onClick']);
    }

    render() {
        const {icon} = this.props;

        return (
            <button onClick={this.onClick}>
                {icon}
                {/*React.cloneElement(icon, {ref: (icon) => this.iconRef = icon})*/}
            </button>
        );
    }
}

class Icon extends Component {
    static propTypes = {
        name: PropTypes.string.isRequired,
        color: PropTypes.string
    };

    shouldComponentUpdate(nextProps) {
        return shallowEqual(this.props, nextProps);
    }

    render() {
        const {name, color} = this.props;
        return getSvgIcon(name, color);
    }
}

const nilClick = () => {};
ReactDOM.render(<Button onClick={() => alert('Clicked!')} icon={<Icon name='done'} />, document.querySelector('#container'));
ReactDOM.render(<Button onClick={nilClick} icon={<Icon name='done'} />, document.querySelector('#container')); // 2nd invovation
ReactDOM.render(<Button onClick={nilClick} icon={<Icon name='cancel'} />, document.querySelector('#container')); // 3rd invovation
```

Given this sample; A `<Button />` component that expects an icon to be passed as an `icon` prop and a simple `<Icon />`. Both are pure components and Button is also coded to not re-render when`onClick` is changed. Pretend that Button actually has a heavy `render()` but its props and state don't change frequently.

On the second invocation, Icon should not require any prop change or render and Button should have its `onClick` prop changed but not require a render.
On the third invocation, Icon should require a render while Button itself does not need to render except for the change to Icon.

However in practice Button will always re-render, including during the second invocation when nothing changes.

This is because `<Icon />` will always result in a new instance and will never be the same.

Normally you could work around this within the component itself, without telling users they have to store `<Icon />` in a variable until they think they need to change its props; for functions you could pass a function that will use `this.props.*` itself and for objects you can do a deep comparison if you know the structure of the object. But for react elements, even though `shouldComponentUpdate` allows React to know if the current component has a render dependency on a sub-component, you do not have access to this information so Button cannot tell if Icon requires a render.

In practice this can turn out to be a problem when you're writing some libraries rather than an application. Notably [Material UI](http://www.material-ui.com/) suffers from this problem in production. `EnhancedSwitch`'s `render()` is not light; `EnhancedSwitch` is used by `RadioButton` and `Checkbox`; both use a `checkedIcon` and `uncheckedIcon` React element prop; you can reasonably have 100 checkboxes on one page; even if they were pure, they cannot identify whether an icon requires an update; as a result, a render of the component containing the checkboxes to check a single checkbox will result in the `render()` of all 100 `EnhancedSwitch` instances.

I can think of a few ideas on what type of API could be added to React to solve this issue.
## shouldComponentUpdate helper

The most obvious API would be a top-level React function that given the instance context, old ReactElement, and new ReactElement would return the result of a Component's `shouldComponentUpdate`. Then heavy parent components can use that to implement a `shouldComponentUpdate` that is aware of render dependencies in its children.
(As a bonus, theoretically you could temporarily remember this while you're walking the current tree; then instead of calling `shouldComponentUpdate` multiple times for every (potentially nested) component the result is simply that `shouldComponentUpdate` calls are raised up to the highest level where a component is render-dependent on them)

`React.shouldComponentUpdate(this, this.props.icon, nextProps.icon)`

However I expect the problem we have with this is that `shouldComponentUpdate` is also responsible for state dependent updates and `this` is supposed to be a rendered instance, not a ReactElement instance. While you know `context` from passing the current instance, you do not have a reference to the state from either of the props.
## ref based shouldComponentUpdate helper

The second most obvious API would be a `shouldComponentUpdate` helper that instead uses a ref.

`React.shouldComponentUpdate(this.iconRef, nextProps.icon)`

The downside to this is that to get a ref for a component you didn't create, you inevitably have to use `React.cloneElement`.
## render passthrough

The next idea I had was a render passthrough. A way during the render process for a component to say ""I do not need a render()/update, but these children of mine may"" which would tell React to skip render() and then run `shouldComponentUpdate` on the instances deeper in the tree.

However those components only know if they need updates if you pass them the new props; so a passthrough won't work. We'd instead need a way to tell react that it should not run `render()` but do pass on an update to a specific component instance

`this.renderRef(this.iconRef, nextProps.icon);`

The advantage of this over using `shouldComponentUpdate` is that instead of only allowing medium components wrapping light components to only `render()` when a child requires it; we also allow heavy components to never `render()` unless they themselves require it, while still allowing them to permit their light children to update.
# partial renders

That `shouldComponentUpdate` based `renderRef` only applying updates to a component child feels somewhat awkward and forced though. So a more robust idea might be a partial render lifecycle that optionally runs when `shouldComponentUpdate => false` and can call for the render of a sub-tree that belongs to the current component.

``` js
class HeavyComponent extends Component {
    shouldComponentUpdate(nextProps) {
        // Ignore icon and children
        return nextProps.text !== this.props.text;
    }

    render() {
        const {text, icon, children} = this.props;

        text = doSomethingAbsurdlyCpuIntensiveAndHardToFactorOutOfThisComponent(text);

        return (
            <div>
                <h2>
                    {React.cloneElement(icon, {ref: (icon) => this.iconRef = icon})}
                    {text}
                </h2>
                <Wrapper ref='subtree'>
                    {children}
                </Wrapper>
        );
    }

    componentSkippedRender(nextProps/*, nextState*/) {
        this.subRender(this.iconRef, React.cloneElement(icon, {ref: (icon) => this.iconRef = icon}));

        this.subRender(
            this.refs.subtree,
            <Wrapper ref='subtree'>
                {children}
            </Wrapper>
        );
    }
}
```

Though `this.subRender` probably has potential for conflicts, so I expect the most react-line way to name that would be something like `React.renderSubtreeIntoComponent(parentComponent, nextElement, component)` which would be invoked using `React.renderSubtreeIntoComponent(this, /* subtree */, this.refs.subtree);`.

The `<Wrapper>` I used would be a really light component that probably would just render its children. It's there because `React.renderSubtreeIntoComponent` should probably not accept dom refs; this should be part of React lifecycle/walker, not part of client side browser only react-dom like `ReactDOM.unstable_renderSubtreeIntoContainer`.
"
facebook/react,2016-07-07 18:21:01,feature,Is there a way to let users know which invalid type was returned?,"This is the error message in question: 

```
LabelButton(...): A valid React element (or null) must be returned. 
You may have returned undefined, an array or some other invalid object.
```

Not very helpful. Is it technically possible to _show_ what was returned?
"
facebook/react,2016-06-27 12:36:08,feature,Clean up top-level event listeners after unmounting all roots,"**Do you want to request a _feature_ or report a _bug_?**
Bug - maybe intended behaviour.

**What is the current behavior?**

_Background_
I have an app that needs to be embedded by other apps (other customers). The idea being ""our"" react app has its javascript loaded in an iframe, but the ""main"" window hosts dom elements from the customers and our react app. That bit works fine. As time goes on ""our"" react UI is no longer needed, and then react root is removed, and the iframe destroyed. These apps are often long lived so there will be times when the react app needs to appear again, and the iframe is recreated and everything reloaded. This can and will happen many times.

_Goal_
We would like to NOT keep the iframe around when its not actually needed, but rather re-create just in time when it is needed. This app is used by customers and they would like to embed our ""react"" app, without interference with their ""app"" and all its javascript, which is why we are doing the iframe thing.

_Problem_
It is evident by watching the chrome dev tools ""timeline"" memory graph that memory always increases each time a new iframe is created and the react UI is init'd. Unmounting and destroying the iframe, never causes the memory to drop to ""near"" original before load value. Repeating this process multiple times slowly show an increase memory.

This also causes a more immediate problem, in that react is throwing exceptions on every event (click, type etc) because the window of the iframe is now null.

_Proof: First symptom - Event exceptions (only happens in my app)_
These exceptions only happen in my (cant share) app, i cant repo them, but parts of this apply to all react apps. Please read thru - it will all make sense when you get to the end and if you examine my poc.

Destroying the Iframe, leaves React and its event dispatching system in memory. I have a  mixture of x-tag, webcomponents which are used to ""create"" the iframe and load the react app. After the custom element is used (lets call it <EMBED-REACT>), the console starts showing exceptions all within react code. This is a side effect of the react dispatchEvent still being active and trying to do stuff.

``` javascript
Uncaught TypeError: Cannot read property 'nodeName' of null
shouldUseChangeEvent @ VM1068_embeddedApp.js:14296
extractEvents @ VM1068_embeddedApp.js:14536
extractEvents @ VM1068_embeddedApp.js:13000
handleTopLevel @ VM1068_embeddedApp.js:19816
handleTopLevelImpl @ VM1068_embeddedApp.js:23870
perform @ VM1068_embeddedApp.js:15510
batchedUpdates @ VM1068_embeddedApp.js:23787
batchedUpdates @ VM1068_embeddedApp.js:14673
dispatchEvent @ VM1068_embeddedApp.js:23946
```

I know about `ReactEventListener.dispatchEvent`(snip below) where i can disable react( i havent actually tried) to avoid the exceptions, but that would leave the memory leak.

https://github.com/facebook/react/blob/master/src/renderers/dom/client/ReactEventListener.js#158

``` javascript
 dispatchEvent: function(topLevelType, nativeEvent) {
    if (!ReactEventListener._enabled) {
      return;
    }
```

Its rather easy to prove that react remains in memory, simply goto the compiled app, find the `React dispatchEvent` and insert a console.log and watch as it continues to ""print"" stuff after unmounting the last component, even though there are no listeners. In my case the exception is caused because all `extractEvents` eventually default to ""window"" as the ""target"".

There are multiple copies of the same basic idea in various react functions, where it tries to get a target that it assumes will never be null. If one doesnt load react in an iframe, then window is always defined.

``` javascript
var targetNode = targetInst ?
      ReactDOMComponentTree.getNodeFromInstance(targetInst) : window;
```

Later the `shouldUseChangeEvent` tries to read the nodeName of the now ""undefined"" window, because its iframe has been destroyed, but that now results in an exception (null pointer etc).

https://github.com/facebook/react/blob/045f1a791c6e17253e9d927ffca70ae5d00b4fe5/src/renderers/dom/client/eventPlugins/ChangeEventPlugin.js#L72 ...

``` javascript
function shouldUseChangeEvent(elem) {
  var nodeName = elem.nodeName && elem.nodeName.toLowerCase();
  return nodeName === 'select' || nodeName === 'input' && elem.type === 'file';
}
```

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem via https://jsfiddle.net or similar (template: https://jsfiddle.net/reactjs/69z2wepo/).**

**What is the expected behavior?**
There are probably two possible solutions, that work in tandem.

1) Firstly React should provide an API that will remove all its global event listeners. Naturally it could complain if there are any active components that remain mounted. This API may be internal/private (not public), if #2 was implemented. It might be called something like `React.shutdownAll` Because everything is gone, the next React render would setup all its globals again.

2) React should dispose of all its global event handlers when the last or ""root"" component is unmounted. This would call the _new api_ mentioned in 1. 

Either option solves my problem, where i wish to either let react shutdown gracefully. With this in mind i could.
- unmount iframe powered react ui component.
- call React.disposeGlobals (mentioned above). If unmounting auto calls an internal `React.shutdownAll` then this step is skipped.
- destroy iframe.

_Proof #2_
Goto your compiled out, locate the `dispatchEvent` and add a console.log, notice even after the last / root container is unmounted stuff will continue to be printed because the event listeners are still active.

I did a very quick scan of the abstraction around adding listeners, and i couldnt see the remove function being stored and then called to cleanup.

_Proof #3_
Look at my last section below where i have a proof of concept form of the popular todomvc react example.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
React 15.0.2
React-Dom 15.0.2
React-redux 4.4.5 (might be useful to know)

**Reproducable use case**

Sorry i tried but decided that using the facebook jsfiddle wasnt really a smart thing for the following reasons.
- the compile the ""jsx"" content means loading babel etc to compile (babel, jsfiddle etc too many moving parts)
- its ""hard"" to get the ""root component"" that is inserted into the ""output"" box and 
- its even just too ""hard"" to put the jsx compiled output into somewhere for the iframe src= to ""load"".

I have forked the popular todomvc app and added a few minor edits to recreate, reload, render+unmount x100, destroy everything about the app, and try again in a loop separated by a sleep.
- https://todomvc.com (todomvc main site)
- https://github.com/tastejs/todomvc (todomvc github)
- https://github.com/mP1/todomvc/pull/2 (my fork - with comments and snapshots of chrome dev tools timeline memory graph)

Hopefully we can trust the todomvc guys are doing the right thing, no dumb memory leaks. If you examine it should be obvious the only thing im adding is support for my horrible create app, run app, render+unmount many times, render, unmount, sleep a bit and then loop again until counter exhausted.

Sorry if this is boring but as a convenience i will list the basic instructions to ""run"" the react version of my branch on your local machines...
1. clone https://github.com/tastejs/todomvc.git
2. in the root, run ""gulp"", to compile everything.
3. run something like ""python -m SimpleHTTPServer""
   4A. navigate to http://localhost:8000/examples/react/index.html 
   4B. navigate to http://localhost:8000/examples/react/index3.html
   // /examples/react corresponds to the dist/examples/react directory that gulp built into.

My poc supports 3 concepts.
- re-run todomvc over and over again in ""same"" window.
- create iframe, load todomvc js in the iframe but render to outer window, unmount, destroy iframe, try 20x
- create custom element, webcontainer creates iframe and load todomvc js in the iframe but render to outer window, unmount, destroy custom element, try 20x

If you look at my p/r against todomvc you will see many helpful pictures with memory leak graphs from chrome dev tools for each of the 3 described scenarios and some commentary.
"
facebook/react,2016-06-22 16:04:08,feature,Expose React build mode/flags,"@kittens has expressed concern that people will forget to set the NODE_ENV when building their React application, which will result in babel producing bloated builds, due to our new dev-mode transforms.  The `__source` and `__self` should never be set in production, and having them set on every element would introduce substantial bloat that you wouldn't want in a production environment.  We probably want to be able to warn when this happens.

In this case, I think we might want to expose `React.mode = __DEV__` or something, such that the transform could add runtime checks to verify that React is in dev mode, and warn if not.  I know we're thinking about switching to real build flags for the various features, and maybe we want to expose all those individual flags.

Anyway, opening the issue so we have a place to discuss and track.
"
facebook/react,2016-06-14 16:28:53,feature,Improve error messages for invalid states,"I think we should create a test suite that throws errors in different lifecycle methods, and make sure we have relatively sensible invariants as early as possible, preferably with component names.
#6990 is an example of this, but we’ll keep regressing until we actually test for something like this explicitly.

cc @jingc @yungsters @facebook/react-core 
"
facebook/react,2016-05-27 23:23:01,feature,Provide an opt-in way to easily manage `this` in event handlers,"There's no shortage of places in React where a dev will write something like

```
onClick={() => this.setBooksSubjects()}
```

or alternatively 

```
onClick={this.setBooksSubjects.bind(this)}
```

It's not ideal to re-create these functions on each render, so the alternative would be some form of auto-binding in the class's constructor, all of which re-create these functions once per instance, and require boilerplate. 

I'd love to see the React team add some way of opting in to having a handler `call`ed with the current component set as this.  By ""current component"" I mean the component whose `render` created the element.  I don't know what it should be called, but, for example, if it were called ""ownClick"" it would look like this

```
   <button ownClick={this.foo}>Click me</button>
```

And so when that button is clicked, `foo` would be called, with the object that owns the `render` method which rendered the button set as `this`.
"
facebook/react,2016-05-11 12:37:07,feature,Warn on inline style update with a bad value,"If set an inline style attribute for a component, such as `backgroundColor: 'yellow'`, and then update the state with a bad value to make the inline style like this `backgroundColor: 'non-exist-color'`. This currently takes no effect on the component, and the backgroundColor will remain yellow. (live example: https://jsfiddle.net/d6me6fca/ )

I suppose this is not the correct behavior, the old value should be override by new value, even the value is non-standard, so it can fallback to use the parent style just like plain HTML. If leave the previous style as is, the behavior of component will lose connection with component state, the style will become chaotic and unpredictable.
"
facebook/react,2016-05-06 20:34:52,feature,<datalist> support,"Not a _ton_ of browser support for this right now, but it appears to be on the horizon for Webkit. 
https://bugs.webkit.org/show_bug.cgi?id=98934

http://caniuse.com/#search=datalist

Right now, I'm not getting any DOM events fired from it in Chrome. Wonder if SyntheticEvent could prollyfill. 
https://facebook.github.io/react/docs/events.html#form-events
"
facebook/react,2016-04-26 17:00:11,feature,Have React ignore a specific DOM element,"As per my chat [here](https://twitter.com/nickdima/status/723904527083147264) with @gaearon I'm filing an issue to discuss this further.

I would like to avoid a specific element that I rendered on the server from beeing further updated by react once it reaches the client.
One specific use case is rendering ad server tags that are kind of a pain in the ars, using things like `document.write`, etc. I render them using `dangerouslySetInnerHTML` but sometimes when React is doing the reconciliation client side they get re-render so they stop executing. Now I managed to track down some of these cases by fixing render differences between server and client which would trigger DOM patching but it still seems to happen.
Any advice?
"
facebook/react,2016-04-21 00:25:26,feature,Add comments/attribute indicating which component was rendered,"As per the discussion today...

Sometimes you are developing on a platform that doesn't have devtools (safari, etc).  The problem is that you are looking at a whole pile of markup, and can't tell which components rendered it.  Without devtools, the output markup is really hard to navigate.  It would be cool if we had comment nodes (or a `data-reactcomponent` attribute) that helps users navigate the output.

These nodes would be rendered only in dev mode or with some flag turned on or something.
"
facebook/react,2016-04-09 10:59:28,feature,Allow specifying multiple fallback values for inline styles (e.g. for vendor prefixing with SSR),"I've been using the ""string"" hack to override CSS values in React components.

For example, if you want to have `display` with different values, you do

```
styleObj.display = '-webkit-box;display: -moz-box;display: -ms-flexbox;display: -webkit-flex;display: flex';
```

I have an npm module for poly-filling my styles in my React components.
https://www.npmjs.com/package/poly-style

All of that worked perfectly in v0.14. No warnings no nothing.
Updated to v15.0 today, and everything is breaking.
a) Normally there are deprecation warnings. I didn't notice any warnings on that change.
b) in the changelog I cannot see anything related to that, to understand what changed.

Am I missing something?
"
facebook/react,2016-04-05 12:26:32,feature,Add support for CSS variables in style attributes,"CSS variables is now supported in Chromium, which we use for rendering. They enable us to write cleaner, more flexible code. Sadly, I cannot seem to use them in React without resorting to various tricks. Ideally, I would like to be able to use them like `<div style={{""--color"": ""hotpink""}} />`, which would make the variable available inside the scope of the div.

I am able to add them using the following syntax `<div style={{[""--color""]: ""hotpink""}} />`, but then they aren't updated if I try assigning a new value—which ruins much of the point of using a variable.

I am able to add and remove them using ReactDOM and `ReactDOM.findDOMNode(this).style.setProperty(""--color"", ""hotpink"")`, but that gets it out of sync with the DOM updates, in addition to not being pretty.

If there are any questions on the usefulness of CSS variables I'll be more than happy to explain.
"
facebook/react,2016-03-14 22:23:07,feature,Support DOM nodes as children,"It would be nice to be able to do the equivalent of `<div>{document.createElement('div')}</div>`. It seems entirely doable now with our new fancy renderer I think? Obviously it wouldn't be supported for SSR though so you would have to provide your own fallback if necessary.
"
facebook/react,2022-04-22 07:15:07,question,Question about React.Fragment and dangerouslySetInnerHTML,"
React version: 17.0.0

React.Fragment Why not  dangerouslySetInnerHTML property
"
facebook/react,2022-03-08 15:06:47,question,"Bug: Data is losing during page refresh in Reactjs-Redux; Tried using 'redux-persist' and localstorage , but not working.","In our project,forms(login,signup,logout,etc..) were built in django and through this we are getting the authorization details and this was stored as redux-data and was used in the rest of the application which is built in react.There was no refresh issue during that time.evenif the store was getting disapper but we are getting it back.Now,we shifted all that we done in Django into react and used the same redux storage method in login,but we are facing the data losage during refresh,store is not getting restore and we are having 403 status for 2 apis for getting the user details.This was not happening in former case.
We used redux-persist package to avoid this data losage.. And also tried using localstorage persisting method(loadState(),saveState()).But,still facing the issue.

store.js
```
import { createStore, applyMiddleware, compose } from 'redux'
import thunk from 'redux-thunk'
import rootReducer from './reducers'
import { persistStore, persistReducer } from 'redux-persist'
import storage from 'redux-persist/lib/storage';
 
const persistConfig = {
key: ""root"",
storage,
}
const composeEnhancers = window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ || compose
const persistedReducer = persistReducer(persistConfig,rootReducer)
const store = createStore(persistedReducer,composeEnhancers(applyMiddleware(thunk)))
const Persistor = persistStore(store);
 
export default (store)
export { Persistor }
```

action.js:
```
import axios from 'axios'
import { SET_PROFILE, SET_FEATURE_TOGGLES } from './actionTypes'
import { client_request_data } from '../config';

const redirectToLogin = () => {
  delete axios.defaults.headers.common.Authorization
  if (window.location.href.indexOf('/accounts/') !== -1) {
    window.location.href = '/accounts/login'
  }
}

export const fetchUserProfile = () => dispatch => {
  axios
    .post(`/accounts/user_profile/`,{
      client_request_data: client_request_data
    })
    .then(resp =>
      dispatch({
        type: SET_PROFILE,
        payload: resp.data,
      }),
    )
    .catch(e => {
      // TODO figure out what do do here
      if (e.response?.status === 403) {
        redirectToLogin()
      }
    })
}

export const fetchFeatureToggles = () => dispatch => {
  axios
    .post(`/api/study/v1/feature_toggle/`,{
      client_request_data: client_request_data
    })
    .then(resp =>
      dispatch({
        type: SET_FEATURE_TOGGLES,
        payload: resp.data,
      }),
    )
    .catch(e => {
      // TODO figure out what do do here
      if (e.response?.status === 403) {
        redirectToLogin()
      }
    })
}
```
Reducers:1.featureToggle.js
```
import { SET_FEATURE_TOGGLES } from '../actionTypes'

const intialstate = {}

export default (state = intialstate, action) => {
  switch (action.type) {
    case SET_FEATURE_TOGGLES:
      return action.payload
    default:
      return state
  }
}
```
2.userprofile.js
```
import { SET_PROFILE } from '../actionTypes'

const intialstate = {}

export default (state = {}, action) => {
  switch (action.type) {
    case SET_PROFILE:
      return action.payload
    default:
      return state
  }
}

```
App.js:
```
import React, { useEffect, Suspense } from 'react'
import { connect } from 'react-redux'
import CssBaseline from '@material-ui/core/CssBaseline'
import { ThemeProvider } from '@material-ui/styles'
import MuiThemeProvider from '@material-ui/core/styles/MuiThemeProvider'
import { Provider } from 'react-redux'
import { BrowserRouter, Switch, Route } from 'react-router-dom'
import theme from './theme/muiTheme'
import './i18n'
import Home from './screens/Home'
import * as actions from './redux/actions'
import Userservice from './services/UserService'
import { BASE_URL} from './config'
import Login from './Login'
import Signup from './Signup'
import Logout from './Logout'
import ResetPassword from './ResetPassword'
import ResetSuccess from './ResetSuccess'
import store from './redux/store'

const App = props => {
  const {
    userProfile,
    featureToggles,
    fetchUserProfile,
    fetchFeatureToggles,
  } = props
  useEffect(() => {
    fetchUserProfile()
    fetchFeatureToggles()
  })
  return (
        <Suspense fallback={<span></span>}>
          <BrowserRouter>
            <Switch>
            <Route
                exact
                path=""/""
                render={() => {
                    return (
                      userProfile === null || featureToggles === null ? <Login/> : <Home /> 
                    )
                }}
              />
             
            </Switch>
          </BrowserRouter>
        </Suspense>
  )
}

const mapStateToProps = state => ({
  userProfile: state.userProfile,
  featureToggles: state.featureToggles,
})

export default connect(mapStateToProps, actions)(App)
```
index.js:
```
import promiseFinally from 'promise.prototype.finally'
import React, {Suspense} from 'react'
import ReactDOM from 'react-dom'
import './index.css'
import CssBaseline from '@material-ui/core/CssBaseline'
import { ThemeProvider } from '@material-ui/styles'
import MuiThemeProvider from '@material-ui/core/styles/MuiThemeProvider'
import { Provider } from 'react-redux'
import * as serviceWorker from './serviceWorker'
import App from './App'
import theme from './theme/muiTheme'
import store,{Persistor} from './redux/store'
import './i18n';
import Home from './screens/Home'
import Login from './Login'
import Signup from './Signup'
import Logout from './Logout'
import { PersistGate } from 'redux-persist/integration/react'
promiseFinally.shim()

ReactDOM.render(
  <Provider store={store}>
    <PersistGate Loading={null} persistor={Persistor}>
    <MuiThemeProvider theme={theme}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <Suspense>
        <App />
        </Suspense>
      </ThemeProvider>
    </MuiThemeProvider>
    </PersistGate>
  </Provider>,
  document.getElementById('root'),
)
serviceWorker.unregister()

```

Also tried with localstorage: localstorage.js(in redux)

```
export const loadState = () => {
    try {
      const serializedState = localStorage.getItem(""state"");
      if (serializedState === null) {
        return undefined;
      }
      return JSON.parse(serializedState);
    } catch (err) {
      return undefined;
    }
  };
  
  export const saveState = (state) => {
    try {
      const serializesState = JSON.stringify(state);
      localStorage.setItem(""state"", serializesState);
    } catch (err) {
      console.log(err);
    }
  };
```
Corresponding store.js:
```
import { createStore, applyMiddleware, compose } from 'redux'
import thunk from 'redux-thunk'
import rootReducer from './reducers'
import { persistStore,persistReducer} from 'redux-persist'
import storage from 'redux-persist/lib/storage';
import { fetchFeatureToggles } from './actions';
import { loadState,saveState } from './localStorage';
import { throttle } from 'lodash';

const persistConfig = {
key: ""root"",
storage,
}
const composeEnhancers = window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ || compose
const persistedState = loadState();
const persistedReducer = persistReducer(persistConfig,rootReducer)
const store = createStore(persistedReducer,persistedState,composeEnhancers(applyMiddleware(thunk)))

store.subscribe(throttle(() => {
    saveState(store.getState());
  },1000));
  
  const Persistor = persistStore(store);
  export default store

export {Persistor} 

```"
facebook/react,2021-07-16 04:26:13,question,react developer tools ,I successfully installed the extensions but i am not able to see the the news tabs ( components and react
facebook/react,2021-06-08 19:41:48,question,Question: startTransition behavior,"I'm very sorry that I'm using the issue tracker to ask this question, but I think others might ask the same question after reading https://github.com/reactwg/react-18/discussions/41 (I don't have commenting rights).

```js
function handleInputChange(e) {
  const input = e.target.value

  setInputValue(input)

  startTransition(() => {
    setSearchQuery(input)
  });
}
```

What happens if the user types ""ab""? i.e.:

```js
// pseudocode representing the first event handler triggered by keystroke ""a""
setInputValue(""a"")
startTransition(() => setSearchQuery(""a""))

// pseudocode representing the second event handler triggered by keystroke ""b""
setInputValue(""ab"")
startTransition(() => setSearchQuery(""ab""))
```

From my understanding `setInputValue(""a"")` and `setInputValue(""ab"")` will batch generating a single rerender, the callback `() => setSearchQuery(""a"")` passed to the first `startTransition` will be cancelled, and only the second callback `() => setSearchQuery(""ab"")` passed to the second `startTransition` will be executed. i.e.:

```js
// pseudocode representing the final logic after keystrokes ""a"" and ""b""

setInputValue(""a"") // will batch with `setInputValue(""ab"")`
startTransition(() => setSearchQuery(""a"")) // noop, this callback will be cancelled

setInputValue(""ab"")
startTransition(() => setSearchQuery(""ab""))
```

Am I correct?

I think this question is important because if the first callback passed to `startTransition` really gets cancelled and I try to do more work inside it, I should have in mind that the additional work will not happen.

cc @gaearon @acdlite "
facebook/react,2021-05-19 03:45:49,question,Experimental createRoot method not available in React 17,"I am using react and react-dom v17.0.2 and I was trying to use the unstable_createRoot method to render my app but looks like that method is not even present in react v17.0.2. 

Can someone comment if this is expected or not.

Thanks,
Arpit"
facebook/react,2021-04-05 13:39:08,question,"Bug: strict mode, initial state changes, and useMemo (with dependency) doesn't seem to be recomputed","<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version: 17.0.2

I ran in to this interesting dynamic that I cannot explain today.

1) The code sets some initial state, which is a random number, and logs this initial value. 
2) It converts the number to a string using `useMemo`, which logs the number it is converting, and is dependant on that number (not the string). And 
3) when the component is mounted, I force a re-render by changing a boolean state once.

The result is that the initial value of the number is changed (and the log is output) so you see the number being set twice to two different values - this only happens in `StrictMode`. It is surprising. Is it expected?

You also see the `useMemo` being computed ONCE - only the first time. So seemingly it does not recompute a new string value.

BUT, the output in the HTML is the correct and shows the stringified value of the _second_ number. 

So what is happening here? Is the console log swallowed? Is `useMemo` behaving correctly, and more importantly, is the `initialValue` of `useState` supposed to change like that?

## Steps To Reproduce

```typescript
export default function App() {
  const [rand] = useState(Math.random());
  const [, setState] = useState(false);

  console.log(`Number: ${rand}`);

  useEffect(() => {
    setState(true);
  }, []);

  const text = useMemo(() => {
    console.log(`Computing text from ${rand}`);
    return rand.toString();
  }, [rand]);

  return (
    <div className=""App"">
      <h1>Rand: {rand}</h1>
      <h1>Text: {text}</h1>
    </div>
  );
}
```

And wrap your app in `StrictMode`

## Link to code example:

https://codesandbox.io/s/strict-mode-random-bug-ml3gv

## The current behavior

initial state computed twice.
usememo seemingly not run twice

## The expected behavior

Initial state computed once?
Or usememo runs twice?
"
facebook/react,2021-03-29 06:44:29,question,Question:  is there any way to retrieve React Devtool performance data?,"Hi guys, I want to get react devtool performance/profiler results, probably a JSON data and send to our local server, I read through the react-devtools-core but unfortunately do to get any clue how to do this ?"
facebook/react,2021-03-03 15:25:10,question,Question about getting the latest state value in the concurrent mode,"<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

React version: 17.0.1

## Steps To Reproduce

1. Enable strict mode for checking for possible issues in the future concurrent mode
2. create the below component and run the code
```
import { useCallback, useState } from ""react"";

const Example = ({ onIncrement }) => {
  const [count, setCount] = useState(0);

  const incrementHandler = useCallback(() => {
    onIncrement(count, count + 1);  // Is count guaranteed to be the latest state here due to including count in the useCallback dependency array?
    setCount((count) => count + 1);
  }, [count, onIncrement]);

  return (
    <>
      <span>{count}</span>
      <button onClick={incrementHandler}>increment</button>
    </>
  );
};

const Parent = () => (
  <Example
    onIncrement={(currentCount, incrementedCount) =>
      alert(
        `count before incrementing: ${currentCount}, after increment: ${incrementedCount}`
      )
    }
  />
);

export default Parent;
```

<!--
  Your bug will get fixed much faster if we can run your code and it doesn't
  have dependencies other than React. Issues without reproduction steps or
  code examples may be immediately closed as not actionable.
-->

<!-- Link to code example: -->

<!--
  Please provide a CodeSandbox (https://codesandbox.io/s/new), a link to a
  repository on GitHub, or provide a minimal code example that reproduces the
  problem. You may provide a screenshot of the application if you think it is
  relevant to your bug report. Here are some tips for providing a minimal
  example: https://stackoverflow.com/help/mcve.
-->

## The current behavior
In this simple example everything seems to be fine but in a more complicated situation full of event handlers that change the count or async callbacks that may change the count( like data fetching callbacks) the count value is not guaranteed to be the latest state and if I change the `incrementHandler` function like below:
```
const incrementHandler = useCallback(() => {
    setCount((count) => {
      onIncrement(count, count + 1);  
      return count + 1
    });
  }, [count, onIncrement]);
```
then the `onIncrement` will run twice in development while in strict mode and may run twice in production in concurrent mode according to documentation.
and If you suggest running the `onIncrement` in `useEffect` callback with `count` and `onIncrement` in effect's dependencies array how can I know that the `onClick` event of the increment button has caused the effect and not another event for example decrement or anything else.

you may say by setting another state that shows what is responsible for the effect, then I may need the previous state which unlike this example may be impossible to recalculate.

you may suggest using a ref for storing the previous state (count) then I will end up with **one extra state or ref for storing what is responsible for the effect to run**, **one extra ref for storing the previous state**, and **a useEffect hook to run the onIncrement click event handler**

## The expected behavior
Providing a second callback argument to `setState`  like in class Components that will run after this state update so we can save the current and next state and use it in the callback like below:
```
const incrementHandler = useCallback(() => {
    let prevCount, nextCount;
    setCount(
      (count) => {
        prevCount = count;
        nextCount = count + 1;
        return nextCount;
      },
      () => onIncrement(prevCount, nextCount)
    );
  }, [onIncrement]);
``` 
In my humble opinion, this doesn't collide with the async nature of `setCount` and can be implemented. 

unlike below`getState` proposals that if it will be asynchronous it may not return the desired state. and if it will be synchronous it will not return the latest state too because `setState` is not executed yet.

**wrong solution:**
```
const [count, setCount, getCount] = useState(0);

  const incrementHandler = useCallback(() => {
    setCount((count) => count + 1);
    const currentCount = getCount();
    const nextCount = currentCount + 1;
    onIncrement(currentCount, nextCount)
  }, [onIncrement]);
```
or providing a third array to `useCallback` for accessing the latest state can not be implemented due to the same problem with `getState` and async nature of setState.

Please tell me if I'm missing something or I've misunderstood things.

If not, please tell me if there is a simple solution for this scenario or similar ones, or tell me the best practices for running a callback or event handler with the latest state.

Thank you!"
facebook/react,2021-02-20 01:05:40,question,Bug: It seems that the default value in functional React component gets updated after render.,"<!--
  Please provide a clear and concise description of what the bug is. Include
  screenshots if needed. Please test using the latest version of the relevant
  React packages to make sure your issue has not already been fixed.
-->

It seems that the default value in functional React component gets updated after render.

React version: 17.0.1

## Steps To Reproduce

I created a question on StackOverflow: https://stackoverflow.com/questions/66286856/why-default-value-in-functional-react-component-gets-updated-after-render, but also repeat it here:


```
const MyComponent = () => {

  // Initialise data with a random value:
  const [data, setData] = React.useState(
    () => {
      const data = _.sampleSize(_.range(5), 3)
      // Print data on initialisation:
      console.log('init data in default:', data)
      return data
    }
  )

  React.useEffect(() => {
    // Print data after the component is rendered:
    console.log('init data after render:', data)
  })

  return (
    <div>{data}</div>
  );
};
```

The output in console is:

```
[Log] init data in default: – [0, 3, 1] (3)
[Log] init data after render: – [2, 1, 3] (3)
```

My understanding is that before the component is rendered, the function under `useState` is called. The value returned by the function is assigned to `data`, and the `data` values is used to render the component on the screen. The function under `useState` is called only once and we never call `setData`, so the value should be the same. Maybe I miss something?

<!--
  Your bug will get fixed much faster if we can run your code and it doesn't
  have dependencies other than React. Issues without reproduction steps or
  code examples may be immediately closed as not actionable.
-->

Link to code example:

<!--
  Please provide a CodeSandbox (https://codesandbox.io/s/new), a link to a
  repository on GitHub, or provide a minimal code example that reproduces the
  problem. You may provide a screenshot of the application if you think it is
  relevant to your bug report. Here are some tips for providing a minimal
  example: https://stackoverflow.com/help/mcve.
-->

https://codesandbox.io/s/jovial-glade-9jm75?file=/src/App.js

## The current behavior

The output in console before and after render is different.

## The expected behavior

The output in console before and after render should be the same."
facebook/react,2021-01-22 14:56:51,question,Dev tools Chrome Extension only works properly in Incognito window,"Hi folks,
At some point w/in the last 5 months or so, the dev tools Chrome extension stopped working properly for me in **non**-incognito Chrome windows.  It's a bit hard to explain, but i'll try: when i use the extension, react components show up, but they are basically just high level wrapper components that we use in our app.  For example, I cannot inspect a button component, a container component, an input component, etc, in the UI.

This issue disappears in incognito mode, however, and i can use the extension just fine.

Chrome version: 87.0.4280.141
Extension version: 4.10.1
React version: 16.13.1

I've been unable to find anyone else with this issue.  Please let me know if there is other information I can provide you with.  Thank you."
facebook/react,2020-10-27 23:40:19,question,Question: CM mode and useEffect cleanups,"Since CM mode now runs useEffects' cleanups async. Are we still guaranteed that they'll resolve in order? By that I mean, if a component get's cleanup, re-rendered and cleaned up again. That the first cleanup will resolve, before the second?

ComponentA (1) -> thrown away -> ComponentA (2) -> thrown away. Will that (2) effectively ""await"" on the (1) to cleanup first."
facebook/react,2020-09-10 07:13:00,question,Some questions about lanes.,"First of all, thank you for reading and patience.

I've been studying the principle of react lanes recently, and its implementation is interesting to me, but I still don't know what the specific problems it solves.

> This constraint was designed before Suspense was a thing, and it made some sense in that world. When all your work is CPU bound, there's not much reason to work on tasks in any order other than by their priority. But when you introduce tasks that are IO-bound (i.e. Suspense), you can have a scenario where a higher priority IO-bound task blocks a lower-priority CPU-bound task from completing.

From the explanation of @acdlite , it seems to solve the blocking problem of IO operation on low priority tasks.

But I couldn't figure out what asynchronous IO blocked？

```js
<A/>
<Suspense>
  <B/>
</Susepsne>
<C/>
```
Based on the above example, before lanes, where is blocked, and where is the problem solved after lanes.

Or do you have a better demo to explain?

For developers, the new technology related information is too little, binary is also very abstract, thank you again for your patience.
"
facebook/react,2020-08-03 14:16:34,question,Why does React warn about multiple renderers using the same context provider?,"I am currently developing a web app that uses both [react-pixi](https://github.com/inlet/react-pixi) and [react-babylonjs](https://github.com/brianzinn/react-babylonjs). Both of these libraries use `react-reconciler` and have a custom renderer. I also use redux in my project, so they share the same Context in the two libraries. 

It displays a warning on Console after every redux state updating, but everything works well, both renderers can trigger an update.

I want to know if there is any risk in doing this, or is this just a false warning?

React version: 16.13.1

## Steps To Reproduce

1. Using multiple react renderers
2. Using the same context provider between that react renderers

Link to code example: https://codesandbox.io/s/multiple-reconciler-using-same-context-v8kq1?file=/src/App.js

## The current behavior

It will throw a warning message after every state updating:

> Warning: Detected multiple renderers concurrently rendering the same context provider. This is currently unsupported. 

But everything works well, both renderers can trigger an update.

## The expected behavior

Don't show any warning."
facebook/react,2020-07-17 19:00:22,question,Showing an Array in string Format in UI,"In JS, Array rendered with ',' in between each element
 e.g. ['Piyush', 'Sinha'] 
// Piyush,Sinha//
but in react Array rendered without ',' in between each element
 e.g. [ 'Piyush', 'Sinha'] 
//PiyushSinha//"
facebook/react,2020-07-08 07:55:22,question,[Micro React Apps] - Need to render another React App into existing React App,"Hi,

I need to render another React App (i.e. App2) into existing React App (i.e. App1) on run time. I have hosted my ""App2"" on a remote server. I read ""asset-manifest.json"" file from it and on runtime I append those .js chunks in our head tag, this overall code I call from my ""App1"" to load my ""App2"" on runtime. 

But I am not able to trigger ""App2"". How should I triggered App2 component inside App1 component?

My application have lot of other internal dependencies, such redux, redux-thunk etc.

 "
facebook/react,2020-06-20 12:13:21,question,devtool Api request : add api for customize renderer inspect element,"I'm wirte a custimse renderer for render element in canvas(like react-pixi), I want intergrate with react dev tool;
I can hightlight element when click element in react dev tool compoent panel use code:
```ts
__REACT_DEVTOOLS_GLOBAL_HOOK__?.reactDevtoolsAgent?._bridge.addListener('highlightNativeElement', (eleInfo: EleInfo) => {
        const { id, rendererID } = eleInfo;
        const renderer = __REACT_DEVTOOLS_GLOBAL_HOOK__?.rendererInterfaces.get(
            rendererID,
        );

        const node_list =
            (renderer.findNativeNodesForFiberID(id) as Sprite[]) || [];

        //... customise render engin hightlight code
    });
```

I want hightlight ele when mouse move in canvas, I can use `__REACT_DEVTOOLS_GLOBAL_HOOK__.rendererInterfaces.get(1).getFiberIDForNative(node)` find node fiber id, I can use `_bridge` send hightlint msg to backend just like the code
https://github.com/facebook/react/blob/6ba25b96df5d4179bf8aba3c3fe1ace3dce28234/packages/react-devtools-shared/src/devtools/views/hooks.js#L311
but I can't get store object and get enugh infomation send to backend.
maybe dev tool can expose proper api for this function"
facebook/react,2020-05-28 19:31:30,question,Selenium integration,"Hello. I'm not sure if this is an issue, but I would like to know a little more about how react developer tools work. 

I want to get reacts props with selenium in order to make easier the debugging of a website. 

I'd be thankful with any kind of help you can give me.

Best regards"
facebook/react,2020-04-24 04:45:53,question,React Hooks will render multiple times after await,"```
const [ html, setHTML ] = useState('');
const [ script, setScript ] = useState('');

const update = (script, html) => {
  setScript(script);
  setHTML(html);
};

update('a', 'b');
```

The above code works fine, React Hooks will render ONCE and combine setScript & setHTML;


```
const [ html, setHTML ] = useState('');
const [ script, setScript ] = useState('');

const update = async (script, html) => {
  await new Promise(resolve => setTimeout(resolve, 10));
  setScript(script);
  setHTML(html);
};

update('a', 'b');
```

The above code doesn't work anymore, React Hooks will render TWICE and it doesn't combine setScript & setHTML.

I can change to the code to:

```
const [ state, setState ] = useState({
  html: '',
  script: ''
});

const update = async (script, html) => {
  await new Promise(resolve => setTimeout(resolve, 10));
  setState({
    script,
    html
  });
};

update('a', 'b');
```

The above code only renders ONCE but it has a new bug: the cursor in the textArea (where script and html go) will move to the end of the textArea instead of staying at where it is."
facebook/react,2020-04-03 13:56:48,question,Extention React non définie sur chrome,"
react Developer Tools 4.6.0
Google chrome Version 80.0.3987.149
L'outil de développement react est inactif sur la console google chrome"
facebook/react,2020-02-18 16:04:52,question,Question: Why not useCallback always return static value without deps?,"```tsx
function useRefCallback<T extends (...args: any) => void>(callback: T) {
  const ref = useRef<T>(callback);
  ref.current = callback;
  return useCallback(function(this: any, ...args: Parameters<T>) {
    return ref.current.apply(this, args);
  } as T, []);
}
```
I think useRefCallback is safe to replace useCallback in any code, and it's better than useCallback because it will never cause recalculation."
facebook/react,2020-02-17 02:21:03,question,Question: How to remove dynamic children from Parent State?,"I'm using react hook `useContext`. I have two identical components (siblings), each that use the same context that is a list.

**Scenario**
1. The first sibling is created, calls `useContext`, and then pushes something into the list. 
2. The second sibling is then created, using the same `useContext`, and then pushes something into the list. 

**Issue**
The second sibling has the current state of list, which has two items, _but the first sibling state is not updated with the second item that was pushed in by the second sibling_

**Expected**
That each component that is using the same `useContext` will be updated amongst all components that use the same context.

Is this a bug or am I misusing this? Any help or guidance is appreciated 🙇 "
facebook/react,2020-02-06 22:24:40,question,Webpack can't find ReactDOM.createRoot,"Hi,

I'm kinda in doubt if this is an error or is just me doing something wrong.

I am trying the new react experimental in a very simple existing app I have. Although I had installed the react experimental versions in my package.json, it seems it doesn't recognize ReactDOM.createRoot.

When I try to run my project I receive the error message from the console:
```
Uncaught TypeError: react_dom__WEBPACK_IMPORTED_MODULE_1___default.a.createRoot is not a function
    at Module../src/client/index.js (main.chunk.js:2437)
    at __webpack_require__ (runtime.bundle.js:786)
    at fn (runtime.bundle.js:151)
    at Object.0 (main.chunk.js:4324)
    at __webpack_require__ (runtime.bundle.js:786)
    at checkDeferredModules (runtime.bundle.js:46)
    at Array.webpackJsonpCallback [as push] (runtime.bundle.js:33)
    at main.chunk.js:1
``` 
This only happens when I try using ``ReactDOM.createRoot``. Using ``ReactDOM.render`` everything works perfectly.

Any idea why this is happening?
```
""dependencies"": {
    ""chalk"": ""^3.0.0"",
    ""compression"": ""^1.7.4"",
    ""express"": ""^4.17.1"",
    ""morgan"": ""^1.9.1"",
    ""uuid"": ""^3.4.0""
  },
  ""devDependencies"": {
    ""@babel/cli"": ""^7.8.4"",
    ""@babel/core"": ""^7.8.4"",
    ""@babel/node"": ""^7.8.4"",
    ""@babel/plugin-proposal-class-properties"": ""^7.7.4"",
    ""@babel/plugin-proposal-decorators"": ""^7.7.4"",
    ""@babel/plugin-proposal-export-namespace-from"": ""^7.7.4"",
    ""@babel/plugin-proposal-function-bind"": ""^7.7.4"",
    ""@babel/plugin-proposal-nullish-coalescing-operator"": ""^7.7.4"",
    ""@babel/plugin-proposal-optional-chaining"": ""^7.7.5"",
    ""@babel/plugin-proposal-pipeline-operator"": ""^7.7.7"",
    ""@babel/plugin-proposal-private-methods"": ""^7.7.4"",
    ""@babel/plugin-proposal-throw-expressions"": ""^7.7.4"",
    ""@babel/plugin-syntax-dynamic-import"": ""^7.7.4"",
    ""@babel/preset-env"": ""^7.8.4"",
    ""@babel/preset-react"": ""^7.7.4"",
    ""@babel/preset-typescript"": ""^7.8.3"",
    ""@hot-loader/react-dom"": ""^16.11.0"",
    ""@testing-library/jest-dom"": ""^5.1.1"",
    ""@testing-library/react"": ""^9.4.0"",
    ""autoprefixer"": ""^9.7.4"",
    ""babel-eslint"": ""^11.0.0-beta.2"",
    ""babel-jest"": ""^25.1.0"",
    ""babel-loader"": ""^8.0.6"",
    ""babel-plugin-dynamic-import-node"": ""^2.3.0"",
    ""babel-plugin-styled-components"": ""^1.10.7"",
    ""case-sensitive-paths-webpack-plugin"": ""^2.3.0"",
    ""circular-dependency-plugin"": ""^5.2.0"",
    ""clean-webpack-plugin"": ""^3.0.0"",
    ""connected-react-router"": ""^6.6.1"",
    ""copy-webpack-plugin"": ""^5.1.1"",
    ""core-js"": ""^3.6.2"",
    ""css-hot-loader"": ""^1.4.4"",
    ""css-loader"": ""^3.4.1"",
    ""deep-freeze"": ""^0.0.1"",
    ""eslint"": ""^6.8.0"",
    ""eslint-loader"": ""^3.0.3"",
    ""eslint-plugin-babel"": ""^5.3.0"",
    ""eslint-plugin-import"": ""^2.20.1"",
    ""eslint-plugin-jsx-a11y"": ""^6.2.3"",
    ""eslint-plugin-ramda"": ""^2.5.1"",
    ""eslint-plugin-react"": ""^7.18.3"",
    ""eslint-plugin-react-hooks"": ""^2.3.0"",
    ""eslint-plugin-redux-saga"": ""^1.1.3"",
    ""eslint-watch"": ""^6.0.1"",
    ""file-loader"": ""^5.0.2"",
    ""hard-source-webpack-plugin"": ""^0.13.1"",
    ""history"": ""^4.10.1"",
    ""html-webpack-plugin"": ""^3.2.0"",
    ""immer"": ""^5.3.4"",
    ""jest"": ""^25.1.0"",
    ""jest-styled-components"": ""^7.0.0"",
    ""lodash"": ""^4.17.15"",
    ""mini-css-extract-plugin"": ""^0.9.0"",
    ""moment"": ""^2.24.0"",
    ""nock"": ""^11.7.1"",
    ""normalizr"": ""^3.5.0"",
    ""npm-run-all"": ""^4.1.5"",
    ""open"": ""^7.0.2"",
    ""optimize-css-assets-webpack-plugin"": ""^5.0.3"",
    ""pm2"": ""^4.2.3"",
    ""postcss-flexbugs-fixes"": ""^4.2.0"",
    ""postcss-loader"": ""^3.0.0"",
    ""prop-types"": ""^15.7.2"",
    ""ramda"": ""^0.27.0"",
    ""react"": ""^0.0.0-experimental-241c4467e"",
    ""react-dom"": ""^0.0.0-experimental-241c4467e"",
    ""react-hooks-testing-library"": ""^0.6.0"",
    ""react-hot-loader"": ""^4.12.19"",
    ""react-is"": ""^16.12.0"",
    ""react-redux"": ""^7.1.3"",
    ""react-router"": ""^5.1.2"",
    ""react-router-dom"": ""^5.1.2"",
    ""react-test-renderer"": ""^16.12.0"",
    ""redux"": ""^4.0.5"",
    ""redux-actions"": ""^2.6.5"",
    ""redux-devtools-extension"": ""^2.13.8"",
    ""redux-logger"": ""^3.0.6"",
    ""redux-saga"": ""^1.1.3"",
    ""redux-saga-test-plan"": ""^4.0.0-rc.3"",
    ""regenerator-runtime"": ""^0.13.3"",
    ""reselect"": ""^4.0.0"",
    ""source-map-loader"": ""^0.2.4"",
    ""style-loader"": ""^1.1.3"",
    ""styled-components"": ""^5.0.1"",
    ""stylelint"": ""^13.0.0"",
    ""stylelint-bare-webpack-plugin"": ""^2.0.0"",
    ""stylelint-config-recommended"": ""^3.0.0"",
    ""stylelint-config-standard"": ""^19.0.0"",
    ""stylelint-config-styled-components"": ""^0.1.1"",
    ""stylelint-custom-processor-loader"": ""^0.6.0"",
    ""stylelint-order"": ""^4.0.0"",
    ""stylelint-processor-styled-components"": ""^1.9.0"",
    ""stylelint-selector-bem-pattern"": ""^2.1.0"",
    ""thread-loader"": ""^2.1.3"",
    ""typescript"": ""^3.7.5"",
    ""url-loader"": ""^3.0.0"",
    ""webpack"": ""^4.41.4"",
    ""webpack-dev-middleware"": ""^3.7.2"",
    ""webpack-hot-middleware"": ""^2.25.0"",
    ""webpack-manifest-plugin"": ""^2.2.0"",
    ""webpack-merge"": ""^4.2.2"",
    ""webpack-pwa-manifest"": ""^4.1.1"",
    ""workbox-webpack-plugin"": ""^5.0.0""
  }
```"
facebook/react,2020-02-04 15:46:04,question,Bug: Nested setState and unstable_batchedUpdates (are they ignored?),"Nested setState and unstable_batchedUpdates (are them ignored?)

React version: 16.12

## Steps To Reproduce
https://codesandbox.io/s/batchedupdates-uselayouteffect-evj8s

open profile after click, you will see 3 commit.

it seems that even if we use unstable_batchedUpdates, nested setStates called on
didUpdate/layouteffect do not get batched.
"
facebook/react,2020-02-03 14:29:36,question,"While using useRef , some data has been updated by context value from reducers, when the context value was updated from some other user event, variable used with useRef also updated, then how to use instance variables in hooks?","const CreateNotificationBase = (props) => {
const [state, dispatch] = useContext(Store);
 const draftData = useRef({});
useEffect(() => {
        if (state.notificationDetails.draftId) {
            draftData.current = state.notificationDetails;
        }
    }, []);
useEffect(() => {
debugger
},[draftData.current])
}

when value in store context changes useEffect of draftData.current also called. Please suggest hwo to resolve."
facebook/react,2020-01-30 02:37:25,question,Question:  Just for my app test. Thanks.,"🚨 This issue tracker is not for questions. 🚨

As it happens, support requests that are created as issues are likely to be closed. We want to make sure you are able to find the help you seek. Please take a look at the following resources.

## Coding Questions

If you have a coding question related to React and React DOM, it might be better suited for Stack Overflow. It's a great place to browse through frequent questions about using React, as well as ask for help with specific questions.

https://stackoverflow.com/questions/tagged/react

## Talk to other React developers

There are many online forums which are a great place for discussion about best practices and application architecture as well as the future of React.

https://reactjs.org/community/support.html#popular-discussion-forums

## Proposals

If you'd like to discuss topics related to the future of React, or would like to propose a new feature or change before sending a pull request, please check out the discussions and proposals repository.

https://github.com/reactjs/rfcs
"
facebook/react,2020-01-19 01:43:43,question,Question: React apollo hooks fails after adding react-native to monorepo,"I am trying to create a React web app and React-native app with monorepo by using yarn workspaces. So I created web and controllers and it works fine. I was able to make graphql queries to my apollo-express server. But, after adding react-native application I see this:
[![enter image description here][1]][1]


  [1]: https://i.stack.imgur.com/KbvYG.png

I am 100% that I am not breaking any react hooks rules because before adding react-native application it was work fine.

Is there any way how can I solve it?

Apollo controller

    import { useQuery } from ""@apollo/react-hooks"";
    import gql from ""graphql-tag"";
    
    export const useHelloQuery = () => useQuery(
         gql`
             {
                 hello
             }
         `
    )


React component:

    function Test() {
         const data = useHelloQuery();
    
         return (
              <Text>awesoe</Text>
         );
    }
    

before adding react-native it was exactly same"
facebook/react,2020-01-16 10:33:57,question,Question: react lib context overrides app context,"Hi, I believe that this can potentially be an issue, though I'm not sure.

I was wondering about good patterns concerning the react context.

Let's get a public library, for example `react-intl` that exposes a Provider (IntlProvider).
Let's create a library `barLib` that uses `react-intl` to manage translations internally and that also exposes a `Provider`.
Now let's imagine I create a web app and use both `barLib` and `react-intl`.

I don't expect the `barLib` to ever override my react-intl context, because i'm not aware it uses internally the `react-intl` lib.
But the `barLib` can accidentally override the react-intl context => https://codesandbox.io/s/embedded-contexts-test-z8e7b

This kinda breaks the isolation of libs IMO.

I see several solutions :
- Don't use an other lib context in the `barLib` (pretty extreme)
- Check that there is not already an intl context in the `barLib`, if so merge the context values ?

I'm not convinced with either solutions, what do you guys think about it ?"
facebook/react,2020-01-15 03:23:40,question,Question: why cann't I set echarts instance using useState?,"

## Coding Questions
i try to store the echart instance using useState, but after `setInstance`, `instance` is always undefined
```
const [instance, setInstance] = useState<ECharts | undefined>(undefined);

const chartInstance = echarts.init(root.current);
    setInstance(prev => {
        console.log('prev instance', prev); // first time: undefined, then Echarts instance
        return prev || chartInstance;
    });
    console.log('instance: ', instance, chartInstance); // instance is always undefined
```


"
facebook/react,2020-01-13 06:51:35,question,help~When I use React.createElement directly and How to pack the component?,"hello all.

I was met a problem when I published a react component, I need to help and discuss with you all 
I am going to write a component to load `React Component from CDN` and make it like a wrapper component.

```jsx
import React, { Component } from 'react';
import scriptjs from 'scriptjs';

const DEV_SCRIPT =
  'https://dev/cdn/resource/phoenix-header.js';
const PROD_SCRIPT =
  'https://cdn/resource/phoenix-header.js';

class PhoenixHeaderWrapper extends Component {
  constructor(props) {
    super(props);
    this.type = null;
    this.scriptUrl =
      props.scriptUrl || (props.env !== 'PROD' ? DEV_SCRIPT : PROD_SCRIPT);
    this.state = {
      cmp: null,
    };
  }

  componentDidMount() {
    scriptjs(this.scriptUrl, () => {
      this.type = window.PhoenixHeader;
      this.createOrUpdateComponent();
    });
  }

  createOrUpdateComponent() {
    const { scriptUrl, ...otherProps } = this.props;
    if (!this.type) {
      console.error('load component failed');
      return;
    }
    const cmp = React.createElement(this.type, otherProps || {});  // this is point
    this.setState({ cmp });
  }

  render() {
    const { cmp } = this.state;
    return cmp;
  }
}

PhoenixHeaderWrapper.defaultProps = {
  scriptUrl: '',
  env: 'PROD',
};

export default PhoenixHeaderWrapper;

```

and then, I do it just like do a normal react component that I was set the webpack config like below:

```js
// PhoenixHeader
  output: {
    publicPath: './',
    filename: 'phoenix-header.js',
    path: paths.appBuild,
    library: 'PhoenixHeader',
    libraryTarget: 'commonjs2',
    libraryExport: 'default',
  },
  mode: 'production',
  externals: {
    react: {
      commonjs: 'react',
      commonjs2: 'react',
      amd: 'react',
      root: 'React',
    },
    ['react-dom']: {
      commonjs: 'react-dom',
      commonjs2: 'react-dom',
      amd: 'react-dom',
      root: 'ReactDom',
    },
  },
```

and then, I run the `npm run build && npm publish` to publish it.

In my own object which use the PhoenixHeader component as a npm package. 

```jsx
// app.jsx
import React from 'react';
import PhoenixHeader from 'phoenix-header';
import './App.css';

function App() {
  return (
    <div className=""App"">
      <PhoenixHeader />
      <header className=""App-header"">
        <p>
          Edit <code>src/App.js</code> and save to reload.
        </p>
        <a
          className=""App-link""
          href=""https://reactjs.org""
          target=""_blank""
          rel=""noopener noreferrer""
        >
          Learn React
        </a>
      </header>
    </div>
  );
}

export default App;

```
after `npm start`, it show me a error:
![image](https://user-images.githubusercontent.com/12051024/72236068-4d270180-3610-11ea-9e62-7a69a2972e15.png)

**That it is my confusion is, why `createElement` not in this scope.**

so I try to make react set into global:
```js
window.React = React;
```

Yes, it's work for me.

**But someone would like to tell me why need to make React set into global?**

**And am I need to build this wrapper component which do not external the react when I was build?**

let's discuss or give me more suggest about this wrapper component please  🙏"
facebook/react,2020-01-03 21:21:32,question,Rendering React component on server to take a screenshot of it,"My React application has a list of to do lists like this:

<img width=""1082"" alt=""figma_canvases"" src=""https://user-images.githubusercontent.com/12554095/71749785-47206c00-2e2b-11ea-8d0c-5a82ceba1b05.png"">

> Replace the Figma canvas preview images with todo lists above.

In the list of todo lists, I'd like to include a preview of each list as well as its name.

Here's what I thought of to achieve this:
- Whenever a todo list is updated, run a AWS Lambda (Node.js environment) job which generates HTML for the todo list server-side (using `ReactDOMServer.renderStaticMarkup`.
- Then, serve that HTML locally, visit the page using puppeteer, and take a screenshot of the page

However, this seems like a lot of work. Is there an easier way of achieving this? Is there anything in the steps above that won't work?

I've looked at `repng` [1] so far but it hasn't worked for the components I tested it with.

[1] https://github.com/jxnblk/repng"
facebook/react,2019-12-31 02:08:08,question,I can't get the latest status value in the initialization method,"I try to get the latest state value in the initialization method, but the result is not satisfactory。
All this happens in function components。

1.react version is 16.12.0；
2.react-dom version is 16.12.0；

this is my demo code :

```
import React,{useState,useEffect} from 'react';

const App=()=>{
	/*button click*/
	const btnClick = ()=>{
		console.log(""initButton getting state is====>"",nowState); //can't get now state ,all is init value
	}
	/*init a button*/ 
	const initTitle = ()=>{
		return (
			<button onClick={btnClick}>click</button>
		)
	}
	const [title, settitle] = useState();

	/*now state*/
	const [nowState, setNowState] = useState(0);
	console.log(""now state is====>"",nowState);

	useEffect(()=>{
		settitle(initTitle());
	},[])

	return (
		<>
			{title}
			<button onClick={()=>setNowState(nowState + 1)}>change now state</button>
		</>
	);
}

export default App;
```
"
facebook/react,2019-12-26 15:11:03,question,[TypeScript]Is there any way to define the state variables when using functional component? ,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

If there is a lot of state variables, I guess it is hard to get a whole picture the state variables verse class components

**Do you want to request a *feature* or report a *bug*?**

**What is the current behavior?**

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

**What is the expected behavior?**

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
"
facebook/react,2019-12-24 07:54:38,question,getDerivedStateFromProps is executed after setState #13015,"Ideally getDerivedStateFromProps  should not be called due to current component's setState. But it is behaving so. Can someone explain?

Couldn't find solution in [#13015](https://github.com/facebook/react/issues/13015)"
facebook/react,2019-12-23 08:43:04,question,Why only one component can be render at root div?,"  I called two render methods to same root div .
```
RenderDOM.render( < Navigation /> ,document.getElementById(' root ')); 
RenderDOM.render( < App /> ,document.getElementById(' root '));
```
And what i get rendered on my screen is only a  App component.
Just want to know that the one render method override the previous  render method?


"
facebook/react,2019-12-12 09:34:37,question,Bug: React table - Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined.,"**Do you want to request a *feature* or report a *bug*?**
bug

**What is the current behavior?**
Hello,
I am new in React and I am trying to create a simple react table to display data from db with login for user authentication. 
Until I added the login, it worked. Momentally, it still throws the same mistake, no matter what. None of the existing solutions helped me, I tried to repair imports and exports, I reinstalled nodejs, reinstalled node_moduls. 

First, I verify the user by logging in to redirect me to the records page after verification. Verification is ok, but then it crashes.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

Edit: login, password: admin, admin

https://codesandbox.io/s/black-voice-2z6y5?fontsize=14&hidenavigation=1&theme=dark
https://codesandbox.io/embed/black-voice-2z6y5?fontsize=14&hidenavigation=1&theme=dark
[![Edit black-voice-2z6y5](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/black-voice-2z6y5?fontsize=14&hidenavigation=1&theme=dark)
![error_message](https://user-images.githubusercontent.com/26010477/70700296-cf976b00-1cca-11ea-9c65-e2ba84d25d51.png)

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

nodejs version v8.10.0
npm version 6.13.3
ubuntu/chrome

Please give me any advice. Thank you in advance :) 
"
facebook/react,2019-11-26 19:15:10,question,How do suspense and subscriptions interact?,"**Do you want to request a *feature* or report a *bug*?**
Ask a question

**What is the current behavior?**
With `Suspense`, a component throws a `Promise` when it encounters something that's not ready. However, our company's data fetching is subscription-oriented: At a very high level, the following happens:

1. Component renders, and calls `useFoo(id, 'name', 'amount', 'discounts');`
2. Internally, the hook adds a callback to the `FooLoader` which is responsible for batching and sending async requests. The callback will invoke the setter for a `useState` inside the hook to force a rerender of the consuming component. 
3. The hook returns a [`RemoteData<Pick<Foo, 'name' | 'amount' | 'discounts'>>`](https://github.com/ExtraHop/ts-remote-data) which could contain the data if it was locally available, or is just a constant that says, ""I haven't asked for this data yet""
4. When the data becomes available, or the request for the data fails, the `FooLoader` invokes the hook-passed-in callback method, which triggers the rerender, which presents the new component state.

At no point in there does the component have a `Promise`. As a result, I'm not sure it's possible for it to throw anything; it's depending on the `useState` inside `useFoo` to trigger rerender when data is available, but if we throw then that never happens and we wouldn't ever complete.

Throwing a `Promise` from inside the hook doesn't seem right, as it would be very difficult to combine multiple data dependencies in a single component.

The only alternative seems to be a pretty sizable plumbing change to return a `Promise` instead of the loading state constant, but that seems to force a lot of allocations and boilerplate code to handle the ""maybe not ready the first time"" case.

Note: Posting in response to [this tweet](https://twitter.com/dan_abramov/status/1194434908984414208) by @gaearon "
facebook/react,2019-11-20 16:02:31,question,Why include refs as a feature? -- seems broken and unnecessary,"
Refs never seem to work, is this a broken feature?

Why not remove them and just let people use 
document.querySelector('#id').action like normal people.

also, what does this mean? 

 Function components cannot have refs. Did you mean to use React.forwardRef()?"
facebook/react,2019-11-01 09:37:27,question,DevTools component filter does not work with location,"**Do you want to request a *feature* or report a *bug*?**
Report a bug.

**What is the current behavior?**
In DevTools when a component filter is added with field set to `location` and regex set to `.*`, nothing is filtered out. (BTW, no documentation in this subject is available anywhere.)

**What is the expected behavior?**
At least some components be filtered out.
It would also be awesome if the `location` was shown somewhere for the selected component, so that users can know what kind of Regex they should put together.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
React DevTools 4.2.0 on Firefox 69.0.3."
facebook/react,2019-10-30 09:25:24,question,Why is useEffect hook not activating when a component is reloaded after previously throwing an error?,"I am learning React and Redux within a Typescript environment. I have managed to implement a container that dispatches a fetch action and subscribes to corresponding fetch success and error state notifications from a redux store. The source code is listed below:

**Container**
``` typescript
import React, { useEffect } from 'react';

import { connect } from 'react-redux';
import Grid from '@material-ui/core/Grid';
import { GridSpacing } from '@material-ui/core/Grid';

import Course from '../components/Course/Course';

import { courseModels } from '../redux/features/course';
import { courseSelectors } from '../redux/features/course';
import { fetchCoursesAsync } from '../redux/features/course/actions';
import { RootState } from 'ReduxTypes';

type ErrorReport = { hasError: boolean; error?: Error };
type StateProps = {
  isLoading: boolean;
  courses: courseModels.Course[];
  error: ErrorReport;
};

/**
 * Redux dispatch and state mappings
 */
const dispatchProps = {
  fetchCourses: fetchCoursesAsync.request,
};

const mapStateToProps = (state: RootState): StateProps => ({
  isLoading: state.courses.isLoadingCourses,
  courses: courseSelectors.getReduxCourses(state.courses),
  error: courseSelectors.getReduxCoursesError(state.courses),
});

/**
 * Component property type definitions
 */
type Props = ReturnType<typeof mapStateToProps> & typeof dispatchProps;

/**
 * CourseList component
 */
const CourseList = ({
  courses = [],
  error,
  fetchCourses,
  isLoading,
}: Propas): JSX.Element => {
  // fetch course action on mount
  useEffect(() => {
    console.log('COURSELIST FETCHING COURSES');
    fetchCourses();
  }, [fetchCourses]);

  if (isLoading) {
    return <p>Loading...</p>;
  }

  if (error && error.hasError && error.error) {
    throw error.error;
    // if throw an error then encapsulating error boundary catches and displays.
    // However when the container is loaded again via clicking on a Navbar link the useEffect
    // action does not trigger. 
    
    // Alternatively, if the error is rendered inside the container then the useEffect hook is 
    // still activated if the container is loaded again (e.g. via clicking on a Navbar link).
    // return <p>{JSON.stringify(error.error, null, 2)}</p>;
  }

  return (
    <div style={{ marginTop: 20, padding: 30 }}>
      {
        <Grid container spacing={2 as GridSpacing} justify=""center"">
          {courses.map(element => (
            <Grid item key={element.courseID}>
              <Course course={element} />
            </Grid>
          ))}
        </Grid>
      }
    </div>
  );
};

/**
 * Exports
 */
export default connect(
  mapStateToProps,
  dispatchProps,
)(CourseList);
```

If I throw an error within the container then the encapsulating error boundary catches and displays it. However, when the container is reloaded via clicking on a Navbar link the useEffect
action does not trigger. Subsequently, the fetchCourses action is not dispatched.

Why is the _useEffect_ hook not triggered on second load after it previously threw an error?

My ErrorBoundary component includes a home button for navigating to '/'. However, after clicking home, if I then click on link to display my CourseList container the ErrorBoundary is again displayed. I do not see the console log message displayed from useEffect. When navigating back to '/courses' shouldn't this recreate the CourseList container? Is this not happening because the error was thrown in render previously, so the container is being reused?

What is best practice for resetting a component that threw an error for surrounding ErrorBoundary?"
facebook/react,2019-10-28 11:40:50,question,Utilize Suspense to express app init loader,"With Concurrent mode getting finalized, I went to try to solve an old problem I have.

The app needs to run a series of init steps before it can do anything viable. Each steps depends on the previous one. This is expressed as nested components. The fairly elaborate animated logo is shown for that process, but it's being restarted for each step and the experience is not that nice.

I've prepared a demo with some experiments: https://codesandbox.io/s/react-suspense-loader-experimental-0ww6i

The first one that's active initially is what we currently have. The second is what we would like to have, but with less naive coding of decreasing counter.

The last one is my attempt to use Suspense, but I definitely missing something out here, because it behaves very oddly and I cannot seem to figure out why. I wonder if the new `useTransition` should be used somehow or what's going on here."
facebook/react,2019-10-15 11:35:15,question,"Weird behavior with functional components and useState, A bug or ""Another rule!""","<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->
```React : '16.9.0'```

sample code 
```javascript
import React from ""react"";
import ReactDOM from ""react-dom"";

function OptionOne(){
  return <div>Blue pill</div>
}

const OptionTwo = React.memo(function OptionTwo(){
  return <div>Red pill</div>
});


function App() {
  const [ Option, setOption ] = React.useState(null);

  return (
    <div>
      <div>
        <button onClick={e=>setOption(OptionOne)}>Option one</button>
        <button onClick={e=>setOption(OptionTwo)}>Option two</button>
      </div>
      { Option && <Option/>}
    </div>
  );
}

const rootElement = document.getElementById(""root"");
ReactDOM.render(<App />, rootElement);
```
Well the expected behavior was Option one wasn't suppose to throw an error;
setState in class components didn't mind if a key value was a pure functional component or a class component even, but it seams the useState hook is sensitive to the value passed using the setter. If its another functional component it throws a confusing error, worst if the pure functional component passed to setVlaue of useState hook uses hooks of its own, then you get multiple misleading hooks errors to debug.
So is the useState hook working like its suppose to ""A rule not to pass a pure functional component as a value to the setValue of the useState hook"" or a bug? 
"
facebook/react,2019-10-09 12:58:43,question,"i was trying to pass through Hook effect, and the codes used are declared no where. like ChatApi ","```js
import React, { useState, useEffect } from 'react';

function FriendStatus(props) {
  const [isOnline, setIsOnline] = useState(null);

  function handleStatusChange(status) {
    setIsOnline(status.isOnline);
  }

  useEffect(() => {
    ChatAPI.subscribeToFriendStatus(props.friend.id, handleStatusChange);

    return () => {
      ChatAPI.unsubscribeFromFriendStatus(props.friend.id, handleStatusChange);
    };
  });

  if (isOnline === null) {
    return 'Loading...';
  }
  return isOnline ? 'Online' : 'Offline';
}
```"
facebook/react,2019-09-26 06:36:13,question,"Why does parent's componentDidMount gets called first, then child's?","I thought it was always the case, that first, child's `componentDidMount` would be called, and then, parent's.

However, in this example: https://codesandbox.io/s/tender-jones-gpkz3

First parent's `componentDidMount` is called, then Child's (check the logs).

This happens _after_ I use this in child:

```
export default compose(
  withStyles(styles),
  withWidth()
)(Child);

```

Does anyone have explanation why this happens?"
facebook/react,2019-09-16 20:05:17,question,Read latest state value in event handler,"I have this question I could have asked on Stack overflow, but I think it is more suitable for people from react team or more experienced users. So I will give it a try to ask it here.

Imagine I have event handler below where I **want to read latest state value and do something with it (however, not do a new `setState`)**:

    onClick(){
    
      let data = this.state.data;
      API.makeRequest(""URL"", data);
    
    }

[Here][1] Dan Abramov says it is safe to read state in event handler (in the sense it will be up to date).
However he says this applies to react 16.

Otherwise he suggests to use functional `setState` to get current state.

I have question: what if I want to read latest state value in event handler, however such that it works also in later react versions (17+, without hooks)? One option IMHO would be to use functional `setState`, but what if like in the beginning of question I said I don't want to `setState`, just read the state value - and do something with it like network request. So using functional `setState` wouldn't be right for me, as it would force me to update state, right? Or I could return empty object from functional `setState` (to avoid updating state) and put the network request code inside it, like this:

 

    onClick(){
        
       this.setState(ps=>{ 
            // using this form only to read current state in event handler which works for 16 and onwards versions probably
            // but this breaks purity of this function
            API.makeRequest(""URL"", ps.data);
            return {};
       })
        
    }

but then I would violate that the function passed to functional `setState` must be pure.

Is there a solution to the question I asked?

  [1]: https://stackoverflow.com/a/43440790/3963067"
facebook/react,2019-09-10 17:06:02,question,DevTools: Component tree navigation,"**Do you want to request a *feature* or report a *bug*?**
Feature

**What is the current behavior?**
Where is no way to collapse/expand component tree or it subtrees. 

If I pick element with ""Select element"" button - I got all the tree expanded, not the only one subtree, where selected element came from(probably bug?) And I don't found way to collapse tree. So if you pick something from page your component tree is basically is always expanded on all levels. 

Maybe we can have selected row context menu like the one in chrome devtools with options to collapse/expand. 

![image](https://user-images.githubusercontent.com/848985/64634574-396f5280-d406-11e9-9cb8-1630e2edef5e.png)

![image](https://user-images.githubusercontent.com/848985/64634564-307e8100-d406-11e9-8d3d-1a97c9f3b77b.png)

Also I guess it maybe good place to add https://github.com/facebook/react/issues/16463
"
facebook/react,2019-09-04 20:55:04,question,There is no 'rendered by' section in my extension,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

**What is the current behavior?**

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

**What is the expected behavior?**

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
"
facebook/react,2019-09-03 19:15:32,question,React devtools always launches in Chrome,"Hi.

I have the extension installed on both chrome and firefox. My default browser is firefox. Each time I try to debug a react native app remotely it launches chrome to use the debugger there.

How do I change the default browser for devtools to Firefox?"
facebook/react,2019-09-02 13:14:47,question,Limitations of context API compared to legacy implementation,"This isn't technically a bug, but a limitation of the new context API implementation and also a question on whether this should be fixed by React, or if I should implement a custom, in-house, solution instead.

I have a fairly ""edgy"" use-case with a component library that provides several parent-child components (e.g. tabs, accordions etc.). This looks like a standard context use-case so far. However, the library has to work in a plugin-based environment, meaning the parent and child components are rendered by two completely independent apps (host app and plugins respectively).

Example:
```jsx
<Accordion> <!-- provided by host app -->
    <!-- provided by separate plugin -->
    <AccordionItem label=""item 1"">Content</AccordionItem>
    //...
</Accordion>
```

Thus, two separate instances of the component library are created, one for the host app and one in the plugin scope, but they still have to communicate with each other, behind the scenes, while keeping it transparent to the user.

This worked seamlessly with the legacy context API, but now with the new one, it breaks. That is because `React.createContext` returns an object that now has to be explicitly shared between the components, by means of an import. But because of the decoupled architecture of the app, and multiple instance of the library being used, this seems impossible to do.

As stated in the docs, the legacy context API is deprecated and will be removed in future versions of React (17+?), so I'd like to avoid being stuck on React 16, when that happens.
"
facebook/react,2019-08-29 16:00:22,question,Error message when calling work.commit in commit phase,"This was me just toying around with unstable APIs. I don't know what these can be used for. Just tried to make sense of them from their names.

**Do you want to request a *feature* or report a *bug*?**

error message of `batch.commit()` is confusing

**What is the current behavior?**

I was experimenting with the `unstable_create(Sync)Root` APIs and just tried to piece together what goes where. While looking through the source I found that the `Work` returned from `createRoot` has a parameter called `onCommit`. For me this implied it's called after the commit [which doesn't seem to be intended](https://github.com/facebook/react/blob/0ca28b526496b4c9cc523e222beffeda73af7172/packages/react-dom/src/__tests__/ReactDOMRoot-test.js#L58). However given the code below I get `Uncaught Invariant Violation: work.commit(): Cannot commit while already rendering. This likely means you attempted to commit from inside a lifecycle method.`

```js
function App() {
  return (
    <div className=""App"">
      <h1>Hello CodeSandbox</h1>
      <h2>Start editing to see some magic happen!</h2>
    </div>
  );
}

const rootElement = document.getElementById(""root"");
const root = ReactDOM.unstable_createRoot(rootElement);

root.render(<App />).then(() => {
  const batch = root.createBatch();

  batch.render(<App />);
  // bad
  batch.commit();
  setTimeout(() => {
    // good
    //batch.commit()
  }, 0);
  batch.then(() => {
    // good
    //batch.commit();
  });
});

```

Three things I noticed:
1. seems like I need to call batch.commit after the batch is complete. Changing it to 
```
batch.then(() => {
  // good
  batch.commit();
});
```
got rid of the error. But I noticed that the original code is used throughout the internal tests. In fact moving createBatch and batch.commit the batch well after (long timeout) the initial root.render call seemed to allow sync `batch.render; batch.commit`.

2. ""lifecycle"" should be replaced with something different before these APIs get stable since we try to get away from this mental model. 

For example [`applies setState in componentDidMount synchronously in a batch`](https://github.com/facebook/react/blob/4d307de458dfdf25e704cb2ca20b0578bba8998c/packages/react-dom/src/__tests__/ReactDOMRoot-test.js#L143) could be converted to a sync test and still pass while I would've expected [`can defer a commit by batching it`](https://github.com/facebook/react/blob/4d307de458dfdf25e704cb2ca20b0578bba8998c/packages/react-dom/src/__tests__/ReactDOMRoot-test.js#L132) to fail with the invariant violation from above.

3. Not all lifecycles are ""during rendering"" as far as I know. `componentDidUpdate` is called during commit.


**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

https://codesandbox.io/s/dreamy-wood-dvzrp

**What is the expected behavior?**

I'm basically asking when it's safe to call `batch.commit`: 
* [ ] during render phase
* [ ] during commit phase 
* [ ] outside of these phases e.g. in some `onComplete` callback 

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

`react(-dom)@16.9.0`
"
facebook/react,2019-08-26 05:50:40,question,Devtools V4: Breadcrumbs are removed?,"**Request for feature**
The older devtools used to show a breadcrumbs/component hierarchy, at the bottom, it is really useful to navigate the parent component, I couldn't find it on the new devtool, did we remove it? any reason to remove it? Will we add it back?
"
facebook/react,2019-08-16 13:07:52,question,Why does DevTool Chrome Extension need access to history?,"I woke up today and the DevTool Extension for Chrome asked for additional permissions. More specifically access to history. 

I couldn't find any explanations or reference in the changelog, so I opened this issue."
facebook/react,2019-06-16 12:13:30,question,Suspense + Concurrent Mode immediately shows fallback when updated from onChange,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

Reporting a bug, or at least trying to understand some spooky behavior 👻

**What is the current behavior?**

I have a simple component which reads from a toy suspense-enabled cache. The dummy cache simply waits 100ms before responding to anything.  The cache key is based on some component state (managed with the useState hook). This component is wrapped with `<Suspense>` and rendered in a React root with concurrent mode enabled. 

```javascript
function MyApp(){
    let [text, setText] = React.useState('stuff')
    return <div>
        Data: {readCacheSuspense(text)}
        <button onClick={e => setText('B-A-N-A-N-A-S')}>Update text from button</button>
        <input type=""text"" value={text} onChange={e => setText(e.target.value)} />
    </div>
}

ReactDOM.unstable_createRoot(document.getElementById('root')).render(<React.Suspense fallback={<div>cause i ain't no fall-a-back div</div>}>
    <MyApp />
</React.Suspense>)
```

The component has a text field whose value is set to the current cache key (with an onChange handler that updates the useState hook when the text changes). It also has a button which updates the state to some fixed string ""asdf"" when clicked. 

Clicking the button does what I would expect— the page doesn't respond for a fraction of a second (while the data is being ""fetched"") and then updates with a view of the loaded data. 

**Editing the text however (for instance, typing a single letter in the field) immediately causes the fallback UI to load and unfocuses the text input**. This happens even if the `setTimeout` is changed to 0ms, or `requestAnimationFrame`, or a `setImmediate` polyfill. 

Rather than directly calling `setText` within the `onChange` handler— if I call it within a `setTimeout(..., 0)`, it behaves the way I would expect (i.e. without unfocusing the field and loading fallback). 

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem.**

https://codesandbox.io/s/competent-goldwasser-yhmxo

**What is the expected behavior?**

I would expect that it shouldn't really matter whether I'm updating state from an `onChange` versus an `onClick`. 

I would expect that the fallback UI doesn't show up until its max duration is met.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

I'm using React 16.8.6. I tested it on Chrome 75 on macOS 10.14."
facebook/react,2019-05-11 10:23:31,question,[eslint-plugin-react-hooks]: Can't call hooks on component returned from function,"Wrapping a component in a function, returning the component.


tl;dr
```javascript
export function Home() {
    return function() {
        const [ items, setItems ] = useState([])
        return <div>nothing</div>
    } 
}

const root = document.getElementById('root')
ReactDOM.render(React.createElement(Home()), root)
```

Results in the following error:

```
React Hook ""useState"" cannot be called inside a callback. React Hooks must be called in a React function component or a custom React Hook function
```

However this works:

```javascript
export function Home() {
        const [ items, setItems ] = useState('')
        return <div>nothing</div>
}

const root = document.getElementById('root')
ReactDOM.render(React.createElement(Home), root)
```

"
facebook/react,2019-04-29 05:31:03,question,useEffect for synchronizing state and props,"Hi. I have a recurring scenario that I’ve been struggling with since the good old days of `componentWillReceiveProps`, and now I’ve pretty much run into the same issue with hooks, so I was hoping I could get some guidance as to what the idiomatic way of solving this and similar cases in React is.

### Problem description - starting point

I have a list of items. Every item has an Edit button next to it. Clicking it opens an “Editor”, where one can change all the fields and either Confirm or Cancel. (Confirming would send an API call to save the data, but this part is not relevant to the problem I am having.) The “parent” component would render the list with the Edit buttons, and have an `itemUnderEdit` property that would be null from the start. Clicking on “Edit” for a specific item would set the `itemUnderEdit` to the clicked item.

![usecase](https://user-images.githubusercontent.com/5010901/56883590-6cbcd080-6a67-11e9-9401-bd44e1747bc2.gif)

Here is the full example with all 3 solutions on CodeSandbox: https://codesandbox.io/s/2oz2nzynpy

### Solution 1

Make the “Editor” component stateless and controlled - it takes in change handlers for every field as props with the parent tracking every change. This solution appeals to me, since I like pure stateful components that are a one-to-one mapping of props to HTML - they are simple to reason about etc etc. This kind of goes against the commonly heard “keep your state close to where it is used” advice, which also seems reasonable, since I don’t really need to know in the parent what the user is typing, I am only interested to know when they are done at the end. This stateless solution also introduces a lot of props, since I need one event handler per field (onNameChanged, onDescriptionChanged in the example, but it could as well be 10 fields), which is a lot of props.

### Solution 2

Make the “Editor” component stateful and only get an event when editing is done: `onConfirm(itemToSave)` or `onCancel()`. This seems like the “React” way and is in line with the advice of keeping state close to where it is used. Since I am only interested to know when the user clicks `Confirm`, a stateful “blackbox”-component that tracks its own state seems reasonable.

In order to achieve this, however, I need to copy my props to the state, which, according to @gaearon, is a bad idea:
```
const [name, setName] = useState(props.item.name);
const [description, setDescription] = useState(props.item.description);
```

Moreover, this solution is buggy from the start, since clicking on Edit for a different item doesn’t “re-sync” the props with the state - it only works if I close the Editor and then reopen it:

![stateful_editor1](https://user-images.githubusercontent.com/5010901/56877667-e2b53d80-6a4f-11e9-8f4c-6a52fa175abd.gif)

Which brings us to Solution 3.

### Solution 3

This one has been one of my biggest pain-points with stateful components in React (which is why I prefer stateless components with a state container, but those I widely demonized nowadays, so I am yet again trying to understand the idiomatic React way of doing this).
The “old” ways were to sync in `componentWillReceiveProps` and later with `getDerivedStateFromProps`. Now I can do this with `useEffect`, where I specify `props.item` as the “dependency”, since I want to run it when the item changes.

```
useEffect(() => {
  if (props.item.name !== name) {
    setName(props.item.name);
  }
  if (props.item.description !== description) {
    setDescription(props.item.description);
  }
}, [props.item]);
```

This seems to work as expected, but I get the linter warning: `React Hook useEffect has missing dependencies: 'description' and 'name'. Either include them or remove the dependency array  react-hooks/exhaustive-deps`. Obviously if I were to add those to the dependency list, I wouldn’t be able to change anything in the inputs, so how come I get this warning?

### Summary

This is a question in two parts: first one about an idiomatic solution in React, as well as feedback to the React team: this scenario is simple and common, but *it’s difficult to know how to implement correctly and safely in a consistent way*.

Lifting state up and making the problematic component stateless is good advice that solves the problem, but every time it seems like a “temporary” solution. It also leads to painful refactoring every time something has to be moved around the component tree, so relying on it in the long run is extremely brittle.

The second part of the question is whether the solution with `useEffect` is viable at all, and in this case - why do I get the linter warning? Clearly I want to run it **only** when a certain prop changes. Is there an edge-case where this would result in an unexpected bug? "
facebook/react,2019-04-26 09:10:44,question,`static getDerivedStateFromProps()` does not works same as componentWillReceiveProps  ,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
   bug
**What is the current behavior?**
 `static getDerivedStateFromProps()` is not a replacement for `componentWillReceiveProps`


**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

**What is the expected behavior?**

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

16


Hi I'm trying to implement `toasterNotificationcards` which will be displayed when a user save an item, stating `item saved successfully`

below is my code I'm using `componentWillReceiveProps` which is depreciated I tried `static getDerivedStateFromProps()` but it didn't work 

how can I removed `componentWillReceiveProps` , assuming the close button shouldn't be in parent component(whichever is calling `notificationcomponent`)

[jsfiddle working example ](https://jsfiddle.net/munsp36f/)
requirement:

  On click of the button show `Notificationcard`
  On click on close hide `Notificationcard`

```jsx
class Notification extends React.Component {
  constructor(props) {
    super(props);
    this.state = {
      open: true
    };
  }

  componentWillReceiveProps(props) {
    this.setState({ open: props.show });
    // setTimeout(this.handleClick.bind(this), 8000);
  }

  handleClick() {
    this.setState({ open: false });
  }

  componentDidMount() {
    //setTimeout(this.handleClick.bind(this), 8000);
  }

  render() {
    if (!this.state.open) {
      return null;
    }

    return (
      <div>
        <br />
        <div>Item saved successfully</div>
        <div className=""cls--btn"" onClick={() => this.handleClick()}>
          &#10006;
        </div>
      </div>
    );
  }
}

class Test extends React.Component {
  handleClick() {
    this.setState({ show: true });
  }

  render() {
    return (
      <div>
        <button onClick={this.handleClick.bind(this)}>click</button>
        <Notification show={true} />
      </div>
    );
  }
}

ReactDOM.render(<Test name=""World"" />, document.getElementById(""container""));
```"
facebook/react,2019-04-25 05:38:14,question,Declarative vs. imperative coding style using Hooks,"_If this should be asked on Stack Overflow instead, please let me know and feel free to close the issue._

Consider a component that fetches some data in a custom hook, saves the fetched data in a state hook, and notifies the user that data has been fetched using a prop callback.

Notifying the user can be done imperatively:

```js
function Component(props) {
  const [ data, setData ] = useState(null);

  useApi(""/api/data"")
    .then(setData)
    .then(props.onFetched);

  return dataToElements(data);
}
```

or declaratively using an effect hook:

```js
function Component(props) {
  const [ data, setData ] = useState(null);

  useApi(""/api/data"")
    .then(setData);

  useEffect(() => {
    if (data) {
      props.onFetched();
    }
  }, [ data ]);

  return dataToElements(data);
}
```

React seems to promote a declarative approach. But what I've found is that when components grow large and complex, using declarative effect hooks makes the flow of data and actions quite hard to follow. If you're not careful, a lot of things start to depend on a lot of other things, and the predicted results become non-intuitive and hard to wrap your head around.

I would like to know other peoples' opinions on this matter, and whether or not an imperative approach might sometimes be better. "
facebook/react,2019-04-15 06:29:03,question,How to test multiple state changes with act?,"**Do you want to request a *feature* or report a *bug*?**
Bug

**What is the current behavior?**
With the new `act` function, I'm unsure how to test state transitions that occur _during_ an event handler processing. For example if I have this handler that is called on form submission:

```
const [isSubmitting, setIsSubmitting] = useState(false);
const handleSubmit = async () => {
  setIsSubmitting(true);
  await fetcher();
  setIsSubmitting(false);
};

```
then I want to be able to test that `isSubmitting` state is indeed set to true before `fetcher` is called.

Due to the nature of `act` (I believe it defers all state changes until after its provided function has been run) I'm not sure that this is currently possible?

Previously I've been testing using `await new Promise(setTimeout)` to flush the current runtime task queue, which works fine for this use case.

I _have_ found a way to make this work without triggering the `act` warning, but it feels like a hack. I have to wrap `act` around my expectation, not the submit.

```
it('displays indicator when form is submitting', async () => {
  ReactTestUtils.Simulate.submit(form());
  await act(async () => {
    expect(container.querySelector('.submittingIndicator')).not.toBeNull();
  });
});
```

I've provided this test in a repo together with a couple of other tests which complete the feature - see the link below.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

https://github.com/dirv/react-act-toggle-state

**What is the expected behavior?**
There's a way for me to test this which doesn't feel like a hack.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
16.9.0-alpha.0"
facebook/react,2019-04-12 02:57:14,question,"[Question] about ""._owner.alternate""","It seems that in react@16 every React element children contains cyclic property `._owner.alternate.alternate.alternate.alternate`....

![image](https://user-images.githubusercontent.com/19988985/56009001-c2c41100-5d10-11e9-839f-b4a4a608cf86.png)

So it is easy to cause ""Maximum call stack exceeded"" error when developer compares `props.children` in deep way(like [deep-equal](https://www.npmjs.com/package/deep-equal)).

This caused bugs for community libraries like [react-helmet](https://github.com/nfl/react-helmet): 
https://github.com/nfl/react-helmet/issues/441

I am extremely curious about:
Why React has `_owner.alternate`, and what it stands for?
As it is named as “_owner”, could it be better if we make “owner” not enumerable?

I tried to search source code and but still can’t find any clue.

Thanks in advance."
facebook/react,2019-04-09 22:45:48,question,useState causing children to re-mount?,"*bug*

**What is the current behavior?**

I have a hook that is supposed to call a callback after a `setTimeout`. When I render a list of children with this hook, the callback behaves differently when its in a function component with `useState` than it does if its in a class component.

To see this in action, checkout the codesandbox below. The demo should show children components being added to the page and then after 2 seconds the child is mounted, it should be removed. Both the examples use the same child components, only difference is the parent component being a class vs functional component.
[CodeSandbox](https://codesandbox.io/s/01yo61v6m0)

**What is the expected behavior?**

The function component should behave like the class component.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

React v16.8.6
Latest Chrome

Unsure if this worked with previous versions of hooks.
"
facebook/react,2019-04-04 22:54:37,question,onAnimationEnd/onTransitionEnd Issues,"**Do you want to request a *feature* or report a *bug*?**
Bug

**What is the current behavior?**

### onAnimationEnd creates unexpected behavior

In the following example, I am creating a simple notification component from an array. Each element in the array is used to generate a html element with a class that has a css animation on it. The generated div has an ""onAnimationEnd"" binding which will remove them from the array of notifications. The basic idea is that the notification will fade away (using a CSS animation) and then be removed from the array, or alternatively, I am also allowing the user to manually click on the notification element to remove it.

The interesting bug is as follows. If you add two notifications, the first one will trigger its onAnimationEnd and remove itself. The remaining notification will suddenly jump to the end of its css animation and never trigger its own onAnimationEnd. 

Even more curiously if you add four notifications, exactly two of them will have the above bug, while the other two function properly. In fact exactly half of the added elements will trigger onAnimationEnd properly, while the other half will not.

The onClick functionality to remove the notifications from the array does NOT cause any unexpected behavior, and thus I am forced to conclude that the fault lies with onAnimationEnd, since they both run the exact same function.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

https://codepen.io/msorrentino/pen/xeVrwz

Click the ""add notification"" button. Then press it again before the first element has faded (7 seconds) . You will notice that the second notification element gets ""fast forwarded"" to the end of its animation when the first notification is removed by its onAnimationEnd trigger. The second notification will then be stuck there, never triggering its own onAnimationEnd.

**What is the expected behavior?**

onAnimationEnd should trigger for each element in the loop properly.


**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

Current version of 16.8.6 displays this behavior.
"
facebook/react,2019-04-03 07:01:40,question,UseEffect how to solve conditional paging list,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
 bug
**What is the current behavior?**
UseEffect how to solve conditional paging list:
    1. Reset the page number to 1 when the condition changes
![image](https://user-images.githubusercontent.com/26135370/55459099-4c912180-5621-11e9-827c-1760fec8aa6b.png)
    2. Request to return the current page and keep the current state
![image](https://user-images.githubusercontent.com/26135370/55459127-5ca90100-5621-11e9-97a4-ba5ea642900f.png)

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

**What is the expected behavior?**
Properly handle paging and conditions
**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
16.8    Previously treated in class form"
facebook/react,2019-03-29 11:03:43,question,Mimic componentDidMount but with hooks,"We are trying to use Hooks and we want to mimic componentDidMount but our eslint is responding with ""React Hook React.useEffect has a missing dependency: '_checkUser'. Either include it or remove the dependency array  react-hooks/exhaustive-deps""

If we add checkUser to the dependency in the useEffect we get: ""The '_checkUser' function makes the dependencies of useEffect Hook change on every render. Move it inside the useEffect callback. Alternatively, wrap the '_checkUser' definition into its own useCallback() Hook  react-hooks/exhaustive-deps"".

If we change the _checkUser to use useCallback eslint is responding with: ""React Hook React.useCallback has a missing dependency: '_handleUserState'. Either include it or remove the dependency array  react-hooks/exhaustive-deps"".

What is the correct way to solve this? Or should we ignore the warnings?

```javascript
function _handleUserState(respons) {
      // Some code
}

function _checkUser() {
       const response = someExternalFunction();
       _handleUserState(response);
}

React.useEffect(
        () => {
            _checkUser();
        },
        [] // Run once
);
```
"
facebook/react,2019-03-16 15:30:22,question,Why function as child is not considered as children?,"After digging deeper with [this question](https://stackoverflow.com/questions/52553580/react-children-with-non-element-children), I have found `function as a child` is not being considered as **children**.

Take this example:
```
class CountExpression extends React.Component {
  render() {
    const children = React.Children.toArray(this.props.children)
    console.log(children)
    return <p>{React.Children.count(children)}</p>
  }
}
<CountExpression>
   {'one'}
   {'two'}
   { () => <p>Still, this will be ignored as child. Why?</p>}
   <p>This will be included in array - that's fine</p>
</CountExpression>
```

So, I would like know why is it so? Is it a bug or an expected behavior?"
facebook/react,2019-03-12 16:51:41,question,× Maximum update depth exceeded in controled way,"**Do you want to request a *feature* or report a *bug*?**
- maybe bug?

**What is the current behavior?**

My case is that I want to update state n times by adding different types of fields to the state and then render them. 
Every updating of dom(adding new field) I have to check whether I should do something more by checking the hight of added elements, for example, add a break between elements. 
Fields are represented by the tree structure of data, so I created the class which helps me with going through the tree of fields and I keep it in the class property.

I know how many times I have to modify the DOM so It will be a fully controlled way of state update and it will finish after all fields are added to DOM but before I render all fields I am getting the error ""Maximum update depth exceeded"".

Do you know How I can handle with such a problem? 
I found a solution by adding setTimeout on the way but I am not sure that is the clean solution?(commented code)
Is it ok that I keep in component class property more complex class to manage structure of data?

I am providing a simple example in codepage which shows the problem and throw the error.

https://codesandbox.io/s/93w2lp37xw
"
facebook/react,2019-03-05 16:49:38,question,Should setting state inside discrete events cause cleanup to run?,"This bug is pretty confusing:

https://twitter.com/kentcdodds/status/1102659818660102145

I think it happens because `fn` scheduled by `setInterval(fn, 0)` jumps in front of the `[running]` effect cleanup caused by `setRunning(false)`. So the interval still fires, overwriting `setLapse(0)` that happened during the event with its `setLapse(someValue)`.

This reminds me of the issue described in https://github.com/facebook/react/issues/14750#issuecomment-460409609, or at least a part of it:

>In fact, this problem exists even for regular React keystrokes (and other “discrete” events). The solution to that would be to flush passive effects before we get a discrete event.

But here, it seems like this wouldn’t be sufficient because the effect flips *as a result* of the click, not before it. So should `setState` inside a discrete event *also* flush passive effect? Seems like not. (That would defeat the purpose of delaying them.)

So this is working as designed, and the fix is just `useLayoutEffect` when the timing matters? Or the rAF solution?"
facebook/react,2019-02-22 10:52:29,question,useLayoutEffect in ssr,"Hi, I do not understand the situation with this hook a bit. I use this hook to perform the animation synchronously with the state update, if I use useEffect, then I have jumps in the animation, because the animation library does not have time to start. Also, the documentation states that useLayoutEffect runs on the same phase as componentDidMount (that is, on the client side), and here my server issues complaints to me about my code. Why is that?

https://codesandbox.io/s/oo47nj9mk9

_Originally posted by @dimensi in https://github.com/facebook/react/pull/14596#issuecomment-466023638_"
facebook/react,2019-02-16 23:32:23,question,Hooks: useState one-off callbacks,"**Do you want to request a *feature* or report a *bug*?**
Question / feature

I've been trying to handle a case where I need to execute a piece of code right after the state is set at a particular place in the code. I do understand I'm supposed to use `useEffect` to respond to changes in state, like so:

```javascript
const [val, setVal] = useState(null);
useEffect(() => { /* handle changes to val here */ }, [val])
```

But the problem is, it will run on all changes made to `val` anywhere in the code. Without the second argument of `setVal` being a callback that'll run after the state is set, how can I execute something after a specific `setVal` function call sets the state ? 





"
facebook/react,2019-02-11 20:59:54,question,Prop reassignment in components,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**
Bug

**What is the current behavior?**
Prop reassignment in components

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

1. Have a parent component that passes a prop to a child
2. Have a child assign the prop to the state default
3. Unpack the state value and use a`.push` to alter it
4. Watch in horror as both the prop and the state changes.

https://codesandbox.io/s/61x9k76v8w
Check child.js

**What is the expected behavior?**
Props should not be reassignable within mounted components

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
All browsers all OS's React: 16.7.0
"
facebook/react,2019-02-08 13:56:21,question,"Under what circumstances, unstable_shouldYield will return true？","In Scheduler.js, 
```
function unstable_shouldYield() {
  return (
    !currentDidTimeout &&
    ((firstCallbackNode !== null &&
      firstCallbackNode.expirationTime < currentExpirationTime) ||
      shouldYieldToHost())
  );
}
```
unstable_shouldYield() return true when currentDidTimeout is false and shouldYieldToHost() return true, but why?
```
shouldYieldToHost = function() {
  return frameDeadline <= getCurrentTime();
};
```
shouldYieldToHost() return true means there's no time left in this idle period
currentDidTimeout is false means the schedule is not timeout
what relationship between them, why does unstable_shouldYield() depend on them?
"
facebook/react,2019-02-06 18:07:40,question,act cannot detect secondary updates,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

bug

**What is the current behavior?**

If a component performs a second (non user triggered) update, `act` cannot detect it and warns about the update.

For example, a button is clicked and updates its text. After a second, the button resets and its text reverts to its original state.

https://codesandbox.io/s/6xkyl37x7k?previewwindow=tests

(The reproduction is a bit contrived, but demonstrates the issue.)

**What is the expected behavior?**

The test runs without warning about being wrapped in `act`.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

React & React DOM @ `16.8.0`"
facebook/react,2019-01-29 13:26:12,question,Unable to use useContext hook inline in Context.Provider,"**Do you want to request a *feature* or report a *bug*?**

Not sure if it is a bug or a feature yet. This relates to Hooks.

It could also be that this is all expected behaviour and one of the workarounds mentioned is required.

**What is the current behavior?**

I have a hook that depends on the `useContext` hook. Using it as follows works perfectly:

```
const MyHookedComponent = () => {
    const contextValue = useContext(DemoContext);

    return (
       //Do something with contextValue
    )
}

const MyContextProviderComponent = () => {

   return (
        <DemoContext.Provider value={someContextValue}>
                <MyHookedComponent />
         </DemoContext.Provider>
   )
}
```

What if I want to use the `getContext` hook inline in the same component that declares the `DemoContext.Provider` ?

```
const MyContextProviderComponent = () => {
       const contextValue = useContext(DemoContext); //Of course this fails due to the Context hierarchy.
   return (
        <DemoContext.Provider value={someContextValue}>
                     //Do something with contextValue
         </DemoContext.Provider>
   )
}
```

I seem to be unable to get this working.

**Please note**:
- I have a very good reason for solving my issue with Context and not passing props.
- The implementation I show above looks trivial and dumb but it is the simplest way to illustrate what the use case is. In my implementation the `Provider` sits in a complex component that does a lot of data management which I really want to happen at this level.
- The usual way to use this will be the first working version I noted above, it is only in the case where the user would want to use the hook inline inside the `Provider`.
- I have searched for a couple of hours and tried various configurations without success, so my apologies if this is a duplicate of another issue.

**What is the expected behavior?**

Any method to consume context inline in the provider using the same re-usable hook without having to revert back to render props.

I know I can solve this with **render props** but I am trying to convert an implementation using render props to hooks. I also know I can hoist the Context Provider higher up but in my implementation it would quadruple the code complexity to develop and maintain while introducing extra complexity into the user interface.

Also, by extracting the body inside the `Provider` to a new component I can also solve this but ideally I would not like to have a user do this for this use case.
"
facebook/react,2019-01-23 08:33:52,question,react-router can't pass Hooks,"This is actually an issue of react-router https://github.com/ReactTraining/react-router/issues/6555 but since it's the major routing lib I want to make you aware that there are issues when you want to pass custom hooks via props through your component tree.

Since routing (with react-router) is a regular use case and React Hooks is an easy/elegant way to manage state through the app they should work together. Otherwise React Hooks is about creating Hooks limited to just one component and you cannot share state/hooks component-wide. Maybe I didn't get something right and there is a way..."
facebook/react,2019-01-18 03:09:42,question,How will react solve nested contexts?,"```js
<context1.Provider value={value1}>
  <context2.Provider value={value2}>
    <context3.Provider value={value3}>
      <context4.Provider value={value4}>
        <context5.Provider value={value5}>

        </context5.Provider>
      </context4.Provider>
    </context3.Provider>
  </context2.Provider>
</context1.Provider>
```
```js
<context1.Consumer>
  {value1 => <context2.Consumer>
    {value2 => <context3.Consumer>
      {value3 => <context4.Consumer>
        {value4 => <context5.Consumer>
          {value5 => (
            null
          )}
        </context5.Consumer>}
      </context4.Consumer>}
    </context3.Consumer>}
  </context2.Consumer>}
</context1.Consumer>
```"
facebook/react,2019-01-08 22:06:01,question,Unable to catch Error emitted in componentDidMount,"**Do you want to request a *feature* or report a *bug*?**
Bug report.

**What is the current behavior?**
Error boundary handles `Error` emitted in `componentDidMount` and somewhy **rethrows** it.

```javascript
class ErrorBoundary extends React.Component {
  constructor(props) {
    super(props);
    this.state = {error: null, errorInfo: null};
  }

  componentDidCatch(error, errorInfo) {
    this.setState({
      error: error,
      errorInfo: errorInfo,
    });
  }

  render() {
    if (this.state.errorInfo) {
    	return (
      	    <div>Ive handled an error!</div>
        );
    }

    return this.props.children;
  }
}

class MyComponent extends React.Component {
  componentDidMount(){
  	this.setState(()=>{
    	    throw new Error('This error somewhy was rethrown!')
        });
  }

  render() {
    return (
    	<div>This component is awesome</div>
    );
  }
}

ReactDOM.render((<ErrorBoundary><MyComponent/></ErrorBoundary>), document.getElementById('AppRoot'));
```

https://jsfiddle.net/xobotyi/96eqo8zp/

**What is the expected behavior?**
It should not rethrow the error.

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
React: 16.7.0
OS: Win 10 x64
Browser: Chromium 71.0.3578"
facebook/react,2018-12-20 13:40:35,question,useCallback/useEffect support custom comparator,"Currently we can pass an array as second argument when using `useCallback` or `useEffect` like below:

```js
useCallback(()=> {
  doSth(a, b)
}, [a, b]) // how to do deep equal if a is an object ?
```

The problem is it only compare array items with `===`,  it there any way to compare complex object ? 

Support custom comparator as third argument looks not bad:

```js
useCallback(()=> {
  doSth(a, b)
  }, 
  [complexObject], 
  (item, previousItem)=> { //custom compare logic, return true || false here }
)
```
"
facebook/react,2018-12-01 09:52:16,question,setState hook inside useEffect can cause unavoidable warning  Can't perform a React state update,"**BUG**

**What is the current behavior?**

Example: https://codesandbox.io/s/6y1x2zr21n clicking on OK button cause `Warning: Can't perform a React state update on an unmounted component.`

The problem that unsubscribe is called during B event `setVisible(v => false);` call, see logs:

```
SET VISIBLE BEFORE 
UNSUBSCRIBE 
Warning: Can't perform a React state update on an unmounted component. This is a no-op, but it indicates a memory leak in your application. To fix, cancel all subscriptions and asynchronous tasks in a useEffect cleanup function.
    in Child (created by Holder)
SET VISIBLE AFTER 
```

In our case we have this even without RAF call, but on `transitionend` DOM event.
(It's occurred randomly and rare in our codebase as transitionend event should be called exactly at needed time, but example showed what happens)
Seems like it occurred only if you have a `setState` call during useEffect callback like `setRefresh(v => v + 1);` (_inside provided code_) (_after rewriting our codebase to avoid setState calls in useEffect the error has gone_)


Code
```javascript
import React from ""react"";
import ReactDOM from ""react-dom"";
import mitt from ""mitt"";

const emitter = mitt();

const Child = () => {
  const [visible, setVisible] = React.useReducer((s, a) => a, true);
  React.useEffect(() => {
    const handle = () => {
      console.log(""SET VISIBLE BEFORE"");
      setVisible(v => false); // <--- THIS CALL CAUSES UNSUBSCRIBE AND WARNING ABOUT STATE
      console.log(""SET VISIBLE AFTER"");
    };
    emitter.on(""B"", handle);
    return () => {
      console.log(""UNSUBSCRIBE"");
      emitter.off(""B"", handle);
    };
  }, []);

  return <div>{visible && <h1>CHILD TEXT</h1>}</div>;
};

const Holder = () => {
  const [refresh, setRefresh] = React.useState(0);
  const visible = React.useRef(true);
  React.useEffect(() => {
    if (refresh === 1) {
      visible.current = false;
      setRefresh(v => v + 1); // <--- This state change from effect caused problems
    }
    const handle = () => {
      setRefresh(v => v + 1);
    };
    emitter.on(""A"", handle);
    return () => {
      emitter.off(""A"", handle);
    };
  });

  return <div>{visible.current && <Child />}</div>;
};

function App() {
  return (
    <div>
      <Holder />
      <button
        onClick={() => {
          emitter.emit(""A"", {});

          requestAnimationFrame(() => {
            emitter.emit(""B"", {});
          });
        }}
      >
        OK
      </button>
    </div>
  );
}

const rootElement = document.getElementById(""root"");
ReactDOM.render(<App />, rootElement);

```

**What is the expected behavior?**

Do not provide warning if unsubscription is called during ""setState"" call.


**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

React 16.7.0-alpha.2
"
facebook/react,2018-11-24 20:56:14,question,getDerivedStateFromProps is user-hostile,"So I think `getDerivedStateFromProps` as designed turns out to be user-hostile. The short summary is that it makes the pattern described in the docs, https://reactjs.org/docs/higher-order-components.html#use-hocs-for-cross-cutting-concerns, impossible for non-trivial cases. 

Imagine implementing an HOC that listens to change events on a DataSource, but where a simple shallowEqual() on the resultant state isn't sufficient to prevent rendering. I.e., what if you need more complex logic to determine if new data from the DataSource should be applied? 

In my case, I have a DataSource that doesn't guarantee that it will give out objects of the same identity, so a `===` check will always return false and cause a re-render. BUT, I can do a little bookkeeping on the side and determine whether the data is actually new and should therefore be loaded into state. 

This leads to some problems: 
1) Because `getDerivedStateFromProps` is static, it's not possible to store some internal bookkeeping data on the Component instance that gets used to determine whether to query the DataSource. Worst case, this bookkeeping information could be stuffed in the state object, but that's unnecessarily constraining and a bit ugly from a code organization perspective. 
2) More importantly, it's not possible to determine why `getDerivedStateFromProps` is being called. Is it because of a props change? Or is it because of a ""change"" event firing on the `DataSource`? 

This matters because if props have changed, data must be fetched and the Component re-rendered unconditionally, but if the props haven't changed, then it's possible all the data loaded is the same as last time, and so `render()` can be skipped. 

Here's an example using the deprecated API that's no longer possible, lightly edited from the HOC example I mention above: 
```
function withDataLoading(Component, DataSource, getDataFunc) {

  return class extends React.PureComponent {
    componentDidMount() {
      // Subscribe to changes
      DataSource.addChangeListener(this.handleChange);
    }
  
    componentWillUnmount() {
      // Clean up listener
      DataSource.removeChangeListener(this.handleChange);
    }

    componentWillReceiveProps(props) {
      //Unconditionally update state and rerender since the props changed
      const possiblyNewData = getDataFunc(DataSource, props, this)
      this.setState(possiblyNewData);
      //Remember some metadata about what we fetched for next time
      this.bookkeeping = DataSource.bookkeepingData();
    }
  
    handleChange() {
      // Update component state whenever the data source changes
      const possiblyNewData = getDataFunc(DataSource, this.props, this)
      if(DataSource.didIFetchNewData(this.bookkeeping)) {
        //The DataSource had updated data in it, so rerender
        this.setState(possiblyNewData);
        //Remember some metadata about what we fetched for next time
        this.bookkeeping = DataSource.bookkeepingData();
      } else {
        //No new data was fetched, so don't update State and don't rerender
        //Do nothing…
      }
    }

    render() {
      <Component data={this.state}/>
    }
  }
}
```

Notice that the behavior is different between `componentWillReceiveProps` and `handleChange`. There's no way to make that distinction with the new API. "
facebook/react,2018-10-29 12:13:54,question,Cases where hooks don't currently provide a good answer vs HOC,"(unsure if this is the right place, so trying it out)

I've noticed that the new React Hooks feature is aiming at providing an alternative composition pattern to HOC and render functions, but I believe that many of the use cases solved by HOC (at the framework level) cannot currently be addressed by the new hooks API. 

Specifically, there is not way to incorporate React Hooks with React.memo. Unless I am incorrect, this means that any system that would like to implement optimisations based on external context, such as the react-redux `connect` function (that uses `mapStateToProps` to implement an efficient `shouldComponentUpdate`) will still need to rely on a HOC/render-prop to automate this optimisation.

The reason I am bringing this up is because one of the main benefits stated in the documentation is to reduce framework level use of HOC that ""pollute"" the tree, of which the react-redux connect HOC is probably the most prevalent use case. 

Additionally redux (and `useRedux`) are specifically brought up as an exemplary use case, although with the current system it will cause large optimisation issues (since with no optimised `shouldComponentUpdate`, every ""connected"" component will re-render on every state change).
(Although this might fit into the documentation repo, this is a discussion / opinion and I do not feel it is a ""mistake"" that I should report, but rather a discussion on importance).

An example solution for this could be if there was a way to use contexts in `React.memo` (which unless I'm incorrect only have access to `props` and `prevProps`)"
facebook/react,2018-09-30 22:49:03,question,[npm:create-react-class] No way to implement getDerivedStateFromProps,"There seems to be no way to implement class methods such as `getDerivedStateFromProps` and a few others.

Am I overlooking something?

There is no mention of it here either: https://reactjs.org/docs/react-without-es6.html"
facebook/react,2018-09-14 02:53:16,question,Element attributes be removed silently in frameset tag,"**Do you want to request a *feature* or report a *bug*?**
bug

**What is the current behavior?**
In some historical reason, i am still using obsolete tag `frameset` in my project. And when i render my component which includes `frameset` tag in react, some attributes are ignored, like `rows`, `cols`.
Could anyone tell me why and how to solve it by no hacking way? Thx.

**input**
```javascript
export default class obsoleteElment extends React.Component {

  render() {
    return (
      <html>
      <head>
        <meta httpEquiv=""content-type"" content=""text/html; charset=UTF-8"" />
          <title>old page</title>
      </head>
      <frameset id=""frame-container"" rows='60,*' frameBorder=""0"" border=""0""  cols=""180,11,*"">
      </frameset>
      </html>
    )
  }
}
```

**output**
```javascript
      <html>
      <head>
        <meta http-equiv=""content-type"" content=""text/html; charset=UTF-8"" />
          <title>old page</title>
      </head>
      <frameset id=""frame-container"" frameBorder=""0"" border=""0"">
      </frameset>
      </html>
```

**expect**
```javascript
      <html>
      <head>
        <meta http-equiv=""content-type"" content=""text/html; charset=UTF-8"" />
          <title>old page</title>
      </head>
      <frameset id=""frame-container"" rows='60,*' frameBorder=""0"" border=""0""  cols=""180,11,*"">
      </frameset>
      </html>
```

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

**react version**
![image](https://user-images.githubusercontent.com/17465046/45526873-9b08db00-b80b-11e8-980b-86407da1934c.png)

**node environment**
![image](https://user-images.githubusercontent.com/17465046/45526918-ca1f4c80-b80b-11e8-911d-cf0bb3ab9b32.png)
![image](https://user-images.githubusercontent.com/17465046/45526934-d905ff00-b80b-11e8-87d4-306ca3a998c3.png)

**OS**
![image](https://user-images.githubusercontent.com/17465046/45526979-18cce680-b80c-11e8-8928-ee784a5f0a7d.png)
"
facebook/react,2018-08-30 20:32:19,question,Access React component underlying DOM tree,"**Do you want to request a *feature* or report a *bug*?**
feature

**What is the current behavior?**
Form component has ""form field"" children (Input(), Checkbox(), etc) that are validated against some custom rules when form is submitted. Validation works fine.

**What is the expected behavior?**
 If the form is invalid, I would like to scroll the page to the first invalid element after the form is submitted but unfortunately components do not expose the underlying DOM three (except via the Fiber object) and I cannot get the ""ref"" of any component, which makes scrolling not possible since I don't have the DOM reference.

I am trying to avoid ref forwarding on ""form field"" components because I would like the Form to handle all validation related code (for encapsulation purposes and in case I want to publish this as a library, for instance).

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
react: ""^16.4.0""

Is there any way to achieve this?
"
facebook/react,2018-08-26 17:31:50,question,Question on reconciliation," I think I understood reconciliation in react however there is one thing I would like to clarify.
Let's say on first render, we render:

```
<ul>
  <li>Duke</li> // key 0
  <li>Villanova</li> // key 1
</ul>
```

And on next render


```
<ul>
  <li>Connecticut</li> // key 0
  <li>Duke</li> // key 1
  <li>Villanova</li> // key 2
</ul>
```

If I understood reconciliation correctly on the second render, react will check that **types (e.g. `<li>`) and keys of first two items from first and second render match**, hence it will add only the new item with key 2 to the new output, hence generate following result:

```
<ul>
  <li>Duke</li> // key 0
  <li>Villanova</li> // key 1
  <li>Villanova</li> // key 2
</ul>
```

However I think this is not what react will generate and it seems then there is some issue with my understanding (especially the bold part in the previous paragraph). Can someone explain what I missed in my understanding?"
facebook/react,2018-08-23 09:15:50,question,Get keys in react-reconciler,"I am struggling to implement reusable views on mobile platforms and to make it i need to get key values (explicitly set and generated) in react-reconciler to match two different view trees somewhere outside react.

Is there a way to achieve this?

Thanks!"
facebook/react,2018-08-21 04:33:25,question,how map ? render An Array Of Elements ,"  
 **What is the current behavior?**
   react16+ support return array components, for example:
   render() {
      return [
          《Li》1《/Li》
          《Li》2《/Li》
          《Li》3《/Li》
      ]
   }
   export default ArrayDemo
   ----------------
   i want to map it with React.Children.map,
  for example:
  import ArrayDemo from 'xxx/xxx';
  ....
  React.Children.map(ArrayDemo,(item, index) => {
      return 《Col span={6}》{item}《/Col》
  })
  ....

  -------------------
  but ArrayDemo has become a single element; React.Children.toArray got [0] only;

**What is the expected behavior?**

  i expected since React can return array;  how can i map it? for sometimes i want to wrap each
 element in array ;

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

   16.4+


---------------------------------------
or am i missing something important?    thx a lot!

"
facebook/react,2018-08-14 19:44:28,question,"Avoid reconciliation, alternative component interface","Hello. I want to ask a question about a way to avoid reconciliation process.

Today I can see the following process:

1. Component wants to re-render.
2. Component render method provides new virtual dom.
3. Some react diff library tries to find some non-optimal way to morph old virtual dom into new one.

Please fix me if I am wrong, I am not familiar with react codebase.

I can see an information in [docs](https://reactjs.org/docs/reconciliation.html):

> you don’t have to worry about exactly what changes on every update

But your solution has complexity about O(n) or even worse, so user should care about what changes sometimes. When user knows what changed he will be able to provide O(log n) or even O(1) solution.

For example I am working with huge data list and I am receiving information from websocket about how to morph my list: append/prepend, remove, swap items, etc. I don't want to render huge component list and run reconciliation process for each mutation. I can tell virtual dom how to morph efficiently.

![append](https://user-images.githubusercontent.com/941925/44114154-05201870-a013-11e8-9c7a-2e5ed890e372.jpg)

Is there a way for user to provide morph method? I can imagine some api like:

```
// render is not defined

morph(component) {
  if (...) {
    component.append(<Item />);
  } else {
    (<Item />).prependTo(component.find({ key: '5' }));
  }
}

```

Do you have any plans to implement it? Thank you. Please feel free to ask any questions."
facebook/react,2018-06-05 23:25:50,question,componentWillUpdate discussion,"<!--
  Note: if the issue is about documentation or the website, please file it at:
  https://github.com/reactjs/reactjs.org/issues/new
-->

**Do you want to request a *feature* or report a *bug*?**

Feature : componentWillUpdate Discussion

**What is the current behavior?**

The current behavior calls the function before re-rendering the render target however there is no indication for when the re-render method should be called

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem. Your bug will get fixed much faster if we can run your code and it doesn't have dependencies other than React. Paste the link to your JSFiddle (https://jsfiddle.net/Luktwrdm/) or CodeSandbox (https://codesandbox.io/s/new) example below:**

**What is the expected behavior?**

The expected behavior should call the function before re-rendering the render target if there is no returned conditional statement and if there is, true should trigger the re-render and false should not

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

16.4.0

I have a few questions before I try to solve this problem and it gets rejected. I'm assuming that the team has decided to move in the direction of removing ""Will-Updates"" from React all together and have labeled them ""Unsafe"". I've seen a lot of issues with those functionalities before as well. I was curious if providing a conditional statement inside those functions would satisfy the unexpected renders. ""shouldComponentUpdate"" does trigger when to call these functions however in those functions that ""will"" run before the render can always be controlled with a conditional statement of it's own. I'm getting comfortable with the code base however I'm curious if the team is removing that functionality all together and using the ""static"" function ""getDerivedStateFromProps"" instead. Has a React lover it is a little confusing and may break a lot of legacy code when updating versions. I believe that may solve the problem of unexpected renders after a ""will"" change lifecycle event.

I was curious if that was the case, and removing ""will"" lifecycles is the next steps for React then how will the ""did"" lifecycles work instead?

I love React and I'm just curious about the future for React as a whole. I'd love to tackle any bugs or feature requests when I have time. I will be writing clean code and create tests for new features or bugs as well."
facebook/react,2018-05-26 23:38:59,question,Suspense: timeout expiration and siblings rendering issues,"**Do you want to request a *feature* or report a *bug*?**

Bug

**What is the current behavior?**

Code for reproducing is [here](https://github.com/alexeyraspopov/react-suspense-sandbox/tree/cb3b60be69523de8f720a474c965face2b521b9b). I've also deployed an example to Zeit Now: https://suspense-fpwoufdzfv.now.sh/.

This is a basic example of using React Suspense and Simple Cache Provider. Postponing text rendering and showing loading spinners when it's necessary.

I can see my use of `<Timeout />` doesn't really care about `ms` I'm passing — it always become expired right after the render. You can open a page and the loading bar appears immediately despite `1000ms` delay that it has.

There is content that is placed next to an async component (the one that's going to be suspended).

https://github.com/alexeyraspopov/react-suspense-sandbox/blob/cb3b60be69523de8f720a474c965face2b521b9b/src/index.js#L51-L56

Looking at React Suspense tests, it is assumed that sibling elements can be rendered in any way.

**What is the expected behavior?**

`<Timeout />` component only shows placehold when expired, sibling content is shown even if an async component was suspended.

I built sources for `react`, `react-dom`, and `simple-cache-provider` from the current master, updating `enableSuspense` flag. I also used `<unstable_AsyncMode />` but it didn't seem to make any difference.

I overall was really satisfied with this feature. I hope I did the code correctly so it shows the real bug. "
facebook/react,2018-05-02 20:12:18,question,Use and set a component's state within setInterval function,"This is a question, so I apologize if this isn't the best place to ask.
I'm trying to work with a component's internal state within a setInterval function and I know there are some asynchronous problems I need to be aware of. I also know that I can pass setState a function which would help me protect against async problems... but I can't because I need to use the changed state within the setInterval function? Is what I'm doing safe or should I be working a different way around this problem.

I've seen the following that nearly answers my question and am having trouble visualizing / adapting this (or maybe the behavior I have is fine?):
[Stackoverflow Answer](https://stackoverflow.com/questions/43428456/do-i-need-to-use-setstatefunction-overload-in-this-case?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)
```
sectionTimerHandler = () => {
    const elapsedSectionTimeMs = this.state.elapsedSectionTimeMs + 1000;
    // Do some stuff with elapsedSectionTimeMs
    this.setState({elapsedSectionTimeMs});
}

restartSectionTimer = () => {
    if (this.sectionTimeIntervalId !== 0) {
        window.clearInterval(this.sectionTimeIntervalId);
    }
    this.sectionTimeIntervalId = window.setInterval(this.sectionTimerHandler, 1000);
    this.setState({ elapsedSectionTimeMs: 0 });
}
```

or would something like the following be better/safer even though I'm using `this.state.elapsedSectionTimeMs + 1000` earlier in the function?

```
 this.setState((prevState: AssessmentState) => {
      return {
          elapsedSectionTimeMs: prevState.elapsedSectionTimeMs + 1000
      };
});
```"
facebook/react,2018-05-02 13:55:21,question,Context API bitmask related questions,"I'm playing with Context API bitmask feature to bail out unwanted re-render.

I have a dynamic model ( a JSON object) as context value. By dynamic i meant , the number of keys and structure of the JSON object is unknown. But when the JSON object changed , i know which key is changed. It seems difficult to turn the unknown keys to static pre-defined bitmasks. But I thought such use case is very common, and the bail-out feature should handle it easily by just matching the key. 

Also I notice default changedBits and observedBits is MAX_SIGNED_31_BIT_INT. Does this mean it has a limitation up to 31 type of context change?"
facebook/react,2018-04-10 15:40:31,question,[Question] Context provider state initialisation.,"Consider a component wrapping a context provider:

```js
class ValueWrapper extends React.Component {
  constructor(props) {
    super(props);
    this.state = {
      value: null,
      setValue: this.setValue,
    };
  }

  setValue = (value) => {
    this.setState({ value });
  };

  render = () => (
    <Context.Provider value={this.state}>
      {this.props.children}
    </Context.Provider>
  );
}
```

A consumer then might want to set a default value when it is first mounted. The only way I can see to do this using the new API is to check for an existing value on first render:

```js
class ValueUpdater extends React.Component {
  state = {
    inputValue: 0,
  };

  handleInputChange = e => {
    this.setState({ inputValue: e.target.value });
  };

  render = () => (
    <Context.Consumer>
      {({ value, setValue }) => {
        if (!value) {
          setValue(this.state.inputValue);
        }

        return (
          <div>
            <input type=""text"" value={value} onChange={handleInputChange}/>
            <button onClick={() => setValue(this.state.inputValue)}>Update value</button>
          </div>
        );
      }}
    </Context.Consumer>
  )
};
```

But this seems to break the golden rule of updating state in the render method (`setValue(this.state.inputValue)`), as this would immediately cause a re-render. Ideally I would be able to call the `setValue` from the context in the `componentDidMount` method of the `ValueUpdater` component, but with context as a render prop, that's not possible, as far as I can tell. The docs suggest passing props down to another component:

```js
  render = () => (
    <Context.Consumer>
      {({ value, setValue }) => (
          <ValueUpdaterInput setValue={ setValue } value={ value } />
      )}
    </Context.Consumer>
  )
```

But if I tried to do the initialisation in the `ValueUpdaterInput` component's `componentDidMount` method, it would be called on every render, surely, as `ValueUpdaterInput` would be re-rendered each time?

Is there a better pattern than this, or am I trying to use context inappropriately?"
facebook/react,2018-03-18 12:06:40,question,Is there a way to access new context api within ComponentDidMount?,"We are building a react mapbox gl module and we use clone and inject props today.

We were looking into using the 16.2.0 context api but I saw that it will have a new one on 16.3.0 but I can’t seem to find a way to read context details
On componentDidMount lifecycle (which makes sense for me to use on the map implementation).

Is there a way around this ?"
facebook/react,2018-03-12 16:16:24,question,Potential Future Bug in getEventKey for Edge with Synthetic Event normalization.,"**Bug**

**Current behavior**
React currently normalizes keyboard events cross-browser by falling back on the native KeyboardEvent.keyCode property and using a dictionary object to normalize the key. As noted in the source, getEventKey is used for ""Normalization of deprecated HTML5 `key` values"".

Edge currently does not implement the correct key values and this normalization will fall back to KeyboardEvent.keyCode. KeyboardEvent.keyCode is deprecated and may be dropped at any time.

Microsoft as per https://developer.microsoft.com/en-us/microsoft-edge/platform/issues/15907408/ have fixed this issue, but it has not yet been released to insider preview releases. This means there is the potential for the KeyboardEvent.keyCode to be removed from Edge before the fix is made public. It may be a good idea to not rely on keyCode in this instance.

Refer to https://github.com/facebook/react/blob/5bd2321ae3dd7d68ac02dee3c3f271e9d0ee8784/packages/react-dom/src/events/getEventKey.js Line 103

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**
react-dom version 16.2.0, potentially affects future versions of Edge.
"
facebook/react,2018-02-27 08:05:21,question,state change in td element,"Displaying tabular rows, when setting data in td element, on state change it displays only the currently updated td element data..all the other ones go missing from screen. When the same thing is placed within text box in each td element things work fine.

Following is sample the code :

Working code :
`<tr key={id}> `
`<td> <input  value={this.state.price[id]}/> </td>`

Failing code :
`<tr key={id}> `
`<td> {this.state.price[id]} </td>`"
facebook/react,2018-02-05 19:36:12,question,Getting started docs are terrible,"I just came back to react after about a year or so of not using it and now the getting started docs are pretty much not helpful in the slightest. All the docs are now is just links to other websites without any instructions on how to get a react project running. I remember a year ago back in react 15 the docs had a step by step walkthrough for how to set up and get a project running from scratch and now they are just links to websites without react specific instructions. What happened to the docs, when did they become so useless?

There needs to be a step by step guide added back to the docs, a guide that will get you from having nothing to running it in the browser instead of just links to other websites that don't have anything to do with react. I remember back in react 15, you could run through the guide and have a hello world app running within 10 minutes no problems, I have been trying to figure it out with these new docs for over an hour now and still 0 luck getting this running. The instructions used to actually be instructions, basically saying, install this, then that, then run this command in terminal, then do this and so on. The docs now just say, well you can use this, then has a link to a site that has nothing to do with react, there is not even any sort of instruction on the react website on what to do with that, just the link without any context around it. Can these docs please be reverted to the old versions or actually create a proper getting started page to get you from nothing to running?"
facebook/react,2018-01-30 14:39:07,question,Concating react with other resources,"Hi.

I want to use many libraries and frameworks in my project.

Can I concat React with other framework like angular, vue, ember...?

"
facebook/react,2018-01-26 16:58:31,question,can't edit the wiki,"Hello,
I can't edit the wiki to add my website to the list there, is editing disabled?"
facebook/react,2018-01-25 19:11:26,question,TypeError: Cannot read property 'state' of undefined with create-react-class,"I am currently attempting to create a button which is red with the text ""Yes"" that when you click on it the button changes to a green color with the text ""Confirm?"" before the final stage in which an action takes place. Where I am currently at is defining `buttonColor` as a state which changes on the click of the button; the initial color should be `#FD8F83` and the final color after the click should be `#A4D87C`. However, I am currently getting the error ""TypeError: Cannot read property 'state' of undefined"" pointing to the `style={{backgroundColor: this.state.buttonColor}} ` line whenever the code is compiled on the webpage. 

**Defining initial state and behavior on click:**
```
getInitialState: function() {
    	return {
    		buttonColor: ""#FD8F83""
    	};
},
handleClick(color) {
    	this.setState({
		buttonColor: color
	}); 
}
```

**Code inside table in render():** 
```
<td>
	<button 
		className=""removeButton"" 
		style={{backgroundColor: this.state.buttonColor}} 
		onClick={function(){this.handleClick(""#A4D87C"")}}>
		Yes
	</button>
</td>
```

Does anyone have any ideas why this is? I am brand new to React so I apologize if it's obvious. I also learned React using createClass so I've been trying to piece together how to make this work with the new `create-react-class` package. Any advice is greatly appreciated! 

React: `^16.2.0`
Chrome: `Version 63.0.3239.132 (Official Build) (64-bit)`
"
facebook/react,2017-11-28 19:21:46,question,Sluggish scrolling when rendering table with large dataset in React,"So I'm creating an application with real-time streaming data in a table using react (v16.1.1). The number of rows shown at a time can be rather large (400+ rows) and when those situations occur, the scrolling behavior on browsers (desktop & mobile) really takes a hit and staggers when attempting to browse the content. Has anybody experienced this kind of scrolling behavior when rendering large data sets in a table? 

I'm expecting React to be able to efficiently draw/redraw these elements with ease but that doesn't appear to be the case. I tried using JSFiddle to recreate the scenario but did not have much success.
"
facebook/react,2017-11-24 10:47:19,question,forceUpdate recalls all ref callbacks,"**Do you want to request a *feature* or report a *bug*?**

Bug, maybe

**What is the current behavior?**

On calling forceUpdate ref callbacks called again. So, doing forceUpdate in ref callback makes infinite loop.

**If the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem via https://jsfiddle.net or similar (template for React 16: https://jsfiddle.net/Luktwrdm/, template for React 15: https://jsfiddle.net/hmbg7e9w/).**

https://codepen.io/TrySound/pen/mqKqeB?editors=0012

**What is the expected behavior?**

Do not recall refs

**Which versions of React, and which browser / OS are affected by this issue? Did this work in previous versions of React?**

react 16.1.1
chrome 62"
facebook/react,2017-11-20 18:53:12,question,can't access discuss react,"I know this is not related to react directly but didn't know where to turn to.
Am I the only one who can't access/login to discuss.reactjs.org? (for quite some time already)
I get error:
_This page isn’t working. discuss.reactjs.org is currently unable to handle this request. HTTP ERROR 500_
and sometimes when I retry this error:
_Sorry, there was an error authorizing your account. Perhaps you did not approve authorization?_"
tensorflow/tensorflow,2023-09-07 05:31:36,question,ADD Suppport for VEDV (https://github.com/yunielrc/vedv),"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
tensorflow/tensorflow,2023-09-03 17:53:40,question,Can't run bert_vocab_from_dataset without TypeError: Tensor is unhashable,"### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

This is the code from you [manual ](https://www.tensorflow.org/text/guide/subwords_tokenizer#generate_the_vocabulary)and I really don't understans that I get this error. Why is it? 

If I add 
tf.compat.v1.disable_eager_execution()
tf.compat.v1.disable_v2_behavior()

I get
RuntimeError: input_dataset: Attempting to capture an EagerTensor without building a function.

### Standalone code to reproduce the issue

```shell
data = tf.data.TextLineDataset([SENTENCES_PATH, TAGS_PATH])

from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab

tokens = bert_vocab.bert_vocab_from_dataset(
    data,
    # The target vocabulary size
    vocab_size = 50000,
    # Reserved tokens that must be included in the vocabulary
    reserved_tokens=[""[PAD]"", ""[UNK]"", ""[START]"", ""[END]""],
    # Arguments for `text.BertTokenizer`
    bert_tokenizer_params=dict(lower_case=True),
    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`
    learn_params={},
)
```


### Relevant log output

```shell
TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
```
"
tensorflow/tensorflow,2023-09-01 16:34:57,question,Float16 mixed precision training,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04.5 LTS

### Mobile device

_No response_

### Python version

Python 3.10.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

A6000

### Current behavior?

Enabled float16 training by setting the mixed precision policy, but why I still need to manually cast the y tensors to float16 before calculating the loss?


Error when no manual cast the tensor:
![image](https://github.com/tensorflow/tensorflow/assets/25906607/46c5efcb-f2c2-4b7a-9483-46656009071b)


### Standalone code to reproduce the issue

```shell
Confidential.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-19 06:53:28,question,CKPT to TFLite,"How can I convert ckpt file to TF Lite, while I've only .ckpt file. No meta-file present"
tensorflow/tensorflow,2023-08-11 14:02:25,question,"When converting tensorflow model to tflite model, is there any way to fix the output order during inference using tflite as Facing an issue of output order of tflite inference on meraki custom cv","I took a pretrained model (SSD MobileNet 320x320) for object detection from the TensorFlow Zoo and configured/tuned it according to my data. I trained a TensorFlow model which detects 2 labels.

I have used the latest checkpoint to save the model, then froze it, and finally performed TF Lite conversion. I did this because I need to upload the TF Lite model only to a Cisco camera. 

I'm facing an issue with the output order during TF Lite inference, as the output arrays get jumbled /rearranged. I need help on how to convert the TensorFlow model to TF Lite efficiently. My TensorFlow version is 2.10"
tensorflow/tensorflow,2023-08-02 19:17:30,question,Distributed training with parameter servers example using a single binary,"Hello everyone! I am sorry if this is a duplicate issue but from my considerable search - I could not find a single end-to-end distributed parameter-server example to run using tensorflow (using the keras api with `.fit()` method). Also, for some reason - the documentation for parameter-server strategy seems a lot more confusing and difficult to get started with, compared to multi-worker strategy. 

I have been running training jobs using the estimator api before and now trying to update it to TF2.x style distributed training job with parameter-server training strategy using a single binary file for all workers and parameter-servers. I started with the example in documentation here (https://www.tensorflow.org/tutorials/distribute/parameter_server_training) and modified the code to be used as a single binary. 

Code:
```
import tensorflow_datasets as tfds
import tensorflow as tf

import os

cluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()
if cluster_resolver.task_type in (""worker"", ""ps""):
  # Start a TensorFlow server and wait.
  server = tf.distribute.Server(cluster_resolver.cluster_spec(),
                                      job_name=cluster_resolver.task_type,
                                      task_index=cluster_resolver.task_id,
                                      protocol=cluster_resolver.rpc_layer or ""grpc"",
                                      start=True)
  server.join()
else:
  ## parameter-server
  strategy = tf.distribute.ParameterServerStrategy(cluster_resolver=cluster_resolver)
  global_batch_size = 64
  x = tf.random.uniform((10, 10))
  y = tf.random.uniform((10,))
  dataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(10).repeat()
  dataset = dataset.batch(global_batch_size)
  dataset = dataset.prefetch(2)
  with strategy.scope():
    model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])
    model.compile(tf.keras.optimizers.legacy.SGD(), loss=""mse"", steps_per_execution=10)
  working_dir = ""./my_working_dir""
  log_dir = os.path.join(working_dir, ""log"")
  ckpt_filepath = os.path.join(working_dir, ""ckpt"")
  backup_dir = os.path.join(working_dir, ""backup"")
  callbacks = [
    tf.keras.callbacks.TensorBoard(log_dir=log_dir),
    tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_filepath),
    tf.keras.callbacks.BackupAndRestore(backup_dir=backup_dir),
  ]
  model.fit(dataset, epochs=5, steps_per_epoch=20, callbacks=callbacks)
```

To my understanding, all workers and paramter-servers will start and wait for chief to assign the tasks. Chief or coordinator (documentation uses them interchangeably but is there any difference between the two?) will automatically divide the work based on the information it gets from `cluster_resolver` (let me know if that's wrong interpretation). In any case, I would highly appreciate if someone can point out what I am doing wrong in this example because I have not been able to get it to work!"
tensorflow/tensorflow,2023-07-31 17:26:18,question,"When building from source code, I always end up with a Python 3.10 whl file, instead of a Python3.8 whl file.","### Issue type

Build/Install

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.14.0

### Custom code

No

### OS platform and distribution

Linux Ubuntu 20.04.6 LTS

### Mobile device

_No response_

### Python version

3.8

### Bazel version

1.17

### GCC/compiler version

9.4.0

### CUDA/cuDNN version

11.8/8.7

### GPU model and memory

GTX 1050 Ti 4GB

### Current behavior?

When I try to build the source code from my machine I end up always with a wheel for Python 3.10, although I specified the python path for python3.8 and I don't even have python3.10 installed.

The generated wheel is called tensorflow-2.14.0-cp310-cp310-linux_x86_64.whl

Can you guide why this is happening and how to solve it?

### Standalone code to reproduce the issue

```shell
Just trying to build the source code following the steps from this two sites:

https://gist.github.com/kmhofmann/e368a2ebba05f807fa1a90b3bf9a1e03
https://www.tensorflow.org/install/source
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-26 06:13:33,question,Issues running Transformer model example with estimator api,"Hello everyone! I am trying to run an Image classification training example with Vision Transformer from keras examples (https://keras.io/examples/vision/image_classification_with_vision_transformer/). Everything ran perfectly when I ran it as it is but I started facing issues when i switched training from `model.fit()` to `tf.estimator.train_and_evaluate()` (ofcourse I made the appropriate changes to first convert model to estimator). From what I understand ... the problem lies with saving and reloading the model which is done by the estimator api. The model has custom classes:
```
class Patches(layers.Layer):
    def __init__(self, patch_size, **kwargs):
        super().__init__(**kwargs)
        self.patch_size = patch_size

    def call(self, images):
        batch_size = tf.shape(images)[0]
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, self.patch_size, self.patch_size, 1],
            strides=[1, self.patch_size, self.patch_size, 1],
            rates=[1, 1, 1, 1],
            padding=""VALID"",
        )
        patch_dims = patches.shape[-1]
        patches = tf.reshape(patches, [batch_size, -1, patch_dims])
        return patches

    ## personal addition
    def get_config(self):
        base_config = super().get_config()
        base_config.update({
            'patch_size': self.patch_size,
        })
        return base_config

class PatchEncoder(layers.Layer):
    def __init__(self, num_patches, projection_dim, **kwargs):
        super().__init__(**kwargs)
        self.num_patches = num_patches
        self.projection = layers.Dense(units=projection_dim)
        self.position_embedding = layers.Embedding(
            input_dim=num_patches, output_dim=projection_dim
        )

    def call(self, patch):
        positions = tf.range(start=0, limit=self.num_patches, delta=1)
        encoded = self.projection(patch) + self.position_embedding(positions)
        return encoded

    ## personal addition
    def get_config(self):
        base_config = super().get_config()
        base_config.update({
            'num_patches': self.num_patches,
            'projection': self.projection,
            'position_embedding': self.position_embedding
        })
        return base_config
```

From looking at some related issues, I found how we need to provide a `get_config()` method to save and reload the model with custom classes so I made small personal modifications but now its sort of giving me a different issue I am unable to understand. 

Error Log:
```
  warnings.warn(
x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)
x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)
WARNING:tensorflow:From train.py:225: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.keras instead.
/home/nearchus/.local/lib/python3.8/site-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn(
Traceback (most recent call last):
  File ""train.py"", line 257, in <module>
    history = run_experiment(vit_classifier)
  File ""train.py"", line 231, in run_experiment
    model_est = keras.estimator.model_to_estimator(keras_model=model, model_dir='.', config=run_config)
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/estimator/__init__.py"", line 376, in model_to_estimator_v2
    return keras_lib.model_to_estimator(
  File ""/home/nearchus/.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/keras_lib.py"", line 725, in model_to_estimator
    warm_start_path = _save_first_checkpoint(keras_model, custom_objects,
  File ""/home/nearchus/.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/keras_lib.py"", line 457, in _save_first_checkpoint
    model = _clone_and_build_model(ModeKeys.TRAIN, keras_model,
  File ""/home/nearchus/.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/keras_lib.py"", line 230, in _clone_and_build_model
    clone = tf.compat.v2.keras.__internal__.models.clone_and_build_model(
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/models/cloning.py"", line 806, in clone_and_build_model
    clone = clone_model(model, input_tensors=input_tensors)
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/models/cloning.py"", line 539, in clone_model
    return _clone_functional_model(
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/models/cloning.py"", line 222, in _clone_functional_model
    model_configs, created_layers = _clone_layers_and_model_config(
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/models/cloning.py"", line 298, in _clone_layers_and_model_config
    config = functional.get_network_config(
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/engine/functional.py"", line 1590, in get_network_config
    layer_config = serialize_layer_fn(layer)
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/models/cloning.py"", line 295, in _copy_layer
    created_layers[layer.name] = layer_fn(layer)
  File ""/home/nearchus/.local/lib/python3.8/site-packages/keras/src/models/cloning.py"", line 52, in _clone_layer
    return layer.__class__.from_config(layer.get_config())
  File ""train.py"", line 108, in from_config
    return cls(**config)
TypeError: __init__() missing 1 required positional argument: 'projection_dim'
```
I thought it might be because of `PatchEncoder` class constructor has custom objects as argument - so i tried to do serialization/deserialization but to no vail. In any case, I would highly appreciate if someone can guide me as to where I am going wrong in this!  


  "
tensorflow/tensorflow,2023-07-19 16:43:13,question,Tesla v100 Tensorflow CUDA Support,"### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.4

### Custom code

Yes

### OS platform and distribution

RHEL 7.9

### Mobile device

_No response_

### Python version

3.6

### Bazel version

_No response_

### GCC/compiler version

4.3

### CUDA/cuDNN version

11/8, 10.1/7.6

### GPU model and memory

Tesla V100 2GB Vram

### Current behavior?

Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error.

NVIDIA-SMI give the following output:| NVIDIA-SMI 450.51.05 Driver Version: 450.51.05 CUDA Version: 11.0

nvcc-V the following output:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:17_PST_2019
Cuda compilation tools, release 10.1, V10.1.105


### Standalone code to reproduce the issue

```shell
Doesnt happen with Windows or Ubuntu systems.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-17 13:53:12,question,Parse output of `mobile_ssd_v2_float_coco.tflite`,"### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

v2.11.1

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

Android

### Python version

_No response_

### Bazel version

6.2.0

### GCC/compiler version

12

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm trying to use the model [mobile_ssd_v2_float_coco.tflite](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobile_ssd_v2_float_coco.tflite) on a C++ application, I'm able to execute the inference and get the results.

Based on the Netron app I see that its output is:
![image](https://github.com/tensorflow/tensorflow/assets/92656601/7ee73cb9-52dc-47ef-a89f-d17843bd0f60)

But I couldn't find an example code showing how to parse this output.

I tried to look into https://github.com/tensorflow/tensorflow/issues/29054 and https://github.com/tensorflow/tensorflow/issues/40298 but the output of the model is different from the one provided [here](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobile_ssd_v2_float_coco.tflite).

Do you have any example code available in Java, Python, or even better in C++ to parse this model output?

### Standalone code to reproduce the issue

```shell
No example code is available to parse the output of mobile_ssd_v2_float_coco.tflite.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-13 19:42:52,question,Error installing impoerting TF model into Node red,"Hello, I am getting a tensor flow to install on my node red. It seems like there is and install issue and I keep on getting the error pictured below. I have also tried import an model from teachable machine too and I get the same error please help.
![Capture](https://github.com/tensorflow/tensorflow/assets/139502937/3df553e5-3715-4ffb-a89f-b6fe324c31e0)
![Capture1](https://github.com/tensorflow/tensorflow/assets/139502937/3e101d5f-29ca-4313-bbe6-8904a801443b)

"
tensorflow/tensorflow,2023-07-10 10:04:47,question,Support for empty GPU batches during distributed training,"### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.12.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When doing `distributed training` using `MirroredStrategy`, one may encounter empty GPU batches when `drop_remainder=False` during dataset construction.

From #44348 , it seems it is a long-standing issue. 

For the last few batches of data it is possible that some replica workers receive an empty tensor as input ( see [here](https://www.tensorflow.org/tutorials/distribute/input#batching) for an example !!! ). 

Either one must set `drop_remainder=True` or consider not using `@tf.function` because you would have to add a conditional statement in the `train_step` function which won't work with `tf.function`. 

So, from the point of efficiency, `drop_remainder=True` seems the only option. In some applications or critical experiments, one would not like to drop the remainder data  for very precise and reproducible quantitative analysis.

So, can there be a support for handling empty GPU batches in distributed mode ?

### Standalone code to reproduce the issue

```shell
`tf.data.Dataset.range(8).batch(4)` over 3 replicas, results in the following output:

Batch 1:

    Replica 1: [0, 1]
    Replica 2: [2, 3]
    Replica 3: []

Batch 2:

    Replica 1: [4, 5]
    Replica 2: [6, 7]
    Replica 3: []

Without `drop_remainder=True`  this will cause an incompatible shape error when doing a forward pass.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-07 16:54:00,question,Convert tf.Tensor into tensorflow::Tensor,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13

### Custom code

Yes

### OS platform and distribution

Ubuntu 20

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

11.2

### GPU model and memory

_No response_

### Current behavior?

Is there any way to convert tf.Tensor from python into tensorflow::Tensor C++?

### Standalone code to reproduce the issue

```shell
Actually using pybind11. I can get PyObject* from tf.Tensor and have no idea how to get tensorflow::Tensor* from PyObject*
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-06 07:06:24,question,How to use keras layers to augment both image and label data in image segmentation tasks？,"### Issue type

Others

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.6

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

python 3.7

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

How to use tool a to enhance both image and label data in image segmentation tasks.
I saw an example in the official document of using Keras layer for data augmentation, which is very useful in the training process of classification models because the data augmentation does not require synchronized operations on labels. However, in the segmentation task, if I embed the data enhancement layer into the model structure, I cannot do operations like rotate 、zoom .etc on the label and image at the same time, because the fit method only feed the original image into the model for inference, which results in the label being isolated from the inference process, so it is impossible to do synchronize Affine transformations with the original image.

Thanks.


### Standalone code to reproduce the issue

```shell
I cannot copy my code from the company computer. I just want to know how to do efficient data augmentation that can apply GPU acceleration and distribute strategy.Thanks.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-06-30 19:15:29,question,SavedModel is not deterministic when saved with enable_op_determinism=True,"### Issue type

Support

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.9.2

### Custom code

No

### OS platform and distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have a model with monte-carlo sampling layers. At train time it is ok for sampling to be random and I do not set a seed.
At inference this model MUST output deterministic results - so the sampled values must be reproducible.
I need to save this model after training using `tf.keras.models.save_model()` and then load it with `tf.keras.models.load_model()`

When training is complete I save the model like so:
```
tf.keras.utils.set_random_seed(42)
tf.config.experimental.enable_op_determinism()
model.seed = 42
tf.keras.models.save_model(model, save_path, save_format=""tf"")
```

To load it:
```
import tensorflow as tf
tf.keras.utils.set_random_seed(42)
tf.config.experimental.enable_op_determinism()
model = tf.keras.models.load_model(save_path)
for _ in range(10):
 output = model(input_tensor, training=False)
```
I expect output to be always the same for the same input - within one python process and when reloading, however it is not.

This is what my model looks like (only the relevant portions):

```
class CustomModel(tf.keras.Model):
   def __init__(self, *args, **kwargs):
       self._seed = None
       self.mc_layer = CustomMonteCarloSamplingLayer()

    @tf.keras.utils.register_keras_serializable(name=""seed"")
    @property
    def seed(self):
        return self._seed
     
    @seed.setter
    def seed(self, value):
        if is_op_determinism_enabled():
            lgr.info(""Setting random seed"")
            self._seed = value
            tf.random.set_seed(value)
        else:
            lgr.info(""TF OP Determinism not set"")

   def call(self, inputs, training=True):
       return self.mc_layer(inputs, seed=self._seed)
```

Internally in `CustomMonteCarloSamplingLayer` I use the seed value like so:
```
tf.random.set_seed(seed)
samples= dist.sample(num_samples, seed=seed)
```
where dist is a distribution from tensorflow_probability.

When `self._seed = None` which is the case in training, `dist.sample` will randomly generate values.
When `self._seed` is set then I need `dist.sample` to be reproducible.

The loaded model, even with op determinism enabled during saving and loading, is not reproducible.

      


### Standalone code to reproduce the issue

```shell
See above
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-06-21 08:54:01,question,"Error: Input 0 of layer 'batch_normalization' is incompatible with the layer: expected ndim=2, found ndim=4.","Estoy intentando entrenar un modelo GAN utilizando Keras en TensorFlow, pero estoy encontrando el siguiente error:

```
Input 0 of layer 'batch_normalization' is incompatible with the layer: expected ndim=2, found ndim=4. Full shape received: (None, None, None, 32768)
```

El error ocurre cuando intento entrenar el modelo con el siguiente código:

```python
history = model.fit(train_generator, epochs=100, callbacks=[checkpoint, tensorboard])
```

¿Alguien podría ayudarme a entender qué está causando este error y cómo puedo solucionarlo? Gracias."
tensorflow/tensorflow,2023-06-15 07:53:12,question,"Hi @radres2019, Thank you for reporting the issue!","              Hi @radres2019, Thank you for reporting the issue!
You are seeing this error because Colab has python version 3.10. Tensorflow quantum 0.7.2 is compatible with Python 3.7, 3.8, 3.9  and does not support Python 3.10. 

Please refer to the gist where I was able to install Tensorflow quantum sucessfully [here](https://colab.sandbox.google.com/gist/synandi/b733cccf4a90d29e5feefb606f02f843/60428.ipynb). Thank you!

_Originally posted by @synandi in https://github.com/tensorflow/tensorflow/issues/60428#issuecomment-1527270841_
            "
tensorflow/tensorflow,2023-06-13 02:47:27,question,Using C api and library,"**System information**
-windows
  if possible):
- TensorFlow Lite in Play windows
- Google Play Services version

**Standalone code to reproduce the issue**
Hi:
    I have compiled tflite's Static library ""libtensorflow-lite. a"" and ""libtensorflowite_c.so"" using cmake according to the official document. However, when I introduced this library and used C to call it, the following error occurred: ""undefined reference to ` __imp_TfLiteModelCreateFromFile '"", undefined reference to`__ IMP_ TfLiteInterpreterOptionsCreate '

Do you know what caused it, or are there any relevant cases

Thanks!
"
tensorflow/tensorflow,2023-06-09 08:28:44,question,What phone support tensorflow lite GPU delegate?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.12.0

### Custom Code

No

### OS Platform and Distribution

Android 13

### Mobile device

Android 13

### Python version

3.8.3

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I tested multiple mobile phones (including Xiaomi 12s Ultra, OnePlus 8, Honor Nova 10, Oppo Reno 9) using the example Android apk at https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android . On all of the devices, the app tells ""GPU is not supported"", but NNAPI and CPU is OK.

Anything I can do to enable the GPU delegate on these Qualcomm Snapdragon devices?

### Standalone code to reproduce the issue

```shell
the example Android apk at https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-07 03:43:07,question,About using C to call tflite,"**System information**
- RIsc-v

**Standalone code to reproduce the issue**
Hi:
    If i want to compile tflite into a library and then use C to call it. How can I effectively optimize and crop it to make the compiled tflite library file smaller. Because for our model, tflite micro is not supported by many operators
"
tensorflow/tensorflow,2023-06-01 08:35:08,question,tensorflow.map hangs randomly when using for num_parallel_calls a value > 1,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: wsl2 on windows
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: 2.12.0
-   **Python version**: 3.8.10
-   **CUDA/cuDNN version**: 12.0
-   **GPU model and memory**: RTX A5000 24GB


### Describe the problem

I am using tensorflow in a docker container on wsl2 for training neural networks but unfortunately everything freezes during the image import if done with the tf.map function with the parameter ""num_parallel_calls"" set to a value >1. Below is a minimal example of the code which causes the console to freeze at a random step and the CPU-usage to drop to a minimal level while the RAM is still occupied. After everything is frozen, the docker container is unresponsive and has to be restarted by stopping the process. This might even take half a day -> a few hundred thousand iterations but it allways happens at some point.


### Source code / logs

`import tensorflow as tf

def parse_function(filename):
    return tf.io.read_file(filename)

filenames = []
for i in range (100000):
    filenames.append(""/D/test.png"")

dataset_train = tf.data.Dataset.from_tensor_slices((filenames))
dataset_train = dataset_train.map(parse_function, num_parallel_calls =  2)
dataset_train = dataset_train.batch(50)

for epoch in range(1000):
    for step, (x_batch_train) in enumerate(dataset_train):
        print(""epoch:"", epoch, ""start train step:"",step)`


This issue is similar to others like #32454 but i still can't find a fix. 
Bypassing the map-function by loading everything at once works -> definitly during mapping if parallel calls are allowed
"
tensorflow/tensorflow,2023-05-25 02:33:48,question,same Error as #35100 --W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. 	 [[{{node PyFunc}}]],"I am reproducing the [code](https://github.com/weizhepei/CasRel) , I followed there requirement but when code reached to 44/100 epoch I got this error : `2023-05-24 06:42:29.554799: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. 	 [[{{node PyFunc}}]]`. I tried to to update tensorflow but it stop working because of keras version. 
Code requirements: 
`Package                          Version
-------------------------------- ---------
absl-py                          1.4.0
astor                            0.8.1
certifi                          2022.12.7
charset-normalizer               3.1.0
colorama                         0.4.6
filelock                         3.12.0
fsspec                           2023.1.0
gast                             0.5.3
google-pasta                     0.2.0
grpcio                           1.51.3
h5py                             3.8.0
huggingface-hub                  0.14.1
idna                             3.4
importlib-metadata               6.0.0
joblib                           1.2.0
Keras                            2.2.4
Keras-Applications               1.0.8
keras-bert                       0.80.0
keras-embed-sim                  0.10.0
keras-layer-normalization        0.16.0
keras-multi-head                 0.29.0
keras-pos-embd                   0.13.0
keras-position-wise-feed-forward 0.8.0
Keras-Preprocessing              1.1.2
keras-self-attention             0.51.0
keras-transformer                0.33.0
Markdown                         3.4.1
MarkupSafe                       2.1.2
mock                             5.0.1
numpy                            1.21.6
packaging                        23.1
pip                              22.3.1
protobuf                         3.20.1
PyYAML                           6.0
regex                            2023.5.5
requests                         2.31.0
scikit-learn                     1.0.2
scipy                            1.7.3
setuptools                       65.6.3
six                              1.16.0
sklearn                          0.0.post5
tensorboard                      1.13.1
tensorflow-estimator             1.13.0
tensorflow-gpu                   1.13.1
termcolor                        2.2.0
threadpoolctl                    3.1.0
tokenizers                       0.13.3
torch                            1.13.1
tqdm                             4.65.0
transformers                     4.29.2
typing_extensions                4.5.0
urllib3                          2.0.2
Werkzeug                         2.2.3
wheel                            0.38.4
wincertstore                     0.2
wrapt                            1.15.0
zipp                             3.15.0
`

and run.py code is: 
`#! -*- coding:utf-8 -*-
from data_loader import data_generator, load_data
from model import E2EModel, Evaluate
from utils import extract_items, get_tokenizer, metric
import os, argparse
os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""
from keras import backend as K
if(K.backend() == 'tensorflow'):
    import tensorflow as tf
    from keras.backend.tensorflow_backend import set_session
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    sess = tf.Session(config=config)


    #tried these lines too but not useful
    '''config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))
    sess = tf.compat.v1.Session(config=config)'''

parser = argparse.ArgumentParser(description='Model Controller')
parser.add_argument('--train', default=True, type=bool, help='to train the HBT model, python run.py --train=True')
parser.add_argument('--dataset', default='VKG', type=str, help='specify the dataset from [""NYT"",""WebNLG"",""ACE04"",""NYT10-HRL"",""NYT11-HRL"",""Wiki-KBP""]')
args = parser.parse_args()


if __name__ == '__main__':
    # pre-trained bert model config
    bert_model = 'cased_L-12_H-768_A-12'
    bert_config_path = 'pretrained_bert_models/' + bert_model + '/bert_config.json'
    bert_vocab_path = 'pretrained_bert_models/' + bert_model + '/vocab.txt'
    bert_checkpoint_path = 'pretrained_bert_models/' + bert_model + '/bert_model.ckpt'

    dataset = args.dataset
    train_path = 'data/' + dataset + '/train_triples.json'
    dev_path = 'data/' + dataset + '/dev_triples.json'
    #test_path = 'data/' + dataset + '/test_split_by_num/test_triples_5.json' # ['1','2','3','4','5']
    #test_path = 'data/' + dataset + '/test_split_by_type/test_triples_seo.json' # ['normal', 'seo', 'epo']
    test_path = 'data/' + dataset + '/test_triples.json' # overall test
    rel_dict_path = 'data/' + dataset + '/rel2id.json'
    save_weights_path = 'saved_weights/' + dataset + '/best_model.weights'
    
    LR = 1e-5
    tokenizer = get_tokenizer(bert_vocab_path)
    train_data, dev_data, test_data, id2rel, rel2id, num_rels = load_data(train_path, dev_path, test_path, rel_dict_path)
    subject_model, object_model, hbt_model = E2EModel(bert_config_path, bert_checkpoint_path, LR, num_rels)
    
    if args.train:
        BATCH_SIZE = 6
        EPOCH = 100
        MAX_LEN = 100
        STEPS = len(train_data) // BATCH_SIZE
        data_manager = data_generator(train_data, tokenizer, rel2id, num_rels, MAX_LEN, BATCH_SIZE)
        evaluator = Evaluate(subject_model, object_model, tokenizer, id2rel, dev_data, save_weights_path)
        hbt_model.fit_generator(data_manager.__iter__(),
                              steps_per_epoch=STEPS,
                              epochs=EPOCH,
                              callbacks=[evaluator]
                              )
    else:
        hbt_model.load_weights(save_weights_path)
        test_result_path = 'results/' + dataset + '/test_result.json'
        isExactMatch = True if dataset == 'Wiki-KBP' else False
        if isExactMatch:
            print(""Exact Match"")
        else:
            print(""Partial Match"")
        precision, recall, f1_score = metric(subject_model, object_model, test_data, id2rel, tokenizer, isExactMatch, test_result_path)
        print(f'{precision}\\t{recall}\\t{f1_score}')

`
#35100 "
tensorflow/tensorflow,2023-05-23 22:52:30,question,Tensorflow Object Detection Project,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

tf1.x

### Custom Code

No

### OS Platform and Distribution

Macos Ventura

### Mobile device

Macbook air 2020 i3

### Python version

3.10.11

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

So i am making an object detection projetc for school and i need help whenever i run this code this is the error that pops up. Please help it is due in a few days

I have installed all neccesary modules, i think

### Standalone code to reproduce the issue

```shell
#!/usr/bin/env python
# coding: utf-8
""""""
Detect Objects Using Your Webcam
================================
""""""

# %%
# This demo will take you through the steps of running an ""out-of-the-box"" detection model to
# detect objects in the video stream extracted from your camera.

# %%
# Create the data directory
# ~~~~~~~~~~~~~~~~~~~~~~~~~
# The snippet shown below will create the ``data`` directory where all our data will be stored. The
# code will create a directory structure as shown bellow:
#
# .. code-block:: bash
#
#     data
#     └── models
#
# where the ``models`` folder will will contain the downloaded models.
import os
#os.chdir( '/Users/akulthota/Desktop/Object Detection' )

DATA_DIR = os.path.join(os.getcwd(), 'data')
MODELS_DIR = os.path.join(DATA_DIR, 'models')
for dir in [DATA_DIR, MODELS_DIR]:
    if not os.path.exists(dir):
        os.mkdir(dir)

# %%
# Download the model
# ~~~~~~~~~~~~~~~~~~
# The code snippet shown below is used to download the object detection model checkpoint file,
# as well as the labels file (.pbtxt) which contains a list of strings used to add the correct
# label to each detection (e.g. person).
#
# The particular detection algorithm we will use is the `SSD ResNet101 V1 FPN 640x640`. More
# models can be found in the `TensorFlow 2 Detection Model Zoo <https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md>`_.
# To use a different model you will need the URL name of the specific model. This can be done as
# follows:
#
# 1. Right click on the `Model name` of the model you would like to use;
# 2. Click on `Copy link address` to copy the download link of the model;
# 3. Paste the link in a text editor of your choice. You should observe a link similar to ``download.tensorflow.org/models/object_detection/tf2/YYYYYYYY/XXXXXXXXX.tar.gz``;
# 4. Copy the ``XXXXXXXXX`` part of the link and use it to replace the value of the ``MODEL_NAME`` variable in the code shown below;
# 5. Copy the ``YYYYYYYY`` part of the link and use it to replace the value of the ``MODEL_DATE`` variable in the code shown below.
#
# For example, the download link for the model used below is: ``download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz``
import tarfile
import urllib.request

# Download and extract model
MODEL_DATE = '20200711'
MODEL_NAME = 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'
MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'
MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'
MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME
PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)
PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))
PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))
if not os.path.exists(PATH_TO_CKPT):
    print('Downloading model. This may take a while... ', end='')
    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)
    tar_file = tarfile.open(PATH_TO_MODEL_TAR)
    tar_file.extractall(MODELS_DIR)
    tar_file.close()
    os.remove(PATH_TO_MODEL_TAR)
    print('Done')

# Download labels file
LABEL_FILENAME = 'mscoco_label_map.pbtxt'
LABELS_DOWNLOAD_BASE = \\
    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'
PATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))
if not os.path.exists(PATH_TO_LABELS):
    print('Downloading label file... ', end='')
    import ssl
    ssl._create_default_https_context = ssl._create_unverified_context
    urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)
    print('Done')

# %%
# Load the model
# ~~~~~~~~~~~~~~
# Next we load the downloaded model

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging
import tensorflow as tf
from object_detection.utils import label_map_util

from object_detection.utils import visualization_utils as vis_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.builders import model_builder

tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)

# Enable GPU dynamic memory allocation
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

# Load pipeline config and build a detection model
configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)
model_config = configs['model']
detection_model = model_builder.build(model_config=model_config, is_training=False)

# Restore checkpoint
ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)
ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()

@tf.function
def detect_fn(image):
    """"""Detect objects in image.""""""

    image, shapes = detection_model.preprocess(image)
    prediction_dict = detection_model.predict(image, shapes)
    detections = detection_model.postprocess(prediction_dict, shapes)

    return detections, prediction_dict, tf.reshape(shapes, [-1])


# %%
# Load label map data (for plotting)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Label maps correspond index numbers to category names, so that when our convolution network
# predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility
# functions, but anything that returns a dictionary mapping integers to appropriate string labels
# would be fine.
category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,
                                                                    use_display_name=True)

# %%
# Define the video stream
# ~~~~~~~~~~~~~~~~~~~~~~~
# We will use `OpenCV <https://pypi.org/project/opencv-python/>`_ to capture the video stream
# generated by our webcam. For more information you can refer to the `OpenCV-Python Tutorials <https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html#capture-video-from-camera>`_
import cv2

cap = cv2.VideoCapture(0)

# %%
# Putting everything together
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
# The code shown below loads an image, runs it through the detection model and visualizes the
# detection results, including the keypoints.
#
# Note that this will take a long time (several minutes) the first time you run this code due to
# tf.function's trace-compilation --- on subsequent runs (e.g. on new images), things will be
# faster.
#
# Here are some simple things to try out if you are curious:
#
# * Modify some of the input images and see if detection still works. Some simple things to try out here (just uncomment the relevant portions of code) include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).
# * Print out `detections['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).
# * Set ``min_score_thresh`` to other values (between 0 and 1) to allow more detections in or to filter out more detections.
import numpy as np

while True:
    # Read frame from camera
    ret, image_np = cap.read()

    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
    image_np_expanded = np.expand_dims(image_np, axis=0)

    # Things to try:
    # Flip horizontally
    # image_np = np.fliplr(image_np).copy()

    # Convert image to grayscale
    # image_np = np.tile(
    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)
    detections, predictions_dict, shapes = detect_fn(input_tensor)

    label_id_offset = 1
    image_np_with_detections = image_np.copy()

    viz_utils.visualize_boxes_and_labels_on_image_array(
          image_np_with_detections,
          detections['detection_boxes'][0].numpy(),
          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),
          detections['detection_scores'][0].numpy(),
          category_index,
          use_normalized_coordinates=True,
          max_boxes_to_draw=200,
          min_score_thresh=.30,
          agnostic_mode=False)

    # Display output
    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))

    if cv2.waitKey(25) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/Users/akulthota/Desktop/Object/object_detection_camera.py"", line 92, in <module>
    from object_detection.utils import label_map_util
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/object_detection/utils/label_map_util.py"", line 21, in <module>
    from object_detection.protos import string_int_label_map_pb2
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/object_detection/protos/string_int_label_map_pb2.py"", line 36, in <module>
    _descriptor.FieldDescriptor(
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 561, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot not be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates
```
</details>"
tensorflow/tensorflow,2023-05-21 08:18:10,question,TypeError: Cannot convert 0.1 to EagerTensor of dtype int64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.12.0

### Custom Code

Yes

### OS Platform and Distribution

GoogleColab

### Mobile device

_No response_

### Python version

3.10.11

### Bazel version

colab

### GCC/Compiler version

colab

### CUDA/cuDNN version

colab

### GPU model and memory

colab

### Current Behaviour?

getting this error when i execute the code present in tensowflow website to implement tf.keras.optimizers.schedules.LearningRateSchedule 
error:

TypeError: Cannot convert 0.1 to EagerTensor of dtype int64

```python
class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):

  def __init__(self, initial_learning_rate):
    self.initial_learning_rate = initial_learning_rate

  def __call__(self, step):
     return self.initial_learning_rate / (step + 1)

optimizer = tf.keras.optimizers.SGD(learning_rate=MyLRSchedule(0.1))

```

### Standalone code to reproduce the issue

```shell
TypeError: Cannot convert 0.1 to EagerTensor of dtype int64
```


### Relevant log output

TypeError                                 Traceback (most recent call last)
[<ipython-input-145-86d045432fd5>](https://localhost:8080/#) in <cell line: 9>()
      7      return self.initial_learning_rate / (step + 1)
      8 
----> 9 optimizer = tf.keras.optimizers.SGD(learning_rate=MyLRSchedule(0.1))

4 frames
[/usr/local/lib/python3.10/dist-packages/keras/optimizers/sgd.py](https://localhost:8080/#) in __init__(self, learning_rate, momentum, nesterov, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)
    121             **kwargs
    122         )
--> 123         self._learning_rate = self._build_learning_rate(learning_rate)
    124         self.momentum = momentum
    125         self.nesterov = nesterov

[/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py](https://localhost:8080/#) in _build_learning_rate(self, learning_rate)
    382                 # Create a variable to hold the current learning rate.
    383                 current_learning_rate = tf.convert_to_tensor(
--> 384                     learning_rate(self.iterations)
    385                 )
    386                 self._current_learning_rate = tf.Variable(

[<ipython-input-145-86d045432fd5>](https://localhost:8080/#) in __call__(self, step)
      5 
      6   def __call__(self, step):
----> 7      return self.initial_learning_rate / (step + 1)
      8 
      9 optimizer = tf.keras.optimizers.SGD(learning_rate=MyLRSchedule(0.1))

[/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py](https://localhost:8080/#) in error_handler(*args, **kwargs)
    151     except Exception as e:
    152       filtered_tb = _process_traceback_frames(e.__traceback__)
--> 153       raise e.with_traceback(filtered_tb) from None
    154     finally:
    155       del filtered_tb

[/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py](https://localhost:8080/#) in convert_to_eager_tensor(value, ctx, dtype)
    101       dtype = dtypes.as_dtype(dtype).as_datatype_enum
    102   ctx.ensure_initialized()
--> 103   return ops.EagerTensor(value, ctx.device_name, dtype)
    104 
    105 

TypeError: Cannot convert 0.1 to EagerTensor of dtype int64

</details>"
tensorflow/tensorflow,2023-05-18 11:42:10,question,unable to compile tensorflow c++ code using cmake ,"i followed this steps

1) i cloned the repo

2) cd tensorflow

3) mkdir examples

in examples folder i created helloworld.cc file and cmakelist.txt

this is cmakelist.txt file 

cmake_minimum_required(VERSION 3.8.0)
project(examples)

# Specify the path to the TensorFlow source directory
set(TENSORFLOW_SOURCE_DIR ""D:/github_issues/tensorflow/tensorflow"")

# Add the TensorFlow source directory to the CMake module path
list(APPEND CMAKE_MODULE_PATH ""${TENSORFLOW_SOURCE_DIR}/cmake"")

# Add the TensorFlow include directories
include_directories(${TENSORFLOW_SOURCE_DIR})
include_directories(${TENSORFLOW_SOURCE_DIR}/tensorflow/cc)
include_directories(${TENSORFLOW_SOURCE_DIR}/tensorflow/core)

# Build the hello-world executable
add_executable(hello-world hello-world.cc)
target_link_libraries(hello-world tensorflow)


after running the command cmake --build . --config Release

i got this error 

D:\\github_issues\\tensorflow\\examples\\hello-world.cc(1,10): fatal  error C1083: Cannot open include file: 'tensorflow/cc/client/cl
ient_session.h': No such file or directory [[D:\\github_issues\\tensorflow\\examples\\build\\hello-world.vcxproj]]
![2](https://github.com/tensorflow/tensorflow/assets/85454586/3a8c3dae-fcd6-48c0-bf89-bb64af5bccfc)
![3](https://github.com/tensorflow/tensorflow/assets/85454586/61d90c15-2468-47cf-a074-e1190693bd4a)
![4](https://github.com/tensorflow/tensorflow/assets/85454586/359b81e6-30f9-43dc-bc04-f563726bc2c4)
![5](https://github.com/tensorflow/tensorflow/assets/85454586/6796388f-0f45-40b7-a369-47c6586e31c1)




"
tensorflow/tensorflow,2023-05-13 06:17:23,question,Shuffle flag is true in make_dataset function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.0

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Just replicating an example of Time Series forecasting from link [TSF](https://www.tensorflow.org/tutorials/structured_data/time_series#recurrent_neural_network)

There is a function make_dataset which uses timeseries_dataset_from_array.
The function timeseries_dataset_from_array shuffle flag is set to true which is not allowed in time series forecasting.


### Standalone code to reproduce the issue

```shell
def make_dataset(self, data):
  data = np.array(data, dtype=np.float32)
  ds = tf.keras.utils.timeseries_dataset_from_array(
      data=data,
      targets=None,
      sequence_length=self.total_window_size,
      sequence_stride=1,
      shuffle=True,
      batch_size=32,)

  ds = ds.map(self.split_window)

  return ds

WindowGenerator.make_dataset = make_dataset
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-05-12 00:44:02,question,Building from source with clang and nvcc?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

Debian GNU/Linux 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

gcc9/clang12

### CUDA/cuDNN version

11.3

### GPU model and memory

Nvidia T4

### Current Behaviour?

The docs say that TF 2.11 is supported with gcc 9, but clang/llvm builds significantly faster. How can I use bazel to at least try to build using clang and nvcc at the same time?

Changing GCC_HOST_COMPILER_PATH=""<clang-path>"" fails. Using my own crosstool-top with clang seems to work, but I'm not sure if this ends up building the CUDA kernels with clang as well.

### Standalone code to reproduce the issue

```shell
# from .bazelrc

build --crosstool_top=//toolchain:clang_suite

build:cuda --repo_env TF_NEED_CUDA=1
# build:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain
build:cuda --@local_config_cuda//:enable_cuda

build:tf_gpu --action_env PYTHON_BIN_PATH=""/opt/conda/bin/python3""
build:tf_gpu --action_env PYTHON_LIB_PATH=""/bin""
build:tf_gpu --python_path=""/opt/conda/bin/python3""
build:tf_gpu --action_env PYTHONPATH=""/home/axlui/p3achyGo/python:/usr/lib/llvm-12/bin:/home/axlui/.local/bin:/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin""
build:tf_gpu --define=with_xla_support=true
build:tf_gpu --action_env TF_CUDA_VERSION=""11""
build:tf_gpu --action_env TF_CUDNN_VERSION=""8""
build:tf_gpu --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-11.3""
build:tf_gpu --action_env CUDNN_INSTALL_PATH=""/usr/local/cuda""
build:tf_gpu --action_env TF_CUDA_COMPUTE_CAPABILITIES=""7.5""
build:tf_gpu --action_env LD_LIBRARY_PATH=""/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64""
build:tf_gpu --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/x86_64-linux-gnu-gcc-9""
# build:tf_gpu --action_env CC=""/usr/lib/llvm-12/bin/clang""
# build:tf_gpu --action_env CXX=""/usr/lib/llvm-12/bin/clang++""
# build:tf_gpu --action_env GCC_HOST_COMPILER_PATH=""/usr/lib/llvm-12/bin/clang""
build:tf_gpu --config=cuda
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-05-09 15:10:48,question,Issue when importing pix2pix in Google Colab,"Hello, I wanted to use pix2pix in Google Colab and here is the command I used to import it:

!pip install git+https://github.com/tensorflow/examples.git

I also tried !pip install -q git+https://github.com/tensorflow/examples.git

But for both request, I get this error:

Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting git+https://github.com/tensorflow/examples.git
  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-z5dheb37
  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/examples.git /tmp/pip-req-build-z5dheb37
  Resolved https://github.com/tensorflow/examples.git to commit 1ca61321294cd2e97efc021ff1b3700b42befd0b
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> See above for output.
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  Preparing metadata (setup.py) ... error
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.

Could you please repair it?
Best regards

P.S.: If there is any way for me to use pix2pix in an alternative way, could you please indicate me on how to do it because I did not found an alternative."
tensorflow/tensorflow,2023-05-08 16:55:32,question,Getting error with using coco-ssd model with the latest tensorflow,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

4.5.0

### Custom Code

Yes

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

when I try to use the net.detect(frame), it throws me error:
TypeError: _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__.util.convertBackendValuesAndArrayBuffer is not a function
    at MathBackendCPU.readSync (backend_cpu.js:99:1)
    at Engine.readSync (engine.js:943:1)
    at Tensor.dataSync (tensor.js:297:1)
    at d.infer (coco-ssd.es2017.esm.min.js:17:1)
Even though I am using the latest tensorflow JS libraries.

### Standalone code to reproduce the issue

```shell
I am trying to use the coco-ssd model to do object detection. In my package.json I have:
    ""@tensorflow-models/coco-ssd"": ""^2.2.2"",
    ""@tensorflow/tfjs"": ""^4.5.0"",
    ""@tensorflow/tfjs-backend-cpu"": ""^4.5.0"",
    ""@tensorflow/tfjs-backend-webgl"": ""^4.5.0"",

for some reasons, I want to use the latest tensorflow libraries, as my project uses other things also.
I have the following code:
const tf = require('@tensorflow/tfjs');
const _tfCPUBackend = require('@tensorflow/tfjs-backend-cpu');
const _tfWebglBackend = require('@tensorflow/tfjs-backend-webgl');
const cocoSsd = require('@tensorflow-models/coco-ssd');

I have also set the tf.setBackend('webgl'), and tf.ready() before cocoSsd.load()
but when I try to use the net.detect(frame), it throws me error:
TypeError: _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__.util.convertBackendValuesAndArrayBuffer is not a function
    at MathBackendCPU.readSync (backend_cpu.js:99:1)
    at Engine.readSync (engine.js:943:1)
    at Tensor.dataSync (tensor.js:297:1)
    at d.infer (coco-ssd.es2017.esm.min.js:17:1)
Even though I am using the latest tensorflow JS libraries.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-05-05 13:08:01,question,How does average pooling function work in TensorFlow?,"Let us assume a tensor like this:

```
x = tf.constant([[1., 2., 3.],
                  [4., 5., 6.],
                  [7., 8., 9.]])
```

To apply the average pooling function, I will do this:

```
x = tf.reshape(x, [1, 3, 3, 1])
avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),strides=(2, 2), padding='same')
avg_pool_2d(x)
```

The result is:

```
<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=
array([[[[3. ],
         [4.5]],
        [[7.5],
         [9. ]]]], dtype=float32)>
```

I can follow the logic above:

```
(1+2+4+5)/4 = 3
(3+6)/2 = 4.5
(7+8)/2 = 7.5
(9/1) = 9
```

**I think the logic is:**  The pooling filter is usually situated inside the tensor to perform the pooling operator. But when the entire filter does not situate inside the tensor (see the below figure for an example), we need to specify the number of elements of the filter that are situated inside the tensor (a). The following figure illustrates the logic for a 4 by 3 tensor, with pooling filter and stride sizes of 2 by 2, and padding the same.

![image](https://user-images.githubusercontent.com/82632526/236491612-8b6b6fee-414a-4dd6-ba7d-98c77713a7c9.png)

However, it is not always like this. For example, suppose the following tensor:

```
y = tf.constant([[1., 2., 3., 4., 5.],
                         [6., 7., 8., 9., 10.]])
```

Then, I do this:

```
y = tf.reshape(y, [1, 2, 5, 1])
avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(4, 4),strides=(4, 4), padding='same')
avg_pool_2d(y)
```

The result is like this:

```
    <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=
array([[[[4.5 ],
         [7.]]]], dtype=float32)>
```

If I wanted to follow the logic for the first example, I expected the result to be like this:

```
(1+2+3+4+6+7+8+9)/8 = 5
(5+10)/2 = 7.5
```

I am using TensorFlow 2.8.0. What mistake am I making?"
tensorflow/tensorflow,2023-05-03 14:22:06,question,xla_sharding in new version,"Hi
What is the replacement for `from tensorflow.compiler.xla.experimental.xla_sharding import xla_sharding` in TF-2.12.0? For example, the function is `xla_sharding.split()`."
tensorflow/tensorflow,2023-04-29 15:58:11,question,We don't have your exam ready right now ," I had purchased the tensorflow exam and tried to start it, but it is showing that we don't have your exam ready right now.but in the candidate portal it is showing resume.so i am gonna post the screenshot of my problem 
<img width=""960"" alt=""Screenshot 2023-04-28 114949"" src=""https://user-images.githubusercontent.com/132153955/235311840-6b7d464f-46e7-4389-8135-db36f93b0605.png"">

"
tensorflow/tensorflow,2023-04-21 05:06:49,question,Unequal strides support recently removed for DepthwiseConv2D,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**: 2.9 and 2.11
-   **Python version**: 3.8
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: 11.2 and 8.1
-   **GPU model and memory**:
-   **Exact command to reproduce**:

import tensorflow as tf
import numpy as np
layer1 = tf.keras.layers.DepthwiseConv2D(depth_multiplier=2,kernel_size=(1,9),strides=(1,2))
print(layer1(np.ones((100, 28, 28, 1), dtype=np.float32)))

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The command would run without any error when I was using it with TF2.11 version installed previously. On the newly installed TF2.9 version, however, the code throws an error as:
InvalidArgumentError: Exception encountered when calling layer 'depthwise_conv2d_1' (type DepthwiseConv2D).
{{function_node __wrapped__DepthwiseConv2dNative_device_/job:localhost/replica:0/task:0/device:CPU:0}} Current implementation only supports equal length strides in the row and column dimensions. [Op:DepthwiseConv2dNative]
Call arguments received by layer 'depthwise_conv2d_1' (type DepthwiseConv2D):
  • inputs=tf.Tensor(shape=(100, 28, 28, 1), dtype=float32)

Seeing the documentation, the error is expected for version 2.12, but should work for versions 2.9 and 2.11
https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/layers/DepthwiseConv2D
https://www.tensorflow.org/versions/r2.11/api_docs/python/tf/keras/layers/DepthwiseConv2D
https://www.tensorflow.org/versions/r2.12/api_docs/python/tf/keras/layers/DepthwiseConv2D

Is it that the implementation existing in the earlier versions has been removed recently for all previous and current versions?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
tensorflow/tensorflow,2023-04-18 09:19:55,question,data and ml module missing,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2

### Custom Code

No

### OS Platform and Distribution

mac

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

A bug happened!

### Standalone code to reproduce the issue

```shell
from data import BodyPart
from ml import Movenet
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-04-17 03:30:02,question,Training data format for EfficientNet,"I would like to train a EfficientNetB7 model from scratch to classify 2D arrays into two 2 classes, but it seems like I did not prepare my data in the correct format. Currently my `x_train` is a list of float64 arrays with a 600x600 size, my `y_train` is a list of integers that are either 0 or 1. Of course `x_train` and `y_train` have the same length. This is what I have so far:
```
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.applications import EfficientNetB7
from tensorflow.keras.models import Sequential

base_model = EfficientNetB7(include_top=False, weights=None, input_shape=(600,600,1), classes=2)
base_model.trainable = True
model = Sequential()
model.add(base_model)
model.add(Flatten())
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, batch_size=8, epochs=100)
```
The last line currently gives me an error: 
```
ValueError: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {""<class 'numpy.ndarray'>""}), (<class 'list'> containing values of types {""<class 'int'>""})
```
What would be the right format for training data? Any help is appreciated! "
tensorflow/tensorflow,2023-04-14 08:26:21,question,Issue with obtaining files from this repo via Google Colab,"![Screenshot 2023-04-14 162503](https://user-images.githubusercontent.com/93562563/231988319-e5946ae6-30fe-4237-9617-c08e8ee8104c.png)
"
tensorflow/tensorflow,2023-04-08 07:24:56,question,tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
tensorflow/tensorflow,2023-04-03 14:07:06,question,Tensorflow Lite library is crashing in WASM library at 3rd inference,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.7.0

### Custom Code

Yes

### OS Platform and Distribution

Emscripten, Ubuntu 18.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hello! I have C++ code that I want to deploy as WASM library and this code contains TFLite library. I have compiled TFLite library with XNNPack support using Emscripten toolchain quite easy, so no issue there. I have a leight-weight convolution+dense model that runs perfectly on Desktop, but I am starting having problems in the browser.

In 99% of cases I have an error on the third inference:

Uncaught RuntimeError: memory access out of bounds

Through some trivial debugging I have found out that the issue comes from _interpreter->Invoke() method. Does not matter if I put any input or not, I just need to call Invoke() three times and I have a crash.

First thing first: I decided to add more memory to my WASM library by adding this line to CMake:

SET(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -s TOTAL_STACK=134217728 -s TOTAL_MEMORY=268435456"")
SET(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -s TOTAL_STACK=134217728 -s TOTAL_MEMORY=268435456"")

128 MB and 256 MB in total for 1 MB model - I think this is more than enough. And on top of that, I am allowing Memory Growth. But unfortunately, I have exactly the same issue.

I am beating on this problem for 2 weeks straight and at this stage I have no clue how to fix it. Also I have tried to set custom allocation using TfLiteCustomAllocation but in this case I have a crash on the very first inference. I guess I was not using it right, but unfortunately I couldn't find even one tutorial describing how to apply custom allocation in TFLite.

I said that I have a crash in 99% of cases. There was one time when WASM library worked and inference worked as well. It happens just randomly once, and I couldn't reproduce it anymore.
```


### Standalone code to reproduce the issue

```shell
Here is the code that does TFLite inference


#include <cstdlib>
#include ""tflite_model.h""
#include <iostream>

#include ""tensorflow/lite/interpreter.h""
#include ""tensorflow/lite/util.h""

namespace tracker {

#ifdef EMSCRIPTEN
	void TFLiteModel::init(std::stringstream& stream) {

		std::string img_str = stream.str();
		std::vector<char> img_model_data(img_str.size());
		std::copy(img_str.begin(), img_str.end(), img_model_data.begin());

		_model = tflite::FlatBufferModel::BuildFromBuffer(img_str.data(), img_str.size());
#else
	void TFLiteModel::init(const std::string& path) {
		_model = tflite::FlatBufferModel::BuildFromFile(path.c_str());

#endif

		tflite::ops::builtin::BuiltinOpResolver resolver;
		tflite::InterpreterBuilder(*_model, resolver)(&_interpreter);

		_interpreter->AllocateTensors();

		/*for (int i = 0; i < _interpreter->tensors_size(); i++) {
			TfLiteTensor* tensor = _interpreter->tensor(i);

			if (tensor->allocation_type == kTfLiteArenaRw || tensor->allocation_type == kTfLiteArenaRwPersistent) {

				int aligned_bytes = tensor->bytes + (tflite::kDefaultTensorAlignment - tensor->bytes % tflite::kDefaultTensorAlignment) % tflite::kDefaultTensorAlignment;

				TfLiteCustomAllocation customAlloc;
				int result = posix_memalign(&customAlloc.data, tflite::kDefaultTensorAlignment, tensor->bytes);
				if (result != 0 || customAlloc.data == NULL) {
					std::cout << ""posix_memalign does not work!\\n"";
				}

				TfLiteStatus st = _interpreter->SetCustomAllocationForTensor(i, customAlloc);
				std::cout << ""status = "" << st << std::endl;
				if (tensor->bytes % tflite::kDefaultTensorAlignment != 0) {
					std::cout << ""bad! i "" << i << "", size "" << tensor->bytes << std::endl;
				}
				_allocations.push_back(customAlloc);
			}
		}
		exit(0);*/
	}

	void TFLiteModel::forward(const cv::Mat& img_input, const std::vector<float>& lms_input) {

		float* model_in = _interpreter->typed_input_tensor<float>(0);
		std::memcpy(model_in, img_input.data, img_input.total() * img_input.elemSize());

		float* lms_in = _interpreter->typed_input_tensor<float>(1);
		std::memcpy(lms_in, lms_input.data(), sizeof(float) * lms_input.size());
		
		_interpreter->Invoke();
	}

	float* TFLiteModel::out() {
		return _interpreter->typed_output_tensor<float>(0);
	}

	std::vector<int> TFLiteModel::getOutputShape() const {
		TfLiteTensor* outtensor = _interpreter->output_tensor(0);
		TfLiteIntArray* dims = outtensor->dims;

		std::vector<int> sh;
		for (int i = 0; i < dims->size; i++) {
			sh.push_back(dims->data[i]);
		}

		return sh;
	}
}
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-03-31 00:51:24,question,How to evaluate a pretrained TF mobilenet_v2 saved_model for accuracy on test dataset,"
### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**:2.11
-   **Python version**: 3.9

### Describe the problem
How can i use a pretrained saved_model and find its accuracy on a test dataset?

I have mobilenet_v2 saved model which is sourced from https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5

I have an imagenet validation dataset consisting of 50000 images, and a labels.txt file consisting of ground truth labels for those 50000 images. 

I also have ImageNetLabels.txt sourced from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt consisting of 1001 imagenet classes. 

How do I preprocess this data so that i can run evaluate() function to find test_data loss and accuracy of this pretrained model?

I am currently using the below script, but it doesn't seem to work:

```
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import os

m = tf.keras.Sequential([hub.KerasLayer(""https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"", output_shape=(1001,))])
m.build([None, 224, 224, 3])# Batch input shape.
images = '/home/Downloads/ILSVRC2012_img_val'
classes = '/home/Documents/ImageNetLabels.txt'
labels ='/home/Documents/val.txt'

with open(labels, 'r') as f:
	label_name = [line.strip() for line in f.readlines()]

class_map = {}
with open(classes, 'r') as f:
	classes = [line.strip() for line in f]
	for i, class_name in enumerate(classes):
		class_map[class_name] = i

test_labels=[]
for label in label_name:
	if label in class_map:
		test_labels.append(class_map[label])
	else:
		print(f""label '{label} not found in class_map"")

image_paths = [os.path.join(images, filename) for filename in os.listdir(images)]
dataset = tf.data.Dataset.from_tensor_slices((image_paths, test_labels))
def preprocess_image(image_path):
	image = tf.io.read_file(image_path)
	image = tf.image.decode_jpeg(image, channels=3)
	image = tf.image.resize(image, [224,224])
	image = tf.image.convert_image_dtype(image, tf.float32)
	image /= 255.0
	return image

dataset = dataset.map(lambda image_path, label: (preprocess_image(image_path), label))

dataset = dataset.batch(batch_size=32)
m.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
loss, accuracy = m.evaluate(dataset)
print('loss: ', loss)
print('accuracy: ', accuracy)
```

I get the below error here:

> Traceback (most recent call last):
>   File ""test1234.py"", line 74, in <module>
>     loss, accuracy = m.evaluate(dataset)
>   File ""/home/mtk/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler
>     raise e.with_traceback(filtered_tb) from None
>   File ""/tmp/__autograph_generated_filemqiwcebs.py"", line 15, in tf__test_function
>     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
> ValueError: in user code:
> 
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1820, in test_function  *
>         return step_function(self, iterator)
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1804, in step_function  **
>         outputs = model.distribute_strategy.run(run_step, args=(data,))
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1792, in run_step  **
>         outputs = model.test_step(data)
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1758, in test_step
>         self.compute_loss(x, y, y_pred, sample_weight)
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1082, in compute_loss
>         return self.compiled_loss(
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py"", line 265, in __call__
>         loss_value = loss_obj(y_t, y_p, sample_weight=sw)
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/losses.py"", line 152, in __call__
>         losses = call_fn(y_true, y_pred)
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/losses.py"", line 284, in call  **
>         return ag_fn(y_true, y_pred, **self._fn_kwargs)
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/losses.py"", line 2004, in categorical_crossentropy
>         return backend.categorical_crossentropy(
>     File ""/home/mtk/.local/lib/python3.8/site-packages/keras/backend.py"", line 5532, in categorical_crossentropy
>         target.shape.assert_is_compatible_with(output.shape)
> 
>     ValueError: Shapes (None, 1) and (None, 1001) are incompatible

I assume something is wrong in the way I preprocess my data though, but not sure how to go about it. Some insights would be nice
thanks"
tensorflow/tensorflow,2023-03-30 10:43:46,question,Docs do not mention discontinuation of support for Python 3.7 in TF 2.11.1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

tf 2.11.1

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The release notes for TensorFlow 2.12.0 state that support for Python 3.7 has been discontinued. However, it seems that Python 3.7 support has also been removed from TensorFlow 2.11.1, despite this not being mentioned in the release notes or documentation. As a result, to maintain compatibility, we were forced to limit our application to using TensorFlow 2.11.0.
```


### Standalone code to reproduce the issue

```shell
NA
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-03-29 14:59:40,question,JVP using tf.autodiff.ForwardAccumulator becomes None under graph execution,"I'm new to Tensorflow. I'm trying to compute a Jacobian-Vector Product using tf.autodiff.ForwardAccumulator with a train function looks something like the code below. The jvp looks fine under eager execution. However, the jvp becomes a list of Nones when activate graph execution using @tf.function. 
What could be the issue here?

### Tensorflow Version

tf 2.6.0

### Python version

3.7

### Train code

```shell
@tf.function
def train(self, data):
        with tf.GradientTape() as upper_tape:
            loss1= self.loss1(data)
        grad1 = upper_tape.gradient(loss1, self.net1.variables)

        with tf.autodiff.ForwardAccumulator(primals=self.net1.variables, tangents=grad1) as acc:
            with tf.GradientTape() as lower_tape:
                loss2 = self.loss2(data)
            grad2 = lower_tape.gradient(loss2, self.net2.variables)

        final_grad = acc.jvp(grad2)
        self.optimizer.apply_gradients(zip(final_grad, self.net2.variables))
```

grad1 and grad2 are correctly computed under both eager mode and graph mode. The only problem is with the jvp."
tensorflow/tensorflow,2023-03-29 03:29:10,question,spam removed,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
tensorflow/tensorflow,2023-03-28 17:56:08,question,Build TensorFlow Lite for iOS failed!!!!,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. `bazel build --config=ios_arm64 -c opt --cxxopt=--std=c++17 \\
  //tensorflow/lite/ios:TensorFlowLiteC_framework
❯ bazel build --incompatible_run_shell_command_string=false --verbose_failures --config=ios_arm64 -c opt //tensorflow/lite/ios:TensorFlowLiteCMetal_framework
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=170
INFO: Reading rc options for 'build' from /Users/thao/Desktop/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/thao/Desktop/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false
INFO: Reading rc options for 'build' from /Users/thao/Desktop/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/Users/thao/miniforge3/bin/python --action_env PYTHON_LIB_PATH=/Users/thao/miniforge3/lib/python3.10/site-packages --python_path=/Users/thao/miniforge3/bin/python
INFO: Reading rc options for 'build' from /Users/thao/Desktop/tensorflow/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /Users/thao/Desktop/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/thao/Desktop/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:ios_arm64 in file /Users/thao/Desktop/tensorflow/.bazelrc: --config=ios --cpu=ios_arm64
INFO: Found applicable config definition build:ios in file /Users/thao/Desktop/tensorflow/.bazelrc: --apple_platform_type=ios --apple_bitcode=embedded --copt=-fembed-bitcode --copt=-Wno-c++11-narrowing --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --define=with_xla_support=false
INFO: Build option --cxxopt has changed, discarding analysis cache.
ERROR: /private/var/tmp/_bazel_thao/26d40dc75f2c247e7283b353a9ab184f/external/local_config_cc/BUILD:48:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'ios_arm64'
ERROR: /private/var/tmp/_bazel_thao/26d40dc75f2c247e7283b353a9ab184f/external/local_config_cc/BUILD:48:19: Analysis of target '@local_config_cc//:toolchain' failed
ERROR: Analysis of target '//tensorflow/lite/ios:TensorFlowLiteCMetal_framework' failed; build aborted: 
INFO: Elapsed time: 45.455s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (66 packages loaded, 1118 targets configured)`

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
MacOS-M1Max : 13.3
Tensorflow:2.9.2
Python: 3.10.0



### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
tensorflow/tensorflow,2023-03-27 02:11:19,question,Thread-safety for `tensorflow::Tensor`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

Yes

### OS Platform and Distribution

Debian GNU/Linux 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

6.1.0

### GCC/Compiler version

LLVM 12

### CUDA/cuDNN version

11.6

### GPU model and memory

T4

### Current Behaviour?

```shell
Are there any methods on `tensorflow::Tensor` objects that are thread-safe? Specifically, any of

SubSlice()
flat(), unaligned_flat(), shaped().
```


### Standalone code to reproduce the issue

```shell
std::vector<Tensor> output;
Mutex mu;
bool ready = false;

void Eval() {
  output = {Tensor(DataType::DT_HALF, {2, 16}); // one entry per thread
  nn_evaluator_.Infer(<some_input>, <some_names>, &output);

  mu.Lock();
  ready = true;
  mu.Unlock();
}

void ReadResult(int thread_id) {
  mu.Lock();
  mu.Await(Condition(&ready));
  mu.Unlock();

  // can we read tensor result now?
  auto res = output[0].SubSlice(thread_id).unaligned_flat<Eigen::half>();
  return res(0);
}
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-03-25 03:19:04,question,If we have any detail information of each CI in tensorflow Github? ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hello, I have been studying the actions (CI) of various open source projects on Github recently.
I noticed that tensorflowhas a well-established CI, so I would like to further understand its composition and structure. Do you have any relevant materials that I can study and refer to? 
Thank you very much.
```


### Standalone code to reproduce the issue

```shell
none
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-03-23 16:27:26,question,Plot training and validation losses of object detection model ,"Hello. I am using the following notebook to train my dataset with **efficientdet-lite0** model. 
https://www.tensorflow.org/lite/models/modify/model_maker/object_detection

I can see for each epoch we get the information of training loss ""loss"" and validation loss ""val_loss"". I would like to plot them like:

loss = model.history['loss']
val_loss = model.history['val_loss']
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

And unfortunately getting the following error **AttributeError: 'ObjectDetector' object has no attribute 'history'** 
Can you help me to figure out how to plot training and validation losses on the same graph. Thanks in advance!"
tensorflow/tensorflow,2023-03-21 06:03:18,question,Type INT32 (2) not supported.Node ADD (number 0) failed to invoke with status 1.Node WHILE (number 10) failed to invoke with status 1,"**System information**
- OS Platform : window10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source):2.3.3
- board: Arduino Nano 33 ble sense



I tried to run TensorFlow Lite for Microcontrollers with Arduino Nano 33 ble sense, the model is my custom LSTM. And the result : 
Type INT32 (2) not supported.Node ADD (number 0) failed to invoke with status 1.Node WHILE (number 10) failed to invoke with status 1.Invoke failed. But it has output values.

![model1 tflite](https://user-images.githubusercontent.com/127216064/226529585-4acac340-fb0b-4f24-a3ea-b1a588c41648.png)



"
tensorflow/tensorflow,2023-03-16 22:12:11,question,How to find accuracy of a pretrained tflite model,"
### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- Ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: None
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: v2.11
-   **Python version**: 3.9

### Describe the problem
I have a pretrained tf mobilenetv2 model downloaded from tfhub which i converted to tflite using tflite interpreter converter. The original model was trained on imagenet dataset, but i want to find out the accuracy of the converted tflite model. How do I do that? As of now, the eval function is specific to models generated from modelmaker. What is the best way to find the model accuracy?

thanks
"
tensorflow/tensorflow,2023-03-15 14:14:05,question,How to benchmark TFLite object detection model,"It seems that only classification models can be benchmarked. There is no explanation for how to run benchmarking on `TFLite` object detection models under https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark. Could anybody point me into the right direction to get the modifications needed to run the `TFLite` benchmark on my custom `TFLite` object detection model?

After running:

```bash
➜  tensorflow git:(master) adb shell am start -S \\                                    
  -n org.tensorflow.lite.benchmark/.BenchmarkModelActivity \\
  --es args '""--graph=/data/local/tmp/my_custom_object_detection_float32.tflite \\
  --num_threads=4""'
```

When I check logcat:

```bash
➜  tensorflow git:(master) adb logcat | grep ""Inference timings in us""
```

I see:

```shell
03-15 14:00:51.294 12836 12836 I tflite  : Inference timings in us: Init: 36618, First inference: 1530248, Warmup (avg): 1.53025e+06, Inference (avg): 1.49712e+06
03-15 14:13:43.409 13393 13393 I tflite  : Inference timings in us: Init: 33412, First inference: 307818, Warmup (avg): 297955, Inference (avg): 333826
```

Basically, my model inference fails and it falls back onto the classification model


<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

### Standalone code to reproduce the issue

```shell
The app falls back onto the classification model once the object detection one fails:

03-15 14:00:51.294 12836 12836 I tflite  : Inference timings in us: Init: 36618, First inference: 1530248, Warmup (avg): 1.53025e+06, Inference (avg): 1.49712e+06
03-15 14:13:43.409 13393 13393 I tflite  : Inference timings in us: Init: 33412, First inference: 307818, Warmup (avg): 297955, Inference (avg): 333826
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-03-14 03:41:01,question,TypeError: VariableMetaclass._variable_v1_call() got an unexpected keyword argument 'experimental_enable_variable_lifting',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

v2.12.0-rc0-46-g0d8efc960d2 2.12.0-rc1

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
self.model = keras.Sequential([
                 ^^^^^^^^^^^^^^^^^^
  File ""C:\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py"", line 205, in _method_wrapper
    result = method(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\variables.py"", line 285, in __call__
    return cls._variable_v1_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: VariableMetaclass._variable_v1_call() got an unexpected keyword argument 'experimental_enable_variable_lifting'
```


### Standalone code to reproduce the issue

```shell
self.model = keras.Sequential([
    keras.layers.Dense(1, input_dim=self.degree),
    keras.layers.Dense(1)
    ])
self.model.compile(optimizer=optimizer, loss=loss)
self.model.summary()
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-03-06 09:09:26,question,Resource exhausted error during training,"Resource exhausted error during training
I would like to train the deep learning task semantic segmentation.
Specifications: model with 31 million  parameters
image size ( minimum 1024x1024), batch size 256 framework -tensorflow keras 2.7
Total image samples 30,000,
Label Mask samples 30,000
Does colab pro plus allow the training for this specification with out OOM error?

Issue currently facing  is even with 2000 number of images and 512x512 size for batch size 32 results in out of memory error in colab pro subscription.
"
tensorflow/tensorflow,2023-03-01 12:05:19,question,`Unsupported object type numpy.ndarray` on multi-input `Dataset`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.11.0

### Custom Code

Yes

### OS Platform and Distribution

Kaggle kernel

### Mobile device

_No response_

### Python version

3.7.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I'm trying to return tuple to a dataset to be used in a multi-input model, but it's throwing an error saying: `Unsupported object type numpy.ndarray`. Previosuly I was setting shape, with `set_shape`, but right now I simply don't know how to set shape for a different input shape.
```


### Standalone code to reproduce the issue

```shell
def read_image(path, rel):
    # blah blah blah, read somehow
    return image

def read_image1(path1, filter0):
    # blah blah blah, read somehow
    return image

def preprocess(x, y):
    def func(x, y):
        x = json.loads(x)
        x_img1 = read_image(x['path'], x['rel']) # 3D image
        x_img2 = read_image(x['path-fork'], x['filter']) #2D image with different shape
        # image resizing will lose data
        
        y = tf.keras.utils.to_categorical(y, num_classes=len(set(df['label'].values))) # todo: yeah, i'll optimize it never
        
        return (x_img1, x_img2), y

    _x, _y = tf.numpy_function(func, [x, y], [tf.float32, tf.float32])
    # _x.set_shape([256, 256, 3]) <--- previously i used to do this
    _y.set_shape([10])
    
    return _x, _y


# here `x` is an array of string, and those strings are actually json/dictionary
def tf_dataset(x,y, batch=16):
    dataset = tf.data.Dataset.from_tensor_slices((x, y))
    dataset = dataset.shuffle(buffer_size=1000)
    dataset = dataset.map(preprocess)
    dataset = dataset.batch(batch)
    dataset = dataset.prefetch(16)
    return dataset
```


### Relevant log output

```shell
InternalError: Graph execution error:

Unsupported object type numpy.ndarray
     [[{{node PyFunc}}]]
     [[IteratorGetNext]] [Op:__inference_train_function_30745]
```

Here is what I'm trying to do:
![multi input model with tf.data.Dataset](https://user-images.githubusercontent.com/29339330/222134871-4b2d6e7b-32b4-400c-8a91-0fc14a13ae11.png)

</details>"
tensorflow/tensorflow,2023-02-26 23:26:45,question,Failing to run hexagon delegates on android,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

QCS6125

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Problem with hexagon delegates, the hexagon libs from hexagon delegates page are set into arm64-v8a folder.

>CPU architecture: 8

>adb shell getprop ro.board.platform
trinket
>adb shell getprop ro.product.device
trinket
```


### Standalone code to reproduce the issue

```shell
implementation 'org.tensorflow:tensorflow-lite:2.10.0'
implementation 'org.tensorflow:tensorflow-lite-hexagon:2.10.0'

Running tensorflow example from Quickstart for Android.
```


### Relevant log output

```shell
/tflite: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.
```
</details>"
tensorflow/tensorflow,2023-02-26 14:21:20,question,Tensorflow Import error,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I cannot import the tensorflow package in my jupyter notebook. I have checked the installations in conda and pip, but everything seems to work. So whenever i try to import it i get the following error:
""ImportError: Traceback (most recent call last):
  File ""C:\\Users\\Rury\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.""
Is it a problem of the environment or a problem with package itself?
I am starting now to study DL so i would appreciate a lot a quick response. Thank you
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-02-24 19:30:14,question,Running tensorflow distributed on Multiple workers,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.6

### Custom Code

Yes

### OS Platform and Distribution

Linux HPC

### Mobile device

_No response_

### Python version

3.8.3

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.3.1

### GPU model and memory

4 RTX 2080 Ti workers each having 8 GPUs

### Current Behaviour?

```shell
I am trying to run tensorflow distributed training code on multiple worker nodes. I initially tried it using the Mirrored strategy using a single worker with multiple GPUs and the code was working fine and the training process was getting distributed among multiple GPUs. when i have tried it with multiple worker nodes, the training process is actually executing seperately on different workers rather than the load getting distributed among the workers.
My Linux systems has 4 worker nodes with each node having 8 2080Ti GPUs and the GPUs are connected through PCIe system. I also not sure How to configure the TF_config. can anyone help me on this ?
```


### Standalone code to reproduce the issue

```shell
if __name__ == ""__main__"":
    # Get mpi rank
    from getOneHot import getOneHot
    from mpi4py import MPI
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()

    # Load in the parameter files
    from json import load as loadf
    with open(""params.json"", 'r') as inFile:
        params = loadf(inFile)

    # Get data files and prep them for the generator
    import tensorflow
    from tensorflow import distribute as D
    callbacks = []
    devices = getDevices()
    print(devices)
    set_tf_config_mpi()
    strat = D.experimental.MultiWorkerMirroredStrategy(
            communication=D.experimental.CollectiveCommunication.NCCL)

# Create network
    from sys import argv
    resume_training = False
    print(argv)
    if ""resume_latest"" in argv:
        resume_training = True
    with strat.scope():
        # Scheduler
        if isinstance(params[""learning_rate""], str):
            # Get the string for the importable function
            lr = params[""learning_rate""]
            from tensorflow.keras.callbacks import LearningRateScheduler
            # Use a dummy learning rate
            params[""learning_rate""] = 0.1
            # model = create_model(**params)
            # Get the importable function
            lr = lr.split(""."")
            baseImport = __import__(lr[0], globals(), locals(), [lr[1]], 0)
            lr = getattr(baseImport, lr[1])
            # Make a schedule
            lr = LearningRateScheduler(lr)
            callbacks.append(lr)
        # Resume Model?
        model_name = None
        if resume_training:
            initial_epoch, model_name = getInitialEpochsAndModelName(rank)
        if model_name is None:
            initial_epoch=0
            model = create_model(**params)
            resume_training = False
        else:
            from tensorflow.keras.models import load_model
            model = load_model(model_name)
    # Load data from disk
    import numpy
    if ""root"" in params.keys():
        root = params['root']
    else:
        root = ""./""
    if ""filename"" in params.keys():
        filename = params[""filename""]
    else:
        filename = ""150MeV_all_shuffled_normed.csv""

    restricted = [
            'euc1', 'e1', 'x1', 'y1', 'z1',
            'euc2', 'e2', 'x2', 'y2', 'z2',
            'euc3', 'e3', 'x3', 'y3', 'z3',
            ]
   x, y = getOneHot(""{}/{}"".format(root, filename), restricted=restricted, **params)
    # val_filename = ""150MeV_180kMUmin-stdCC_stitched_triples_dtot_trip_only.csv""
    # val_x, val_y = getOneHot(""{}/{}"".format(root, val_filename), restricted=restricted)
    val_x, val_y = None, None
    params[""gbatch_size""] = params['batch_size'] * len(devices)
    print(""x.shape ="", x.shape)
    print(""y.shape ="", y.shape)
    print(""epochs  ="", params['epochs'], type(params['epochs']))
    print(""batch   ="", params['batch_size'], type(params['batch_size']))
    print(""gbatch  ="", params['gbatch_size'], type(params['gbatch_size']))
    # Load data into a distributed dataset
    # Dataset object does nothing in place:
    # https://stackoverflow.com/questions/55645953/shape-of-tensorflow-dataset-data-in-keras-tensorflow-2-0-is-wrong-after-conver
    from tensorflow.data import Dataset
    data = Dataset.from_tensor_slices((x, y))

    # Create validation set
    v = params['validation']
    if val_x is not None:
        vrecord = val_x.shape[0]
        val  = Dataset.from_tensor_slices((val_x, val_y))
        validation = val # data.take(vrecord)
    else:
        vrecord = int(x.shape[0]*v)
        validation = data.take(vrecord)
    validation = validation.batch(params['gbatch_size'])
    validation = validation.repeat(params['epochs'])
    # Validation -- need to do kfold one day
    # This set should NOT be distributed
    vsteps = vrecord // params['gbatch_size']
    if vrecord % params['gbatch_size'] != 0:
        vsteps += 1
    data    = data.batch(params['gbatch_size'])
    data    = data.repeat(params['epochs'])
    records = x.shape[0] # - vrecord
    steps   = records // params['gbatch_size']
    if records % params['gbatch_size']:
        steps += 1
    print(""steps   ="", steps)
    # Note that if we are resuming that the number of _remaining_ epochs has
    # changed!
    # The number of epochs * steps is the numbers of samples to drop
    print(""initial   cardinality = "", data.cardinality())
    print(""initial v cardinality = "", data.cardinality())
    data       = data.skip(initial_epoch*steps)
    validation = validation.skip(initial_epoch*vsteps)
    print(""final     cardinality = "", data.cardinality())
    print(""final v   cardinality = "", data.cardinality())
    # data = strat.experimental_distribute_dataset(data)
    # Split into validation and training
    callbacks  = createCallbacks(params, callbacks, rank, resume_training)
    print(callbacks)
    print(""fitting model"")
    print(data)





    import tensorflow as tf
    options = tf.data.Options()
    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF
    train_data = data.with_options(options)
    val_data = validation.with_options(options)

    history = model.fit(train_data, epochs=params['epochs'],
            batch_size=params['gbatch_size'],
            steps_per_epoch=steps,
            verbose=0,
            initial_epoch=initial_epoch,
            validation_data=val_data,
            validation_steps=vsteps,
            callbacks=callbacks)
    print(""fitting model done"")
    if rank == 0:
        model.save(""model-final"")
    else:
        model.save(""checkpoints/model-tmp"")




############### slurm script :

#!/bin/bash
#SBATCH --job-name=job1 # Job name
#SBATCH --mem=30000 # Job memory request
#SBATCH --gres=gpu:4 # Number of requested GPU(s)
#SBATCH --time=3-23:00:00 # Time limit days-hrs:min:sec
#SBATCH --constraint=rtx_2080 # Specific hardware constraint
#SBATCH --error=slurm.err # Error file name
#SBATCH --output=slurm.out # Output file name
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --array=1-2%1

if [ -d ""model-final"" ]
then
scancel $SLURM_ARRAY_JOB_ID
else
module load Anaconda3/2020.07
module load TensorFlow/2.6.0-foss-2021a-CUDA-11.3.1
mpirun python -u main.py resume_latest
fi
```


### Relevant log output

```shell
I log each and every epoch in a csv file. I see two csv files created and each one has different workers running.
```
</details>"
tensorflow/tensorflow,2023-02-24 02:16:56,question,Tensorflow grad,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf 2.X

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi:
If i want to Slimming Network
```


### Standalone code to reproduce the issue

```shell
I want to ask how I can get the gradient value of each iteration in the model training process.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-02-21 17:44:16,question,tensorflow static library of windows: missing few files,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Its tensorflow provided code as given in https://www.tensorflow.org/install/lang_c
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 10
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: Laptop
-   **TensorFlow installed from (source or binary)**: static library from https://www.tensorflow.org/install/lang_c
-   **TensorFlow version (use command below)**: 2.11
-   **Python version**: NA
-   **Bazel version (if compiling from source)**: NA
-   **GCC/Compiler version (if compiling from source)**: 12.2
-   **CUDA/cuDNN version**:NA
-   **GPU model and memory**: NA
-   **Exact command to reproduce**: Took static library from tensorflow ebsite from link below : https://www.tensorflow.org/install/lang_c
Have taken windows version of https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.11.0.zip (CPU version)
unzipped and created hello_tf.c as mentioned in same webpage.
Compiled the hello_tf.c as below : 
gcc hello_tf.c -I D:\\tensorflow_lib\\include -lD:\\tensorflow_lib\\lib\\tensorflow -o hello_tf

Got error as 
_In file included from hello_tf.c:2:
D:\\tensorflow_lib\\include/tensorflow/c/c_api.h:23:10: fatal error: tensorflow/c/tf_buffer.h: No such file or directory
   23 | #include ""tensorflow/c/tf_buffer.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated._

Then took tf_buffer.h from github repo , to see if the error is only dependent on tf_buffer.h, but then got another error : 

_D:\\tensorflow_lib>gcc hello_tf.c -I D:\\tensorflow_lib\\include -lD:\\tensorflow_lib\\lib\\tensorflow -o hello_tf
In file included from D:\\tensorflow_lib\\include/tensorflow/c/tf_tstring.h:19,
                 from D:\\tensorflow_lib\\include/tensorflow/c/c_api.h:27,
                 from hello_tf.c:2:
D:\\tensorflow_lib\\include/tensorflow/core/platform/ctstring.h:19:10: fatal error: tensorflow/tsl/platform/ctstring.h: No such file or directory
   19 | #include ""tensorflow/tsl/platform/ctstring.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated._

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Took static library from tensorflow ebsite from link below : https://www.tensorflow.org/install/lang_c
Have taken windows version of https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.11.0.zip (CPU version)
unzipped and created hello_tf.c as mentioned in same webpage.
Compiled the hello_tf.c as below : 
gcc hello_tf.c -I D:\\tensorflow_lib\\include -lD:\\tensorflow_lib\\lib\\tensorflow -o hello_tf

Got error as 
_In file included from hello_tf.c:2:
D:\\tensorflow_lib\\include/tensorflow/c/c_api.h:23:10: fatal error: tensorflow/c/tf_buffer.h: No such file or directory
   23 | #include ""tensorflow/c/tf_buffer.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated._

Then took tf_buffer.h from github repo , to see if the error is only dependent on tf_buffer.h, but then got another error : 

_D:\\tensorflow_lib>gcc hello_tf.c -I D:\\tensorflow_lib\\include -lD:\\tensorflow_lib\\lib\\tensorflow -o hello_tf
In file included from D:\\tensorflow_lib\\include/tensorflow/c/tf_tstring.h:19,
                 from D:\\tensorflow_lib\\include/tensorflow/c/c_api.h:27,
                 from hello_tf.c:2:
D:\\tensorflow_lib\\include/tensorflow/core/platform/ctstring.h:19:10: fatal error: tensorflow/tsl/platform/ctstring.h: No such file or directory
   19 | #include ""tensorflow/tsl/platform/ctstring.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated._


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
tensorflow/tensorflow,2023-02-20 14:05:03,question,What is the final training result of asynchronous synchronous parallel distributed training？,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When distributed training adopts asynchronous synchronous parallel, the parameters updated by each worker are inconsistent. Is the final result of distributed training the slowest parameter updated by workers?
```


### Standalone code to reproduce the issue

```shell
When distributed training adopts asynchronous synchronous parallel, the parameters updated by each worker are inconsistent. Is the final result of distributed training the slowest parameter updated by workers?
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-02-15 12:30:58,question,"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 22.04.1 LTS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The warning appears:


WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.
```

Can you please, explain, what is meant by this warning and how to fix it? I have the following accompanying questions to it:

* Function traces are basically graph representations of functions or something else?

* If these jit traces are not found in a loaded model, will they be generated again? Is model compilation needed for regeneration?

* Are these functions needed only for training or also for prediction/evaluation?

I have found in Keras docs (https://keras.io/api/models/model_saving_apis/) that I can disable saving the traces with the following note:
""Disabling this will decrease serialization time and reduce file size, but it requires that all custom layers/models implement a get_config() method.""

* Why would the `get_config()` method be only needed when I disable saving the traces?

Thanks in advance for any explanations given!

```shell
### Reproducer

It's not my code but the warnings appear e.g. here: https://jovian.com/blog/tutorials/%20parameter-logging-wandb-ai
```

```
### Relevant log output

WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.
```
</details>"
tensorflow/tensorflow,2023-02-10 08:04:57,question,How to use exported automl tensorflow model for tabular data in Python,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.9

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hello,

I followed the instructions from Google Cloud to export and load a trainen AutoML model (training was done with data from BigQuery): https://cloud.google.com/vertex-ai/docs/export/export-model-tabular

As we want to integrate this model in our Spark flow I need to load it and make predictions on it in Python directly. I tested the model with the tensorflow serving docker image as described in the documentation. This works perfectly fine. However, when I try to use the model directly I get an erro ""Error: DATA_LOSS: Failed skipping unrequested field"". Input must be a string tensor. I tried several formats (JSON, CSV) but none of them seemed to be correct.

Can anybody give me a hint on how to convert the tabular data into a string tensor in a way that the model accepts the data and returns a prediction?

Thanks in advance!!
Kay
```


### Standalone code to reproduce the issue

```shell
import struct2tensor
import tensorflow as tf
import json
import requests


MODEL_PATH = '/home/kay/tmp/models/ml_cr_2022_12'

predict_sample = {'Animals': '0.0', 'Apparel': '0.0165423884627339', 'Arts': '0.000893240417492657', 'Baby': '0.0', 'Business': '0.0', 'Cameras': '0.000158694043359865', 'Electronics': '0.0', 'Food': '6.4749054130615e-05', 'Furniture': '0.0', 'Hardware': '0.000247099237409669', 'Health': '0.00928790329794604', 'Home': '0.0442892335578687', 'Luggage': '3.65980448833796e-05', 'Mature': '0.0', 'Media': '0.70324946112978', 'Office': '0.000297127488105344', 'Religious': '0.0', 'Software': '0.0', 'Sporting': '0.0', 'Toys': '0.0', 'Vehicles': '7.25524348202571e-06', 'aov_bench': '59.8599307847218', 'aov_rep': '0', 'avgprice': '12.704623853211', 'bouncerate': '81.06', 'brand_search_volume': '0', 'brand_search_volume_share': '0.0', 'category': 'adult', 'competition': '0.0', 'cpc': '0.0', 'cr_bench': '0.00972125074728272', 'date': '2022-08-01', 'directShare': '40.79', 'displayShare': '0.0', 'domain_cat_1': '0', 'domain_cat_2': '0', 'domain_search_volum_share': '0.0', 'domain_search_volume': '0', 'ekps_aov': '26.859908543707', 'ekps_cr': '0.0194748958674429', 'iib_bench': '1.04867824234893', 'int64_field_0': '1', 'lineid': '1', 'mailShare': '0.0', 'mainCountry': 'Germany', 'mainCountryShare': '84.25', 'no_cat': '0.224926250022808', 'organicShare': '57.66', 'pageviews': '1.74154466250536', 'paidsearchShare': '0.0'}

# Request to tensorflow_serving docker container, works perfectly
response = requests.post(
    'http://localhost:8080/predict',
    json={'instances': [predict_sample]}
)
# prints {""predictions"": 0.0056517720222473145}
print(response.text)

model = tf.saved_model.load(MODEL_PATH)
infer = model.signatures[""serving_default""]

# No matter what I tried as input here, I always get error ""Error consuming . Error: DATA_LOSS: Failed skipping unrequested field""
print(infer(tf.constant('How to feed model with one string tensor??')))
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-02-03 18:10:28,question,TFlite minimal example failing on latest tensorflow repo,"When I run latest tensorflow lite example minimal and it is failing on Linux machine with the below error

Followed steps mentioned here  and ran on x86_64 GNU/Linux
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal



,,,
100%] Linking CXX executable minimal
/usr/bin/ld: tensorflow-lite/libtensorflow-lite.a(register.cc.o): in function `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()':
register.cc:(.text+0x1cd): undefined reference to `tflite::ops::builtin::Register_ABS()'
/usr/bin/ld: register.cc:(.text+0x1ed): undefined reference to `tflite::ops::builtin::Register_HARD_SWISH()'
/usr/bin/ld: register.cc:(.text+0x207): undefined reference to `tflite::ops::builtin::Register_RELU()'
/usr/bin/ld: register.cc:(.text+0x227): undefined reference to `tflite::ops::builtin::Register_RELU_N1_TO_1()'
/usr/bin/ld: register.cc:(.text+0x241): undefined reference to `tflite::ops::builtin::Register_RELU_0_TO_1()'
/usr/bin/ld: register.cc:(.text+0x25b): undefined reference to `tflite::ops::builtin::Register_RELU6()'
/usr/bin/ld: register.cc:(.text+0x27b): undefined reference to `tflite::ops::builtin::Register_TANH()'
/usr/bin/ld: register.cc:(.text+0x29b): undefined reference to `tflite::ops::builtin::Register_LOGISTIC()'
/usr/bin/ld: register.cc:(.text+0x2bb): undefined reference to `tflite::ops::builtin::Register_AVERAGE_POOL_2D()'
/usr/bin/ld: register.cc:(.text+0x2db): undefined reference to `tflite::ops::builtin::Register_MAX_POOL_2D()'
/usr/bin/ld: register.cc:(.text+0x2fb): undefined reference to `tflite::ops::builtin::Register_L2_POOL_2D()'
/usr/bin/ld: register.cc:(.text+0x315): undefined reference to `tflite::ops::builtin::Register_CONV_2D()'
/usr/bin/ld: register.cc:(.text+0x335): undefined reference to `tflite::ops::builtin::Register_DEPTHWISE_CONV_2D()'
/usr/bin/ld: register.cc:(.text+0x355): undefined reference to `tflite::ops::builtin::Register_SVDF()'
/usr/bin/ld: register.cc:(.text+0x375): undefined reference to `tflite::ops::builtin::Register_RNN()'
/usr/bin/ld: register.cc:(.text+0x395): undefined reference to `tflite::ops::builtin::Register_BIDIRECTIONAL_SEQUENCE_RNN()'
/usr/bin/ld: register.cc:(.text+0x3b5): undefined reference to `tflite::ops::builtin::Register_UNIDIRECTIONAL_SEQUENCE_RNN()'
/usr/bin/ld: register.cc:(.text+0x3d5): undefined reference to `tflite::ops::builtin::Register_EMBEDDING_LOOKUP()'
/usr/bin/ld: register.cc:(.text+0x3f5): undefined reference to `tflite::ops::builtin::Register_EMBEDDING_LOOKUP_SPARSE()'
/usr/bin/ld: register.cc:(.text+0x40f): undefined reference to `tflite::ops::builtin::Register_FULLY_CONNECTED()'
/usr/bin/ld: register.cc:(.text+0x42f): undefined reference to `tflite::ops::builtin::Register_LSH_PROJECTION()'
/usr/bin/ld: register.cc:(.text+0x449): undefined reference to `tflite::ops::builtin::Register_HASHTABLE_LOOKUP()'
/usr/bin/ld: register.cc:(.text+0x463): undefined reference to `tflite::ops::builtin::Register_SOFTMAX()'
/usr/bin/ld: register.cc:(.text+0x483): undefined reference to `tflite::ops::builtin::Register_CONCATENATION()'
/usr/bin/ld: register.cc:(.text+0x4a3): undefined reference to `tflite::ops::builtin::Register_ADD()'
/usr/bin/ld: register.cc:(.text+0x4c0): undefined reference to `tflite::ops::builtin::Register_SPACE_TO_BATCH_ND()'
/usr/bin/ld: register.cc:(.text+0x4e0): undefined reference to `tflite::ops::builtin::Register_BATCH_TO_SPACE_ND()'
/usr/bin/ld: register.cc:(.text+0x500): undefined reference to `tflite::ops::builtin::Register_MUL()'
/usr/bin/ld: register.cc:(.text+0x520): undefined reference to `tflite::ops::builtin::Register_L2_NORMALIZATION()'
/usr/bin/ld: register.cc:(.text+0x540): undefined reference to `tflite::ops::builtin::Register_LOCAL_RESPONSE_NORMALIZATION()'
/usr/bin/ld: register.cc:(.text+0x55a): undefined reference to `tflite::ops::builtin::Register_LSTM()'
/usr/bin/ld: register.cc:(.text+0x57a): undefined reference to `tflite::ops::builtin::Register_BIDIRECTIONAL_SEQUENCE_LSTM()'
/usr/bin/ld: register.cc:(.text+0x59a): undefined reference to `tflite::ops::builtin::Register_UNIDIRECTIONAL_SEQUENCE_LSTM()'
/usr/bin/ld: register.cc:(.text+0x5ba): undefined reference to `tflite::ops::builtin::Register_PAD()'
/usr/bin/ld: register.cc:(.text+0x5da): undefined reference to `tflite::ops::builtin::Register_PADV2()'
/usr/bin/ld: register.cc:(.text+0x5fa): undefined reference to `tflite::ops::builtin::Register_RESHAPE()'
/usr/bin/ld: register.cc:(.text+0x614): undefined reference to `tflite::ops::builtin::Register_RESIZE_BILINEAR()'
/usr/bin/ld: register.cc:(.text+0x634): undefined reference to `tflite::ops::builtin::Register_RESIZE_NEAREST_NEIGHBOR()'
/usr/bin/ld: register.cc:(.text+0x654): undefined reference to `tflite::ops::builtin::Register_SKIP_GRAM()'
/usr/bin/ld: register.cc:(.text+0x66e): undefined reference to `tflite::ops::builtin::Register_SPACE_TO_DEPTH()'
/usr/bin/ld: register.cc:(.text+0x68e): undefined reference to `tflite::ops::builtin::Register_DEPTH_TO_SPACE()'
/usr/bin/ld: register.cc:(.text+0x6ae): undefined reference to `tflite::ops::builtin::Register_GATHER()'
/usr/bin/ld: register.cc:(.text+0x6ce): undefined reference to `tflite::ops::builtin::Register_TRANSPOSE()'
/usr/bin/ld: register.cc:(.text+0x6ee): undefined reference to `tflite::ops::builtin::Register_MEAN()'
/usr/bin/ld: register.cc:(.text+0x70e): undefined reference to `tflite::ops::builtin::Register_DIV()'
/usr/bin/ld: register.cc:(.text+0x72e): undefined reference to `tflite::ops::builtin::Register_SUB()'
/usr/bin/ld: register.cc:(.text+0x74e): undefined reference to `tflite::ops::builtin::Register_SPLIT()'
/usr/bin/ld: register.cc:(.text+0x76e): undefined reference to `tflite::ops::builtin::Register_SPLIT_V()'
/usr/bin/ld: register.cc:(.text+0x78e): undefined reference to `tflite::ops::builtin::Register_SQUEEZE()'
/usr/bin/ld: register.cc:(.text+0x7ae): undefined reference to `tflite::ops::builtin::Register_STRIDED_SLICE()'
/usr/bin/ld: register.cc:(.text+0x7ce): undefined reference to `tflite::ops::builtin::Register_EXP()'
/usr/bin/ld: register.cc:(.text+0x7e8): undefined reference to `tflite::ops::builtin::Register_TOPK_V2()'
/usr/bin/ld: register.cc:(.text+0x808): undefined reference to `tflite::ops::builtin::Register_LOG()'
/usr/bin/ld: register.cc:(.text+0x822): undefined reference to `tflite::ops::builtin::Register_LOG_SOFTMAX()'
/usr/bin/ld: register.cc:(.text+0x842): undefined reference to `tflite::ops::builtin::Register_CAST()'
/usr/bin/ld: register.cc:(.text+0x862): undefined reference to `tflite::ops::builtin::Register_DEQUANTIZE()'
/usr/bin/ld: register.cc:(.text+0x882): undefined reference to `tflite::ops::builtin::Register_PRELU()'
/usr/bin/ld: register.cc:(.text+0x89c): undefined reference to `tflite::ops::builtin::Register_MAXIMUM()'
/usr/bin/ld: register.cc:(.text+0x8bc): undefined reference to `tflite::ops::builtin::Register_MINIMUM()'
/usr/bin/ld: register.cc:(.text+0x8dc): undefined reference to `tflite::ops::builtin::Register_ARG_MAX()'
/usr/bin/ld: register.cc:(.text+0x8fc): undefined reference to `tflite::ops::builtin::Register_ARG_MIN()'
/usr/bin/ld: register.cc:(.text+0x91c): undefined reference to `tflite::ops::builtin::Register_GREATER()'
/usr/bin/ld: register.cc:(.text+0x93c): undefined reference to `tflite::ops::builtin::Register_GREATER_EQUAL()'
/usr/bin/ld: register.cc:(.text+0x95c): undefined reference to `tflite::ops::builtin::Register_LESS()'
/usr/bin/ld: register.cc:(.text+0x97c): undefined reference to `tflite::ops::builtin::Register_LESS_EQUAL()'
/usr/bin/ld: register.cc:(.text+0x99c): undefined reference to `tflite::ops::builtin::Register_FLOOR()'
/usr/bin/ld: register.cc:(.text+0x9b6): undefined reference to `tflite::ops::builtin::Register_CEIL()'
/usr/bin/ld: register.cc:(.text+0x9d0): undefined reference to `tflite::ops::builtin::Register_ROUND()'
/usr/bin/ld: register.cc:(.text+0x9ea): undefined reference to `tflite::ops::builtin::Register_NEG()'
/usr/bin/ld: register.cc:(.text+0xa04): undefined reference to `tflite::ops::builtin::Register_SELECT()'
/usr/bin/ld: register.cc:(.text+0xa24): undefined reference to `tflite::ops::builtin::Register_SELECT_V2()'
/usr/bin/ld: register.cc:(.text+0xa3e): undefined reference to `tflite::ops::builtin::Register_SLICE()'
/usr/bin/ld: register.cc:(.text+0xa5e): undefined reference to `tflite::ops::builtin::Register_SIN()'
/usr/bin/ld: register.cc:(.text+0xa78): undefined reference to `tflite::ops::builtin::Register_COS()'
/usr/bin/ld: register.cc:(.text+0xa92): undefined reference to `tflite::ops::builtin::Register_TRANSPOSE_CONV()'
/usr/bin/ld: register.cc:(.text+0xab2): undefined reference to `tflite::ops::builtin::Register_TILE()'
/usr/bin/ld: register.cc:(.text+0xad2): undefined reference to `tflite::ops::builtin::Register_SUM()'
/usr/bin/ld: register.cc:(.text+0xaf2): undefined reference to `tflite::ops::builtin::Register_REDUCE_PROD()'
/usr/bin/ld: register.cc:(.text+0xb12): undefined reference to `tflite::ops::builtin::Register_REDUCE_MAX()'
/usr/bin/ld: register.cc:(.text+0xb32): undefined reference to `tflite::ops::builtin::Register_REDUCE_MIN()'
/usr/bin/ld: register.cc:(.text+0xb52): undefined reference to `tflite::ops::builtin::Register_REDUCE_ANY()'
/usr/bin/ld: register.cc:(.text+0xb6c): undefined reference to `tflite::ops::builtin::Register_REDUCE_ALL()'
/usr/bin/ld: register.cc:(.text+0xb86): undefined reference to `tflite::ops::builtin::Register_EXPAND_DIMS()'
/usr/bin/ld: register.cc:(.text+0xba0): undefined reference to `tflite::ops::builtin::Register_SPARSE_TO_DENSE()'
/usr/bin/ld: register.cc:(.text+0xbc0): undefined reference to `tflite::ops::builtin::Register_EQUAL()'
/usr/bin/ld: register.cc:(.text+0xbe0): undefined reference to `tflite::ops::builtin::Register_NOT_EQUAL()'
/usr/bin/ld: register.cc:(.text+0xc00): undefined reference to `tflite::ops::builtin::Register_SQRT()'
/usr/bin/ld: register.cc:(.text+0xc1a): undefined reference to `tflite::ops::builtin::Register_RSQRT()'
/usr/bin/ld: register.cc:(.text+0xc3a): undefined reference to `tflite::ops::builtin::Register_SHAPE()'
/usr/bin/ld: register.cc:(.text+0xc54): undefined reference to `tflite::ops::builtin::Register_RANK()'
/usr/bin/ld: register.cc:(.text+0xc6e): undefined reference to `tflite::ops::builtin::Register_POW()'
/usr/bin/ld: register.cc:(.text+0xc88): undefined reference to `tflite::ops::builtin::Register_FAKE_QUANT()'
/usr/bin/ld: register.cc:(.text+0xca8): undefined reference to `tflite::ops::builtin::Register_PACK()'
/usr/bin/ld: register.cc:(.text+0xcc8): undefined reference to `tflite::ops::builtin::Register_ONE_HOT()'
/usr/bin/ld: register.cc:(.text+0xce2): undefined reference to `tflite::ops::builtin::Register_LOGICAL_OR()'
/usr/bin/ld: register.cc:(.text+0xcfc): undefined reference to `tflite::ops::builtin::Register_LOGICAL_AND()'
/usr/bin/ld: register.cc:(.text+0xd16): undefined reference to `tflite::ops::builtin::Register_LOGICAL_NOT()'
/usr/bin/ld: register.cc:(.text+0xd30): undefined reference to `tflite::ops::builtin::Register_UNPACK()'
/usr/bin/ld: register.cc:(.text+0xd50): undefined reference to `tflite::ops::builtin::Register_FLOOR_DIV()'
/usr/bin/ld: register.cc:(.text+0xd70): undefined reference to `tflite::ops::builtin::Register_SQUARE()'
/usr/bin/ld: register.cc:(.text+0xd8a): undefined reference to `tflite::ops::builtin::Register_ZEROS_LIKE()'
/usr/bin/ld: register.cc:(.text+0xda4): undefined reference to `tflite::ops::builtin::Register_FLOOR_MOD()'
/usr/bin/ld: register.cc:(.text+0xdbe): undefined reference to `tflite::ops::builtin::Register_RANGE()'
/usr/bin/ld: register.cc:(.text+0xdd8): undefined reference to `tflite::ops::builtin::Register_LEAKY_RELU()'
/usr/bin/ld: register.cc:(.text+0xdf8): undefined reference to `tflite::ops::builtin::Register_SQUARED_DIFFERENCE()'
/usr/bin/ld: register.cc:(.text+0xe18): undefined reference to `tflite::ops::builtin::Register_FILL()'
/usr/bin/ld: register.cc:(.text+0xe38): undefined reference to `tflite::ops::builtin::Register_MIRROR_PAD()'
/usr/bin/ld: register.cc:(.text+0xe58): undefined reference to `tflite::ops::builtin::Register_UNIQUE()'
/usr/bin/ld: register.cc:(.text+0xe72): undefined reference to `tflite::ops::builtin::Register_REVERSE_V2()'
/usr/bin/ld: register.cc:(.text+0xe92): undefined reference to `tflite::ops::builtin::Register_ADD_N()'
/usr/bin/ld: register.cc:(.text+0xeac): undefined reference to `tflite::ops::builtin::Register_GATHER_ND()'
/usr/bin/ld: register.cc:(.text+0xecc): undefined reference to `tflite::ops::builtin::Register_WHERE()'
/usr/bin/ld: register.cc:(.text+0xeec): undefined reference to `tflite::ops::builtin::Register_ELU()'
/usr/bin/ld: register.cc:(.text+0xf06): undefined reference to `tflite::ops::builtin::Register_REVERSE_SEQUENCE()'
/usr/bin/ld: register.cc:(.text+0xf20): undefined reference to `tflite::ops::builtin::Register_MATRIX_DIAG()'
/usr/bin/ld: register.cc:(.text+0xf3a): undefined reference to `tflite::ops::builtin::Register_QUANTIZE()'
/usr/bin/ld: register.cc:(.text+0xf5a): undefined reference to `tflite::ops::builtin::Register_MATRIX_SET_DIAG()'
/usr/bin/ld: register.cc:(.text+0xf74): undefined reference to `tflite::ops::builtin::Register_IF()'
/usr/bin/ld: register.cc:(.text+0xf8e): undefined reference to `tflite::ops::builtin::Register_WHILE()'
/usr/bin/ld: register.cc:(.text+0xfa8): undefined reference to `tflite::ops::builtin::Register_NON_MAX_SUPPRESSION_V4()'
/usr/bin/ld: register.cc:(.text+0xfc2): undefined reference to `tflite::ops::builtin::Register_NON_MAX_SUPPRESSION_V5()'
/usr/bin/ld: register.cc:(.text+0xfdc): undefined reference to `tflite::ops::builtin::Register_SCATTER_ND()'
/usr/bin/ld: register.cc:(.text+0xff6): undefined reference to `tflite::ops::builtin::Register_DENSIFY()'
/usr/bin/ld: register.cc:(.text+0x1010): undefined reference to `tflite::ops::builtin::Register_SEGMENT_SUM()'
/usr/bin/ld: register.cc:(.text+0x102a): undefined reference to `tflite::ops::builtin::Register_BATCH_MATMUL()'
/usr/bin/ld: register.cc:(.text+0x104a): undefined reference to `tflite::ops::builtin::Register_CUMSUM()'
/usr/bin/ld: register.cc:(.text+0x1064): undefined reference to `tflite::ops::builtin::Register_BROADCAST_TO()'
/usr/bin/ld: register.cc:(.text+0x1084): undefined reference to `tflite::ops::builtin::Register_CALL_ONCE()'
/usr/bin/ld: register.cc:(.text+0x109e): undefined reference to `tflite::ops::builtin::Register_RFFT2D()'
/usr/bin/ld: register.cc:(.text+0x10b8): undefined reference to `tflite::ops::builtin::Register_CONV_3D()'
/usr/bin/ld: register.cc:(.text+0x10d2): undefined reference to `tflite::ops::builtin::Register_IMAG()'
/usr/bin/ld: register.cc:(.text+0x10ec): undefined reference to `tflite::ops::builtin::Register_REAL()'
/usr/bin/ld: register.cc:(.text+0x1106): undefined reference to `tflite::ops::builtin::Register_COMPLEX_ABS()'
/usr/bin/ld: register.cc:(.text+0x1120): undefined reference to `tflite::ops::builtin::Register_BROADCAST_ARGS()'
/usr/bin/ld: register.cc:(.text+0x113a): undefined reference to `tflite::ops::builtin::Register_HASHTABLE()'
/usr/bin/ld: register.cc:(.text+0x1154): undefined reference to `tflite::ops::builtin::Register_HASHTABLE_FIND()'
/usr/bin/ld: register.cc:(.text+0x116e): undefined reference to `tflite::ops::builtin::Register_HASHTABLE_IMPORT()'
/usr/bin/ld: register.cc:(.text+0x1188): undefined reference to `tflite::ops::builtin::Register_HASHTABLE_SIZE()'
/usr/bin/ld: register.cc:(.text+0x11a2): undefined reference to `tflite::ops::builtin::Register_CONV_3D_TRANSPOSE()'
/usr/bin/ld: register.cc:(.text+0x11bc): undefined reference to `tflite::ops::builtin::Register_VAR_HANDLE()'
/usr/bin/ld: register.cc:(.text+0x11d6): undefined reference to `tflite::ops::builtin::Register_READ_VARIABLE()'
/usr/bin/ld: register.cc:(.text+0x11f0): undefined reference to `tflite::ops::builtin::Register_ASSIGN_VARIABLE()'
/usr/bin/ld: register.cc:(.text+0x120a): undefined reference to `tflite::ops::builtin::Register_MULTINOMIAL()'
/usr/bin/ld: register.cc:(.text+0x1224): undefined reference to `tflite::ops::builtin::Register_RANDOM_STANDARD_NORMAL()'
/usr/bin/ld: register.cc:(.text+0x123e): undefined reference to `tflite::ops::builtin::Register_BUCKETIZE()'
/usr/bin/ld: register.cc:(.text+0x1258): undefined reference to `tflite::ops::builtin::Register_RANDOM_UNIFORM()'
/usr/bin/ld: register.cc:(.text+0x1272): undefined reference to `tflite::ops::builtin::Register_GELU()'
/usr/bin/ld: register.cc:(.text+0x1292): undefined reference to `tflite::ops::builtin::Register_DYNAMIC_UPDATE_SLICE()'
/usr/bin/ld: register.cc:(.text+0x12ac): undefined reference to `tflite::ops::builtin::Register_UNSORTED_SEGMENT_PROD()'
/usr/bin/ld: register.cc:(.text+0x12c6): undefined reference to `tflite::ops::builtin::Register_UNSORTED_SEGMENT_MAX()'
/usr/bin/ld: register.cc:(.text+0x12e0): undefined reference to `tflite::ops::builtin::Register_UNSORTED_SEGMENT_MIN()'
/usr/bin/ld: register.cc:(.text+0x12fa): undefined reference to `tflite::ops::builtin::Register_UNSORTED_SEGMENT_SUM()'
/usr/bin/ld: register.cc:(.text+0x1314): undefined reference to `tflite::ops::builtin::Register_ATAN2()'
/usr/bin/ld: register.cc:(.text+0x132e): undefined reference to `tflite::ops::builtin::Register_SIGN()'
/usr/bin/ld: register.cc:(.text+0x134e): undefined reference to `tflite::ops::custom::Register_NUMERIC_VERIFY()'
/usr/bin/ld: register.cc:(.text+0x136a): undefined reference to `tflite::ops::custom::Register_MFCC()'
/usr/bin/ld: register.cc:(.text+0x1386): undefined reference to `tflite::ops::custom::Register_AUDIO_SPECTROGRAM()'
/usr/bin/ld: register.cc:(.text+0x13a2): undefined reference to `tflite::ops::custom::Register_DETECTION_POSTPROCESS()'
/usr/bin/ld: tensorflow-lite/libtensorflow-lite.a(xnnpack_delegate.cc.o): in function `TfLiteXNNPackDelegateCreateWithThreadpool':
xnnpack_delegate.cc:(.text+0xc74f): undefined reference to `tflite::CpuBackendContext::GetFromContext(TfLiteContext*)'
/usr/bin/ld: xnnpack_delegate.cc:(.text+0xc757): undefined reference to `tflite::CpuBackendContext::get_xnnpack_threadpool()'
collect2: error: ld returned 1 exit status
gmake[2]: *** [CMakeFiles/minimal.dir/build.make:179: minimal] Error 1
gmake[1]: *** [CMakeFiles/Makefile2:1251: CMakeFiles/minimal.dir/all] Error 2
gmake: *** [Makefile:136: all] Error 2

,,,"
tensorflow/tensorflow,2023-02-02 03:19:29,question,"On MTK platforms, tflite calls the GPU with clGetPlatformIDs return -1001","**System information**
- Android Device information (use `adb shell getprop ro.build.fingerprint`
  if possible): Redmi/rembrandt/rembrandt:13/TP1A.220624.014/23.1.31:user/release-keys

- TensorFlow Lite in Play Services SDK version (found in `build.gradle`): 29
- Google Play Services version
  (`Settings` > `Apps` > `Google Play Services` > `App details`): 

**Standalone code to reproduce the issue**

on MTK platforms
code:
if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {
            LOGE(""delegate init failed!"");
            exit(-1);
        }

get:
clGetPlatformIDs returned -1001 or clGetPlatformIDs returned -30


**Any other info / logs**
This MTK platform has a GPU device.

"
tensorflow/tensorflow,2023-02-01 12:58:33,question,How to create `tf.keras.layers.Input` without batch_size dimension?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.9.1

### Custom Code

No

### OS Platform and Distribution

centos7

### Mobile device

_No response_

### Python version

3.8.14

### Bazel version

5.0

### GCC/Compiler version

10.2

### CUDA/cuDNN version

11.4

### GPU model and memory

A30

### Current Behaviour?

One input of my model has nothing to do with batch_size, for example, its shape is [1,2,3], how to avoid automatically adding 1 dimension when creating  `tf.keras.layers.Input` ? If I manually slice it, the slice operator will be introduced, resulting in a decrease in inference performance.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

x = tf.keras.layers.Input(shape=(32,64))
# x.shape: (None, 32, 64)
x = x[0, :, :]
# x.shape: (32, 64)

```
"
tensorflow/tensorflow,2023-01-28 20:08:59,question,graph execution error,"I'm facing an issue that says ""graph execution error"" tried to solve it but couldn't.
"
tensorflow/tensorflow,2023-01-27 10:41:41,question,How to invoke .h5 model instead of .tflite model for pose classification?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.7

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
I need to implement pose_classifier.h5 model instead of pose_classifier.tflite.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-01-24 16:46:34,question,pass additional parameters to @tf.custom_gradient,"
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.8.0

### Current Behaviour?

Currently we can define a custom gradient using `@tf.custom_gradient` following https://www.tensorflow.org/api_docs/python/tf/custom_gradient

What I'm looking for is to be able to pass to this function additional information (in my case, the loss of my network)

For example (it's stupid, but it's to give an idea) to take the incoming gradient and multiply it by loss that has generated that gradient

"
tensorflow/tensorflow,2023-01-24 11:47:23,question,Can't convert custom model to tflite with model config and weights file being separate,"Hi,
I am trying to convert a custom model to tflite with these steps:
```
#creates a custom model that I have previously defined (Resnet50 as a backbone (pretrained weights) + transformer encoder + MLP head)
model = create_model(classes=5)   
#the best weights file obtained after my custom model training
model.load_weights(model_weights_path)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]  
tfmodel = converter.convert()
with tf.io.gfile.GFile(tf_lite_path +  'tflite_model' + "".tflite"", 'wb') as f:
    f.write(tfmodel)
```
I do not get any output on this, no errors as well. The question is - is it possible to convert my custom model with creating the model (without saving it) and then loading the weights the way I have done? Is there any other way how to make my model smaller after training?

"
tensorflow/tensorflow,2023-01-18 23:34:13,question,Error in importing tensor flow ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

tf 4.9

### Custom Code

No

### OS Platform and Distribution

windows

### Mobile device

_No response_

### Python version

3.8.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I have installed tensorflow using below command.
! pip install tensorflow
! pip install keras

then I tried to import 
and throwing error 
AttributeError: module 'numpy' has no attribute 'typeDict'

current numpy version 
numpy-1.24.1
numpy-1.21
```


### Standalone code to reproduce the issue

```shell
I have installed tensorflow using below command.
! pip install tensorflow
! pip install keras

then I tried to import 
and throwing error 
AttributeError: module 'numpy' has no attribute 'typeDict'

current numpy version 
numpy-1.24.1
numpy-1.21
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-01-18 03:49:13,question,Missing fp16 ops when converting from TF to TFLite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (or github SHA if from source): 2.11


**Provide the text output from tflite_convert**

```
[full_error.txt](https://github.com/tensorflow/tensorflow/files/10441958/full_error.txt)

error: failed while converting: 'main': 
Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select 
TF Select ops: AddV2, Cast, ConcatV2, Conv2D, DepthwiseConv2dNative, Elu, GatherV2, Max, Minimum, Mul, Pad, RealDiv, Relu, Sqrt, Sum, Transpose
```

**Standalone code to reproduce the issue** 
converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)
tflite_model  = converter.convert()


"
tensorflow/tensorflow,2023-01-17 18:32:50,question,Tensorflow data validation-visualize_statistics()-Not working on databricks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am unable to display the output of tfdv.visualize_statistics() output on databricks where as the same is working on local system.

Is it because that facets are not supported on databricks? Please provide a solution on how I can use modules of tensorflow data validation library on databricks.
```


### Standalone code to reproduce the issue

```shell
tfdv.visualize_statistics()

#link
https://www.tensorflow.org/tfx/data_validation/get_started
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-01-16 16:30:23,question,Model save issues with custom optimizer - DPKerasSGDOptimizer,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Problem 
A keras sequential Model was compiled using DPKerasSGD optimizer and saved. But when the saved model is loaded it throws the below error

""Unknown optimizer: 'DPOptimizerClass'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details""

Expected Behaviour
Since the model was already compiled using the optimizer it should run perfectly fine when fitted with the data. 

Whereas the same works when the optimizer is replaced. Please provide a solution on how to save the model with this custom optimizer.
```


### Standalone code to reproduce the issue

```shell
#building the model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')])

#compiling the model
  model.compile(
    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True,reduction=tf.losses.Reduction.NONE),
    optimizer=tensorflow_privacy.DPKerasSGDOptimizer(l2_norm_clip=1,noise_multiplier=2,learning_rate=0.01),
    metrics=[
        tf.keras.metrics.BinaryAccuracy(name='accuracy'),
        tf.keras.metrics.Precision(name='precision'),
        tf.keras.metrics.Recall(name='recall')
    ])

#saving the model
model.save('my_model')

#loading the model
keras.models.load_model('mymodel')

#throws the error
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-01-14 03:35:08,question,How to get label of detection after (@tensorflow/tfjs-tflite) predict returns result from a custom tflite model in Reactjs web App,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

binary

### Tensorflow Version

tfjs@^3.7.0

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

Windows laptop

### Python version

2.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am using 

     import * as tflite from '@tensorflow/tfjs-tflite';


and have successfully loaded a custom tflite model:

     tfliteModel = await tflite.loadTFLiteModel(""model/myModel.tflite"");

as well as gotten a prediction
     var outputTensor = await tfliteModel.predict(Img);

The code works well when I only have 1 label to detect initially. Now I need to detect multiple labels. I created a new custom model and tested that it is able to detect multiple labels in an Android project, eg. I can get labels 'L1', and 'L2'

Can I detect multi labels using the code above after I load in the new model? If not, what changes do I have to make to detect multi labels and know which label I am detecting (eg. obtain the name of the label)
```


### Standalone code to reproduce the issue

```shell
See above. Not a bug issue.
```


### Relevant log output

```shell
Instance of result, outputTensor's value

outputTensor:
{
  ""StatefulPartitionedCall:1"": {
    kept: false,
    isDisposedInternal: false,
    shape: [
      1,
      25,
    ],
    dtype: ""float32"",
    size: 25,
    strides: [
      25,
    ],
    dataId: {
      id: 364,
    },
    id: 364,
    rankType: ""2"",
  },
  ""StatefulPartitionedCall:3"": {
    kept: false,
    isDisposedInternal: false,
    shape: [
      1,
      25,
      4,
    ],
    dtype: ""float32"",
    size: 100,
    strides: [
      100,
      4,
    ],
    dataId: {
      id: 365,
    },
    id: 365,
    rankType: ""3"",
  },
  ""StatefulPartitionedCall:0"": {
    kept: false,
    isDisposedInternal: false,
    shape: [
      1,
    ],
    dtype: ""float32"",
    size: 1,
    strides: [
    ],
    dataId: {
      id: 366,
    },
    id: 366,
    rankType: ""1"",
  },
  ""StatefulPartitionedCall:2"": {
    kept: false,
    isDisposedInternal: false,
    shape: [
      1,
      25,
    ],
    dtype: ""float32"",
    size: 25,
    strides: [
      25,
    ],
    dataId: {
      id: 367,
    },
    id: 367,
    rankType: ""2"",
  },
}
```
</details>"
tensorflow/tensorflow,2023-01-12 08:52:18,question,Error while evaluating tflite model with bazel run_eval ,"Hi, i managed to train a SSD_mobilenet_v1 using model_main_tf2.py. After that i managed to export with export_tflite_graph_tf2.py changing the max_detections paramenter to 33, and then i successfully exported a tflite model. I tried then to run some inference with the new tflite model and it worked as expected.
I decided then to try to evaluate  the tflite model using this [guide](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/coco_object_detection),  but when i run this command: 
`bazel run -c opt -- //tensorflow/lite/tools/evaluation/tasks/coco_object_detection:run_eval --model_file=/home/gab/PycharmProjects/tensorflow_prova2/new_model_quant_F16Q.tflite --ground_truth_images_path=/home/gab/PycharmProjects/tensorflow_prova2/images  --model_output_labels=/home/gab/PycharmProjects/tensorflow_prova2/label_map.txt --output_file_path=/home/gab/PycharmProjects/tensorflow_prova2/coco_output.txt --debug_mode=true`
output shows odd results like this:
Object [0]
  Score: 33
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.999825
    Normalized Bottom: 0.999262
    Normalized Left: 0.999445
    Normalized Right: 0.999066
Object [1]
  Score: 0
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.998896
    Normalized Bottom: 0.997808
    Normalized Left: 0.998822
    Normalized Right: 0.996969
Object [2]
  Score: 0.780337
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.996294
    Normalized Bottom: 0.988497
    Normalized Left: 0.994716
    Normalized Right: 0.985629
Object [3]
  Score: 0.479028
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.972919
    Normalized Bottom: 0.0584207
    Normalized Left: 0.0640493
    Normalized Right: 0.0434026
Object [4]
  Score: 0
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.0374295
    Normalized Bottom: 0.0290796
    Normalized Left: 0.0313877
    Normalized Right: 0.0227272
Object [5]
  Score: 0
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.0221782
    Normalized Bottom: 0.0208216
    Normalized Left: 0.0213712
    Normalized Right: 0.0207996
Object [6]
  Score: 0
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.0199532
    Normalized Bottom: 0.0192215
    Normalized Left: 0.0193954
    Normalized Right: 0.0187497
Object [7]
  Score: 0
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.0186509
    Normalized Bottom: 0.0180727
    Normalized Left: 0.0181409
    Normalized Right: 0.0176707
Object [8]
  Score: 0
  Class-ID: 1
  Bounding Box:
    Normalized Top: 0.0176005
    Normalized Bottom: 2.02493
    Normalized Left: 0.0637459
    Normalized Right: 0.325256

This is for the first image of the folder i used, one thing i noted is that the first score of the first object is always 33 that is the parameter i changed when i exported the trained model with export_tflite_graph_tf2.py

Is there a way to fix this so i can evaluate my tflite model?
Thanks
"
tensorflow/tensorflow,2023-01-12 00:40:23,question,serialized_pb,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
tensorflow/tensorflow,2023-01-10 17:27:33,question,How to design tf.keras callback to save model predictions for each batch and each epoch,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to create a tf.keras callback to save model predictions for each batch and each epoch during the training using the training data sets to a numpy array

i have tried the following callback, however it gives error like

AttributeError: 'PredictionCallback' object has no attribute 'X_train'
```


### Standalone code to reproduce the issue

```shell
class PredictionCallback(tf.keras.callbacks.Callback):    

  def on_epoch_end(self, epoch, logs={}):

    y_pred = self.model.predict(self.X_train)

    print('prediction: {} at epoch: {}'.format(y_pred, epoch))

    pd.DataFrame(y_pred).assign(epoch=epoch).to_csv('{}_{}.csv'.format(filename, epoch))

    cnn_model.fit(X_train, y_train,validation_data=[X_valid,y_valid],epochs=epochs,batch_size=batch_size,
               callbacks=[model_checkpoint,reduce_lr,csv_logger, early_stopping,PredictionCallback()],
               verbose=1)
```


### Relevant log output

```shell
AttributeError: 'PredictionCallback' object has no attribute 'X_train'


i also tried tensorflow - Create keras callback to save model predictions and targets for each batch during training - Stack Overflow but not get success yet.Hope experts will help me.Thanks.
```
</details>"
tensorflow/tensorflow,2023-01-07 18:08:25,question, cannot import name 'build_info' from 'tensorflow.python.platform',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

Yes

### OS Platform and Distribution

windows 11 22h2

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

no

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

mx150 2gb vram

### Current Behaviour?

```shell
cannot import name 'build_info' from 'tensorflow.python.platform'
```


### Standalone code to reproduce the issue

```shell
cannot import name 'build_info' from 'tensorflow.python.platform'
import tensorflow as tf
from object_detection.utils import config_util
from object_detection.protos import pipeline_pb2
from google.protobuf import text_format
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-01-05 10:54:10,question,i want to reduce the app size with TensorFlowLiteSelectTfOps,"### 1. System information

- ios
- tflite model
- cocoapods
   pod 'TensorFlowLiteObjC', '=2.7.0' 
   pod 'TensorFlowLiteSelectTfOps', '0.0.1-nightly.20210521' 

### 2. Code and Question
with parsing linkmap file ,I found the TensorFlowLiteSelectTfOps take 74 MB, which is too bigger.
when converting the tflite model , my model just use three tensorflow ops:FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack.
who can tell me some ways to reduce the size of app with TensorFlowLiteSelectTfOps
"
tensorflow/tensorflow,2023-01-03 13:06:53,question,a bug in tensorflow,"<details><su

### Standalone code to reproduce the issue



### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-12-29 03:52:23,question,8222c1cfc866126111f23bd9872998480cebf2c1.tar.gz    404,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
https://github.com/tensorflow/tensorflow/archive/8222c1cfc866126111f23bd9872998480cebf2c1.tar.gz  

this file can download at 2022.12.28,today[2022.12.29] is 404
```


### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/tensorflow/archive/8222c1cfc866126111f23bd9872998480cebf2c1.tar.gz  

this file can download at 2022.12.28,today[2022.12.29] is 404
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-12-27 12:26:27,question,ERROR: Could not find a version that satisfies the requirement tensorflow==1.15.2,"I use google colab and was wondering if anyone can solve this problem, if you want to fix my notebook I will leave a link down below, thanks if you solve it!
https://colab.research.google.com/drive/1ecuUD2sxfuM6IOhjZEW3ls-jvbpJEei4?usp=share_link"
tensorflow/tensorflow,2022-12-26 09:33:04,question,error: 'tf.Conv2D' op is neither a custom op nor a flex op,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): v2.10

### 2. Code
Code for conversion
```
converter = tf.lite.TFLiteConverter.from_saved_model(f'savedmodel/decoder')
tflite_model = converter.convert()

# save the model
with open(f'{name}.tflite', 'wb') as f:
      f.write(tflite_model)
```
Code for the model
```
latent = keras.layers.Input((n_h, n_w, 4))
decoder = Decoder()
decoder = keras.models.Model(latent, decoder(latent))
```
```
class Decoder(keras.Sequential):
    def __init__(self):
        super().__init__(
            [
                keras.layers.Lambda(lambda x: 1 / 0.18215 * x),
                PaddedConv2D(4, 1),
                PaddedConv2D(512, 3, padding=1),
                ResnetBlock(512, 512),
                AttentionBlock(512),
                ResnetBlock(512, 512),
                ResnetBlock(512, 512),
                ResnetBlock(512, 512),
                ResnetBlock(512, 512),
                keras.layers.UpSampling2D(size=(2, 2)),
                PaddedConv2D(512, 3, padding=1),
                ResnetBlock(512, 512),
                ResnetBlock(512, 512),
                ResnetBlock(512, 512),
                keras.layers.UpSampling2D(size=(2, 2)),
                PaddedConv2D(512, 3, padding=1),
                ResnetBlock(512, 256),
                ResnetBlock(256, 256),
                ResnetBlock(256, 256),
                keras.layers.UpSampling2D(size=(2, 2)),
                PaddedConv2D(256, 3, padding=1),
                ResnetBlock(256, 128),
                ResnetBlock(128, 128),
                ResnetBlock(128, 128),
                tfa.layers.GroupNormalization(epsilon=1e-5),
                keras.layers.Activation(""swish""),
                PaddedConv2D(3, 3, padding=1),
            ]
        )
```

### 3. Failure after conversion
conversion fails


### 5. (optional) Any other info / logs
[error.log](https://github.com/tensorflow/tensorflow/files/10302790/error.log)
```
Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select 
TF Select ops: Conv2D
Details:
	tf.Conv2D(tensor<?x?x?x?xf32>, tensor<1x1x512x512xf32>) -> (tensor<?x?x?x512xf32>) : {data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
	tf.Conv2D(tensor<?x?x?x?xf32>, tensor<3x3x128x128xf32>) -> (tensor<?x?x?x128xf32>) : {data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
	tf.Conv2D(tensor<?x?x?x?xf32>, tensor<3x3x128x3xf32>) -> (tensor<?x?x?x3xf32>) : {data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
	tf.Conv2D(tensor<?x?x?x?xf32>, tensor<3x3x256x128xf32>) -> (tensor<?x?x?x128xf32>) : {data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
	tf.Conv2D(tensor<?x?x?x?xf32>, tensor<3x3x256x256xf32>) -> (tensor<?x?x?x256xf32>) : {data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
	tf.Conv2D(tensor<?x?x?x?xf32>, tensor<3x3x512x256xf32>) -> (tensor<?x?x?x256xf32>) : {data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
	tf.Conv2D(tensor<?x?x?x?xf32>, tensor<3x3x512x512xf32>) -> (tensor<?x?x?x512xf32>) : {data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
```
According to the error message, I suspect that it can not recognize the input shape. But as you can see on the above code, input is specified for the functional API for `decoder` model. 
(FYI, The inference code is called with `predict_on_batch` method. I found out other model with `predict_on_batch` is converted successfully, but that model doesn't contain `conv2d` block inside. Can using `predict_on_batch` together with `conv2d` be a problem?)

**I'm sure `conv2d` is on the allowlist for TFLite operators. Any suggestions for this problem? Thank you.**"
tensorflow/tensorflow,2022-12-21 14:18:28,question,__init__() got an unexpected keyword argument 'reduction',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.7.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.8.3

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Compile a model with `metrics=[tf.keras.losses.XXX]` does not raise error. The training process seems also good. However, if we save the model and try to reload it, it does not work.

Now I know we could not use `tf.keras.losses` in `metrics`, we must use some functions in `tf.keras.metrics` or some customized metrics. But the error message ""__init__() got an unexpected keyword argument 'reduction'"" gives no information. 

Why not raise an error during the training or even during the compiling? That would be much more friendly for new comers.
```


### Standalone code to reproduce the issue

```shell
import numpy as np
from tensorflow.keras.layers import Dense, Dropout
import tensorflow as tf

input_length = 2
latent_dim = 512
output_length = 2

model = tf.keras.Sequential([
    Dense(latent_dim, activation='relu', input_shape=(input_length,)),
    Dropout(rate=0.5),
    Dense(units=latent_dim, activation='relu'),
    Dense(units=output_length),
  ])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
        loss=tf.keras.losses.MeanSquaredError(),
        metrics=[tf.keras.losses.MeanAbsoluteError()])

x_train = np.ones(shape=(150000, 2))
y_train = np.ones(shape=(150000, 2))

history = model.fit(x_train, y_train, epochs=2, batch_size=128)

model.save('saved_model/my_model')
pretrained = tf.keras.models.load_model('saved_model/my_model')
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""d:/VScode/M2-SMC/debug.py"", line 26, in <module>
    pretrained = tf.keras.models.load_model('saved_model/my_model')
  File ""C:\\Users\\yunhao\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\\Users\\yunhao\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py"", line 784, in from_config
    return cls(**config)
TypeError: __init__() got an unexpected keyword argument 'reduction'
```
</details>"
tensorflow/tensorflow,2022-12-19 10:35:13,question,tf.custom_gradient with multiple input and output,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**: 2.9.2
-   **Python version**: 3.9
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

### Describe the problem
I have a function with 4 inputs (x1, x2, x3, x4) and 2 outputs (y1, y2) using Tensorflow. I would like to specify the gradients, since I perform some non-autodiff operations inside the function.

I need to specify the derivatives of the outputs with respect to the inputs. We can see these derivatives as a Jacobian of size (2,4). Regarding this, I have 8 derivatives: dy1_dx1, dy1_dx2, dy1_dx3, dy1_dx4, dy2_dx1, dy2_dx2, dy2_dx3 and dy2_dx4.

However, the grad function used in this tf.custom.gradient needs to have the same length as the inputs, this is 4. So, I do not know how Tensorflow handles with the introduction of the 8 derivatives using just 4 elements. I tried to include them as lists, but it gives the error. Here is a general code to reproduce the error:

```
import tensorflow as tf
@tf.custom_gradient
def bar(x1, x2, x3, x4):
  def grad(dy1, dy2):
    dy1_dx1 = x2**2 * x3**3 * x4**4             #360000
    dy1_dx2 = x1 * 2*x2 * x3**3 * x4**4         #480000
    dy1_dx3 = x1 * x2**2 * 3*x3**2 * x4**4      #540000
    dy1_dx4 = x1 * x2**2 * x3**3 * 4*x4**3      #576000
    dy2_dx1 = x2**2 + x3**3 + x4**4             #698
    dy2_dx2 = x1 + 2*x2 + x3**3 + x4**4         #697
    dy2_dx3 = x1 + x2**2 + 3*x3**2 + x4**4      #684
    dy2_dx4 = x1 + x2**2 + x3**3 + 4*x4**3      #575
    return [dy1_dx1, dy2_dx1], [dy1_dx2, dy2_dx2], [dy1_dx3, dy2_dx3], [dy1_dx4, dy2_dx4]

  y1 = x1 * x2**2 * x3**3 * x4**4
  y2 = x1 + x2**2 + x3**3 + x4**4
  return [y1, y2], grad

x1 = tf.constant(2.0, dtype=tf.float32)
x2 = tf.constant(3.0, dtype=tf.float32)
x3 = tf.constant(4.0, dtype=tf.float32)
x4 = tf.constant(5.0, dtype=tf.float32)
with tf.GradientTape(persistent=True) as tape:
  tape.watch(x1)
  tape.watch(x2)
  tape.watch(x3)
  tape.watch(x4)
  z = bar(x1, x2, x3, x4)

print(tape.gradient(z, x1))             #[dy1_dx1, dy2_dx1]
print(tape.gradient(z, x2))             #[dy1_dx2, dy2_dx2]
print(tape.gradient(z, x3))             #[dy1_dx3, dy2_dx3]
print(tape.gradient(z, x4))             #[dy1_dx4, dy2_dx4]

```

The  error says: ""custom_gradient function expected to return 4 gradients, but returned 8 instead"".

I expect someway to specify the correspondent 8 derivatives. Thank you in advance!

"
tensorflow/tensorflow,2022-12-13 14:36:30,question,Strange C macro generated by tensorflow.lite.python.util.convert_bytes_to_c_source(),"### 1. System information

Although I believe the system setup does not matter in this issue, here goes:
Windows 10 and Ubuntu 22.10
Python 3.7, Python 3.8, Python 3.10
Tensorflow Lite 2.10 and 2.11 (pip package)


### 2. Code

`tensorflow.lite.python.util.convert_bytes_to_c_source()` generates the following strange C macro:
```
// We need to keep the data array aligned on some architectures.
#ifdef __has_attribute
#define HAVE_ATTRIBUTE(x) __has_attribute(x)
#else
#define HAVE_ATTRIBUTE(x) 0
#endif
#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))
#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))
#else
#define DATA_ALIGN_ATTRIBUTE
#endif
```

The strange part is: `defined(__GNUC__) && !defined(__clang__))`
If the code is compiled with the GNU C compiler, then of course it is not compiled with the Clang compiler. The `&& !defined(__clang__)` seems redundant. And if it's not redundant, can someone explain it to me?"
tensorflow/tensorflow,2022-12-12 09:08:32,question,How to reduce power consumption for gpu delegate on android,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

2.10 or 2.11

### Custom Code

Yes

### OS Platform and Distribution

android

### Mobile device

android

### Python version

3.7

### Bazel version

no 

### GCC/Compiler version

no

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Here it is not a bug.
I want to  reduce power consumption for gpu delegate on android,because I find the execution of tflite model using gpu occupys many power（mA）.
I use opencl backend.
Do you have some optimization method in order to reduce power of model. Thank you very much
```


### Standalone code to reproduce the issue

```shell
my configuration is following,
 TfLiteGpuDelegateOptionsV2 gpu_options = TfLiteGpuDelegateOptionsV2Default();
  gpu_options.inference_priority1 =
      TFLITE_GPU_INFERENCE_PRIORITY_MIN_MEMORY_USAGE;
  gpu_options.inference_priority2 = TFLITE_GPU_INFERENCE_PRIORITY_MIN_LATENCY;
  gpu_options.inference_priority3 = TFLITE_GPU_INFERENCE_PRIORITY_MAX_PRECISION;
  gpu_options.experimental_flags |= TFLITE_GPU_EXPERIMENTAL_FLAGS_ENABLE_QUANT;
 gpu_options.inference_preference =
      TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER;
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-12-12 03:26:56,question, How to release memory when I want to change model with tf.saved_model.load already?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.11

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I use tf.saved_model.load to load a trained model. I want to change another model when it done. But the memory is still high, How to release the memory? I have test tf.keras.backend.clear_session() and gc.collect(), all of these didn't work.
```


### Standalone code to reproduce the issue

```shell
model = tf.saved_model.load(model_dir)

tf.keras.backend.clear_session()
gc.collect()
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-12-11 04:45:52,question,How to calculate the model's flops when I use tensorflow?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I don't find a good way to calculate the model's flops by tensorflow.
```


### Standalone code to reproduce the issue

```shell
I don't find a good way to calculate the model's flops by tensorflow.
```


### Relevant log output

```shell
I don't find a good way to calculate the model's flops by tensorflow.
```
</details>"
tensorflow/tensorflow,2022-12-07 13:56:27,question,Deploy yolo5 model into TensorFlow Lite Object Detection Android,"Hello Tensorflow team!

I checked your real time object detection app which works good with the initial models (MobileNet V1, EfficientNet Lite0, EfficientNet Lite1, EfficientNet Lite2). https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android

But I receive errors when I try to add other model for example yolo5s model trained on COCO dataset which converted from **pt** format to **tflite** with export.py script https://github.com/ultralytics/yolov5/blob/master/export.py

Below you can find converted models for yolo5s (fp16 and int8 options), I already checked they are working fine with detect.py.
https://github.com/HripsimeS/Projects/blob/main/yolov5s-fp16.tflite
https://github.com/HripsimeS/Projects/blob/main/yolov5s-int8.tflite

Is it possible to deploy/integrate yolo5 model into your real time object detection app? If yes, can you please check if you can deploy into app one of those two models (fp16 or int8) I shared with you above. In case if it works for you, can you share your experience what did you exactly modify in initial TensorFlow Lite Object Detection app scripts. Thank you in advance!"
tensorflow/tensorflow,2022-12-06 12:56:25,question,which encoding can i use to parse tensorflow_stats.pb?,"### Issue Type

Others

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

ubuntu 16.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

i get a tensorflow_stats.pb file by tf.profiler. code like this:
```

            tf.profiler.experimental.start(""./logs_dir"")
            loss = dnn_model.train_step(batch_data)
            tf.profiler.experimental.stop()
```
I want to read tensorflow_stats.pb in my python code, but i don't know which Encoding this file use.
the file content is:
```
""ä°
pHostUpdateMetricState""UpdateMetricState(1ňŇMbx@9ňŇMbx@AňŇMbx@IňŇMbx@a×ÝťÁ.Ň?i×ÝťÁ.Ň?Unknown
rHostUpdateMetricState""UpdateMetricState_1(11ŹZB@91ŹZB@A1ŹZB@I1ŹZB@ać
[ŤŻóĚ?iĽą´KAŕ?Unknown
BHostIDLE""IDLE1ÁĘĄEś×l@AÁĘĄEś×l@aľśş?iôűŮă?Unknown
rHostUpdateMetricState""UpdateMetricState_2(1ŮÎ÷ób@9ŮÎ÷ób@AŮÎ÷ób@IŮÎ÷ób@aÍÖ×;Öą?iďîĂÉĺ?Unknown
pHostAsyncPushGradient""AsyncPushGradient(1î|?5^BV@9î|?5^BV@Aî|?5^BV@Iî|?5^BV@ać^EĂ¤?iYÝe÷pç?Unknown
dHostEmbOutputTransfer""label(1×Łp=
I@9×Łp=
I@A×Łp=
I@I×Łp=
I@aiśÂ­¤?i[veĐç?Unknown
\\HostPrintV2""PrintV2(1+ŮÎF@9+ŮÎF@A+ŮÎF@I+ŮÎF@aâÉ­ß?i[ŮŢbyč?Unknown
HostGlobalNormGrad""Bgradient_tape/simple_dnn_model/global_normalization/GlobalNormGrad(19´Čvž?B@99´Čvž?B@A9´Čvž?B@I9´Čvž?B@aĐţ~[ęć?iRŃşľĚé?Unknown
b	Host
```

"
tensorflow/tensorflow,2022-12-02 05:09:17,question,How to convert model with multiple input?,"### 1. System information

- OS Platform and Distribution (e.g., window 10):
- TensorFlow installation (pip package):
- TensorFlow library (tensorflow 2.9.1):

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

I'm use code as below, what should I change to make convertion success? 
```
import numpy as np
import tensorflow as tf
from tensorflow import keras

# how to write ""representative_dataset_gen"" function?
def representative_dataset_gen():
    for _ in range(20):
        data1 = np.random.rand(1, 3, 16, 16).astype(np.float32)
        data2 = np.random.rand(1, 3, 16, 16).astype(np.float32)
        yield [data1, data2]

# build model
kinput1 = keras.Input(shape=(16, 16, 3), batch_size=1, name=""input_1"")
kinput2 = keras.Input(shape=(16, 16, 3), batch_size=1, name=""input_2"")
conv1 = keras.layers.Conv2D(16, 3, 2)(kinput1)
conv2 = keras.layers.Conv2D(16, 3, 2)(kinput2)
out = conv1 + conv2

keras_model = keras.Model(inputs=[kinput1, kinput2], outputs=out)
keras_model.trainable = False
keras_model.summary()

# convert
converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8  # or tf.int8
converter.inference_output_type = tf.uint8  # or tf.int8
converter.representative_dataset = representative_dataset_gen
tflite_model = converter.convert()
with open(""./model.tflite"", ""wb"") as fp:
    fp.write(tflite_model)
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

error info:
```
ValueError: The inference_input_type and inference_output_type must be tf.float32.
```
"
tensorflow/tensorflow,2022-12-01 08:53:42,question,TF-lite model with a Conv2DTranspose layer is fail to run on mobile gpu.,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
  - Conversion env: Centos7
  - Test env: Galaxy S10 `(samsung/beyond1lteks/beyond1:10/QP1A.190711.020/G973NKSU4CTE9:user/release-keys)`
- TensorFlow installation (pip package or built from source): pip install
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.10.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:
```
def get_model():
    inputs = tf.keras.Input(shape=(64, 64, 3))
    x = keras.layers.Conv2D(16, 3, activation=""relu"", name=""conv1"")(inputs)
    x = keras.layers.Conv2D(16, 3, activation=""relu"", name=""conv2"")(x)
    x = keras.layers.Conv2DTranspose(16, 3, strides=2, activation=""relu"", name=""deconv1"")(x)
    x = keras.layers.Conv2DTranspose(16, 3, strides=2, activation=""relu"", name=""deconv2"")(x)
    outputs = x
    
    model = keras.Model(inputs=inputs, outputs=outputs, name=""custom"")

    x = tf.ones((5, 64, 64, 3))
    y = model(x)

    print(x.shape)
    print(y.shape)
    
    return model

def convert_model(saved_model_dir, tflite_save_dir):
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float32]
    tflite_model = converter.convert()

    with open(tflite_save_dir, ""wb"") as f:
        f.write(tflite_model)

if __name__==""__main__"":
    model = get_model()

    current_path = os.path.dirname(os.path.realpath(__file__))
    save_dir = os.path.join(current_path, ""custom/1/"")
    tf.saved_model.save(model, save_dir)

    tflite_save_dir = os.path.join(current_path, ""my_model.tflite"")
    convert_model(save_dir, tflite_save_dir)
    test_tflite(tflite_save_dir)
```

### 3. Failure after conversion
TF Lite conversion and run on the mobile phone with cpu is OK, but when running with gpu, an error occurs. (I tested the model in adb shell)
![image](https://user-images.githubusercontent.com/33739495/205008146-3abb7c7e-9fea-4361-88cb-a110b6ca1aaa.png)"
tensorflow/tensorflow,2022-11-28 07:08:17,question,Add support for 3rd part object storage (S3) in Docker image,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.6+

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When using tensorflow docker image to run tensorboard (Kubeflow uses this method), out of the box the image only supports gcs-filesystem and to support for 3rd party object storage (eg. S3) due to the dependency on `tensorflow-io`. The ask is to make tensorflow-io as required pip dependency while docker build happens that way lot of customizations could be avoided and the support is out of the box.
```


### Standalone code to reproduce the issue

```shell
When using the below sample spec (simplified to make the reproducibility easy):

    spec:
      affinity: {}
      containers:
      - args:
        - AWS_REGION=us-east-1 S3_ENDPOINT=https://SOME_S3_ENDPOINT
          AWS_ACCESS_KEY_ID=SOME_AWS_KEY AWS_SECRET_ACCESS_KEY= SOME_AWS_SECRET /usr/local/bin/tensorboard
          --logdir=s3:/LOGS_PATH --bind_all
        command:
        - /bin/sh
        - -c
        image: tensorflow/tensorflow:2.11.0
        imagePullPolicy: IfNotPresent
        name: tensorboard
        ports:
        - containerPort: 6006
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        workingDir: /
      dnsPolicy: ClusterFirst
      imagePullSecrets:
      - name: regcred
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
```


### Relevant log output

```shell
when the above Spec is deployed we will run into the following error `Error: Unsupported filename scheme 's3' (supported schemes: ['ram', 'file', '', 'gs']). For additional filesystem support, consider instal │
│ ling TensorFlow I/O (https://www.tensorflow.org/io) via `pip install tensorflow-io`.`
```
</details>"
tensorflow/tensorflow,2022-11-25 11:33:46,question,AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_unique_id',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Debian64 ( Unix )

### Mobile device

_No response_

### Python version

3.10.4

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hello to Everyone

I need to training an Actor network for a reinforcement learning algorithm but in time i am trying to predict continuous actions i have a problem with the function: 

self.Actor.optimizer.apply_gradients ( zip ( grads2 , std ) )

also this one gives me the same error:
self.Actor.optimizer.apply_gradients ( zip ( [ grads1 , grads2 ] , [ self.Actor.model.trainable_variables , std ] ) )

Please note that with the following function all goes well:
self.Actor.optimizer.minimize ( loss_actions , var_list = [ self.Actor.model.trainable_variables , std ] , tape = tape_actions )

the problem seems to be caused by the external variable std ( that it is not internal to the model ), Did I make some mistakes? is there a way to clip_by_norm the std variable's gradients ?

Best Regards Samir
```


### Standalone code to reproduce the issue

```shell
one = tf.ones ( self.settings.action_size , dtype = float )
std = tf.Variable ( one , dtype = float , name = 'std' )

sample = self.replay.sample ()

with tf.GradientTape ( persistent = False ) as tape_actions :
     tape_actions.reset ()
               
     actions_local = self.Actor.model ( sample [ 0 ] )

     tfp_dist  = tfp.distributions.Normal ( loc = actions_local , scale = std )
     new_probs = tfp_dist.log_prob        (       sample [ 1 ]                )
     new_probs = tf.math.reduce_sum       (       new_probs     , axis  = 1   )
     new_probs = tf.math.exp              (       new_probs                   )

     ratio = new_probs / sample [ 3 ] # >= 0

     ratio = tf.math.reduce_min (
             tf.convert_to_tensor ( [ ratio * sample [ 4 ] , \\
             tf.clip_by_value     (   ratio , clip_value_min = 1 - 0.1 ,
                                              clip_value_max = 1 + 0.1 ) * sample [ 4 ] ] ) ,
                                   axis = 0 )

     loss_actions = - tf.math.reduce_mean ( ratio )

grads = tape_actions.gradient ( loss_actions , [ self.Actor.model.trainable_variables , std ] )

grads1 = [ tf.clip_by_norm ( t = w , clip_norm = 0.75 ) for w in grads [ 0 ] ]
grads2 = [ tf.clip_by_norm ( t = w , clip_norm = 0.75 ) for w in grads [ 1 ] ]

self.Actor.optimizer.apply_gradients ( zip ( grads1 , self.Actor.model.trainable_variables ) )
self.Actor.optimizer.apply_gradients ( zip ( grads2 ,                                  std ) )
```


### Relevant log output

```shell
1/1250/usr/lib/python3/dist-packages/apport/report.py:13: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses
  import fnmatch, glob, traceback, errno, sys, atexit, locale, imp, stat
Traceback (most recent call last):
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/Reacher.py"", line 43, in <module>
    future.cross_entropy_loss ()
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 295, in cross_entropy_loss
    self.play_EP ( ie , self.settings.envs.reset ( train_mode = True ) [ self.settings.brain_name ] )
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 78, in play_EP
    print ( '' ) ; self.training_for_elite (real_steps_to_train) ; print ( '' )
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 169, in training_for_elite
    self.training ( self.future_rewards_elite , real_steps_to_train )
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 272, in training
    self.Actor.optimizer.apply_gradients ( zip ( grads2 ,                                  std ) )
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 695, in apply_gradients
    self._create_all_weights(var_list)
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 959, in _create_all_weights
    self._create_slots(var_list)
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py"", line 126, in _create_slots
    self.add_slot(var, ""m"")
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 1017, in add_slot
    var_key = _var_key(var)
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 1650, in _var_key
    return var._unique_id
  File ""/home/kaumi/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 446, in __getattr__
    self.__getattribute__(name)
AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_unique_id'
```
</details>"
tensorflow/tensorflow,2022-11-23 12:26:12,question,How much FPS in iOS (Swift)?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

 pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

MacOS

### Mobile device

iPhone X

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Can I increase number of frames per second?
```


### Standalone code to reproduce the issue

```shell
How much FPS in iOS (Swift)?
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-11-21 12:00:10,question,TensorFlow Lite Quantization Debugger Issue,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.3 
- TensorFlow library (version, if pip package or github SHA, if built from source):tensorflow-gpu==2.10.0

### 2. Code

def dense_block(inputs, filters):

    y = Dense(units=filters,use_bias=False)(inputs)
    y = BatchNormalization()(y)
    return y

def model():
    inputs = Input(shape = (112, 112, 3))
    .
    .
    .
    .
    .
    .
    .
    x = dense_block(x, 1)  -> (input_size=1,1,1,256, output_size=1,1,1,1)
    return Model(inputs, x)

### 3. conversion is successful,but the predicted value of int8 tflite has a large error value with the .pb weights file
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and accuracy drop 7~15%.

### 5. (optional) Any other info / logs

Question1:
My weights .pb file is successfully quantized into an int8 tflite model.
When doing tf.lite.experimental.QuantizationDebugger, the rmse/scale value of the last layer(Conv2D) is 2, which is far more than 0.289, but the rmse/scale values ​​in other layers are all It is around 0.289, and if I change the output of the last layer to more nodes, the value of rmse/scale of the last layer will be closer to 0.289.

Does anyone know what could be causing this to happen?
thanks!"
tensorflow/tensorflow,2022-11-18 12:10:40,question,from keras.models import load_model raises no module named tensorflow.compat error,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

Windoes 11

### Mobile device

_No response_

### Python version

3.7.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When doing  keras.models import load_model, An error saying no module named tensorflow.compat appears
```


### Standalone code to reproduce the issue

```shell
Just open python 3.7 and type  keras.models import load_model
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""c:/Users/Noah Ryu/Coding/AI/Teachable Machine/Guesser3.py"", line 1, in <module>
    from keras.models import load_model # TensorFlow is needed for Keras to work
  File ""C:\\Users\\Noah Ryu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\__init__.py"", line 21, in <module>
    from keras import models
  File ""C:\\Users\\Noah Ryu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\models\\__init__.py"", line 18, in <module>  
    from keras.engine.functional import Functional
  File ""C:\\Users\\Noah Ryu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\functional.py"", line 24, in <module>
    import tensorflow.compat.v2 as tf
ModuleNotFoundError: No module named 'tensorflow.compat'
```
</details>"
tensorflow/tensorflow,2022-11-16 09:33:42,question,there is no operator to calculate the matrix's inverse using tflite,"tf.raw_ops.MatrixInverse and tf.linalg.svd is not supported in tflite 
BatchMatrixInverse is not available in GraphDef version 1205.

Hence， how to calculate the matrix's inverse using tflite?

I need some Op to calculate the  matrix's inverse


best wishes




"
tensorflow/tensorflow,2022-11-14 10:02:34,question,difference between core/grappler/optimizers/graph_optimizer.h and core/common_runtime/graph_optimizer.h,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

2.6

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
This is not a bug report, just a question.
Now I'm learning the source code of tensorflow and I can't understand the difference between these two graph_optimizer.h(core/grappler/optimizers/graph_optimizer.h and core/common_runtime/graph_optimizer.h). Can anyone explain this for me? Thanks.
```


### Standalone code to reproduce the issue

```shell
none
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-11-11 13:43:33,question,old versions of tflite native benchmark binaries,"Hi, is it possible to download old versions of tflite native benchmark binaries? I can find [here](https://www.tensorflow.org/lite/performance/measurement#download_or_build_the_binary) only the nightly version.
"
tensorflow/tensorflow,2022-11-09 11:45:26,question,Running TensorFlow on SHArC processors?,Are there any information on the possibility to compile TensorFlow (Lite C) targeting SHArC processor from Analog Devices? 
tensorflow/tensorflow,2023-09-29 11:30:45,feature,implement llama 2 using Tensorflow,"### Issue type

Feature Request

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.8

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

-

### Standalone code to reproduce the issue

```shell
-
```


### Relevant log output

```shell
-
```
"
tensorflow/tensorflow,2023-08-26 19:26:42,feature,Will there a MLP model in the future version?,"### Issue type

Feature Request

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13.0

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When building deep learning models like Multi-Layer Perceptrons (MLPs), code reusability and conciseness are crucial factors. Currently, using `tf.keras.Sequential` in TensorFlow allows for convenient creation of sequential models. However, manually adding common operations such as Batch Normalization or Dropout to each layer can lead to code redundancy and an increased burden in terms of coding and maintenance. Therefore, proposing the addition of a feature in TensorFlow to directly create MLPs with Batch Normalization and Dropout is highly beneficial.

Here are several reasons why this feature would be advantageous for TensorFlow users:

1. **Simplified Code**: Users won't need to manually add Batch Normalization and Dropout operations to each layer, resulting in cleaner, more readable, and maintainable code.

2. **Reduced Error Rate**: Manual copy-pasting of code is error-prone, especially as model complexity increases. Automating the integration of Batch Normalization and Dropout operations can reduce issues arising from code errors.

3. **Increased Productivity**: Developers can build and iterate on models more swiftly, focusing on design and parameter tuning rather than rewriting the same code segments for every new model.

4. **Education and Learning**: For newcomers to TensorFlow, this feature can provide a quicker onboarding process, lowering the learning curve and enabling them to grasp and apply deep learning concepts faster.

Certainly, here's the additional information:

I also believe that PyTorch has implemented MLP functionality quite effectively. An example of this can be found in the following URL: [PyTorch MLP](https://pytorch.org/vision/main/generated/torchvision.ops.MLP.html). PyTorch's approach to creating MLPs provides a good reference for how TensorFlow could potentially integrate similar features.

### Standalone code to reproduce the issue

origin
```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(64),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(32),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10),
])
```


with MLP model
```python
model = tf.keras.MLP(
    hidden_channels=[128, 64, 32, 10],
    norm_layer=tf.keras.layers.BatchNormalization,
    activation_layer=tf.keras.layers.ReLU,
    dropout=0.2,
)
```

### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-15 18:28:52,feature,pybind11_proto from python to C++,"@BlaziusMaximus thanks for the explanation.
I've been exploring how to update the [`import_graph_def()`](https://github.com/tensorflow/tensorflow/blob/v2.13.0/tensorflow/python/framework/importer.py#L353-L411) code-path to use pybind11_protobuf and I could use your help with the following:  Similar to how pybind11_protobuf allows us to pass protos directly from C++ to Python, is there a way to pass a `GraphDef` proto from python to C++ without performing serialization? This would be needed to invoke the [TF_GraphImportGraphDefWithResults](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.cc#L1801) from pywrap session in C++.

_Originally posted by @othakkar in https://github.com/tensorflow/community/issues/453#issuecomment-1674101660_
            "
tensorflow/tensorflow,2023-08-05 11:48:09,feature,[Feature] The Heaviside step function as a activation function,Some of the implementations like Single Layer Perceptron needs discrete outputs like 0 or 1. Adding this could make the model building ease.
tensorflow/tensorflow,2023-07-25 04:10:16,feature,float8 support for array ops,"### Issue type

Feature Request

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.12.0

### Custom code

No

### OS platform and distribution

macOS-13.2.1-arm64-arm-64bit

### Mobile device

_No response_

### Python version

3.9.6

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Please add FP8 datatype support for array ops (like Reshape, Transpose, GatherV2, ExpandDims, Squeeze, ConcatV2, Split, Pack, Unpack, and StridedSlice).

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.python.framework import dtypes

a = tf.constant([[1.2345678, 2.3456789, 3.4567891], [4.5678912, 5.6789123, 6.7891234]], dtype=dtypes.float16)
print(a)

a_fp8 = tf.cast(a, dtypes.float8_e4m3fn)
print(a_fp8)

b = a_fp8[1:2] # tensorflow.python.framework.errors_impl.NotFoundError
b = tf.transpose(a_fp8, [1, 0]) # tensorflow.python.framework.errors_impl.NotFoundError
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-16 21:10:22,feature,Issue still tittle,"### Issue type

Documentation Feature Request

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

Tf2.8

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

What you see what I'm see

### Standalone code to reproduce the issue

```shell
Us see you
```


### Relevant log output

```shell
Productive projects
```
"
tensorflow/tensorflow,2023-06-22 12:42:38,feature,the tf keras models load_model() used for loading ml model is not able to load model,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Hi, I am trying to load my deep learning model using  **tensorflow keras models load_model ()** . when I run it for first time it got loaded but from next time** it is not loading**. Like it is in this function for more than 30 min. 

I store my model in **.h5** format. model size is approx 13 MB.
At the time of saving deep learning, I use model.save() 

I am using a machine with 128 GB RAM. 
I am using multiprocessing with no of worker 16. Sometime it worked and sometime is got stucked.


### Standalone code to reproduce the issue

```shell
tensorflow.keras.models.load_model.()
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-17 03:43:54,feature,tf.keras.metrics.Precision treats label as binary?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

binary

### Tensorflow Version

2.14.0-dev20230611

### Custom Code

Yes

### OS Platform and Distribution

Linux

### Mobile device

NA

### Python version

3.11.3

### Bazel version

NA

### GCC/Compiler version

NA

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

tf.keras.metrics.Precision is returning precision assuming the label is binary? It looks so to me.

See:

```
In [4]: m = tf.keras.metrics.Precision()
   ...: m.update_state([0, 1, 2, 3], [0, 1, 2, 2])
   ...: m.result().numpy()
Out[4]: 1.0

In [5]: import tensorflow as tf

In [6]: m = tf.keras.metrics.Precision()
   ...: m.update_state([0, 1, 2, 3], [0, 1, 2, 2])
   ...: m.result().numpy()
Out[6]: 1.0

In [7]: tf.__version__
Out[7]: '2.14.0-dev20230611'

In [8]: m = tf.keras.metrics.Precision()
   ...: m.update_state([0, 5, 3, 3], [0, 1, 2, 2])
   ...: m.result().numpy()
Out[8]: 1.0
```

Above shouldn't be 1.0 if labels are treated as non binary.  It appears to me that 0s are treated as 0 while non zeros are treated as 1.

But nowhere in the doc mentions this behavior. I can't find categorical precision or similar either. Please update doc to explain this behavior.

### Standalone code to reproduce the issue

```shell
See above.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-10 20:48:10,feature,"Could not interpret loss function ""NDCG Lambda Weight V2""","A erro happened!
Could not interpret loss function NDCG Lambda Weight V2

-------------------------------------------------------------------
model.compile (

optimizer=optimizer,   

loss=tfr.keras.losses.NDCGLambdaWeightV2(topn=60),
                           
metrics=[tfr.keras.metrics.NDCGMetric(topn=60), tfr.keras.metrics.OPAMetric()]

 )

model.fit(train_dataset, epochs=20)
-------------------------------------------------------------
some error happened in "" mode.fit()""
ValueError: Could not interpret loss function identifier: <tensorflow_ranking.python.keras.losses.NDCGLambdaWeightV2 object at 0x7fa0e84ee6e0>"
tensorflow/tensorflow,2023-06-08 12:25:39,feature,GPU Delegate dynamic tensor input shape (Feature Request),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf 2.12.0

### Custom Code

Yes

### OS Platform and Distribution

Android

### Mobile device

Android

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Hello, I'm writing you to ask, are there plans to implement dynamic input shape in gpu delegate in near future ? 

Right now dynamic input shape working fine on cpu, but on gpu delegate I'm getting the issue 
`java.lang.IllegalArgumentException: Internal error: Error applying delegate: `

This is very important feature, if this feature already exist and it is possible somehow to rung with dynamic shape will be good to have some information in documentation. 


### Standalone code to reproduce the issue

```shell
@Throws(IOException::class)
    private fun initInterpreter(context: Context): Interpreter {

        val tfliteOptions = Interpreter
            .Options()
        
        if (delegate != null) {
            tfliteOptions.addDelegate(delegate)
            tfliteOptions.numThreads = 1
        } else {
            tfliteOptions.numThreads = 4
        }

        val interpreter = Interpreter(loadModelFile(context), tfliteOptions)
        
        interpreter.resizeInput(0, intArrayOf(1, modelHeight, modelWidth, 3), true)
        interpreter.allocateTensors()
        
        return interpreter
    }
```


### Relevant log output

```shell
java.lang.IllegalArgumentException: Internal error: Error applying delegate: 
org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:110)
org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:73)
org.tensorflow.lite.NativeInterpreterWrapperExperimental.<init>(NativeInterpreterWrapperExperimental.java:36)
org.tensorflow.lite.Interpreter.<init>(Interpreter.java:214)
```
</details>"
tensorflow/tensorflow,2023-06-07 07:16:25,feature,Add docs reference to latest numpy version for `tf.experimental.numpy` functions,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.12.0

### Custom Code

No

### OS Platform and Distribution

Linux ubuntu 18.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

As the tf version requirements for running the latest version we need the latest version of numpy and all `tf.experimental.numpy` functions point to the `numpy` `v1.16` https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/allclose

I am thinking if we can update the referencing docs link.

Thanks

### Standalone code to reproduce the issue

```shell
Check this https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/allclose
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-05-05 22:48:10,feature,"Network-Level Control of Precision (fp32 in training, fp16 in inference)","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

binary

### Tensorflow Version

tf 2.12

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

A very common use case is that we train and export the model in fp32, then use fp16 mode in inference. But it seems XLA doesn't support this?

It would be good if XLA can support [Network-Level Control of Precision](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#network-level-control) like TensorRT

### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-05-03 17:40:14,feature,How to write custom XLA op for tensorflow,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

binary

### Tensorflow Version

2.12.0

### Custom Code

Yes

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Hi,

I have custom tensorflow ops implemented in C++ [using this guide](https://www.tensorflow.org/guide/create_op) which are invoked during training. They work fine as long as XLA is not used, however I'm unable to get them working (and even a dummy custom xla op). 

The test op I have written is mentioned below and compiled by following the guide linked above. The compilation succeeds but I get following runtime error when the module with custom op is imported:

```
Non-OK-status: lookup_status status: NOT_FOUND: Op type not registered 'XlaTestOp' in binary running on <hostname>. Make sure the Op and Kernel are registered in the binary running in this process. 
```

I'm not able to find any more info how to resolve this issue. 



### Standalone code to reproduce the issue

```shell
C++ XLA op implementation:



#include ""tensorflow/compiler/tf2xla/shape_util.h""
#include ""tensorflow/compiler/tf2xla/xla_compiler.h""
#include ""tensorflow/compiler/tf2xla/xla_op_kernel.h""
#include ""tensorflow/compiler/tf2xla/xla_op_registry.h""
#include ""tensorflow/compiler/xla/client/xla_builder.h""
#include ""tensorflow/compiler/xla/service/custom_call_target_registry.h""
#include ""tensorflow/compiler/xla/service/hlo.pb.h""
#include ""tensorflow/compiler/xla/shape.h""
#include ""tensorflow/compiler/xla/xla_data.pb.h""
#include ""tensorflow/core/framework/op_kernel.h""
#include ""tensorflow/core/lib/hash/hash.h""
#include ""tensorflow/core/platform/human_readable_json.h""

void test_op(cudaStream_t stream, void** buffers, const char* opaque,
                     size_t opaque_len) {
  std::cout << ""executing test_op()\\n"";
}



class XLATestOp : public XlaOpKernel {
public:
  explicit XLATestOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) { }

  void Compile(XlaOpKernelContext* ctx) override {

    ::xla::XlaBuilder* const builder = ctx->builder();
    ::xla::XlaOp input = ctx->Input(0);

    // use output aliasing to reuse input buffer for output
    std::vector<std::pair<::xla::ShapeIndex,
        std::pair<int64, ::xla::ShapeIndex>>> output_operand_aliasing = {
        {::xla::ShapeIndex{}, {0, ::xla::ShapeIndex{}}}
    };

    ::xla::Shape output_shape = builder->GetShape(input).value();

    ::xla::XlaOp output_op = builder->ReportErrorOrReturn(
        ::xla::CustomCall(
            builder,
            ""test_op"",
            {input},
            output_shape,
            /*opaque=*/ """",
            /*has_side_effect=*/false,
            output_operand_aliasing,
            /*literal=*/nullptr
        )
    );

    ctx->SetOutput(0, output_op);
  }
};


REGISTER_XLA_OP(Name(""XlaTestOp""), XLATestOp);
XLA_REGISTER_CUSTOM_CALL_TARGET(test_op, ""CUDA"");
```
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-04-19 02:51:07,feature,Need Add Perl to Supported API Languages,"This page lists all the languages with support for the TensorFlow API:
https://www.tensorflow.org/api_docs

Thanks to an official grant from The Perl Foundation, we have recently released a Perl API:
https://github.com/EntropyOrg/perl-AI-TensorFlow-Libtensorflow
https://metacpan.org/dist/AI-TensorFlow-Libtensorflow

How do we go about getting Perl added to the list?"
tensorflow/tensorflow,2023-03-27 22:59:29,feature,Make time series_from_array() more intuitive to use,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.10.0 (Tensorflow-macos)

### Custom Code

Yes

### OS Platform and Distribution

MacOS 13.2.1

### Mobile device

_No response_

### Python version

3.10.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

TimeseriesGenerator() is deprecated, and Tensorflow docs encourage the use of time series_from_array() instead. However, this is not intuitive to use, requiring far more boilerplate code to achieve the same effect.

In addition, the results are not as expected. I spent hours debugging my code to realise time series_from_array() is not behaving as expected. Using the code below, I would expect there to be 6 different inputs and outputs, however, there are only 3. Running the same code with TimeseriesGenerator(), without the [:-4] and [4:] indexing, produces the expected 6 inputs and outputs.


### Standalone code to reproduce the issue

```shell
x = np.zeros((10, 3))
y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

test = keras.utils.timeseries_dataset_from_array(x[:-4], y[4:], sequence_length=4, batch_size=2000)
list(test.as_numpy_iterator())
```


### Relevant log output

```shell
[(array([[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],
  
         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],
  
         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]),
  array([5, 6, 7]))]
```

### Code for TimeseriesGenerator() (expected output)

```Python
test = keras.preprocessing.sequence.TimeseriesGenerator(x, y, length=4)
test[0]
```

### Expected output

```shell
(array([[[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]],
 
        [[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]],
 
        [[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]],
 
        [[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]],
 
        [[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]],
 
        [[0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.],
         [0., 0., 0.]]]),
 array([ 5,  6,  7,  8,  9, 10]))
```

</details>"
tensorflow/tensorflow,2023-03-20 11:56:44,feature,How to build with xnnpack,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

ubuntu 20.04

### Mobile device

Qualcomm

### Python version

3.8

### Bazel version

5.1.1

### GCC/Compiler version

9.3.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to build without xnnpack, or with xnnpack-qs8 diabled. How to achieve that?
```


### Standalone code to reproduce the issue

```shell
I tried with ""--define=tflite_with_xnnpack_qu8=false --define=tflite_with_xnnpack_qs8=false"", and ""--define tflite_with_xnnpack=false"". But it seems that they didn't work.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-03-02 12:21:42,feature,Freeze zero weights during training,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Is there any way to freeze zero weights during model retraining? (this is different than freezing a layer which is already available in TF)
This is relevant to model pruning. For example, i want to retrain only non-zero weights of a pruned model. Is it possible to use tf.IndexedSlices efficiently for this?
```


### Standalone code to reproduce the issue

```shell
I think we can achieve this if there's any feature in TF to calculate grads only for non-zero weights. I couldn't find any method to achieve this 

@tf.function
def train_step(inputs, targets):
    with tf.GradientTape() as tape:
       predictions = model(inputs, training=True)
       loss_value = loss_fn(targets, predictions)
    grads = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(grads, model.trainable_weights))
    return loss_value
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-02-17 16:37:57,feature,Cast int32 to bfloat16 does not run on A100 GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

TensorFlow version 2.13.0-dev20230215

### Custom Code

Yes

### OS Platform and Distribution

ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.8/8.6

### GPU model and memory

single A100 80G

### Current Behaviour?

```shell
when using tf.cast to cast tf.int32 tensor to tf.bfloat16 tensor, op run on GPU.

when i convert int32->bfloat16, it run on CPU.
when i convert int32->float32->bfloat16, it run on GPU. is it expected ?
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras import mixed_precision

tf.debugging.set_log_device_placement(True)
policy = mixed_precision.Policy('mixed_bfloat16')
print(policy.name)
mixed_precision.set_global_policy(policy)

class toy_layer(tf.keras.layers.Layer):
  def build(self, input_shape):
    self.kernel = self.add_weight('kernel', (input_shape[-1], 10))
  def call(self, inputs):
    out = tf.linalg.matmul(inputs, self.kernel)
    out2 = tf.ones((10, 10), dtype=tf.int32)
    #out2 = tf.cast(out2, tf.float32, name=""cast_out2_1"")
    out2 = tf.cast(out2, out.dtype, name=""cast_out2_2"")
    out3 = out * out2
    return out3

layer = toy_layer()
y = layer(tf.ones((10, 10)))
```


### Relevant log output

```shell
2023-02-17 16:26:34.748024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-17 16:26:35.370677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
mixed_bfloat16
2023-02-17 16:26:36.876507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78915 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0001:00:00.0, compute capability: 8.0
input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:36.886233: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:36.886254: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0
output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:36.886267: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:36.889118: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.293473: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.293513: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0
output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.293521: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.294777: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
dims: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.295227: I tensorflow/core/common_runtime/placer.cc:114] dims: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.295238: I tensorflow/core/common_runtime/placer.cc:114] value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
Fill: (Fill): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.295250: I tensorflow/core/common_runtime/placer.cc:114] Fill: (Fill): /job:localhost/replica:0/task:0/device:GPU:0
output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.295257: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.295729: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.297303: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.297667: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.297928: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.298227: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
seed: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.298533: I tensorflow/core/common_runtime/placer.cc:114] seed: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
StatelessRandomGetKeyCounter: (StatelessRandomGetKeyCounter): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.298547: I tensorflow/core/common_runtime/placer.cc:114] StatelessRandomGetKeyCounter: (StatelessRandomGetKeyCounter): /job:localhost/replica:0/task:0/device:GPU:0
key_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.298561: I tensorflow/core/common_runtime/placer.cc:114] key_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
counter_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.298573: I tensorflow/core/common_runtime/placer.cc:114] counter_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.299212: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.300704: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
shape: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.300963: I tensorflow/core/common_runtime/placer.cc:114] shape: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
key: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.300974: I tensorflow/core/common_runtime/placer.cc:114] key: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
counter: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.300979: I tensorflow/core/common_runtime/placer.cc:114] counter: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
alg: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.300993: I tensorflow/core/common_runtime/placer.cc:114] alg: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
StatelessRandomUniformV2: (StatelessRandomUniformV2): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.300999: I tensorflow/core/common_runtime/placer.cc:114] StatelessRandomUniformV2: (StatelessRandomUniformV2): /job:localhost/replica:0/task:0/device:GPU:0
output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.301008: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.301526: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op StatelessRandomUniformV2 in device /job:localhost/replica:0/task:0/device:GPU:0
x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.302304: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.302316: I tensorflow/core/common_runtime/placer.cc:114] y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
Sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.302332: I tensorflow/core/common_runtime/placer.cc:114] Sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.302338: I tensorflow/core/common_runtime/placer.cc:114] z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.302706: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0
x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.303361: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.303372: I tensorflow/core/common_runtime/placer.cc:114] y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.303379: I tensorflow/core/common_runtime/placer.cc:114] Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.303391: I tensorflow/core/common_runtime/placer.cc:114] z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.303748: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0
x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.304205: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.304216: I tensorflow/core/common_runtime/placer.cc:114] y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
AddV2: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.304223: I tensorflow/core/common_runtime/placer.cc:114] AddV2: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0
z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.304229: I tensorflow/core/common_runtime/placer.cc:114] z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.304663: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op AddV2 in device /job:localhost/replica:0/task:0/device:GPU:0
resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.305249: I tensorflow/core/common_runtime/placer.cc:114] resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.305263: I tensorflow/core/common_runtime/placer.cc:114] VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.305637: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0
resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.306104: I tensorflow/core/common_runtime/placer.cc:114] resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.306122: I tensorflow/core/common_runtime/placer.cc:114] value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.306139: I tensorflow/core/common_runtime/placer.cc:114] AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.306554: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0
x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.307498: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.307523: I tensorflow/core/common_runtime/placer.cc:114] Cast: (Cast): /job:localhost/replica:0/task:0/device:GPU:0
y_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.307532: I tensorflow/core/common_runtime/placer.cc:114] y_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.307943: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0
resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.308714: I tensorflow/core/common_runtime/placer.cc:114] resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.308734: I tensorflow/core/common_runtime/placer.cc:114] ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
value_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.308743: I tensorflow/core/common_runtime/placer.cc:114] value_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.309154: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.309366: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Cast in device /job:localhost/replica:0/task:0/device:GPU:0
a: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.309693: I tensorflow/core/common_runtime/placer.cc:114] a: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
b: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.309710: I tensorflow/core/common_runtime/placer.cc:114] b: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.309727: I tensorflow/core/common_runtime/placer.cc:114] MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
product_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.309738: I tensorflow/core/common_runtime/placer.cc:114] product_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.310165: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.897703: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.897841: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0
dims: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.898261: I tensorflow/core/common_runtime/placer.cc:114] dims: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
value: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.898272: I tensorflow/core/common_runtime/placer.cc:114] value: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0
Fill: (Fill): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.898280: I tensorflow/core/common_runtime/placer.cc:114] Fill: (Fill): /job:localhost/replica:0/task:0/device:GPU:0
output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.898285: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.898934: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0
x: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.899509: I tensorflow/core/common_runtime/placer.cc:114] x: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0
Cast: (Cast): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.899523: I tensorflow/core/common_runtime/placer.cc:114] Cast: (Cast): /job:localhost/replica:0/task:0/device:CPU:0
y_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.899530: I tensorflow/core/common_runtime/placer.cc:114] y_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0
2023-02-17 16:26:37.899935: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Cast in device /job:localhost/replica:0/task:0/device:CPU:0
x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.900335: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.900348: I tensorflow/core/common_runtime/placer.cc:114] y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0
Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.900361: I tensorflow/core/common_runtime/placer.cc:114] Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.900369: I tensorflow/core/common_runtime/placer.cc:114] z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0
2023-02-17 16:26:37.901006: I tensorflow/core/common_runtime/eager/execute.cc:1514] Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0
```
</details>"
tensorflow/tensorflow,2023-02-11 08:30:30,feature,Feature Request: More descriptive get_weights() method,"### Issue Type

Feature Request

### Tensorflow Version

tf 2.11.0

### OS Platform and Distribution

Windows 11

### Python version

3.10.9


Hello!
Currently, I can get the weights of each layer of a Keras model by calling TensorFlow's `get_weights()` method. Additionally, this method returns the bias of the layer if the `use_bias` term is true. There is no mention of the order in which weights and biases are returned in TensorFlow or Keras documentation. When the method returns two or more NumPy arrays, how can we determine what these layers represent?

It would be awesome if the `get_weights()` method could also indicate whether a particular NumPy array is a weights array, bias array, etc.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

def get_model():
    mnist_model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.45),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.45),
    tf.keras.layers.Dense(10)])
    return mnist_model


def get_model_state_dict(model):
    for index, layer in enumerate(model.layers):
        print(model.layers[index].get_weights())

state_dict = (get_model_state_dict(get_model()))
```


"
tensorflow/tensorflow,2023-02-01 20:42:46,feature,Proto file missing in nightly wheels,"### Have you reproduced the bug with TF nightly?

Yes


### Tensorflow Version

tf 2.12

### Current Behaviour?

I work on the TensorFlow-DirectML plugin, and we use the .proto files included in the TF wheel to generate pb.cc/pb.h files needed by the plugin. One of the files needed is the tensorflow/tsl/profiler/protobuf/xplane.proto file, which has not been included in the nightly wheels so far. Would it be possible to make sure that it's included for TF 2.12?"
tensorflow/tensorflow,2023-01-19 11:02:01,feature,How to change specific body line colour eg. Hip-Knee-Ankle line in swift ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

MacOS

### Mobile device

iPhone X

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Unable to change specific body line colour eg. Hip-Knee-Ankle line in swift
```


### Standalone code to reproduce the issue

```shell
How to change specific body line colour eg. Hip-Knee-Ankle line in swift
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-01-16 21:25:50,feature,keras.models.clone_model not working,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
To clone a model using keras.models.clone_model to keep ema weights
```


### Standalone code to reproduce the issue

```shell
When cloning a model that inherits from (tf.keras.models.Model), can't use keras.models.clone_model.
```


### Relevant log output

```shell
ValueError                                Traceback (most recent call last)
Input In [20], in <cell line: 1>()
----> 1 gan = GAN(generator=generator, discriminator=discriminator)
      5 # Define losses
      6 generator_loss, discriminator_loss = get_loss('nsl')

Input In [19], in AdatGAN.__init__(self, generator, discriminator)
      4 super(AdatGAN, self).__init__()
      5 self.generator = generator
----> 6 self.ema_generator = tf.keras.models.clone_model(self.generator)
      7 self.discriminator = discriminator
      8 self.noise_dim = noise_dim

File ~/anaconda3/envs/tf28/lib/python3.8/site-packages/keras/models/cloning.py:505, in clone_model(model, input_tensors, clone_function)
    501     return _clone_sequential_model(
    502         model, input_tensors=input_tensors, layer_fn=clone_function
    503     )
    504 else:
--> 505     return _clone_functional_model(
    506         model, input_tensors=input_tensors, layer_fn=clone_function
    507     )

File ~/anaconda3/envs/tf28/lib/python3.8/site-packages/keras/models/cloning.py:173, in _clone_functional_model(model, input_tensors, layer_fn)
    167     raise ValueError(
    168         ""Expected `model` argument ""
    169         ""to be a functional `Model` instance, ""
    170         f""got a `Sequential` instance instead: {model}""
    171     )
    172 if not model._is_graph_network:
--> 173     raise ValueError(
    174         ""Expected `model` argument ""
    175         ""to be a functional `Model` instance, ""
    176         f""but got a subclassed model instead: {model}""
    177     )
    179 new_input_layers = {}  # Cache for created layers.
    180 if input_tensors is not None:
    181     # Make sure that all input tensors come from a Keras layer.

ValueError: Expected `model` argument to be a functional `Model` instance, but got a subclassed model instead: <__main__.Generator object at 0x7efff88591c0>
```
</details>"
tensorflow/tensorflow,2023-01-12 09:51:05,feature,How to train with mobilenet models using model_spec.get() ??,"Hello. I am using this tutorial to train my dataset for the object detection and efficientdet_lite (0-4) models are working fine.
https://www.tensorflow.org/lite/models/modify/model_maker/object_detection

I found a documentation for **model_spec.get** and it seems you can train only with **efficientdet_lite** models.
https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/model_spec

Is there any way to train the model with **ssd-mobilenet-v2** or **ssd-mobilenet-v1** models and what I should write inside of **model_spec.get ('........')** ?? Look forward to hearing from you!"
tensorflow/tensorflow,2023-01-10 17:03:04,feature,Request: Some way to initialise a dynamically-sized state variable in TFLite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **All**
- TensorFlow installed from (source or binary): **Binary**
- TensorFlow version (or github SHA if from source): **2.9.1**

**Provide the text output from tflite_convert**
```
tensorflow.python.ops.op_selector.UnliftableError: Unable to lift tensor <tf.Tensor 'zeros:0' shape=(None, None) dtype=float32> because it depends transitively on placeholder <tf.Operation 'arr' type=Placeholder> via at least one path, e.g.: zeros (Fill) <- Shape (Shape) <- arr (Placeholder)
```

**Standalone code to reproduce the issue** 

I want to define a stateful graph where the shape of the state variable is defined when model is LOADED, not when it's saved.

As a simple example - lets say I just want to compute a temporal difference - ie. a graph that returns the difference between the input in two consecutive calls. The following should pass:

```
func = load_tflite_model_func(tflite_model_file_path)
runtime_shape = 60, 80
rng = np.random.RandomState(1234)
ims = [rng.randn(*runtime_shape).astype(np.float32) for _ in range(3)]
assert np.allclose(func(ims[0]), ims[0])
assert np.allclose(func(ims[1]), ims[1]-ims[0])
assert np.allclose(func(ims[2]), ims[2]-ims[1])
```

However as far as I know there is not way I can save a model, or define some function `load_tflite_model_func` for loading it, that would make this work for any `runtime_shape`, because variables in the graph can only be saved with a pre-determined size.   

A full stand-alone notebook demonstrating the issue is here:
https://colab.research.google.com/drive/19CwkF1MSGlfMXKxlrndCNqTv7V4fx55Q

**Request is for TFLite to be able to initialise state-variables, where the shape of the initialised variable can depend on the input-shape**

See also https://stackoverflow.com/questions/75052366/how-do-i-to-save-a-stateful-tflite-model-where-shape-of-state-depends-on-input "
tensorflow/tensorflow,2022-12-27 09:55:14,feature,Support for keepdims and padding in tf.boolean_mask or tf.ragged.boolean_mask,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Given two example tensors `input` and `mask`:


```
>>> input = tf.random.normal([2,3,5])
>>> input
<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=
array([[[ 1.1260294 , -0.05932725,  0.85893923, -1.5332409 ,
          0.6681451 ],
        [ 0.8833729 ,  0.8421117 , -0.60990584,  0.08593109,
          0.5969471 ],
        [ 0.20015325, -0.9459327 , -1.0818844 , -1.7254639 ,
         -0.51545954]],

       [[-0.36073774, -0.24315724,  1.5217028 ,  1.5075827 ,
          0.05745999],
        [-0.2570101 ,  1.5501927 , -0.17113225,  0.16063859,
         -0.95638955],
        [ 0.48955616,  0.11943919, -0.3523262 ,  0.10750653,
          1.1027677 ]]], dtype=float32)>

>>> mask = tf.constant([[0,1,0],[1,0,1]])
>>> mask
<tf.Tensor: shape=(2, 3), dtype=int32, numpy=
array([[0, 1, 0],
       [1, 0, 1]], dtype=int32)>

```

I need to mask out `input` according to `mask` where values are 0. However, since the number of masked out elements for each example in the batch `input` might be different, to keep the output a valid tensor, the output should be:

```
>>> masked_input
<tf.Tensor: shape=(2, 3, 5), dtype=float32, numpy=
array([[[ 0.8833729 ,  0.8421117 , -0.60990584,  0.08593109,
          0.5969471 ],
        [ 0 , 0 , 0 , 0 ,
         0],
        [ 0 , 0 , 0 , 0 ,
         0]],

       [[-0.36073774, -0.24315724,  1.5217028 ,  1.5075827 ,
          0.05745999],
        [ 0.48955616,  0.11943919, -0.3523262 ,  0.10750653,
          1.1027677 ],
        [ 0 , 0 , 0 , 0 ,
          0]]], dtype=float32)>
```
i.e. in the output, the masked input keeps only elements where `mask` is 1, and, with zero-padding at the end to ensure that the output is a valid tensor.



I've searched around and tried using:
1. `tf.gather`, however, still can't figure out how to proceed.
2. `tf.boolean_mask`, however, it doesn't support masking but just drops the first (zeroth) dimension, as shown below:
```
>>> tf.boolean_mask(input, mask)
<tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[ 0.8833729 ,  0.8421117 , -0.60990584,  0.08593109,  0.5969471 ],
       [-0.36073774, -0.24315724,  1.5217028 ,  1.5075827 ,  0.05745999],
       [ 0.48955616,  0.11943919, -0.3523262 ,  0.10750653,  1.1027677 ]],
      dtype=float32)>
```
3. `tf.ragged.boolean_mask`, this is by far the closest one to what I want, it keeps the dimension, however, still doesn't support masking, so the result is a ragged tensor...


Similar issues are mentioned in GitHub: https://github.com/tensorflow/tensorflow/issues/18238

In short:
```
tensor = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
mask = np.array([[True, False, True], [False, False, True], [True, True, True]])
boolean_mask(tensor, mask, keepdims=False) # [1, 3, 6, 7, 8, 9]
boolean_mask(tensor, mask, keepdims=True, pad_val=0) # [[1, 3, 0], [6, 0, 0], [7, 8, 9]] 
```


### Standalone code to reproduce the issue

```
As mentioned above
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-12-05 16:04:43,feature,TensorFlow Lite Image Classification - add a new model,"Hello. I tested your TensorFlow Lite Image Classification android app and it works perfect with these models (MobileNet V1, EfficientNet Lite0, EfficientNet Lite1, EfficientNet Lite2) which are downloading automatically by the download.gradle file.

https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android

Then I wanted to add my own classification model which has different labels compared to models mentioned above. I placed my model in **assets** folder app\\src\\main\\assets and then did some modification in **ImageClassifierHelper.kt** file.

val modelName =
            when (currentModel) {
                MODEL_MYMODEL -> ""mymodel.tflite""
                MODEL_MOBILENETV1 -> ""mobilenetv1.tflite""
                else -> ""mymodel.tflite""
            }

companion object {
        const val DELEGATE_CPU = 0
        const val DELEGATE_GPU = 1
        const val DELEGATE_NNAPI = 2
        const val MODEL_MYMODEL = 0
        const val MODEL_MOBILENETV1 = 1
        private const val TAG = ""ImageClassifierHelper""
    }


While I build and launch the app, I received the following error:

**Launching 'app' on Xiaomi .....
Install successfully finished in 6 s 117 ms.
$ adb shell am start -n ""org.tensorflow.lite.examples.imageclassification/org.tensorflow.lite.examples.imageclassification.MainActivity"" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER
Connected to process 15146 on device 'xiaomi-......'.**

Can you please let me know how to fix the issue and do I need to do other modification in scripts to make it work with my model. 

Look forward to hearing from you and thank you in advance!
"
tensorflow/tensorflow,2022-11-29 19:26:25,feature,Expecting the same names when converting to tflite model,"Hello,

I have created very simple model, and I want to export it to tflite model, to benchmark it on android device, and run simple inferences. This is code to create model:
```python
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers

input0 = keras.Input(shape=(64,), name=""input0"") 
input1 = keras.Input(shape=(16,), name=""input1"")
input2 = keras.Input(shape=(16,), name=""input2"")

layer0 = layers.Dense(3, activation=""relu"", name=""layer0"")(input0)
layer1 = layers.Dense(5, activation=""relu"", name=""layer1"")(input1)
layer2 = layers.Dense(7, activation=""relu"", name=""layer2"")(input2)

x0 = layers.concatenate([layer0, layer1, layer2])
x1 = layers.concatenate([layer0, layer1, layer2])

output0 = layers.Dense(3, name=""output0"")(x0)
output1 = layers.Dense(7, name=""output1"")(x1)

model = keras.Model(
    inputs=[input0, input1, input2],
    outputs=[output0, output1],
)
model.compile(optimizer='sgd', loss='mean_squared_error')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```
environment: google colab

I expect, that tflite model would have `input0`, `input1`, `input2` input names, and `output0` , `output1` output names. But...
Real names are: `serving_default_input0:0`, `serving_default_input1:0`, `serving_default_input2:0`, `StatefulPartitionedCall:0`, `StatefulPartitionedCall:1`"
tensorflow/tensorflow,2022-11-25 08:13:37,feature,Tensorflow Lite iOS Interpreter production logs,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

iOS

### Mobile device

iOS

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The log outputs of the Interpreter cannot be disabled for production use, but we would need that.
See: https://github.com/tensorflow/tensorflow/blob/bb5ff1b22f5d4d6bf937dcd71f8b710064eadce6/tensorflow/lite/core/interpreter.cc#L97

Would be nice if you could introduce another option for the Interpreter where you could set log outputs enabled/disabled or even with LogLevels.
```


### Standalone code to reproduce the issue

```shell
Interpreter(modelPath: path, options: options)
```


### Relevant log output

```shell
Initialized TensorFlow Lite runtime.
```
</details>"
tensorflow/tensorflow,2022-11-24 11:24:54,feature,Feature request (TensorFlow Lite): Implement mechanism to load Flex ops in C for Android,"### System information

-   **Have I written custom code**: no
-   **OS Platform and Distribution**: macOS Monterey 12.6
-   **TensorFlow installed from**: source
-   **TensorFlow version**: 2.10.0
-   **Python version**: 3.10.8
-   **Bazel version**: 5.1.1
-   **GCC/Compiler version**: Apple clang 14.0.0 (clang-1400.0.29.202)
-   **CUDA/cuDNN version**: Not using CUDA
-   **GPU model and memory**: Not using GPU acceleration
-   **Exact command to reproduce**: Feature request, no 

### Describe the problem

This is a feature request.

In TensorFlow Lite 2.7 and higher, if a model contains Flex ops you must go through Java to load the Flex library (see [NativeInterpreterWrapper.java](https://github.com/tensorflow/tensorflow/blob/3c53121ab319ce3646d3cb5b0152e78ef02c3925/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java#L542) and [FlexDelegate.java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/flex/java/src/main/java/org/tensorflow/lite/flex/FlexDelegate.java)).

We develop a cross-platform app where most of the ML inference logic runs in a separate C library. We test that library separately from the rest of the app using GTest, without going through the Android runtime. For our purposes, it would be much more convenient if we could load the Flex library directly in C.

As a tentative implementation, we could move the logic in `NativeInterpreterWrapper.java` to C, so that we could automatically load Flex ops when creating models from the C API with `TfLiteModelCreate`. The existing Java classes could be kept as shallow wrappers to the underlying C implementation. Java and C entry points could be toggled at build time through a flag.

Is this something that you would consider implementing, and, if not, would you accept PRs that go in that direction?"
tensorflow/tensorflow,2022-11-13 19:32:36,feature,"`tf.identity` docs missing instructions, GPU to CPU","
 ### Issue Type

Documentation Feature Request

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

The [docs](https://www.tensorflow.org/api_docs/python/tf/identity) do not describe how `.cpu()` should be accomplished.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.constant(1.).cpu()
```


### Relevant log output

```shell
_EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.identity instead.
```"
tensorflow/tensorflow,2022-11-09 00:02:02,feature,Document behavior of tf.keras.layers.Bidirectional with return_state=True,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Source

source

### Tensorflow Version

2.10

### Custom Code

No
</details>

It is unclear from the documentation how a `tf.keras.layers.Bidirectional` layer will behave if `return_state` is True; ie, in what order the hidden/cell states will be returned, and what, if any, interaction there is with `merge_mode`.

Per the source code, any states of forward layer are returned after the output(s), followed by any states of the backward layer. This should be documented. 

```
if self.return_state:
            states = y[1:] + y_rev[1:]
            y = y[0]
            y_rev = y_rev[0]

# ...

if self.return_state:
            if self.merge_mode is None:
                return output + states
            return [output] + states
        return output

```"
tensorflow/tensorflow,2022-10-29 08:47:09,feature,How to enable GSPMD?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf 2.7

### Custom Code

No

### OS Platform and Distribution

Linux 

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
We are trying to utilize GSPMD on a server with 8 GPUS, we find the ut-test cases as follows:
https://github.com/tensorflow/tensorflow/blob/r2.7/tensorflow/compiler/xla/experimental/xla_sharding/xla_sharding_test.py

To dump the IRs, we enable the environment variables as: TF_DUMP_GRAPH_PREFIX=/tmp/generated \\
  TF_XLA_FLAGS=""--tf_xla_clustering_debug --tf_xla_auto_jit=2"" \\
  XLA_FLAGS=""--xla_dump_hlo_as_text --xla_dump_to=/tmp/generated"" \\
    my/tensorflow/program"".

But, only 4 IRs are saved: mark_for_compilation.pbtxt, mark_for_compilation_annotated.pbtxt, before_mark_for_compilation.pbtxt, before_increase_dynamism_for_auto_jit_pass.pbtxt. None of them is related to SPMD pass.

It seems that our current run does NOT enable GSPMD functionality at all. Is there any tutorial or instructions for us to follow to enable GSPMD on multiple GPUS?
```


### Standalone code to reproduce the issue

```shell
from tensorflow.compiler.xla.experimental.xla_sharding import xla_sharding
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.framework import test_util
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
import numpy as np
from tensorflow.python.eager import def_function


class XlaShardingTest(test_util.TensorFlowTestCase):  
  def test_dot_split(self):
    @def_function.function
    def split_helper(tensor):
      device_mesh = np.array([[0, 1, 2, 3], [4, 5, 6, 7]])
      split_tensor = xla_sharding.mesh_split(tensor, device_mesh, [0, 1])
      self.assertIsInstance(split_tensor, ops.Tensor)
      split_sharding = xla_sharding.get_tensor_sharding(split_tensor)
      split_shape = xla_sharding.get_sharding_tile_shape(split_sharding)
      expected_shape = [2, 4]
      self.assertEqual(expected_shape, split_shape)

      y_tensor = array_ops.ones([8, 8], dtype=dtypes.float32)
      y_split = xla_sharding.mesh_split(y_tensor, device_mesh, [0, 1])
      result = math_ops.matmul(split_tensor, y_split)
      device_mesh = np.array([[0, 1], [2, 3], [4, 5], [6, 7]])
      result = xla_sharding.mesh_split(result, device_mesh, [0, 1])
      result = math_ops.sqrt(result)
      result = xla_sharding.mesh_split(result, device_mesh, [1, 0])
      return result

    in_tensor = 2 * np.sqrt(2) * array_ops.ones([8, 8], dtype=dtypes.float32)
    result = split_helper(
        array_ops.ones([8, 8], dtype=dtypes.float32))
    self.assertAllEqual(in_tensor, result)


if __name__ == ""__main__"":
    xlasharding = XlaShardingTest()
    xlasharding.test_dot_split()
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-10-27 10:50:06,feature,Support for C++ Builder 11.2 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

TF 2.8

### Custom Code

No

### OS Platform and Distribution

Windows 11 x64

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Is there anyway to support C++ Builder 11.2 ? current static libs are in a format not supported by C++ Builder. Static libs are only in COFF format so they cant be linked with in C++ builder , they need to be in OMF format for C++ builder to link the static libs. the only way i can solve this is to do a loadlibrary in code and get proc address of each function
```


### Standalone code to reproduce the issue

```shell
No able to link static libs only in MSVC not C++ builder.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-10-18 21:17:41,feature,LeakyRelu in Tensorflow lite with the Hexagon Delegate not supported,"When using a tflite model (8-bits quantized via TensorFlow lite conversion framework) that includes the activation function ""LeakyRelu"", the Hexagon delegate from tensorflow framework cannot perform the DNN inference on the whole graph, but rather it falls back to the CPU/XNNPack delegate. This is due to the fact that 'LeakyRelu' operation is not supported by the Hexagon Delegate (confirmed in TensorFlow doc: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/hexagon/README.md). When using Relu activation function (and Relu6 as well), we can see below that the TF Hexagon Delegate can process the whole DNN graph, unfortunately, the qualitative results I get are much worse, hence the need of having 'Leaky Relu' implemented in the Hexagon Delegate. We can easily reproduce this behavior by using TensorFlow Benchmark tool (see below)

Could we consider to implement Leaky Relu in tensorflow lite DSP delegate ?

**System information**
- OS Platform and Distribution): Android 10, NDK R21e
- TensorFlow installed from (source or binary): from source using the Release tag '2.9.1'
- TensorFlow version (or github SHA if from source):  2.9.1


**Provide the text output from tflite_convert**

```
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 23). These functions will not be directly callable after loading.
C:\\Users\\eelfahsi\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(""Statistics for quantized inputs were expected, but not ""
2022-10-13 18:13:16.990773: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.
2022-10-13 18:13:16.991046: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.
2022-10-13 18:13:16.998334: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: C:\\Users\\eelfahsi\\AppData\\Local\\Temp\\tmp731h7tgk
2022-10-13 18:13:17.027069: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }
2022-10-13 18:13:17.027795: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: C:\\Users\\eelfahsi\\AppData\\Local\\Temp\\tmp731h7tgk
2022-10-13 18:13:17.269741: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-10-13 18:13:17.291178: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2022-10-13 18:13:18.176412: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: C:\\Users\\eelfahsi\\AppData\\Local\\Temp\\tmp731h7tgk
2022-10-13 18:13:18.475762: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1477588 microseconds.
2022-10-13 18:13:19.015757: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
Found 7390 files belonging to 1 classes.
fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9

Process finished with exit code 0

```

**Standalone code to reproduce the issue** 
Here is a colab link with the code used to:
- generate the model that include leaky relu op.
- quantize and save the model in int8 ops.

Colab code Link: https://colab.research.google.com/drive/1xmktQACGQ6GnMmrwco3bNXcmJIDjt5PK?usp=sharing

**Link to the quantized model:**
[my_quant_model_leaky_relu.zip](https://github.com/tensorflow/tensorflow/files/9815061/my_quant_model_leaky_relu.zip)

The tool below from Tensorflow allow to run any model, when running the model above, it fails because 'LeakyRelu' is not supported.

**Link to TensorFlow Benchmark**:
https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model

tflite benchmark command line:
```
./tf_benchmark --graph=/data/local/tmp/my_quant_model_leaky_relu.tflite  --require_full_delegation=true --use_hexagon=true --hexagon_lib_path=/data/local/tmp/

```
When performing the inference on dsp using Tensorflow lite Benchmark tool for android, we get the following error message:
```
./tf_benchmark  --use_hexagon=true --graph=./my_quant_model_leaky_relu.tflite   --require_full_delegation=true --hexagon_lib_path=/data/local/tmp/          <
STARTING!
Log parameter values verbosely: [0]
Graph: [./my_quant_model_leaky_relu.tflite]
Require full delegation: [1]
Use Hexagon: [1]
Hexagon lib path: [/data/local/tmp/]
Loaded model ./my_quant_model_leaky_relu.tflite
INFO: Initialized TensorFlow Lite runtime.
loaded libcdsprpc.so
Hexagon delegate created.
INFO: TfLiteHexagonDelegate delegate: 6 nodes delegated out of 12 nodes with 5 partitions.

VERBOSE: Replacing 6 node(s) with delegate (TfLiteHexagonDelegate) node, yielding 6 partitions.
Disallowed CPU fallback detected.
Benchmarking failed.
```

If I disable the usage of the dsp, then it works properly
tflite benchmark command line:
```
./tf_benchmark --graph=/data/local/tmp/my_quant_model_leaky_relu.tflite 
```
Logs
```
./tf_benchmark  --graph=./my_quant_model_leaky_relu.tflite                                                                          
STARTING!
Log parameter values verbosely: [0]
Graph: [./my_quant_model_leaky_relu.tflite]
Loaded model ./my_quant_model_leaky_relu.tflite
INFO: Initialized TensorFlow Lite runtime.
The input model file size (MB): 0.038384
Initialized session in 0.57ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=1141 first=4613 curr=428 min=427 max=4613 avg=438.004 std=125

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=2311 first=433 curr=428 min=427 max=627 avg=432.374 std=14

Inference timings in us: Init: 570, First inference: 4613, Warmup (avg): 438.004, Inference (avg): 432.374
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=0 overall=3.09766
...
```

If I replace leakyRelu by Relu, then it works properly
Here is a colab link with the code used to:
- generate the model that include relu op.
- quantize and save the model in int8 ops.

Colab code Link: https://colab.research.google.com/drive/1PZjt4BkFDP5EXAcVEi5N3Q4mYlfaawQP?usp=sharing

**Link to the quantized model:**
[my_quant_model_relu.zip](https://github.com/tensorflow/tensorflow/files/9815007/my_quant_model_relu.zip)

tflite benchmark command line:
```
./tf_benchmark  --use_hexagon=true --graph=./my_quant_model_relu.tflite   --require_full_delegation=true --hexagon_lib_path=/data/local/tmp/
```
Logs
```
./tf_benchmark  --use_hexagon=true --graph=./my_quant_model_relu.tflite   --require_full_delegation=true --hexagon_lib_path=/data/local/tmp/                                                             <
STARTING!
Log parameter values verbosely: [0]
Graph: [./my_quant_model_relu.tflite]
Require full delegation: [1]
Use Hexagon: [1]
Hexagon lib path: [/data/local/tmp/]
Loaded model ./my_quant_model_relu.tflite
INFO: Initialized TensorFlow Lite runtime.
loaded libcdsprpc.so
Hexagon delegate created.
INFO: TfLiteHexagonDelegate delegate: 8 nodes delegated out of 8 nodes with 1 partitions.

VERBOSE: Replacing 8 node(s) with delegate (TfLiteHexagonDelegate) node, yielding 1 partitions.
Explicitly applied Hexagon delegate, and the model graph will be completely executed by the delegate.
The input model file size (MB): 0.0374
Initialized session in 174.22ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=918 first=796 curr=537 min=324 max=3378 avg=540.937 std=180

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=1754 first=701 curr=537 min=443 max=2552 avg=565.409 std=136

Inference timings in us: Init: 174220, First inference: 796, Warmup (avg): 540.937, Inference (avg): 565.409
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=3.48047 overall=3.48047


```
"
tensorflow/tensorflow,2022-10-06 07:46:16,feature,Making tensorflow.tile similar to numpy.tile and torch.tile,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.9.1

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Running this code:
`tf.tile(tf.ones((3,)),(2,1))` will currently give an error for TensorFlow since the dimension length of the input and the multiples is different. Numpy and Pytorch handle this by modifying the dimension of the multiples or the input argument. I believe it would be nice if TensorFlow did this too.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.tile(tf.ones((3,)),(2,1))
```


### Relevant log output

```shell
tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected multiples argument to be a vector of length 1 but got length 2 [Op:Tile]
```
</details>"
tensorflow/tensorflow,2022-10-05 03:34:07,feature,Supporting int32 value type in TextFileInitializer.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf 2.9

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
In [TextFileInitializer](https://github.com/tensorflow/tensorflow/blob/359c3cdfc5fabac82b3c70b3b6de2b0a8c16874f/tensorflow/python/ops/lookup_ops.py#L731) we have a validation to check whether the value_dtype is of type tf.int64, wondering why do we have such constraints? 

The context is that, we are trying to initialize a vocabulary lookup table in the TensorFlow model and would like to save memory for the HashTable, both the key and value type can be of int32 type, but seems that the value type is restricted to int64. 
```


### Standalone code to reproduce the issue

```shell
initializer = tf.lookup.TextFileInitializer(
                    vocab_file,
                    key_dtype=tf.int64, key_index=0,
                    value_dtype=tf.int32, value_index=1,
                    delimiter="" "")
```


### Relevant log output

```shell
[0]<stderr>:    vocab_table = tf.lookup.StaticVocabularyTable(initializer=initializer, num_oov_buckets=1)
[0]<stderr>:  File ""/home/coder/ads-ai-offline/build/scin-azkaban/environments/development-venv/lib/python3.7/site-packages/tensorflow/python/ops/lookup_ops.py"", line 1235, in __init__
[0]<stderr>:    (dtypes.int64, initializer.value_dtype))
[0]<stderr>:TypeError: Invalid value dtype, expected <dtype: 'int64'> but got <dtype: 'int32'>.
```
</details>"
tensorflow/tensorflow,2022-09-27 19:01:34,feature,How to build TensorFlow from source with Clang?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

v2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

5.1.1

### GCC/Compiler version

clang 14

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am trying to build TensorFlow with clang and add options for generating coverage information (https://clang.llvm.org/docs/SourceBasedCodeCoverage.html). However, it fails with clang build.
```


### Standalone code to reproduce the issue

```shell
bazel build --verbose_failures //tensorflow/tools/pip_package:build_pip_package --repo_env=CC=clang --copt=-fprofile-instr-generate --copt=-fcoverage-mapping


Removing `--copt=-fprofile-instr-generate --copt=-fcoverage-mapping` also fails.
```


### Relevant log output

```shell
""""""
ERROR: /home/jiawei/.cache/bazel/_bazel_jiawei/b619a772dd31287f179cb3c11ac7f523/external/llvm-project/mlir/BUILD.bazel:3204:11: Compiling mlir/lib/Support/IndentedOstream.cpp failed: undeclared inclusion(s) in rule '@llvm-project//mlir:Support':
this rule is missing dependency declarations for the following files included by 'mlir/lib/Support/IndentedOstream.cpp':
  'bazel-out/k8-opt/bin/external/llvm-project/llvm/config.cppmap'
  'bazel-out/k8-opt/bin/external/llvm-project/llvm/Demangle.cppmap'
  'bazel-out/k8-opt/bin/external/llvm_terminfo/terminfo.cppmap'
  'bazel-out/k8-opt/bin/external/llvm_zlib/zlib.cppmap'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 138.453s, Critical Path: 63.33s
INFO: 7649 processes: 4288 internal, 3361 local.
FAILED: Build did NOT complete successfull
""""""
```
</details>"
tensorflow/tensorflow,2022-09-26 02:51:59,feature,Adan optimizer,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

tf 2.9.1

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Adan seems to be a superior optimizer compared to Adam and its variants. Can we introduce this in Tf/Keras optimizers?

Please find a few references below:

Adan paper: https://arxiv.org/abs/2208.06677

Pytorch implementation:
- https://github.com/sail-sg/Adan
- https://github.com/lucidrains/Adan-pytorch

Blog article:
- https://wandb.ai/capecape/adan_optimizer/reports/Adan-A-New-Optimizer-That-Challenges-Adam--VmlldzoyNTQ5NjQ5
```


### Standalone code to reproduce the issue

```shell
NA
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-09-20 22:49:43,feature,GPU detection src location,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

2

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.7

### GPU model and memory

Tesla V100

### Current Behaviour?

```shell
Hello, 

I'm a student researcher and I am only posting this as I got no response on the Tensorflow Google group. (Please direct me to next place to the answer).

I'm trying to develop a feature where if tensorflow does not detect a local GPU, I direct the binary to my custom application (a GPU virtualization framework) for it to talk to a remote GPU execute the calls.

I want to know, in the large codebase of tensorflow where should I start looking for this? I need source file where it decides ""no GPU so use CPU"" or something similar.
```


### Standalone code to reproduce the issue

```shell
NA
```


### Relevant log output

```shell
NA
```
</details>"
tensorflow/tensorflow,2022-09-19 20:57:21,feature,tf.image.combined_non_max_suppression crash with segmentation fault,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0-dev20220916

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

N/A

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.image.combined_non_max_suppression crash with segmentation fault when `max_total_size` is given a large value
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
tf.image.combined_non_max_suppression(max_output_size_per_class=10, max_total_size=1916847725, scores=np.ones((2,2,1)), boxes=np.ones((2,2,1,4)))
```


### Relevant log output

```shell
2022-09-19 20:56:42.880536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-09-19 20:56:42.880586: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-19 20:56:42.880661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2022-09-19 20:56:42.881322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-19 20:56:42.924370: W tensorflow/core/kernels/image/non_max_suppression_op.cc:995] Detected a large value for `max_total_size`. This may cause OOM error. (max_total_size: 1916847725)
Segmentation fault (core dumped)
```
</details>"
tensorflow/tensorflow,2022-09-13 08:46:32,feature,"Include ""name"" parameter in tf.keras.models.clone_model() function to give a new name to the clone.","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.8.2

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When using the `tf.keras.models.clone_model(previous_model)` function, it assigns the same name as ""previous_model"" to the created clone. I want to assign a new name to the created clone. This can probably be done by passing a name parameter to the `clone_model()` function.
```


### Standalone code to reproduce the issue

```shell
`pre_m1 = tf.keras.Sequential([
    sentence_encoder_layer,
    layers.Dense(64,activation=""relu""),
    layers.Dense(1,activation=""sigmoid"")
],name=""pre_trained_m1"")

pre_m2 = tf.keras.models.clone_model(pre_m1)

# In the summary, the name of pre_m2 is printed as ""pre_trained_m1"" i.e. same as pre_m1.
print(pre_m2.summary())
`
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-09-05 13:42:55,feature,Feature: Balanced Accuracy,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

tf 2.10.0-rc3

### Custom Code

No

### OS Platform and Distribution

Debian 11

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2

### GPU model and memory

_No response_

### Current Behaviour?

I suggest adding [Balanced Accuracy](https://www.statology.org/balanced-accuracy/) as additional [Keras metrics](https://keras.io/api/metrics/).

It is useful for training with an imbalanced validation dataset.

(Note: I see various suggestions on StackOverflow: [1](https://stackoverflow.com/questions/59339531/balanced-accuracy-score-in-tensorflow), [2](https://stackoverflow.com/questions/65189262/tensorflow-2-0-custom-metric-balanced-accuracy-score-for-modelcheckpoint-not))


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
metrics = [tf.keras.metrics.BalancedAccuracy()]
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-08-31 07:40:44,feature,tf.image.rot90 should add a note for the case k<0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Source

source

### Tensorflow Version

TF2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The documentation only describes how the code runs when k>0, and dont mention k<0. The code shows that when k<0, the image will be rotated clockwise. I think a note should be added to explain what happens when k<0
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
results={}
try:
  arg_0 = tf.saturate_cast(tf.random.uniform([2, 2, 1], minval=-256, maxval=257, dtype=tf.int64), dtype=tf.int32)
  k = -1
  results[""res""] = tf.image.rot90(arg_0,k=k,)
except Exception as e:
  results[""err""] = ""Error:""+str(e)
print(results)
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-08-30 15:49:47,feature,`tf.pad` fails when executing in `tf.autodiff.ForwardAccumulator`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9.1

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.pad` fails when executing in `tf.autodiff.ForwardAccumulator` and throws `TypeError`. However, if we run `tf.pad` outside of `ForwardAccumulator` with the same input, it will pass.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

input_tensor = tf.random.uniform([3, 1, 1, 1], minval=2.0, maxval=3.0, dtype=tf.float32)
paddings = tf.random.uniform([4, 2], minval=0, maxval=5, dtype=tf.int64) 
mode = ""CONSTANT""
constant_values = 0 
result = tf.pad(input_tensor, paddings, mode=mode, constant_values=constant_values, ) 
print(result.shape) # Pass

tangent = tf.reshape(tf.one_hot(1, tf.size(input_tensor), dtype=input_tensor.dtype), shape=input_tensor.shape)
with tf.autodiff.ForwardAccumulator(input_tensor, tangent) as acc:
    result = tf.pad(input_tensor, paddings, mode=mode, constant_values=constant_values, ) # Fail
```


### Relevant log output

```shell
(8, 3, 8, 4)
TypeError: Input 'y' of 'Sub' Op has type int64 that does not match type int32 of argument 'x'.
```
</details>"
tensorflow/tensorflow,2022-08-23 14:12:13,feature,when will tensorflow support FP8?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

tf2.9

### Custom Code

No

### OS Platform and Distribution

Linux ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Pytorch added FP8 support, will TF add FP8 support sometime for both E4M3 and E5M2?
```


### Standalone code to reproduce the issue

```shell
No source code, just a feature request question
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-08-16 19:47:50,feature,Please publish official wheels for Apple Silicon,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.9.1

### Custom Code

No

### OS Platform and Distribution

macOS 12

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

</details>

### Current Behaviour?

Users of Macs with Apple Silicon (M1, M2, etc.) cannot `pip install tensorflow` because wheels for the architecture are not published on PyPI.

The current state of this (August 2022) is that these wheels are published under a different package name, [`tensorflow-macos`](https://pypi.org/project/tensorflow-macos/), which is released separately by Apple.

This makes it more complicated to install software that uses TensorFlow on macOS; e.g., a `requirements.txt` file might have to look something like

```
tensorflow;  sys.platform != 'darwin' or platform.machine != 'arm64'
tensorflow-macos;  sys.platform == 'darwin' and platform.machine == 'arm64'
``` 

Apple's repository, [`tensorflow_macos`](https://github.com/apple/tensorflow_macos) is archived which makes it unclear where users should get support. Is it here?

Moreover, at the time of writing, `tensorflow-macos` is version 3.9.2, which is one bugfix release ahead of the latest official `tensorflow`, so comparing version numbers across the two is difficult.

And it leaves many other unanswered questions: Are these being tested in CI? How soon after an upstream release will `tensorflow-macos` get an update?

Finally, both `tensorflow` and `tensorflow-macos` support Intel-based Macs, which is another potential point of confusion—which is preferred?

cc @kulinseth @jhavukainen


### Standalone code to reproduce the issue

```shell
(.venv) % arch
arm64
(.venv) % python3 -m pip install tensorflow
ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow
```"
tensorflow/tensorflow,2022-08-11 01:10:57,feature,"How to fix the ""undefined reference"" problem for the TF Lite? A suggestion.","When [CMakeLists.txt](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/CMakeLists.txt) is used to build a shared library of TF Lite, it is impossible to link with it because of the ""undefined reference"" problem.

Those ""undefined reference"" objects reside on the `tensorflow` main branch, but the following macro `populate_tf_source_vars` has never populated a single line of main Tensorflow code for the TF Lite build, yet the main code is referenced by it. No wonder we see the ""undefine reference"". 

I did try to use `populate_tf_source_vars` to bring those missing objects to TF Lite. Unfortunately, however, the references will quickly escalate to reference a lot of main Tensorflow stuff. That defeats the very motivation of having a ""Lite"" version of Tensorflow, doesn't it?

Can you please make TF Lite stop referencing those objects because they don't seem to be important? If you do think they are important, can you make a light version of them just for TF Lite?

https://github.com/tensorflow/tensorflow/blob/d35d3a1614fc8dd34dc181f521cf1d7f472249c1/tensorflow/lite/CMakeLists.txt#L136

**_The problem:_**

```
/usr/bin/ld: /usr/local/lib/libtensorflow-lite.so: undefined reference to `tensorflow::profiler::internal::g_trace_level'
/usr/bin/ld: /usr/local/lib/libtensorflow-lite.so: undefined reference to `tensorflow::profiler::TraceMeRecorder::Record(tensorflow::profiler::TraceMeRecorder::Event&&)'
/usr/bin/ld: /usr/local/lib/libtensorflow-lite.so: undefined reference to `tensorflow::profiler::GetCurrentTimeNanos()'
/usr/bin/ld: /usr/local/lib/libtensorflow-lite.so: undefined reference to `tensorflow::profiler::ScopedMemoryDebugAnnotation::ThreadMemoryDebugAnnotation()'

```"
tensorflow/tensorflow,2022-08-02 06:09:44,feature,Is possible to measure height of person using tensorFlow pose Estimation ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to performe Vertical Jump test & want to measure distance between floor to ankle.
```


### Standalone code to reproduce the issue

```shell
I want to performe Vertical Jump test & want to measure distance between floor to ankle.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-07-26 03:24:12,feature,Rsqrt doesn't support for tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
tensorflow/tensorflow,2022-07-25 02:28:22,feature,Are there on-device training with Tensorflow lite in Arduino IDEs???,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

No

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Is there a way to perform on-device training with Tensorflow lite in Arduino IDE? I see an option for Java and C++ with android but can't find the C++ doc... Seems like C ain't supported too.
```


### Standalone code to reproduce the issue

```shell
No code
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-07-21 01:07:38,feature,[Feature Request] GELU activation with the Hexagon delegate,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.9.1

I think I'd be able to implement this myself, but wanted to see if there was any interest in including this upstream.  Most of this I'm writing out to make sure my own understanding is correct.

### The problem

I'd like to add support for the GELU op to the Hexagon Delegate.  The motivation for this is mostly for use with [DistilBERT](https://huggingface.co/distilbert-base-multilingual-cased), which uses this activation function in its feedforward network layers.  (Also used by BERT, GPT-3, RoBERTa, etc.)

Adding this as a supported op for the Hexagon delegate would avoid creating a graph partition/transferring between DSP<-->CPU each time the GELU activation function is used.

### How I'd implement this

GELU in TF Lite is implemented as a lookup table when there are integer inputs ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/activations.cc#L120-L140) and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/reference/gelu.h#L37-L53)).

This same approach could be used for the Hexagon delegate, as it has int8/uint8 data types and also supports lookup tables.

I'd plan to do this by adding a new op builder in the delegate, populating a lookup table for each node as is currently done for the CPU version of the op, and then using the [Gather_8](https://source.codeaurora.org/quic/hexagon_nn/nnlib/tree/hexagon/ops/src/op_gather.c)  nnlib library function to do the lookup.

### Possible workaround

A workaround I thought of:

I'm going to try removing the [pattern matching](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td#L1034-L1095) for approximate GELU in MLIR, and then using the approximate version of GELU (so that using tanh and not Erf).  This will probably be slower, but should let me keep execution on the DSP.

Since this will then be tanh, addition, multiplication ops instead of GELU they should all be runnable by the DSP."
tensorflow/tensorflow,2022-07-18 20:47:08,feature,[TF.io] Incompatible with AWS S3 filepaths,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.1

### Custom Code

No

### OS Platform and Distribution

RHEL

### Mobile device

_No response_

### Python version

3.7.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Apparently, from the AWS logs it seems the Headers are obtained but the response body is empty.

I'm using `TFDS`, However its accessing (via `etils`) the TF backend to create a stream for the S3 object. Hence why its reproducible from a `TF` method. 

This was the full error from TFDS, for those interested, to verify that it does indeed call `tf.io` as a backend to execute the request. 

```
Traceback (most recent call last):
  File ""scripts/kecam_tester.py"", line 47, in <module>
    description='Preprocessed TFRecords of BDD100K dataset, long only, delayed by 60 frames for each tuple.',
  File ""/home/awesome/.local/lib/python3.7/site-packages/tensorflow_datasets/core/folder_dataset/write_metadata_utils.py"", line 80, in write_metadata
    f for f in data_dir.iterdir() if naming.FilenameInfo.is_valid(f.name)
  File ""/home/awesome/.local/lib/python3.7/site-packages/tensorflow_datasets/core/folder_dataset/write_metadata_utils.py"", line 80, in <listcomp>
    f for f in data_dir.iterdir() if naming.FilenameInfo.is_valid(f.name)
  File ""/home/awesome/.local/lib/python3.7/site-packages/etils/epath/gpath.py"", line 126, in iterdir
    for f in self._backend.listdir(self._path_str):
  File ""/home/awesome/.local/lib/python3.7/site-packages/etils/epath/backend.py"", line 191, in listdir
    return self.gfile.listdir(path)
  File ""/home/awesome/.local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 769, in list_directory_v2
    message=""Could not find directory {}"".format(path))
tensorflow.python.framework.errors_impl.NotFoundError: Could not find directory s3://s-laion/ssd-videos/new_tfrecs
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

# Insert any S3 filepath
tf.io.gfile.listdir('s3://...')
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/awesome/.local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 769, in list_directory_v2
    message=""Could not find directory {}"".format(path))
tensorflow.python.framework.errors_impl.NotFoundError: Could not find directory s3://...
```
</details>"
tensorflow/tensorflow,2022-07-12 03:29:00,feature,CMAKE has no key to disable the build of python wrapper when building TF lite from source using Xcode or Android Studio,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

TF2.9

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18 or MacOS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
CMAKE has no key to disable the build of python wrapper when building TF lite from source using Xcode or Android Studio. 

current cmake in tensorflow/tensorflow/lite with the a non optional python wrapper, which triggers errors when using tensorflow as a submodule in an Xcode or Android studio project 

# Python interpreter wrapper.
add_library(_pywrap_tensorflow_interpreter_wrapper SHARED EXCLUDE_FROM_ALL
  ${TFLITE_SOURCE_DIR}/python/interpreter_wrapper/interpreter_wrapper.cc
  ${TFLITE_SOURCE_DIR}/python/interpreter_wrapper/interpreter_wrapper_pybind11.cc
  ${TFLITE_SOURCE_DIR}/python/interpreter_wrapper/numpy.cc
  ${TFLITE_SOURCE_DIR}/python/interpreter_wrapper/python_error_reporter.cc
  ${TFLITE_SOURCE_DIR}/python/interpreter_wrapper/python_utils.cc
)

# To remove ""lib"" prefix.
set_target_properties(_pywrap_tensorflow_interpreter_wrapper PROPERTIES PREFIX """")

target_include_directories(_pywrap_tensorflow_interpreter_wrapper
  PUBLIC
    ${TFLITE_INCLUDE_DIRS}
)

target_link_libraries(_pywrap_tensorflow_interpreter_wrapper
  tensorflow-lite
  ${CMAKE_DL_LIBS}
)
target_compile_options(_pywrap_tensorflow_interpreter_wrapper
  PUBLIC ${TFLITE_TARGET_PUBLIC_OPTIONS}
  PRIVATE ${TFLITE_TARGET_PRIVATE_OPTIONS}
)

I would expect a cmake key to enable or disable the python wrapper 
e.g.

if(TFLITE_ENABLE_pywrap)
...
endif()
```


### Standalone code to reproduce the issue

```shell
CMAKE has no key to disable the build of python wrapper when building TF lite from source using Xcode or Android Studio.
```


### Relevant log output

```shell
cannot find Python.h
```
</details>"
tensorflow/tensorflow,2022-07-07 19:14:02,feature,Custom Op written in C API errors when requesting GPU_Device stream,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Source

binary

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux 

### Mobile device

07010841551

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi there!

I was trying to write a custom op using the tensorflow C API and in the cuda version I was facing errors while requesting for the GPU_Device stream.
My questions are:
1.Is there any way to convert SP_Stream(returned by TF_GetStream(context,status)) to cudastream?
2.What is the equivalent of eigen_device<GPUDevice>().stream() (c++) for the C API?
3.Where is the implementation of TF_OPKernelContext.

Thanks,
Yoga
```


### Standalone code to reproduce the issue

```shell
// C++ code
cudaStream_t theStream=context->eigen_device<GPUDevice>().stream();

// Equivalent C code
cudaStream_t theStream = TF_GetStream(context,status);
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-06-23 11:14:37,feature,Reproducible sparse-dense matrix multiplication,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

v2.9.0-18-gd8ce9f9c301 2.9.1

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
There is currently no deterministic sparse-dense matrix multiplication implementation on the GPU. I would like to have one.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.keras.utils.set_random_seed(3948)
tf.config.experimental.enable_op_determinism()

m = tf.SparseTensor(
    indices=[[0, 0], [0, 1]],
    values=np.array([1, 2], dtype=np.float32),
    dense_shape=(3, 2),
)
v = tf.constant([[1], [1]], dtype=tf.float32)

tf.sparse.sparse_dense_matmul(m, v)
```


### Relevant log output

```shell
UnimplementedError: A deterministic GPU implementation of SparseTensorDenseMatmulOp is not currently available. [Op:SparseTensorDenseMatMul]
```
</details>"
tensorflow/tensorflow,2022-06-15 08:20:19,feature,Tensorflow GPU Delegate Limit resources (Feature Request),"Hello, sometimes when I'm running the tflite model on gpu delegate it use almost all gpu resources while execution and this behaviour freeze UI because of lack resources. If it possible, will be good to have some initial option with percentage of GPU use. 

OS Android

For example - 
GpuDelegate.Options().gpuUsePercentage = 0.8

This feature will provide more control over resources."
tensorflow/tensorflow,2022-06-08 21:13:26,feature,Is it possible to sync tensorflow stream_executor's cuda stream with cuda stream outside?,"In tensorflow, streams including cuda streams are handled by stream_executer. Now I make some modification to tensorflow and create an independent cuda stream outside stream_executer. I was wondering is it possible to sync the independent cuda stream with the streams that wrap a cuda stream in stream_executer? 

I really appreciate if someone has advices."
tensorflow/tensorflow,2022-06-07 11:36:24,feature,Custom Op written in C API compilation Issue,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Source

binary

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux 

### Mobile device

07010841551

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi there!
Is there any example where Custom OP written using C API was compiled successfully and executed after tf_load_library()?
I have referred the entire kernels.h ,ops.h and c_api.h files of the official github tf repo but I am not able to figure it out.
Could someone give the command to execute a C API custom op file along with the code?

Thanks,
Yoga
```


### Standalone code to reproduce the issue

```shell
#include ""tensorflow/c/kernels.h""
#include ""tensorflow/c/ops.h""
#include ""tensorflow/c/tf_tensor.h""
#include ""tensorflow/core/framework/common_shape_fns.h""
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/registration/registration.h""
#include ""tensorflow/core/framework/shape_inference.h""
#include ""tensorflow/core/platform/macros.h""

// shape inference
void basic_shape_inference_fn(TF_ShapeInferenceContext* ctx,TF_Status* status) {
  TF_ShapeHandle* handle = TF_NewShapeHandle();
  TF_ShapeInferenceContextGetInput(ctx, 0, handle, status);
  TF_ShapeInferenceContextSetOutput(ctx, 0, handle, status);
  TF_DeleteShapeHandle(handle);
  assert(TF_GetCode(status) != TF_OK);
}

typedef struct Basic {
  TF_Tensor* input;
  TF_Tensor* output;
} Basic;

static void* Basic_Create(TF_OpKernelConstruction* context) {
  Basic* k = (Basic*) calloc(1, sizeof(Basic));
  TF_Status* status = TF_NewStatus();
  /* initialize the fields of k as needed */
  assert(TF_GetCode(status) != TF_OK);
  TF_DeleteStatus(status);
  return (void*) k;
  
}

static void Basic_Compute(void* k, TF_OpKernelContext* ctx) { 
  /* compute the result */
  TF_Tensor* input_tensor=NULL;
  TF_Status* status = TF_NewStatus();
  TF_GetInput(ctx, 0, &input_tensor, status);
  TF_SetOutput(ctx, 0, input_tensor, status);
  assert(TF_GetCode(status) != TF_OK);
  TF_DeleteStatus(status);
}

static void Basic_Delete(void* kernel) {
  delete static_cast<Basic*>(kernel);
}

// Op and Kernel Registration

void InitPlugin(){
  TF_Status* status = TF_NewStatus();
  TF_OpDefinitionBuilder* op_builder = TF_NewOpDefinitionBuilder(""Basic"");
  TF_OpDefinitionBuilderAddInput(op_builder, ""to_zero: int32"");
  TF_OpDefinitionBuilderAddOutput(op_builder, ""zeroed: int32"");
  TF_OpDefinitionBuilderSetShapeInferenceFunction(op_builder,&basic_shape_inference_fn);
  TF_RegisterOpDefinition(op_builder, status);
  assert(TF_GetCode(status) != TF_OK);
  TF_DeleteStatus(status);
  TF_Status* status1 = TF_NewStatus();
    auto* builder = TF_NewKernelBuilder(""Basic"", tensorflow::DEVICE_CPU,
                                        &Basic_Create, &Basic_Compute,
                                        &Basic_Delete);
    TF_RegisterKernelBuilder(""Basic"", builder, status1);
    assert(TF_OK != TF_GetCode(status1));
  TF_DeleteStatus(status1);
}

// TF_ATTRIBUTE_UNUSED static bool IsBasicKernelRegistered = []() {
//   if (SHOULD_REGISTER_OP_KERNEL(""Basic"")) {
//     RegisterBasicKernel();
//   }
//   return true;
// }();
```


### Relevant log output

```shell
module '012ff3e36e3c24aefc4a3a7b68a03fedd1e7a7e1' has no attribute 'basic'
```
</details>"
tensorflow/tensorflow,2022-06-06 18:36:02,feature,Add tf.Complex to tflite ops. Support padding and slicing of complex tensors,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

2.9.1

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
It would be great if we could get support in tflite for the `tf.Complex` op as well as support for slicing and padding complex numbers.

This is very important for audio use cases as it often involves running STFTs and working with complex numbers.

Here's the error I currently get when I try to convert my model:


Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select
TF Select ops: Complex, Pad, StridedSlice
Details:
	tf.Complex(tensor<2x128x2048x2xf32>, tensor<2x128x2048x2xf32>) -> (tensor<2x128x2048x2xcomplex<f32>>) : {device = """"}
	tf.Pad(tensor<2x128x2048x2xcomplex<f32>>, tensor<4x2xi32>) -> (tensor<2x128x2049x2xcomplex<f32>>) : {device = """"}
	tf.StridedSlice(tensor<2x128x2049x2xcomplex<f32>>, tensor<4xi32>, tensor<4xi32>, tensor<4xi32>) -> (tensor<2x128x2048x2xcomplex<f32>>) : {begin_mask = 15 : i64, ellipsis_mask = 0 : i64, end_mask = 11 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 0 : i64}
```
```


### Standalone code to reproduce the issue

```shell
NA
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-06-04 15:26:44,feature,F1 score metric,"### Issue Type

<kbd>Feature Request</kbd>

---

### Tensorflow Version

2.9.1

---

### Current Behaviour?

No F1 score metric. It's a holistic measure for classification.

https://torchmetrics.readthedocs.io/en/stable/classification/f1_score.html

https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score

---

### Standalone code to reproduce the issue

https://www.tensorflow.org/api_docs/python/tf/keras/metrics
"
tensorflow/tensorflow,2022-06-02 06:50:54,feature,Is it possible to change colour of specific keypoint in iOS,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

MacOS

### Mobile device

iPhone X

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to change colour of specific body landmarks. Is it possible to achieve in iOS using Swift
```


### Standalone code to reproduce the issue

```shell
Multicolor on overlay image
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-06-01 06:50:06,feature,Building Tflite compiling out pthread,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf2.9

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 16.04.2 LTS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am trying to build Tflite example ""minimal"" for a device which does not support Posix Thread.
I know one can disabled multi-threading by setting num_threads = 1 in the Interpreter, but what I am trying to get is disabling PTHREAD fully during compilation.

Is there a way to achieve this?

Thanks
```


### Standalone code to reproduce the issue

```shell
You can run the https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal test.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-05-31 04:17:16,feature,How to display custom label with angles in iOS?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How to display degree of angle on every keyPoint.
```


### Standalone code to reproduce the issue

```shell
Below code for to create degree of angle I used

func angle(
              firstLandmark: CGPoint,
              midLandmark: CGPoint,
              lastLandmark: CGPoint
          ) -> CGFloat {
              let radians: CGFloat =
                  atan2(lastLandmark.y - midLandmark.y,
                            lastLandmark.x - midLandmark.x) -
                    atan2(firstLandmark.y - midLandmark.y,
                            firstLandmark.x - midLandmark.x)
              
              
               var degrees = radians * 180.0 / .pi
              //var degrees = radians * .pi / 180 /// .pi
                degrees = abs(degrees) // Angle should never be negative
               if degrees > 180.0 {
                  degrees = 360.0 - degrees // Always get the acute representation of the angle
               }
              
               let roundedValue1 = round(degrees)
              
              return roundedValue1
          }
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-05-30 04:30:56,feature,How to calculate 45 degree standing position of body from camera in swift (Pose estimation),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How to calculate 45 degree standing position of body from camera in swift.
```


### Standalone code to reproduce the issue

```shell
How to calculate 45 degree standing position of body from camera in swift using the body keypoints. (Pose estimation)
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-05-26 04:38:18,feature,is it possible to calculate Body degree angle using pose estimation,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How to calculate degree of angles using body keyPoints? & Pose angle. ie. 45 degree, 90 degree.
```


### Standalone code to reproduce the issue

```shell
I want to detect human body pose angle is it possible?
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-05-22 07:53:07,feature,Restore non max suppression (nms) support for Tensorflow Lite GPU Delegate.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

v2.9.0-rc2-42-g8a20d54a3c1 2.9.0

### Custom Code

Yes

### OS Platform and Distribution

Google Colab

### Mobile device

_No response_

### Python version

3.7.13 (Google Colab)

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
TL;DR: 
Please restore support for NonMaxSuppression for Tensorflow Lite GPU Delegate.  
It was supported before (TF 2.3) and is not supported now.

Background:
Back in Tensorflow version 2.3 one could take and run Object Detection model (e.g. from
Tensorflow Object Detection API) and run it fully on the TFLite with GPU via delegate.

Right now it is impossible - operations that were previously supported (like `NonMaxSuppression`) are now unsupported.

By dropping support to these operations user's are forced-locked to use older Tensorflow version. Please bring back support for `NonMaxSuppression` as it was previously supported.
```


### Standalone code to reproduce the issue

```shell
# Colab link:
# https://colab.research.google.com/drive/1orm0B-5US7Tn5EaAKJl4xGKbHegLtNYm?usp=sharing

# Let's verify support with TFLite's Authoring Tool
import tensorflow as tf

@tf.function(input_signature = [
    tf.TensorSpec(shape=(1, 100, 4), dtype=tf.float32),  # boxes
    tf.TensorSpec(shape=(1, 100, 1), dtype=tf.float32)  # scores
])
def nms(boxes, scores):
    return tf.image.non_max_suppression_padded(
        boxes,
        scores,
        max_output_size=15,
        pad_to_max_output_size=True,
    )

# Verify this works:
boxes = tf.ones(shape=(1, 100, 4))
scores = tf.ones(shape=(1, 100, 1))
selected_indices_padded, num_valid = nms(boxes, scores)

# Verify crashes TFLite GPU Delegate (authoring tool)
target_spec = tf.lite.TargetSpec()
target_spec.experimental_supported_backends = [""GPU""]
func_to_test = tf.lite.experimental.authoring.compatible(
    nms, converter_target_spec=target_spec, raise_exception=True
)
func_to_test(boxes, scores)
```


### Relevant log output

```shell
# The log output is rather long and covers multiple sub ops. I'm only pasting the lower part:

During handling of the above exception, another exception occurred:

CompatibilityError                        Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/authoring/authoring.py in _decode_error(self, err)
    244 
    245     if self._raise_exception and self._log_messages:
--> 246       raise CompatibilityError(f""CompatibilityException at {repr(self._func)}"")
    247 
    248   def _log(self, message):

CompatibilityError: CompatibilityException at <tensorflow.python.eager.def_function.Function object at 0x7f70f5780590>
```
</details>"
tensorflow/tensorflow,2022-05-18 10:44:29,feature,[TFLite] Dynamic batch size with GPU delegate,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.10.0-dev20220427

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

Linux Ubuntu 18.04

### Python version

3.10

### Bazel version

5.1.1

### GCC/Compiler version

7.5.0

### CUDA/cuDNN version

CUDA 11.6

### GPU model and memory

NVIDIA GeForce GTX 1650 4BG

### Current Behaviour?

Considering these two assertions (please tell me if they are wrong):
* It is not possible to use dynamic-sized tensors with the GPU delegate.
* Nor is it possible to use a batch size greater than one with the GPU delegate.

EDIT: It seems that when I saw the bug with batch size greater than one, the GPU delegate switched to OpenGL instead of OpenCL (I do not know the reason), and now that it is working with OpenCL (after rebooting the computer), the inference can run on the GPU with any batch size. Thus it would still mean that this feature should be available with OpenGL...

However it would very convenient to be able to modify the batch size before creating the network on the GPU, or (if requested by the user) to recreate the network at any time with a different batch size.
This would allow to convert and store a single model with dynamic-sized tensors, the size of which would actually be known (i.e., batch size would be set) before making use of the network.

Then it would be possible to perform [on-device training](https://www.tensorflow.org/lite/examples/on_device_training/overview#build_a_model_for_on-device_training) on the GPU with a batch of inputs, once issue #56151 is solved.


### Standalone code to reproduce the issue

Try running [this on-device training tutorial](https://www.tensorflow.org/lite/examples/on_device_training/overview#build_a_model_for_on-device_training) with both Flex and GPU delegates using the experimental C API.


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-05-17 12:13:42,feature,Build/release Python 3.10 tflite-runtime wheels to PyPI,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.9.0

### Custom Code

No

### OS Platform and Distribution

Linux & macOS

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

[Tensorflow 2.9.0 was released with Python 3.10 support](https://pypi.org/project/tensorflow/2.9.0/#files).

We would like to support Python 3.10 in production, but in order to do this we need all of the following packages to support Python 3.10:

- `tensorflow`
- `tensorflow-macos` (for ARM macOS)
- `tflite-runtime` (for stripped down production on Linux)

Neither [`tensorflow-macos`](https://pypi.org/project/tensorflow-macos/#history) or [`tflite-runtime`](https://pypi.org/project/tflite-runtime/) have 2.9.0 releases on PyPI yet.


### Standalone code to reproduce the issue

Create a Python 3.10 virtual environment on Linux:

```bash
(venv) $ python -m pip install tflite-runtime
```

Create a Python 3.10 virtual environment on macOS ARM:

```bash
(venv) $ python -m pip install tensorflow-macos
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-05-06 14:59:06,feature,3D SSIM ,"Hi, is it possible to add 3D SSIM (batched) into TensorFlow? We need this feature for 3D inference. Currently `tf.image.ssim` only accepts batched 2D input. 

If not, is there any internal beta version of 3D SSIM for try-out? 

Thanks. 
"
tensorflow/tensorflow,2022-05-02 14:21:19,feature,tf.keras.optimizers.experimental.AdamW only support constant weight_decay,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.keras.optimizers.experimental.AdamW only supports constant weight decay. But usually we want the weight_decay value to decay with learning rate schedule.
```


### Standalone code to reproduce the issue

```shell
The legacy tfa.optimizers.AdamW supports callable weight_decay, which is much better.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-04-30 09:27:56,feature,How to resize (downsample) 5D samples in tensorflow? ,"Issue Type: Feature Request
Source: binary
Tensorflow Version: tf 2.8
Custom Code: Yes
OS Platform and Distribution: Windows 10
Python version: 3.9

---

## Note.

Reposting from [here](https://github.com/keras-team/keras/issues/16260). It's closed in keras and recommended to post it on the tensorflow side because this functionality is not precisely available in tensorflow. It may need to write low-level ops in tf for best performance.


# Current Behaviour?

Currently, for **5D** data, `(batch_size, h, w, depth, channel)`, the [`tf.keras.backend.resize_volumes`](https://github.com/keras-team/keras/pull/3274) or `UpSampling3D` can be used to **upsampling purpose**. 

For example, I can do 

```python
a  = tf.ones(shape=(1, 100, 100, 64, 1))

tf.keras.backend.resize_volumes(
       a, depth_factor=2, 
       height_factor=2, 
       width_factor=2, 
       data_format=""channels_last""
).shape
TensorShape([1, 200, 200, 128, 1])
```

These `*_factor` values (above), should be an **integer**, and are coded here: https://github.com/keras-team/keras/blob/master/keras/backend.py#L3441-L3444. 

In that case, how can we **downsample** the input sample? For example:

```python
a  = tf.ones(shape=(1, 100, 100, 64, 1))

tf.keras.backend.resize_volumes(
       a, depth_factor=0.5, 
       height_factor=0.5, 
       width_factor=0.5 
       data_format=""channels_last""
).shape

TypeError: 'float' object cannot be interpreted as an integer

# EXPECTED
TensorShape([1, 50, 50, 32, 1])
```

[ HERE https://stackoverflow.com/q/57341504/9215780, another scenario where the factor needed to be fractional. ]

# Candidate Solutions

- [scipy.ndimage.zoom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.zoom.html)
- [in pytorch](https://discuss.pytorch.org/t/pytorch-resize-3d-numpy-array/70338/4) (didn't test)

## Others

- Such downsampling feature needs to be implemented in low-level. 
- In the `depth` part of volumetric data, it might be hard to decide the appropriate strategy to drop the slices depending on the domain. For example, in medical data, if we drop the slice blindly, we might lose information. FYI, in CT/MRI images, most of the information appears mainly in the **middle range**. 
- Currently a workaround for **medical data (CT/MRI)**, we're following:

```
# (input data: 1, 50, 50, 20, 4)
# (desired output: 1, 25, 25, 10, 4)
```
```python
a = tf.ones(shape=(1, 50, 50, 20, 4))
a.shape # TensorShape([1, 50, 50, 20, 4])

a2 = tf.reshape(a, [-1, 50, 50, 20*4])
a2.shape # TensorShape([1, 50, 50, 80])

a3 = tf.image.resize(a2, [25, 25])
a3.shape # TensorShape([1, 25, 25, 80])

a4 = tf.reshape(a3, [-1, 25, 25, 20, 4])
a4.shape # TensorShape([1, 25, 25, 20, 4])

# HERE, Picking some middle slices -
# - Assuming that by this we may get relevant slices. 
# How convenient is this? # May not general! 
a5 = a4[...,  5:15, :]
a5.shape
TensorShape([1, 25, 25, 10, 4])
```"
tensorflow/tensorflow,2022-04-21 08:47:07,feature,TFLite Tensor name converted by 2.7.0 is much longer than 1.14.0,"### System information

-   **OS Platform and Distribution**: Linux Ubuntu 18.04
-   **Mobile device**: No
-   **TensorFlow installed from (source or binary)**: binary, pip install tensorflow==2.7.0
-   **TensorFlow version**: 2.7.0
-   **Python version**: 3.8.13
-   **Bazel version (if compiling from source)**: None
-   **GCC/Compiler version (if compiling from source)**: None
-   **CUDA/cuDNN version**: None
-   **GPU model and memory**: None
-   **Exact command to reproduce**: None

### Describe the problem
Using tensorflow 1.14.0 convert .pb model to tflite as follows:
```python
import tensorflow as tf

graph_def_file = '/path/to/mobilenet_v1.pb'
input_arrays = ['input']
output_arrays = ['MobilenetV1/Predictions/Reshape_1']
input_shapes = {'input': [1, 224, 224, 3]}

convert = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes)
tflite_model = convert.convert()
with open('mobilenet_v1_tf1.14.tflite', 'wb') as f:
    f.write(tflite_model)
```

After update tensorflow to 2.7.0 and modify scripts as follows:
```python
import tensorflow as tf

graph_def_file = '/path/to/mobilenet_v1.pb'
input_arrays = ['input']
output_arrays = ['MobilenetV1/Predictions/Reshape_1']
input_shapes = {'input': [1, 224, 224, 3]}

convert = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes)
tflite_model = convert.convert()
with open('mobilenet_v1_tf2.7.tflite', 'wb') as f:
    f.write(tflite_model)
```
I found tensor name in `mobilenet_v1_tf2.7.tflite` is much longer than `mobilenet_v1_tf1.14.tflite`. Such a long name caused a lot of trouble when comparing the tflite model with the original model.

However, I also noticed that there will be a new `Attributes` in TFLiteConverter.
```python
convert = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes)
convert.experimental_new_convert = False
tflite_model = convert.convert()
```
But the log as follows warning me that old converter is deprecated:
```shell
WARNING:absl:Please consider switching to the new converter by setting experimental_new_converter=True. The old converter (TOCO) is deprecated.
```
Is is possible to add an attribute in the new version, so that the model conversion name can remain unchanged, and the tensor of folder const can be removed.

"
tensorflow/tensorflow,2022-04-20 22:25:36,feature,Replacing Add Layer with Linear Combination of Learnable Weights,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

The Add() Layer can be expressed as a linear combination of inputs where each coefficient value is 1. 

I was trying to make a custom layer that performs the same as Add, except uses trainable coefficients as we assume a coefficient of 1 is optimal. Unfortunately, I was unable to do so on my own, specifically the gradients. 

I do not think this would be too hard to implement as all the code is kind of already there, just need to calculate gradients and then update.

### Source

source

### Tensorflow Version

2.7

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The Add() Layer can be expressed as a linear combination of inputs where each coefficient value is 1. 

I was trying to make a custom layer that performs the same as Add, except uses trainable coefficients as we assume a coefficient of 1 is optimal. Unfortunately, I was unable to do so on my own, specifically the gradients. 

I do not think this would be too hard to implement as all the code is kind of already there, just need to calculate gradients and then update.
```


### Standlone code to reproduce the issue

```shell
x
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2022-04-13 03:32:21,feature,request for feature gather and matmul,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.7.1
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
This function can realize that the corresponding weight is taken from the matrix B according to the index given by the matrix C and then multiplied by the matrix A.
A: [batch, h]
B: [num, h, d]
C: [batch, ]
out: [batch, d]
batch >> num
```python
for i, j in enumerate(C):
   out[i] = matmul(A[i], B[j])
```
Currently this function can be implemented by tf.gather then tf.matmul. However, it will waste a lot of gpu memory due to the need to define an intermediate variable W.
```python
W = tf.gather(B, C)
out = tf.matmul(A, W)
```
It can also be implemented by one hot matmul. However the time complexity of the calculation will be very high.
```python
tmp = tf.one_hot(C, depth=num)
out = tf.enisum('bh,bn,nhd->bd', A, tmp, B)
```
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
This function can be applied to the moe model to achieve the assignment of experts strictly according to the probability of the router. Avoids the limitations of the expert capacity currently required. 
**Any Other info.**
No"
tensorflow/tensorflow,2022-04-06 12:53:30,feature,RFE tensorflow-aarch64==2.6.0 build ?,"**System information**
 TensorFlow version (you are using):  2.6.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Brainchip Akida AKD1000 SNN neuromorphic MetaTF SDK support 2.6.0 on x86_64. They claim support for aarch64, but when creating a virtualenv it fails on aarch64 due to lacking tensorflow-aarc64==2.6.0 build.

**Will this change the current api? How?**

NA

**Who will benefit with this feature?**

Customer of Brainchip Akida who run on Arm64 platforms.

**Any Other info.**

https://doc.brainchipinc.com/installation.html


"
tensorflow/tensorflow,2022-04-03 02:32:54,feature,tf.image.extract_patches default value for areas outside the input ,"Running tf.image.extract_patches by the ""Same"" padding leads to zeros for areas outside the input. There is no way to change the default value and it is best to have this as another parameter for this function. This background label should be always zero; otherwise, this function mess up the labels."
tensorflow/tensorflow,2022-03-29 12:53:21,feature,`pfor`/`tf.vectorize_map`: Improve feedback/hints messages when it `fallback_to_while_loop`,"**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):
Probably if I can talk with a codeowner of this namepace

**Describe the feature and the current behavior/state.**
As we are adding [a root cause message](https://github.com/tensorflow/tensorflow/pull/55192) on the cause we are going internally to rely on `fallback_to_while_loop`  it would be nice to have a more clear feedback  string to the user on what kind of action is required (e.g. refactoring his function, open a new ticket with a code gist on TF github, etc..).

See more at https://github.com/tensorflow/tensorflow/pull/55192#issuecomment-1081306349 /cc @wangpengmit 

**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Developers that partially fail to fully `tf.vectorize_map` their functions
**Any Other info.**
"
tensorflow/tensorflow,2022-03-16 23:20:45,feature,List of TF ops that tf.vectorized_map supports,"Where can I get this information? 

Which tf operation is a vectorized operation? and which one is not?

"
tensorflow/tensorflow,2022-03-15 21:25:46,feature,Generalise `xla::Map` to functions over arbitrary shapes,"**System information**
- TensorFlow version (you are using): 2.8
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

Currently `xla::Map` only allow functions from shape [] to []. I'd like to use functions with arbitrary shapes. For example, apply a function with shapes [2, 3] -> [5] to a tensor [100, 4, 2, 3] to get a [100, 4, 5].

I've not yet thought about how it would work when mapping multiple input tensors at once.

**Will this change the current api? How?**

It would extend `xla::Map`, either internally, or as an overload. It's possible additional information would need to be passed to a more general implementation of map, in which an overload may be preferable to maintain backwards compatibility.

**Who will benefit with this feature?**

Anyone using XLA who'd like to apply a function over sections of a tensor. It would effectively be an alternative to (some portion of) broadcasting, allowing people to use functions that don't allow leading dimensions to tensors with leading dimensions.

It is particularly useful for me as I'm working with dependent types and adding leading dimensions is non-trivial (and verbose) in type signatures.

**Any Other info.**

It is already possible to do this by indexing into the tensor and iteratively applying the function to the contents, then concatenating the results, but I expect this is significantly slower than could be achieved within XLA. I have considered using `xla::While` for this but I still expect the slicing and concatenation would still come with a significant performance cost."
tensorflow/tensorflow,2022-03-08 12:17:27,feature,please publish TensorFlowLiteObjC 2.8,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
Android 2.8
iOS 2.7
- Are you willing to contribute it (Yes/No):
NO


**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
tensorflow/tensorflow,2022-02-23 09:27:19,feature,capture_tpu_profile on Cloud TPU VM,"Hello

It seems that capture_tpu_profile only works for legacy TPU devices, but not for Cloud TPU VM.

I was wondering if and when we can expect to have support for Cloud TPU VM. 
At the moment, its is impossible to monitor Jax/Flax TPU workloads, as tensorboard instrumentation does not exhibit the right metrics (eg % utilization of TPU Matrix Units).

Other related thread for legacy TPU devices: https://stackoverflow.com/questions/52427141/check-tpu-workload-utilization

Thanks!
"
tensorflow/tensorflow,2022-02-22 13:50:23,feature,XLA tf.bincount support,"**System information**
- TensorFlow version (you are using): master
- Are you willing to contribute it (Yes/No): only if we have a clear path and a reviewer on how to contribute this
**Describe the feature and the current behavior/state.**
`tf.bincount` isn't supported by XLA
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Speedup functions/loops that rely on `tf.bincount`
**Any Other info.**
How to reproduce it:
```python
import tensorflow as tf
@tf.function(jit_compile=True)
def compiled_bincount(values):
  return tf.math.bincount(values)

values = tf.constant([1,1,2,3,2,4,4,5])
print(compiled_bincount(values)) #[0 2 2 1 2 1]
```

```python
InvalidArgumentError: Detected unsupported operations when trying to compile graph __inference_compiled_bincount_296[_XlaMustCompile=true,config_proto=3175580994766145631,executor_type=11160318154034397263] on XLA_CPU_JIT: Bincount (No registered 'Bincount' OpKernel for XLA_CPU_JIT devices compatible with node {{node bincount/Bincount}}){{node bincount/Bincount}}
The op is created at: 
```

Without this we had problems to compile intermediate Ms Coco recall function in keras-cv:
https://github.com/keras-team/keras-cv/issues/141#issuecomment-1043692891

Extra: 
Please also note that the CPU/GPU TF2XLA supported ops tables are probably outdated (2018):
https://github.com/tensorflow/tensorflow/issues/14798#issuecomment-1047796247

/cc @joker-eph @LukeWood "
tensorflow/tensorflow,2022-02-20 08:12:01,feature,gradient_function/gradient_tapes with device annotations,"**System information**
- TensorFlow version (you are using): 2.8
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Feature request: adding `colocate_gradients_with_ops` option to `tf.gradients` in 1.x to `tf.GradientTape` in 2.x.

This feature request/issue was 1st mentioned in https://github.com/tensorflow/tensorflow/issues/33688 almost two years ago by @olesalscheider . Allow me to quickly review the op in which the current behavior (still hold in tf 2.8) is described.

> Currently GradientTape.gradient() is executed on the device of the scope it is called in. Have a look at the following code:
> 
```
with tf.GradientTape() as tape:
    with tf.device('/gpu:1'):
        x = f1(input)
    with tf.device('/gpu:2'):
        x = f2(x)
    with tf.device('/gpu:0'):
        g = tape.gradient(x, f_vars)
```
> Here all gradient calculations will be carried out by GPU:0 and all variables needed for the gradient calculation will also be allocated on GPU:0. This is a problem if these temporary variables are too large to fit into the VRAM of GPU:0.
> 
> Please provide a way to execute the backward functions on the device of the corresponding forward function and allocate temporary variables for gradient calculation there. This allows to split a large model and distribute it among as many GPUs as necessary.
> 

Also, @olesalscheider provided a pr https://github.com/tensorflow/tensorflow/commit/a64ff0f2cda9d4e35ea450d4e945009a90ddee9a to achieved such feature and it get merged at the beginning, but shortly get rollbacked due to certain performance issues. 

I opened another pr https://github.com/tensorflow/tensorflow/pull/54510/commits/c292044a64700ecc3fa419b8247dfb1b61cf3ce7 to fit the current master (tf2.8) and build and test it. It looks to me the gradient can now be split correctly according to the device annotation.

**Will this change the current api? How?**
It will allow tf.GradientTape to do gradient in the device of the corresponding forward function. Hence, it would be possible to split the training of large models into as many possible GPUs as necessary

**Who will benefit with this feature?**
Anyone who wants to train large models that do not fit into the VRAM of a single GPU.

**Any Other info.**

It looks to me that the original post has gone silence... So I raise the issue again here to draw more attentions. It is a very import feature for peoples working in large image segmentation tasks. Some times the input tensor is so large and the model can not even be fitted into a single A100 card. 

Moreover, I noticed that in the discussion flow in the original post that there are some other work around like split into different tapes. I tried but with no luck. all gradient calculation still be allocated on gpu:0, and moreover, splitting tape would be very different for model like u-net which has a lot of skip-connections.

Last but not the least, I know for a fact that there is the Mash-Tensorflow which propose to do such job, but a native tensorflow support would be also very useful for people work on large models."
tensorflow/tensorflow,2022-02-11 03:17:35,feature,RuntimeError: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>
2022-02-11 11:05:30.792376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Traceback (most recent call last):
  File ""01_GenQuadProposals.py"", line 82, in <module>
    CNNModel.restoreCNNSess()
  File ""/home/dms/SupplementaryMaterials/CodeAndData/Code/QuadProposals/CNNQuadDetector.py"", line 92, in restoreCNNSess
    saver = tf.train.import_meta_graph(self.cfg.cornerdet_sess + '.meta', import_scope=""cornerdet"")
  File ""/home/dms/anaconda3/envs/SupplementaryMaterials/lib/python3.8/site-packages/tensorflow/python/training/saver.py"", line 1460, in import_meta_graph
    return _import_meta_graph_with_return_elements(meta_graph_or_file,
  File ""/home/dms/anaconda3/envs/SupplementaryMaterials/lib/python3.8/site-packages/tensorflow/python/training/saver.py"", line 1472, in _import_meta_graph_with_return_elements
    raise RuntimeError(""Exporting/importing meta graphs is not supported when ""
RuntimeError: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.

**System information**
- TensorFlow version (you are using):
tensorboard                  2.8.0
tensorboard-data-server      0.6.1
tensorboard-plugin-wit       1.8.1
tensorflow                   2.3.1
tensorflow-estimator         2.3.0
tensorflow-hub               0.12.0
tensorflow-io-gcs-filesystem 0.24.0
tensorflowjs                 3.13.0
cuda                           10.1
cudnn                          7.6
python                         3.8
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
tensorflow/tensorflow,2022-02-04 21:29:34,feature,Option to avoid caching with bijectors.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.7.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
The current behaviour for `tensorflow_probability.bijectors.Bijector` is to cache the input to be used if the inverse function is called. I would very much like a keyword being able to turn this caching off to ensure the inverse function of the bijector is always called. Whilst setting the property of `_is_injective` can accomplish this, you lose other features.

**Will this change the current api? How?**
Yes, a keyword in the definition of the Bijector class.

**Who will benefit with this feature?**
Anyone who wishes to have bijectors where the inverse function is always called rather than the input that's been cached.

**Any Other info.**
"
tensorflow/tensorflow,2022-01-30 16:26:23,feature,Gradient for tf.sparse.reduce_max,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>



**Describe the feature and the current behavior/state.**
tf.sparse.reduce_max do not define grad. So it cannot be used in training step.

**Will this change the current api? How?**
Won't change current api. Just add grad in tf.sparse.reduce_max

**Who will benefit with this feature?**
People using sparse.reduce_max in training. If they have huge sparse matrix and cannot turn to dense array.

**Any Other info.**
I am working with pointnet-like model. And it will take a huge sparse matrix. If I turn this sparse matrix to dense, it will take ~60G memory. So I need do global maxpooling. Using tf sparse reduce_max. Unfortunately, it cannot be used in training right now.
Thanks"
tensorflow/tensorflow,2022-01-24 14:49:06,feature,iterating over `tf.Tensor` is not allowed,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.3
- Python version:3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I have a dictionary that I build by accessing only the channel dimensions of an output layer of a convolutional neural network (it has a shape (100,24,24,6) )
Therefore keys of this dictionary are tuples of tensor shape (6, ) . I want to map these keys to the input of the next layer using the tf.map_fn(). However, i am incapable of doing it because the keys of my dictionary are of type tensor and i cannot iterate over them .
Looking for some help. Thank you.
**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
tensorflow/tensorflow,2022-01-22 20:53:44,feature,Count number of leaves in the ensemble gradient BoostedTree,"This is an issue related to the performance of [TensorFlow.BoostedTree](https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier)




**System information**
- TensorFlow version (you are using): 2.7.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Is there any method that returns the number of entire leaves in the built ensemble?
If the feature already exists, would you please introduce it a bit more here, if not could we develop it?

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Users of the tensorflow

"
tensorflow/tensorflow,2022-01-21 19:39:23,feature,normalization should be done using moving averages?,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/structured_data/time_series#normalize_the_data

## Description of issue (what needs changing):

Hello this is a small feature request. In the Time series tutorial at the normalization section in the 3rd paragraph there is a remark saying:
""and that this normalization should be done using moving averages.""

I am very curious on how a moving average would be used here. 
Should  a ""simple moving average"" for the whole dataset be computed and then on that new ""dataset-MA"" just use the normalization technique that is described in the tutorial?

The feature I am requesting is something like a remark on how this would be done or maybe a pointer to different tutorial if one exists or some further references/research users could look into."
tensorflow/tensorflow,2022-01-18 13:28:51,feature,Using scipy fsolve or other solvers (e.g. GEKKO) in combination with backpropagation models,"I was wondering if there was any progress or existing methodologies to use existing solvers such as GEKKO to find/update certain values in your network.
E.g: When using PINN networks on a electrical circuit, one might use a variable resistance dependent on one of your network input parameters. When this dependency is given by an explicit equation it would be nice to, given the inputs, be able to use existing solvers as scipy's fsolve to get this value and use it further on in the network.

From my experience in order to be able to use solvers, tensors should be converted to numpy elements and used in combination with tf.numpy_function, this way I can use solvers as such, however it breaks the chain of gradients and TF can no longer find gradients for certain values and thus no longer train the network.

**System information**
- Tensorflow 2.3.0 (but using some TF1 functionalities from tf.compat.v1:
- No possibility to share existing code, but see below for small (hypothetical) case example. 



### start of code
from scipy.optimize import fsolve
Class PPINlayer(tf.keras.layers.Layer)
       def __init__(self):
               super(PPINlayer, self).__init__(**kwargs)

       def call(self, input, NN *args):
               NNoutput = NN(input)                # this is a NN already initialized somewhere else with trainable parameters
               output = self.f(NNoutput, input)
               return output                                # the output is then used later on to compare with labeled data as loss function for training
       def f(self, NNoutput, input)
             R0 = input[0]
             R1 = input[1]
             V0 = input[2]
             def R2_eq(R2, R0, R1):
                    return np.exp(R2/R1) * R1/R2 + R0**2
             R2 = fsolve(R2_eq, 0, args=(R0, R1))
             return (V0/R0 * R2)


Thanks in advance!
Cedric
"
tensorflow/tensorflow,2022-01-15 07:35:06,feature,[TFLite] Optional Debug Tools can only support log in Desktop Computer,"Hi TensorFlowers,
The `tflite::PrintInterpreterState(interpreter.get())` in [minimal.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/minimal/minimal.cc#L62) can only be used on computer system with desktop. Because it use `printf` style to output info in [optional_debug_tools.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/optional_debug_tools.cc#L278), not the `TFLITE_LOG` in [minimal_logging](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/minimal_logging.h) the better way supporting more systems. Besides, why not use something like `std::stringstream` to format info, that seems more general?"
tensorflow/tensorflow,2022-01-09 16:06:11,feature,I have made wrapper of Tensor ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):

Latest Github release

**Describe the feature and the current behavior/state.**

Graph

**Will this change the current api? How?**

nope

**Who will benefit with this feature?**

Everyone

**Any Other info.**


I have started wrapper of Tensorflow using cppflow. I need some help with graph. It is unclear how it works in C API. I am thinking of wrapping C++ api. It works for all swig languages. The question is does C/api suppot the graph enough to use it or should I wrap the C++ API?"
tensorflow/tensorflow,2022-01-07 03:36:12,feature,tf.data.dataset gather element,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): Tensorflow 2.7
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
I want to do something like tf.gather on tf.data.Dataset. 
For example, 
dataset = tf.data.Dataset.from_tensor_slices(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i'])
choice_dataset = tf.data.Dataset.range(3).repeat(2) # Define a dataset containing [0, 1, 2, 0, 1, 2]

I want it to output a dataset having ['a', 'b', 'c', 'a', 'b', 'c']

This is somewhat similar to choose_from_datasets, but that method choose from multiple datasets not element in the dataset

**Will this change the current api? How?** Add new method to tf.data.Dataset

**Who will benefit with this feature?** Tensorflow dataset user

**Any Other info.**
 I am not sure if there is a workaround. Please correct me if I am wrong.
"
tensorflow/tensorflow,2021-12-30 15:09:03,feature,Request for RandomIllumination layer in keras,"Something like this already is possible with `ImageDataGenerator` but with corners in it (only applies brightness scale).
What is needed is a full keras layer that randomize illumination differences spatially across the image (or even a single scaling factor to the whole image).
i think more ideas can be added to something like this if it was implemented properly."
tensorflow/tensorflow,2021-12-30 10:30:07,feature,Release tensorflow-macos wheel compatible with Python 3.9 and x86,"Currently in version 2.7.0 of `tensorflow-macos`, there are only 3 wheels released in pip: 2 for arm64 supporting Python 3.8-3.9 and 1 for x86 only supporting Python 3.8.
It would be great to have also a wheel for Python 3.9 for the x86 architecture.
The same thing also applies for `tensorflow-metal`.


**System information**
- TensorFlow version (you are using): 2.7.0



**Describe the feature and the current behavior/state.**
See above

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Every Intel Mac User with Python 3.9

**Any Other info.**
"
tensorflow/tensorflow,2021-12-16 21:49:47,feature,tf.debugging.assert_type throws error when checking type of RaggedTensor,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04.6 LTS**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: **N/A**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **v2.7.0-rc1-69-gc256c071bb2 2.7.0**
- Python version: **3.9.0**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **N/A**
- GPU model and memory: **N/A**

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When calling `tf.debugging.assert_type` on a `RaggedTensor`, a `ValueError: TypeError: object of type 'RaggedTensor' has no len()` is thrown.

**Describe the expected behavior**
The assertion check should pass if the ragged tensor is the correct type or fail otherwise.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): **no**
- Briefly describe your candidate solution(if contributing): **N/A**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

a = tf.ragged.constant([[1, 2], [1]])
tf.debugging.assert_type(a, tf_type=tf.int32)  # Should pass
>>> ValueError: TypeError: object of type 'RaggedTensor' has no len()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

**Workaround**
```
import tensorflow as tf

a = tf.ragged.constant([[1, 2], [1]])
assert a.dtype == tf.int32
```"
tensorflow/tensorflow,2021-12-16 00:39:34,feature,Support partial parameter warm-start from pretrained checkpoints in tensorflow v2 (non-estimator mode),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tensorflow 2.x
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Warm-starting from an existing checkpoint is an important feature for all kinds of model training that's well supported under tf.estimator framework. The latter unfortunately seems relegated to second class status in tensorflow 2.x, since it's not eager (at least not natively?). 

The closest way to achieve warm-start in tf2.x seems to be via tf.train.Checkpoint, a more directly approach than tf.estimator.warm_start_utils, that is, if implemented well. So far however I see that it supports loading all the parameters in a checkpoint altogether, but not loading only some of the parameters. 

**Will this change the current api? How?**
Possibly. Maybe provide a kwarg in Checkpoint initializer called parameter_list.

**Who will benefit with this feature?**
Anyone who wants to reuse a pretrained model but not all of its parameters.

**Any Other info.**
There is a lot of emphasis on eagerness, efficiency, in tensorflow v2, but in my opinion not sufficient focus on flexibility and directness of usage so far. Warm-starting is one example.

Update: my colleague found an unofficial implementation of flexible warm-start from a checkpoint in the TF2 version of BERT [here](https://github.com/kpe/bert-for-tf2/blob/master/bert/loader.py#L236). I would recommend adding some official examples along similar lines."
tensorflow/tensorflow,2021-12-13 11:17:54,feature,New dtype: bcomplex32 ,"


**System information**
- TensorFlow version (you are using): 2.7
- Are you willing to contribute it (Yes/No): Probably yes



**Describe the feature and the current behavior/state.**
Add bcomplex32 dtype.
Currently only a real (like in Math, real field) version is supported (bfloat16)

**Will this change the current api? How?**
Each function that supports the dtype paramter, should also support the new bcomplex32
**Who will benefit with this feature?**
Anyone who uses the complex plane and wants a speedup for further calculations on supported hardware such as GPUs with compatibility level of 7 and above, for example while using FFT.
**Any Other info.**
"
tensorflow/tensorflow,2021-12-07 08:22:29,feature,Can I repeat a 1-D tensor in segment form?,"According to the doc, TF has: tf.segment_xxx and tf.repeat. But can I repeat a 1-D tensor in segment form?

#### Example:
segment = [0 0 0 1 1]
value = [0 1 2 3 4]

#### [ 1 ] If repeat_cnt = [2 2 2 1 1]
With tf.repeat, I can easily repeat value to: [0 0 1 1 2 2 3 4]

#### [ 2 ] But I want a segment repeat, which means: segment-0 repeat 2 times, segment-1 repeat 1 time.
That is to say, if repeat_cnt_new = [2 1], and I want to repeat value to: [0 1 2 0 1 2 3 4].

#### I mean, repeat blocks in a vector: [0 1 2] * 2 + [3 4] * 1. Are there any TF func or api can help?
Thanks!"
tensorflow/tensorflow,2021-12-04 07:43:01,feature,LSTM expansion,"**System information**
- TensorFlow version (you are using): 1.3
- Are you willing to contribute it (Yes/No): Maybe

**Describe the feature and the current behavior/state.**

Simple LSTMs have limitations. It cannot extract some features, i.e. some mathematical operands, conditional logic, etc. I don't think the LSTM advancements cover this. This paper kind of shows what logic needs to be part of LSTM out of the box: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610074 
Can we improve the LSTM to include ability to figure out some basic logic like mathematical operands and conditional logic?

**Will this change the current api? How?**
Shouldn't.

**Who will benefit with this feature?**
Everyone.

**Any Other info.**
LSTM is brokened at the moment. Pretty rudimentary."
tensorflow/tensorflow,2023-09-23 14:14:42,bug,KeyError: 'min',"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.13

### Custom code

Yes

### OS platform and distribution

5.15.90.1-microsoft-standard-WSL2

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2

### GPU model and memory

_No response_

### Current behavior?

Traceback (most recent call last):
  File ""o2k.py"", line 11, in <module>
    k_model = onnx_to_keras(onnx_model, ['input.1'], name_policy='renumerate', verbose=True)
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/converter.py"", line 175, in onnx_to_keras
    AVAILABLE_CONVERTERS[node_type](
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/operation_layers.py"", line 31, in convert_clip
    if params['min'] == 0:
KeyError: 'min'

### Standalone code to reproduce the issue

```shell
from onnx2keras import onnx_to_keras
import keras
import onnx
import sys
# sys.path.append(""/root/MR"")
onnx_model = onnx.load('ssd_bmv1_torch.onnx')
onnx_inputs = onnx_model.graph.input
print(""==========================="")
print(onnx_inputs)
# onnx_model = onnx.load('vgg11.onnx')
k_model = onnx_to_keras(onnx_model, ['input.1'], name_policy='renumerate', verbose=True)
keras.models.save_model(k_model, 'ssd_bmv1_torch.h5', overwrite=True, save_format=""h5"")

onnx file can be downloaded at https://pan.xunlei.com/s/VNf1O2DqsdqdbTYYpyemSqveA1?pwd=by77#
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""o2k.py"", line 11, in <module>
    k_model = onnx_to_keras(onnx_model, ['input.1'], name_policy='renumerate', verbose=True)
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/converter.py"", line 175, in onnx_to_keras
    AVAILABLE_CONVERTERS[node_type](
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/operation_layers.py"", line 31, in convert_clip
    if params['min'] == 0:
KeyError: 'min'
```
"
tensorflow/tensorflow,2023-09-23 14:07:35,bug,AttributeError: Number of inputs is not equal 1 for unsqueeze layer,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

tf 2.13

### Custom code

Yes

### OS platform and distribution

5.15.90.1-microsoft-standard-WSL2

### Mobile device

_No response_

### Python version

3.8.17

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2

### GPU model and memory

_No response_

### Current behavior?

Traceback (most recent call last):
  File ""o2k.py"", line 11, in <module>
    k_model = onnx_to_keras(onnx_model, ['onnx::Unsqueeze_0'], name_policy='renumerate', verbose=True)
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/converter.py"", line 175, in onnx_to_keras
    AVAILABLE_CONVERTERS[node_type](
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/reshape_layers.py"", line 210, in convert_unsqueeze
    raise AttributeError('Number of inputs is not equal 1 for unsqueeze layer')
AttributeError: Number of inputs is not equal 1 for unsqueeze layer

### Standalone code to reproduce the issue

```shell
please run the below codes to reproduce:

from onnx2keras import onnx_to_keras
import keras
import onnx
import sys
# sys.path.append(""/root/MR"")
onnx_model = onnx.load('textcnn_torch.onnx')
onnx_inputs = onnx_model.graph.input
print(""==========================="")
print(onnx_inputs)
# onnx_model = onnx.load('vgg11.onnx')
k_model = onnx_to_keras(onnx_model, ['onnx::Unsqueeze_0'], name_policy='renumerate', verbose=True)
keras.models.save_model(k_model, 'textcnn_torch.h5', overwrite=True, save_format=""h5"")
```
onnx file can be downloaded at https://pan.xunlei.com/s/VNf1M2KIkqx6PBbrBdTiuTkMA1?pwd=wxqf#
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""o2k.py"", line 11, in <module>
    k_model = onnx_to_keras(onnx_model, ['onnx::Unsqueeze_0'], name_policy='renumerate', verbose=True)
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/converter.py"", line 175, in onnx_to_keras
    AVAILABLE_CONVERTERS[node_type](
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/reshape_layers.py"", line 210, in convert_unsqueeze
    raise AttributeError('Number of inputs is not equal 1 for unsqueeze layer')
AttributeError: Number of inputs is not equal 1 for unsqueeze layer
```
"
tensorflow/tensorflow,2023-09-23 13:40:43,bug,"ValueError: Exception encountered when calling layer ""13"" (type Lambda).","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.13

### Custom code

Yes

### OS platform and distribution

5.15.90.1-microsoft-standard-WSL2

### Mobile device

_No response_

### Python version

3.8.17

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.2

### GPU model and memory

_No response_

### Current behavior?

<html xmlns:v=""urn:schemas-microsoft-com:vml""
xmlns:o=""urn:schemas-microsoft-com:office:office""
xmlns:x=""urn:schemas-microsoft-com:office:excel""
xmlns=""http://www.w3.org/TR/REC-html40"">

<head>

<meta name=ProgId content=Excel.Sheet>
<meta name=Generator content=""Microsoft Excel 15"">
<link id=Main-File rel=Main-File
href=""file:///C:/Users/pengg/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">
<link rel=File-List
href=""file:///C:/Users/pengg/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">
<style>
<!--table
	{mso-displayed-decimal-separator:""\\."";
	mso-displayed-thousand-separator:""\\,"";}
@page
	{margin:.75in .7in .75in .7in;
	mso-header-margin:.3in;
	mso-footer-margin:.3in;}
.font5
	{color:windowtext;
	font-size:9.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:等线;
	mso-generic-font-family:auto;
	mso-font-charset:134;}
tr
	{mso-height-source:auto;
	mso-ruby-visibility:none;}
col
	{mso-width-source:auto;
	mso-ruby-visibility:none;}
br
	{mso-data-placement:same-cell;}
td
	{padding-top:1px;
	padding-right:1px;
	padding-left:1px;
	mso-ignore:padding;
	color:black;
	font-size:11.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:等线;
	mso-generic-font-family:auto;
	mso-font-charset:134;
	mso-number-format:General;
	text-align:general;
	vertical-align:middle;
	border:none;
	mso-background-source:auto;
	mso-pattern:auto;
	mso-protection:locked visible;
	white-space:nowrap;
	mso-rotate:0;}
.xl65
	{text-align:center;}
.xl66
	{text-align:center;
	white-space:normal;}
ruby
	{ruby-align:left;}
rt
	{color:windowtext;
	font-size:9.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:等线;
	mso-generic-font-family:auto;
	mso-font-charset:134;
	mso-char-type:none;
	display:none;}
-->
</style>
</head>

<body link=""#0563C1"" vlink=""#954F72"">



ValueError:   Exception encountered when calling layer ""13"" (type Lambda).          Dimensions must be equal, but are 204 and 206 for '{{node 13/Add}} =   AddV2[T=DT_FLOAT](Placeholder, Placeholder_1)' with input shapes:   [?,64,204,204], [?,64,206,206].          Call arguments received by layer ""13"" (type Lambda):       • inputs=['tf.Tensor(shape=(None,   64, 204, 204), dtype=float32)', 'tf.Tensor(shape=(None, 64, 206, 206),   dtype=float32)']       • mask=None       • training=None
--




</body>

</html>


### Standalone code to reproduce the issue

```shell
just run the following code to reproduce:

from onnx2keras import onnx_to_keras
import keras
import onnx
import sys
# sys.path.append(""/root/MR"")
onnx_model = onnx.load('yolov3_darknet53.onnx')
onnx_inputs = onnx_model.graph.input
print(""==========================="")
print(onnx_inputs)
# onnx_model = onnx.load('vgg11.onnx')
k_model = onnx_to_keras(onnx_model, ['x'], name_policy='renumerate', verbose=True)
keras.models.save_model(k_model, 'ssd_resnet50fpn_torch.h5', overwrite=True, save_format=""h5"")
```
the onnx file can be downloaded at https://pan.xunlei.com/s/VNf1FtBh2v6mP_QXJWVailBmA1?pwd=g43e#
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""o2k.py"", line 11, in <module>
    k_model = onnx_to_keras(onnx_model, ['x'], name_policy='renumerate', verbose=True)
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/converter.py"", line 175, in onnx_to_keras
    AVAILABLE_CONVERTERS[node_type](
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/elementwise_layers.py"", line 83, in convert_elementwise_add
    layers[node_name] = lambda_layer([input_0, input_1])
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/root/miniconda3/envs/onnx/lib/python3.8/site-packages/onnx2keras/elementwise_layers.py"", line 76, in target_layer
    layer = tf.add(
ValueError: Exception encountered when calling layer ""LAYER_12"" (type Lambda).

Dimensions must be equal, but are 204 and 206 for '{{node LAYER_12/Add}} = AddV2[T=DT_FLOAT](Placeholder, Placeholder_1)' with input shapes: [?,64,204,204], [?,64,206,206].

Call arguments received by layer ""LAYER_12"" (type Lambda):
  • inputs=['tf.Tensor(shape=(None, 64, 204, 204), dtype=float32)', 'tf.Tensor(shape=(None, 64, 206, 206), dtype=float32)']
  • mask=None
  • training=None
```
"
tensorflow/tensorflow,2023-09-19 09:12:56,bug,Training Vanilla Transformer on TPU gives InternalError,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04.2 (Google Colab)

### Mobile device

Colab

### Python version

3.10.12

### Bazel version

Colab

### GCC/compiler version

Colab

### CUDA/cuDNN version

Colab

### GPU model and memory

Colab

### Current behavior?

Training Transformer model on TPU gives Internal Error 

I have some idea on the error that there's a incompatible tensor ops thats causing the problem but i can't pinpoint it.

I had already done a bigger model which is using pretrained embeddings and it went off without a hitch i tried to replicate the same but with different tfds dataset

If this is already solved please direct me to the relevant links

### Standalone code to reproduce the issue

```
[This is the notebook](https://colab.research.google.com/drive/1y3VEuaYXnsoB42TaVd8UBB-18U8UHFBt#scrollTo=Y0hKZ9yRC3FU)

[This notebook worked fine](https://colab.research.google.com/drive/1DJU058LhhyCfNsuHZ74kZ0E2ziHw-VYo)

Thankyou in advance. I will respond asap
```


### Relevant log output

```shell
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
[<ipython-input-12-013fa12d9e3a>](https://localhost:8080/#) in <cell line: 1>()
----> 1 model.fit(
      2     train_ds,
      3     validation_data=valid_ds,
      4     epochs=EPOCHS,
      5     steps_per_epoch=train_steps,

1 frames
[/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py](https://localhost:8080/#) in error_handler(*args, **kwargs)
     68             # To get the full stack trace, call:
     69             # `tf.debugging.disable_traceback_filtering()`
---> 70             raise e.with_traceback(filtered_tb) from None
     71         finally:
     72             del filtered_tb

[/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/capture/capture_container.py](https://localhost:8080/#) in capture_by_value(self, graph, tensor, name)
    120         graph_const = self.by_val_internal.get(id(tensor))
    121         if graph_const is None:
--> 122           graph_const = tensor._capture_as_const(name)  # pylint: disable=protected-access
    123           if graph_const is None:
    124             # Some eager tensors, e.g. parallel tensors, are not convertible to

InternalError: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:35437: Failed to connect to remote host: Connection refused
Additional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:
:UNKNOWN:failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:35437: Failed to connect to remote host: Connection refused {created_time:""2023-09-19T08:56:09.694479753+00:00"", grpc_status:14}
Executing non-communication op <MultiDeviceIteratorInit> originally returned UnavailableError, and was replaced by InternalError to avoid invoking TF network error handling logic.
```
"
tensorflow/tensorflow,2023-09-14 16:07:56,bug,Body function of `while_loop` cannot access the external variable after compilation ,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.15.0-dev20230914

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

The body function of `while_loop` cannot access the external variable after compilation. It will raise the error `UnboundLocalError: local variable 'x' referenced before assignment`

However, if I run the model without the `@tf.function(jit_compile=True)`, the model can be executed without any error.

### Standalone code to reproduce the issue

```shell
class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()

  @tf.function(jit_compile=True) # Comment this line, it will succeed
  def call(self, x):

    def cond(i, _):
      return i < 10

    def body(i, y):
      y = tf.math.add(y, 2.0)
      x = tf.math.multiply(x, 2.0)
      return [tf.math.subtract(i, 1), y + x]

    i = tf.constant(10)
    y = tf.constant(1.0)
    _, final_y = tf.while_loop(cond, body, [i, y], shape_invariants=[i.shape, y.shape])
    return final_y

m = Model()
input_shape = [1,2]
x = tf.constant([4.,5.], shape=input_shape)

y = m(x)
```


### Relevant log output

```shell
UnboundLocalError: Exception encountered when calling layer 'model_28' (type Model).

in user code:

    File ""<ipython-input-31-1eb50a9c2c75>"", line 16, in body  *
        x = tf.math.multiply(x, 2.0)

    UnboundLocalError: local variable 'x' referenced before assignment


Call arguments received by layer 'model_28' (type Model):
  • x=tf.Tensor(shape=(1, 2), dtype=float32)
```
"
tensorflow/tensorflow,2023-09-13 07:26:53,bug,Could not find matching concrete function to call loaded from the SavedModel,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.10

### Custom code

Yes

### OS platform and distribution

win10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

How to match data of signature?

### Standalone code to reproduce the issue

```shell
...

model.save(filepath=save_model_dir, save_format='tf', signatures=None)
local_model = tf.keras.models.load_model(filepath=save_model_dir)

y_local_pred = local_model.predict(x_test)
y_model_pred = model.predict(x_test)
print('y_local_pred == y_model_pred:', numpy.allclose(y_local_pred, y_model_pred))

user_inputs = [
    tf.TensorSpec.from_tensor(tf.convert_to_tensor(user_inputs[0]), name='inputs/0'),
    tf.TensorSpec.from_tensor(tf.convert_to_tensor(user_inputs[1]), name='inputs/1'),
    tf.TensorSpec.from_tensor(tf.convert_to_tensor(user_inputs[2]), name='inputs/2'),
]

user_outputs = local_model.user_fn(user_inputs)
```


### Relevant log output

```shell
Could not find matching concrete function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * [<tf.Tensor 'inputs/0:0' shape=(150, 5) dtype=float32>,
 <tf.Tensor 'inputs/1:0' shape=(150, 10) dtype=int32>,
 <tf.Tensor 'inputs/2:0' shape=(150, 3, 5) dtype=int32>]
  Keyword arguments: {}
 Expected these arguments to match one of the following 1 option(s):
Option 1:
  Positional arguments (1 total):
    * (TensorSpec(shape=(None, 5), dtype=tf.float32, name='inputs/0'),
 TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/1'),
 TensorSpec(shape=(None, 3, 5), dtype=tf.int32, name='inputs/2'))
  Keyword arguments: {}
```
"
tensorflow/tensorflow,2023-09-08 07:58:42,bug,ValueError: Unable to create dataset (name already exists),"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Epoch 1/10
1/1 [==============================] - ETA: 0s - loss: 6.8405 - accuracy: 0.3250
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-57-865e41f45523> in <cell line: 1>()
----> 1 transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds,batch_size=BATCH_SIZE,callbacks=[early_stop, checkpoint_call, plot_losses])

2 frames
/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)
    161         sid = h5s.create_simple(shape, maxshape)
    162 
--> 163     dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl, dapl=dapl)
    164 
    165     if (data is not None) and (not isinstance(data, Empty)):

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/h5d.pyx in h5py.h5d.create()

ValueError: Unable to create dataset (name already exists)


i want to save each epoch as a checkpoint two weeks back back without any any error each checkpoint will save as a checkpoint but suddenly now getting error

### Standalone code to reproduce the issue

```shell
import matplotlib.pyplot as plt

from tensorflow.keras.callbacks import Callback


import os

checkpoint_dir = '/model/checkpoints_m_1'

if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)
from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', patience=3)
# Set up the model checkpoint callback
checkpoint_call = ModelCheckpoint(filepath=checkpoint_dir+""/checkpoint_{epoch}.hdf5"",
                                  monitor='val_loss',
                                  save_best_only=True,
                                  save_weights_only=False,
                                  mode='min',
                                  save_freq='epoch')
transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds,batch_size=BATCH_SIZE,callbacks=[early_stop, checkpoint_call)
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-09-06 01:05:08,bug,bazel  test failed with some ctest,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf2.12

### Custom code

Yes

### OS platform and distribution

centos7.6

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.3.0

### GCC/compiler version

9.3.1

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

After compiling tensorflow based on the source code, bazel test is executed for unit testing, some test items are passed, but there are many failures, and the reasons for the error are as follows
So I want to know if I'm executing the statement incorrectly, how should I set it up?
bazel test -c opt  --config=cuda  --test_sharding_strategy=disabled  //tensorflow/core/kernels/...
output information:
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
Executing tests from //tensorflow/core/kernels/image:resize_ops_test_gpu

![image](https://github.com/tensorflow/tensorflow/assets/30514703/bc876890-814c-4488-8c74-ee9f46960ada)


![image](https://github.com/tensorflow/tensorflow/assets/30514703/befa4291-9404-42d1-956a-11250f384cc4)


### Standalone code to reproduce the issue

```shell
bazel test -c opt  --config=cuda  --test_sharding_strategy=disabled  //tensorflow/core/kernels/...
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-09-05 04:04:13,bug,"Unable to open file (truncated file: eof = 2568306, sblock->base_addr = 0, stored_eof = 9406464)","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

v2.13.0-rc2-7-g1cb1a030a62 2.13.0

### Custom code

No

### OS platform and distribution

mac os 13.5.1

### Mobile device

_No response_

### Python version

3.11.3

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
Cell In[15], line 3
      1 # Create the base model from the pre-trained model MobileNet V2
      2 IMG_SHAPE = IMG_SIZE + (3,)
----> 3 base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=IMG_SHAPE,
      4                                                include_top=False,
      5                                                weights='imagenet')

File [~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras/src/applications/mobilenet_v2.py:481], in MobileNetV2(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)
    477         weight_path = BASE_WEIGHT_PATH + model_name
    478         weights_path = data_utils.get_file(
    479             model_name, weight_path, cache_subdir=""models""
    480         )
--> 481     model.load_weights(weights_path)
    482 elif weights is not None:
    483     model.load_weights(weights)

File [~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70], in filter_traceback..error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb
...
File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper()

File h5py/h5f.pyx:106, in h5py.h5f.open()

OSError: Unable to open file (truncated file: eof = 2568306, sblock->base_addr = 0, stored_eof = 9406464)

### Standalone code to reproduce the issue

```shell
https://tensorflow.google.cn/tutorials/images/transfer_learning

# Create the base model from the pre-trained model MobileNet V2
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-30 10:49:08,bug,"XLA compiled tf.where with known output shape error (set_shape, tf.concat / tf.stack)","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13

### Custom code

No

### OS platform and distribution

Google Colab

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Output of `tf.where`, when used inside `tf.function` with `jit_compile=True`, can sometimes be used correctly (as with sum), and sometimes raises shape mismatch error (as with concatenation). This error is present even if output shape is set manually with `set_shape`. 

The code below runs without `jit_compile` or with sum instead of `tf.concat`, and only fails if concatenating inside a compiled function. 

Note: `autoclustering` solves the issue on the toy example, but _not_ on the codebase I am working on.

### Standalone code to reproduce the issue

Colab: https://colab.research.google.com/drive/1FuboVMSao8eCZLcZ2F7Fdsa1UvlnHQmG?usp=sharing

```python
import tensorflow as tf

def fun(x, y):
    x = tf.where(x == 1)
    print(f'Shape before (unknown): {x.shape}') 
    x.set_shape(shape=[y.shape[0], 2])
    print(f'Shape after (known): {x.shape}') 
    return tf.concat([x,y], axis=1)  # Concatentation fails
    # return x + y  # Sum would succeed

x = tf.constant([[0,0,1,1,0],
                  [0,1,0,1,0],
                  [1,0,0,0,1],
                  [1,0,1,0,0],
                  [0,1,1,0,0],], dtype=tf.int32)
y = tf.expand_dims(tf.range(x.shape[0] * 2, dtype=tf.int64), axis=-1)

fun(x, y)

tf.function(fun)(x,y)

tf.function(fun, jit_compile=True)(x,y)  # Fails as described above
```


### Relevant log output

```shell
Shape before (unknown): (None, 2)
Shape after (known): (10, 2)
InvalidArgumentError: Cannot concatenate arrays that differ in dimensions other than the one being concatenated. Dimension 0 in both shapes must be equal: s64[<=25,2] vs s64[10,1].
```
"
tensorflow/tensorflow,2023-08-26 19:24:11,bug,Will there a MLP model in the future version?,"### Issue type

Feature Request

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13.0

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When building deep learning models like Multi-Layer Perceptrons (MLPs), code reusability and conciseness are crucial factors. Currently, using `tf.keras.Sequential` in TensorFlow allows for convenient creation of sequential models. However, manually adding common operations such as Batch Normalization or Dropout to each layer can lead to code redundancy and an increased burden in terms of coding and maintenance. Therefore, proposing the addition of a feature in TensorFlow to directly create MLPs with Batch Normalization and Dropout is highly beneficial.

Here are several reasons why this feature would be advantageous for TensorFlow users:

1. **Simplified Code**: Users won't need to manually add Batch Normalization and Dropout operations to each layer, resulting in cleaner, more readable, and maintainable code.

2. **Reduced Error Rate**: Manual copy-pasting of code is error-prone, especially as model complexity increases. Automating the integration of Batch Normalization and Dropout operations can reduce issues arising from code errors.

3. **Increased Productivity**: Developers can build and iterate on models more swiftly, focusing on design and parameter tuning rather than rewriting the same code segments for every new model.

4. **Education and Learning**: For newcomers to TensorFlow, this feature can provide a quicker onboarding process, lowering the learning curve and enabling them to grasp and apply deep learning concepts faster.

Certainly, here's the additional information:

I also believe that PyTorch has implemented MLP functionality quite effectively. An example of this can be found in the following URL: [PyTorch MLP](https://pytorch.org/vision/main/generated/torchvision.ops.MLP.html). PyTorch's approach to creating MLPs provides a good reference for how TensorFlow could potentially integrate similar features.

### Standalone code to reproduce the issue

```shell
origin

model = tf.keras.Sequential([
    tf.keras.layers.Dense(128),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(64),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(32),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10),
])


with MLP model
```python
model = tf.keras.MLP(
    hidden_channels=[128, 64, 32, 10],
    norm_layer=tf.keras.layers.BatchNormalization,
    activation_layer=tf.keras.layers.ReLU,
    dropout=0.2,
)
```
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-25 08:27:34,bug,"extensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

1.13.1

### Custom code

Yes

### OS platform and distribution

Unbuntu 22

### Mobile device

_No response_

### Python version

Python 2.7

### Bazel version

_No response_

### GCC/compiler version

9.4.0

### CUDA/cuDNN version

10

### GPU model and memory

GTX 1060 

### Current behavior?

Hi, I got this error when I run Dirt model with my tensorflow-gpu 1.13.1 . 

`2023-08-25 15:23:37.711796: F /home/engineer1/dirt/csrc/gl_common.h:46] extensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available`

### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
import dirt

canvas_width, canvas_height = 128, 128
centre_x, centre_y = 32, 64
square_size = 16


def get_non_dirt_pixels():
    xs, ys = tf.meshgrid(tf.range(canvas_width), tf.range(canvas_height))
    xs = tf.cast(xs, tf.float32) + 0.5
    ys = tf.cast(ys, tf.float32) + 0.5
    x_in_range = tf.less_equal(tf.abs(xs - centre_x), square_size / 2)
    y_in_range = tf.less_equal(tf.abs(ys - centre_y), square_size / 2)
    return tf.cast(tf.logical_and(x_in_range, y_in_range), tf.float32)


def get_dirt_pixels():

    # Build square in screen space
    square_vertices = tf.constant([[0, 0], [0, 1], [1, 1], [1, 0]], dtype=tf.float32) * square_size - square_size / 2.
    square_vertices += [centre_x, centre_y]

    # Transform to homogeneous coordinates in clip space
    square_vertices = square_vertices * 2. / [canvas_width, canvas_height] - 1.
    square_vertices = tf.concat([square_vertices, tf.zeros([4, 1]), tf.ones([4, 1])], axis=1)

    return dirt.rasterise(
        vertices=square_vertices,
        faces=[[0, 1, 2], [0, 2, 3]],
        vertex_colors=tf.ones([4, 1]),
        background=tf.zeros([canvas_height, canvas_width, 1]),
        height=canvas_height, width=canvas_width, channels=1
    )[:, :, 0]


def main():

    if '.' in tf.__version__ and int(tf.__version__.split('.')[0]) < 2:

        session = tf.Session()
        with session.as_default():

            non_dirt_pixels = get_non_dirt_pixels().eval()
            dirt_pixels = get_dirt_pixels().eval()

    else:

        non_dirt_pixels = get_non_dirt_pixels().numpy()
        dirt_pixels = get_dirt_pixels().numpy()

    if np.all(non_dirt_pixels == dirt_pixels):
        print('successful: all pixels agree')
    else:
        print('failed: {} pixels disagree'.format(np.sum(non_dirt_pixels != dirt_pixels)))


if __name__ == '__main__':
    main()
```


### Relevant log output

```shell
2023-08-25 15:23:37.181664: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2023-08-25 15:23:37.186756: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2496000000 Hz
2023-08-25 15:23:37.189184: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x24d6bf0 executing computations on platform Host. Devices:2023-08-25 15:23:37.189205: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2023-08-25 15:23:37.478413: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2023-08-25 15:23:37.478518: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x233ae60 executing computations on platform CUDA. Devices:2023-08-25 15:23:37.478540: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1
2023-08-25 15:23:37.478666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: NVIDIA GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 5.09GiB
2023-08-25 15:23:37.478681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2023-08-25 15:23:37.478801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-08-25 15:23:37.478813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2023-08-25 15:23:37.478817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2023-08-25 15:23:37.478968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.
2023-08-25 15:23:37.479033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4913 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
2023-08-25 15:23:37.711796: F /home/engineer1/dirt/csrc/gl_common.h:46] extensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available
Aborted
```
"
tensorflow/tensorflow,2023-08-23 19:29:13,bug,Batch matmul imprecision,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13 / 2.14.0-dev20230706

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

```
$ mamba list | grep cu
cuda-nvcc                 12.2.128                      0    nvidia
cudatoolkit               11.8.0              h4ba93d1_12    conda-forge
nvidia-cublas-cu11        2022.4.8                 pypi_0    pypi
nvidia-cublas-cu117       11.10.1.25               pypi_0    pypi
nvidia-cuda-nvrtc-cu11    2022.4.8                 pypi_0    pypi
nvidia-cuda-nvrtc-cu117   11.7.50                  pypi_0    pypi
nvidia-cudnn-cu11         8.9.4.25                 pypi_0    pypi
```
### GPU model and memory

NVIDIA GeForce RTX 3060 - 12 GB
Driver Version: 520.61.05

### Current behavior?

I'm trying to do a batch matrix multiply (i.e. I've got a bunch of m x n matrices, all in one tensor, and I want to do a matrix multiply of each of them with some other matrix). However, I'm getting slightly different results than I get from Numpy (and previous TensorFlow versions, this script passed for me in 2.9). 

One interesting thing is that the value 25 (the second dimension of `x`) is significant. If I reduce this to 16 or below, it passes. Also, if I change the second dimension of `c` from 2 to 1, it also passes.

### Standalone code to reproduce the issue

```python
import numpy as np
import tensorflow as tf

print(f""file: {tf.__file__}"")
print(f""git version: {tf.version.GIT_VERSION}"")
print(f""version: {tf.__version__}"")

rng = np.random.RandomState(0)
x = rng.uniform(-1, 1, size=(1, 25, 5)).astype(np.float32)
c = rng.uniform(-1, 1, size=(5, 2)).astype(np.float32)

y = x @ c

x2 = np.tile(x, (2, 1, 1))
y2 = x2 @ c

for y2i in y2:
    np.testing.assert_allclose(y2i, y.squeeze(0))

tols = dict(atol=1e-7, rtol=1e-5)

z = tf.matmul(x, c).numpy()
# z = tf.einsum(""...tq,...qr->...tr"", x, c)
np.testing.assert_allclose(z, y, **tols)

z2 = tf.matmul(x2, c).numpy()
# z2 = tf.einsum(""...tq,...qr->...tr"", x2, c)
np.testing.assert_allclose(z2, y2, **tols)
```


### Relevant log output

```shell
file: /home/ehunsber/mambaforge/envs/tf213/lib/python3.8/site-packages/tensorflow/__init__.py
git version: v1.12.1-96406-gfa4d29bfef8
version: 2.14.0-dev20230706
Traceback (most recent call last):
  File ""test_batch.py"", line 26, in <module>
    np.testing.assert_allclose(z2, y2)
  File ""/home/ehunsber/mambaforge/envs/tf213/lib/python3.8/site-packages/numpy/testing/_private/utils.py"", line 1592, in assert_allclose
    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),
  File ""/home/ehunsber/mambaforge/envs/tf213/lib/python3.8/contextlib.py"", line 75, in inner
    return func(*args, **kwds)
  File ""/home/ehunsber/mambaforge/envs/tf213/lib/python3.8/site-packages/numpy/testing/_private/utils.py"", line 862, in assert_array_compare
    raise AssertionError(msg)
AssertionError: 
Not equal to tolerance rtol=1e-07, atol=0

Mismatched elements: 100 / 100 (100%)
Max absolute difference: 0.00046098
Max relative difference: 0.01047752
 x: array([[[-0.187503,  0.005696],
        [-0.255552, -0.84404 ],
        [ 0.268836, -1.250793],...
 y: array([[[-0.187499,  0.005691],
        [-0.255404, -0.844322],
        [ 0.268935, -1.251033],...
```
"
tensorflow/tensorflow,2023-08-22 09:20:30,bug,TF Quantizer breaks pip package,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

git HEAD

### Custom code

No

### OS platform and distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.9.16

### Bazel version

6.1.0

### GCC/compiler version

16.0.6

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current behavior?

The commit https://github.com/tensorflow/tensorflow/commit/fee881376914381062deb767759d144d0f07d760 added pywrap_quantize_model.so to the pip package but the build fails to set the RPATH for _pywrap_tensorflow_internal.so in the new .so leading to a failure in auditwheel when attempting to 'repair' to make it manylinux2014 compatible.

### Standalone code to reproduce the issue

```shell
$ python3 -m auditwheel repair --plat manylinux2014_aarch64 ./tensorflow-pkg/tensorflow_aarch64-2.15.0-cp311-cp311-linux_aarch64.whl --wheel-dir ./whl/
```


### Relevant log output

```shell
$ python3 -m auditwheel repair --plat manylinux2014_aarch64 ./tensorflow-pkg/tensorflow_aarch64-2.15.0-cp311-cp311-linux_aarch64.whl --wheel-dir ./whl/
INFO:auditwheel.main_repair:Repairing tensorflow_aarch64-2.15.0-cp311-cp311-linux_aarch64.whl
Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""/usr/local/lib/python3.11/dist-packages/auditwheel/__main__.py"", line 6, in <module>
    sys.exit(main())
             ^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/auditwheel/main.py"", line 59, in main
    rval = args.func(args, p)
           ^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/auditwheel/main_repair.py"", line 173, in execute
    out_wheel = repair_wheel(
                ^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.11/dist-packages/auditwheel/repair.py"", line 80, in repair_wheel
    raise ValueError(
ValueError: Cannot repair wheel, because required library ""_pywrap_tensorflow_internal.so"" could not be located

Also

$ ldd venv_bad/lib/python3.11/site-packages/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_quantize_model.so
	linux-vdso.so.1 (0x0000ffffb8af9000)
	libtensorflow_framework.so.2 => /workspace/venv_bad/lib/python3.11/site-packages/tensorflow/compiler/mlir/quantization/tensorflow/python/../../../../../libtensorflow_framework.so.2 (0x0000ffffb6800000)
	_pywrap_tensorflow_internal.so => not found
	libdl.so.2 => /lib/aarch64-linux-gnu/libdl.so.2 (0x0000ffffb8923000)
	libpthread.so.0 => /lib/aarch64-linux-gnu/libpthread.so.0 (0x0000ffffb88f2000)
	libm.so.6 => /lib/aarch64-linux-gnu/libm.so.6 (0x0000ffffb8847000)
	libstdc++.so.6 => /lib/aarch64-linux-gnu/libstdc++.so.6 (0x0000ffffb661b000)
	libgcc_s.so.1 => /lib/aarch64-linux-gnu/libgcc_s.so.1 (0x0000ffffb8823000)
	libc.so.6 => /lib/aarch64-linux-gnu/libc.so.6 (0x0000ffffb64a8000)
	/lib/ld-linux-aarch64.so.1 (0x0000ffffb8ac9000)
	librt.so.1 => /lib/aarch64-linux-gnu/librt.so.1 (0x0000ffffb8809000)

Compare with

$ ldd venv_bad/lib/python3.11/site-packages/tensorflow/python/saved_model/pywrap_saved_model.so
	linux-vdso.so.1 (0x0000ffffa40a2000)
	libtensorflow_framework.so.2 => /workspace/venv_bad/lib/python3.11/site-packages/tensorflow/python/saved_model/../../libtensorflow_framework.so.2 (0x0000ffffa1e00000)
	_pywrap_tensorflow_internal.so => /workspace/venv_bad/lib/python3.11/site-packages/tensorflow/python/saved_model/../_pywrap_tensorflow_internal.so (0x0000ffffa1c0a000)
	libdl.so.2 => /lib/aarch64-linux-gnu/libdl.so.2 (0x0000ffffa3ee5000)
	libm.so.6 => /lib/aarch64-linux-gnu/libm.so.6 (0x0000ffffa3e3a000)
	libpthread.so.0 => /lib/aarch64-linux-gnu/libpthread.so.0 (0x0000ffffa3e09000)
	libstdc++.so.6 => /lib/aarch64-linux-gnu/libstdc++.so.6 (0x0000ffffa1a25000)
	libgcc_s.so.1 => /lib/aarch64-linux-gnu/libgcc_s.so.1 (0x0000ffffa3de5000)
	libc.so.6 => /lib/aarch64-linux-gnu/libc.so.6 (0x0000ffffa18b2000)
	/lib/ld-linux-aarch64.so.1 (0x0000ffffa4072000)
	librt.so.1 => /lib/aarch64-linux-gnu/librt.so.1 (0x0000ffffa3dcd000)
	libtensorflow_cc.so.2 => /workspace/venv_bad/lib/python3.11/site-packages/tensorflow/python/saved_model/../../libtensorflow_cc.so.2 (0x0000ffff8be00000)
	libml_dtypes.so.so => /workspace/venv_bad/lib/python3.11/site-packages/tensorflow/python/saved_model/../../tsl/python/lib/core/libml_dtypes.so.so (0x0000ffffa3d99000)
	libomp.so.5 => /usr/lib/llvm-16/lib/libomp.so.5 (0x0000ffff8bcc0000)
```
"
tensorflow/tensorflow,2023-08-22 02:41:46,bug,"  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/interpreter.py"", line 915, in invoke     self._interpreter.Invoke() RuntimeError: tensorflow/lite/kernels/concatenation.cc:158 t->dims->data[d] != t0->dims->data[d] (1 != 2)Node number 304 (CONCATENATION) failed to prepare.","### 1. System information
![image](https://github.com/tensorflow/tensorflow/assets/35233355/cfc8e9d3-9790-4a89-86db-062b97d3bbbc)

- OS Platform and Distribution (Linux Ubuntu 20.04):
- TensorFlow installation (2.9.1+nv22.9):

### 2. Code
`import numpy as np
import tensorflow as tf

def main():
    # Load the TFLite model and allocate tensors.
    interpreter = tf.lite.Interpreter(model_path=""model.tflite"")
    interpreter.allocate_tensors()
    
    #return

    # Get input and output tensors.
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    # Test the model on random input data.

    input_shape = input_details[0]['shape']
    input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
    #interpreter.set_tensor(input_details[0]['index'], input_data)

    signatures = interpreter.get_signature_list()
    print(signatures)

    interpreter.invoke()
    return
    # The function `get_tensor()` returns a copy of the tensor data.
    # Use `tensor()` in order to get a pointer to the tensor.
    output_data = interpreter.get_tensor(output_details[0]['index'])
    print(output_data)


if __name__ == '__main__':
    main()`

**How to get the model:**
I used a library here to get a unet with efficientnetb0 as encoder
https://github.com/qubvel/segmentation_models.
So you can try to use my script to get the model:
`    BACKBONE = 'efficientnetb0'
    BATCH_SIZE = 1
    CLASSES = [""background"", ""target"", ""others""]
    LR = 0.0001
    EPOCHS = 10

    preprocess_input = sm.get_preprocessing(BACKBONE)

    # define network parameters
    n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation
    activation = 'sigmoid' if n_classes == 1 else 'softmax'

    #create model
    model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)`

"
tensorflow/tensorflow,2023-08-21 04:37:48,bug,Check failed when running tensorflow.python.ops.gen_nn_ops.max_pool_grad_with_argmax,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Specific input combination is caused check failure.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import gen_nn_ops
try:
  try:
    with tf.device('/CPU'):
      arg_0_tensor = tf.random.uniform([2, 3, 3, 1], dtype=tf.float32)
      arg_0 = tf.identity(arg_0_tensor)
      arg_1_tensor = tf.random.uniform([2, 2, 2, 1], dtype=tf.float32)
      arg_1 = tf.identity(arg_1_tensor)
      arg_2_tensor = tf.random.uniform([2, 2, 2, 1], minval=-256, maxval=257, dtype=tf.int64)
      arg_2 = tf.identity(arg_2_tensor)
      ksize_0 = 1
      ksize_1 = 2
      ksize_2 = 2
      ksize_3 = 1
      ksize = [ksize_0,ksize_1,ksize_2,ksize_3,]
      strides_0 = 1
      strides_1 = 1
      strides_2 = 1
      strides_3 = 1
      strides = [strides_0,strides_1,strides_2,strides_3,]
      padding = ""VALID""
      include_batch_in_index = False
      out = gen_nn_ops.max_pool_grad_with_argmax(arg_0,arg_1,arg_2,ksize=ksize,strides=strides,padding=padding,include_batch_in_index=include_batch_in_index,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      arg_0 = tf.identity(arg_0_tensor)
      arg_0 = tf.cast(arg_0, tf.float32)
      arg_1 = tf.identity(arg_1_tensor)
      arg_1 = tf.cast(arg_1, tf.float32)
      arg_2 = tf.identity(arg_2_tensor)
      arg_2 = tf.cast(arg_2, tf.int64)
      ksize = [ksize_0,ksize_1,ksize_2,ksize_3,]
      strides = [strides_0,strides_1,strides_2,strides_3,]
      gen_nn_ops.max_pool_grad_with_argmax(arg_0,arg_1,arg_2,ksize=ksize,strides=strides,padding=padding,include_batch_in_index=include_batch_in_index,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-21 00:36:14.553160: F tensorflow/core/kernels/maxpooling_op.cc:1081] Check failed: grad_out_index >= output_start && grad_out_index < output_end Invalid output gradient index: 77, 0, 18
Aborted

```
```
"
tensorflow/tensorflow,2023-08-20 13:40:36,bug,Cannot build tensorflow from source,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

latest

### Custom code

Yes

### OS platform and distribution

Debian 12

### Mobile device

_No response_

### Python version

Python 3.8

### Bazel version

Latest

### GCC/compiler version

Clang 16

### CUDA/cuDNN version

Dont have

### GPU model and memory

Dont have

### Current behavior?

I tried several times, still same error. Searched on google found nothing

### Standalone code to reproduce the issue

```shell
I follow the guide from tensorflow.com but still faced this error. Please help
```


### Relevant log output

```shell
(myenv) root@drowsiness:~/tensorflow# bazel build -j 2 --local_ram_resources=3000 --config=opt --verbose_failures //tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=189
INFO: Reading rc options for 'build' from /root/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /root/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --features=-force_no_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --incompatible_enforce_config_setting_visibility
INFO: Reading rc options for 'build' from /root/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/root/anaconda3/envs/myenv/bin/python3 --action_env PYTHON_LIB_PATH=/root/anaconda3/envs/myenv/lib/python3.8/site-packages --python_path=/root/anaconda3/envs/myenv/bin/python3 --action_env CLANG_COMPILER_PATH=/usr/lib/llvm-16/bin/clang --repo_env=CC=/usr/lib/llvm-16/bin/clang --repo_env=BAZEL_COMPILER=/usr/lib/llvm-16/bin/clang --copt=-Wno-gnu-offsetof-extensions
INFO: Found applicable config definition build:short_logs in file /root/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /root/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:opt in file /root/tensorflow/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare
INFO: Found applicable config definition build:linux in file /root/tensorflow/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --copt=-Wswitch --copt=-Werror=switch --copt=-Wno-error=unused-but-set-variable --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /root/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (648 packages loaded, 42257 targets configured).
INFO: Found 1 target...
INFO: Deleting stale sandbox base /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/sandbox
ERROR: /root/tensorflow/tensorflow/compiler/mlir/tensorflow/BUILD:475:11: Compiling tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc failed: (Killed): clang failed: error executing command (from target //tensorflow/compiler/mlir/tensorflow:tensorflow_ops) 
  (cd /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow && \\
  exec env - \\
    CLANG_COMPILER_PATH=/usr/lib/llvm-16/bin/clang \\
    PATH=/root/.cache/bazelisk/downloads/bazelbuild/bazel-6.1.0-linux-x86_64/bin:/root/anaconda3/envs/myenv/bin:/root/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\
    PWD=/proc/self/cwd \\
    PYTHON_BIN_PATH=/root/anaconda3/envs/myenv/bin/python3 \\
    PYTHON_LIB_PATH=/root/anaconda3/envs/myenv/lib/python3.8/site-packages \\
    TF2_BEHAVIOR=1 \\
  /usr/lib/llvm-16/bin/clang -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -Wunused-but-set-parameter -Wno-free-nonheap-object -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops/tf_ops.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops/tf_ops.pic.o' -fPIC '-DLLVM_ON_UNIX=1' '-DHAVE_BACKTRACE=1' '-DBACKTRACE_HEADER=<execinfo.h>' '-DLTDL_SHLIB_EXT="".so""' '-DLLVM_PLUGIN_EXT="".so""' '-DLLVM_ENABLE_THREADS=1' '-DHAVE_DEREGISTER_FRAME=1' '-DHAVE_LIBPTHREAD=1' '-DHAVE_PTHREAD_GETNAME_NP=1' '-DHAVE_PTHREAD_H=1' '-DHAVE_PTHREAD_SETNAME_NP=1' '-DHAVE_REGISTER_FRAME=1' '-DHAVE_SETENV_R=1' '-DHAVE_STRERROR_R=1' '-DHAVE_SYSEXITS_H=1' '-DHAVE_UNISTD_H=1' -D_GNU_SOURCE '-DHAVE_LINK_H=1' '-DHAVE_MALLINFO=1' '-DHAVE_SBRK=1' '-DHAVE_STRUCT_STAT_ST_MTIM_TV_NSEC=1' '-DLLVM_NATIVE_ARCH=""X86""' '-DLLVM_NATIVE_ASMPARSER=LLVMInitializeX86AsmParser' '-DLLVM_NATIVE_ASMPRINTER=LLVMInitializeX86AsmPrinter' '-DLLVM_NATIVE_DISASSEMBLER=LLVMInitializeX86Disassembler' '-DLLVM_NATIVE_TARGET=LLVMInitializeX86Target' '-DLLVM_NATIVE_TARGETINFO=LLVMInitializeX86TargetInfo' '-DLLVM_NATIVE_TARGETMC=LLVMInitializeX86TargetMC' '-DLLVM_NATIVE_TARGETMCA=LLVMInitializeX86TargetMCA' '-DLLVM_HOST_TRIPLE=""x86_64-unknown-linux-gnu""' '-DLLVM_DEFAULT_TARGET_TRIPLE=""x86_64-unknown-linux-gnu""' '-DLLVM_VERSION_MAJOR=18' '-DLLVM_VERSION_MINOR=0' '-DLLVM_VERSION_PATCH=0' '-DLLVM_VERSION_STRING=""18.0.0git""' -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS '-DBLAKE3_USE_NEON=0' -DBLAKE3_NO_AVX2 -DBLAKE3_NO_AVX512 -DBLAKE3_NO_SSE2 -DBLAKE3_NO_SSE41 -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -DHAVE_SYS_UIO_H -DTF_USE_SNAPPY '-DBAZEL_CURRENT_REPOSITORY=""""' -iquote . -iquote bazel-out/k8-opt/bin -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/llvm-project -iquote bazel-out/k8-opt/bin/external/llvm-project -iquote external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -iquote external/gif -iquote bazel-out/k8-opt/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/k8-opt/bin/external/libjpeg_turbo -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/k8-opt/bin/external/zlib -iquote external/eigen_archive -iquote bazel-out/k8-opt/bin/external/eigen_archive -iquote external/ml_dtypes -iquote bazel-out/k8-opt/bin/external/ml_dtypes -iquote external/double_conversion -iquote bazel-out/k8-opt/bin/external/double_conversion -iquote external/snappy -iquote bazel-out/k8-opt/bin/external/snappy -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/ArithCanonicalizationIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/AsmParserTokenKinds -isystem external/llvm-project/llvm/include -isystem bazel-out/k8-opt/bin/external/llvm-project/llvm/include -isystem external/llvm-project/mlir/include -isystem bazel-out/k8-opt/bin/external/llvm-project/mlir/include -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem third_party/eigen3/mkl_include -isystem bazel-out/k8-opt/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/ml_dtypes -isystem bazel-out/k8-opt/bin/external/ml_dtypes -isystem external/ml_dtypes/ml_dtypes -isystem bazel-out/k8-opt/bin/external/ml_dtypes/ml_dtypes -Wno-all -Wno-extra -Wno-deprecated -Wno-deprecated-declarations -Wno-ignored-attributes -Wno-array-bounds -Wunused-result '-Werror=unused-result' -Wswitch '-Werror=switch' '-Wno-error=unused-but-set-variable' -DAUTOLOAD_DYNAMIC_KERNELS -Wno-gnu-offsetof-extensions -Wno-sign-compare '-std=c++17' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc -o bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops/tf_ops.pic.o)
# Configuration: 4332b06bceb8e99a0d8ed4f75fa26218a779c66acf683ffad0936df1e9f625df
# Execution platform: @local_execution_config_platform//:platform
In file included from tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc:16:
In file included from ./tensorflow/compiler/mlir/tensorflow/ir/tf_ops.h:38:
In file included from ./tensorflow/compiler/mlir/tensorflow/ir/tf_attributes.h:21:
In file included from ./tensorflow/core/ir/types/dialect.h:31:
bazel-out/k8-opt/bin/tensorflow/core/ir/types/dialect.h.inc:31:19: warning: 'parseType' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
     ::mlir::Type parseType(::mlir::DialectAsmParser &parser) const;
                  ^
external/llvm-project/mlir/include/mlir/IR/Dialect.h:107:16: note: overridden virtual function is here
  virtual Type parseType(DialectAsmParser &parser) const;
               ^
In file included from tensorflow/compiler/mlir/tensorflow/ir/tf_ops.cc:16:
In file included from ./tensorflow/compiler/mlir/tensorflow/ir/tf_ops.h:38:
In file included from ./tensorflow/compiler/mlir/tensorflow/ir/tf_attributes.h:21:
In file included from ./tensorflow/core/ir/types/dialect.h:31:
bazel-out/k8-opt/bin/tensorflow/core/ir/types/dialect.h.inc:32:11: warning: 'printType' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
     void printType(::mlir::Type type, ::mlir::DialectAsmPrinter &printer) const;
          ^
external/llvm-project/mlir/include/mlir/IR/Dialect.h:110:16: note: overridden virtual function is here
  virtual void printType(Type, DialectAsmPrinter &) const {
               ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 3990.011s, Critical Path: 343.16s
INFO: 991 processes: 3 internal, 988 local.
FAILED: Build did NOT complete successfully
```
"
tensorflow/tensorflow,2023-08-18 07:31:16,bug,"libtensorflowlite_jni.so (offset 0x2f3000):signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0xa59fdbc0","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

org.tensorflow:tensorflow-lite:0.0.0-nightly org.tensorflow:tensorflow-lite-gpu:2.3.0 org.tensorflow:tensorflow-lite-support:0.1.0

### Custom code

Yes

### OS platform and distribution

Andorid 13

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Our process com.vt.tv.aipq use tensorflow-lite cause process crash:
*** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
Build fingerprint: 'Hisense/songshan-FFM/songshan:11/RTT2.220118.001/00.00.00.40:user/release-keys'
Revision: '1234'
ABI: 'arm'
Timestamp: 2023-05-06 14:36:47+0800
pid: 14794, tid: 28796, name: TFService-T  >>> com.vt.tv.aipq <<<
uid: 1000
signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0xa59fdbc0
    r0  00000004  r1  00000020  r2  00000300  r3  a59fdbc0
    r4  31a05640  r5  000002f0  r6  31a05740  r7  a59fe4c0
    r8  31a056c0  r9  a5674220  r10 a59fe1c0  r11 31a055c0
    ip  a59fdec0  sp  84db73e8  lr  832ded97  pc  832f08ac

backtrace:
      #00 pc 000258ac  /system_ext/app/HiAIPQ/HiAIPQ.apk!libtensorflowlite_jni.so (offset 0x2f3000)

### Standalone code to reproduce the issue

```shell
The Google server background statistics process crash information, unable to clarify the steps to reproduce the problem.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-18 00:54:16,bug,Overflow bug when running tf.image.resize,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large elements in the input list

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  arg_0_tensor = tf.constant(-1000000, shape=[577, 700, 3, 1], dtype=tf.float64,)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1_0 = 1610637938
  arg_1_1 = 1250999896764
  arg_1 = [arg_1_0,arg_1_1,]
  out = tf.image.resize(arg_0,arg_1,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__ResizeBilinear_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 929338090226 with 1164413628, result: -1 [Op:ResizeBilinear] name:
```
```
"
tensorflow/tensorflow,2023-08-18 00:42:33,bug,Overflow when running tf.compat.v1.linalg.diag,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large elements in the input list

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  diagonal_0_0_0_0 = 1111
  diagonal_0_0_0_1 = 1112
  diagonal_0_0_0 = [diagonal_0_0_0_0,diagonal_0_0_0_1,]
  diagonal_0_0_1_0 = 1121
  diagonal_0_0_1_1 = 1122
  diagonal_0_0_1 = [diagonal_0_0_1_0,diagonal_0_0_1_1,]
  diagonal_0_0 = [diagonal_0_0_0,diagonal_0_0_1,]
  diagonal_0_1_0_0 = 1211
  diagonal_0_1_0_1 = 1212
  diagonal_0_1_0 = [diagonal_0_1_0_0,diagonal_0_1_0_1,]
  diagonal_0_1_1_0 = 1221
  diagonal_0_1_1_1 = 1222
  diagonal_0_1_1 = [diagonal_0_1_1_0,diagonal_0_1_1_1,]
  diagonal_0_1 = [diagonal_0_1_0,diagonal_0_1_1,]
  diagonal_0 = [diagonal_0_0,diagonal_0_1,]
  diagonal_1_0_0_0 = 2111
  diagonal_1_0_0_1 = 2112
  diagonal_1_0_0 = [diagonal_1_0_0_0,diagonal_1_0_0_1,]
  diagonal_1_0_1_0 = 2121
  diagonal_1_0_1_1 = 2122
  diagonal_1_0_1 = [diagonal_1_0_1_0,diagonal_1_0_1_1,]
  diagonal_1_0 = [diagonal_1_0_0,diagonal_1_0_1,]
  diagonal_1_1_0_0 = 2211
  diagonal_1_1_0_1 = 2212
  diagonal_1_1_0 = [diagonal_1_1_0_0,diagonal_1_1_0_1,]
  diagonal_1_1_1_0 = 2221
  diagonal_1_1_1_1 = 2222
  diagonal_1_1_1 = [diagonal_1_1_1_0,diagonal_1_1_1_1,]
  diagonal_1_1 = [diagonal_1_1_0,diagonal_1_1_1,]
  diagonal_1 = [diagonal_1_0,diagonal_1_1,]
  diagonal = [diagonal_0,diagonal_1,]
  name = ""diag_part""
  k = 1610637938
  padding_value = 0
  align = ""RIGHT_LEFT""
  out = tf.compat.v1.linalg.diag(diagonal=diagonal,name=name,k=k,padding_value=padding_value,align=align,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 12885103520 with 1610637940, result: -1 [Op:MatrixDiagV3]
```
```
"
tensorflow/tensorflow,2023-08-18 00:34:55,bug,Overflow when running tf.compat.v1.tile,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large elements in the input list

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  input_tensor = tf.random.uniform([370, 1, 1024], dtype=tf.float32)
  input = tf.identity(input_tensor)
  multiples_0 = 125091515651
  multiples_1 = 125091515651
  multiples_2 = 125091515651
  multiples = [multiples_0,multiples_1,multiples_2,]
  name_tensor = tf.random.uniform([], dtype=tf.int32, maxval=66860669291904)
  name = tf.identity(name_tensor)
  name = tf.Variable(name)
  out = tf.compat.v1.tile(input=input,multiples=multiples,name=name,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 46283860790870 with 125091515651, result: -1
	 [[{{node Tile}}]] [Op:Tile]

```
```
"
tensorflow/tensorflow,2023-08-18 00:04:42,bug,Overflow bug when running tf.raw_ops.ResizeNearestNeighbor,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large list element

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  images_tensor = tf.constant(-256, shape=[16, 4, 5, 1], dtype=tf.float16,)
  images = tf.identity(images_tensor)
  size_0 = 1250999896764
  size_1 = 1610637938
  size = [size_0,size_1,]
  align_corners = False
  half_pixel_centers = False
  name = None
  out = tf.raw_ops.ResizeNearestNeighbor(images=images,size=size,align_corners=align_corners,half_pixel_centers=half_pixel_centers,name=name,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__ResizeNearestNeighbor_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 18630618048 with 1610637938, result: -1 [Op:ResizeNearestNeighbor]

```
```
"
tensorflow/tensorflow,2023-08-17 23:57:05,bug,Overflow bug when running tf.keras.layers.ZeroPadding2D,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large list element

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  padding_0_0 = 125091515651
  padding_0_1 = False
  padding_0 = [padding_0_0,padding_0_1,]
  padding_1_0 = 125091515651
  padding_1_1 = 125091515651
  padding_1 = [padding_1_0,padding_1_1,]
  padding = [padding_0,padding_1,]
  arg_class = tf.keras.layers.ZeroPadding2D(padding=padding,)
  arg_input_0_tensor = tf.random.uniform([3, 300, 300, 192], dtype=tf.float32)
  arg_input_0 = tf.identity(arg_input_0_tensor)
  arg_input = [arg_input_0,]
  out = arg_class(*arg_input)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
['{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 2501999793529 with 2501999793530, result: -1\\n', '\\t [[{{node Pad}}]] [Op:Pad]\\n', '\\n', ""Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):\\n"", ' • inputs=tf.Tensor(shape=(1, 1, 2, 2), dtype=float32)\\n']
```
```
"
tensorflow/tensorflow,2023-08-17 23:51:04,bug,Overflow bug when running tf.linalg.diag on colab,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large integer list element

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  diagonal_0_0_0_0 = 1111
  diagonal_0_0_0_1 = 1112
  diagonal_0_0_0 = [diagonal_0_0_0_0,diagonal_0_0_0_1,]
  diagonal_0_0_1_0 = 1121
  diagonal_0_0_1_1 = 1122
  diagonal_0_0_1 = [diagonal_0_0_1_0,diagonal_0_0_1_1,]
  diagonal_0_0 = [diagonal_0_0_0,diagonal_0_0_1,]
  diagonal_0_1_0_0 = 1211
  diagonal_0_1_0_1 = 1212
  diagonal_0_1_0 = [diagonal_0_1_0_0,diagonal_0_1_0_1,]
  diagonal_0_1_1_0 = 1221
  diagonal_0_1_1_1 = 1222
  diagonal_0_1_1 = [diagonal_0_1_1_0,diagonal_0_1_1_1,]
  diagonal_0_1 = [diagonal_0_1_0,diagonal_0_1_1,]
  diagonal_0 = [diagonal_0_0,diagonal_0_1,]
  diagonal_1_0_0_0 = 2111
  diagonal_1_0_0_1 = 2112
  diagonal_1_0_0 = [diagonal_1_0_0_0,diagonal_1_0_0_1,]
  diagonal_1_0_1_0 = 2121
  diagonal_1_0_1_1 = 2122
  diagonal_1_0_1 = [diagonal_1_0_1_0,diagonal_1_0_1_1,]
  diagonal_1_0 = [diagonal_1_0_0,diagonal_1_0_1,]
  diagonal_1_1_0_0 = 2211
  diagonal_1_1_0_1 = 2212
  diagonal_1_1_0 = [diagonal_1_1_0_0,diagonal_1_1_0_1,]
  diagonal_1_1_1_0 = 2221
  diagonal_1_1_1_1 = 2222
  diagonal_1_1_1 = [diagonal_1_1_1_0,diagonal_1_1_1_1,]
  diagonal_1_1 = [diagonal_1_1_0,diagonal_1_1_1,]
  diagonal_1 = [diagonal_1_0,diagonal_1_1,]
  diagonal = [diagonal_0,diagonal_1,]
  name = ""None""
  k = -92233720368
  padding_value = 0
  align = ""RIGHT_LEFT""
  out = tf.linalg.diag(diagonal=diagonal,name=name,k=k,padding_value=padding_value,align=align,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 16315257232 with 2039407154, result: -1 [Op:MatrixDiagV3]
```
```
"
tensorflow/tensorflow,2023-08-17 23:23:57,bug,Overflow bug when running tf.clip_by_value on colab,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large tensor 

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  arg_0_tensor = tf.random.uniform([2, 472, 496, 4, 1, 1024], dtype=tf.float64)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1 = 0
  arg_2 = False
  out = tf.clip_by_value(arg_0,arg_1,arg_2,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""2023-08-17T21:55:14.593Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""2023-08-17T21:55:14.598Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.594 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T21:55:14.600Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.601 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""2023-08-17T21:55:14.603Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T21:55:14.603Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""2023-08-17T21:55:14.604Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.604 NotebookApp] Looking for jupyter_notebook_config in /etc/jupyter"",""time"":""2023-08-17T21:55:14.605Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.604 NotebookApp] Loaded config file: /etc/jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T21:55:14.608Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.605 NotebookApp] Looking for jupyter_notebook_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T21:55:14.608Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.597 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""2023-08-17T21:55:14.598Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.609 NotebookApp] Loaded config file: /usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:14.610Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.610 NotebookApp] Looking for jupyter_notebook_config in /usr/etc/jupyter"",""time"":""2023-08-17T21:55:14.611Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.610 NotebookApp] Looking for jupyter_notebook_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T21:55:14.611Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.610 NotebookApp] Looking for jupyter_notebook_config in /root/.jupyter"",""time"":""2023-08-17T21:55:14.611Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.612 NotebookApp] Loaded config file: /root/.jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T21:55:14.613Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.597 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""2023-08-17T21:55:14.599Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.597 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T21:55:14.601Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.598 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""2023-08-17T21:55:14.601Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.598 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T21:55:14.602Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.598 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""2023-08-17T21:55:14.602Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.599 NotebookApp] Looking for jupyter_notebook_config in /etc/jupyter"",""time"":""2023-08-17T21:55:14.610Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.600 NotebookApp] Loaded config file: /etc/jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T21:55:14.612Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.601 NotebookApp] Looking for jupyter_notebook_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T21:55:14.612Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.603 NotebookApp] Loaded config file: /usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:14.612Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.603 NotebookApp] Looking for jupyter_notebook_config in /usr/etc/jupyter"",""time"":""2023-08-17T21:55:14.613Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.603 NotebookApp] Looking for jupyter_notebook_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T21:55:14.614Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.603 NotebookApp] Looking for jupyter_notebook_config in /root/.jupyter"",""time"":""2023-08-17T21:55:14.614Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.606 NotebookApp] Loaded config file: /root/.jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T21:55:14.614Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.051Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json"",""time"":""2023-08-17T21:55:15.056Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.056Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.059Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.060Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.061Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret"",""time"":""2023-08-17T21:55:15.074Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Authentication of /metrics is OFF, since other authentication is disabled."",""time"":""2023-08-17T21:55:15.076Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""google.colab serverextension initialized."",""time"":""2023-08-17T21:55:15.159Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.173Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json"",""time"":""2023-08-17T21:55:15.175Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.177Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.179Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.180Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T21:55:15.183Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret"",""time"":""2023-08-17T21:55:15.192Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Authentication of /metrics is OFF, since other authentication is disabled."",""time"":""2023-08-17T21:55:15.193Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""google.colab serverextension initialized."",""time"":""2023-08-17T21:55:15.213Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Serving notebooks from local directory: /"",""time"":""2023-08-17T21:55:19.313Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Serving notebooks from local directory: /"",""time"":""2023-08-17T21:55:19.314Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Jupyter Notebook 6.5.5 is running at:"",""time"":""2023-08-17T21:55:19.314Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""http://172.28.0.2:9000/"",""time"":""2023-08-17T21:55:19.314Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Use Control-C to stop this server and shut down all kernels (twice to skip confirmation)."",""time"":""2023-08-17T21:55:19.315Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Jupyter Notebook 6.5.5 is running at:"",""time"":""2023-08-17T21:55:19.314Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""http://172.28.0.12:9000/"",""time"":""2023-08-17T21:55:19.316Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Use Control-C to stop this server and shut down all kernels (twice to skip confirmation)."",""time"":""2023-08-17T21:55:19.316Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Kernel started: 92d4365c-be07-4243-a024-4094c7317470, name: python3"",""time"":""2023-08-17T21:55:37.205Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""Got events for closed stream <zmq.eventloop.zmqstream.ZMQStream object at 0x79d03bf475b0>"",""time"":""2023-08-17T21:55:52.871Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 21:55:56.928312: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T21:55:56.928Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T21:55:56.928Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 21:55:58.601992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T21:55:58.602Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 21:56:04.276761: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at tile_ops.cc:193 : INVALID_ARGUMENT: Encountered overflow when multiplying 500366062604 with 125091515651, result: -1"",""time"":""2023-08-17T21:56:04.276Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""Task exception was never retrieved"",""time"":""2023-08-17T22:10:59.200Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""future: <Task finished name='Task-35' coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /usr/local/lib/python3.10/dist-packages/tornado/websocket.py:1085> exception=WebSocketClosedError()>"",""time"":""2023-08-17T22:10:59.200Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""Traceback (most recent call last):"",""time"":""2023-08-17T22:10:59.200Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""  File \\""/usr/local/lib/python3.10/dist-packages/tornado/websocket.py\\"", line 1087, in wrapper"",""time"":""2023-08-17T22:10:59.200Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    await fut"",""time"":""2023-08-17T22:10:59.200Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""tornado.iostream.StreamClosedError: Stream is closed"",""time"":""2023-08-17T22:10:59.200Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""During handling of the above exception, another exception occurred:"",""time"":""2023-08-17T22:10:59.200Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""Traceback (most recent call last):"",""time"":""2023-08-17T22:10:59.201Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""  File \\""/usr/lib/python3.10/asyncio/tasks.py\\"", line 232, in __step"",""time"":""2023-08-17T22:10:59.201Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    result = coro.send(None)"",""time"":""2023-08-17T22:10:59.201Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""  File \\""/usr/local/lib/python3.10/dist-packages/tornado/websocket.py\\"", line 1089, in wrapper"",""time"":""2023-08-17T22:10:59.201Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    raise WebSocketClosedError()"",""time"":""2023-08-17T22:10:59.201Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""tornado.websocket.WebSocketClosedError"",""time"":""2023-08-17T22:10:59.201Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""Got events for closed stream <zmq.eventloop.zmqstream.ZMQStream object at 0x79d03bffc0d0>"",""time"":""2023-08-17T23:11:18.034Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 23:17:17.631931: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 19327655268 exceeds 10% of free system memory."",""time"":""2023-08-17T23:17:17.634Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T23:17:28.209Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 92d4365c-be07-4243-a024-4094c7317470 restarted"",""time"":""2023-08-17T23:17:28.209Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 23:19:54.827450: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T23:19:54.827Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T23:19:54.827Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 23:19:58.360271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T23:19:58.360Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 23:20:03.457377: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 15342764032 exceeds 10% of free system memory."",""time"":""2023-08-17T23:20:03.457Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T23:20:40.231Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 92d4365c-be07-4243-a024-4094c7317470 restarted"",""time"":""2023-08-17T23:20:40.234Z"",""v"":0}
```
```
"
tensorflow/tensorflow,2023-08-17 22:03:19,bug,Overflow when running tf.raw_ops.PadV2,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to the large list of element

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  input_tensor = tf.random.uniform([16, 4, 4, 512], dtype=tf.float32)
  input = tf.identity(input_tensor)
  paddings_0_0 = 125091515651
  paddings_0_1 = 125091515651
  paddings_0 = [paddings_0_0,paddings_0_1,]
  paddings_1_0 = 125091515651
  paddings_1_1 = 125091515651
  paddings_1 = [paddings_1_0,paddings_1_1,]
  paddings_2_0 = 125091515651
  paddings_2_1 = 125091515651
  paddings_2 = [paddings_2_0,paddings_2_1,]
  paddings_3_0 = 125091515651
  paddings_3_1 = 125091515651
  paddings_3 = [paddings_3_0,paddings_3_1,]
  paddings = [paddings_0,paddings_1,paddings_2,paddings_3,]
  constant_values = 0
  name = None
  out = tf.raw_ops.PadV2(input=input,paddings=paddings,constant_values=constant_values,name=name,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__PadV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 250183031318 with 250183031306, result: -1
	 [[{{node PadV2}}]] [Op:PadV2]

```
```
"
tensorflow/tensorflow,2023-08-17 21:58:34,bug,Overflow when running tf.image.pad_to_bounding_box on colab,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large list element

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  arg_0_0_0_0 = 1.0
  arg_0_0_0_1 = 2.0
  arg_0_0_0_2 = 3.0
  arg_0_0_0 = [arg_0_0_0_0,arg_0_0_0_1,arg_0_0_0_2,]
  arg_0_0_1_0 = 4.0
  arg_0_0_1_1 = 5.0
  arg_0_0_1_2 = 6.0
  arg_0_0_1 = [arg_0_0_1_0,arg_0_0_1_1,arg_0_0_1_2,]
  arg_0_0 = [arg_0_0_0,arg_0_0_1,]
  arg_0_1_0_0 = 7.0
  arg_0_1_0_1 = 8.0
  arg_0_1_0_2 = 9.0
  arg_0_1_0 = [arg_0_1_0_0,arg_0_1_0_1,arg_0_1_0_2,]
  arg_0_1_1_0 = 10.0
  arg_0_1_1_1 = 11.0
  arg_0_1_1_2 = 12.0
  arg_0_1_1 = [arg_0_1_1_0,arg_0_1_1_1,arg_0_1_1_2,]
  arg_0_1 = [arg_0_1_0,arg_0_1_1,]
  arg_0 = [arg_0_0,arg_0_1,]
  arg_1 = 1
  arg_2 = 1
  arg_3 = 4
  arg_4 = 1676240524292489355
  out = tf.image.pad_to_bounding_box(arg_0,arg_1,arg_2,arg_3,arg_4,)
except Exception as e:
  print(""Error:""+str(e))

```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 6704962097169957420 with 3, result: -1
	 [[{{node Pad}}]] [Op:Pad] name: 

```
```
"
tensorflow/tensorflow,2023-08-17 21:53:16,bug,Overflow when running tf.keras.layers.ZeroPadding2D,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large list elements

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  padding_0_0 = 125091515651
  padding_0_1 = False
  padding_0 = [padding_0_0,padding_0_1,]
  padding_1_0 = 125091515651
  padding_1_1 = 125091515651
  padding_1 = [padding_1_0,padding_1_1,]
  padding = [padding_0,padding_1,]
  arg_class = tf.keras.layers.ZeroPadding2D(padding=padding,)
  arg_input_0_tensor = tf.random.uniform([3, 300, 300, 192], dtype=tf.float32)
  arg_input_0 = tf.identity(arg_input_0_tensor)
  arg_input = [arg_input_0,]
  out = arg_class(*arg_input)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:Exception encountered when calling layer 'zero_padding2d' (type ZeroPadding2D).

{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 375274547853 with 250183031602, result: -1
	 [[{{node Pad}}]] [Op:Pad]

Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):
  • inputs=tf.Tensor(shape=(3, 300, 300, 192), dtype=float32)
{}

```
```
"
tensorflow/tensorflow,2023-08-17 18:47:06,bug,Overflow bug when running tf.pad on colab,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large input tensor

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
try:
  try:
    with tf.device('/CPU'):
      arg_0_tensor = tf.random.uniform([12, 2, 256, 513], dtype=tf.float32)
      arg_0 = tf.identity(arg_0_tensor)
      arg_1_tensor = tf.random.uniform([4, 2], dtype=tf.int32, maxval=54676034958255)
      arg_1 = tf.identity(arg_1_tensor)
      out = tf.pad(arg_0,arg_1,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      arg_0 = tf.identity(arg_0_tensor)
      arg_0 = tf.cast(arg_0, tf.float32)
      arg_1 = tf.identity(arg_1_tensor)
      arg_1 = tf.cast(arg_1, tf.int32)
      tf.pad(arg_0,arg_1,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 2206572623628733836 with 75929941, result: -1 [Op:Pad] name: 
Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 2206572623628733836 with 75929941, result: -1 [Op:Pad] name
```
```
"
tensorflow/tensorflow,2023-08-17 15:55:59,bug,"Cannot type ""I Accept"" to extract from hexagon_nn_skel","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

hexagon_nn_skel_v1.20.0.1

### Custom code

No

### OS platform and distribution

Android

### Mobile device

Android

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Same as here https://github.com/tensorflow/tensorflow/issues/61378, running the ./tflite_hexagon_nn_skel_v1.20.0.1.run instantly prints:
```
license. Extraction aborted.
./extract.sh[5]: read: -p: no coprocess
Aborting extraction.. Done
```
Without giving time to write ""I ACCEPT"".
Neither does --accept option work.


### Standalone code to reproduce the issue

```shell
adb push tflite_hexagon_nn_skel_v1.20.0.1.run /data/local/tmp
adb shell
cd /data/local/tmp
chmod +x tflite_hexagon_nn_skel_v1.20.0.1.run
./tflite_hexagon_nn_skel_v1.20.0.1.run [--accept]
```


### Relevant log output

```shell
...
Limited or its designated affiliate. LICENSEE shall be solely responsible to
obtain such separate license from Apical Limited. The provision or license of a
PKLA Product Kit to LICENSEE does not convey any license or other right under
any patents of QUALCOMM Incorporated or SnapTrack, Inc.


Type ""I ACCEPT"" if you agree to the terms of the license: You didn't accept the
license. Extraction aborted.
./extract.sh[5]: read: -p: no coprocess
Aborting extraction.. Done
HNNTH:/data/local/tmp $
```
"
tensorflow/tensorflow,2023-08-17 14:57:29,bug,Crash when running tf.compat.v1.keras.layers.MaxPool2D on colab,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Due to large elements in input lists

### Standalone code to reproduce the issue

```shell
results = dict()
import tensorflow as tf
import os
import numpy as np
try:
  pool_size_0 = 1e+38
  pool_size_1 = 1048576
  pool_size = [pool_size_0,pool_size_1,]
  strides_0 = 2
  strides_1 = 2
  strides = [strides_0,strides_1,]
  padding = ""same""
  data_format = None
  arg_class = tf.compat.v1.keras.layers.MaxPool2D(pool_size=pool_size,strides=strides,padding=padding,data_format=data_format,)
  arg_input_0_tensor = tf.random.uniform([3, 74, 74, 256], dtype=tf.float32)
  arg_input_0 = tf.identity(arg_input_0_tensor)
  arg_input = [arg_input_0,]
  out = arg_class(*arg_input)
except Exception as e:
  print(""Error:""+str(e))

print(results)
```
```


### Relevant log output

```shell
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""2023-08-17T14:24:43.838Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""2023-08-17T14:24:43.846Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:43.847Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:43.848Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:43.848Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""2023-08-17T14:24:43.850Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.843 NotebookApp] Looking for jupyter_notebook_config in /etc/jupyter"",""time"":""2023-08-17T14:24:43.850Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.847 NotebookApp] Loaded config file: /etc/jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:43.854Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.847 NotebookApp] Looking for jupyter_notebook_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:43.855Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Loaded config file: /usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:43.855Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Looking for jupyter_notebook_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:43.862Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Looking for jupyter_notebook_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:43.863Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Looking for jupyter_notebook_config in /root/.jupyter"",""time"":""2023-08-17T14:24:43.864Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.857 NotebookApp] Loaded config file: /root/.jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:43.865Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.049 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""2023-08-17T14:24:44.050Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""2023-08-17T14:24:44.056Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.059 NotebookApp] Looking for jupyter_notebook_config in /etc/jupyter"",""time"":""2023-08-17T14:24:44.065Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.059 NotebookApp] Loaded config file: /etc/jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Loaded config file: /usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:44.067Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /root/.jupyter"",""time"":""2023-08-17T14:24:44.067Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.061 NotebookApp] Loaded config file: /root/.jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:44.067Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.713Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json"",""time"":""2023-08-17T14:24:44.715Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.715Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.717Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.719Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.723Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret"",""time"":""2023-08-17T14:24:44.743Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Authentication of /metrics is OFF, since other authentication is disabled."",""time"":""2023-08-17T14:24:44.745Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""google.colab serverextension initialized."",""time"":""2023-08-17T14:24:44.800Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.806Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json"",""time"":""2023-08-17T14:24:44.808Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.808Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.809Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.810Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.811Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret"",""time"":""2023-08-17T14:24:44.831Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Authentication of /metrics is OFF, since other authentication is disabled."",""time"":""2023-08-17T14:24:44.831Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""google.colab serverextension initialized."",""time"":""2023-08-17T14:24:44.856Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Serving notebooks from local directory: /"",""time"":""2023-08-17T14:24:49.405Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Jupyter Notebook 6.4.8 is running at:"",""time"":""2023-08-17T14:24:49.405Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""http://172.28.0.12:9000/"",""time"":""2023-08-17T14:24:49.406Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Use Control-C to stop this server and shut down all kernels (twice to skip confirmation)."",""time"":""2023-08-17T14:24:49.406Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Serving notebooks from local directory: /"",""time"":""2023-08-17T14:24:49.430Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Jupyter Notebook 6.4.8 is running at:"",""time"":""2023-08-17T14:24:49.431Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""http://172.28.0.2:9000/"",""time"":""2023-08-17T14:24:49.432Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Use Control-C to stop this server and shut down all kernels (twice to skip confirmation)."",""time"":""2023-08-17T14:24:49.432Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Kernel started: 5b91d383-2a5d-4d17-8f8d-5f59277ecb11, name: python3"",""time"":""2023-08-17T14:26:06.571Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:29.531813: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:26:29.531Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:26:29.532Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:32.617224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:26:32.617Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.113889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.114Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.787982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.788Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.788362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.788Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.803571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.803Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.803974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.804Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.804329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.804Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000771: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.077428: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750902 exceeds 10% of free system memory."",""time"":""2023-08-17T14:26:40.077Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:42.860963: F tensorflow/core/framework/tensor_shape.cc:587] Check failed: size >= 0 (0 vs. -1248091845)"",""time"":""2023-08-17T14:26:42.861Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:26:45.571Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:26:45.573Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:36.094812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:27:36.100Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:27:36.101Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:37.142240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:27:37.142Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.764145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.764Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.816688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.816Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.826117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.828Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.831423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.831Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.832476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.832Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.833383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.833Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.665264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:43.665Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.667057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:43.667Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.668052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:43.668Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.668828: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:27:43.668Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.669432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:27:43.669Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.701398: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750902 exceeds 10% of free system memory."",""time"":""2023-08-17T14:27:43.701Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:48.308263: F tensorflow/core/framework/tensor_shape.cc:587] Check failed: size >= 0 (0 vs. -1248091845)"",""time"":""2023-08-17T14:27:48.308Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:27:51.576Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:27:51.576Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:09.645133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:31:09.645Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:31:09.646Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:10.714033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:31:10.714Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.844776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.844Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.892144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.892Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.894009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.894Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.896074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.896Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.897012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.897Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.897897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.897Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.331805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:14.332Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332751: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:18.149537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900"",""time"":""2023-08-17T14:31:18.149Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:18.151181: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:959] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)"",""time"":""2023-08-17T14:31:18.151Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:31:18.580Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:31:18.581Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:32:58.023248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:32:58.024Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:32:58.024Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:33:00.925573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:33:00.925Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.817441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.817Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.920819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.920Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.921484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.921Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.923040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.923Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.923548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.923Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.924029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.924Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.323413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:24.323Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:24.324Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:24.324Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324522: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:34:24.325Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:34:24.325Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:29.102979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900"",""time"":""2023-08-17T14:34:29.103Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:29.104423: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:959] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)"",""time"":""2023-08-17T14:34:29.104Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:34:30.587Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:34:30.587Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:39.499788: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:34:39.500Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:34:39.500Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:41.797362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:34:41.797Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Kernel restarted: 5b91d383-2a5d-4d17-8f8d-5f59277ecb11"",""time"":""2023-08-17T14:34:51.616Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:59.388548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:34:59.392Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:34:59.392Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:35:01.250311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:35:01.250Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.143899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.144Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.181829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.182Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.182572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.182Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.184389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.184Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.184737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.185Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.185055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.185Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.232416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:07.232Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.232868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.233157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.233367: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.233419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13692 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.261994: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at matrix_diag_op.cc:273 : INVALID_ARGUMENT: Encountered overflow when multiplying 12884901888 with 1610612736, result: -1"",""time"":""2023-08-17T14:36:07.262Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:57.056526: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750902 exceeds 10% of free system memory."",""time"":""2023-08-17T14:36:57.056Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:37:03.543980: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at matrix_diag_op.cc:273 : INVALID_ARGUMENT: Encountered overflow when multiplying 3046875451 with 3046875451, result: -9163294059803098215"",""time"":""2023-08-17T14:37:03.544Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:37:04.268280: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750784 exceeds 10% of free system memory."",""time"":""2023-08-17T14:37:04.268Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:37:08.172313: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at matrix_diag_op.cc:273 : INVALID_ARGUMENT: Encountered overflow when multiplying 3046875392 with 3046875392, result: -9163294419334397952"",""time"":""2023-08-17T14:37:08.172Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:38:16.953443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900"",""time"":""2023-08-17T14:38:16.953Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:38:16.953795: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:983] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)"",""time"":""2023-08-17T14:38:16.954Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:38:18.617Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:38:18.617Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:41:46.795637: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:41:46.795Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:41:46.795Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:41:47.897333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:41:47.897Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:41:50.174067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:41:50.174Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:41:50.217161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:41:50.217Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:41:50.217535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:41:50.217Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:15.973272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:53:15.973Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:15.977064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:53:15.977Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:15.977438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:53:15.977Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:17.404160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:53:17.404Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:17.405355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:53:17.405Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:17.406091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:53:17.406Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:17.406821: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:53:17.406Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:17.407403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13692 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:53:17.407Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:53:17.447492: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at matrix_diag_op.cc:273 : INVALID_ARGUMENT: Encountered overflow when multiplying 9984734776 with 1248091847, result: -5984878005326580344"",""time"":""2023-08-17T14:53:17.447Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:56:00.832626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900"",""time"":""2023-08-17T14:56:00.832Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:56:00.832804: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:983] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)"",""time"":""2023-08-17T14:56:00.833Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:56:03.623Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:56:03.623Z"",""v"":0}
```
```
"
tensorflow/tensorflow,2023-08-17 14:44:21,bug,Crash when running tf.keras.layers.MaxPooling2D,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"" UBUNTU_CODENAME=jammy

### Mobile device

_No response_

### Python version

  3.10.12 (main, Jun 11 2023, 05:26:28) 

### Bazel version

_No response_

### GCC/compiler version

[GCC 11.4.0]

### CUDA/cuDNN version

nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0

### GPU model and memory

T4

### Current behavior?

Due to the large list of elements

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
try:
  arg_0_0 = 1e+20
  arg_0_1 = True
  arg_0 = [arg_0_0,arg_0_1,]
  strides_0 = 2
  strides_1 = 2
  strides = [strides_0,strides_1,]
  arg_class = tf.keras.layers.MaxPooling2D(arg_0,strides=strides,)
  arg_input_0_tensor = tf.random.uniform([2, 17, 17, 768], dtype=tf.float32)
  arg_input_0 = tf.identity(arg_input_0_tensor)
  arg_input = [arg_input_0,]
  out = arg_class(*arg_input)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""2023-08-17T14:24:43.838Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""2023-08-17T14:24:43.846Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:43.847Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:43.848Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:43.848Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""2023-08-17T14:24:43.850Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.843 NotebookApp] Looking for jupyter_notebook_config in /etc/jupyter"",""time"":""2023-08-17T14:24:43.850Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.847 NotebookApp] Loaded config file: /etc/jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:43.854Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.847 NotebookApp] Looking for jupyter_notebook_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:43.855Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Loaded config file: /usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:43.855Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Looking for jupyter_notebook_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:43.862Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Looking for jupyter_notebook_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:43.863Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.849 NotebookApp] Looking for jupyter_notebook_config in /root/.jupyter"",""time"":""2023-08-17T14:24:43.864Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.857 NotebookApp] Loaded config file: /root/.jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:43.865Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.049 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""2023-08-17T14:24:44.050Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""2023-08-17T14:24:44.056Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.056 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""2023-08-17T14:24:44.057Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.059 NotebookApp] Looking for jupyter_notebook_config in /etc/jupyter"",""time"":""2023-08-17T14:24:44.065Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.059 NotebookApp] Loaded config file: /etc/jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /usr/local/etc/jupyter"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Loaded config file: /usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /usr/etc/jupyter"",""time"":""2023-08-17T14:24:44.066Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /root/.local/etc/jupyter"",""time"":""2023-08-17T14:24:44.067Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.060 NotebookApp] Looking for jupyter_notebook_config in /root/.jupyter"",""time"":""2023-08-17T14:24:44.067Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:44.061 NotebookApp] Loaded config file: /root/.jupyter/jupyter_notebook_config.py"",""time"":""2023-08-17T14:24:44.067Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.713Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json"",""time"":""2023-08-17T14:24:44.715Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.715Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.717Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.719Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.723Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret"",""time"":""2023-08-17T14:24:44.743Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Authentication of /metrics is OFF, since other authentication is disabled."",""time"":""2023-08-17T14:24:44.745Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""google.colab serverextension initialized."",""time"":""2023-08-17T14:24:44.800Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.806Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json"",""time"":""2023-08-17T14:24:44.808Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.808Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/usr/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.809Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.local/etc/jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.810Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""    \\t/root/.jupyter/jupyter_notebook_config.json"",""time"":""2023-08-17T14:24:44.811Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret"",""time"":""2023-08-17T14:24:44.831Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Authentication of /metrics is OFF, since other authentication is disabled."",""time"":""2023-08-17T14:24:44.831Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""google.colab serverextension initialized."",""time"":""2023-08-17T14:24:44.856Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Serving notebooks from local directory: /"",""time"":""2023-08-17T14:24:49.405Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Jupyter Notebook 6.4.8 is running at:"",""time"":""2023-08-17T14:24:49.405Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""http://172.28.0.12:9000/"",""time"":""2023-08-17T14:24:49.406Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Use Control-C to stop this server and shut down all kernels (twice to skip confirmation)."",""time"":""2023-08-17T14:24:49.406Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Serving notebooks from local directory: /"",""time"":""2023-08-17T14:24:49.430Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Jupyter Notebook 6.4.8 is running at:"",""time"":""2023-08-17T14:24:49.431Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""http://172.28.0.2:9000/"",""time"":""2023-08-17T14:24:49.432Z"",""v"":0}
{""pid"":6,""type"":""jupyter"",""level"":30,""msg"":""Use Control-C to stop this server and shut down all kernels (twice to skip confirmation)."",""time"":""2023-08-17T14:24:49.432Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Kernel started: 5b91d383-2a5d-4d17-8f8d-5f59277ecb11, name: python3"",""time"":""2023-08-17T14:26:06.571Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:29.531813: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:26:29.531Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:26:29.532Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:32.617224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:26:32.617Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.113889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.114Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.787982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.788Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.788362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.788Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.803571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.803Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.803974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.804Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:36.804329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:36.804Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000771: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.000816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:26:40.001Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:40.077428: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750902 exceeds 10% of free system memory."",""time"":""2023-08-17T14:26:40.077Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:26:42.860963: F tensorflow/core/framework/tensor_shape.cc:587] Check failed: size >= 0 (0 vs. -1248091845)"",""time"":""2023-08-17T14:26:42.861Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:26:45.571Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:26:45.573Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:36.094812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:27:36.100Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:27:36.101Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:37.142240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:27:37.142Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.764145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.764Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.816688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.816Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.826117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.828Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.831423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.831Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.832476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.832Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:41.833383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:41.833Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.665264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:43.665Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.667057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:43.667Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.668052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:27:43.668Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.668828: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:27:43.668Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.669432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:27:43.669Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:43.701398: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750902 exceeds 10% of free system memory."",""time"":""2023-08-17T14:27:43.701Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:27:48.308263: F tensorflow/core/framework/tensor_shape.cc:587] Check failed: size >= 0 (0 vs. -1248091845)"",""time"":""2023-08-17T14:27:48.308Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:27:51.576Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:27:51.576Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:09.645133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:31:09.645Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:31:09.646Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:10.714033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:31:10.714Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.844776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.844Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.892144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.892Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.894009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.894Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.896074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.896Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.897012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.897Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:12.897897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:12.897Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.331805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:14.332Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332751: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:14.332800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:31:14.333Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:18.149537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900"",""time"":""2023-08-17T14:31:18.149Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:31:18.151181: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:959] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)"",""time"":""2023-08-17T14:31:18.151Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:31:18.580Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:31:18.581Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:32:58.023248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:32:58.024Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:32:58.024Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:33:00.925573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:33:00.925Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.817441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.817Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.920819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.920Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.921484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.921Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.923040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.923Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.923548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.923Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:22.924029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:22.924Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.323413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:24.323Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:24.324Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:34:24.324Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324522: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:34:24.325Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:24.324601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13664 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:34:24.325Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:29.102979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900"",""time"":""2023-08-17T14:34:29.103Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:29.104423: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:959] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)"",""time"":""2023-08-17T14:34:29.104Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:34:30.587Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:34:30.587Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:39.499788: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:34:39.500Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:34:39.500Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:41.797362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:34:41.797Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""Kernel restarted: 5b91d383-2a5d-4d17-8f8d-5f59277ecb11"",""time"":""2023-08-17T14:34:51.616Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:34:59.388548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations."",""time"":""2023-08-17T14:34:59.392Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags."",""time"":""2023-08-17T14:34:59.392Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:35:01.250311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"",""time"":""2023-08-17T14:35:01.250Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.143899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.144Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.181829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.182Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.182572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.182Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.184389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.184Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.184737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.185Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:06.185055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:06.185Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.232416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:07.232Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.232868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.233157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355"",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.233367: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0."",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.233419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13692 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5"",""time"":""2023-08-17T14:36:07.233Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:07.261994: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at matrix_diag_op.cc:273 : INVALID_ARGUMENT: Encountered overflow when multiplying 12884901888 with 1610612736, result: -1"",""time"":""2023-08-17T14:36:07.262Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:36:57.056526: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750902 exceeds 10% of free system memory."",""time"":""2023-08-17T14:36:57.056Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:37:03.543980: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at matrix_diag_op.cc:273 : INVALID_ARGUMENT: Encountered overflow when multiplying 3046875451 with 3046875451, result: -9163294059803098215"",""time"":""2023-08-17T14:37:03.544Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:37:04.268280: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6093750784 exceeds 10% of free system memory."",""time"":""2023-08-17T14:37:04.268Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:37:08.172313: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at matrix_diag_op.cc:273 : INVALID_ARGUMENT: Encountered overflow when multiplying 3046875392 with 3046875392, result: -9163294419334397952"",""time"":""2023-08-17T14:37:08.172Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:38:16.953443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900"",""time"":""2023-08-17T14:38:16.953Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""2023-08-17 14:38:16.953795: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:983] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)"",""time"":""2023-08-17T14:38:16.954Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":30,""msg"":""KernelRestarter: restarting kernel (1/5), keep random ports"",""time"":""2023-08-17T14:38:18.617Z"",""v"":0}
{""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""WARNING:root:kernel 5b91d383-2a5d-4d17-8f8d-5f59277ecb11 restarted"",""time"":""2023-08-17T14:38:18.617Z"",""v"":0}
```
```
"
tensorflow/tensorflow,2023-08-17 14:20:37,bug,Integer overflow when running tf.experimental.numpy.identity,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"" UBUNTU_CODENAME=jammy

### Mobile device

_No response_

### Python version

3.10.12 (main, Jun 11 2023, 05:26:28)

### Bazel version

_No response_

### GCC/compiler version

[GCC 11.4.0]

### CUDA/cuDNN version

[nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0](nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0)

### GPU model and memory

T4

### Current behavior?

Due to large integer variable

### Standalone code to reproduce the issue

```shell
results = dict()
import tensorflow as tf
import numpy as np
try:
  try:
    with tf.device('/CPU'):
      n_tensor = 3046875451 
      n = tf.identity(n_tensor)
      dtype = tf.uint16
      out = tf.experimental.numpy.identity(n=n,dtype=dtype,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      n = tf.identity(n_tensor)
      n = tf.cast(n, tf.complex64)
      dtype = tf.uint16
      tf.experimental.numpy.identity(n=n,dtype=dtype,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))

print(results)
```
```


### Relevant log output

```shell
Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 3046875451 with 3046875451, result: -9163294059803098215 [Op:MatrixDiagV3] name: diag

/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py:1035: ComplexWarning: Casting complex values to real discards the imaginary part
  return int(self._numpy())

Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 3046875392 with 3046875392, result: -9163294419334397952 [Op:MatrixDiagV3] name: diag
{}


```
```
"
tensorflow/tensorflow,2023-08-17 01:59:06,bug,Could not find a version that satisfies the requirement tensorflow-compression~=2.12.0 (from versions: none),"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

fail

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.9.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I try to pip intsall tensorflow-federated it fail, so i build it on source, i pip install --requirement ""requirements.txt"" then happened this error. can i know how to solve this problem?

### Standalone code to reproduce the issue

```shell
-
```


### Relevant log output

```shell
ERROR: Could not find a version that satisfies the requirement tensorflow-compression~=2.12.0 (from versions: none)
ERROR: No matching distribution found for tensorflow-compression~=2.12.0
```
"
tensorflow/tensorflow,2023-08-16 00:27:17,bug,Train Simple Audio Recognition - TinyML,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.12.0

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

**Issue Report** - Error in Training Audio Recognition Model

**Description**:

I am trying to train a simple audio recognition model as described in the book ""TinyML."" I am using Google Colab to train the model. However, I encountered errors during both the installation of dependencies and the training process.

**Error during Install Dependencies**:

When attempting to install dependencies using the command 

!pip uninstall -y tensorflow tensorflow_estimator tensorboard
!pip install -q tf-estimator-nightly==1.14.0.dev2019072901 tf-nightly-gpu==1.15.0.dev20190729

 I encountered the following error:


ERROR: Could not find a version that satisfies the requirement tf-nightly-gpu==1.15.0.dev20190729 (from versions: 2.12.0)
ERROR: No matching distribution found for tf-nightly-gpu==1.15.0.dev20190729
Error during Training - ModuleNotFoundError:

**Error to Begin Training**:

Upon running the training script with TensorFlow in the ""Begin Training"" Section, I received the following error:

Traceback (most recent call last):
  File ""/content/tensorflow/tensorflow/examples/speech_commands/train.py"", line 81, in <module>
    import input_data
  File ""/content/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 35, in <module>
    from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio
ModuleNotFoundError: No module named 'tensorflow.contrib'


**Observations**:

I suspect that these errors are occurring because the code provided in the book is intended for TensorFlow 1.15, while I am using TensorFlow 2.12.0. Since TensorFlow 1.15 is no longer supported. Not sure how I can resolve this. Please help me to fix this issue.

### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/1t2QMMiCdIxP3xnoNyiz9FjmPmbrF0_iD?usp=sharing
```


### Relevant log output

```shell
ERROR: Could not find a version that satisfies the requirement tf-nightly-gpu==1.15.0.dev20190729 (from versions: 2.12.0)
ERROR: No matching distribution found for tf-nightly-gpu==1.15.0.dev20190729





Traceback (most recent call last):
  File ""/content/tensorflow/tensorflow/examples/speech_commands/train.py"", line 81, in <module>
    import input_data
  File ""/content/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 35, in <module>
    from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio
ModuleNotFoundError: No module named 'tensorflow.contrib'
```
"
tensorflow/tensorflow,2023-08-15 02:05:49,bug,Crash when running tensorflow.python.ops.nn_ops.fractional_max_pool,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.10.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to feeding Large integer value

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import nn_ops
try:
  arg_0_tensor = tf.random.uniform([5, 20, 20, 3], dtype=tf.float64)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1_0 = 1
  arg_1_1 = -13.0
  arg_1_2 = 1.5
  arg_1_3 = 1
  arg_1 = [arg_1_0,arg_1_1,arg_1_2,arg_1_3,]
  seed = 125091515651
  seed2 = 1
  deterministic = True
  out = nn_ops.fractional_max_pool(arg_0,arg_1,seed=seed,seed2=seed2,deterministic=deterministic,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 22:05:06.501205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-14 22:05:07.064824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.082027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.082168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.082457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 22:05:07.083701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.083818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.083916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.144960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.145099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.145198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 22:05:07.145279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4205 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:From /home/nimashiri/anaconda3/envs/fuzzer_tf_2.10.0/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: fractional_max_pool (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` and `deterministic` args are deprecated.  Use fractional_max_pool_v2.
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-15 01:55:05,bug,Crash when running tensorflow.python.eager.context.check_alive,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.10.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Probably due to an invalid string argument.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow.python.eager import context
try:
  try:
    with tf.device('/CPU'):
      arg_0 = ""/job:remote_device/replica:0/task:1""
      out = context.check_alive(arg_0,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      context.check_alive(arg_0,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
023-08-14 21:43:55.028346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.045718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.045863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.046195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 21:43:55.047241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.047355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.047452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.101589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.101732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.101832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:43:55.101916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4018 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-15 01:37:14,bug,Abort when running tensorflow.python.ops.gen_ctc_ops.ctc_loss,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to large input tensor

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import gen_ctc_ops
try:
  arg_0_tensor = tf.constant(-8968073515812833920, shape=[2, 2, 3], dtype=tf.float32,)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1_tensor = tf.constant(8968073515812833920, shape=[4, 2], dtype=tf.int64,)
  arg_1 = tf.identity(arg_1_tensor)
  arg_2_tensor = tf.random.uniform([4], minval=-256, maxval=257, dtype=tf.int32)
  arg_2 = tf.identity(arg_2_tensor)
  arg_3_tensor = tf.random.uniform([2], minval=-256, maxval=257, dtype=tf.int32)
  arg_3 = tf.identity(arg_3_tensor)
  preprocess_collapse_repeated = False
  ctc_merge_repeated = True
  ignore_longer_outputs_than_inputs = False
  out = gen_ctc_ops.ctc_loss(arg_0,arg_1,arg_2,arg_3,preprocess_collapse_repeated=preprocess_collapse_repeated,ctc_merge_repeated=ctc_merge_repeated,ignore_longer_outputs_than_inputs=ignore_longer_outputs_than_inputs,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 21:36:56.173477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.190838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.190979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.191266: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 21:36:56.191900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.192006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.192110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.252143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.252287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.252387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:36:56.252470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4025 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
2023-08-14 21:36:56.314614: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600
2023-08-14 21:36:56.327748: F tensorflow/stream_executor/cuda/cuda_dnn.cc:804] Check failed: cudnnSetConvolutionGroupCount( handle_.get(), convolution_descriptor.group_count()) == CUDNN_STATUS_SUCCESS (3 vs. 0)
Aborted

```
```
"
tensorflow/tensorflow,2023-08-15 01:32:49,bug,Abort when running tensorflow.python.ops.nn_ops.conv3d_transpose,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.10.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to feeding invalid list element

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import nn_ops
try:
  arg_0_tensor = tf.random.uniform([2, 5, 6, 4, 3], dtype=tf.float32)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1_tensor = tf.random.uniform([3, 3, 3, 2, 3], dtype=tf.float32)
  arg_1 = tf.identity(arg_1_tensor)
  arg_2_0 = 2
  arg_2_1 = 11
  arg_2_2 = 13
  arg_2_3 = 9
  arg_2_4 = False
  arg_2 = [arg_2_0,arg_2_1,arg_2_2,arg_2_3,arg_2_4,]
  strides_0 = 1
  strides_1 = 2
  strides_2 = 2
  strides_3 = 2
  strides_4 = 1
  strides = [strides_0,strides_1,strides_2,strides_3,strides_4,]
  padding = ""VALID""
  out = nn_ops.conv3d_transpose(arg_0,arg_1,arg_2,strides=strides,padding=padding,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 21:32:34.731642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.748917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.749058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.749350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 21:32:34.750631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.750742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.750840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.804553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.804756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.804893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 21:32:34.804979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4009 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
2023-08-14 21:32:34.866964: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600
2023-08-14 21:32:34.880076: F tensorflow/stream_executor/cuda/cuda_dnn.cc:804] Check failed: cudnnSetConvolutionGroupCount( handle_.get(), convolution_descriptor.group_count()) == CUDNN_STATUS_SUCCESS (3 vs. 0)
Aborted

```
```
"
tensorflow/tensorflow,2023-08-14 23:47:30,bug,Internal Assertion Failure when running tensorflow.python.eager.remote.connect_to_remote_host,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to feeding NaN input

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow.python.eager import remote
try:
  try:
    with tf.device('/CPU'):
      arg_0 = ""nan""
      out = remote.connect_to_remote_host(arg_0,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      remote.connect_to_remote_host(arg_0,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 19:46:47.563173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.580413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.580559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.580847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 19:46:47.582229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.582354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.582453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.643352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.643499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.643600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.643684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4110 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
2023-08-14 19:46:47.645827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.645936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.646029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.646141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.646236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:46:47.646304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4110 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
2023-08-14 19:46:47.654175: E tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:580] INVALID_ARGUMENT: Could not interpret ""nan"" as a host-port pair.
E0814 19:46:47.654333018   18949 completion_queue.cc:244]    assertion failed: queue.num_items() == 0
Aborted

```
```
"
tensorflow/tensorflow,2023-08-14 23:38:01,bug,Crash when running tensorflow.python.ops.gen_array_ops.lower_bound,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.10.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to mismatch between input tensors

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import gen_array_ops
try:
  try:
    with tf.device('/CPU'):
      arg_0_tensor = tf.random.uniform([2, 3], dtype=tf.float32)
      arg_0 = tf.identity(arg_0_tensor)
      arg_1_tensor = tf.random.uniform([2], dtype=tf.float32)
      arg_1 = tf.identity(arg_1_tensor)
      arg_2 = tf.int32
      arg_3 = False
      out = gen_array_ops.lower_bound(arg_0,arg_1,arg_2,arg_3,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      arg_0 = tf.identity(arg_0_tensor)
      arg_0 = tf.cast(arg_0, tf.float32)
      arg_1 = tf.identity(arg_1_tensor)
      arg_1 = tf.cast(arg_1, tf.float32)
      arg_2 = tf.int32
      gen_array_ops.lower_bound(arg_0,arg_1,arg_2,arg_3,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 19:37:09.497421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.514487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.514629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.514917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 19:37:09.515817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.515932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.516035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.573389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.573531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.573629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:37:09.573710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4043 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
free(): invalid pointer
Aborted

```
```
"
tensorflow/tensorflow,2023-08-14 23:12:57,bug,Crash when running tensorflow.python.ops.gen_list_ops.tensor_list_reserve,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to the large integer value

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import gen_list_ops
try:
  element_shape_tensor = tf.random.uniform([0], minval=-256, maxval=257, dtype=tf.int32)
  element_shape = tf.identity(element_shape_tensor)
  num_elements = 1250999896764
  element_dtype = tf.float64
  out = gen_list_ops.tensor_list_reserve(element_shape=element_shape,num_elements=num_elements,element_dtype=element_dtype,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 19:12:02.093783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.111206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.111351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.111663: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 19:12:02.113096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.113270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.113369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.167538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.167673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.167772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 19:12:02.167855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4163 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-14 23:00:54,bug,Abort when running tensorflow.python.ops.math_ops.sobol_sample,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.10.0

### Custom code

No

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to empty input value

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import math_ops
try:
  arg_0 = 10
  arg_1 = 50
  arg_2 = [()]
  dtype = None
  out = math_ops.sobol_sample(arg_0,arg_1,arg_2,dtype=dtype,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 18:57:53.081061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.098644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.098788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.099088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 18:57:53.099985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.100112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.100209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.168279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.168422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.168524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:57:53.168607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3574 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
2023-08-14 18:57:53.212928: F tensorflow/core/framework/tensor.cc:733] Check failed: 1 == NumElements() (1 vs. 0)Must have a one element tensor
Aborted

```
```
"
tensorflow/tensorflow,2023-08-14 22:11:39,bug,Crash when running tensorflow.python.eager.context.add_function,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.10.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to Feeding None value

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.eager import context
try:
  arg_0 = None
  out = context.add_function(arg_0,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-14 18:09:38.431471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-14 18:09:39.008742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.026368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.026511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.026801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 18:09:39.027611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.027718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.027812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.086029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.086174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.086268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 18:09:39.086349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4023 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-14 21:16:23,bug,segmentation fault when running tensorflow.python.ops.nn_ops.fractional_max_pool,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.11.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to large input tensor

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import nn_ops
try:
  arg_0_tensor = tf.random.uniform([5, 20, 20, 3], dtype=tf.float64)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1_0 = 4.0
  arg_1_1 = 1.5
  arg_1_2 = 1.5
  arg_1_3 = 1
  arg_1 = [arg_1_0,arg_1_1,arg_1_2,arg_1_3,]
  seed = 1
  seed2 = 1
  deterministic = True
  out = nn_ops.fractional_max_pool(arg_0,arg_1,seed=seed,seed2=seed2,deterministic=deterministic,)
except Exception as e:
  print(""Error:""+str(e))

```
```


### Relevant log output

```shell
2023-08-14 16:35:31.365070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-14 16:35:31.920926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:31.937761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:31.937904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:31.938205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-14 16:35:31.939360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:31.939470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:31.939568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:32.006452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:32.006593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:32.006693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-14 16:35:32.006775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4461 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:From /home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: fractional_max_pool (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` and `deterministic` args are deprecated.  Use fractional_max_pool_v2.
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-14 07:51:15,bug,UnicodeDecodeError when loading model from a path with Chinese characters.,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.13.0

### Custom code

Yes

### OS platform and distribution

Windows 11 22h2

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Current behavior:
When I attempt to use tf.keras.models.load_model to load a saved model from a folder path that contains Chinese characters, TensorFlow throws a UnicodeDecodeError. This suggests that TensorFlow may not be parsing Chinese characters correctly in the folder path.

Expected behavior:
I expect tf.keras.models.load_model to be able to load the model correctly from any folder path, regardless of whether it contains Chinese characters or not. If there are limitations on the folder name, it should be clearly documented or provide a more descriptive error message.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

# Create a simple model
model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
model.compile(optimizer='adam', loss='mse')
model.save('模型/')  # '模型' is Chinese for 'model'

# Now, try to load the saved model
loaded_model = tf.keras.models.load_model('模型/')
```


### Relevant log output

```shell
Traceback (most recent call last):
...
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa1 in position 27: invalid start byte
```
"
tensorflow/tensorflow,2023-08-13 06:11:17,bug,Segmentation fault when running tensorflow.python.framework.importer._GatherReturnElements,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.11.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to feeding None value

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.framework import importer
try:
  arg_0_0 = ""A""
  arg_0 = [arg_0_0,]
  arg_1 = None
  arg_2 = None
  out = importer._GatherReturnElements(arg_0,arg_1,arg_2,)
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
023-08-13 02:10:14.149106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-13 05:59:59,bug,Abort when running,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.11.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to a Negative Large Integer. The behavior is bizarre. It would be best if you ran multiple times to see the Abort.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import gen_math_ops
try:
  try:
    with tf.device('/CPU'):
      splits_tensor = tf.constant(-1000000, shape=[129, 1, 1], dtype=tf.float16,)
      splits = tf.identity(splits_tensor)
      values_tensor = tf.saturate_cast(tf.constant(-153, shape=[3456], dtype=tf.int64,),dtype=tf.uint64)
      values = tf.identity(values_tensor)
      weights_tensor = tf.saturate_cast(tf.constant(-1012756988, shape=[128, 27], dtype=tf.int64,),dtype=tf.int16)
      weights = tf.identity(weights_tensor)
      size = -3046875451
      out = gen_math_ops.ragged_bincount(splits=splits,values=values,weights=weights,size=size,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      splits = tf.identity(splits_tensor)
      splits = tf.cast(splits, tf.float16)
      values = tf.identity(values_tensor)
      values = tf.cast(values, tf.uint64)
      weights = tf.identity(weights_tensor)
      weights = tf.cast(weights, tf.int16)
      gen_math_ops.ragged_bincount(splits=splits,values=values,weights=weights,size=size,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
2023-08-13 01:58:36.322308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-13 01:58:37.120869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.139665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.139841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.140154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-13 01:58:37.140677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.140794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.140896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.187990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.188156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.188267: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 01:58:37.188356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 152 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
Error:can't convert negative int to unsigned
2023-08-13 01:58:37.207611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 152.81M (160235520 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2023-08-13 01:58:37.207886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 137.53M (144211968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2023-08-13 01:58:37.208138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 123.78M (129790976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2023-08-13 01:58:37.213816: F ./tensorflow/python/eager/pywrap_tensor_conversion.h:58] Check failed: !PyErr_Occurred() 
Aborted
```
```
"
tensorflow/tensorflow,2023-08-13 04:24:35,bug,Abort when running tensorflow.python.ops.gen_array_ops.depth_to_space,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.11.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Due to very large integer argument

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import gen_array_ops
try:
  arg_0_tensor = tf.random.uniform([3, 2, 3, 4], dtype=tf.float32)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1 = 2147483647
  arg_2 = ""NHWC""
  out = gen_array_ops.depth_to_space(arg_0,arg_1,arg_2,)
except Exception as e:
  print(""Error:""+str(e))

```
```


### Relevant log output

```shell
023-08-13 00:23:53.644564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-13 00:23:54.491071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.510564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.510736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.511051: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-13 00:23:54.511595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.511717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.511830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.572398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.572634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.572791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-13 00:23:54.572916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 153 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
2023-08-13 00:23:54.594062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 153.88M (161349632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2023-08-13 00:23:54.594484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 138.49M (145214720 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2023-08-13 00:23:54.600623: F tensorflow/core/framework/tensor_shape.cc:201] Non-OK-status: InitDims(dim_sizes) status: INVALID_ARGUMENT: Expected a non-negative size, got -2
Aborted

```
```
"
tensorflow/tensorflow,2023-08-13 03:08:38,bug,Segmentation fault when running tensorflow.python.ops.list_ops.tensor_list_reserve,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

When num_elements is very large

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import list_ops
try:
  element_shape_0 = 1
  element_shape = [element_shape_0,]
  num_elements = 1250999896764
  element_dtype = tf.float32
  out = list_ops.tensor_list_reserve(element_shape=element_shape,num_elements=num_elements,element_dtype=element_dtype,)
except Exception as e:
  print(""Error:""+str(e))

```
```


### Relevant log output

```shell
2023-08-12 23:05:56.608429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-12 23:05:57.434965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.454466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.454644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.454958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-12 23:05:57.455499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.455620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.455724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.504359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.504534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.504649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 23:05:57.504741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 151 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
2023-08-12 23:05:57.518166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 151.44M (158793728 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-12 20:10:54,bug,check failure when running tensorflow.python.ops.nn_ops.conv3d_transpose_v2,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.11.0

### Custom code

No

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

```
The following input combination causes check failure
```

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import os
import numpy as np
from tensorflow.python.ops import nn_ops
try:
  arg_0_tensor = tf.random.uniform([2, 5, 6, 4, 3], dtype=tf.float32)
  arg_0 = tf.identity(arg_0_tensor)
  arg_1_tensor = tf.random.uniform([3, 3, 3, 2, 3], dtype=tf.float32)
  arg_1 = tf.identity(arg_1_tensor)
  arg_2_0 = 2
  arg_2_1 = 11
  arg_2_2 = 13
  arg_2_3 = 9
  arg_2_4 = False
  arg_2 = [arg_2_0,arg_2_1,arg_2_2,arg_2_3,arg_2_4,]
  arg_3_0 = 1
  arg_3_1 = 2
  arg_3_2 = 2
  arg_3_3 = 2
  arg_3_4 = 1
  arg_3 = [arg_3_0,arg_3_1,arg_3_2,arg_3_3,arg_3_4,]
  padding = ""VALID""
  data_format = ""NDHWC""
  dilations = None
  out = nn_ops.conv3d_transpose_v2(arg_0,arg_1,arg_2,arg_3,padding=padding,data_format=data_format,dilations=dilations,)
except Exception as e:
  print(""Error:""+str(e))

```
```


### Relevant log output

```shell
2023-08-06 06:58:26.108204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-06 06:58:26.851251: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/:/home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/python3.9/site-packages/nvidia/cudnn/lib:
2023-08-06 06:58:26.851492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/:/home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/python3.9/site-packages/nvidia/cudnn/lib:
2023-08-06 06:58:26.851500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-06 06:58:27.585126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/:/home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/python3.9/site-packages/nvidia/cudnn/lib:
2023-08-06 06:58:27.585372: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/:/home/nimashiri/anaconda3/envs/fuzzer_tf_2.11.0/lib/python3.9/site-packages/nvidia/cudnn/lib:
2023-08-06 06:58:27.585380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-06 06:59:12.781705: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:876] Check failed: cudnnSetConvolutionGroupCount( handle_.get(), convolution_descriptor.group_count()) == CUDNN_STATUS_SUCCESS (3 vs. 0)
```
```
"
tensorflow/tensorflow,2023-08-12 19:28:30,bug,Segmentation fault when running tensorflow.python.eager.context.check_alive,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

22.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

nvidia-cudnn-cu11==8.6.0.163, cudatoolkit=11.8.0

### GPU model and memory

_No response_

### Current behavior?

Probably due to invalid string argument.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow.python.eager import context
try:
  try:
    with tf.device('/CPU'):
      arg_0 = ""/job:remote_device/replica:0/task:1""
      out = context.check_alive(arg_0,)
  except Exception as e:
    print(""Error:""+str(e))
  try:
    with tf.device('/GPU:0'):
      context.check_alive(arg_0,)
  except Exception as e:
    print(""Error:""+str(e))
except Exception as e:
  print(""Error:""+str(e))
```
```


### Relevant log output

```shell
/cudnn/lib:
2023-08-12 15:27:22.605920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-08-12 15:27:23.511442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.533020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.533197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.533535: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-08-12 15:27:23.534136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.534277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.534432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.605501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.605704: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.605831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-08-12 15:27:23.605930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5
Segmentation fault

```
```
"
tensorflow/tensorflow,2023-08-11 17:32:02,bug,TypeError: Unable to serialize 64.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13

### Custom code

No

### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.11.3

### Bazel version

N/A

### GCC/compiler version

N/A

### CUDA/cuDNN version

Not using GPU

### GPU model and memory

N/A

### Current behavior?

I have been receiving this message when trying to save a variety of  tensorflow models since version 2.11.  I have reported it before.

It appears to be produced by the lack of an ability by tensorfow to serialize the model representations it maintains in memory.

TypeError: Unable to serialize 64.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.

See the debugger output below for details

Can I change anything in my models to dodge this logic?
Is there another model saving function I can try?

### Standalone code to reproduce the issue

```shell
Please email me for code.
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""D:\\Craig\\Python\\Projects\\CraigsPackages\\koopman_operator_autoencoder_unit_tests.py"", line 132, in <module>
    tf.keras.saving.save_model(model=autoencoder,  filepath='autoencoder_model', save_format=""tf"")
  File ""C:\\Users\\Craig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py"", line 149, in save_model
    return legacy_sm_saving_lib.save_model(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\\Users\\Craig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\\Users\\Craig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py"", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\\Users\\Craig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py"", line 258, in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
TypeError: Unable to serialize 64.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.
```
"
tensorflow/tensorflow,2023-08-11 06:17:10,bug,BinaryFocalCrossentropy: alpha does not work,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.13

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

`tf.keras.losses.BinaryFocalCrossentropy` computes the loss without using the `alpha`.
```
import tensorflow as tf
y_true_list = [0, 1, 0, 0]
logits_list = [-1.6, 0.51, 2.94, -1.8]
gamma = 2

focal_func1 = tf.keras.losses.BinaryFocalCrossentropy(gamma=gamma, alpha=0.25, from_logits=True)
focal_loss1 = focal_func1(y_true_list, logits_list)

focal_func2 = tf.keras.losses.BinaryFocalCrossentropy(gamma=gamma, alpha=10, from_logits=True)
focal_loss2 = focal_func2(y_true_list, logits_list)

focal_func3 = tf.keras.losses.BinaryFocalCrossentropy(gamma=gamma, alpha=100, from_logits=True)
focal_loss3 = focal_func3(y_true_list, logits_list)

print(focal_loss1)
print(focal_loss2)
print(focal_loss3)  
```
The results are:
```
tf.Tensor(0.6932789, shape=(), dtype=float32)
tf.Tensor(0.6932789, shape=(), dtype=float32)
tf.Tensor(0.6932789, shape=(), dtype=float32)
```

`focal_loss1` in the codes should be `0.51168`

### Standalone code to reproduce the issue

```shell
In above.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-09 08:30:33,bug,NotImplementedError while converting a tensorflow model to coreml using coremltools,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I am facing a NotImplementedError while trying to convert [MoViNets](https://github.com/tensorflow/models/tree/master/official/projects/movinet) model to coreml.

The model is saved in [SavedModel](https://www.tensorflow.org/guide/saved_model) format and I am using a tensorflow version equal to **2.13.0** and a version of [Core ML Tools](https://coremltools.readme.io/docs/what-are-coreml-tools) equal to **6.3.0** and a **3.10.6** python.

I don't understand the origin of **StatefulPartitionedCall** operation and its meaning, any idea what's could be going on?

### Here are the steps to reproduce the error:
1. Download a savedModel from the following [link](https://tfhub.dev/tensorflow/movinet/a0/base/kinetics-600/classification/3).
2. Convert the model using:
```shell
import coremltools as ct
coreml_model = ct.convert(saved_dir, convert_to=""mlprogram"")
```
where *saved_dir* is the path to the downloaded model.

### Relevant log output

```shell
NotImplementedError: Conversion for TF op 'StatefulPartitionedCall' not implemented.
 
name: ""StatefulPartitionedCall""
op: ""StatefulPartitionedCall""
input: ""image""
input: ""unknown""
input: ""unknown_0""
input: ""unknown_1""
input: ""unknown_2""
input: ""unknown_3""
input: ""unknown_4""
input: ""unknown_5""
input: ""unknown_6""
input: ""unknown_7""
input: ""unknown_8""
input: ""unknown_9""
input: ""unknown_10""
input: ""unknown_11""
input: ""unknown_12""
input: ""unknown_13""
input: ""unknown_14""
input: ""unknown_15""
...
input: ""unknown_597""
input: ""unknown_598""
input: ""unknown_599""
attr {
  key: ""Tin""
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""Tout""
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_XlaMustCompile""
  value {
    b: true
  }
}
attr {
  key: ""_collective_manager_ids""
  value {
    list {
    }
  }
}
attr {
  key: ""_has_manual_control_dependencies""
  value {
    b: true
  }
}
attr {
  key: ""_read_only_resource_inputs""
  value {
    list {
      i: 1
      i: 2
      i: 3
      i: 4
      i: 5
      i: 6
      i: 7
      i: 8
      i: 9
      i: 10
      i: 11
      i: 12
      i: 13
      i: 14
      i: 15
...
      i: 597
      i: 598
      i: 599
      i: 600
      i: 601
    }
  }
}
attr {
  key: ""config""
  value {
    s: """"
  }
}
attr {
  key: ""config_proto""
  value {
    s: ""\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0012\\005*\\0010J\\0008\\001\\202\\001\\000""
  }
}
attr {
  key: ""executor_type""
  value {
    s: """"
  }
}
attr {
  key: ""f""
  value {
    func {
      name: ""__inference_predict_frozen_288748""
    }
  }
}

```
```
"
tensorflow/tensorflow,2023-08-08 01:42:25,bug,Tensorflow inference error,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.8

### Custom code

Yes

### OS platform and distribution

linux centos

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

My model can train normally, but there was an error when inference after the training was completed.The model structure code is as follows:

conv_1 = Conv2D(32,(1,5),(1,1),name='mode0_conv_1',padding='same')(input_1)
bn_1 = BatchNormalizetion(name='mode0_bn_1')(conv_1)
out_1 = PReLU(shared_axes=[1,2])(bn_1)
out_2 = tf.reshape(........)(out_1)
dp_1 = LSTM(......)(out_2)

dp_o1 = Dense(32,)(dp_1)
dp_o2 = PReLU(shared_axes=[1,2])(dp_o1)

ls_o1 = LSTM(................)(dp_o2)

dp_o3 = Dense(2,)(ls_o1)

The error is as follows:

tensorflow.pyrhon.framework.errors_impl.InvalidArgumentError:Graph execution error:
....

Node:'model/model0_bn_1/FuseBatchNormV3'
scale must have the same number of elements as the channels of x, got 32 and 2
         [[{node model/model0_bn_1/FuseBatchNormV3}]] [op:__inference_predict_function_3355]

May I ask what caused this and if it can be resolved?

### Standalone code to reproduce the issue

```shell
No
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-02 19:25:47,bug,How to get detailed information about the issue,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.12.1

### Custom code

No

### OS platform and distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

Cuda 11.8, Cudnn 8.9.2

### GPU model and memory

Nvidia A10

### Current behavior?

I'm getting following error while compiling the model with XLA:

```
OP_REQUIRES failed at xla_ops.cc:347 : INVALID_ARGUMENT: Trying to access resource Resource-3-at-0x55555dbbdfb0 located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0
```

This issue is documented as XLA limitation [here](https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device), which seems reasonable, but the error message doesn't specify where this issue is coming from.

Is there any way to get more details on which variable is creating this issue?

### Standalone code to reproduce the issue

```shell
NA
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-02 05:17:09,bug,tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value num_blocks_2/multihead_attention/conv1d_1/kerne,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.8

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have trained the [CARCA(Context and Attribute-Aware Sequential Recommendation via Cross-Attention)](https://github.com/ahmedrashed-ml/CARCA) on Video Games Dataset. I saved the session after 1 epoch and try to restore the session since all the Architecture was written using the concepts of the session. I saved the session using tf.train.Saver() .save() method.
```

session_saver = tf.train.Saver(save_relative_paths=True)
session_output_path = os.path.join(args.output_dir, ""epochs_""+str(epoch))
if not os.path.isdir(session_output_path):
    os.makedirs(session_output_path)# make directory if not exists
session_saver.save(sess, session_output_path+""/carca_model"")
print(f""[INFO]: Save the model after epochs: {epoch}"")
```
then, I restored session using:
```
saver = tf.train.import_meta_graph(session_dir +""carca_model.meta"")
saver.restore(sess, tf.train.latest_checkpoint(session_dir))
```
I have tried to perform prediction on new dataset using restored session sess, But I have encountered Attempting to use uninitialized value error. The full error is:
```

Traceback (most recent call last):
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value num_blocks_2/multihead_attention/conv1d_1/kernel_1
         [[{{node num_blocks_2/multihead_attention/conv1d_1/kernel_1/read}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""CARCA_train.py"", line 1441, in <module>
    get_load_model_and_inference(dataset, usernum, itemnum, args, ItemFeatures, UserFeatures, CXTDict)
  File ""CARCA_train.py"", line 1317, in get_load_model_and_inference
    predictions = -model.predict(sess, np.ones(args.maxlen)*u, [seq], item_idx, [seqcxt], testitemscxt)
  File ""CARCA_train.py"", line 976, in predict
    {self.test_user: u, self.input_seq: seq, self.test_item: item_idx, self.is_training: False, self.seq_cxt:seqcxt, self.test_item_cxt:testitemcxt})
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value num_blocks_2/multihead_attention/conv1d_1/kernel_1
         [[node num_blocks_2/multihead_attention/conv1d_1/kernel_1/read (defined at CARCA_train.py:670) ]]

Original stack trace for 'num_blocks_2/multihead_attention/conv1d_1/kernel_1/read':
  File ""CARCA_train.py"", line 1441, in <module>
    get_load_model_and_inference(dataset, usernum, itemnum, args, ItemFeatures, UserFeatures, CXTDict)
  File ""CARCA_train.py"", line 1266, in get_load_model_and_inference
    model = Model(usernum, itemnum, args, ItemFeatures, UserFeatures, cxt_size = cxt_size ,use_res = True)
  File ""CARCA_train.py"", line 768, in __init__
    dropout_rate=args.dropout_rate, is_training=self.is_training)
  File ""CARCA_train.py"", line 670, in feedforward
    outputs = tf.layers.conv1d(**params)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py"", line 218, in conv1d
    return layer.apply(inputs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1479, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/layers/base.py"", line 537, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 591, in __call__
    self._maybe_build(inputs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1881, in _maybe_build
    self.build(input_shapes)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 165, in build
    dtype=self.dtype)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/layers/base.py"", line 450, in add_weight
    **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 384, in add_weight
    aggregation=aggregation)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 663, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1496, in get_variable
    aggregation=aggregation)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1239, in get_variable
    aggregation=aggregation)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 562, in get_variable
    aggregation=aggregation)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 514, in _true_getter
    aggregation=aggregation)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 929, in _get_single_variable
    aggregation=aggregation)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 259, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 220, in _variable_v1_call
    shape=shape)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 198, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 2511, in default_variable_creator
    shape=shape)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 263, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 1568, in __init__
    shape=shape)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 1755, in _init_from_args
    self._snapshot = array_ops.identity(self._variable, name=""read"")
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py"", line 86, in identity
    ret = gen_array_ops.identity(input, name=name)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 4253, in identity
    ""Identity"", input=input, name=name)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/home/zakipoint/miniconda3/envs/sequential_recommendation_carca/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()

I have also checked the variables in both the stored session and the session just after training. Both outputs seem similar. I was stuck on this issue for a few days and also tested saving the model using tf.saved_model.builder.SavedModelBuilder() and restoring the model using tf.saved_model.loader.load() but not solved the issue.Currently,I am using tensorflow 1.14
```

### Standalone code to reproduce the issue

```shell
session_saver = tf.train.Saver(save_relative_paths=True)
session_output_path = os.path.join(args.output_dir, ""epochs_""+str(epoch))
if not os.path.isdir(session_output_path):
    os.makedirs(session_output_path)# make directory if not exists
session_saver.save(sess, session_output_path+""/carca_model"")
print(f""[INFO]: Save the model after epochs: {epoch}"")

saver = tf.train.import_meta_graph(session_dir +""carca_model.meta"")
saver.restore(sess, tf.train.latest_checkpoint(session_dir))
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-08-01 09:51:02,bug,//tensorflow/compiler/mlir/lite/tests:optimize.mlir.test fails,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

git HEAD

### Custom code

No

### OS platform and distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.9.17

### Bazel version

6.1.0

### GCC/compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current behavior?

Unit test fails since commit https://github.com/tensorflow/tensorflow/commit/9d0fea2d5935285122b56867c4499433121f531f

### Standalone code to reproduce the issue

```shell
bazel test --config=mkl_aarch64_threadpool --copt=-flax-vector-conversions --test_env=TF_ENABLE_ONEDNN_OPTS=1 --test_env=TF2_BEHAVIOR=1 --define=tf_api_version=2 --jobs=75 --build_tests_only -- //tensorflow/compiler/mlir/lite/tests:optimize.mlir.test
```


### Relevant log output

```shell
==================== Test output for //tensorflow/compiler/mlir/lite/tests:optimize.mlir.test:
-- Testing: 1 tests, 1 workers --
FAIL: MLIR tests :: optimize.mlir (1 of 1)
******************** TEST 'MLIR tests :: optimize.mlir' FAILED ********************
Script:
--
: 'RUN: at line 2';   /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/tf-opt /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir -tfl-optimize | /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/llvm-project/llvm/FileCheck /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir
: 'RUN: at line 4';   /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/tf-opt /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir -tfl-optimize='enable-canonicalization=true' | /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/llvm-project/llvm/FileCheck --check-prefix=FOLD /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir
: 'RUN: at line 7';   /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/tf-opt /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir -tfl-legalize-tf -tfl-optimize | /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/llvm-project/llvm/FileCheck --check-prefix=Fusing /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir
: 'RUN: at line 9';   /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/tf-opt /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir -tfl-legalize-tf -tfl-optimize='disable-fuse-mul-and-fc=true' | /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/llvm-project/llvm/FileCheck --check-prefix=NoFusing /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir
--
Exit Code: 1

Command Output (stderr):
--
/home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir:3622:12: error: CHECK: expected string not found in input
 // CHECK: ""tfl.batch_matmul""(%arg0, %arg1)
           ^
<stdin>:1542:53: note: scanning from here
 func.func @FuseReshapeAndTransposeAroundBatchMatmul(%arg0: tensor<1x128x1024xf32>, %arg1: tensor<1024x16xf32>) -> tensor<1x128x16xf32> {
                                                    ^
<stdin>:1549:7: note: possible intended match here
 %2 = ""tfl.batch_matmul""(%arg1, %1) {adj_x = true, adj_y = false, asymmetric_quantize_inputs = false} : (tensor<1024x16xf32>, tensor<1024x128xf32>) -> tensor<16x128xf32>
      ^

Input file: <stdin>
Check file: /home/andrew/src/tf_test/tensorflow-git/bazel-ci_build-cache/.cache/bazel/_bazel_andrew/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/optimize.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
              .
              .
              .
           1537:  %3 = ""tfl.transpose""(%2, %0) : (tensor<16x1x8x1280xf32>, tensor<4xi32>) -> tensor<8x1x16x1280xf32> 
           1538:  %4 = ""tfl.gather_nd""(%3, %1) : (tensor<8x1x16x1280xf32>, tensor<16x1xi32>) -> tensor<16x1x16x1280xf32> 
           1539:  %5 = ""tfl.reshape""(%4, %cst) : (tensor<16x1x16x1280xf32>, tensor<4xi32>) -> tensor<1x16x16x1280xf32> 
           1540:  return %5 : tensor<1x16x16x1280xf32> 
           1541:  } 
           1542:  func.func @FuseReshapeAndTransposeAroundBatchMatmul(%arg0: tensor<1x128x1024xf32>, %arg1: tensor<1024x16xf32>) -> tensor<1x128x16xf32> { 
check:3622'0                                                         X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
           1543:  %cst = arith.constant dense<[1, 2, 0]> : tensor<3xi32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1544:  %cst_0 = arith.constant dense<[16, 1, 128]> : tensor<3xi32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1545:  %cst_1 = arith.constant dense<[1024, 128]> : tensor<2xi32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1546:  %cst_2 = arith.constant dense<[2, 0, 1]> : tensor<3xi32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1547:  %0 = ""tfl.transpose""(%arg0, %cst_2) : (tensor<1x128x1024xf32>, tensor<3xi32>) -> tensor<1024x1x128xf32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1548:  %1 = ""tfl.reshape""(%0, %cst_1) : (tensor<1024x1x128xf32>, tensor<2xi32>) -> tensor<1024x128xf32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1549:  %2 = ""tfl.batch_matmul""(%arg1, %1) {adj_x = true, adj_y = false, asymmetric_quantize_inputs = false} : (tensor<1024x16xf32>, tensor<1024x128xf32>) -> tensor<16x128xf32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:3622'1           ?                                                                                                                                                                    possible intended match
           1550:  %3 = ""tfl.reshape""(%2, %cst_0) : (tensor<16x128xf32>, tensor<3xi32>) -> tensor<16x1x128xf32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1551:  %4 = ""tfl.transpose""(%3, %cst) : (tensor<16x1x128xf32>, tensor<3xi32>) -> tensor<1x128x16xf32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1552:  return %4 : tensor<1x128x16xf32> 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           1553:  } 
check:3622'0     ~~~
           1554:  func.func @FuseTransposeFCRhsToBatchMatmul(%arg0: tensor<16x1024xf32>, %arg1: tensor<1024x128xf32>, %arg2: none) -> tensor<16x128xf32> { 
check:3622'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
              .
              .
              .
>>>>>>

--

********************
********************
Failed Tests (1):
  MLIR tests :: optimize.mlir


Testing Time: 0.53s
  Failed: 1
================================================================================
```
"
tensorflow/tensorflow,2023-08-01 02:23:13,bug,Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.10.0

### Custom code

Yes

### OS platform and distribution

Windows 11

### Mobile device

N/A

### Python version

3.10(Microsoft Store)

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

Cuda: 11.2

### GPU model and memory

RTX 3070 Ti 8GB
### Current behavior?

I installed CUDA 11.2 as recommended for tf 2.10.0, here's the install:
![Screenshot](https://github.com/tensorflow/tensorflow/assets/1494132/59352a2a-f90f-45bf-b8bd-861dc893a9ff)
At first, I thought it was a path issue, but after restarting my pc, I was able to access exe files in that folder:
![image](https://github.com/tensorflow/tensorflow/assets/1494132/5d9ccfca-4417-4045-ba74-fffde7b8a121)
If the files are in path, why can't tensorflow find them?
Many people say to use miniconda, so I did, but I got the same result. Other resolved issues were resolved as the OP's were using the wrong version of CUDA, I checked on the website and I can confirm that my version is the required one.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
```


### Relevant log output

```shell
2023-07-31 18:56:25.098058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-07-31 18:56:25.098226: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-07-31 18:56:26.164080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2023-07-31 18:56:26.164320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2023-07-31 18:56:26.164540: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2023-07-31 18:56:26.164818: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2023-07-31 18:56:26.368828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2023-07-31 18:56:26.369092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
```
"
tensorflow/tensorflow,2023-07-29 18:23:20,bug,JAVA - org.tensorflow.TensorFlowException: Can't parse /<modelPath>/<somePathToFolder>/saved_model.pb as binary proto - JDK 17,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

1.15.0

### Custom code

Yes

### OS platform and distribution

RHEL 8 version, 8.7.5

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

`/<modelPath>/<somePathToFolder>/`
Has following files:
1. assets/vocab.txt
2. saved_model.pb
3. variables/variables.data-00000-of-00001 
4. variables/variables.index

I am using java binding code to run the inference. Libraries I am using are 

```
<groupId>org.tensorflow</groupId>
<artifactId>tensorflow</artifactId>
<artifactId>1.15.0</artifactId>


<groupId>org.tensorflow</groupId>
<artifactId>libtensorflow</artifactId>
<artifactId>1.15.0</artifactId>


<groupId>org.tensorflow</groupId>
<artifactId>proto</artifactId>
<artifactId>1.15.0</artifactId>

<groupId>org.tensorflow</groupId>
<artifactId>libtensorflow_jni</artifactId>
<artifactId>1.15.0</artifactId>


```

TensorFlow version - 1.15.0
JDK - Oracle Open Jdk Version 17.0.5
OS - RHEL 8 version, 8.7.5
**Describe the current behavior**

```
org.tensorflow.TensorFlowException: Can't parse </modelPath>/<somePathToFolder>/saved_model.pb as binary proto
	at app//org.tensorflow.SavedModelBundle.load(Native Method)
	at app//org.tensorflow.SavedModelBundle.access$000(SavedModelBundle.java:27)
	at app//org.tensorflow.SavedModelBundle$Loader.load(SavedModelBundle.java:32)
	at app//org.tensorflow.SavedModelBundle.load(SavedModelBundle.java:95)
	at app//com.main.java.main.tensorflow.TestClass.TFPredictor(TestClass.java:19)
```

**Describe the expected behavior**
In JDK 11, the code runs while in JDK 17 its throws error. The model file is not corrupted & same model path file is able to run successfully in JDK 11 

### Standalone code to reproduce the issue

```shell
Code:


import com.google.common.io.Resources;
import org.junit.Test;
import org.tensorflow.SavedModelBundle;
import org.tensorflow.Session;

import java.io.IOException;
import java.net.URISyntaxException;
import java.nio.file.Paths;

public class TestClass {

    @Test
    public void TFPredictor() throws IOException, URISyntaxException {
        SavedModelBundle b = SavedModelBundle.load(""/<modelPath>/<somePathToFolder>"", ""serve"");
        Session sess = b.session();
    }

}
```"
tensorflow/tensorflow,2023-07-27 06:51:08,bug,Issue,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.9

### Custom code

Yes

### OS platform and distribution

linux ubuntu

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

xyz

### Standalone code to reproduce the issue

```shell
xyz
```


### Relevant log output

```shell
jkjnk
```
"
tensorflow/tensorflow,2023-07-26 08:43:02,bug,int8 tflite model allocate_tensors() silently stop python process.,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.8.1, 2.13.0, '2.14.0-dev20230706'

### Custom code

Yes

### OS platform and distribution

Windows 11, Windows 10 WSL with Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have converted a Resnet18 model from onnx to tflite. (onnx > tf > tflite)
onnx to tf conversion is done by this [repo](https://github.com/onnx/onnx-tensorflow)
tflite is converted to int8 precision using post-training integer quantization [link](https://www.tensorflow.org/lite/performance/post_training_integer_quant)
Netron can display the converted int8 model correctly.
onnx model & tflite model [link](https://drive.google.com/file/d/1XvxGt5GGFCO7h2FW69hgdYZ9noh5Svd4/view?usp=sharing)
tflite int8 model [link](https://drive.google.com/file/d/1bLjoawNnhQTy-DMsBGUEtF6mW3GLVN2F/view?usp=sharing)

but when I try to do inference. calling the method allocate_tensors() stop the python process without showing any error/warning.

if the tflite model is converted with fp32, this issue  doesn't happen.

I have no idea how do to fix this issue or is there any workaround?
thanks

### Standalone code to reproduce the issue

```shell
## tf to tflite conversion
import tensorflow as tf
import numpy as np

saved_model_dir = 'resnet18'
tflite_model_path = saved_model_dir + '.tflite'

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

def representative_dataset_gen():
    for _ in range(100):
        data = np.random.rand(1, 3, 224, 224)
        yield [data.astype(np.float32)]

converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8

tflite_model = converter.convert()

# Save the model
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)


## inference time
import tensorflow as tf
interpreter = tf.lite.Interpreter(model_path=""resnet18.tflite"")
print('before')
interpreter.allocate_tensors()
print('after') # this line not displayed
```


### Relevant log output

```shell
# inference time output (tf 2.14.0-dev20230706)
WARNING:tensorflow:From C:\\Users\\AI\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From C:\\Users\\AI\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
before
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
```
"
tensorflow/tensorflow,2023-07-25 03:57:58,bug, Invalid work group size,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.10.0

### Custom code

Yes

### OS platform and distribution

ubuntu 20.04

### Mobile device

Qualcomm SM6225

### Python version

3.8

### Bazel version

5.1.1

### GCC/compiler version

9.4.0

### CUDA/cuDNN version

no

### GPU model and memory

QUALCOMM Adreno(TM) QUALCOMM OpenCL C 2.0 Adreno(TM) 610

### Current behavior?

use tflite to invoke mobilnet-v2 or any model with op softmax on mobile device, will encounter an error:
TfLiteGpuDelegate Invoke: Failed to clEnqueueNDRangeKernel - Invalid work group size.

More details:
if INFERENCE_FORCE_FP16 is false,  no error occured. 
if work group size is smaller than 256, no error occured.

### Standalone code to reproduce the issue

```shell
same code as tflite invoke on android phone will reproduce this issue.
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-24 23:58:21,bug,"RNG generators make python abort in python3.11 and tf2.12, conda-forge","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.12.1

### Custom code

Yes

### OS platform and distribution

MacOS 13.4.1(c)

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Unable to make random number generators. This happens with conda-forge (python 3.11.3 + tensorflow.2.12.1). It works fine with pip (python 3.11.3 + tensorflow 2.12.0)

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
g = tf.random.Generator.from_seed(1)
g.normal(shape=[3])
```


### Relevant log output

```shell
Assertion failed: (f == nullptr || dynamic_cast<To>(f) != nullptr), function down_cast, file ./tensorflow/tsl/platform/default/casts.h, line 58.
[1]    18173 abort      python
```
"
tensorflow/tensorflow,2023-07-24 06:53:39,bug,cannot find explicitly assigned device for op,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.8.4

### Custom code

No

### OS platform and distribution

ubuntu18.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

5.2.0

### GCC/compiler version

gcc-11.3.0

### CUDA/cuDNN version

none

### GPU model and memory

none

### Current behavior?

model trained use GPU, but infer machine don't have GPU device, so will meet cannot find assigend device at model load stage. here is log
```
E20230724 13:02:27.982717 35915 tf_model_core.cc:80] Failed to load model in /data/mfs6/new_wifi_models/tf_ranking_model/cvr_model/cvr_dynamic_embedding/2023-07-11.23/, Cannot assign a device for operation lr_weight-parameter_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport: {{node lr_weight-parameter_mht_1of1_lookup_table_export_values/TFRA>CuckooHashTableExport}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.


```

### Standalone code to reproduce the issue

```shell
no code
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-22 03:19:56,bug,LSTM loss does not work TPU with bfloat16,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.12.0

### Custom code

Yes

### OS platform and distribution

Google Colab  + TPU

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

LSTM on TPU works in float32.
Gives error message in bfloat16:
Value passed to parameter 'input' has DataType bfloat16 not in list of allowed values: float16, float32, float64

### Standalone code to reproduce the issue

```shell
Colab Code in this gist:
https://colab.research.google.com/gist/sronen71/cacdc527ea3a7d267e5f47e6dcc8f17f/working_with_rnns.ipynb.

Run with TPU.
```


### Relevant log output

```shell
TypeError                                 Traceback (most recent call last)

<ipython-input-12-d2060b3c689a> in <cell line: 1>()
      1 with strategy.scope():
----> 2   model = build_model()
      3 
      4   model.compile(
      5     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),

3 frames

/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)
     54     allowed_values = "", "".join(dtypes.as_dtype(x).name for x in allowed_list)
     55     if dtype not in allowed_list:
---> 56       raise TypeError(
     57           f""Value passed to parameter '{param_name}' has DataType ""
     58           f""{dtypes.as_dtype(dtype).name} not in list of allowed values: ""

TypeError: Exception encountered when calling layer ""lstm_4"" (type LSTM).

Value passed to parameter 'input' has DataType bfloat16 not in list of allowed values: float16, float32, float64

Call arguments received by layer ""lstm_4"" (type LSTM):
  • inputs=tf.Tensor(shape=(None, None, 128), dtype=bfloat16)
  • mask=None
  • training=None
  • initial_state=None
```
"
tensorflow/tensorflow,2023-07-21 06:26:47,bug,AssertionError: Tried to export a function which references an 'untracked' resource. TensorFlow objects(e.g. tf.Variable),"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.10

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

As you can see in the code below, the operation of multiplying **attn** by **temperature**  at **MDTA** is being performed. And the **temperature** is defined by tf.Variable().

The model using the attention module below runs normally until training(model.fit()), but an AssertionError occurs when saving the model. I would appreciate it if you could tell me how to make the **temperature** variable trackable.

### Standalone code to reproduce the issue

```shell
# import tensorflow.compat.v2 as tf
import tensorflow as tf
import keras
from keras import backend
from keras.applications import imagenet_utils
from keras.engine import training
from keras.layers import VersionAwareLayers
from keras.utils import data_utils
from keras.utils import layer_utils

from keras.layers import Layer, Activation, ReLU, Concatenate, Conv2D, Add, Dense, MaxPool2D, AvgPool2D, Flatten, multiply, Softmax
from keras.layers import Dropout, Dense, GlobalAveragePooling2D, Input, BatchNormalization, DepthwiseConv2D, ZeroPadding2D, LayerNormalization
from tensorflow.keras import backend as K

from keras.models import Model
#import tensorflow.keras

# 정상적으로 작동 (temperature제외)

# isort: off
from tensorflow.python.platform import tf_logging as logging
from tensorflow.python.util.tf_export import keras_export

BASE_WEIGHT_PATH = (
    ""https://storage.googleapis.com/tensorflow/"" ""keras-applications/mobilenet/""
)


@keras_export(
    ""keras.applications.mobilenet.MobileNet"", ""keras.applications.MobileNet""
)
def MobileNet(
    input_shape=None,
    alpha=1.0,
    depth_multiplier=1,
    dropout=1e-3,
    include_top=True,
    weights=""imagenet"",
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation=""softmax"",
    **kwargs,
):

#     global layers
#     if ""layers"" in kwargs:
#         layers = kwargs.pop(""layers"")
#     else:
#         layers = VersionAwareLayers()
    if kwargs:
        raise ValueError(f""Unknown argument(s): {(kwargs,)}"")
    if not (weights in {""imagenet"", None} or tf.io.gfile.exists(weights)):
        raise ValueError(
            ""The `weights` argument should be either ""
            ""`None` (random initialization), `imagenet` ""
            ""(pre-training on ImageNet), ""
            ""or the path to the weights file to be loaded.  ""
            f""Received weights={weights}""
        )

    if weights == ""imagenet"" and include_top and classes != 1000:
        raise ValueError(
            'If using `weights` as `""imagenet""` with `include_top` '
            ""as true, `classes` should be 1000.  ""
            f""Received classes={classes}""
        )

    # Determine proper input shape and default size.
    if input_shape is None:
        default_size = 224
    else:
        if backend.image_data_format() == ""channels_first"":
            rows = input_shape[1]
            cols = input_shape[2]
        else:
            rows = input_shape[0]
            cols = input_shape[1]

        if rows == cols and rows in [128, 160, 192, 224]:
            default_size = rows
        else:
            default_size = 224

    input_shape = imagenet_utils.obtain_input_shape(
        input_shape,
        default_size=default_size,
        min_size=32,
        data_format=backend.image_data_format(),
        require_flatten=include_top,
        weights=weights,
    )

    if backend.image_data_format() == ""channels_last"":
        row_axis, col_axis = (0, 1)
    else:
        row_axis, col_axis = (1, 2)
    rows = input_shape[row_axis]
    cols = input_shape[col_axis]

    if weights == ""imagenet"":
        if depth_multiplier != 1:
            raise ValueError(
                ""If imagenet weights are being loaded, ""
                ""depth multiplier must be 1.  ""
                f""Received depth_multiplier={depth_multiplier}""
            )

        if alpha not in [0.25, 0.50, 0.75, 1.0]:
            raise ValueError(
                ""If imagenet weights are being loaded, ""
                ""alpha can be one of""
                ""`0.25`, `0.50`, `0.75` or `1.0` only.  ""
                f""Received alpha={alpha}""
            )

        if rows != cols or rows not in [128, 160, 192, 224]:
            rows = 224
            logging.warning(
                ""`input_shape` is undefined or non-square, ""
                ""or `rows` is not in [128, 160, 192, 224]. ""
                ""Weights for input shape (224, 224) will be ""
                ""loaded as the default.""
            )

    if input_tensor is None:
        img_input = Input(shape=input_shape)
    else:
        if not backend.is_keras_tensor(input_tensor):
            img_input = Input(tensor=input_tensor, shape=input_shape)
        else:
            img_input = input_tensor
    
    num_heads = 4
    expansion_factor = 3
    
    x = _conv_block(img_input, 32, alpha, strides=(2, 2))
    x = _transformer_block(x, num_heads, expansion_factor)
        
    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)
    x = _transformer_block(x, num_heads, expansion_factor)

    x = _depthwise_conv_block(
        x, 128, alpha, depth_multiplier, strides=(2, 2), block_id=2)
    x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)
    x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(
        x, 256, alpha, depth_multiplier, strides=(2, 2), block_id=4)
    x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)
    x = _transformer_block(x, num_heads, expansion_factor)

    x = _depthwise_conv_block(
        x, 512, alpha, depth_multiplier, strides=(2, 2), block_id=6)
    #x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)
    #x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)
    #x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)
    #x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)
    #x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)
    #x = _transformer_block(x, num_heads, expansion_factor)

    x = _depthwise_conv_block(
        x, 1024, alpha, depth_multiplier, strides=(2, 2), block_id=12)
    #x = _transformer_block(x, num_heads, expansion_factor)
    
    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)
    #x = _transformer_block(x, num_heads, expansion_factor)

    if include_top:
        x = layers.GlobalAveragePooling2D(keepdims=True)(x)
        x = layers.Dropout(dropout, name=""dropout"")(x)
        x = layers.Conv2D(classes, (1, 1), padding=""same"", name=""conv_preds"")(x)
        x = layers.Reshape((classes,), name=""reshape_2"")(x)
        imagenet_utils.validate_activation(classifier_activation, weights)
        x = layers.Activation(
            activation=classifier_activation, name=""predictions""
        )(x)
    else:
        if pooling == ""avg"":
            x = GlobalAveragePooling2D()(x)
        elif pooling == ""max"":
            x = GlobalMaxPooling2D()(x)

    # Ensure that the model takes into account
    # any potential predecessors of `input_tensor`.
    if input_tensor is not None:
        inputs = layer_utils.get_source_inputs(input_tensor)
    else:
        inputs = img_input

    # Create model.
    model = training.Model(inputs, x, name=""mobilenet_%0.2f_%s"" % (alpha, rows))

    # Load weights.
    if weights == ""imagenet"":
        if alpha == 1.0:
            alpha_text = ""1_0""
        elif alpha == 0.75:
            alpha_text = ""7_5""
        elif alpha == 0.50:
            alpha_text = ""5_0""
        else:
            alpha_text = ""2_5""

        if include_top:
            model_name = ""mobilenet_%s_%d_tf.h5"" % (alpha_text, rows)
            weight_path = BASE_WEIGHT_PATH + model_name
            weights_path = data_utils.get_file(
                model_name, weight_path, cache_subdir=""models""
            )
        else:
            model_name = ""mobilenet_%s_%d_tf_no_top.h5"" % (alpha_text, rows)
            weight_path = BASE_WEIGHT_PATH + model_name
            weights_path = data_utils.get_file(
                model_name, weight_path, cache_subdir=""models""
            )
        model.load_weights(weights_path, by_name=True)
    elif weights is not None:
        model.load_weights(weights, by_name=True)

    return model


class MDTA(keras.layers.Layer):
    '''***IMPORTANT*** - The channels must be zero when divided by num_heads'''
    def __init__(self, num_heads):
        super(MDTA, self).__init__()
        self.num_heads = num_heads
        #self.temperature = tf.Variable([[[[1.]] for _ in range(self.num_heads)]], shape=[None, self.num_heads, 1, 1], trainable=True)

    def build(self, inputs):
        '''(N, H, W, C) -> (N, H, W, C)
           Output of MDTA feature should be added to input feature x'''
        b, h, w, c = inputs.shape
        
        # --------------------  Layers  -------------------- 
        qkv = Conv2D(filters=c*3, kernel_size=1, use_bias=False) 
        qkv_conv = Conv2D(c*3, kernel_size=3, padding='same', groups=c*3, use_bias=False)
        project_out = Conv2D(filters=c, kernel_size=1, use_bias=False)

        temperature = tf.Variable([[[[1.]] for _ in range(self.num_heads)]], shape=[None, self.num_heads, 1, 1], trainable=True)
        
        # --------------------  forward  -------------------- 
        q, k, v = tf.split(qkv_conv(qkv(inputs)), num_or_size_splits=3, axis=-1)
        
        # divide the # of channels into heads & learn separate attention map
        q = tf.reshape(q, [-1, self.num_heads, c//self.num_heads, h * w])  # (N, num_heads, C/num_heads, HW)
        k = tf.reshape(k, [-1, self.num_heads, c//self.num_heads, h * w])
        v = tf.reshape(v, [-1, self.num_heads, c//self.num_heads, h * w])
        
        q, k = tf.nn.l2_normalize(q, axis=-1), tf.nn.l2_normalize(k, axis=-1)

        # CxC Attention map instead of HWxHW (when num_heads=1)
        attn = tf.matmul(q, k, transpose_b=True) 
        attn = multiply([attn, temperature])
        attn = Softmax(axis=-1)(attn)
        
        out = tf.matmul(attn, v)
        shape = [tf.shape(out)[k] for k in range(4)]  # [Batch, num_heads, c/num_heads, H*W]
        out = tf.reshape(out,  [shape[0], h, w, shape[1]*shape[2]])
        out = project_out(out)  # attn*v: (N, num_heads, C/num_heads, HW)
        return out
    
    def __call__(self, inputs):
        return self.build(inputs)
    

class GDFN(keras.layers.Layer):
    def __init__(self):
        super(GDFN, self).__init__()
        self.expansion_factor = 2

    def build(self, inputs):
        '''(N, H, W, C) -> (N, H, W, C) with expansion_factor=r
           Output of GDFN feature should be added to input feature x'''
        b, h, w, c = inputs.shape
        hidden_channels = int(c * self.expansion_factor)  # channel expansion 
        
        # --------------------  Layers  -------------------- 
        project_in = Conv2D(hidden_channels * 2, kernel_size=1, use_bias=False)
        conv = Conv2D(hidden_channels * 2, kernel_size=3, padding='same',
                      groups=hidden_channels * 2, use_bias=False)
        project_out = Conv2D(c, kernel_size=1, use_bias=False)
        
        # --------------------  Forward  -------------------- 
        x = project_in(inputs)  # (N, H, W, 2Cr)
        x = conv(x)  # (N, H, W, 2Cr)

        x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)  # (N, H, W, Cr), (N, H, W, Cr)

        # Gating: the element-wise product of 2 parallel paths of linear transformation layers 
        out = ReLU()(x1) * x2  # (N, H, W, Cr)
        out = project_out(out)  # (N, H, W, Cr)
        return out
    
    def __call__(self, inputs):
        return self.build(inputs)
    
    
def _transformer_block(inputs, num_heads, expansion_factor):
    '''(N, H, W, C) -> (N, H, W, C)'''
    
    shape = [tf.shape(inputs)[k] for k in range(4)]
    b, h, w, c = inputs.shape[0], inputs.shape[1], inputs.shape[2], inputs.shape[3]
    assert c % num_heads == 0   

    norm1 = LayerNormalization()  # default: axis=-1
    attn = MDTA(num_heads)
    norm2 = LayerNormalization()
    ffn = GDFN()
        
    # Add MDTA output feature
    inputs_norm1 = norm1(tf.reshape(inputs, [-1, h*w, c]))
    inputs_norm1 = tf.reshape(inputs_norm1, [-1, h, w, c])
        
    inputs = inputs + attn(inputs_norm1)
        
    # ADD GDFN output feature
    inputs_norm2 = norm2(tf.reshape(inputs, [-1, h*w, c]))
    inputs_norm2 = tf.reshape(inputs_norm2, [-1, h, w, c])
        
    x = inputs + ffn(inputs_norm2)
        
    return x
    
    
def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):
    channel_axis = 1 if backend.image_data_format() == ""channels_first"" else -1
    filters = int(filters * alpha)
    x = Conv2D(
        filters,
        kernel,
        padding=""same"",
        use_bias=False,
        strides=strides,
        name=""conv1"",
    )(inputs)
    x = BatchNormalization(axis=channel_axis, name=""conv1_bn"")(x)
    return ReLU(6.0, name=""conv1_relu"")(x)


def _depthwise_conv_block(
    inputs,
    pointwise_conv_filters,
    alpha,
    depth_multiplier=1,
    strides=(1, 1),
    block_id=1,
):
    channel_axis = 1 if backend.image_data_format() == ""channels_first"" else -1
    pointwise_conv_filters = int(pointwise_conv_filters * alpha)

    if strides == (1, 1):
        x = inputs
    else:
        x = ZeroPadding2D(
            ((0, 1), (0, 1)), name=""conv_pad_%d"" % block_id
        )(inputs)
    x = DepthwiseConv2D(
        (3, 3),
        padding=""same"" if strides == (1, 1) else ""valid"",
        depth_multiplier=depth_multiplier,
        strides=strides,
        use_bias=False,
        name=""conv_dw_%d"" % block_id,
    )(x)

    x = BatchNormalization(
        axis=channel_axis, name=""conv_dw_%d_bn"" % block_id
    )(x)
    x = ReLU(6.0, name=""conv_dw_%d_relu"" % block_id)(x)

    x = Conv2D(
        pointwise_conv_filters,
        (1, 1),
        padding=""same"",
        use_bias=False,
        strides=(1, 1),
        name=""conv_pw_%d"" % block_id,
    )(x)
    x = BatchNormalization(
        axis=channel_axis, name=""conv_pw_%d_bn"" % block_id
    )(x)
    return ReLU(6.0, name=""conv_pw_%d_relu"" % block_id)(x)


def gen_mobilenetv1_mdta(input_shape, dropout_rate, num_class):
    if input_shape==(224, 224, 3):
        weights = 'imagenet'
    else:
        weights = None
        
    base_model = MobileNet(weights=weights,
                           include_top=False, 
                           input_tensor=Input(input_shape),
                           input_shape=input_shape)
    
    base_model.trainable = True
    x = base_model.output
    head_layer = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(name='simple_classifier_pooling'),
                         tf.keras.layers.Dropout(dropout_rate, name='simple_classifier_dropout'),
                         tf.keras.layers.Dense(512, activation='relu', name='simple_classifier_dense1'),
                         tf.keras.layers.Dense(num_class, activation='softmax'),])
    predictions = head_layer(x)

    # this is the model we will train
    model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)
    #print(model)
    return model

input_shape = (768, 768, 3)
x = Input(input_shape)
model = gen_mobilenetv1_mdta(input_shape, 0.3, 6)
out = model(x)

save_path = 'D:/model_mdta.h5'
model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc'])
model.save(save_path )
 
```


### Relevant log output

In the vscode-terminal

```shell
AssertionError: Tried to export a function which references an 'untracked' resource. TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly. See the information below:
        Function name = b'__inference_signature_wrapper_18418'
        Captured Tensor = <ResourceHandle(name=""Resource-40-at-0x55f74d07bcf0"", device=""/job:localhost/replica:0/task:0/device:CPU:0"", container=""Anonymous"", type=""tensorflow::Var"", dtype and shapes : ""[ DType enum: 1, Shape: [?,4,1,1] ]"")>
        Trackable referencing this tensor = <tf.Variable 'Variable:0' shape=(None, 4, 1, 1) dtype=float32>
        Internal Tensor = Tensor(""18172:0"", shape=(), dtype=resource)

During handling of the above exception, another exception occurred:
```

In the Jupyter-Noetebook

```shell
ValueError                                Traceback (most recent call last)
/tmp/ipykernel_828829/1178680124.py in <module>
      1 model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc'])
----> 2 model.save('D:/model_mdta.h5')

~/conda/envs/hrvi2/lib/python3.8/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
     68             # To get the full stack trace, call:
     69             # `tf.debugging.disable_traceback_filtering()`
---> 70             raise e.with_traceback(filtered_tb) from None
     71         finally:
     72             del filtered_tb

~/conda/envs/hrvi2/lib/python3.8/json/encoder.py in encode(self, o)
    197         # exceptions aren't as detailed.  The list call should be roughly
    198         # equivalent to the PySequence_Fast that ''.join() would do.
--> 199         chunks = self.iterencode(o, _one_shot=True)
    200         if not isinstance(chunks, (list, tuple)):
    201             chunks = list(chunks)

~/conda/envs/hrvi2/lib/python3.8/json/encoder.py in iterencode(self, o, _one_shot)
    255                 self.key_separator, self.item_separator, self.sort_keys,
    256                 self.skipkeys, _one_shot)
--> 257         return _iterencode(o, 0)
    258 
    259 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,

ValueError: Unable to serialize VariableSpec(shape=(None, 4, 1, 1), dtype=tf.float32, trainable=True, alias_id=None) to JSON, because the TypeSpec class <class 'tensorflow.python.ops.resource_variable_ops.VariableSpec'> has not been registered.
```


"
tensorflow/tensorflow,2023-07-19 12:44:33,bug,Could not load dynamic library 'libcublasLt.so.12'; dlerror: libcublasLt.so.12: cannot open shared object file: No such file or directory,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

v2.13.0-rc2-7-g1cb1a030a62 2.13.0

### Custom code

No

### OS platform and distribution

Linux Ubuntu 23.10

### Mobile device

_No response_

### Python version

3.11

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

11.8.0-1/8.9.3.28-1+cuda12.1

### GPU model and memory

NVIDIA GeForce GTX 960M, 4096MiB

### Current behavior?

running the mobilenet from keras included by tensorflow leads to the following error:
```
Could not load library libcublasLt.so.12. Error: libcublasLt.so.12: cannot open shared object file: No such file or directory                                                         
Abgebrochen (Speicherabzug geschrieben)
```

### Standalone code to reproduce the issue

```shell
python -c 'from tensorflow.keras.applications.mobilenet import MobileNet; import numpy as np; m = MobileNet(); m.predict(np.zeros((32,224,224,3)))'
```


### Relevant log output

```shell
Could not load library libcublasLt.so.12. Error: libcublasLt.so.12: cannot open shared object file: No such file or directory                                                         
Abgebrochen (Speicherabzug geschrieben)
```
"
tensorflow/tensorflow,2023-07-17 23:41:39,bug,TensorFlow distributed training works for at most 2 GPUs,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

2.12.0

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.9.16

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.8, cuDNN 8.6.0.163

### GPU model and memory

_No response_

### Current behavior?

I have 8 NVIDIA H100s on this system. Below is the output of `nvidia-smi`.
![image](https://github.com/tensorflow/tensorflow/assets/77916424/7d027250-8312-4503-bf98-14b6d2aa0db9)

The following code works as intended if `gpus` includes at most 2 GPUs.
![image](https://github.com/tensorflow/tensorflow/assets/77916424/47f78e02-e92e-47cc-814b-4ddcba433a8b)

In the ""Relevant log output"" section, I have the error log from running the code with 3 GPUs in the `gpus` list.

Please let me know if you need any additional information!

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
gpus = [""/gpu:0"", ""/gpu:1"", ""/gpu:2""]
strategy = tf.distribute.MirroredStrategy(gpus)
with strategy.scope():
    model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
model.compile(loss=""mse"", optimizer=""sgd"")
dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(16)
model.fit(dataset)
```


### Relevant log output

```shell
2023-07-17 23:28:31.469519: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-07-17 23:28:31.516738: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-17 23:28:31.972313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-07-17 23:28:35.178825: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:35.181183: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:35.183528: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:35.185905: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:35.188234: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:35.190559: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:35.192895: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:35.195198: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.609484: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.610685: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.611908: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.613166: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.614370: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.615584: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.616799: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.617975: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2048] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2023-07-17 23:28:36.680264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78938 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:19:00.0, compute capability: 9.0
2023-07-17 23:28:36.682112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78938 MB memory:  -> device: 1, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:3b:00.0, compute capability: 9.0
2023-07-17 23:28:36.683772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78938 MB memory:  -> device: 2, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:4c:00.0, compute capability: 9.0
2023-07-17 23:28:36.685499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78938 MB memory:  -> device: 3, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:5d:00.0, compute capability: 9.0
2023-07-17 23:28:36.687179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 78938 MB memory:  -> device: 4, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:9b:00.0, compute capability: 9.0
2023-07-17 23:28:36.688884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 78938 MB memory:  -> device: 5, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:bb:00.0, compute capability: 9.0
2023-07-17 23:28:36.690581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 78938 MB memory:  -> device: 6, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:cb:00.0, compute capability: 9.0
2023-07-17 23:28:36.692292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 78938 MB memory:  -> device: 7, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:db:00.0, compute capability: 9.0
2023-07-17 23:28:39.806560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1]
         [[{{node Placeholder/_1}}]]
2023-07-17 23:28:39.806723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1]
         [[{{node Placeholder/_0}}]]
2023-07-17 23:28:39.807452: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: ""TensorDataset/_2""
op: ""TensorDataset""
input: ""Placeholder/_0""
input: ""Placeholder/_1""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: ""_cardinality""
  value {
    i: 1
  }
}
attr {
  key: ""metadata""
  value {
    s: ""\\n\\017TensorDataset:0""
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 1
        }
      }
      shape {
        dim {
          size: 1
        }
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
}

2023-07-17 23:28:39.823305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1]
         [[{{node Placeholder/_1}}]]
2023-07-17 23:28:39.823469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1]
         [[{{node Placeholder/_1}}]]
2023-07-17 23:28:40.010671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1]
         [[{{node Placeholder/_1}}]]
2023-07-17 23:28:40.010843: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [1]
         [[{{node Placeholder/_0}}]]
2023-07-17 23:28:48.599915: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fe600008ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-17 23:28:48.599956: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.599964: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.599971: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (2): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.599977: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (3): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.599983: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (4): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.599988: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (5): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.599994: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (6): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.600003: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (7): NVIDIA H100 80GB HBM3, Compute Capability 9.0
2023-07-17 23:28:48.636269: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-07-17 23:28:48.636335: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:438] Possibly insufficient driver version: 535.54.3
2023-07-17 23:28:48.649063: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-07-17 23:28:48.649131: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:438] Possibly insufficient driver version: 535.54.3
2023-07-17 23:28:48.711026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600
2023-07-17 23:28:48.712282: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
*** Begin stack trace ***
        tsl::CurrentStackTrace[abi:cxx11]()

        xla::status_macros::MakeErrorStream::Impl::GetStatus()
        xla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)
        xla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)
        xla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)
        xla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        xla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        tensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)

        tensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)
        tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)


        Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)
        std::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)



*** End stack trace ***

2023-07-17 23:28:48.712483: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
2023-07-17 23:28:48.712506: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
         [[{{node update_0_1/StatefulPartitionedCall}}]]
2023-07-17 23:28:48.727426: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
*** Begin stack trace ***
        tsl::CurrentStackTrace[abi:cxx11]()

        xla::status_macros::MakeErrorStream::Impl::GetStatus()
        xla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)
        xla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)
        xla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)
        xla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        xla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        tensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)

        tensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)
        tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)


        Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)
        std::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)



*** End stack trace ***

2023-07-17 23:28:48.727590: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
2023-07-17 23:28:48.727609: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:1] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
         [[{{node update_1_1/StatefulPartitionedCall}}]]
2023-07-17 23:28:48.728128: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-07-17 23:28:48.728185: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:438] Possibly insufficient driver version: 535.54.3
2023-07-17 23:28:48.740946: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 9.0
2023-07-17 23:28:48.740965: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas
2023-07-17 23:28:48.742906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2023-07-17 23:28:48.742961: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:438] Possibly insufficient driver version: 535.54.3
2023-07-17 23:28:48.770994: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-07-17 23:28:48.806579: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
*** Begin stack trace ***
        tsl::CurrentStackTrace[abi:cxx11]()

        xla::status_macros::MakeErrorStream::Impl::GetStatus()
        xla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)
        xla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)
        xla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)
        xla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        xla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        tensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)

        tensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)
        tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)


        Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)
        std::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)



*** End stack trace ***

2023-07-17 23:28:48.806809: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
2023-07-17 23:28:48.818268: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
*** Begin stack trace ***
        tsl::CurrentStackTrace[abi:cxx11]()

        xla::status_macros::MakeErrorStream::Impl::GetStatus()
        xla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)
        xla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)
        xla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)
        xla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        xla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
        tensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)
        tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)

        tensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)
        tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)


        Eigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)
        std::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)



*** End stack trace ***

2023-07-17 23:28:48.818437: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
2023-07-17 23:28:48.858099: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:2] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
         [[{{node update_0_1/StatefulPartitionedCall}}]]
         [[GroupCrossDeviceControlEdges_1/Identity_7/_166]]
Traceback (most recent call last):
  File ""/home/user4/project/src/test.py"", line 8, in <module>
    model.fit(dataset)
  File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InternalError: Graph execution error:

Detected at node 'update_1_1/StatefulPartitionedCall' defined at (most recent call last):
    File ""/home/user4/project/src/test.py"", line 8, in <module>
      model.fit(dataset)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1284, in train_function
      return step_function(self, iterator)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py"", line 1250, in _distributed_apply_gradients_fn
      distribution.extended.update(
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py"", line 1245, in apply_grad_to_update_var
      return self._update_step_xla(grad, var, id(self._var_key(var)))
Node: 'update_1_1/StatefulPartitionedCall'
Detected at node 'update_0_1/StatefulPartitionedCall' defined at (most recent call last):
    File ""/home/user4/project/src/test.py"", line 8, in <module>
      model.fit(dataset)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1284, in train_function
      return step_function(self, iterator)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py"", line 1250, in _distributed_apply_gradients_fn
      distribution.extended.update(
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py"", line 1245, in apply_grad_to_update_var
      return self._update_step_xla(grad, var, id(self._var_key(var)))
Node: 'update_0_1/StatefulPartitionedCall'
Detected at node 'update_0_1/StatefulPartitionedCall' defined at (most recent call last):
    File ""/home/user4/project/src/test.py"", line 8, in <module>
      model.fit(dataset)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1685, in fit
      tmp_logs = self.train_function(iterator)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1284, in train_function
      return step_function(self, iterator)
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py"", line 1268, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py"", line 1250, in _distributed_apply_gradients_fn
      distribution.extended.update(
    File ""/home/user4/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py"", line 1245, in apply_grad_to_update_var
      return self._update_step_xla(grad, var, id(self._var_key(var)))
Node: 'update_0_1/StatefulPartitionedCall'
3 root error(s) found.
  (0) INTERNAL:  RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
         [[{{node update_1_1/StatefulPartitionedCall}}]]
  (1) INTERNAL:  RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
         [[{{node update_0_1/StatefulPartitionedCall}}]]
         [[GroupCrossDeviceControlEdges_1/Identity_7/_166]]
  (2) INTERNAL:  RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr
         [[{{node update_0_1/StatefulPartitionedCall}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_1810]
```
"
tensorflow/tensorflow,2023-07-16 03:39:41,bug,The return value when LayerNormalization takes zero vectors as input,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf2.12.0

### Custom code

Yes

### OS platform and distribution

MacOs

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

#### Output

```
tf.Tensor(
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)
tf.Tensor(
[[nan nan nan nan]
 [nan nan nan nan]
 [nan nan nan nan]], shape=(3, 4), dtype=float32)
tf.Tensor(
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)
```

#### Document

epsilon is used to avoid division by zero errors, but when LayerNormalization takes a zero vector as input, it returns nan, and BatchNormalization returns 0

（p.s.epsilon is documented as a small floating-point number.In our experiments, we found that epsilon works with larger floating-point numbers.Is this a bit vague?）

### Standalone code to reproduce the issue

```shell
#### Standalone code


import tensorflow as tf
data = tf.zeros(shape=(3, 4))
print(data)

layer1 = tf.keras.layers.LayerNormalization(axis=1, epsilon=0)
output1 = layer1(data)
print(output1)

layer2 = tf.keras.layers.BatchNormalization(axis=1, epsilon=0)
output2 = layer2(data)
print(output2)
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-15 04:12:59,bug,`tf.math.reduce_sum`'s `name` property doesn't change in `model.compile`,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.13

### Custom code

No

### OS platform and distribution

Linux Ubuntu 18.04.6 LTS

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

```
...
out = tf.math.reduce_sum(tf.cast(position> 0.5, tf.float32), axis=-1, keepdims=True, name='final')
model = models.Model(inputs=input_, outputs=[position, out])

model.summary()

=============================================================
...
tf.math.reduce_sum (TFOpLambda  (None, 1)           0           ['tf.cast[0][0]']                 )   
==============================================================
```

### Standalone code to reproduce the issue

```shell
input_ = layers.Input(shape=(3))
position = layers.Dense(5, 'sigmoid', name='position')(input_)
out = tf.math.reduce_sum(tf.cast(position> 0.5, tf.float32), axis=-1, keepdims=True, name='final')
model = models.Model(inputs=input_, outputs=[position, out])

model.summary()
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-14 08:34:09,bug,can't save compiled model as .tf,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13.0

### Custom code

Yes

### OS platform and distribution

Mac mini m1

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

m1 gpu and 8GB Ram

### Current behavior?

can't save compile model as a .tf file.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf


class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __init__(self, d_model, f=0.5, warmup_steps=4_000):
        super().__init__()

        self.d_model = d_model
        self.d_model = tf.cast(self.d_model, tf.float32)

        self.warmup_steps = warmup_steps
        self.f = f

    def __call__(self, step):
        step = tf.cast(step, dtype=tf.float32)
        arg1 = tf.math.rsqrt(step)
        arg2 = step * (self.warmup_steps ** -1.5)

        return self.f * tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)

    def get_config(self):
        config = {
            ""d_model"": self.d_model,
            ""warmup_steps"": self.warmup_steps,
            ""f"": self.f
        }
        return config


model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(784,)),
    tf.keras.layers.Dense(10)
])
learning_rate = CustomSchedule(1024)
optimizer = tf.keras.optimizers.legacy.Adam(learning_rate, beta_1=0.9, beta_2=0.98,
                                            epsilon=1e-5)
model.compile(
    optimizer=optimizer,
    loss=""mse"", metrics=['accuracy'])
model.save(""model.tf"")
```


### Relevant log output

```shell
/opt/homebrew/Caskroom/miniconda/base/envs/pythonProject/bin/python /Users/albert/PycharmProjects/pythonProject/AI/test.py 
Traceback (most recent call last):
  File ""/Users/albert/PycharmProjects/pythonProject/AI/test.py"", line 40, in <module>
    model.save(""model.tf"")
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/pythonProject/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/pythonProject/lib/python3.10/json/encoder.py"", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/pythonProject/lib/python3.10/json/encoder.py"", line 257, in iterencode
    return _iterencode(o, 0)
TypeError: Unable to serialize 1024.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.
```
"
tensorflow/tensorflow,2023-07-13 06:22:06,bug,Segmentation fault  ,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tensorflow/tensorflow:latest-gpu-jupyter

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

 python train.py --X ../../data/train2_x.npy --Y ../../data/train2_y.npy

### Standalone code to reproduce the issue

```shell
Segmentation fault  
but I use tensorflow:2.12.0  This problem does not occur
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-12 13:38:32,bug,The required input dimension and type changed after conversion of SAC algorithm,"### 1. System information

- OS Platform and Distribution : Linux Ubuntu 22.04
- TensorFlow installation : Pip Package
- TensorFlow library: Tensorflow 2.12.1

### 2. Code
most of them I followed the SAC Minitaur tutorial here https://www.tensorflow.org/agents/tutorials/7_SAC_minitaur_tutorial but with some modification to fit with my environment, also with additional function to convert to TFLite 
https://colab.research.google.com/drive/1Eea5Fi861_h3TzH1eGUaP-H9dSPBn3OJ?usp=sharing

### 3. Failure after conversion
The Observation Spec reduced and changed from shape (5,), float32 to shape[1], int32 in this conversion

> Observation Spec:
BoundedArraySpec(shape=(5,), dtype=dtype('float32'), name='observation', minimum=0.0, maximum=1.0)
Reward Spec:
ArraySpec(shape=(), dtype=dtype('float32'), name='reward')
Action Spec:
BoundedArraySpec(shape=(1,), dtype=dtype('float32'), name='action', minimum=-0.6000000238418579, maximum=0.6000000238418579)
Time step:
TimeStep(
{'discount': array(1., dtype=float32),
 'observation': array([0.09387773, 0.45744053, 0.8837498 , 0.84389937, 0.5       ],
      dtype=float32),
 'reward': array(0., dtype=float32),
 'step_type': array(0, dtype=int32)}) 
step = 0: AverageReturn = 0.000758, AverageEpisodeLength = 120.449997
step = 100: loss = -0.29556670784950256
step = 200: loss = -0.42344561219215393
step = 300: loss = -0.4886786639690399
step = 400: loss = -0.5600587129592896
step = 500: loss = -0.6421032547950745
step = 600: loss = -0.7184216380119324
step = 700: loss = -0.785315752029419
step = 800: loss = -0.8600273728370667
step = 900: loss = -0.9031595587730408
step = 1000: AverageReturn = 1.299191, AverageEpisodeLength = 115.500000
step = 1000: loss = -0.990966796875  
Policy Saved at  /home/erde/minipads/sim/experiment/RL_Ctler/tf_exp/temp_sac/policy
#################### Convert to TFlite
Input shape: {'arg_0_discount': TensorSpec(shape=(None,), dtype=tf.float32, name='0/discount'), 'arg_0_observation': TensorSpec(shape=(None, 5), dtype=tf.float32, name='0/observation'), 'arg_0_reward': TensorSpec(shape=(None,), dtype=tf.float32, name='0/reward'), 'arg_0_step_type': TensorSpec(shape=(None,), dtype=tf.int32, name='0/step_type')}
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
Input details: 
 [{'name': 'action_0_step_type:0', 'index': 0, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'action_0_discount:0', 'index': 1, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'action_0_observation:0', 'index': 2, 'shape': array([1, 5], dtype=int32), 'shape_signature': array([-1,  5], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'action_0_reward:0', 'index': 3, 'shape': array([1], dtype=int32), 'shape_signature': array([-1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
Output details: 
 [{'name': 'StatefulPartitionedCall:0', 'index': 92, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
Input data: 
 [0]
Input shape: [1]
Output data: 
 [[-0.6]]

- The converted model has less dimension input and different input type required
"
tensorflow/tensorflow,2023-07-11 19:30:47,bug,AttributeError: module 'tensorflow_datasets' has no attribute 'load',"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.10.0


### OS platform and distribution

Windows 11

### Mobile device

_No response_

### Python version

3.10.12

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I cannot access [UCF101](https://www.tensorflow.org/datasets/catalog/ucf101) and download.

TensorFlow 2.10
Python 3.11.12
tensorflow_datasets 4.9.2

### Standalone code to reproduce the issue

```shell
import tensorflow_datasets
ucf101 = tensorflow_datasets.video.ucf101.Ucf101()
```


### Relevant log output

```shell
AttributeError: module 'tensorflow_datasets' has no attribute 'load'
```
"
tensorflow/tensorflow,2023-07-11 02:45:10,bug,tf.data train model worse than numpy data,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.10

### Custom code

Yes

### OS platform and distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

12.0

### GPU model and memory

_No response_

### Current behavior?
**1. Used tf.data train model best val loss is 0.14, and the code is:**
![image](https://github.com/tensorflow/tensorflow/assets/15938790/36ab9474-3a88-47ba-9226-675f3dfeb11a)

```
train_dataset1 = tf.data.Dataset.from_tensor_slices((np.array(xtrain).reshape(-1,10*12,1),np.array(encoder_train),np.array(decoder_train)))
train_dataset2 = tf.data.Dataset.from_tensor_slices((np.array(ytrain)))
train_dataset = tf.data.Dataset.zip((train_dataset1, train_dataset2))
test_dataset1 = tf.data.Dataset.from_tensor_slices((np.array(xtest).reshape(-1,10*12,1),np.array(encoder_test),np.array(decoder_test)))
test_dataset2 = tf.data.Dataset.from_tensor_slices((np.array(ytest)))
test_dataset = tf.data.Dataset.zip((test_dataset1, test_dataset2))

BATCH_SIZE = 256
SHUFFLE_BUFFER_SIZE = 1000

train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)

model = Model(inputs = inputs, outputs = s2s)
model.compile(loss = 'mse', optimizer='adam', metrics=['mape'])
early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)
model.fit(train_dataset, epochs=20, #batch_size=256, 
          validation_data = test_dataset, callbacks=[early_stopping])
```


**2. Used numpy array train model best val loss is 0.10, the code is:**
![image](https://github.com/tensorflow/tensorflow/assets/15938790/a9eec3fc-cdfe-4380-836d-7b047ab2580c)


```
model = Model(inputs = inputs, outputs = s2s)
model.compile(loss = 'mse', optimizer='adam', metrics=['mape'])
early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)
model.fit([np.array(xtrain).reshape(-1,10*12,1),np.array(encoder_train),np.array(decoder_train)], np.array(ytrain), epochs=20, batch_size=256, 
          validation_data = ([np.array(xtest).reshape(-1,10*12,1),np.array(encoder_test),np.array(decoder_test)], np.array(ytest)), callbacks=[early_stopping])
```

**3. tf.data.Dataset.from_generator val loss worse more:**

### Standalone code to reproduce the issue

```shell
tf.data bugs at version 2.10
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-10 14:20:47,bug,site/en/guide/create_op.md example code has memory leak,"### Issue type

Documentation Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

tf 2.6.5

### Custom code

Yes

### OS platform and distribution

linux centos 7.6

### Mobile device

linux centos 7.6

### Python version

3.7

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?


In the demo code, Tensor* **output_tensor** was allocated but the memory was not free

`#include ""tensorflow/core/framework/op_kernel.h""

using namespace tensorflow;

class ZeroOutOp : public OpKernel {
 public:
  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor& input_tensor = context->input(0);
    auto input = input_tensor.flat<int32>();

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),
                                                     &output_tensor));
    auto output_flat = output_tensor->flat<int32>();

    // Set all but the first element of the output tensor to 0.
    const int N = input.size();
    for (int i = 1; i < N; i++) {
      output_flat(i) = 0;
    }

    // Preserve the first input value if possible.
    if (N > 0) output_flat(0) = input(0);
  }
};`

### Standalone code to reproduce the issue

```shell
Repeatedly call the ZeroOutOp. You'll see the memory continue to increase
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-08 08:45:59,bug,tf.image.adjust_gamma outputs incorrect error message for string input,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.12.0

### Custom code

Yes

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

When giving tf.image.adjust_gamma a string inputs, it outputs misleading error messages:
```
ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).
```

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
t = tf.constant([], dtype=tf.string)
i = tf.image.adjust_gamma(t, gamma=0.1)
```
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-07 21:53:46,bug,DistributedDatasetInterface is not an attribute of input_lib - engine\\data_adapter.py,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.13

### Custom code

No

### OS platform and distribution

_No response_

### Mobile device

_No response_

### Python version

3.10.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I'm new to machine learning and I was setting up this network with just one layer, with only one neuron inside it, just to see how it works. Setting up went fine. The error occured when I asked it to predict.

I'm not sure what exactly happend, but apparently, a non existent attribute (`input_lib.DistributedDatasetInterface`) was passed to `isinstance()` in the file: ...\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py (line 1699).

I've replaced by the wrong one by the one suggested and worked as expected.

### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
from tensorflow.python.keras.layers import Dense, Input
from tensorflow.python.keras import Sequential
from tensorflow.python.keras.activations import sigmoid

import logging
logging.getLogger(""tensorflow"").setLevel(logging.ERROR)
tf.autograph.set_verbosity(0)

X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)
Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)

model = Sequential([
    Input(shape=(1,)),
    Dense(1, activation=sigmoid, name = ""L1"")
])
model.summary()

# Setting the weights and bias of the neuron
logistic_layer = model.get_layer('L1')
set_w = np.array([[2]])
set_b = np.array([-4.5])
logistic_layer.set_weights([set_w, set_b])

# Performance test
a1 = model.predict(X_train[0].reshape(1,1)) # this line caused the error
print(a1)
alog = sigmoid(np.dot(set_w,X_train[0].reshape(1,1)) + set_b)
print(alog)
```


### Relevant log output

```shell
...\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py"", line 1699, in _is_distributed_dataset
    return isinstance(ds, input_lib.DistributedDatasetInterface)
AttributeError: module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'. Did you mean: 'DistributedDatasetSpec'?
```
"
tensorflow/tensorflow,2023-07-07 05:11:51,bug,My customized OP gives incorrect outputs on GPUs since `tf-nightly 2.13.0.dev20230413`,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

binary

### TensorFlow version

2.13

### Custom code

Yes

### OS platform and distribution

fedora 36

### Mobile device

_No response_

### Python version

3.11.4

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

I have a complex program based on TensorFlow with several customized OPs. These OPs were created following https://www.tensorflow.org/guide/create_op. Yesterday TF 2.13.0 was released, but after I upgraded to 2.13.0, I found that one of my customized OP gives incorrect results on GPUs and still has the correct outputs on CPUs.

Then I tested many `tf-nightly` versions and found that `tf-nightly 2.13.0.dev20230412` works but `tf-nightly 2.13.0.dev20230413` fails. So the situation is shown in the following table:
| version | CPU       | GPU          |
| -------- | --------- | ----------- |
| tensorflow 2.12.0 | Correct  | Correct      |
| tensorflow 2.13.0 | Correct  | Incorrect   |
| tf-nightly  2.13.0.dev20230412 | Correct  | Correct      |
| tf-nightly  2.13.0.dev20230413 | Correct      | Incorrect   |

I'd like to know what changed between April 12th and 13th related to the customized OPs. This can be a breaking change to downstream applications or an internal bug. Thanks!

Here is a quick link for commits between April 12th and 13th:
https://github.com/tensorflow/tensorflow/commits/master?before=525da8a93eca846e32e5c41eddc0496b25a2ef5b+770


### Standalone code to reproduce the issue

```shell
Indeed, the reason is still unclear to me, so it is hard to create a minimal example.

The code of our customized OPs is https://github.com/deepmodeling/deepmd-kit/blob/37fd8d193362f91c925cf7c2f3a58b97dc921b27/source/op/prod_force_multi_device.cc#L49-L166
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-05 20:01:55,bug,Python 3.7.0 is incompitable with tensorflow 2.11.0 ,"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

2.11.0

### Custom code

Yes

### OS platform and distribution

Windows 10 Educion

### Mobile device

_No response_

### Python version

3.7.0

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

![image](https://github.com/tensorflow/tensorflow/assets/7984605/ad719afa-c5bf-4d3d-ba06-5f73d914785f)
Python 3.7.0 throws an exception that it cannot import OrderedDict from typings. The fix was downgrading from tensorflow 2.11.0 to tensorflow 2.10.0. 

- Orderd Dict is supported starting from python 3.7.2: https://docs.python.org/3.7/library/typing.html#typing.OrderedDict
- By default pip installs 2.11.0 for python 3.7.0 which is not supported
- The doc  states that 3.7.0 is supported: https://www.tensorflow.org/install/source#tested_build_configurations

### Standalone code to reproduce the issue

```shell
1) Install python 3.7.0
2) pip install tensorflow==2.11.0
3) inside python shell type: import tensorflow as tf
4) Exception will rise
```


### Relevant log output

_No response_"
tensorflow/tensorflow,2023-07-03 12:28:21,bug,"tf.data Dataset: Warning when caching validation set. ""You should use `dataset.take(k).cache().repeat()` instead.""","### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

source

### TensorFlow version

tf 2.9.0

### Custom code

Yes

### OS platform and distribution

Ubuntu 22.04 LTS

### Mobile device

_No response_

### Python version

3.9.5

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

cuda_11.3.r11.3/compiler.29920130_0

### GPU model and memory

NVIDIA A100-SXM4-80GB

### Current behavior?

Whenever I use the cache function on my tf.data validation dataset I get the warning below. When I use the cache only and without the validation set, no warning appears.

### Standalone code to reproduce the issue

```shell
dataset = tf.data.Dataset.from_generator(pygen.generator, args=[files,minmax],output_signature=(
    tf.TensorSpec(shape=s[0], dtype=tf.float32),
    tf.TensorSpec(shape=s[1], dtype=tf.float32)))

    val_dataset = tf.data.Dataset.from_generator(pygen.generator, args=[val_files,minmax],output_signature=(
    tf.TensorSpec(shape=s[0], dtype=tf.float32),
    tf.TensorSpec(shape=s[1], dtype=tf.float32)))
dataset = dataset.take(len(files)).cache().batch(args.bs).repeat(args.epochs).prefetch(tf.data.AUTOTUNE) 
    
val_dataset = val_dataset.take(len(val_files)).cache(filename=f'{tempfile.gettempdir()}/val').batch(64).repeat(args.epochs).prefetch(tf.data.AUTOTUNE)
strategy = tf.distribute.MultiWorkerMirroredStrategy()
        with strategy.scope():
            m = unet28.build(s[0])
            m.fit(dataset,validation_data=val_dataset, epochs=args.ep, steps_per_epoch = spe,validation_steps = vspe,callbacks=[model_checkpoint_callback,save50,model_csv_logger,model_tensorboard,model_earlystopping_30],verbose=2)
```


### Relevant log output

```shell
2023-07-03 13:47:14.532355: W tensorflow/core/kernels/data/cache_dataset_ops.cc:296] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
```
"
tensorflow/tensorflow,2023-07-01 10:11:36,bug,Not correct result from tf.split(),"### Issue type

Bug

### Have you reproduced the bug with TensorFlow Nightly?

No

### Source

binary

### TensorFlow version

tf 2.8-2.9-2.10

### Custom code

No

### OS platform and distribution

Both on Mac and on Ubuntu

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current behavior?

Tryng to split a four axes tensor, I got some unexpected zeros in the splitted tensors.
This behaviour is not presented in the tf 2.12. Is an old bug?

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

vec=tf.ones((1,768,3,1400))
splitted=tf.split(vec,[256,512],axis=1)
print(splitted) ##zeros have occured in the tensor
```


### Relevant log output

```shell
No
```
"
tensorflow/tensorflow,2023-06-29 08:49:35,bug,"` #include ""include/float8.h""  // from @ml_dtypes` is missing","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.14.0

### Custom Code

Yes

### OS Platform and Distribution

docker/tensorflow/tensorflow:nightly-gpu

### Mobile device

No

### Python version

3.8

### Bazel version

NA

### GCC/Compiler version

NR

### CUDA/cuDNN version

NR

### GPU model and memory

NR

### Current Behaviour?

create a test.cc:
```
#include ""tensorflow/core/framework/op.h""
```
compile it with flags provided by TensorFlow:
get_compile_flags():
```-I/usr/local/lib/python3.8/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1 --std=c++17 -DEIGEN_MAX_ALIGN_BYTES=64```
get_link_flags():
```-L/usr/local/lib/python3.8/dist-packages/tensorflow -l:libtensorflow_framework.so.2```

```g++ -Wl,-R,'$ORIGIN/..' -Wl,-rpath,'$ORIGIN' --std=c++17 -DNDEBUG -shared  test.cc -o /tmp/test.so -fPIC -I/usr/local/lib/python3.8/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=1 --std=c++17 -DEIGEN_MAX_ALIGN_BYTES=64 -I/usr/include -I/usr/local/cuda/include -L/usr/local/lib/python3.8/dist-packages/tensorflow -l:libtensorflow_framework.so.2  -O2```

The result is:
```
      In file included from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/tsl/platform/types.h:22,
                       from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/tsl/framework/numeric_types.h:22,
                       from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/numeric_types.h:24,
                       from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/bfloat16.h:19,
                       from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/types.h:24,
                       from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/op_def_builder.h:28,
                       from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/full_type_inference_util.h:24,
                       from /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/core/framework/op.h:27,
                       from /tmp/pip-req-build-88874pcq/daliop.cc:19:
      /usr/local/lib/python3.8/dist-packages/tensorflow/include/tensorflow/tsl/platform/float8.h:19:10: fatal error: include/float8.h: No such file or directory
         19 | #include ""include/float8.h""  // from @ml_dtypes
```
It is probably caused by [this PR](https://github.com/tensorflow/tensorflow/commit/ef1ea4f5c5c36209b6bd56a99fdd71e5052f6d63).

Either tensorflow/tsl/platform/float8.h should have `#include ""external/ml_dtypes/include/float8.h""  // from @ml_dtypes`, or `get_compile_flags()` should include `-I/usr/local/lib/python3.8/dist-packages/tensorflow/include/external/ml_dtypes`

### Standalone code to reproduce the issue

```shell
As above
```


### Relevant log output

```shell
As above
```
</details>"
tensorflow/tensorflow,2023-06-27 22:31:32,bug,Model running on CPU when using NNAPI even with NnApiDelegate.Options().useNnapiCpu = false,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

tensorflow-lite 2.12.0

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

Google Pixel 7

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I am running the OpenAI whisper tiny model on Android using the TensorFlow Lite NNAPI delegate. It seems to be running on the CPU instead of the hardware accelerator on the Google Pixel 7 even though ""NnApiDelegate.Options().useNnapiCpu = false"" is set.

### Standalone code to reproduce the issue

```shell
NnApiDelegate.Options().useNnapiCpu = false
```


### Relevant log output

```shell
W  Access denied finding property ""ro.mediatek.platform""
W  Access denied finding property ""ro.chipname""
W  Access denied finding property ""ro.hardware.chipname""
I  Created TensorFlow Lite XNNPACK delegate for CPU.
```
</details>"
tensorflow/tensorflow,2023-06-27 09:35:46,bug,NoClassDefFoundError: GpuDelegateFactory$Options not found,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

False

### Source

source

### Tensorflow Version

TF2.12

### Custom Code

Yes

### OS Platform and Distribution

Android 12

### Mobile device

Android 12

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

The GPU is not being used correctly.

### Standalone code to reproduce the issue

```shell
implementation 'org.tensorflow:tensorflow-lite:2.12.0'
 implementation 'org.tensorflow:tensorflow-lite-gpu:2.12.0'

Interpreter.Options options = new Interpreter.Options();
options.addDelegate(new GpuDelegate());

File file = new File(getFilesDir().getAbsolutePath()+""/movenet_thunder.tflite"");
Interpreter interpreter = new Interpreter(file, options);
```


### Relevant log output

```shell
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.litesnap.open.flow.diffusion, PID: 13553
    java.lang.NoClassDefFoundError: Failed resolution of: Lorg/tensorflow/lite/gpu/GpuDelegateFactory$Options;
        at org.tensorflow.lite.gpu.GpuDelegate.<init>(GpuDelegate.java:53)
        at com.litesnap.open.flow.diffusion.MainActivity$1.onClick(MainActivity.java:27)
        at android.view.View.performClick(View.java:7792)
        at android.widget.TextView.performClick(TextView.java:16112)
        at com.google.android.material.button.MaterialButton.performClick(MaterialButton.java:1131)
        at android.view.View.performClickInternal(View.java:7769)
        at android.view.View.access$3800(View.java:910)
        at android.view.View$PerformClick.run(View.java:30218)
        at android.os.Handler.handleCallback(Handler.java:938)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loopOnce(Looper.java:226)
        at android.os.Looper.loop(Looper.java:313)
        at android.app.ActivityThread.main(ActivityThread.java:8663)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:567)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1135)
     Caused by: java.lang.ClassNotFoundException: Didn't find class ""org.tensorflow.lite.gpu.GpuDelegateFactory$Options"" on path: DexPathList[[zip file ""/data/app/~~oMimw9IoQp1ajJTsKEnrxQ==/com.litesnap.open.flow.diffusion-s0YwqVUhGU20kZbxCKdqXw==/base.apk""],nativeLibraryDirectories=[/data/app/~~oMimw9IoQp1ajJTsKEnrxQ==/com.litesnap.open.flow.diffusion-s0YwqVUhGU20kZbxCKdqXw==/lib/arm64, /data/app/~~oMimw9IoQp1ajJTsKEnrxQ==/com.litesnap.open.flow.diffusion-s0YwqVUhGU20kZbxCKdqXw==/base.apk!/lib/arm64-v8a, /system/lib64, /system/system_ext/lib64]]
        at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:218)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:379)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:312)
        at org.tensorflow.lite.gpu.GpuDelegate.<init>(GpuDelegate.java:53) 
        at com.litesnap.open.flow.diffusion.MainActivity$1.onClick(MainActivity.java:27) 
        at android.view.View.performClick(View.java:7792) 
        at android.widget.TextView.performClick(TextView.java:16112) 
        at com.google.android.material.button.MaterialButton.performClick(MaterialButton.java:1131) 
        at android.view.View.performClickInternal(View.java:7769) 
        at android.view.View.access$3800(View.java:910) 
        at android.view.View$PerformClick.run(View.java:30218) 
        at android.os.Handler.handleCallback(Handler.java:938) 
        at android.os.Handler.dispatchMessage(Handler.java:99) 
        at android.os.Looper.loopOnce(Looper.java:226) 
        at android.os.Looper.loop(Looper.java:313) 
        at android.app.ActivityThread.main(ActivityThread.java:8663) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:567) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1135) 
```
</details>"
tensorflow/tensorflow,2023-06-26 19:46:34,bug,TF2.13 Breaks register_keras_serializable,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

pypi

### Tensorflow Version

TF2.13.0rc2

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

When building TF Addons for TF2.13 we're noticing that our ability to register custom Keras objects as serializable has been broken:

```
@tf.keras.saving.register_keras_serializable('my_package')
class MyDense(tf.keras.layers.Dense):
    def __init__(self, units, **kwargs):
        super().__init__(units, **kwargs)
```

### Standalone code to reproduce the issue

```shell
Here it is shown as working in TF2.12:
https://colab.research.google.com/drive/172A4_GAiSFzWJr6iVAaFYMujVCwbTk3W?usp=sharing

Here it breaks in TF2.13:
https://colab.research.google.com/drive/16BH2aNXXw3zMVevx7IYMx5cH6fZsREO_?usp=sharing
```


### Relevant log output

```shell
ValueError: Unknown layer: 'MyDense'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.
```
```
</details>"
tensorflow/tensorflow,2023-06-25 20:55:00,bug,Error to run tf,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Windowsx 11

### Mobile device

_No response_

### Python version

3.10.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

*When i try to run TensorFlow (import him), i get this error:*
![image](https://github.com/tensorflow/tensorflow/assets/95155123/3b4c7eda-fb5c-4f03-910f-74ba03ebc7ad)


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-23 11:41:25,bug,XLA unit tests fail to build on gcc,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.13

### Bazel version

6.1.0

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

3 unit tests fail to build and one fails with error.

### Standalone code to reproduce the issue

```shell
'bazel test --config==mkl_aarch64_threadpool'
```


### Relevant log output

```shell
ERROR: /tf/tensorflow/tensorflow/compiler/xla/service/BUILD:5779:12: Compiling tensorflow/compiler/xla/service/hlo_parser_test.cc failed: (Exit 1): gcc failed: error executing command (from target //tensorflow/compiler/xla/service:hlo_parser_test)
      (cd /home/buildslave/.cache/bazel/_bazel_buildslave/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow && \\
      exec env - \\
        CACHEBUSTER=20220325 \\
        PATH=/home/buildslave/.cache/bazelisk/downloads/bazelbuild/bazel-6.1.0-linux-arm64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\
        PWD=/proc/self/cwd \\
        PYTHON_BIN_PATH=/usr/local/bin/python3 \\
        TF2_BEHAVIOR=1 \\
      /dt10/usr/bin/gcc -MD -MF bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_parser_test/hlo_parser_test.d '-frandom-seed=bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_parser_test/hlo_parser_test.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -DHAVE_SYS_UIO_H -DTF_USE_SNAPPY -DBENCHMARK_STATIC_DEFINE '-DBAZEL_CURRENT_REPOSITORY=""""' -iquote . -iquote bazel-out/aarch64-opt/bin -iquote external/eigen_archive -iquote bazel-out/aarch64-opt/bin/external/eigen_archive -iquote external/com_google_absl -iquote bazel-out/aarch64-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/aarch64-opt/bin/external/nsync -iquote external/double_conversion -iquote bazel-out/aarch64-opt/bin/external/double_conversion -iquote external/com_google_protobuf -iquote bazel-out/aarch64-opt/bin/external/com_google_protobuf -iquote external/snappy -iquote bazel-out/aarch64-opt/bin/external/snappy -iquote external/com_googlesource_code_re2 -iquote bazel-out/aarch64-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/aarch64-opt/bin/external/farmhash_archive -iquote external/com_google_googletest -iquote bazel-out/aarch64-opt/bin/external/com_google_googletest -iquote external/com_google_benchmark -iquote bazel-out/aarch64-opt/bin/external/com_google_benchmark -iquote external/zlib -iquote bazel-out/aarch64-opt/bin/external/zlib -iquote external/bazel_tools -iquote bazel-out/aarch64-opt/bin/external/bazel_tools -Ibazel-out/aarch64-opt/bin/external/com_google_benchmark/_virtual_includes/benchmark -isystem external/eigen_archive -isystem bazel-out/aarch64-opt/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/aarch64-opt/bin/external/nsync/public -isystem external/com_google_protobuf/src -isystem bazel-out/aarch64-opt/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/aarch64-opt/bin/external/farmhash_archive/src -isystem external/com_google_googletest/googlemock -isystem bazel-out/aarch64-opt/bin/external/com_google_googletest/googlemock -isystem external/com_google_googletest/googlemock/include -isystem bazel-out/aarch64-opt/bin/external/com_google_googletest/googlemock/include -isystem external/com_google_googletest/googletest -isystem bazel-out/aarch64-opt/bin/external/com_google_googletest/googletest -isystem external/com_google_googletest/googletest/include -isystem bazel-out/aarch64-opt/bin/external/com_google_googletest/googletest/include -isystem external/zlib -isystem bazel-out/aarch64-opt/bin/external/zlib -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -Wno-all -Wno-extra -Wno-deprecated -Wno-deprecated-declarations -Wno-ignored-attributes -Wno-array-bounds -Wunused-result '-Werror=unused-result' -Wswitch '-Werror=switch' '-Wno-error=unused-but-set-variable' -DAUTOLOAD_DYNAMIC_KERNELS '-mtune=generic' '-march=armv8-a' -O3 '-std=c++17' '--sysroot=/dt10' -c tensorflow/compiler/xla/service/hlo_parser_test.cc -o bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_parser_test/hlo_parser_test.o)
    # Configuration: de691fac16e6bac2c61ad8c09da26892c92f72e8ffaa16698c2dd3959f4ebc3a
    # Execution platform: @local_execution_config_platform//:platform
    tensorflow/compiler/xla/service/hlo_parser_test.cc: In member function 'virtual void xla::{anonymous}::HloParserTest_ParseTrivialIotaShardingPartialReplication_Test::TestBody()':
    tensorflow/compiler/xla/service/hlo_parser_test.cc:3488:51: error: call of overloaded 'TileAssignment(<brace-enclosed initializer list>)' is ambiguous
     3488 |   TileAssignment tiling_last_dim_replicated({2, 2});
          |                                                   ^
    In file included from ./tensorflow/compiler/xla/hlo/ir/hlo_sharding.h:34,
                     from ./tensorflow/compiler/xla/hlo/ir/hlo_instruction.h:48,
                     from ./tensorflow/compiler/xla/hlo/ir/hlo_computation.h:35,
                     from ./tensorflow/compiler/xla/service/hlo_parser.h:23,
                     from tensorflow/compiler/xla/service/hlo_parser_test.cc:16:
    ./tensorflow/compiler/xla/hlo/ir/tile_assignment.h:173:12: note: candidate: 'xla::TileAssignment::TileAssignment(absl::lts_20230125::Span<const long int>)'
      173 |   explicit TileAssignment(absl::Span<const int64_t> dims)
          |            ^~~~~~~~~~~~~~
    ./tensorflow/compiler/xla/hlo/ir/tile_assignment.h:172:12: note: candidate: 'xla::TileAssignment::TileAssignment(xla::IotaTileAssignment)'
      172 |   explicit TileAssignment(IotaTileAssignment iota) : iota_(std::move(iota)) {}

And more
```
</details>"
tensorflow/tensorflow,2023-06-23 04:01:11,bug,TF Lite Converter produces outputs in an incorrect order when multiple outputs are present,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.14.0-dev20230622

### 2. Code
This is the minimized code to reproduce the issue:
```python
import tensorflow as tf
import numpy as np

x1 = tf.constant([1.], shape=[1,1])

class Model(tf.keras.Model):
  def __init__(self):
    super(Model, self).__init__()

  def call(self, x1):
    x2 = tf.eye(1)
    x3 = tf.eye(2)
    x4 = tf.eye(1)
    return [x2, x3, x4]


m = Model()
expected_value = m(x1)

converter = tf.lite.TFLiteConverter.from_keras_model(m)
tflite_model = converter.convert()

def _evaluateTFLiteModel(tflite_model, input_data):
    interpreter = tf.lite.Interpreter(model_content=tflite_model)
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    for i in range(len(input_data)):
        interpreter.set_tensor(input_details[i]['index'], input_data[i])

    interpreter.invoke()

    output_data = [interpreter.get_tensor(output_details[i]['index'])
                   for i in range(len(output_details))]
    return output_data

actual_value = _evaluateTFLiteModel(tflite_model,[x1])

#Outputs
print(f""Expected output_1: {expected_value[0].numpy()}"")
print(f""Lite output_1: {actual_value[0]}"")
print(""-----------------------------------"")
print(f""Expected output_2: {expected_value[1].numpy()}"")
print(f""Lite output_2: {actual_value[1]}"")
print(""-----------------------------------"")
print(f""Expected output_3: {expected_value[2].numpy()}"")
print(f""Lite output_3: {actual_value[2]}"")
#wrong order

tf.lite.experimental.Analyzer.analyze(model_content=tflite_model) #Output IR
```
### 3. Failure after conversion
Output (incorrect order):
```
Expected output_1: [[1.]]
Lite output_1: [[1.]]
-----------------------------------
Expected output_2: [[1. 0.]
 [0. 1.]]
Lite output_2: [[1.]]
-----------------------------------
Expected output_3: [[1.]]
Lite output_3: [[1. 0.]
 [0. 1.]]
```
Lite IR:
```
Subgraph#0 main(T#0) -> [T#1, T#1, T#2]

Tensors of Subgraph#0
  T#0(serving_default_input_1:0) shape_signature:[-1, 1], type:FLOAT32
  T#1(PartitionedCall:0) shape:[1, 1], type:FLOAT32 RO 4 bytes, buffer: 2, data:[1]
  T#2(PartitionedCall:1) shape:[2, 2], type:FLOAT32 RO 16 bytes, buffer: 3, data:[1, 0, 0, 1]
```
TF Lite converter produces wrong outputs:
- In the Lite IR, the ouput should be `[T#1, T#2, T#1]`   instead of `[T#1, T#1, T#2]` .

"
tensorflow/tensorflow,2023-06-21 18:43:32,bug,float8 (both e4m3fn and e5m2) missing from numbertype,"### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.12.0

### Custom Code

Yes

### OS Platform and Distribution

macOS-13.2.1-arm64-arm-64bit

### Mobile device

_No response_

### Python version

3.9.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

FP8 datatypes are missing from `kNumberTypes` in `tensorflow/core/framework/types.h`, and also missing from `TF_CALL_FLOAT_TYPES(m)` in `tensorflow/core/framework/register_types.h`. This causes simple ops (like slice, transpose, split, etc.) to raise NotFoundError.

### Standalone code to reproduce the issue

```python
import tensorflow as tf
from tensorflow.python.framework import dtypes

a = tf.constant([[1.2345678, 2.3456789, 3.4567891], [4.5678912, 5.6789123, 6.7891234]], dtype=dtypes.float16)
print(a)

a_fp8 = tf.cast(a, dtypes.float8_e4m3fn)
print(a_fp8)

b = a_fp8[1:2] # tensorflow.python.framework.errors_impl.NotFoundError
b = tf.transpose(a_fp8, [1, 0]) # tensorflow.python.framework.errors_impl.NotFoundError
```


### Relevant log output

```
tensorflow.python.framework.errors_impl.NotFoundError: Could not find device for node: {{node StridedSlice}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT8_E4M3FN, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=0]
All kernels registered for op StridedSlice:
  device='XLA_CPU_JIT'; Index in [DT_INT32, DT_INT16, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 930109355527764061, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN]
  device='CPU'; T in [DT_UINT64]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_UINT32]
  device='CPU'; T in [DT_UINT16]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_BOOL]
  device='CPU'; T in [DT_STRING]
  device='CPU'; T in [DT_RESOURCE]
  device='CPU'; T in [DT_VARIANT]
  device='CPU'; T in [DT_QINT8]
  device='CPU'; T in [DT_QUINT8]
  device='CPU'; T in [DT_QINT32]
  device='DEFAULT'; T in [DT_INT32]
 [Op:StridedSlice] name: strided_slice/
```

```
tensorflow.python.framework.errors_impl.NotFoundError: Could not find device for node: {{node Transpose}} = Transpose[T=DT_FLOAT8_E4M3FN, Tperm=DT_INT32]
All kernels registered for op Transpose:
  device='XLA_CPU_JIT'; Tperm in [DT_INT32, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 930109355527764061, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN]
  device='CPU'; T in [DT_UINT64]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_UINT32]
  device='CPU'; T in [DT_UINT16]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_BOOL]
  device='CPU'; T in [DT_STRING]
  device='CPU'; T in [DT_RESOURCE]
  device='CPU'; T in [DT_VARIANT]
 [Op:Transpose]
```"
tensorflow/tensorflow,2023-06-21 02:54:44,bug,android gpu delegate Failed to build program executable,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.10 or 2.11

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

A bug happened!
I test gpu delegate on oppo R9. 
TfLiteInterpreterModifyGraphWithDelegate will reture error value.

ERROR: Failed to build program executable - Build program failure<source>:35:26: error: OpenCL extension 'cl_khr_3d_image_writes' is not supported
#pragma OPENCL EXTENSION cl_khr_3d_image_writes : enable
                         ^
error: Compiler frontend failed (error code 58)

ERROR: Falling back to OpenGL
ERROR: TfLiteGpuDelegate Init: OpenGL-based API disabled
ERROR: TfLiteGpuDelegate Prepare: delegate is not initialized
ERROR: Node number 100 (TfLiteGpuDelegateV2) failed to prepare.
ERROR: Restored original execution plan after delegate application failure.
tflite gpu Delegate create failed!2

### Standalone code to reproduce the issue

```shell
oppo R9 is produced in 2016 year
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-20 08:27:18,bug,get_file raises exception if the content-length is unknown,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 22.04.2 LTS

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Calling get_file on a URL that doesn't indicate the content-length causes an exception.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

p=tf.keras.utils.get_file(fname=""auto-mpg.csv"",
  origin=""http://archive.ics.uci.edu/ml/""+
  ""machine-learning-databases/auto-mpg/auto-mpg.data"")
print(p)
```


### Relevant log output

```shell
Downloading data from http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data
   8192/Unknown - 0s 0us/stepTraceback (most recent call last):
  File ""/home/kent/env-ml/src/f3.py"", line 3, in <module>
    p=tf.keras.utils.get_file(fname=""auto-mpg.csv"",
  File ""/home/kent/env-ml/lib/python3.10/site-packages/keras/utils/data_utils.py"", line 300, in get_file
    urlretrieve(origin, fpath, DLProgbar())
  File ""/home/kent/env-ml/lib/python3.10/site-packages/keras/utils/data_utils.py"", line 86, in urlretrieve
    for chunk in chunk_read(response, reporthook=reporthook):
  File ""/home/kent/env-ml/lib/python3.10/site-packages/keras/utils/data_utils.py"", line 78, in chunk_read
    reporthook(count, chunk_size, total_size)
  File ""/home/kent/env-ml/lib/python3.10/site-packages/keras/utils/data_utils.py"", line 294, in __call__
    self.progbar.update(self.progbar.target)
  File ""/home/kent/env-ml/lib/python3.10/site-packages/keras/utils/generic_utils.py"", line 252, in update
    bar = ""%7d/Unknown"" % current
TypeError: %d format: a real number is required, not NoneType
```
</details>"
tensorflow/tensorflow,2023-06-19 14:12:15,bug,Some parameters are missing type descriptions,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tf 2.12.0

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

<html xmlns:o=""urn:schemas-microsoft-com:office:office""
xmlns:x=""urn:schemas-microsoft-com:office:excel""
xmlns=""http://www.w3.org/TR/REC-html40"">

<head>

<meta name=ProgId content=Excel.Sheet>
<meta name=Generator content=""Microsoft Excel 15"">
<link id=Main-File rel=Main-File
href=""file:///C:/Users/pigpi/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">
<link rel=File-List
href=""file:///C:/Users/pigpi/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">
<style>
<!--table
	{mso-displayed-decimal-separator:""\\."";
	mso-displayed-thousand-separator:""\\,"";}
@page
	{margin:.75in .7in .75in .7in;
	mso-header-margin:.3in;
	mso-footer-margin:.3in;}
.font5
	{color:windowtext;
	font-size:9.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:等线;
	mso-generic-font-family:auto;
	mso-font-charset:134;}
tr
	{mso-height-source:auto;
	mso-ruby-visibility:none;}
col
	{mso-width-source:auto;
	mso-ruby-visibility:none;}
br
	{mso-data-placement:same-cell;}
td
	{padding-top:1px;
	padding-right:1px;
	padding-left:1px;
	mso-ignore:padding;
	color:black;
	font-size:11.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:等线;
	mso-generic-font-family:auto;
	mso-font-charset:134;
	mso-number-format:General;
	text-align:general;
	vertical-align:bottom;
	border:none;
	mso-background-source:auto;
	mso-pattern:auto;
	mso-protection:locked visible;
	white-space:nowrap;
	mso-rotate:0;}
ruby
	{ruby-align:left;}
rt
	{color:windowtext;
	font-size:9.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:等线;
	mso-generic-font-family:auto;
	mso-font-charset:134;
	mso-char-type:none;
	display:none;}
-->
</style>
</head>

<body link=""#0563C1"" vlink=""#954F72"">



API | lack of type desciption params
-- | --
tf.sparse.bincount | values
tf.keras.layers.Input | tensor
tf.keras.applications.DenseNet121 | input_tensor
tf.math.add_n | inputs
tf.keras.applications.MobileNetV2 | input_tensor
tf.device | device_name
tf.keras.regularizers.get | identifier
tf.metrics.RootMeanSquaredError | metrics
tf.expand_dims | input
tf.keras.applications.DenseNet201 | input_tensor
tf.signal.frame | signal
tf.losses.mean_squared_error | y_true 、 y_pred
tf.losses.cosine_similarity | y_true 、 y_pred
tf.keras.metrics.binary_accuracy | y_true 、 y_pred
tf.keras.losses.logcosh | y_true 、 y_pred
tf.keras.applications.EfficientNetB5 | input_tensor
tf.metrics.binary_accuracy | y_true 、 y_pred
tf.data.experimental.assert_cardinality | expected_cardinality
tf.keras.metrics.sparse_top_k_categorical_accuracy | y_true 、 y_pred
tf.losses.squared_hinge | y_true 、 y_pred
tf.keras.utils.pack_x_y_sample_weight | x、y、sample_weight
tf.keras.activations.softplus | x
tf.nn.depth_to_space | input
tf.gather_nd | params
tf.zeros_like | input
tf.keras.applications.EfficientNetB2 | input_tensor
tf.keras.metrics.MeanAbsoluteError | metrics
tf.stack | values
tf.ensure_shape | x
tf.roll | input
tf.keras.activations.gelu | x
tf.linalg.set_diag | input、diagonal、k
tf.math.bincount | arr、weights
tf.concat | values
tf.keras.applications.EfficientNetB6 | input_tensor
tf.keras.losses.mean_squared_error | y_true 、 y_pred
tf.random.categorical | logits
tf.keras.backend.is_keras_tensor | x
tf.keras.activations.tanh | x
tf.pad | tensor
tf.keras.initializers.identity | gain
tf.keras.applications.EfficientNetB0 | input_tensor
tf.repeat | input
tf.image.convert_image_dtype | image
tf.split | value
tf.keras.utils.to_categorical | y
tf.scatter_nd | updates
tf.keras.layers.concatenate | input
tf.linalg.banded_triangular_solve | bands、rhs
tf.ones_like | input
tf.nest.flatten | structure
tf.keras.activations.linear | x
tf.linalg.tensor_diag_part | input
tf.image.pad_to_bounding_box | image
tf.config.set_visible_devices | devices
tf.size | input
tf.image.resize | images
tf.tile | input
tf.keras.applications.VGG16 | input_tensor
tf.keras.metrics.top_k_categorical_accuracy | y_true 、 y_pred
tf.initializers.identity | gain
tf.image.stateless_random_brightness | image
tf.ragged.range | starts、limits、deltas
tf.reshape | tensor
tf.losses.logcosh | y_true 、 y_pred
tf.keras.applications.ResNet50V2 | input_tensor
tf.nn.moments | x
tf.keras.applications.EfficientNetB4 | input_tensor
tf.image.adjust_jpeg_quality | image
tf.keras.losses.sparse_categorical_crossentropy | y_true 、 y_pred
tf.control_dependencies | control_inputs
tf.image.grayscale_to_rgb | images
tf.image.rgb_to_yiq | images
tf.keras.applications.EfficientNetB3 | input_tensor
tf.ragged.boolean_mask | data、mask
tf.image.random_hue | image
tf.image.adjust_gamma | image
tf.is_tensor | x
tf.keras.initializers.orthogonal | gain
tf.math.polyval | coeffs、x
tf.io.serialize_tensor | tensor
tf.image.stateless_random_saturation | image
tf.one_hot | indices
tf.linalg.diag_part | input、padding_value、
tf.image.adjust_saturation | image
tf.boolean_mask | tensor、mask
tf.transpose | a
tf.image.flip_up_down | image
tf.keras.losses.binary_crossentropy | y_true 、 y_pred
tf.broadcast_to | input
tf.image.stateless_random_crop | value
tf.losses.mean_absolute_percentage_error | y_true 、 y_pred
tf.image.stateless_random_flip_left_right | image
tf.image.random_flip_up_down | image
tf.keras.activations.exponential | x
tf.keras.applications.Xception | input_tensor
tf.identity | input
tf.gather | params
tf.keras.applications.InceptionV3 | input_tensor
tf.keras.layers.Masking | mask_value
tf.losses.kullback_leibler_divergence | y_true 、 y_pred
tf.linalg.band_part | input
tf.keras.losses.cosine_similarity | y_true 、 y_pred
tf.image.random_contrast | image
tf.image.transpose | image
tf.stop_gradient | input
tf.strings.bytes_split | input
tf.random.stateless_parameterized_truncated_normal | means、stddevs、minvals、maxvals
tf.keras.losses.mean_absolute_error | y_true 、 y_pred
tf.image.stateless_random_hue | image
tf.keras.applications.DenseNet169 | input_tensor
tf.keras.losses.categorical_crossentropy | y_true 、 y_pred
tf.nn.embedding_lookup | params
tf.math.reduce_variance | input_tensor
tf.keras.utils.unpack_x_y_sample_weight | data
tf.nn.l2_normalize | x
tf.keras.losses.categorical_hinge | y_true 、 y_pred
tf.keras.applications.EfficientNetB1 | input_tensor
tf.keras.constraints.get | identifier
tf.initializers.orthogonal | gain
tf.divide | x、y
tf.math.top_k | input
tf.keras.losses.kullback_leibler_divergence | y_true 、 y_pred
tf.image.stateless_random_jpeg_quality | image
tf.keras.losses.mean_absolute_percentage_error | y_true 、 y_pred
tf.keras.applications.EfficientNetB7 | input_tensor
tf.clip_by_value | t
tf.type_spec_from_value | value
tf.losses.mean_squared_logarithmic_error | y_true 、 y_pred
tf.tensor_scatter_nd_update | tensor、indices
tf.equal | x、y
tf.image.rgb_to_grayscale | images
tf.image.stateless_random_contrast | image
tf.image.rgb_to_hsv | images
tf.convert_to_tensor | value
tf.losses.sparse_categorical_crossentropy | y_true 、 y_pred
tf.keras.activations.sigmoid | x
tf.slice | input_
tf.image.adjust_hue | image
tf.math.argmax | input
tf.reverse_sequence | input
tf.losses.categorical_crossentropy | y_true 、 y_pred
tf.keras.losses.squared_hinge | y_true 、 y_pred
tf.squeeze | input
tf.math.equal | x、y
tf.math.divide | x、y
tf.unstack | value
tf.keras.applications.MobileNet | input_tensor
tf.keras.applications.ResNet152V2 | input_tensor
tf.keras.activations.softsign | x
tf.keras.applications.NASNetMobile | input_tensor
tf.keras.activations.swish | x
tf.metrics.categorical_accuracy | y_true 、 y_pred
tf.keras.metrics.sparse_categorical_accuracy | y_true 、 y_pred
tf.metrics.sparse_top_k_categorical_accuracy | y_true 、 y_pred
tf.losses.mean_absolute_error | y_true 、 y_pred
tf.losses.binary_crossentropy | y_true 、 y_pred
tf.keras.applications.ResNet50 | input_tensor
tf.image.random_jpeg_quality | image、min_jpeg_quality、max_jpeg_quality
tf.keras.activations.hard_sigmoid | x
tf.image.flip_left_right | image
tf.keras.applications.ResNet101V2 | input_tensor
tf.nn.batch_normalization | x、mean、variance、offset、scale
tf.math.reduce_min | input_tensor
tf.keras.applications.ResNet101 | input_tensor
tf.math.not_equal | x、y
tf.image.rot90 | image
tf.keras.applications.VGG19 | input_tensor
tf.image.stateless_random_flip_up_down | image
tf.keras.applications.MobileNetV3Large | input_tensor
tf.keras.applications.ResNet152 | input_tensor
tf.keras.metrics.categorical_accuracy | y_true 、 y_pred
tf.sparse.cross | inputs
tf.keras.losses.mean_squared_logarithmic_error | y_true 、 y_pred
tf.image.random_flip_left_right | image



</body>

</html>


### Standalone code to reproduce the issue

```shell
Many parameters are not for any type of value, so the allowed types should be clearly marked in the document.
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-19 05:35:02,bug,Tensorboard histogram onehot operation causing ResourceExhauseError: OOM,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I'm trying to train a VGG16 model. I'm using a sample dataset of 4000 300x300 images in 14 classes, and running my code on a Google VM using an Nvidia L4 GPU with 20gb of memory. I am running python 3.7, tf version 2.11, and cuda version 12.1. My data is stored in GCS.

When I run the model with the following TensorBoard callback:

`tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)`

I get this error at the end of the first epoch:

```
2023-06-14 19:51:21.248476: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (mklcpu) ran out of memory trying to allocate 22.97GiB (rounded to 24662507520)requested by op OneHot
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 

ResourceExhaustedError: {{function_node _wrapped__OneHot_device/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[102760448,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:OneHot]

```
The error traces back to the tensorboard histogram object:
```

--------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
/var/tmp/ipykernel_5723/1753739100.py in <module>
      1 # Fit model
----> 2 history = model.fit(train_ds, validation_data=val_ds, epochs=5, callbacks=[tensorboard_callback])

/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
     68             # To get the full stack trace, call:
     69             # `tf.debugging.disable_traceback_filtering()`
---> 70             raise e.with_traceback(filtered_tb) from None
     71         finally:
     72             del filtered_tb

/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py in histogram(name, data, step, buckets, description)
    198             tensor=lazy_tensor,
    199             step=step,
--> 200             metadata=summary_metadata,
    201         )
    202 

/opt/conda/lib/python3.7/site-packages/tensorboard/util/lazy_tensor_creator.py in __call__(self)
     64                 elif self._tensor is None:
     65                     self._tensor = _CALL_IN_PROGRESS_SENTINEL
---> 66                     self._tensor = self._tensor_callable()
     67         return self._tensor
     68 

/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py in lazy_tensor()
    192         @lazy_tensor_creator.LazyTensorCreator
    193         def lazy_tensor():
--> 194             return _buckets(data, buckets)
    195 
    196         return tf.summary.write(

/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py in _buckets(data, bucket_count)
    291             )
    292 
--> 293         return tf.cond(is_empty, when_empty, when_nonempty)

/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py in when_nonempty()
    288 
    289             return tf.cond(
--> 290                 has_single_value, when_single_value, when_multiple_values
    291             )
    292 

/opt/conda/lib/python3.7/site-packages/tensorboard/plugins/histogram/summary_v2.py in when_multiple_values()
    257                 # See https://github.com/tensorflow/tensorflow/issues/51419 for details.
    258                 one_hots = tf.one_hot(
--> 259                     clamped_indices, depth=bucket_count, dtype=tf.float64
    260                 )
    261                 bucket_counts = tf.cast(

ResourceExhaustedError: {{function_node __wrapped__OneHot_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[102760448,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:OneHot]


```
Interestingly it seems to be calling tf.one_hot and blowing up the gpu memory with a massive tensor regardless of whether I train the model with integer labels and spare categorical cross entropy or if I train it with one hot labels and cross entropy. I don't really understand what the tensor contains because its dimensions neither relate to the number of training examples or classes that I am using.

### Standalone code to reproduce the issue

```shell
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)


I get this error at the end of the first epoch:

2023-06-14 19:51:21.248476: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (mklcpu) ran out of memory trying to allocate 22.97GiB (rounded to 24662507520)requested by op OneHot
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 

ResourceExhaustedError: {{function_node _wrapped__OneHot_device/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[102760448,30] and type double on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:OneHot]
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-16 12:20:44,bug,tf.test.gpu_device_name() leads to soft lockup and unusable system,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

binary

### Tensorflow Version

2.12.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.16 (Conda 11.4)

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.4

### GPU model and memory

NVIDIA T4

### Current Behaviour?

We found that running `tf.test.gpu_device_name()` leads to a soft lockup and an unresponsive system.

I apologise in advance, I don't know much about Tensorflow. But several of my co-workers do and I'm in charge of maintaining infrastructure. We have a virtual server for compute-intensive tasks where we train models and work with large datasets. Yesterday at about 7 local time I found that I couldn't SSH into the server so I had to wait for IT to forcibly restart the server. At around 13 local time the server was back up and I looked through the kernel logs to find that there was a soft lockup kernel bug. This means that the server was still running, but some process wasn't releasing the CPU for more than 20 seconds, which meant that no other process could fulfill its tasks.

Not even half an hour later and the server locked up again. I got a message from a co-worker who suspected that they were at fault for the server locking up because they started running a very compute-intensive Python script on the server last night. They opened a Python shell and typed in these two lines and watched the server lock up in real time.

```py
import tensorflow as tf 
print('Default GPU Device{}'.format(tf.test.gpu_device_name()))
```

I provided the relevant log output below. It required another hard reset from IT to get the server back into a working state.

After the server restarted again I had another look at the kernel logs and found that the reported errors were the same, which means I have reason to believe that running `tf.test.gpu_device_name()` consistently leads to a soft lockup on our infrastructure.

As mentioned previously, we run our computations on a virtual server. The hypervisor is VMWare. We're running on a Nvidia T4 GPU with Nvidia drivers in version 470.63.01. These drivers were provided to us by IT. Installing another version, for some reason, isn't possible and I prefer not to mess with that. The co-worker installed Tensorflow in a Conda environment using Pip.

Since we're running on a virtual server, we depend on IT in case things go very wrong. This means our means of reproducing this issue are somewhat limited. If the server locks up, we have to wait up to a couple hours for our service desk to escalate this issue enough so that IT restarts the server. We cannot afford downtimes like these since we rely on the server for our computations. I'm happy to provide any logs from previous runs but if possible I would like to not share them on GitHub in their entirety since they might contain confidential info.

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
print('Default GPU Device {}'.format(tf.test.gpu_device_name()))
```


### Relevant log output

```shell
# Output from running the function in a Python shell

$ python3
Python 3.8.16 (default, Mar  2 2023, 03:21:46) 
[GCC 11.2.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
import tensorflow as tf 
2023-06-15 13:34:49.940226: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-06-15 13:34:50.367115: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2023-06-15 13:34:50.368678: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-15 13:34:52.102738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
>>> print('Default GPU Device{}'.format(tf.test.gpu_device_name()))
2023-06-15 13:35:05.586532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-15 13:35:05.587485: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...

Message from syslogd@s050009088 at Jun 15 13:35:32 ...
 kernel:[  176.957689] watchdog: BUG: soft lockup - CPU#6 stuck for 22s! [python3:4167]


# Output from journalctl

Jun 15 13:35:05 s050009088 kernel: nvidia-uvm: Loaded the UVM driver, major device number 238.
Jun 15 13:35:05 s050009088 kernel: ------------[ cut here ]------------
Jun 15 13:35:05 s050009088 kernel: Trying to vfree() nonexistent vm area (00000000f9521180)
Jun 15 13:35:05 s050009088 kernel: WARNING: CPU: 6 PID: 4167 at mm/vmalloc.c:2245 __vunmap+0x1ff/0x210
Jun 15 13:35:05 s050009088 kernel: Modules linked in: nvidia_uvm(OE) veth xt_nat xt_tcpudp xt_conntrack xt_MASQUERADE nf_conntrack_netlink nfnetlink xfrm_user xfrm_algo iptable_nat nf_nat nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 xt_addrtype iptable_filter bpfilter br_netfilter bridge stp llc aufs overlay vmw_vsock_vmci_transport vsock dm_multipath scsi_dh_rdac scsi_dh_emc scsi_dh_alua binfmt_misc nvidia_drm(POE) nvidia_modeset(POE) intel_rapl_msr nvidia(POE) vmw_balloon intel_rapl_common input_leds intel_powerclamp joydev rapl serio_raw vmw_vmci mac_hid sch_fq_codel msr ramoops reed_solomon efi_pstore ip_tables x_tables autofs4 btrfs zstd_compress raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid1 raid0 multipath linear vmwgfx crct10dif_pclmul crc32_pclmul ttm ghash_clmulni_intel drm_kms_helper syscopyarea aesni_intel sysfillrect crypto_simd sysimgblt mptspi cryptd fb_sys_fops glue_helper psmouse mptscsih drm mptbase ahci i2c_piix4 vmxnet3 scsi_transport_spi
Jun 15 13:35:05 s050009088 kernel:  libahci pata_acpi
Jun 15 13:35:05 s050009088 kernel: CPU: 6 PID: 4167 Comm: python3 Tainted: P           OE     5.4.0-150-generic #167-Ubuntu
Jun 15 13:35:05 s050009088 kernel: Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 11/12/2020
Jun 15 13:35:05 s050009088 kernel: RIP: 0010:__vunmap+0x1ff/0x210
Jun 15 13:35:05 s050009088 kernel: Code: ff e8 d5 fc ff ff eb bf 48 89 fe 48 c7 c7 a0 6d b8 8e e8 36 ba 82 00 0f 0b eb b4 4c 89 ee 48 c7 c7 c8 6d b8 8e e8 23 ba 82 00 <0f> 0b eb a1 66 66 2e 0f 1f 84 00 00 00 00 00 66 90 0f 1f 44 00 00
Jun 15 13:35:05 s050009088 kernel: RSP: 0018:ffffab66c32b7c00 EFLAGS: 00010286
Jun 15 13:35:05 s050009088 kernel: RAX: 0000000000000000 RBX: 0000000000000001 RCX: 0000000000000006
Jun 15 13:35:05 s050009088 kernel: RDX: 0000000000000007 RSI: 0000000000000096 RDI: ffff8ce3bfb9c8c0
Jun 15 13:35:05 s050009088 kernel: RBP: ffffab66c32b7c28 R08: 00000000000006d2 R09: 286565726676206f
Jun 15 13:35:05 s050009088 kernel: R10: 286565726676206f R11: 6978656e6f6e2029 R12: 0000000000000000
Jun 15 13:35:05 s050009088 kernel: R13: ffff8ce22c348000 R14: ffff8ce22c349000 R15: 0000000000000027
Jun 15 13:35:05 s050009088 kernel: FS:  00007fbf935e3180(0000) GS:ffff8ce3bfb80000(0000) knlGS:0000000000000000
Jun 15 13:35:05 s050009088 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
Jun 15 13:35:05 s050009088 kernel: CR2: 000000000435c3d0 CR3: 0000001e50400001 CR4: 00000000003606e0
Jun 15 13:35:05 s050009088 kernel: Call Trace:
Jun 15 13:35:05 s050009088 kernel:  __vfree+0x22/0x60
Jun 15 13:35:05 s050009088 kernel:  vfree+0x2c/0x40
Jun 15 13:35:05 s050009088 kernel:  os_free_mem+0x1b/0x30 [nvidia]
Jun 15 13:35:05 s050009088 kernel:  os_unlock_user_pages+0x6c/0xa0 [nvidia]
Jun 15 13:35:05 s050009088 kernel:  _nv000647rm+0xdc/0x160 [nvidia]
Jun 15 13:35:05 s050009088 kernel: WARNING: kernel stack frame pointer at 0000000068b18731 in python3:4167 has bad value 00000000f3874266
Jun 15 13:35:05 s050009088 kernel: unwind stack type:0 next_sp:0000000000000000 mask:0x2 graph_idx:0
Jun 15 13:35:05 s050009088 kernel: 00000000c0e190e6: ffffab66c32b7c40 (0xffffab66c32b7c40)
Jun 15 13:35:05 s050009088 kernel: 0000000074c2bd79: ffffffff8da6e972 (__vfree+0x22/0x60)
Jun 15 13:35:05 s050009088 kernel: 00000000ea3bef41: 0000000000000200 (0x200)
Jun 15 13:35:05 s050009088 kernel: 00000000d32e6150: ffffab66c32b7c58 (0xffffab66c32b7c58)
Jun 15 13:35:05 s050009088 kernel: 00000000e4c2b257: ffffffff8da6e9dc (vfree+0x2c/0x40)
Jun 15 13:35:05 s050009088 kernel: 000000008b622c26: ffff8ce22c348000 (0xffff8ce22c348000)
Jun 15 13:35:05 s050009088 kernel: 00000000b443bda0: ffffab66c32b7c68 (0xffffab66c32b7c68)
Jun 15 13:35:05 s050009088 kernel: 0000000004f89fc7: ffffffffc068ccdb (os_free_mem+0x1b/0x30 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 0000000058382150: ffffab66c32b7c98 (0xffffab66c32b7c98)
Jun 15 13:35:05 s050009088 kernel: 000000007fb1b873: ffffffffc068edfc (os_unlock_user_pages+0x6c/0xa0 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 00000000629b0f28: ffff8ce395ff60c8 (0xffff8ce395ff60c8)
Jun 15 13:35:05 s050009088 kernel: 000000003a4ac7ef: 0000010004400000 (0x10004400000)
Jun 15 13:35:05 s050009088 kernel: 000000005e9a76c9: 0000000000000200 (0x200)
Jun 15 13:35:05 s050009088 kernel: 000000005fe4a88b: 00000000aa000000 (0xaa000000)
Jun 15 13:35:05 s050009088 kernel: 0000000068b18731: ffff8ce3b3e92fb0 (0xffff8ce3b3e92fb0)
Jun 15 13:35:05 s050009088 kernel: 00000000bd345bcf: ffffffffc101e8dc (_nv000647rm+0xdc/0x160 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 0000000089f90db7: ffff8ce395ff60c8 (0xffff8ce395ff60c8)
Jun 15 13:35:05 s050009088 kernel: 00000000c99c1977: ffff8ce39726c0c0 (0xffff8ce39726c0c0)
Jun 15 13:35:05 s050009088 kernel: 000000009060a662: 0000000000000008 (0x8)
Jun 15 13:35:05 s050009088 kernel: 0000000043ee1352: ffffffffc101f3a3 (_nv000723rm+0xa43/0xa90 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 0000000064b64c73: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 0000000030c878cd: ffff8ce3b35bc000 (0xffff8ce3b35bc000)
Jun 15 13:35:05 s050009088 kernel: 00000000e60fac70: ffffffffc101f316 (_nv000723rm+0x9b6/0xa90 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 0000000065747b0c: ffff8ce3b3e90000 (0xffff8ce3b3e90000)
Jun 15 13:35:05 s050009088 kernel: 0000000063da2df1: ffff8ce3a658b800 (0xffff8ce3a658b800)
Jun 15 13:35:05 s050009088 kernel: 0000000008c0ac4e: ffffab66c32b7e48 (0xffffab66c32b7e48)
Jun 15 13:35:05 s050009088 kernel: 0000000057ee515b: ffff8ce3b35b9400 (0xffff8ce3b35b9400)
Jun 15 13:35:05 s050009088 kernel: 000000006c5468b7: 0000000000000027 (0x27)
Jun 15 13:35:05 s050009088 kernel: 0000000065281df3: ffffffffc1025204 (rm_ioctl+0x54/0xb0 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 00000000b419e233: 000000388da5fdb5 (0x388da5fdb5)
Jun 15 13:35:05 s050009088 kernel: 000000006f1b29a3: ffff8ce39726c0c0 (0xffff8ce39726c0c0)
Jun 15 13:35:05 s050009088 kernel: 00000000465f1196: 8000000000000027 (0x8000000000000027)
Jun 15 13:35:05 s050009088 kernel: 0000000024eadd83: 0000000000001047 (0x1047)
Jun 15 13:35:05 s050009088 kernel: 00000000e74dc1ab: 00000000000007e9 (0x7e9)
Jun 15 13:35:05 s050009088 kernel: 00000000f6d262ce: 003d08dcf6746300 (0x3d08dcf6746300)
Jun 15 13:35:05 s050009088 kernel: 00000000400760c5: 003d08dde4df8b00 (0x3d08dde4df8b00)
Jun 15 13:35:05 s050009088 kernel: 00000000c7874ca7: 003d08e3f2980f00 (0x3d08e3f2980f00)
Jun 15 13:35:05 s050009088 kernel: 00000000946d2608: 003d08dd6da9f700 (0x3d08dd6da9f700)
Jun 15 13:35:05 s050009088 kernel: 000000007a9cecb7: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 000000000e6b2400: 0000000000000200 (0x200)
Jun 15 13:35:05 s050009088 kernel: 0000000022df682d: 0000002000000006 (0x2000000006)
Jun 15 13:35:05 s050009088 kernel: 0000000005972aee: 0000000000001047 (0x1047)
Jun 15 13:35:05 s050009088 kernel: 00000000f3ab8670: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 0000000043395ee6: 0000000000000001 (0x1)
Jun 15 13:35:05 s050009088 kernel: 0000000090b81e91: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 00000000ce75a231: ffff8ce39726c0c0 (0xffff8ce39726c0c0)
Jun 15 13:35:05 s050009088 kernel: 00000000336aa9c4: 0000000000000038 (0x38)
Jun 15 13:35:05 s050009088 kernel: 0000000016e174a9: ffff8ce3b35b9400 (0xffff8ce3b35b9400)
Jun 15 13:35:05 s050009088 kernel: 00000000c453e6ee: ffff8ce3a658b800 (0xffff8ce3a658b800)
Jun 15 13:35:05 s050009088 kernel: 00000000ca8fc06a: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 0000000027388a61: ffffffffc068268f (nvidia_ioctl+0x66f/0x880 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 000000001f100b3c: ffff8ce3b3e90000 (0xffff8ce3b3e90000)
Jun 15 13:35:05 s050009088 kernel: 00000000d70e2948: 00007ffd116cef60 (0x7ffd116cef60)
Jun 15 13:35:05 s050009088 kernel: 000000009e15ae1f: ffff8ce3b35b9498 (0xffff8ce3b35b9498)
Jun 15 13:35:05 s050009088 kernel: 000000002d53d487: 00007ffd00000027 (0x7ffd00000027)
Jun 15 13:35:05 s050009088 kernel: 000000002ea37e99: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 00000000723c86e7: 0000000000000003 (0x3)
Jun 15 13:35:05 s050009088 kernel: 000000004b070af4: 3c5520dc9b31e900 (0x3c5520dc9b31e900)
Jun 15 13:35:05 s050009088 kernel: 00000000260adce7: ffff8ce3a37b1e01 (0xffff8ce3a37b1e01)
Jun 15 13:35:05 s050009088 kernel: 00000000f3ab64dd: ffff8ce3a37b1e00 (0xffff8ce3a37b1e00)
Jun 15 13:35:05 s050009088 kernel: 000000009250db0d: ffff8ce3a46feaa0 (0xffff8ce3a46feaa0)
Jun 15 13:35:05 s050009088 kernel: 000000001a439626: 00007ffd116cef60 (0x7ffd116cef60)
Jun 15 13:35:05 s050009088 kernel: 00000000d28c869f: ffff8ce3a37b1e00 (0xffff8ce3a37b1e00)
Jun 15 13:35:05 s050009088 kernel: 00000000264cc6e1: ffffab66c32b7e58 (0xffffab66c32b7e58)
Jun 15 13:35:05 s050009088 kernel: 00000000c9cdb9ef: ffffffffc069191b (nvidia_frontend_unlocked_ioctl+0x3b/0x50 [nvidia])
Jun 15 13:35:05 s050009088 kernel: 00000000dc15a7de: ffffab66c32b7ed8 (0xffffab66c32b7ed8)
Jun 15 13:35:05 s050009088 kernel: 000000009b8c3053: ffffffff8dae8e77 (do_vfs_ioctl+0x407/0x670)
Jun 15 13:35:05 s050009088 kernel: 00000000f2d02675: 0000010004400000 (0x10004400000)
Jun 15 13:35:05 s050009088 kernel: 00000000c52e1241: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 0000000027ba7e88: ffffab66c32b7e78 (0xffffab66c32b7e78)
Jun 15 13:35:05 s050009088 kernel: 00000000aaf3e429: ffffab66c32b7e78 (0xffffab66c32b7e78)
Jun 15 13:35:05 s050009088 kernel: 00000000fd0b1f6d: 3c5520dc9b31e900 (0x3c5520dc9b31e900)
Jun 15 13:35:05 s050009088 kernel: 0000000051d890d1: 0000000000000031 (0x31)
Jun 15 13:35:05 s050009088 kernel: 000000001e5b54d6: 0000000000200000 (0x200000)
Jun 15 13:35:05 s050009088 kernel: 00000000bf7d038a: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 00000000a021b6f5: 3c5520dc9b31e900 (0x3c5520dc9b31e900)
Jun 15 13:35:05 s050009088 kernel: 00000000382d5bbd: ffff8ce3a37b1e01 (0xffff8ce3a37b1e01)
Jun 15 13:35:05 s050009088 kernel: 000000005691996c: 0000000000000006 (0x6)
Jun 15 13:35:05 s050009088 kernel: 000000002b0a9fae: 00000000c0384627 (0xc0384627)
Jun 15 13:35:05 s050009088 kernel: 00000000ed0791ed: 00007ffd116cef60 (0x7ffd116cef60)
Jun 15 13:35:05 s050009088 kernel: 00000000944e63ee: ffff8ce3a37b1e00 (0xffff8ce3a37b1e00)
Jun 15 13:35:05 s050009088 kernel: 00000000b8133399: ffffab66c32b7f18 (0xffffab66c32b7f18)
Jun 15 13:35:05 s050009088 kernel: 000000006b019d54: ffffffff8dae9147 (ksys_ioctl+0x67/0x90)
Jun 15 13:35:05 s050009088 kernel: 0000000025959ce7: 3c5520dc9b31e900 (0x3c5520dc9b31e900)
Jun 15 13:35:05 s050009088 kernel: 0000000019e92101: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 000000002801fc84: ffffab66c32b7f58 (0xffffab66c32b7f58)
Jun 15 13:35:05 s050009088 kernel: 0000000060185eb1: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 000000007c1db1b7: ffffab66c32b7f28 (0xffffab66c32b7f28)
Jun 15 13:35:05 s050009088 kernel: 0000000084b8d84e: ffffffff8dae918a (__x64_sys_ioctl+0x1a/0x20)
Jun 15 13:35:05 s050009088 kernel: 000000009b8e8f5f: ffffab66c32b7f48 (0xffffab66c32b7f48)
Jun 15 13:35:05 s050009088 kernel: 00000000f2da7b14: ffffffff8d804fd7 (do_syscall_64+0x57/0x190)
Jun 15 13:35:05 s050009088 kernel: 00000000942f1f70: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 00000000f56a3750: ffffffff8e4000a4 (entry_SYSCALL_64_after_hwframe+0x5c/0xc1)
Jun 15 13:35:05 s050009088 kernel: 0000000018f467fe: 00007ffd116ceed0 (0x7ffd116ceed0)
Jun 15 13:35:05 s050009088 kernel: 00000000831b89bf: 00000000648af769 (0x648af769)
Jun 15 13:35:05 s050009088 kernel: 000000000597aba6: 00007ffd116cef88 (0x7ffd116cef88)
Jun 15 13:35:05 s050009088 kernel: 00000000a139f77e: 0000000000000006 (0x6)
Jun 15 13:35:05 s050009088 kernel: 000000006612db4e: 00000000c0384627 (0xc0384627)
Jun 15 13:35:05 s050009088 kernel: 00000000ab55bfe9: 00007ffd116cef60 (0x7ffd116cef60)
Jun 15 13:35:05 s050009088 kernel: 000000000b644430: 0000000000000246 (0x246)
Jun 15 13:35:05 s050009088 kernel: 00000000d2d8779b: 0000000000000000 ...
Jun 15 13:35:05 s050009088 kernel: 00000000725ab6b6: 00007ffd116cef88 (0x7ffd116cef88)
Jun 15 13:35:05 s050009088 kernel: 000000000399d500: 00007ffd116cef60 (0x7ffd116cef60)
Jun 15 13:35:05 s050009088 kernel: 00000000c0a877c1: ffffffffffffffda (0xffffffffffffffda)
Jun 15 13:35:05 s050009088 kernel: 00000000fb645881: 00007fbf936f83ab (0x7fbf936f83ab)
Jun 15 13:35:05 s050009088 kernel: 00000000f6cd2602: 00007ffd116cef60 (0x7ffd116cef60)
Jun 15 13:35:05 s050009088 kernel: 000000006fc36d91: 00000000c0384627 (0xc0384627)
Jun 15 13:35:05 s050009088 kernel: 00000000e5058b78: 0000000000000006 (0x6)
Jun 15 13:35:05 s050009088 kernel: 000000002777ac42: 0000000000000010 (0x10)
Jun 15 13:35:05 s050009088 kernel: 00000000d68cb82a: 00007fbf936f83ab (0x7fbf936f83ab)
Jun 15 13:35:05 s050009088 kernel: 0000000077e7b064: 0000000000000033 (0x33)
Jun 15 13:35:05 s050009088 kernel: 0000000037ef3830: 0000000000000246 (0x246)
Jun 15 13:35:05 s050009088 kernel: 00000000fcba1669: 00007ffd116ceec8 (0x7ffd116ceec8)
Jun 15 13:35:05 s050009088 kernel: 00000000ea0caaa1: 000000000000002b (0x2b)
Jun 15 13:35:05 s050009088 kernel:  ? _nv000723rm+0xa43/0xa90 [nvidia]
Jun 15 13:35:05 s050009088 kernel:  ? _nv000723rm+0x9b6/0xa90 [nvidia]
Jun 15 13:35:05 s050009088 kernel:  ? rm_ioctl+0x54/0xb0 [nvidia]
Jun 15 13:35:05 s050009088 kernel:  ? nvidia_ioctl+0x66f/0x880 [nvidia]
Jun 15 13:35:05 s050009088 kernel:  ? nvidia_frontend_unlocked_ioctl+0x3b/0x50 [nvidia]
Jun 15 13:35:05 s050009088 kernel:  ? do_vfs_ioctl+0x407/0x670
Jun 15 13:35:05 s050009088 kernel:  ? ksys_ioctl+0x67/0x90
Jun 15 13:35:05 s050009088 kernel:  ? __x64_sys_ioctl+0x1a/0x20
Jun 15 13:35:05 s050009088 kernel:  ? do_syscall_64+0x57/0x190
Jun 15 13:35:05 s050009088 kernel:  ? entry_SYSCALL_64_after_hwframe+0x5c/0xc1
Jun 15 13:35:05 s050009088 kernel: ---[ end trace be1a4a9ea080b7b8 ]---

## The following logs are then repeatedly printed, leading to the soft lockup

Jun 15 13:35:05 s050009088 kernel: BUG: Bad page state in process python3  pfn:1e301a6
Jun 15 13:35:05 s050009088 kernel: page:ffffd052f8c06980 refcount:0 mapcount:0 mapping:ffff8ce230f6e0d8 index:0x1
Jun 15 13:35:05 s050009088 kernel: shmem_aops name:""dev/zero""
Jun 15 13:35:05 s050009088 kernel: flags: 0x17ffffc0000000()
Jun 15 13:35:05 s050009088 kernel: raw: 0017ffffc0000000 dead000000000100 dead000000000122 ffff8ce230f6e0d8
Jun 15 13:35:05 s050009088 kernel: raw: 0000000000000001 0000000000000000 00000000ffffffff 0000000000000000
Jun 15 13:35:05 s050009088 kernel: page dumped because: non-NULL mapping
Jun 15 13:35:05 s050009088 kernel: Modules linked in: nvidia_uvm(OE) veth xt_nat xt_tcpudp xt_conntrack xt_MASQUERADE nf_conntrack_netlink nfnetlink xfrm_user xfrm_algo iptable_nat nf_nat nf_conntrack nf_defrag_ipv6 nf_defrag_ipv4 xt_addrtype iptable_filter bpfilter br_netfilter bridge stp llc aufs overlay vmw_vsock_vmci_transport vsock dm_multipath scsi_dh_rdac scsi_dh_emc scsi_dh_alua binfmt_misc nvidia_drm(POE) nvidia_modeset(POE) intel_rapl_msr nvidia(POE) vmw_balloon intel_rapl_common input_leds intel_powerclamp joydev rapl serio_raw vmw_vmci mac_hid sch_fq_codel msr ramoops reed_solomon efi_pstore ip_tables x_tables autofs4 btrfs zstd_compress raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid1 raid0 multipath linear vmwgfx crct10dif_pclmul crc32_pclmul ttm ghash_clmulni_intel drm_kms_helper syscopyarea aesni_intel sysfillrect crypto_simd sysimgblt mptspi cryptd fb_sys_fops glue_helper psmouse mptscsih drm mptbase ahci i2c_piix4 vmxnet3 scsi_transport_spi
Jun 15 13:35:05 s050009088 kernel:  libahci pata_acpi
Jun 15 13:35:05 s050009088 kernel: CPU: 6 PID: 4167 Comm: python3 Tainted: P        W  OE     5.4.0-150-generic #167-Ubuntu
Jun 15 13:35:05 s050009088 kernel: Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 11/12/2020
Jun 15 13:35:05 s050009088 kernel: Call Trace:
Jun 15 13:35:05 s050009088 kernel:  dump_stack+0x6d/0x8b
Jun 15 13:35:05 s050009088 kernel:  bad_page.cold+0x80/0xb1
Jun 15 13:35:05 s050009088 kernel:  free_pages_check_bad+0x5f/0x70
Jun 15 13:35:05 s050009088 kernel:  free_pcppages_bulk+0x186/0x6b0
Jun 15 13:35:05 s050009088 kernel:  free_unref_page_commit+0xb6/0xd0
Jun 15 13:35:05 s050009088 kernel:  free_unref_page_list+0x107/0x190
Jun 15 13:35:05 s050009088 kernel:  release_pages+0x38d/0x400
Jun 15 13:35:05 s050009088 kernel:  free_pages_and_swap_cache+0xb9/0xd0
Jun 15 13:35:05 s050009088 kernel:  tlb_flush_mmu+0x3a/0x140
Jun 15 13:35:05 s050009088 kernel:  zap_pte_range.isra.0+0x563/0x860
Jun 15 13:35:05 s050009088 kernel:  ? __warn+0x9d/0xe0
Jun 15 13:35:05 s050009088 kernel:  unmap_page_range+0x2e6/0x560
Jun 15 13:35:05 s050009088 kernel:  unmap_single_vma+0x7f/0xf0
Jun 15 13:35:05 s050009088 kernel:  unmap_vmas+0x79/0xf0
Jun 15 13:35:05 s050009088 kernel:  unmap_region+0xbc/0x160
Jun 15 13:35:05 s050009088 kernel:  __do_munmap+0x2aa/0x500
Jun 15 13:35:05 s050009088 kernel:  mmap_region+0x248/0x650
Jun 15 13:35:05 s050009088 kernel:  do_mmap+0x3b4/0x5c0
Jun 15 13:35:05 s050009088 kernel:  vm_mmap_pgoff+0xcb/0x120
Jun 15 13:35:05 s050009088 kernel:  ksys_mmap_pgoff+0x125/0x2b0
Jun 15 13:35:05 s050009088 kernel:  ? fput+0x13/0x20
Jun 15 13:35:05 s050009088 kernel:  ? ksys_ioctl+0x77/0x90
Jun 15 13:35:05 s050009088 kernel:  __x64_sys_mmap+0x33/0x40
Jun 15 13:35:05 s050009088 kernel:  do_syscall_64+0x57/0x190
Jun 15 13:35:05 s050009088 kernel:  entry_SYSCALL_64_after_hwframe+0x5c/0xc1
Jun 15 13:35:05 s050009088 kernel: RIP: 0033:0x7fbf936fc8e6
Jun 15 13:35:05 s050009088 kernel: Code: 00 00 00 00 f3 0f 1e fa 41 f7 c1 ff 0f 00 00 75 2b 55 48 89 fd 53 89 cb 48 85 ff 74 37 41 89 da 48 89 ef b8 09 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 62 5b 5d c3 0f 1f 80 00 00 00 00 48 8b 05 71
Jun 15 13:35:05 s050009088 kernel: RSP: 002b:00007ffd116cf078 EFLAGS: 00000206 ORIG_RAX: 0000000000000009
Jun 15 13:35:05 s050009088 kernel: RAX: ffffffffffffffda RBX: 0000000000000032 RCX: 00007fbf936fc8e6
Jun 15 13:35:05 s050009088 kernel: RDX: 0000000000000000 RSI: 0000000000200000 RDI: 0000010004400000
Jun 15 13:35:05 s050009088 kernel: RBP: 0000010004400000 R08: 00000000ffffffff R09: 0000000000000000
Jun 15 13:35:05 s050009088 kernel: R10: 0000000000000032 R11: 0000000000000206 R12: 00000000044be5e0
Jun 15 13:35:05 s050009088 kernel: R13: 0000000000000001 R14: 00000000047d97c0 R15: 000000000430b450

## Eventually the watchdog reports the soft lockup
## Checking the PID against the one from the process that ran `tf.test.gpu_device_name()` shows that it must've caused this lockup

Jun 15 13:46:45 s050009088 kernel: watchdog: BUG: soft lockup - CPU#6 stuck for 22s! [python3:4167]
```
</details>"
tensorflow/tensorflow,2023-06-12 21:17:01,bug,tf.data.Dataset.map does not support randomization,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

Didn't try.

### Source

binary

### Tensorflow Version

tf 2.11.0

### Custom Code

Yes

### OS Platform and Distribution

MacOS

### Python version

Python 3.8

It seems like `tf.data.Dataset.map` does not support randomization from `numpy`.
For the sample code, it gives constant output from the `randint` function call, but if you switch the function from `numpy.random.randint` to `tf.random.uniform` (toggle the comment), then you get good randomization behavior. 
I am wondering if this is expected.

### Standalone code to reproduce the issue

```shell
a = [{""key"": i, ""value"": np.random.random()} for i in range(5)]
dict_of_list = pd.DataFrame.from_records(a).to_dict(
    orient=""list"")
keys = dict_of_list.keys()

dataset = tf.data.Dataset.zip(
    tuple([
        tf.data.Dataset.from_tensor_slices(dict_of_list[key]) for key in keys
    ])
)
dataset = dataset.map(lambda *x: {key: x[i] for i, key in enumerate(keys)})

for i in range(2):
    for b in dataset:
        print(""before map:"", i, b)

def test_function(x, f=""key"", low=0, high=100):
    #x[f] = tf.random.uniform(shape=(), minval=1, maxval=5, dtype=tf.int32) # this is randomized
    x[f] = np.random.randint(low=low, high=high) # this is not randomized
    return x

dataset = dataset.map(test_function)

for i in range(2):
    for b in dataset:
        print(""after map:"", i, b)
```


### Relevant log output

```shell
before map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=0>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.9599878>}
before map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.5124935>}
before map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39335275>}
before map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=3>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.1416868>}
before map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=4>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39475128>}
before map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=0>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.9599878>}
before map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.5124935>}
before map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39335275>}
before map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=3>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.1416868>}
before map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=4>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39475128>}
after map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.9599878>}
after map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.5124935>}
after map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39335275>}
after map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.1416868>}
after map: 0 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39475128>}
after map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.9599878>}
after map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.5124935>}
after map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39335275>}
after map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.1416868>}
after map: 1 {'key': <tf.Tensor: shape=(), dtype=int32, numpy=44>, 'value': <tf.Tensor: shape=(), dtype=float32, numpy=0.39475128>}
```
</details>"
tensorflow/tensorflow,2023-06-12 10:35:48,bug,Functional Bug：Could not interpret serialized activation function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Have you reproduced the bug with TF nightly?

No

### Source

source

### Tensorflow Version

tf2.12.0

### Custom Code

Yes

### OS Platform and Distribution

MacOs

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

#### Output

```
Could not interpret serialized activation function: Tensor(""conv1a/BiasAdd:0"", shape=(None, 224, 224, 64), dtype=float32)
```

#### Document

| `activation` | Activation function to use. If you don't specify anything, no activation is applied (see [`keras.activations`](https://www.tensorflow.org/api_docs/python/tf/keras/activations)). |
| ------------ | ------------------------------------------------------------ |

### Standalone code to reproduce the issue
```py
x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, activation=""deserialize"", padding=""same"", name=""conv1a"")(input_tensor)
```

```py
x = keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, activation=""serialize"", padding=""same"", name=""conv1a"")(input_tensor)
```


### Relevant log output

_No response_</details>"
tensorflow/tensorflow,2023-06-12 06:50:40,bug,Image Segmenter | tflite-suuport | AttributeError: type object 'SegmentationOptions' has no attribute 'OutputType',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Have you reproduced the bug with TF nightly?

Yes

### Source

source

### Tensorflow Version

tflite-support 0.1.0a1

### Custom Code

No

### OS Platform and Distribution

MacOS Ventura 13.4

### Mobile device

_No response_

### Python version

3.8.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

The syntax provided for using [Image Segmenter](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/inference_with_metadata/task_library/image_segmenter.md)  did not execute ```processor.SegmentationOptions``` in python environment.

### Possible Fix:
The line 
``` 
segmentation_options = processor.SegmentationOptions(
    output_type=processor.SegmentationOptions.OutputType.CATEGORY_MASK) 
``` 
should have been 
```
segmentation_options = processor.SegmentationOptions(
    output_type=processor.SegmentationOptions.output_type.CATEGORY_MASK) 
```



### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/inference_with_metadata/task_library/image_segmenter.md#step-2-using-the-model-2
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""image_segmenter.py"", line 8, in <module>
    segmentation_options = processor.SegmentationOptions(output_type=processor.SegmentationOptions.OutputType.CATEGORY_MASK)
AttributeError: type object 'SegmentationOptions' has no attribute 'OutputType'
```
</details>"
microsoft/vscode,2023-09-29 12:23:43,bug,When saving new file with some content in a readonly directory VSCode creates an empty file instead,"Type: <b>Bug</b>

1. Use the following settings.json file:
{
	""files.readonlyInclude"": {
		""**"": true
	}
}

2. Create temporary file with some content in editor:
![image](https://github.com/microsoft/vscode/assets/53169542/c61a4c4f-0a54-43da-93ee-392c05b64f19)

3. Save file somewhere on the computer:
![image](https://github.com/microsoft/vscode/assets/53169542/d95c98a3-6648-491f-9b1b-5b068e6d0c05)


4. The file created by VSCode is empty, this is a bug:
![image](https://github.com/microsoft/vscode/assets/53169542/ba8274b5-502c-4dfc-a262-9129575d4d0b)



VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.22621
Modes: Unsupported

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i5-1235U (12 x 2496)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.69GB (6.78GB free)|
|Process Argv||
|Screen Reader|no|
|VM|0%|
</details>Extensions: none<details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
2e4cg342:30602488
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
9b8hh234:30694863
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
copilotsettingt:30839829
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
pythonmhint1:30842940
dsvsc015:30845448

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-29 00:21:41,bug,Can't use icon contributed using TTF file ,"Does this issue occur when all extensions are disabled?: Yes

- VS Code Version: 1.82.2
- OS Version: macOs Monterey 12.3

Steps to Reproduce:

1.  Created a ttf font file using https://glyphter.com/ select any icon and font character ( I have selected G)
2. Update the package.json to include the ttf file ```icons"": {
      ""my-icon-id"": {
        ""description"": ""my icon"",
        ""default"": {
          ""fontPath"": ""./check.ttf"",
          ""fontCharacter"": ""G""
        }
      }
    }```
3. Create Status bar item with text `$(my-icon-id): text`
4. The Icon needs to show up but the character G shows up instead


![image](https://github.com/microsoft/vscode/assets/105740053/7aa6e9e1-866a-47e3-9a71-21d450367b0e)

Attached my font file
[glyphter-font.zip](https://github.com/microsoft/vscode/files/12754778/glyphter-font.zip)

expected to show
![image](https://github.com/microsoft/vscode/assets/105740053/f828b843-e938-41d3-9dce-59e7df67b48b)


"
microsoft/vscode,2023-09-28 20:31:47,bug,focus cell output with ctrl+down does not visually select the output,"found testing for https://github.com/microsoft/vscode/issues/111255#issuecomment-1739961604

1. run a cell to get output
2. press ctrl+down to focus the output
:bug: visually, it looks like the cell container is focused."
microsoft/vscode,2023-09-28 17:39:52,bug,terminal accessible view opens unexpectedly,"1. create a terminal
2. quickly, use `alt+f1`
3. 🐛 the terminal accessible view opens, dynamic prompt data is shown"
microsoft/vscode,2023-09-28 11:47:28,bug,Clarify what `always` means,"The comment for `editor.codeActionsOnSave: always` just says ""Always trigger code actions on save"" but that's not true because format on delay isn't a trigger reason. This should be mentioned explicitly because other folks are confused. Also, the `#setting.name#` syntax could be used to link to the required setting"
microsoft/vscode,2023-09-27 16:54:44,bug,clear persistent tasks when task reconnection is disabled,"When one disables task reconnection, the persistent tasks should get cleared."
microsoft/vscode,2023-09-27 09:29:19,bug,Comment widget jump to max height when switching editors,"Testing #194011



https://github.com/microsoft/vscode/assets/9205389/3ab5b357-900b-42bd-b31f-43887b71a3f0

"
microsoft/vscode,2023-09-27 01:32:39,bug,'Focus Session' button shows in debug toolbar in command center,"When there are multiple debug sessions, the dropdown action item shows in the debug toolbar here as a button that doesn't do anything. You can see it in the gif in https://github.com/microsoft/vscode/issues/194248

We could just hide that item when this setting is set"
microsoft/vscode,2023-09-26 21:52:13,bug,Comments accessibility help nits,"Testing #194012

The following commands are inconsistently treated in the accessibility help menu:

1. Run the command: Go to Previous Commenting Range, which is currently not triggerable via keybinding. <-- should just be listed as Go to Previous Commenting Range, aligning with Go to Next Commenting Range. Also, should be 'triggerable via a keybinding'
2. Run the command: Focus Sticky Scroll to focus the currently nested scopes. It is currently not triggerable by a keybinding. <--should just be listed as Focus Sticky Scroll

![Image](https://github.com/microsoft/vscode/assets/30305945/1d08f79e-144d-4ac9-9697-01f1b144aa4a)

"
microsoft/vscode,2023-09-26 21:21:31,bug,Scrolling is blocked when mouse is on review comment,"Testing #194011 

I am able to see the text size grow fine with the existing comment,
but realized scrolling freezes/blocked when my mouse cursor is on the comment section. 

When I move the mouse cursor to the actual document itself, I am able to scroll back and forth in the document fine,
but scrolling seems to be stuck when cursor is in the comment block.

For example, place the mouse cursor in the black comment section and try scrolling up and down the document, scrolling will freeze. 
However, having mouse cursor in outside the comment section. In this case the green section, will not freeze the scrolling. 
<img width=""736"" alt=""Screenshot 2023-09-26 at 2 18 04 PM"" src=""https://github.com/microsoft/vscode/assets/62267334/8bc1f2bd-1602-4672-a24c-d5ae0eb007e3"">
"
microsoft/vscode,2023-09-26 18:24:06,bug,Top tab border wrong size with Pinned Tab Sizing shrink when scrolling/wrapping,"Testing #193991


Enable `workbench.editor.highlightModifiedTabs` and make a pinned editor dirty. Notice how the blue color appears over the entire tab bar:

![Image](https://github.com/microsoft/vscode/assets/900690/364847e8-0e94-4a17-9702-a8ef9bb81c15)

VS in stable:



![Image](https://github.com/microsoft/vscode/assets/900690/32ed3afd-604f-4d6b-94b6-ef18bab0970e)

"
microsoft/vscode,2023-09-26 18:06:22,bug,Wrapping tabs needs a smaller threshold for disabling wrapping when 2 rows show,"Testing #193991

See here:



![Image](https://github.com/microsoft/vscode/assets/900690/9bd3880a-9d96-46e1-aff4-6d2995d4c93a)

When many tabs are wrapping and height is little, at once point we disable wrapping to make room for the editor. I think this limit now needs to account for when 2 tab rows are showing."
microsoft/vscode,2023-09-26 18:00:39,bug,Active pinned tab has no separation to other tab row,"Testing #193991

With the default light modern theme and this layout:



![Image](https://github.com/microsoft/vscode/assets/900690/28c83b39-7cff-4e6a-974d-d517167d02da)


See how the active tab in the first row shows no border to the bottom row. I think I would have expected the border to go through here."
microsoft/vscode,2023-09-26 17:24:21,bug,Navigating to previous comment thread with shift+alt+f9 does not work on Linux,"Testing #194012

The accessibility help says this should work, but it does not appear to do anything




https://github.com/microsoft/vscode/assets/2230985/ac26c4b2-d04d-45f4-a261-e1532065ce64

"
microsoft/vscode,2023-09-26 16:09:03,bug,Don't observe any result from Run Recent Command,"Testing #193852

Testing on Windows 11.

- `alt+f1` opens terminal accessibility help dialog correctly:

![Image](https://github.com/microsoft/vscode/assets/25310137/81624354-dc49-4cd3-bdaf-b4c95f929e4e)

- Explore options, decide I want to try Run Recent Command (`Control+Alt+R`)
- `alt+f2` to open terminal accessible view, opens correctly:

![Image](https://github.com/microsoft/vscode/assets/25310137/4a1ced9f-e542-4efd-9b7b-ac22e56f62c4)

- Try `Control+Alt+R`
- ❓ I don't observe anything happen - but maybe I'm misunderstanding what should happen or how I should set this command up?

"
microsoft/vscode,2023-09-26 14:17:07,bug,Missing background color when showing inline chat inbetween ,"* open inline chat on a mid sized method/function
* the whole function gets included (by the chat extension)
* 🐛 the background color isn't contiguous 

<img width=""963"" alt=""Screenshot 2023-09-26 at 16 15 59"" src=""https://github.com/microsoft/vscode/assets/1794099/06155884-3cf2-4e8e-a43c-c548a5b5d365"">
"
microsoft/vscode,2023-09-26 13:50:26,bug,Can not set breakpoint in .c files,"Testing #194071

I have the DWARF extension installed but I can not set breakpoint in `.c` files.
Should Dwarf contribute the ability to set breakpoints in `c` files?

Or am I missing something?"
microsoft/vscode,2023-09-26 13:24:02,bug,SCM Sync: File change shows `COMMIT^`,"Testing #194016

Although technically correct, we should use the actual commit's short hash, not the `PARENT^` syntax, for left side:

![Image](https://github.com/microsoft/vscode/assets/22350/e582104b-7eb8-4ed0-82b3-a39fe760f071)

"
microsoft/vscode,2023-09-26 12:52:53,bug,Make max comment area height depend on editor height?,"Testing #194011

The constant max height works well with large editors. When the editor area is small, the comment can overgrow it. Maybe the max height could be constant unless the editor is very small."
microsoft/vscode,2023-09-26 10:11:07,bug,Quick diff decorations not rendering at all or rendering the wrong state,"Diff decorations are disappearing when switching to another file and back.

![Recording 2023-09-26 at 11 46 09](https://github.com/microsoft/vscode/assets/44439583/a8f68795-b39f-4176-a1ee-166ff349e564)

"
microsoft/vscode,2023-09-26 09:25:09,bug,Go to prev/next commands keybindings are not working in terminal,"Testing #193852



![Image](https://github.com/microsoft/vscode/assets/10746682/9a4a42e4-2e12-4577-b8b2-7a43819299ca)


Option + Down/Up arrow in terminal is not navigating between commands. These are working only in accessibility view. In terminal the keybindings are cmd + Down/Up arrow.

"
microsoft/vscode,2023-09-25 20:57:05,bug,"Settings Sync gets stuck at ""Turning on Settings Sync..."" after turning it off","<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->

Does this issue occur when all extensions are disabled?: Yes

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->

- - VS Code Version: 
Version: 1.83.0-insider (user setup)
Commit: 109e1f8d8afb754ed31317f79937a44e98d5063b
Date: 2023-09-25T10:41:26.295Z
Electron: 25.8.2
ElectronBuildId: 23977753
Chromium: 114.0.5735.289
Node.js: 18.15.0
V8: 11.4.183.29-electron.0

- - OS Version: 
OS: Windows_NT x64 10.0.23550

Steps to Reproduce:

1. Turn on Settings Sync
2. Do not select anything to sync (leave all checkboxes unchecked) and click on ""Sign in to Sync""
3. Sign in (used my GH account, Insiders)
4. Get a notification that Settings Sync is on
5. Go back to the gear, Turn off Settings Sync

Result:


![Image](https://github.com/microsoft/vscode/assets/1487073/e8b7f418-8f11-42c8-b3b2-fe09a0037a74)

The only way out of this is to restart VS Code (reload Window doesn't fix it). Once you do that, it appears to be turned off, everything is normal again.
"
microsoft/vscode,2023-09-25 15:42:54,bug,"[Accessibility] Take out ""Exit this dialog (Escape)."" from terminal accessible view","
Type: <b>Bug</b>

Tested with terminal created in editor area.

At the bottom of the terminal buffer (accessible view), there is an instruction:

> Exit this dialog (Escape).

Users may not want to hear this instruction all the time. Please consider removing this instruction when verbosity setting is off.

VS Code version: Code - Insiders 1.83.0-insider (109e1f8d8afb754ed31317f79937a44e98d5063b, 2023-09-25T10:41:26.295Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1145G7 @ 2.60GHz (8 x 2611)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (4.73GB free)|
|Process Argv|. --crash-reporter-id b05b88e5-8894-4031-ae34-fa034ebddea9|
|Screen Reader|yes|
|VM|0%|
</details><details><summary>Extensions (91)</summary>

Extension|Author (truncated)|Version
---|---|---
android-dev-ext|ade|1.3.2
aiprm-lang|AIP|0.0.2
Bookmarks|ale|13.4.1
openscad|Ant|1.2.1
spellright|ban|3.0.118
zoterolatex|bna|0.4.1
mermaid-markdown-syntax-highlighting|bpr|1.5.2
doxdocgen|csc|1.4.0
vscode-markdownlint|Dav|0.52.0
vscode-eslint|dba|2.4.2
vscode-quick-select|dba|0.2.9
vscode-deno|den|3.23.1
gitlens|eam|14.3.0
EditorConfig|Edi|0.16.4
prettier-vscode|esb|10.1.0
vscode-google-translate|fun|1.4.13
codespaces|Git|1.15.3
copilot|Git|1.115.437
copilot-chat|Git|0.8.2023092502
remotehub|Git|0.60.0
vscode-github-actions|git|0.26.2
vscode-pull-request-github|Git|0.72.0
overleaf-workshop|iam|0.2.4
cslpreview|igo|0.2.2
easy-snippet|inu|0.6.3
path-autocomplete|ion|1.25.0
latex-workshop|Jam|9.14.0
lilypond-syntax|jea|0.1.1
scheme|jea|0.2.0
better-cpp-syntax|jef|1.17.2
google-search|kam|0.0.1
vscode-lua-format|Koi|1.3.8
lilypond-formatter|lhl|0.2.3
lilypond-pdf-preview|lhl|0.2.8
lilypond-snippets|lhl|0.1.1
vslilypond|lhl|1.7.3
zotero|mbl|0.1.10
git-graph|mhu|1.30.0
vscode-docker|ms-|1.26.1
black-formatter|ms-|2023.4.1
flake8|ms-|2023.6.0
isort|ms-|2023.11.12681021
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.20
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.312.0
remote-ssh|ms-|0.106.4
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.4
vscode-remote-extensionpack|ms-|0.24.0
azure-repos|ms-|0.36.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
js-debug-nightly|ms-|2023.9.2117
powershell|ms-|2023.6.0
remote-repositories|ms-|0.38.1
vscode-github-issue-notebooks|ms-|0.0.129
vscode-selfhost-test-provider|ms-|0.3.18
vscode-serial-monitor|ms-|0.10.0
vsliveshare|ms-|1.0.5883
autodocstring|njp|0.6.1
pandocciter|not|0.10.3
shiny-python|Pos|0.1.4
shinyuieditor|pos|0.4.3
quarto|qua|1.100.0
r-debugger|RDe|0.5.4
java|red|1.22.1
vscode-xml|red|0.26.1
r|REd|2.8.1
multi-command|ryu|1.6.0
vscode-deepl|soe|1.0.6
abc-music|sof|0.4.0
lua|sum|3.7.0
latex-utilities|tec|0.4.10
cmake|twx|0.0.17
errorlens|use|3.13.0
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-arduino|vsc|0.6.0
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.14
vscode-java-test|vsc|0.40.0
vscode-maven|vsc|0.42.0
markdown-all-in-one|yzh|3.5.1
grammarly|znc|0.22.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805cf:30301675
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012:30540252
pynewext54:30618038
a9j8j154:30646983
showlangstatbar:30737417
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
asynctok:30821568
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonlinttype:30823781
pythonmpsinfo:30842935
dsvsc015:30821418
pythontestfixt:30826906
pythonfb280951:30830809
pythonregdiag:30842812

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-25 14:48:45,bug,SCM sync view actions are contributed to all views,"SCM Sync view refresh command:

![Image](https://github.com/microsoft/vscode/assets/10746682/59c0035d-5fba-4ce7-a1b7-876e52a94687)

"
microsoft/vscode,2023-09-25 12:52:09,bug,Debug controls in command center appear and rightaway disappear on window reload,"1. Reload vscode window (given you have setting to put debug controls in the command center
2. 🐛 notice how the command center includes debug controls and then right away disappear

See: 

https://github.com/microsoft/vscode/assets/16353531/747f1931-8688-48f2-853c-ab8723c38fd1

# Version 

```
Version: 1.83.0-insider
Commit: c72447e8d8aaa7497c9a4bd68bc4301584b92beb
Date: 2023-09-22T09:31:18.274Z
Electron: 25.8.1
ElectronBuildId: 23779380
Chromium: 114.0.5735.289
Node.js: 18.15.0
V8: 11.4.183.29-electron.0
OS: Darwin arm64 22.6.0
```"
microsoft/vscode,2023-09-22 18:45:58,bug,Profile icon missing,"Type: <b>Bug</b>

In yesterday's Insider I changed the icon for my Documentation profile. Atfer the update today it's gone. Reloading the window didn't help.

<img width=""177"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/4674940/47a447f3-55ff-4931-a1f2-a112ad33f5e0"">


VS Code version: Code - Insiders 1.83.0-insider (c72447e8d8aaa7497c9a4bd68bc4301584b92beb, 2023-09-22T09:31:18.274Z)
OS version: Darwin arm64 22.6.0
Modes:
Remote OS version: Linux x64 5.8.0-1039-azure


<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-21 19:46:59,bug,next/previous commenting range command doesn't work,I'm on a mac. setting it to be `option+f10` works though
microsoft/vscode,2023-09-21 17:38:15,bug,[Accessibility] alt+UpArrow and alt+DownArrow does not work as expected in terminal buffer accessible view,"Type: <b>Bug</b>

CC @meganrogge 

1. Create a terminal in editor area

1. type `echo hello; echo world` in the terminal

1. Press alt+f2 to open Accessible View

1. Press alt+UpArrow and alt+DownArrow to see if it moves between executed commands.

* Notes: alt+DownArrow unexpectedly opens a new terminal view.

VS Code version: Code - Insiders 1.83.0-insider (11bfd76a61a299156a9f3138ecfad70937af3527, 2023-09-21T05:34:38.227Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1145G7 @ 2.60GHz (8 x 2611)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (5.33GB free)|
|Process Argv|--crash-reporter-id b05b88e5-8894-4031-ae34-fa034ebddea9|
|Screen Reader|yes|
|VM|0%|
</details><details><summary>Extensions (91)</summary>

Extension|Author (truncated)|Version
---|---|---
android-dev-ext|ade|1.3.2
aiprm-lang|AIP|0.0.2
Bookmarks|ale|13.4.1
openscad|Ant|1.2.1
spellright|ban|3.0.118
zoterolatex|bna|0.4.1
mermaid-markdown-syntax-highlighting|bpr|1.5.2
doxdocgen|csc|1.4.0
vscode-markdownlint|Dav|0.51.0
vscode-eslint|dba|2.4.2
vscode-quick-select|dba|0.2.9
vscode-deno|den|3.23.1
gitlens|eam|14.3.0
EditorConfig|Edi|0.16.4
prettier-vscode|esb|10.1.0
vscode-google-translate|fun|1.4.13
codespaces|Git|1.15.3
copilot|Git|1.115.430
copilot-chat|Git|0.8.2023092101
remotehub|Git|0.60.0
vscode-github-actions|git|0.26.2
vscode-pull-request-github|Git|0.72.0
overleaf-workshop|iam|0.2.1
cslpreview|igo|0.2.2
easy-snippet|inu|0.6.3
path-autocomplete|ion|1.25.0
latex-workshop|Jam|9.14.0
lilypond-syntax|jea|0.1.1
scheme|jea|0.2.0
better-cpp-syntax|jef|1.17.2
google-search|kam|0.0.1
vscode-lua-format|Koi|1.3.8
lilypond-formatter|lhl|0.2.3
lilypond-pdf-preview|lhl|0.2.8
lilypond-snippets|lhl|0.1.1
vslilypond|lhl|1.7.3
zotero|mbl|0.1.10
git-graph|mhu|1.30.0
vscode-docker|ms-|1.26.1
black-formatter|ms-|2023.4.1
flake8|ms-|2023.6.0
isort|ms-|2023.11.12061012
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.20
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.311.0
remote-ssh|ms-|0.106.4
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.4
vscode-remote-extensionpack|ms-|0.24.0
azure-repos|ms-|0.36.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
js-debug-nightly|ms-|2023.9.2017
powershell|ms-|2023.6.0
remote-repositories|ms-|0.38.1
vscode-github-issue-notebooks|ms-|0.0.129
vscode-selfhost-test-provider|ms-|0.3.18
vscode-serial-monitor|ms-|0.10.0
vsliveshare|ms-|1.0.5883
autodocstring|njp|0.6.1
pandocciter|not|0.10.3
shiny-python|Pos|0.1.4
shinyuieditor|pos|0.4.3
quarto|qua|1.98.0
r-debugger|RDe|0.5.4
java|red|1.22.1
vscode-xml|red|0.26.1
r|REd|2.8.1
multi-command|ryu|1.6.0
vscode-deepl|soe|1.0.6
abc-music|sof|0.4.0
lua|sum|3.7.0
latex-utilities|tec|0.4.10
cmake|twx|0.0.17
errorlens|use|3.13.0
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-arduino|vsc|0.6.0
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.14
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
markdown-all-in-one|yzh|3.5.1
grammarly|znc|0.22.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805cf:30301675
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012:30540252
pynewext54:30618038
a9j8j154:30646983
showlangstatbar:30737417
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
asynctok:30821568
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonlinttype:30823781
pythonmpsinfo:30815194
dsvsc015:30821418
pythontestfixt:30826906
pythonfb280951:30830809

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-20 21:51:20,bug,goto symbol cell decorations do not persist for multiple symbols in a single cell,"Steps to Reproduce:

1. create a notebook with a markdown cell that has multiple headers e.g.
```
# header 

## sub header
```
3. Show the preview for the markdown cell - shift+enter
4. open symbols quickpick ctrl+shift+o and arrow down through the symbols list
:bug: cell decoration appears for the first item but then is removed for the second
"
microsoft/vscode,2023-09-20 15:32:48,bug,focusing a task terminal tab removes its status,"1. run a task, like `VS Code - Build`
2. click on the terminal tab for one of the task terminals
3. 🐛 the status is gone"
microsoft/vscode,2023-09-20 12:32:11,bug,Quick diff should not run in diff editor,"I think we had it disabled there:

![Image](https://github.com/microsoft/vscode/assets/900690/77f902a0-1671-4385-ac79-659e6ed101f8)

"
microsoft/vscode,2023-09-19 16:13:02,bug,Issue Reporter doesn't have a placeholder in the Extension drop down,"![Image](https://github.com/microsoft/vscode/assets/2644648/dfa5caf6-cb4e-489c-83a4-6dd5afdc4e28)

This is needed for accessibility. 
"
microsoft/vscode,2023-09-19 11:31:03,bug,[Accessibility] ctrl+DownArrow in editor-type terminal buffer creates a new terminal view,"
Type: <b>Bug</b>

## Reproducible Steps

1. Terminal: Create New Terminal in Editor Area

1. Type `echo hello` and hit enter.

1. Press alt+f2 to open accessible terminal buffer.

1. In the accessible terminal buffer, press ctrl+DownArrow to see if your focus goes back to the terminal input area.

* Notes: Pressing ctrl+DownArrow unexpectedly creates a new terminal view.

VS Code version: Code - Insiders 1.83.0-insider (7c7f7eee860e299499a3bd2915ad716f09f2d6a6, 2023-09-19T08:56:35.775Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1145G7 @ 2.60GHz (8 x 2611)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (5.70GB free)|
|Process Argv|C:\\\\Users\\\\jseo1005\\\\OneDrive - University of Illinois - Urbana\\\\Desktop\\\\source.R --crash-reporter-id b05b88e5-8894-4031-ae34-fa034ebddea9|
|Screen Reader|yes|
|VM|0%|
</details><details><summary>Extensions (91)</summary>

Extension|Author (truncated)|Version
---|---|---
android-dev-ext|ade|1.3.2
aiprm-lang|AIP|0.0.2
Bookmarks|ale|13.4.1
openscad|Ant|1.2.1
spellright|ban|3.0.118
zoterolatex|bna|0.4.1
mermaid-markdown-syntax-highlighting|bpr|1.5.2
doxdocgen|csc|1.4.0
vscode-markdownlint|Dav|0.51.0
vscode-eslint|dba|2.4.2
vscode-quick-select|dba|0.2.9
vscode-deno|den|3.22.0
gitlens|eam|14.3.0
EditorConfig|Edi|0.16.4
prettier-vscode|esb|10.1.0
vscode-google-translate|fun|1.4.13
codespaces|Git|1.15.3
copilot|Git|1.112.422
copilot-chat|Git|0.8.2023091901
remotehub|Git|0.60.0
vscode-github-actions|git|0.26.2
vscode-pull-request-github|Git|0.72.0
overleaf-workshop|iam|0.1.5
cslpreview|igo|0.2.2
easy-snippet|inu|0.6.3
path-autocomplete|ion|1.25.0
latex-workshop|Jam|9.14.0
lilypond-syntax|jea|0.1.1
scheme|jea|0.2.0
better-cpp-syntax|jef|1.17.2
google-search|kam|0.0.1
vscode-lua-format|Koi|1.3.8
lilypond-formatter|lhl|0.2.3
lilypond-pdf-preview|lhl|0.2.8
lilypond-snippets|lhl|0.1.1
vslilypond|lhl|1.7.3
zotero|mbl|0.1.10
git-graph|mhu|1.30.0
vscode-docker|ms-|1.26.0
black-formatter|ms-|2023.4.1
flake8|ms-|2023.6.0
isort|ms-|2023.11.12061012
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.311.0
remote-ssh|ms-|0.106.4
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.3
vscode-remote-extensionpack|ms-|0.24.0
azure-repos|ms-|0.36.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
js-debug-nightly|ms-|2023.9.1317
powershell|ms-|2023.6.0
remote-repositories|ms-|0.38.1
vscode-github-issue-notebooks|ms-|0.0.129
vscode-selfhost-test-provider|ms-|0.3.18
vscode-serial-monitor|ms-|0.10.0
vsliveshare|ms-|1.0.5883
autodocstring|njp|0.6.1
pandocciter|not|0.10.3
shiny-python|Pos|0.1.4
shinyuieditor|pos|0.4.3
quarto|qua|1.98.0
r-debugger|RDe|0.5.4
java|red|1.22.1
vscode-xml|red|0.26.1
r|REd|2.8.1
multi-command|ryu|1.6.0
vscode-deepl|soe|1.0.6
abc-music|sof|0.4.0
lua|sum|3.7.0
latex-utilities|tec|0.4.10
cmake|twx|0.0.17
errorlens|use|3.13.0
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-arduino|vsc|0.6.0
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.14
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
markdown-all-in-one|yzh|3.5.1
grammarly|znc|0.22.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805cf:30301675
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012:30540252
pynewext54:30618038
a9j8j154:30646983
showlangstatbar:30737417
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
asynctok:30821568
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonlinttype:30823781
pythonmpsinfo:30815194
dsvsc015:30821418
pythontestfixt:30826906
pythonfb280951:30830809

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-19 08:18:23,bug,`treeView.message = undefined` should not block `viewsWelcome` from appearing,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.82.2
- OS Version: MacOS 13.5.2

Steps to Reproduce:

1.  Use VSCode treeView with a `viewsWelcome`, make sure the treeView is empty
2. Set the `treeView.message` to `undefined`
3. The viewWelcome is not shown

A minimal reproducible example is accessible on here: https://github.com/JulesFaucherre/vscode-views-welcome-issue

Expected behaviour:
Setting the `treeView.message` to `undefined` should make VSCode consider the message as empty and show the `viewsWelcome`
"
microsoft/vscode,2023-09-18 15:33:48,bug,Add placeholder to terminal change icon and color,"
![Image](https://github.com/microsoft/vscode/assets/2193314/8426150c-4e22-4c1d-b593-20b679f8d863)



![Image](https://github.com/microsoft/vscode/assets/2193314/71e7f511-2e4d-4f61-b9ed-02c75ca742ba)

Feedback from @TylerLeonhardt (not Daniel)"
microsoft/vscode,2023-09-18 13:01:47,bug,Moved Code False Positive,"## Description

This shouldn't be reported as moved code:

![Image](https://github.com/microsoft/vscode/assets/2931520/55d22ed7-745a-4986-955d-095318261482)

## Playground Example

[Monaco Editor Playground Repro](https://microsoft.github.io/monaco-editor/playground.html?source=v0.44.0-dev-20230918#XQAAAAIsEQAAAAAAAABBqQkHQ5NjdMeMm-jY7SIQ9S7DNlzs5W-mwj0fe1ZCDRFc9ws9XQE0SJE1jc2VKxhaLFIw9vEWdz-byd4PZMRoX4gTjZnHx_R_ugxZ6xrWgz8k0rlYVGZfwQ3QjH2GDw7bI_8paqOoYtw1AXFwYvJQ2FfcOWSRahkBHGInNz3PAvwl_7dvt_t-U0EqT7d84tbHaNJn2VlyRnFjSHABEeOUEdj9uKE_cVVjDoTQKgsghW9AdkqG91KvfMnkGo54qtZN0NuTQQiGrECXstCzNNYiJ5eqZLR-kDMq3ioY3wUKZKR339FqiM85rpYMX3U7H7ZagWHMnGCe76NMJI9anHfKtN14glLZSsJaUuhI4o33VBry0N8CSRtzj4NBJxzjy8q-kVpH600hdxgpev30KDXyKXkYwzwnTlkm3LXCH_r6QL0KV4ScFa0MSn-sRhLwivAsWKIXQMJHVMaFAOdev3d6M5xRJcQLleeTZdoBL8hyCjKLvNf8kXrMxTTof2v9d5NTl5GCw08hjEdV2RgzO_1Hy-tgu9Y-qfi7Si_mKwQs2czvDaP93CPW1A43AXdrEj-Bw4JJ2nVj47XrP2ewQ5ib9Om3DtZnMEkloyHwwmjZaflapZ1J7C8orzOLyCtIH2F2lFmvmx4TSNZzg7N8tqZ8S15fCEgs0fLGO7rvmyYEAktizEXAVQm429H8MFvKyK2UnzM8bleOqfgJl89wvkdYWDEjWSDVqTaWIx6_xRgO8F9Z1vTeNNx8llopDGhdJT7Y1H9eylE2w0vpG4K-gamagcDSyM8r69jN6O4ftFYYdDa-l74PIj39gNq_Wv7gyebxdgS_udXrCZy_sStdtPqT4cMC3Iib3NHvEqdTOr-_TruCPmlrkAeDp9WV9Upoau7lP0ACLElVjJ-hV07tn_NpehEUaDanqxMU0EQXYqWPIwy0dzC5H_EwG7JGvMR60erNdNqUipJdVKjIz5sGzBRkR1DHdEGi9f6AWaxESEiituR6besuI6QNksYwdWPi90g8u0ogXNWnefUW68smWzWZytsNbzbIpSPGxWszQlP7T07MWethbgGbOfF_KpD534tr_olPhls9u8wOySlee-5nrj_KTEfbbR6HwNpRh8RIaVWW2wFbO7hR5mRF8pncONWOuTLrVQ4RJyf_c005ywBcmwh51LH9jeRgsLeXaGrBI1feipEKYMysn0-TjrMXGm0IsmYhtvPgHNPv7BcgkWFUTTcCsNY7sH5E_aj2NNE6qx-agjWgEQ9wR6cBSm37wijysFmBodaCtAQJojfm5y9x2CIXcV15NSbdSWVFS3OQ4uXMgLnj4GeCJqVydIH8PYm0g3-icau8rQniIk7qDLv3GR965NAcOJYbWaObhrhOB7GCrbC_qXO0TYDW57XIjIWdjFgCGB5_odB_JJxdwSrydElv7IC_xOTOIcQLtF1F2LULAs0E4dbAcsfPUoVEuHGa5qnLYWWxPQu9Aqhn6Fuv2_OGFEEasQea8_6QvMRrBeJ4f79DxRRWQs5I_8dMT3520s_oZlLoGA0VZ8VhzVEDBH63xa2Lu7qjK1OtH0ZaOFVF42D28wC34GEBEs9KcyJdrWNQlCs-66uako4E7k914aQ_bGp7V--F6iRzVi620BVukrAky6DOynT9J0AxuANc8tyQtqIZcQup9lH35BqPO41j_6D9UhA) (click on ""use latest dev"" to verify a future bug-fix)

[Another example](https://microsoft.github.io/monaco-editor/playground.html?source=v0.43.0#XQAAAAIbCQAAAAAAAABBqQkHQ5NjdMjwa-jY7SIQ9S7DNlzs5W-mwj0fe1ZCDRFc9ws9XQE0SJE1jc2VKxhaLFIw9vEWSxW3yscxFQXNaAEiAJM8XEuX7Os378jBGtVLkr6ryuhqvky-XZ9Sy0vyFSI1m9nA63UIspIqwBpFUxr6TKoTm7Lj0ldqb6KNTnicdxofWGXSbb3VEBw_wA6G-1h9NbNQDd-qCGjqj8n5A77-Sqv2khwOu74g-hdag0k-w5GM1zL9QrDauyUhHVZ5ASogUPKZu_US0vi2zH2STmW20YpbDq0cCFx9OYbPN1pxE4LeYcRMhylqn1OtS5sh6ZGtbfkQr6217Z6fm5MPuj4id7f5IVDYC3jDM84PHRtP_D6JAMAK6eK8ADG6NHqsw9HSZSRDE81SqL5WX0l6F2OuNkHHyYBSgayYrkN0p-xDbkyFttZUH728xDhU8uWKiwaEj8FVQ-sMdtlaFMul00DsvkX9A9Alh2cDNKa4eDPnPvbzEENHYqJyePf32s_seWD_E_XcBw6Cxr_LaE9zj4EsE5NegULSCmUTeI65ssAsDI1FWMKOaMraPLuNQu7Y7lPi-8Z9Eu7nNG5gyBxsEsyEIvASxYBPH9t8szZ7hfQMLEg9PSbryQb2K-lvJtewOPdhV7rqBTGpwAfxaY_vwSO3nBxrJ1qlR9m5hkPcSyHd1ZKnZG6OaJXUNUS3iHxdk97pxKjvYNoJpsKEBGbBMCdrCPqNQ63KjmWWtoO_Mg4NfPzhhlpo2XWR7bu4akmj648uNL624c4y-MNXSEBysBIlRT-eT2M8Dtvkq9EGB0Ke0mFcr_uvxWpgk6CZMuhoyKNFwSlExfLAaKOxNCgLLay6lPblcd0V2VvhcoBdUPrsn7JRSw_e0fwPNPyGzAaZg8qY6VAAR0Ex3LfQ3KJvJ506VzY1RfUJvWQXYVP29_bthj056_BJ710EErP6_TVPixeRy4rn0pMKZEWUcP6KLGntjgMjWU91xZsbHgWt2N3RL8QEh5r86xij-WwBYbu2UP9t-Rhpx6OcAEc7AR03vjaBbQuzfbWyBf1J0NjEBP7rwhg)"
microsoft/vscode,2023-09-17 17:51:10,bug,AADSTS500202 Pass-thru error trying to sign-in with  an MSA using 'microsoft' auth provider on github.dev,"The below code works fine in VS Code desktop, and in https://vscode.dev, but fails on https://github.dev **IF** using an MSA account. When I sign-in using my corp account (i.e. `*@microsoft.com`) is also works fine.

```ts
  log.debug(""Querying for account workspaces"");
  // *** Authenticate and retrieve tenants the user has Azure resources for ***

  // For the MSA case, you need to query the tenants first and get the underlying AzureAD
  // tenant for the 'guest' MSA. See https://stackoverflow.microsoft.com/a/76246/108570
  const firstAuth = await vscode.authentication.getSession(
    ""microsoft"",
    [scopes.armMgmt],
    { createIfNone: true }
  );
// NOTE: Doesn't even get to this line, so the above must throw.
  if (!firstAuth) {
    log.error(""No authentication session returned"");
    return;
  }
```

Below is the debug level output from the `Microsoft Authentication` channel:

```
2023-09-17 10:08:28.202 [info] Reading sessions from secret storage...
2023-09-17 10:08:28.202 [info] Got 0 stored sessions
2023-09-17 10:08:28.203 [info] Getting sessions for all scopes...
2023-09-17 10:08:28.203 [info] Got 0 sessions for all scopes...
2023-09-17 10:08:28.203 [info] Getting sessions for the following scopes: email offline_access openid profile
2023-09-17 10:08:28.203 [info] Got 0 sessions for scopes: email offline_access openid profile
2023-09-17 10:09:02.899 [info] Getting sessions for the following scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:09:02.899 [trace] No session found with idtoken scopes... Using fallback scope list of: https://management.azure.com/user_impersonation
2023-09-17 10:09:02.899 [info] Got 0 sessions for scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:09:05.852 [info] Logging in for the following scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:09:08.990 [info] Exchanging login code for token for scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:09:09.369 [error] Error exchanging code for token (for scopes email https://management.azure.com/user_impersonation offline_access openid profile): Error: {""error"":""invalid_grant"",""error_description"":""AADSTS500202: User account '{EmailHidden}' from external identity provider 'live.com' is not supported for API version '2.0'. Microsoft account pass-thru users and guests are not supported by the tenant-independent endpoint.\\r\\nTrace ID: 481ada76-a441-490d-aec8-5f6ab6141600\\r\\nCorrelation ID: c4c89d78-165c-4eff-9c4e-4518776450f4\\r\\nTimestamp: 2023-09-17 17:09:09Z"",""error_codes"":[500202],""timestamp"":""2023-09-17 17:09:09Z"",""trace_id"":""481ada76-a441-490d-aec8-5f6ab6141600"",""correlation_id"":""c4c89d78-165c-4eff-9c4e-4518776450f4""}
```

Using exactly the same code with the same MSA account but working on `https://vscode.dev` (or VS Code desktop) it works fine and the log shows: 

```
2023-09-17 10:35:57.937 [info] Reading sessions from secret storage...
2023-09-17 10:35:57.937 [info] Got 0 stored sessions
2023-09-17 10:35:57.937 [info] Getting sessions for all scopes...
2023-09-17 10:35:57.937 [info] Got 0 sessions for all scopes...
2023-09-17 10:35:57.937 [info] Getting sessions for the following scopes: email offline_access openid profile
2023-09-17 10:35:57.938 [info] Got 0 sessions for scopes: email offline_access openid profile
2023-09-17 10:36:03.229 [info] Getting sessions for the following scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:36:03.229 [info] Got 0 sessions for scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:36:05.259 [info] Logging in for the following scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:36:08.863 [info] Exchanging login code for token for scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:36:09.472 [info] Exchanging login code for token (for scopes: email https://management.azure.com/user_impersonation offline_access openid profile) succeeded!
2023-09-17 10:36:09.473 [info] Setting token for scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:36:09.474 [info] Login successful for scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:36:09.474 [info] Token available from cache (for scopes email https://management.azure.com/user_impersonation offline_access openid profile), expires in 4713999 milliseconds
2023-09-17 10:36:09.475 [info] Stored token for scopes: email https://management.azure.com/user_impersonation offline_access openid profile
2023-09-17 10:36:09.479 [info] Getting sessions for the following scopes: email offline_access openid profile
2023-09-17 10:36:09.480 [info] Refreshing token for scopes: email offline_access openid profile
2023-09-17 10:36:09.981 [info] Setting token for scopes: email offline_access openid profile
2023-09-17 10:36:09.982 [info] Token refresh success for scopes: email offline_access openid profile
2023-09-17 10:36:09.983 [info] Got 1 sessions for scopes: email offline_access openid profile
```

If interested, the extension I'm using is published at https://marketplace.visualstudio.com/items?itemName=quantum.qsharp-lang-vscode-dev and you can see the code for it at https://github.com/microsoft/qsharp/blob/main/vscode/src/azure/workspaceActions.ts#L27 .


<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
"
microsoft/vscode,2023-09-15 16:52:58,bug,Notebook list view height changes after toggling the panel off/on,"1. open a notebook where two cells take up more than the scrollable region
2. navigate between the two cells, note how far down the region scrolls
3. toggle the panel off/on
4. navigate between the two cells again
🐛 the scroll placement is different because `listView.renderHeight` returns a different value.

![Recording 2023-09-15 at 09 51 19](https://github.com/microsoft/vscode/assets/2019016/e88346f1-8bbd-433f-8b2a-0a09a700d826)
"
microsoft/vscode,2023-09-14 22:40:26,bug,Backup file system provider can not do buffered write,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.83-Insiders
- OS Version: macOS

I was verifying https://github.com/microsoft/vscode/issues/192970 and found that large file piece tree buffers are still merged before write. Turns out that backup is always doing `doWriteUnbuffered` since it's using `FileUserDataProvider`, which doesn't have `FileOpenReadWriteClose` capability so it always runs https://github.com/microsoft/vscode/blob/3b60c12380f5a9782439be309d8d2642835b8822/src/vs/platform/files/common/fileService.ts#L394-L395

and unfortunately unbuffered write always concatenates all `buffers` first 

https://github.com/microsoft/vscode/blob/3b60c12380f5a9782439be309d8d2642835b8822/src/vs/platform/files/common/fileService.ts#L1294

<img width=""977"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/876920/c0eca986-0220-49e3-bfdd-727e0a83ecde"">
"
microsoft/vscode,2023-09-14 12:48:59,bug,"Since latest update, each time debugging, annoying popup","Type: <b>Bug</b>

I don't use GitHub with VSCode.  

Since the latest update, each time I click the ""Open browser devtools"" button while debugging a site, I get the following popup dialog and have to click ""Cancel"".

""The extension 'Local Tunnel Port Forwarding' wants to sign in using GitHub.""

I've searched for the extension and am not finding it.

VS Code version: Code 1.82.1 (6509174151d557a81c9d0b5f8a5a1e9274db5585, 2023-09-08T08:45:05.575Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i9-12900K (24 x 3187)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|63.70GB (51.20GB free)|
|Process Argv||
|Screen Reader|no|
|VM|50%|
</details><details><summary>Extensions (17)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-intelephense-client|bme|1.9.5
vscode-eslint|dba|2.4.2
prettier-vscode|esb|10.1.0
vscode-browser-sync|jas|1.3.1
classic-asp-html|jtj|0.1.3
al-object-designer|mar|0.2.4
better-folding|Moh|0.5.1
vscode-docker|ms-|1.26.0
al|ms-|11.7.863928
vscode-edge-devtools|ms-|2.1.3
isort|ms-|2023.10.1
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10
vscode-icons|vsc|12.5.0
php-debug|xde|1.33.0
php-pack|xde|1.0.3
php-intellisense|zob|1.3.2


</details>
<!-- generated by issue reporter -->
![Screenshot 2023-09-14 054336](https://github.com/microsoft/vscode/assets/8278361/68531545-5a1b-46ab-b739-bf1417b11bab)
"
microsoft/vscode,2023-09-14 03:17:41,bug,Error messages from linters overlapping with chatprompt message,"* I have linters to ensure files have the right header, 
* when i created the empty ts file, i get the linter error as well as chat prompt
* However when I add an empty line, you can see the caht prompt does not appear and linter error is in the second line
![Screenshot 2023-09-14 at 13 12 33](https://github.com/microsoft/vscode/assets/1948812/ff339853-7365-4a86-8fc6-95f2aa28f2db)
![Screenshot 2023-09-14 at 13 12 27](https://github.com/microsoft/vscode/assets/1948812/a4119174-a596-46b3-9cc0-31b4e1370c92)
"
microsoft/vscode,2023-09-13 01:10:52,bug,Debug stop button doesn't work after restarting session,"- Start debugging python (not js because restart is handled inside the adapter)
- Click restart
- Click stop
- Nothing happens

This is from https://github.com/microsoft/vscode/pull/191913/files#diff-e79a396155cbc97a29fd0a1a4741975d29336d0683d751c7a4856c2ac1e46dbeR729. Similarly to https://github.com/microsoft/vscode/issues/192653, we reuse the DebugSession when restarting, then these get disposed and never readded. Maybe I can't really fix this until https://github.com/microsoft/vscode/issues/191904 is properly fixed. cc @jrieken "
microsoft/vscode,2023-09-12 21:07:48,bug,Log files created should be created under the log home folder of the process by default,"A logger file created in the window (renderer) process should create the log file scoped to that window. For example, following should create the view log file under the current window

```ts
loggerService.createLogger('view', { name: 'view' })
```

If a component wants to create the logger shared across windows, one should provide the log file while creating the logger as follows

```ts
loggerService.createLogger(joinPath(environmentService.logsHome, `${LOG_ID}.log`), { id: LOG_ID, name: LOGGER_NAME })
```"
microsoft/vscode,2023-09-12 20:37:27,bug,task status bar says `Building...` even after task statuses have been applied,only happens for tasks that have been reconnected
microsoft/vscode,2023-09-12 16:01:05,bug,`RPCProtocol._remoteCall` leaks a listener,"This handler for token cancellation is never disposed:

https://github.com/microsoft/vscode/blob/b78136d6f3963648e9dc97c350ae060a85e75997/src/vs/workbench/services/extensions/common/rpcProtocol.ts#L479-L483

Found it with the help of the new commands from https://github.com/microsoft/vscode/pull/192871 to track disposables in the app, opening and closing editors."
microsoft/vscode,2023-09-12 11:00:18,bug,Copy and pasting issues,"
Type: <b>Bug</b>

When I'm copying and pasting text from Onenote into VS Code editor it comes up like this `![Alt text](image.png)`.  How do I correct this

VS Code version: Code 1.82.0 (8b617bd08fd9e3fc94d14adb8d358b56e3f72314, 2023-09-06T22:07:07.438Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details><summary>Extensions (59)</summary>

Extension|Author (truncated)|Version
---|---|---
better-comments|aar|3.0.2
aws-toolkit-vscode|ama|1.89.0
LinkCheckMD|bla|0.3.1
excel-to-markdown-table|csh|1.3.0
vscode-markdownlint|Dav|0.51.0
docs-article-templates|doc|1.0.3
docs-authoring-pack|doc|1.0.0
docs-build|doc|0.4.1
docs-images|doc|1.0.1
docs-linting|doc|0.0.13
docs-markdown|doc|1.0.2
docs-metadata|doc|1.0.9
docs-preview|doc|1.0.3
docs-scaffolding|doc|1.0.0
docs-yaml|doc|1.0.1
gitlens|eam|14.3.0
pythonsnippets|frh|1.0.2
codespaces|Git|1.15.1
remotehub|Git|0.60.0
vscode-github-actions|git|0.26.2
vscode-pull-request-github|Git|0.72.0
go|gol|0.39.1
terraform|has|2.27.2
vsc-python-indent|Kev|1.18.0
vscode-docker|ms-|1.26.0
vscode-kubernetes-tools|ms-|1.3.13
data-workspace-vscode|ms-|0.5.0
mssql|ms-|1.20.1
sql-bindings-vscode|ms-|0.4.0
sql-database-projects-vscode|ms-|1.2.0
isort|ms-|2023.10.1
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.309.0
remote-ssh|ms-|0.106.3
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.3
vscode-remote-extensionpack|ms-|0.24.0
powershell|ms-|2023.6.0
remote-explorer|ms-|0.4.1
remote-repositories|ms-|0.38.1
remote-server|ms-|1.4.3
vscode-markdown-notebook|ms-|0.0.26
vsliveshare|ms-|1.0.5883
vsliveshare-pack|ms-|0.4.0
vscode-sanddance|msr|4.1.0
autodocstring|njp|0.6.1
vscode-yaml|red|1.14.0
vscode-taskexplorer|spm|2.13.2
code-spell-checker|str|3.0.1
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscodeintellicode-completions|Vis|1.0.22
vscode-icons|vsc|12.5.0

(7 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
2e4cg342:30602488
89544117:30613380
showlangstatbar:30737416
a2ce3375:30757347
57b77579:30736110
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015cf:30829746

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-11 17:17:27,bug,"UI Overlap With `window.nativeTabs: false`, `window.commandCenter: true`, and Tab per Project","Type: <b>Bug</b>

1. Have `window.nativeTabs: false` and `window.commandCenter: true`.
2. Open a project.
3. Open a new tab (i.e., on macOS, command + shift + N).
4. Open a new project in that tab (i.e., on macOS, control + R then select one).
5. Notice overlap of Command Center atop tabs.

| screenshot (dark mode) |
| - |
| ![vs code command center and tab per project](https://github.com/microsoft/vscode/assets/62723358/432cea87-b4c7-467c-9dda-f8ac4bfe4024) |

| screenshot (light mode) |
| - |
| ![Screenshot 2023-09-11 at 12 40 44 PM](https://github.com/microsoft/vscode/assets/62723358/b884815d-2f9d-40f2-89af-ec249d8ab9dc) |

https://github.com/microsoft/vscode/assets/62723358/594bd4f0-efe7-48df-9f4c-ec4baec46fcd

VS Code version: Code 1.82.0 (Universal) (8b617bd08fd9e3fc94d14adb8d358b56e3f72314, 2023-09-06T22:09:41.364Z)
OS version: Darwin arm64 22.6.0
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Apple M2 (8 x 24)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|2, 3, 3|
|Memory (System)|24.00GB (0.12GB free)|
|Process Argv|--crash-reporter-id 34098c29-9101-4ba7-b025-6e3e06616ace --crash-reporter-id 34098c29-9101-4ba7-b025-6e3e06616ace --crash-reporter-id 34098c29-9101-4ba7-b025-6e3e06616ace --crash-reporter-id 34098c29-9101-4ba7-b025-6e3e06616ace --crash-reporter-id 34098c29-9101-4ba7-b025-6e3e06616ace --crash-reporter-id 34098c29-9101-4ba7-b025-6e3e06616ace|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (34)</summary>

Extension|Author (truncated)|Version
---|---|---
yaml2json|ahe|0.0.5
vscode-css-modules|and|1.2.3
icons-carbon|ant|0.2.6
chalice-icon-theme|art|1.2.24
django-html|bib|1.3.0
markdown-checkbox|bie|0.4.0
markdown-footnotes|bie|0.1.1
postcss|css|1.0.9
vscode-markdownlint|Dav|0.51.0
mustache|daw|1.1.1
vscode-eslint|dba|2.4.2
gitlens|eam|14.3.0
vscode-html-css|ecm|1.13.1
EditorConfig|Edi|0.16.4
vscode-github-actions|git|0.26.2
vscode-env|Iro|0.1.0
vscode-edit-csv|jan|0.8.2
minifyall|jos|2.10.0
python-sphinx-highlight|leo|0.3.0
twig-language-2|mbl|0.9.2
rainbow-csv|mec|3.7.0
theme-monokai-pro-vscode|mon|1.2.1
language-gettext|mro|0.2.2
python|ms-|2023.16.0
color-highlight|nau|2.5.0
autodocstring|njp|0.6.1
vscode-yaml|red|1.14.0
synthwave-vscode|Rob|0.1.15
jinjahtml|sam|0.20.0
markdown-to-confluence-vscode|t-n|0.1.5
solarized-high-contrast-light|tin|0.4.0
vscode-css-custom-properties|Toc|0.0.5
simple-rst|tro|1.5.3
vscode-mdx|uni|1.4.0

(3 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vscaat:30438848
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
ecj1e332:30736112
pythonfmttext:30731395
f8hc8238:30694864
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-11 07:23:59,bug,"Update to 1.82.0, VSCode takes more time to kill processes after quit","Type: <b>Bug</b>

In this video, I quit VSCode at 7 seconds, but it (Dock Icon) was killed at 12 seconds.

https://github.com/microsoft/vscode/assets/19561959/8c970026-b060-4062-83af-f61e0219cfc4



VS Code version: Code 1.82.0 (8b617bd08fd9e3fc94d14adb8d358b56e3f72314, 2023-09-06T22:09:41.364Z)
OS version: Darwin x64 22.5.0
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz (8 x 2000)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|3, 3, 3|
|Memory (System)|32.00GB (13.43GB free)|
|Process Argv|--crash-reporter-id 25337f27-0fd6-4ad2-a343-d23e45e01d53|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (2)</summary>

Extension|Author (truncated)|Version
---|---|---
astro-vscode|ast|2.3.3
vscode-language-pack-zh-hans|MS-|1.82.2023090609


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
2e4cg342:30602488
f6dab269:30613381
2i9eh265:30646982
showlangstatbar:30737416
0bi6i642:30831757
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30821571
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-09 13:57:18,bug,Terminal link underline flickers and is re-evaluated when the buffer changes (but not on the current line),"Repro:

1. Run vscode tests
2. Scroll up
3. Hover a link, 🐛 it will flicker and be difficult to ctrl/cmd+click

Not sure yet if this is upstream or vscode."
microsoft/vscode,2023-09-09 11:59:32,bug,Terminal DOM renderer: Selection background is drawn incorrectly when unfocused,Upstream: https://github.com/xtermjs/xterm.js/issues/4750
microsoft/vscode,2023-09-09 01:47:54,bug,Cannot connect to the server after update,"The updated version is:

Version: 1.82.0 (Universal)
OS: Darwin arm64 22.1.0

The issue is ""Cannot reconnect. Please reload the window.""

But as I reload the window, it shows ""waiting for port forwarding to be ready""

=================
Update: I uninstalled the extension ""WSL"" and it solves the problem.

=================
Update:
Per #192740 , changing the SSH extension to the pre-release version can also help"
microsoft/vscode,2023-09-08 20:52:54,bug,Toggle collapse unchanged regions button is showing on every editor,Even ones without changes. Shouldn't it only show it diffs?
microsoft/vscode,2023-09-08 16:25:30,bug,Error traces show unrendered HTML `href` that makes them hard to read,"<!-- Please search existing issues to avoid creating duplicates. -->

## Environment data

-   VS Code version: 1.82.0
-   Jupyter Extension version (available under the Extensions sidebar): v1.0.17
-   Python Extension version (available under the Extensions sidebar): v2023.16.0
-   OS (Windows | Mac | Linux distro) and version: linux (debian 12)
-   Python and/or Anaconda version: conda 23.7.3 (python 3.11)
-   Type of virtual environment used (N/A | venv | virtualenv | conda | ...): conda
-   Jupyter server running: Local

## Steps to reproduce:

1. Open an interactive jupyter window.
2. Execute some python code that would trigger an exception in a library - example:
```python
from sklearn.linear_model import LogisticRegression
LogisticRegression().fit(3,4)
```

## Expected behaviour

Should show me a readable error trace like it does in regular terminal-based python and regular jupyter.

## Actual behaviour

Shows me an error trace in which each line that references a line of code from an external library shows up with what looks like unrendered HTML tags:
![image](https://github.com/microsoft/vscode-jupyter/assets/11860098/9f69e629-74a0-4f73-8728-3ad98f738bb7)

And doesn't let me change the ""presentation format"" anymore for the cell outputs like it used to do in the past.

"
microsoft/vscode,2023-09-08 11:20:18,bug,[Bug]: Sash to expand diff editor appears to be shorter than full height,"Doesn't seem to happen with other editors

<img width=""1066"" alt=""Screenshot 2023-09-08 at 13 18 05"" src=""https://github.com/microsoft/vscode/assets/61460952/93520b06-91eb-42d3-bb76-e9e9a70c1949"">
"
microsoft/vscode,2023-09-08 06:43:36,bug,Regression: Port forwarding fails while working with remote SSH,"This is the 4th time this issue has occurred and fixed, then regressed within the last 4 months.. Such frequent major bugs make VScode really unstable to use :/

Does this issue occur when all extensions are disabled?: Yes

```
Version: 1.82.0 (user setup)
Commit: 8b617bd08fd9e3fc94d14adb8d358b56e3f72314
Date: 2023-09-06T22:07:07.438Z
Electron: 25.8.0
ElectronBuildId: 23503258
Chromium: 114.0.5735.289
Node.js: 18.15.0
V8: 11.4.183.29-electron.0
OS: Windows_NT x64 10.0.19045
```

Steps to Reproduce: (See https://github.com/microsoft/vscode/issues/192521#issuecomment-1714483320 )

1. Connect to a remote ssh host via remote explorer
2. Start a server on 0.0.0.0:3000
3. Port forward it
4. Try to access it on the current PC.

Error logs in `Shared` window: (Could be irrelevant since I get the log below on both 1.81.2 and 1.81.1 but no issue is faced on 1.18.1)
```
2023-09-08 12:03:50.235 [error] [uncaught exception in sharedProcess]: Cannot read properties of undefined (reading 'then'): TypeError: Cannot read properties of undefined (reading 'then')
    at v.s (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:4731)
    at v.q (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:4161)
    at c.value (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:3566)
    at b.w (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:1902)
    at b.x (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:1972)
    at b.fire (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:2188)
    at MessagePortMain.te (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:19:40559)
    at MessagePortMain.emit (node:events:513:28)
    at MessagePortMain._internalPort.emit (node:electron/js2c/utility_init:2:367)
2023-09-08 12:03:51.522 [error] [uncaught exception in sharedProcess]: Cannot read properties of undefined (reading 'then'): TypeError: Cannot read properties of undefined (reading 'then')
    at v.s (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:4731)
    at v.q (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:4161)
    at c.value (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:3566)
    at b.w (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:1902)
    at b.x (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:1972)
    at b.fire (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:2188)
    at MessagePortMain.te (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:19:40559)
    at MessagePortMain.emit (node:events:513:28)
    at MessagePortMain._internalPort.emit (node:electron/js2c/utility_init:2:367)
2023-09-08 12:03:52.335 [error] [uncaught exception in sharedProcess]: Cannot read properties of undefined (reading 'then'): TypeError: Cannot read properties of undefined (reading 'then')
    at v.s (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:4731)
    at v.q (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:4161)
    at c.value (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:26:3566)
    at b.w (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:1902)
    at b.x (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:1972)
    at b.fire (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:21:2188)
    at MessagePortMain.te (c:\\Users\\Ashesh\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\code\\node\\sharedProcess\\sharedProcessMain.js:19:40559)
    at MessagePortMain.emit (node:events:513:28)
    at MessagePortMain._internalPort.emit (node:electron/js2c/utility_init:2:367)
```


launch.json:

```
{
    ""version"": ""0.2.0"",
    ""configurations"": [
        {
            ""name"": ""Next.js: debug server-side"",
            ""type"": ""node-terminal"",
            ""request"": ""launch"",
            ""command"": ""npm run dev""
        },
        {
            ""name"": ""Next.js: debug client-side"",
            ""type"": ""chrome"",
            ""request"": ""launch"",
            ""url"": ""http://localhost:3000""
        },
        {
            ""name"": ""Next.js: debug full stack"",
            ""type"": ""node-terminal"",
            ""request"": ""launch"",
            ""command"": ""npm run dev"",
            ""serverReadyAction"": {
                ""pattern"": ""started server on .+, url: (https?://.+)"",
                ""uriFormat"": ""%s"",
                ""action"": ""debugWithChrome""
            },
            ""sourceMaps"": true,
        }
    ]
}
```

![image](https://github.com/microsoft/vscode/assets/3626859/bab54f52-4074-42e2-8f49-18a16c8460b6)



"
microsoft/vscode,2023-09-08 06:01:38,bug,Regresion: Terminal group relative size not preserved,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: stable and from sources
- OS Version: 

Steps to Reproduce:

1. Open terminal panel
2. Split terminal and resize
3. Reload window
4. :bug: terminal relative sizes are not preserved
"
microsoft/vscode,2023-09-07 20:40:53,bug,Updater wastes large amount of disk space logging once per second while waiting for VS Code to close,"Type: <b>Bug</b>

The VS Code update process appears to write to log files named `%TEMP%/Setup Log [DATE] #[NUMBER].txt`.  It appends a new line once every second as it waits for a running instance of VS Code to be closed.  Here's a snippet from a current file on my machine:

```
2023-09-07 14:09:42.549   Application is still running, waiting
2023-09-07 14:09:43.552   Application is still running, waiting
2023-09-07 14:09:44.555   Application is still running, waiting
2023-09-07 14:09:45.558   Application is still running, waiting
2023-09-07 14:09:46.560   Application is still running, waiting
```

I basically always have VS Code running, and sometimes don't close it for weeks at a time, and just found that I had over 200MB of log files mostly filled with lines like the above.

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.19044
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-07 15:44:01,bug,Consider changing dim usage in test terminal,"This:

https://github.com/microsoft/vscode/blob/3551954b33c5e93c9ebd09b77e9e92680609b9d0/src/vs/workbench/contrib/testing/browser/testingOutputPeek.ts#L1529-L1531

Now results in 1/2 the minimum contrast requirements which is a soft accessibility issue. It seems like these messages are special vscode messages which use special formatting in the real terminal:

https://github.com/microsoft/vscode/blob/3551954b33c5e93c9ebd09b77e9e92680609b9d0/src/vs/platform/terminal/common/terminalStrings.ts#L18-L34"
microsoft/vscode,2023-09-07 15:36:29,bug,Test view output needs a space separator between messages,"These 2 don't have a space or new line between them:

https://github.com/microsoft/vscode/blob/3551954b33c5e93c9ebd09b77e9e92680609b9d0/src/vs/workbench/contrib/testing/browser/testingOutputPeek.ts#L1494-L1503



![Image](https://github.com/microsoft/vscode/assets/2193314/2902c6af-64b7-4931-88d6-515d4d7c97ee)

"
microsoft/vscode,2023-09-07 13:12:35,bug,Test Results view misses separator between editor and list,"There's no separator line between the two components.

![Image](https://github.com/microsoft/vscode/assets/22350/7b85aa3e-e29c-47a9-99d1-1ae118ed330f)

"
microsoft/vscode,2023-09-07 11:41:53,bug,Build task status indicator not reappearing on window reload,"Steps to Reproduce:

1.  I use the default build task in `vscode` on a multi root workspace
2. I see a ""2"" appearing in the status bar, indicating the 2 runs (see pic [1])
3. I reload the window
4. everything is fine
5. I open 2 more terminals (see pic [2])
6. I hide the panel
7. I reload window

=> 🐛 there is no more a ""2"" in my status bar



[1]



![Image](https://github.com/microsoft/vscode/assets/900690/8615f520-ca94-47d7-8cd9-66fdf4c77bbb)



![Image](https://github.com/microsoft/vscode/assets/900690/ad262d89-840a-414b-94df-39c88c2157d2)

[2]



![Image](https://github.com/microsoft/vscode/assets/900690/415511c3-fd68-4b3b-a29d-ae3bf259be5d)




"
microsoft/vscode,2023-09-06 19:21:11,bug,Themes warn on unknown theme key activityBarItem.profilesBackground,"

![Image](https://github.com/microsoft/vscode/assets/2193314/073bddab-789b-46a9-ab75-6ed06ab8915f)

"
microsoft/vscode,2023-09-06 18:40:46,bug,Processing artifacts fails with error about blob already existing,"https://dev.azure.com/monacotools/Monaco/_build/results?buildId=230771&view=logs&j=43b54640-f671-5524-8f7b-714d77229de9&t=93e2f8ab-3488-5e8e-d7d9-978a5cf7f65f

```
Creating asset...
Size: 7710698
SHA1: fbe6dc51e3e5a0de9bf6b6b43042a855100d2b05
SHA256: d1403e8a597b5787ba9524069de397175d81f76401dbfc0caf42b73c46184132
/mnt/vss/_work/1/s/build/azure-pipelines/common/createAsset.js:170
        uploadPromises.push(Promise.reject(new Error(`Blob ${quality}, ${blobName} already exists, not publishing again.`)));
                                           ^

Error: Blob insider, b254a4c05a4b7625970e7fee3cbcb3dbf2862bba/vscode_cli_linux_x64_cli.tar.gz already exists, not publishing again.
    at main (/mnt/vss/_work/1/s/build/azure-pipelines/common/createAsset.js:170:44)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5

```"
microsoft/vscode,2023-09-06 12:27:41,bug,Null error in sticky scroll test,"When running the sticky scroll unit tests, the following error was noticed:

```
""Uncaught (in promise) TypeError: Cannot read properties of null (reading 'coordinatesConverter')"", source: file:///Users/bpasero/Development/Microsoft/vscode/out/vs/editor/contrib/stickyScroll/browser/stickyScrollWidget.js (180)
```"
microsoft/vscode,2023-09-05 13:12:46,bug,Pasting is not selecting the newly pasted text,"This happens after a regular ctrl+v:

![Image](https://github.com/microsoft/vscode/assets/2193314/253f6723-704c-43fc-b070-52d4f12a583d)

It's very easy to reproduce.

버전: 1.82.0-insider (user setup)
커밋: f1302be1e67e3af5fbeb8bbb2ea784de7bc96150
날짜: 2023-09-01T11:08:40.414Z
Electron: 25.8.0
ElectronBuildId: 23503258
Chromium: 114.0.5735.289
Node.js: 18.15.0
V8: 11.4.183.29-electron.0
OS: Windows_NT x64 10.0.22621"
microsoft/vscode,2023-09-04 18:54:40,bug,Terminal cursor doesn't reflect that the terminal is focused,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->

Does this issue occur when all extensions are disabled?: Yes

# Description

Terminal has focus, but the cursor displayed doesn't look like it does -- it's not filled white

## Actual

https://github.com/microsoft/vscode/assets/16353531/68fc39a0-9961-45d0-8e68-c99a6c5a6342


## Expected

with stable 1.81.1:

https://github.com/microsoft/vscode/assets/16353531/6fe14c7a-141f-4b63-b587-89787fd5de0f





# Steps to Reproduce:

I don't have any, but I can repro even with a new vscode window without any workspace folders. 

# Version 

```
Version: 1.82.0-insider
Commit: f1302be1e67e3af5fbeb8bbb2ea784de7bc96150
Date: 2023-09-01T11:13:22.523Z
Electron: 25.8.0
ElectronBuildId: 23503258
Chromium: 114.0.5735.289
Node.js: 18.15.0
V8: 11.4.183.29-electron.0
OS: Darwin arm64 22.6.0
```

Can't seem to repro with 1.81.1 stable. 

Within my vscode integrated terminal 

```
$  zsh --version
zsh 5.9 (x86_64-apple-darwin22.0)
```

it's weirdly x86_64 even though I'm on arm64, but it seems ok - https://www.reddit.com/r/mac/comments/oq3tex/default_shell_zsh_on_mac_m1_is_x86/
"
microsoft/vscode,2023-09-04 11:19:38,bug,`vscode.TreeView.dispose` doesn't clean up in the renderer,"I went after some later callers of `Disposable#_register` (see [dev-discuss](https://vscodeteam.slack.com/archives/C03ERNTC03X/p1693495534466199?thread_ts=1693487218.646529&cid=C03ERNTC03X)) and I noticed that `$registerTreeViewDataProvider` uses the disposable of its container object, not one specific to the tree view (id). It's likely a theoretical bug but it seems that extensions calling dispose of their view don't achieve anything and that repeated create calls for the same id could leak some memory"
microsoft/vscode,2023-09-01 19:47:00,bug,Is moved code range correct?,"@hediet not sure if it a bug report or question, but I notcied that moved lines range is not correct:

![image](https://github.com/microsoft/vscode/assets/22894169/42b9b243-0b4c-4158-a941-b29ced5d18c8)

why it is written that lines are moved from 16-21? Shouldn't they be marked as ""moved from 16-20""? The same question is about ""moved to""."
microsoft/vscode,2023-08-31 23:35:15,bug,Pre launch task doesn't run if similar task is already running in different workspace folder,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: **Yes**

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.82.0-insider
- OS Version: macOS Ventura 13.5

Issue description:

If the preLaunchTask for a debug configuration in workspace A is already running in workspace B, the task is not started in workspace A. VS Code thinks the preLaunchTask is already running, even though it's running in a different workspace folder. The expected behavior is to launch the task in the workspace folder containing the debug configuration.

Seems similar to https://github.com/microsoft/vscode/pull/168742

I've created a repository which reproduces the bug. The repo contains two Node express hello world apps, and corresponding launch/tasks.json configs for debugging the apps. The debug config is a simple launch program and each has a `preLaunchTask` that runs `tsc --watch` as a background task with a problem matcher. 

Steps to Reproduce:

1. Clone https://github.com/alexweininger/vscode-task-bug
2. Open the `workspace.code-workspace` workspace file in VS Code. 
<img width=""232"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/12476526/0f0d3c1f-e833-49f7-bcae-977a6ccb18f2"">

3. Run `npm install` in each workspace folder. Each workspace folder contains a hello world express server.
4. Run the ""npm: watch"" task in workspace-1. 

<img width=""618"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/12476526/9ffdb4da-926b-46ed-b9d4-39d83f221425"">

5. Launch ""Launch Program (workspace-2)"" from the debug menu. It will not run the preLaunchTask and it will not work.
<img width=""442"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/12476526/7293da04-8652-483a-8900-2fc4e5584af2"">"
microsoft/vscode,2023-08-31 22:19:06,bug,Quick Chat layout issue on resize,"On the latest Insiders on Windows

1. Open Quick chat.
2. Close it.
3. Zoom in or out of the editor.
4. Open Quick Chat again.
5. :bug: Layout issue"
microsoft/vscode,2023-08-31 15:58:54,bug,"Improve consistency, lessen redundancy of accessibility help dialog text","As a result of the discussion in #191672, we should format each command, description, and keybinding more consistently and limit redundancy. "
microsoft/vscode,2023-08-31 13:44:24,bug,Invoking choice from `Show CodeLens Commands For Current Line` may require multiple Enters or clicks,"Type: <b>Bug</b>

1. Set `""typescript.referencesCodeLens.enabled"": true`
2. Open a  .ts file.
3. Put cursor on a line that has an `N references` CodeLens above it.
4. Open Command Palette and run `Show CodeLens Commands For Current Line`.
5. Press Enter to try and run the selected (only) entry (N references).

:bug: nothing happens until you press Enter a second time (or more...).

Results of using a mouse-click to try and run the CodeLens from the quickpick is the same. First click does nothing, and a second click is required.

This also happens in 1.81.1 so it is not a 1.82 regression.

VS Code version: Code - Insiders 1.82.0-insider (e7756c8870ee1df7360e6624e220534174039b02, 2023-08-31T05:33:59.698Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-31 10:20:02,bug,renderSideBySideInlineBreakpoint invalid default value,"

![Image](https://github.com/microsoft/vscode/assets/2931520/e2a6cab6-3e9a-4502-a895-0662be8b5bf2)

"
microsoft/vscode,2023-08-31 07:03:54,bug,"After the command is localized, it cannot be searched by keywords.","ADD ISSUE DESCRIPTION HERE

Version: 1.81.1
Commit: 6c3e3dba23e8fadc360aed75ce363ba185c49794
User Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36
Embedder: vscode.dev

<!-- generated by web issue reporter -->

![bug3](https://github.com/microsoft/vscode/assets/11473889/68161483-efe2-42cc-adce-b77f5d434eae)

Steps:
1. Open vscode.dev or VS Code App
2. Switch to a language other than the default, for example, Simplified Chinese.
3. Search command by shortcut key, for example, search `toggle`, some matching commands will appear.
4. But I search the keyword directly (incomplete command keyword), nothing will be matched."
microsoft/vscode,2023-08-31 02:19:41,bug,"[serve-web] In-app Github sign-in link rotates ports and cannot be preset with --port, breaking SSH local forwarding","Summary: The sign-in link for Github in VSCode running through serve-web rotates ports in the 54xxx range, breaking any pre-set port forwarding for users connecting via SSH. This occurs regardless of any port option set with --port (taken from my comment in #168492)

Does this issue occur when all extensions are disabled?: Yes

- VS Code Version: Insiders 1.82.0
- OS Version: Mac OS 13.3

Steps to Reproduce:

1. Connect to the device hosting code via SSH, with local port forwarding for port 8000 enabled
2. On the remote device, launch serve-web with ```code-insiders serve-web```
3. Open a browser window and navigate to the URL given by serve-web
4. Turn on settings sync, showing a github sign-in URL. Note the port is different than the default, requiring you to reconnect and add a new forwarded port 

Expected behavior:

Setting the port with --port should (a) also determine the port used for sign-in, or (b) be a separate option so that SSH port forwarding does not require updating SSH config and reconnecting each time you need to sign in"
microsoft/vscode,2023-08-30 17:14:22,bug,Terminal buffer is not updating information,"Type: <b>Bug</b>

In the insiders version, I noticed that the buffer is no longer automatically reflecting terminal information.

For example, when executing the mvn clean install command in my project, the information of the build that starts to run is updated from time to time in the buffer, sometimes it is only necessary to give a tab to go to the terminal and give a shift tab that I have the information updated while the build is running and printing various information.

In the insiders version, this update no longer occurs.

I have to keep pressing alt + f2, but I couldn't be sure if I still have all the updated information.

VS Code version: Code - Insiders 1.82.0-insider (35be9bf683eace09796e59d54f1f225bbc3a7866, 2023-08-30T05:33:47.972Z)
OS version: Windows_NT x64 10.0.22621
Modes:
Remote OS version: Linux x64 5.15.90.1-microsoft-standard-WSL2

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-8365U CPU @ 1.60GHz (8 x 1896)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|31.72GB (11.44GB free)|
|Process Argv|--crash-reporter-id dd13835f-488a-4675-bdf9-21fedc4249ef|
|Screen Reader|yes|
|VM|0%|

|Item|Value|
|---|---|
|Remote|WSL: ubuntu|
|OS|Linux x64 5.15.90.1-microsoft-standard-WSL2|
|CPUs|Intel(R) Core(TM) i5-8365U CPU @ 1.60GHz (4 x 1896)|
|Memory (System)|15.62GB (5.22GB free)|
|VM|0%|
</details><details><summary>Extensions (22)</summary>

Extension|Author (truncated)|Version
---|---|---
remote-containers|ms-|0.307.0
remote-wsl|ms-|0.81.0
cucumber-official|Cuc|1.7.0
gitlens|eam|2023.8.3005
copilot|Git|1.106.367
copilot-chat|Git|0.7.2023083001
vscode-docker|ms-|1.26.0
vscode-language-pack-pt-BR|MS-|1.82.2023083009
postman-for-vscode|Pos|0.6.2
vscode-thunder-client|ran|2.10.5
java|red|1.21.0
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-boot-dev-pack|vmw|0.2.1
vscode-spring-boot|vmw|1.48.0
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.13
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
vscode-spring-boot-dashboard|vsc|0.13.1
vscode-spring-initializr|vsc|0.11.2


</details><details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805:30301674
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30618038
2i9eh265:30646982
showlangstatbar:30737417
0bi6i642:30823812
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
gsofa:30797620
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonlinttypecf:30823782
pythonmpsinfo:30815194
dsvsc015:30821418

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-30 09:20:33,bug,Port forwarding log has formatting issues,"Testing #191540 on Linux

There are ANSI escape sequences as well as empty lines:

```
2023-08-30 11:12:19.936 [info] [forwarding] starting CLI
2023-08-30 11:12:19.997 [info] [forwarding] [2023-08-30 11:12:19] debug No code server tunnel found, creating new one

2023-08-30 11:12:19.997 [info] [forwarding] [2m[2023-08-30 11:12:19] trace Found token in keyring

2023-08-30 11:12:23.233 [info] [forwarding] [0m[2023-08-30 11:12:23] info Creating tunnel with the name: ubuntu-linux-22-04-desktop

2023-08-30 11:12:23.233 [info] [forwarding] [2m[2023-08-30 11:12:23] trace Found token in keyring

2023-08-30 11:12:26.235 [info] [forwarding] [0m[2m[2023-08-30 11:12:26] trace Found token in keyring

2023-08-30 11:12:27.197 [info] [forwarding] [0m[2023-08-30 11:12:27] debug Starting tunnel to server...

2023-08-30 11:12:27.199 [info] [forwarding] [2m[2023-08-30 11:12:27] trace Found token in keyring

2023-08-30 11:12:28.872 [info] [forwarding] [0m[2023-08-30 11:12:28] debug Connected to tunnel endpoint: TunnelRelayTunnelEndpoint { base: TunnelEndpoint { connection_mode: TunnelRelay, host_id: ""ad01adb3-1b36-4c76-803c-eb1b09e822ff"", host_public_keys: [], port_uri_format: Some(""https://01bkhf70-{port}.eun1.devtunnels.ms/""), tunnel_uri: Some(""https://01bkhf70.eun1.devtunnels.ms/""), port_ssh_command_format: Some(""ssh 01bkhf70-{port}@ssh.eun1.devtunnels.ms""), tunnel_ssh_command: Some(""ssh 01bkhf70@ssh.eun1.devtunnels.ms""), ssh_gateway_public_key: None }, host_relay_uri: Some(""wss://eun1-data.rel.tunnels.api.visualstudio.com/api/v1/Host/Connect/01bkhf70""), client_relay_uri: Some(""wss://eun1-data.rel.tunnels.api.visualstudio.com/api/v1/Client/Connect/01bkhf70"") }

2023-08-30 11:12:28.872 [info] [forwarding] [2m[2023-08-30 11:12:28] trace Found token in keyring

2023-08-30 11:12:28.873 [error] [forwarding] 

2023-08-30 11:12:29.498 [info] [forwarding] [0m[2023-08-30 11:12:29] info forwarding port 8000 at Private

2023-08-30 11:12:46.702 [error] [forwarding] 

2023-08-30 11:12:46.702 [info] [forwarding] [2m[2023-08-30 11:12:46] trace Found token in keyring

2023-08-30 11:12:47.371 [info] [forwarding] [0m[2023-08-30 11:12:47] info forwarding port 3000 at Private

2023-08-30 11:14:40.594 [error] [forwarding] 
```

![Image](https://github.com/microsoft/vscode/assets/22350/017db7b2-64ca-4e53-9ffc-5495eebe136c)

"
microsoft/vscode,2023-08-30 07:36:20,bug,Quick Text Search: Duplicate results when file is open,"Testing #191499

- open the vscode repo
- open command palette, type `% findTheme`
- pick the first entry in `workbenchThemeService`. the file opens
- again, open command palette, type `% findTheme`

You see duplicated results


![Image](https://github.com/microsoft/vscode/assets/6461412/5b2bbe05-96ce-4402-ad94-4b61c0eb23b1)

"
microsoft/vscode,2023-08-29 22:57:32,bug,Progressive rendering freezes sometimes,"

![Image](https://github.com/microsoft/vscode/assets/323878/7dff60ed-8650-4b65-8a30-f0af15203336)

I thought I noticed this happening from time to time after we made changes to how rendering works, but in this case with my test extension it's pretty obvious, I will investigate"
microsoft/vscode,2023-08-29 20:15:23,bug,Align quick question code block style with chat view,"Testing #191496

Not sure why we would the backgrounds different:

![Image](https://github.com/microsoft/vscode/assets/2193314/7966d09d-78c2-4648-aab3-60c8a39e1cdd)

![Image](https://github.com/microsoft/vscode/assets/2193314/0bb51c42-5262-48d7-b27a-b3109fb43fcb)

"
microsoft/vscode,2023-08-29 20:06:34,bug,bad input box styling in quick chat UI,"![image](https://github.com/microsoft/vscode/assets/2019016/5c6d5e3d-b671-49bd-b3da-7292c926ac10)

I'm not sure how I got to this point, but resizing the window just makes it worse:

![image](https://github.com/microsoft/vscode/assets/2019016/b248a12c-4f82-45c0-b659-b89195d10819)"
microsoft/vscode,2023-08-29 18:34:04,bug,Icons in Accessible view don't seem right,"Testing #191345

![image](https://github.com/microsoft/vscode/assets/3840081/fd38d13b-6a60-4e7d-95a1-223400bba803)

The bell icon for manage extension does not seem correct here, gear icon might be better.
The shown next and show previous should swap places.  `>` and `<` should probably be `<` and `>`
I would expect `x` to be at the end."
microsoft/vscode,2023-08-29 18:03:20,bug,Confusing accessibility help message in an editor,"1. Open settings.json 
2. Run Open Accessibility Help
3. See this message 
4. I don't really understand what ""Disable the aria hint label to open this"" means

![Image](https://github.com/microsoft/vscode/assets/30305945/618fbc50-48de-4ad2-8458-1e0662435a1d)

"
microsoft/vscode,2023-08-29 17:31:59,bug,I cannot click on the left hand side to expand:,"              I cannot click on the left hand side to expand:

![image](https://github.com/microsoft/vscode/assets/900690/8bf6a252-1473-4870-9e47-620b73b4a521)

Also, is the hover color themable?

_Originally posted by @bpasero in https://github.com/microsoft/vscode/issues/185781#issuecomment-1697638159_
            "
microsoft/vscode,2023-08-29 16:08:47,bug,Dim unfocused setting link does not work,"Forked off from https://github.com/microsoft/vscode/issues/191618

The link in settings does not work:

![Image](https://github.com/microsoft/vscode/assets/2193314/042441b1-8a56-4c29-8504-e8ee8833b221)

I'm pretty sure I'm following this reference exactly though:

https://github.com/microsoft/vscode/blob/64f1488b7e388e744cd80cd1bf5b238c9f193b0a/src/vs/workbench/contrib/files/browser/files.contribution.ts#L259

Config is defined here:

https://github.com/microsoft/vscode/blob/64f1488b7e388e744cd80cd1bf5b238c9f193b0a/src/vs/workbench/contrib/accessibility/browser/accessibilityConfiguration.ts#L127-L139"
microsoft/vscode,2023-08-29 14:21:35,bug,Consider to revert dynamic grow from scroll when reopening,"Testing #191496

I think that growing quick chat when you scroll is an interesting idea, but I would reset the size back to how it was when you reopen quick chat because its harder to manage the size to make it small again. You cannot just scroll to get back where you were."
microsoft/vscode,2023-08-29 13:54:30,bug,Port forwarding attempts wrong path to tunnel binary on linux,"Testing #191540

1) Use latest snap installation of insiders
2) Attempt to forward a port and after sign in flow, see the notification with following error
<img width=""727"" alt=""Screenshot 2023-08-29 at 22 53 14"" src=""https://github.com/microsoft/vscode/assets/964386/e469e6f2-22d7-4a79-8422-08368dd12c84"">

3) Path should have been `/snap/code-insiders/1392/usr/share/code-insiders/bin/code-tunnel-insiders`
"
microsoft/vscode,2023-08-29 13:27:15,bug,Moved code widget does not get highlighted when is moved over cursor,"Testing #191508

Steps to Reproduce:

1. Create two copies of the same lines. One of this copy will be connected with arrow
2. Select the connected copy and past some symbols, so that arrow jumps to another copy
3. Remove those symbols, so the arrow jumps again over the block where cursor is located
4. . 🐛 Now the moved lines frame is located so that the cursor is inside of it but it is not highlighted untill the cursor is moved


https://github.com/microsoft/vscode/assets/22894169/a281ff19-7299-4816-bb88-38b0e9ca0e41

[Example](https://microsoft.github.io/monaco-editor/playground.html?source=v0.42.0-dev-20230828#XQAAAAJACQAAAAAAAABBqQkHQ5NjdMjwa-jY7SIQ9S7DNlzs5W-mwj0fe1ZCDRFc9ws9XQE0SJE1jc2VKxhaLFIw9vEWSxW3yscxFeeC3VciAJM8XEuX7Os378jBGtVLkr6ryuhqvky-XZ9Sy0vyFSI1m9lYQpwqOsaKmhydYWIo-9hGbv_4wlPHJE32WwJQXiHR3looR_fkyQDM0QL-JXDok5ge95iYvjHlF3FxmJhq-ML2Mv0DrG9odUt0RyrqVQLLqqsyWIhAOnmJlHmgVKAkVlHyT9q1aDx3m-fUO12m6oja-Zn9-fj1Z1wWKXs-cw34GUHYz47IEQnvaKMYJfd4WtH1vQwjkqpt_WUupRACsfidP_pQTwOWuhB5MT-Ge5-i-iAKSo3RMckpFZil2ux1-zHD8sd10NJ0CY7MNyUK-EbLWHtl2oJLbqlWUE_AJSCTcAPwGERCKy27cRn4JON6GXoG8c9Hd7bIdtmXIWLAy9h0QK9K7KFa2mEue088OXS8Tg6mo5JUeJS0Ffh3GgqGwGh-Wk3P8MmoxDLm9l9hhhti984QwibNzk1JFX_Ma43tG1C9W4Mqqz_0vs_ltlShgywXYBTS6GzySwVCSdp00GejQ3KovaylCG9yM_HjlQB0QRAkc2B89HyjRS-UpIbpM0fsHPV6px2HIVvc8KdbT7nNVDYlb-dqx55ma4jOZpt9nsULRxtlBTreNr7bFbAi4RMZE0mxW4SeSWg-FArsLghaXlPjwLHLiYJeBfPXTZDCBypbv-q5zRvpjZO2CwhXdTiroYGQfoqhSEMhgWsSRusn3vXdy66DdBlU7ntEgMmhVvP-lQGT7bNQionJOaZ3ORsTwey35X_0cv_FS8W0)
"
microsoft/vscode,2023-08-29 13:21:35,bug,Welcome editor does not dim,"Testing #191527



![Image](https://github.com/microsoft/vscode/assets/900690/dd5c31b6-b1d8-4890-8788-668540454878)

"
microsoft/vscode,2023-08-29 13:20:40,bug,Settings editor does not fully dim,"Testing #191527



![Image](https://github.com/microsoft/vscode/assets/900690/14e772bf-395e-49ae-9334-75e490bd71b6)

"
microsoft/vscode,2023-08-29 12:58:15,bug,"Clicking ""Compare"" in another moved section doesn't compare","Testing #191508

1. Move 2 blocks of code
2. Click ""Compare"" on one of them.
3. Scroll to the other block and click ""Compare on that.
4. I would expect the compare the move to the second block, but instead it just untoggles the compare

![Recording 2023-08-29 at 08 57 45](https://github.com/microsoft/vscode/assets/38270282/ed76c617-1349-435f-8e93-82b9aef7bff3)


[Monaco Editor Playground Repro](https://microsoft.github.io/monaco-editor/playground.html?source=v0.42.0-dev-20230828#XQAAAAJQOgAAAAAAAABBqQkHQ5NjdMjwa-jY7SIQ9S7DNlzs5W-mwj0fe1ZCDRFc9ws9XQE0SJE1jc2VKxhaLFIw9vEWSxW3yscy_rDB41xEYuPZ-GBXBWsVCDi8eWiJ-k3m3zYdvUYhdbIBEVA4bW4tKs6pOgndLQLxdOQ6A77gU1hhrcZMjBUTzvsOADZZmd3A8k8TBXwbzs72nrvooEUSBZPojjnQzEehNRWSBICoSg2i1dHAxaUcQIG06YQ7VVQnTozZHOFsvIghuXKlg9t9yPqnuZRFVXU_kj2691GMY-25a3pTyr7215WAOWTvDdA8e7qojeDEOxW9Dw5kYQxLyafyGK21vgFRxC1Lmb0znoTaq6dyBOjxJpiMNY3IIBkJILpdjISYOpaDqnxz8E7ME_vEL0u6Tr2g0F67na6nqipiX3tNnlUCggyENB4gygsntDwujebtw_Tys3HwoUFLesvuqoiDBvYpB7nJ5EhZ9bIO6kflPHg6TPqc3XYdfpQI6dC5CfRU0PlsOxg_Jxxikk1wBojrWfa79cppQh5BKIp1pxFZ0VQzINkFlTtLUh9gbDs19TkljGapTqVjol-bBBwqYpz8sw4EzQKPLVjG80GOk3YQ57MuPZT2A2_RzrkaH4lEcE2XjndpNho8Fomngx5vNEzlsnpLG4GvIKpx74lvG3eIx3FvU60sAe0yGtTDFT5c4BUc3JrZoDtORFOSK_LQl9eoYzJSz7KXrMvwA4sMbZJL-0NODApLykpD5RYVHYtcVhMjvov8aBJSf64ikqZwRH-EHJAteyBmXBA_knIYcH0RQ7O78cwmZnJAcTjgagw0DJq8NkvZgimXlmXAF-Mc9jWPWOeTBJ-8lr5P4YcwiE2zYjk1WIQV4p52iSnz_wAV6M1Lx1g9Lh8MZEuZ2CYrTpf7-H5G8vygHHEeVkRsGDxLdm4cfXOomcW4jQ3oAWdKpofUVN-0IAFAB79ppsG4Ag2Yixs9H-zf6EMi5owU3uWnrGNSI_g57ohIe3yjvGHv6PsvZBwtwqrR1v1yW1ZRWBhC9-kT8ILo1PrkKODKwobNGOwn-LIeLaml4ahBDgnxsvVZCTf0_FIrUG-R_ntDLN7Cb99dKJxec2JFKUTR0qZKHq1Vq2VYfI6SFSLrTbSwYXWvs1z4q32e67MA6JPbtoctYAGOhps0zry9MQ5VXYywU87V0KSPWbNUXRFarpndJDTHtUO3VX3E8_bafSn6HrBszcEDkZ6cMowAMHFsxIi8U7bnrByXqjUJWvKu4UgGSptqy9JB5lx0OSHBlmjKN_K7FrLqlpnfetdB2R0KHqEl21JSN2_l3lihI-u74cdRcIwX-2q_jSsfN3o8DPi4_edpLimMVAjBeuaiLuWgTmYMtVgnRrnKR5clGCw87TpqdrUptjMcQsxtG5MbDPW00WpaDj3rlaf_rrmNuro2hRiWd9Nf_y31GFjc9Khsk2lX_rxlXDQeI8ZHHESz-vQUk2jCYBsrLPZglF5vkM_zYVRN_-f4Hvl3l8iFZ1e-b-hy5zHACo8U_s_Vo8v9KYY8XwSf7NvR28nsqkeMfB-nSIim1Uzz9HkWa_PTWvirz1NlJC5sMnPZrI7IlsGgkdD9egF3jMxsnhL4jSrecVn7rYE3ozBoUtVhtJWh-7R4tGHdSz2wwcXYIELb9v0MVxmPJtZG6ECT1zvG19J8IOl-v7iq-01OsK9XwjOvgoEcyIGTYYHMTOiN75K3h-nXYakAIVaDp_3X1JmyotAW7bkmJeSWmFI6cJvF1Yvmsq0UgyewjiIkfgLvTPinl42e0RKvPqyLgto-8P6UqphNGpFpaRwDh6_nwCllxcp6JERv4saWiypihI_mpeQSE3Zk9vxOaZEh7UEWaSqht15BmeIohbNIFOv81jw5ZBCOU230-Yb_CRGB3kNVRTottQlpNGNb-HtmdYbGyW_cq2I1xgZr_QSpwHI23hQDFWmyerhl8fJIsvzYTpZ4dmFAoEjb-o-2GPwvduMb1fQ5CPwDxzL5Zq-QKGGETyz37Xp0DF-RDTvPl2l1bLSqFXHihhWYNC36bVG34zASclrWhMOLs6bzPjdycSzdg1MhhEQagNqsC4dOf8ndBK5oFy9vDPJnv2rcRQHWmEFz-NgOj4mxiKAleu_U1FeIUvC8v_OncQYAEyBGPipQkB_-PCjAELj9s1RGAUm9BUiGlmHNuuXQB3PrRnlsVdJCjecBz-iU5Zy_sqk4Ss0VZk8hhG_bDdiIDiLQlyOnor7N2G54gpiyCRwci13HspDDDqe0gvWAK9Cg6K-QcE-0S4EY-dQ0j1F7R7r_9Zc8Na3T33f6t4JagN6d0bwM3EzdAF5XAdFJpDj1TNTokf2SupgcfPW8JhbFA4gDKpAQIcIDJLjT_pJjkEDV9VjXdQXvjhgjWtvsgwQ7-7FeyzHCLVoIN4MjGbFkym58sW00E-170weydhCte0DIT0SxaOwKtMT_E0Utr_aqJb1Xag9EuA-iTRavxc-1jJHrTnOWrXYplGn7OqjWQIKKkIsWbgEpWGNW5utuIXgr6UXA8GQlfyJgRDa7NJUF4C8XWqvGPJvmP6Bk0HXG40-rg1cmC38vCsq2DyrviygJcAqWx8TcuOS_zkhSZ1BHBJdWQmcDDVNdnqpNV9Ng-DjkFvmzYX646V9mYUrBY3aXPDoGOBFD5HNR9OceVaer2sbGu_FljBpQlcW5bQSjxVNw8hmES7xYjMhVZuyiuLzV8vn58Y-8e5aX0J4a583aGvtUI2TG8KaLz9K5nRYLd4bsygIihidbyR4-qbRRjEPWV3NVR3T7c5rsih1Z5zycaJLQPcXVTygc9DKjnwSn6leR4zywFe1NqJJ_COvNiLyTKutIEb3Bibn9BCQ2CSp7oZ6HZC3MbxNN9AtcrOdJIj7qFQbHZRdPag1rFo_9QW70y1GYmEttUdvI-fSxRnUxm3KrKXrnaW1vY8rjSLI-L1AmiTHj0DGf4FooX6V5NKFLBGFqRIlaFnEKWokBuUsZuY0bNkxbIDZMEuObzkB_Nphg8vSbZa7TEV7tgDNfoMtMzdpH7ZueXCAl4ubd12HcsEB5FUqhO88kvkJPP3hZWruKnDF4dJMHwhhrHAb7FVdY45ZOn2LfgtIxdP1Lr6qLJign1xt-HZP-3spsDeN5xSwSQ5AApOO1ljf7a1SjvTXoZUtO7ls78umu-lThTYetYePQt-xA9p_ZZNcT1yidErHr5skOzf_7fMoY)"
microsoft/vscode,2023-08-29 12:10:07,bug,Missing jsdoc for `GlobalEnvironmentVariableCollection`,"* The `GlobalEnvironmentVariableCollection` type lacks a leading jsdoc comments
* the `getScoped` function lacks a `@return` annotation"
microsoft/vscode,2023-08-29 09:26:06,bug,Clicking on search result sets the selection in the cell and not in the output,"Testing #191488

* open https://github.com/donnemartin/data-science-ipython-notebooks
* enable `""search.experimental.closedNotebookRichContentResults"": true`
* search for `[1, 2, 3, 4, 5]`
* click on a result in `02.08-Sorting.ipynb`
* observe the selection is set on the input code and not on the output




https://github.com/microsoft/vscode/assets/5047891/bdce58d0-66b1-48c6-91e2-283cccffcc85




```
Version: 1.82.0-insider
Commit: ebd67244fb2da33ab078bb2baa96106fda29f336
Date: 2023-08-29T05:48:32.218Z
Electron: 25.5.0
ElectronBuildId: 23084831
Chromium: 114.0.5735.289
Node.js: 18.15.0
V8: 11.4.183.29-electron.0
OS: Darwin arm64 22.6.0
```"
microsoft/vscode,2023-08-28 22:22:54,bug,Notification and notification buttons lack border radius,"1. If the notification content is sufficiently long, insufficient height is allocated for the action buttons to grow, consequently they appear cramped and lack border radius


2. When a notification is focused the focus border radius is truncated 

![Image](https://github.com/microsoft/vscode/assets/30305945/37be5cfc-0747-4d31-a77b-66ab57a43208)
"
microsoft/vscode,2023-08-28 17:50:37,bug,`ctrl+upArrow` doesn't open accessible buffer on windows,"1. enable screen reader mode
2. focus a terminal
3. `ctrl+upArrow`
4. 🐛 the accessible buffer isn't entered

This is because it's getting sent to the shell. Adding it to commands to skip shell fixes this.

reported by @jooyoungseo"
microsoft/vscode,2023-08-28 14:49:37,bug,Unable to ssh to remote host,"
Type: <b>Bug</b>

Note: I was unable to create a bug report after I choose the ""An extension"" option in the dropdown in the ""Help: Report Issue..."" window as it does not show any of my extensions (I do have extensions for whatever reason the bug report does not show them)

After installing 1.82.0 (insiders), I started to get the following error message:

notificationsAlerts.ts:42 Failed to connect to the remote extension host server (Error: WrappedError(WrappedError { message: ""server exited without writing socket"", original: ""channel closed"" }))

And

Could not fetch remote environment

When I use an older version (via regular VsCode) this issue does not happen.

VS Code version: Code - Insiders 1.82.0-insider (f7973f357e7c316a88e8817886f41a843021fe74, 2023-08-28T05:35:52.131Z)
OS version: Windows_NT x64 10.0.19044
Modes:
Connection to 'SSH: devlab.linepulse.ca' could not be established  WrappedError(WrappedError { message: ""server exited without writing socket"", original: ""channel closed"" })

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-8665U CPU @ 1.90GHz (8 x 2112)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.72GB (6.99GB free)|
|Process Argv|--crash-reporter-id 857fed38-4fa8-49ff-b2f3-bbf104e17732|
|Screen Reader|no|
|VM|0%|

Connection to 'SSH: devlab.linepulse.ca' could not be established  WrappedError(WrappedError { message: ""server exited without writing socket"", original: ""channel closed"" })
</details>Extensions: none<details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805:30301674
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012:30540252
pynewext54:30618038
vscrp:30624060
2i9eh265:30646982
showlangstatbar:30737417
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
gsofa:30797620
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonmpsinfo:30815194
dsvsc015:30821418

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-27 20:04:03,bug,Avoid unnecessary virtual scroll bar area refreshing during typing ,"- VS Code Version: 1.80.0
- OS Version: Windows 11 22H2 (22621.2134)

Steps to Reproduce:
1. Open a text file. Turn on Developer tools \\ Rendering \\ Paint flashing
2. Type a few characters without changing line. 

Observe the screen refresh areas. With each character typing, the virtual scroll bar area is updated. 

Expected: Because there is no line change, I'd expect the scroll bar area shouldn't update. 

Impact: I think this behavior leads to [issue 164503](https://github.com/microsoft/vscode/issues/164503), which causes underlying Chromium to combine and refresh the entire whole editor screen. This kind of behavior is not optimized for Remote Desktop experience such as Dev Box. "
microsoft/vscode,2023-08-25 16:25:00,bug,Toggling Command Center does not resize the title bar,"Toggling the command center works, but the title bar height is stuck until the window is resized. I also noticed some issues where I had to click twice to open the command center once enabled. The command center input then disappears while the command center quick pick opens.

https://github.com/microsoft/vscode/assets/25163139/a36320d8-bc21-4479-9401-5154b49e8a4d

"
microsoft/vscode,2023-08-25 13:48:35,bug,[Accessibility] Accept suggestion button disappeared in the latest Accessible View,"
Type: <b>Bug</b>

Press Alt+F2 on any inline suggestion and press Shift+Tab key where you can find related action buttons, such as go to symbols, go to next/previous suggestion. There is no ""Accept suggestion"" button anymore.

VS Code version: Code - Insiders 1.82.0-insider (083fca132543aa91a7e1de2dc23857d70ea56dd3, 2023-08-25T05:33:34.878Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1145G7 @ 2.60GHz (8 x 2611)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (7.66GB free)|
|Process Argv|C:\\\\Users\\\\jseo1005\\\\OneDrive - University of Illinois - Urbana\\\\Desktop\\\\email.md --crash-reporter-id b05b88e5-8894-4031-ae34-fa034ebddea9|
|Screen Reader|yes|
|VM|0%|
</details><details><summary>Extensions (89)</summary>

Extension|Author (truncated)|Version
---|---|---
android-dev-ext|ade|1.3.2
Bookmarks|ale|13.4.1
openscad|Ant|1.2.1
spellright|ban|3.0.116
zoterolatex|bna|0.4.1
mermaid-markdown-syntax-highlighting|bpr|1.5.2
doxdocgen|csc|1.4.0
vscode-markdownlint|Dav|0.51.0
vscode-eslint|dba|2.4.2
vscode-quick-select|dba|0.2.9
vscode-deno|den|3.20.0
gitlens|eam|14.2.1
EditorConfig|Edi|0.16.4
prettier-vscode|esb|10.1.0
vscode-google-translate|fun|1.4.13
codespaces|Git|1.14.16
copilot|Git|1.105.358
copilot-chat|Git|0.7.2023082404
remotehub|Git|0.60.0
vscode-github-actions|git|0.26.1
vscode-pull-request-github|Git|0.70.0
cslpreview|igo|0.2.2
easy-snippet|inu|0.6.3
path-autocomplete|ion|1.24.1
latex-workshop|Jam|9.13.4
lilypond-syntax|jea|0.1.1
scheme|jea|0.2.0
better-cpp-syntax|jef|1.17.2
google-search|kam|0.0.1
vscode-lua-format|Koi|1.3.8
lilypond-formatter|lhl|0.2.3
lilypond-pdf-preview|lhl|0.2.8
lilypond-snippets|lhl|0.1.1
vslilypond|lhl|1.7.3
zotero|mbl|0.1.10
git-graph|mhu|1.30.0
vscode-docker|ms-|1.26.0
black-formatter|ms-|2023.4.1
flake8|ms-|2023.6.0
isort|ms-|2023.11.12061012
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.40
jupyter|ms-|2023.7.1002162226
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.306.0
remote-ssh|ms-|0.105.1
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.0
vscode-remote-extensionpack|ms-|0.24.0
azure-repos|ms-|0.36.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.4
cpptools-extension-pack|ms-|1.3.0
js-debug-nightly|ms-|2023.8.2317
powershell|ms-|2023.6.0
remote-repositories|ms-|0.38.1
vscode-github-issue-notebooks|ms-|0.0.129
vscode-selfhost-test-provider|ms-|0.3.16
vscode-serial-monitor|ms-|0.10.0
vsliveshare|ms-|1.0.5883
autodocstring|njp|0.6.1
pandocciter|not|0.10.3
shiny-python|Pos|0.1.2
shinyuieditor|pos|0.4.3
quarto|qua|1.94.0
r-debugger|RDe|0.5.4
java|red|1.21.0
vscode-xml|red|0.26.1
r|REd|2.8.1
multi-command|ryu|1.6.0
vscode-deepl|soe|1.0.6
abc-music|sof|0.4.0
lua|sum|3.7.0
latex-utilities|tec|0.4.10
cmake|twx|0.0.17
errorlens|use|3.13.0
intellicode-api-usage-examples|Vis|0.2.7
vscodeintellicode|Vis|1.2.30
vscode-arduino|vsc|0.6.0
vscode-java-debug|vsc|0.53.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.13
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
markdown-all-in-one|yzh|3.5.1
grammarly|znc|0.22.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805cf:30301675
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012:30540252
pynewext54:30618038
a9j8j154:30646983
showlangstatbar:30737417
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
gsofa:30797620
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
asynctok:30821568
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonmpsinfo:30815194
dsvsc015:30821418

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-25 07:01:25,bug,macOS: Window menu does not show opened windows in some cases,"Steps to Reproduce:

1. have 2 windows opened, e.g. one on `vscode` and an empty window
2. quit
3. start
4. verify 2 windows open

=> 🐛 the ""Window"" menu only shows 1 window for me



![Image](https://github.com/microsoft/vscode/assets/900690/58bd54b1-fb42-412d-834a-4010d7ae1ca6)


"
microsoft/vscode,2023-09-28 12:26:38,feature,[Accessibility] Cannot clear terminal buffer using shortcut key,"
Type: <b>Bug</b>

If you assign a keybinding for clear terminal command and press the key in the accessible terminal buffer, it does not work.

`keybindings`:

``` json
[
  {
    ""key"": ""ctrl+l"",
    ""command"": ""workbench.action.terminal.clear"",
    ""when"": ""terminalFocus && terminalHasBeenCreated || terminalAccessibleBufferFocus && terminalHasBeenCreated""
  }
]
```
* Note: `ctrl+l` only works in terminal input, not terminal buffer.

VS Code version: Code - Insiders 1.83.0-insider (aad333b878b4cfce2f4152d48552fb6f980d7daf, 2023-09-28T05:34:00.540Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1145G7 @ 2.60GHz (8 x 2611)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (6.02GB free)|
|Process Argv|--crash-reporter-id b05b88e5-8894-4031-ae34-fa034ebddea9|
|Screen Reader|yes|
|VM|0%|
</details><details><summary>Extensions (92)</summary>

Extension|Author (truncated)|Version
---|---|---
android-dev-ext|ade|1.3.2
aiprm-lang|AIP|0.0.2
Bookmarks|ale|13.4.1
openscad|Ant|1.2.1
spellright|ban|3.0.118
zoterolatex|bna|0.4.1
mermaid-markdown-syntax-highlighting|bpr|1.5.2
doxdocgen|csc|1.4.0
vscode-markdownlint|Dav|0.52.0
vscode-eslint|dba|2.4.2
vscode-quick-select|dba|0.2.9
vscode-deno|den|3.25.0
gitlens|eam|14.3.0
EditorConfig|Edi|0.16.4
prettier-vscode|esb|10.1.0
vscode-google-translate|fun|1.4.13
codespaces|Git|1.15.4
copilot|Git|1.117.446
copilot-chat|Git|0.8.2023092701
remotehub|Git|0.60.0
vscode-github-actions|git|0.26.2
vscode-pull-request-github|Git|0.72.0
overleaf-workshop|iam|0.2.4
cslpreview|igo|0.2.2
easy-snippet|inu|0.6.3
path-autocomplete|ion|1.25.0
latex-workshop|Jam|9.14.0
lilypond-syntax|jea|0.1.1
scheme|jea|0.2.0
better-cpp-syntax|jef|1.17.2
vscode-bard|jim|0.0.10
google-search|kam|0.0.1
vscode-lua-format|Koi|1.3.8
lilypond-formatter|lhl|0.2.3
lilypond-pdf-preview|lhl|0.2.8
lilypond-snippets|lhl|0.1.1
vslilypond|lhl|1.7.3
zotero|mbl|0.1.10
git-graph|mhu|1.30.0
vscode-docker|ms-|1.26.1
black-formatter|ms-|2023.4.1
flake8|ms-|2023.6.0
isort|ms-|2023.11.12711013
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.20
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.313.0
remote-ssh|ms-|0.106.4
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.5
vscode-remote-extensionpack|ms-|0.24.0
azure-repos|ms-|0.36.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
js-debug-nightly|ms-|2023.9.2717
powershell|ms-|2023.6.0
remote-repositories|ms-|0.38.1
vscode-github-issue-notebooks|ms-|0.0.130
vscode-selfhost-test-provider|ms-|0.3.18
vscode-serial-monitor|ms-|0.10.0
vsliveshare|ms-|1.0.5883
autodocstring|njp|0.6.1
pandocciter|not|0.10.3
shiny-python|Pos|0.1.4
shinyuieditor|pos|0.5.0
quarto|qua|1.100.0
r-debugger|RDe|0.5.4
java|red|1.22.1
vscode-xml|red|0.26.1
r|REd|2.8.1
multi-command|ryu|1.6.0
vscode-deepl|soe|1.0.6
abc-music|sof|0.4.0
lua|sum|3.7.0
latex-utilities|tec|0.4.10
cmake|twx|0.0.17
errorlens|use|3.14.0
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-arduino|vsc|0.6.0
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.14
vscode-java-test|vsc|0.40.0
vscode-maven|vsc|0.42.0
markdown-all-in-one|yzh|3.5.1
grammarly|znc|0.22.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805cf:30301675
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012:30540252
pynewext54:30618038
a9j8j154:30646983
showlangstatbar:30737417
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
asynctok:30821568
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonlinttype:30823781
pythonmpsinfo:30842935
dsvsc015:30821418
pythontestfixt:30826906
pythonfb280951:30830809
pythonregdiag:30842812
pythoncet0:30848247

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-25 17:14:29,feature,"Have the ""Ask Chat"" button in the Command Palette default to the ChatView","Originally this option, which can be seen if you have a Chat Provider installed like Copilot Chat:


![Image](https://github.com/microsoft/vscode/assets/2644648/d5bfef99-bdd2-42b6-8bce-12b64fd9055c)


would open the query in Quick Chat.

However, I got feedback that Quick Chat may be too hard for newer users of VS Code and that instead it should open in Chat View... but there should be a setting to change this behavior to Quick Chat.

We should do this."
microsoft/vscode,2023-09-21 17:49:59,feature,"[Accessibility] ctrl+k, ctrl+shift+n does not open actionable notification items","
Type: <b>Bug</b>

The recently added keybinding ctrl+k, ctrl+shift+n does not seem to do what screen reader users want. If there are some notification items that require user interactions, pressing this key does not move user focus to the actionable notification item list.

Linking this keybinding to `""notifications.showList""` command seems more reasonable for the accessibility purpose.

VS Code version: Code - Insiders 1.83.0-insider (11bfd76a61a299156a9f3138ecfad70937af3527, 2023-09-21T05:34:38.227Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1145G7 @ 2.60GHz (8 x 2611)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (6.13GB free)|
|Process Argv|--crash-reporter-id b05b88e5-8894-4031-ae34-fa034ebddea9|
|Screen Reader|yes|
|VM|0%|
</details><details><summary>Extensions (91)</summary>

Extension|Author (truncated)|Version
---|---|---
android-dev-ext|ade|1.3.2
aiprm-lang|AIP|0.0.2
Bookmarks|ale|13.4.1
openscad|Ant|1.2.1
spellright|ban|3.0.118
zoterolatex|bna|0.4.1
mermaid-markdown-syntax-highlighting|bpr|1.5.2
doxdocgen|csc|1.4.0
vscode-markdownlint|Dav|0.51.0
vscode-eslint|dba|2.4.2
vscode-quick-select|dba|0.2.9
vscode-deno|den|3.23.1
gitlens|eam|14.3.0
EditorConfig|Edi|0.16.4
prettier-vscode|esb|10.1.0
vscode-google-translate|fun|1.4.13
codespaces|Git|1.15.3
copilot|Git|1.115.430
copilot-chat|Git|0.8.2023092101
remotehub|Git|0.60.0
vscode-github-actions|git|0.26.2
vscode-pull-request-github|Git|0.72.0
overleaf-workshop|iam|0.2.1
cslpreview|igo|0.2.2
easy-snippet|inu|0.6.3
path-autocomplete|ion|1.25.0
latex-workshop|Jam|9.14.0
lilypond-syntax|jea|0.1.1
scheme|jea|0.2.0
better-cpp-syntax|jef|1.17.2
google-search|kam|0.0.1
vscode-lua-format|Koi|1.3.8
lilypond-formatter|lhl|0.2.3
lilypond-pdf-preview|lhl|0.2.8
lilypond-snippets|lhl|0.1.1
vslilypond|lhl|1.7.3
zotero|mbl|0.1.10
git-graph|mhu|1.30.0
vscode-docker|ms-|1.26.1
black-formatter|ms-|2023.4.1
flake8|ms-|2023.6.0
isort|ms-|2023.11.12061012
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.20
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.311.0
remote-ssh|ms-|0.106.4
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.4
vscode-remote-extensionpack|ms-|0.24.0
azure-repos|ms-|0.36.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
js-debug-nightly|ms-|2023.9.2017
powershell|ms-|2023.6.0
remote-repositories|ms-|0.38.1
vscode-github-issue-notebooks|ms-|0.0.129
vscode-selfhost-test-provider|ms-|0.3.18
vscode-serial-monitor|ms-|0.10.0
vsliveshare|ms-|1.0.5883
autodocstring|njp|0.6.1
pandocciter|not|0.10.3
shiny-python|Pos|0.1.4
shinyuieditor|pos|0.4.3
quarto|qua|1.98.0
r-debugger|RDe|0.5.4
java|red|1.22.1
vscode-xml|red|0.26.1
r|REd|2.8.1
multi-command|ryu|1.6.0
vscode-deepl|soe|1.0.6
abc-music|sof|0.4.0
lua|sum|3.7.0
latex-utilities|tec|0.4.10
cmake|twx|0.0.17
errorlens|use|3.13.0
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-arduino|vsc|0.6.0
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.14
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
markdown-all-in-one|yzh|3.5.1
grammarly|znc|0.22.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805cf:30301675
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012:30540252
pynewext54:30618038
a9j8j154:30646983
showlangstatbar:30737417
ecj1e332:30687743
pythonfmttext:30716741
fixshowwlkth:30771523
showindicator:30805243
pythongtdpath:30726887
i26e3531:30792625
welcomedialog:30812478
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingt:30808721
asynctok:30821568
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206
pythonlinttype:30823781
pythonmpsinfo:30815194
dsvsc015:30821418
pythontestfixt:30826906
pythonfb280951:30830809

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-14 23:13:36,feature,debug: surface StackFrame moduleId in the debug CALL STACK UI,"Go debug adapter (delve) has been using the fully qualified go function names as the stack frame names.
These names include the full package path (e.g. `example.com/foo/bar`) and the function name (e.g. `pkg.ACoolFuncName`), and many users requested to shorten the names presented in the CALL STACK view. For example,  https://github.com/microsoft/vscode/issues/178964, https://github.com/golang/vscode-go/issues/2707.
 
One way to handle this is to shorten the name by dropping the full package path.
For example, our contributor is proposing to control this by adding a new launch config setting.
https://github.com/go-delve/delve/pull/3497 I think it makes sense to show the function name, 
but I wonder if we can still carry the package info (""module"" in other languages).

`StackFrame` has the `moduleId` field.
The current VS Code doesn't seem to utilize this field at all.

How about utilizing the `moduleId` field and surfacing it in the UI?

I think the tooltip shown when hovering over the stackframe name is a good option.

Screenshot with [a small change in callStackView.ts](https://github.com/microsoft/vscode/compare/main...hyangah:vscode:debugstackframe) and a delve-side change:

![Screenshot 2023-09-14 at 6 36 33 PM](https://github.com/microsoft/vscode/assets/4999471/6b5b1ff8-007f-40c2-924b-f9263ab06eff)

One concern is it will be surprising for other language debug adapters that use the `moduleId` field already for other purposes.

cc @suzmue @stefanhaller @aarzilli"
microsoft/vscode,2023-09-14 07:13:25,feature,indentSize API finalization,"This API adds `indentSize` as a property to `TextEditorOptions`

https://github.com/microsoft/vscode/blob/main/src/vscode-dts/vscode.proposed.indentSize.d.ts"
microsoft/vscode,2023-09-11 13:19:46,feature,Windows is ignore terminal titles unless they look like paths,"From @NoelAbrahams in https://github.com/microsoft/vscode/issues/172821#issuecomment-1712935578

> I've been trying to programmatically set the title of a bash terminal without success, and glad that I chanced upon this issue.
> 
> Here is the repro:
> 
> System: Windows 11.
> Git Bash installed.
> VSCode version:  1.82.0
> 
> VSCode Workspace Settings:
> 
> ![image](https://github.com/microsoft/vscode/assets/1106823/597a9727-bbac-41bc-81cd-0a73a723787f)
> 
> 
> **.bashrc**
> ```shell
> echo -en ""\\033]0;New terminal title\\a""
> ```
> 
> The title of the bash terminal window remains stubbornly unchanged as `bash myworkspacefolder`.
> 
> I'm assuming this issue will fix my use case.
> 
> Thanks

---

This section is setting it to undefined:

https://github.com/microsoft/vscode/blob/41e940f76f5deda197bc5930b044c55607ba1cbc/src/vs/workbench/contrib/terminal/browser/terminalInstance.ts#L1933-L1946

We want to keep the path trimming behavior above, but only when it looks like a path."
microsoft/vscode,2023-09-08 15:44:48,feature,Allow the debug toolbar to show in the command center,"Today the debug toolbar can be hidden, floating around, or be docked inside the viewlet. This is about adding it to the command center. 

Implemented by https://github.com/microsoft/vscode/pull/192571, via `""debug.toolBarLocation"": ""commandCenter""`

https://github.com/microsoft/vscode/assets/1794099/3dff87e9-7230-4a15-a906-bb8c1134dbce

"
microsoft/vscode,2023-09-07 09:36:46,feature,Support icons for Profiles,"Support Icons for Profiles

- https://github.com/microsoft/vscode/issues/192309
- https://github.com/microsoft/vscode/issues/188972"
microsoft/vscode,2023-09-06 19:50:02,feature,Adopt accessible view in terminal,This change should be seamless for screen reader users and we'll want to test it thoroughly to ensure that.
microsoft/vscode,2023-09-05 18:19:49,feature,Theme names should have transated name and untranslated name like the command palette,"See in the list below:

- Dark+ (no localization)
- Kimbie 어둡게 (only dark translated)
- 다크 모던 (all translated with loan words ""daku modeon"")

![Image](https://github.com/microsoft/vscode/assets/2193314/9140bef0-9dbf-4063-993a-418ab77fef19)

Ideally this would act like commands where we provide the original if they differ:

![Image](https://github.com/microsoft/vscode/assets/2193314/99b734c7-f12d-4c22-9de5-d0ad4a726d21)

"
microsoft/vscode,2023-09-01 12:00:15,feature,Moved Code Should Scan Previous/Next Lines,"## Description

These moves could be one:

![Image](https://github.com/microsoft/vscode/assets/2931520/bc3d00b8-bcd6-4701-ad0d-7b8a147174a2)

And this move could be bigger:

![Image](https://github.com/microsoft/vscode/assets/2931520/fc608030-2dfb-4d12-afb9-984b7432ac2c)


## Playground Example

[Monaco Editor Playground Repro 1](https://microsoft.github.io/monaco-editor/playground.html?source=v0.42.0-dev-20230901#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)


[Monaco Editor Playground Repro 2](https://microsoft.github.io/monaco-editor/playground.html?source=v0.42.0-dev-20230901#XQAAAAKfFAAAAAAAAABBqQkHQ5NjdMeMm-jY7SIQ9S7DNlzs5W-mwj0fe1ZCDRFc9ws9XQE0SJE1jc2VKxhaLFIw9vEWdz-byd4qAOcAtGHISeqPUOpmZMOtupg8LSGcQyHTbXfA4-ZuN7bGSQev24D3DlbBsuzz4NuoMTyCTQh-PcwtOu8kKuGTw-CICnoPDJZTuv9aDW5r9TA-xXqj_q9vfucH4sLCdJpcMdKu0v_hhroVLUOqVQjGhZEI-tuN-If50K_ST264MrIQ29zKBgDhOYs9Rzfc9ISiQA5b3yF60OMIpSMQnFrOJbor1bjWDCMIwCej92z1EnRRaIi6KTDZDtJ-Wf-e42v-IhOf3THzMKqxqUUplKblD0pEElZQyj88swVXiO62DaA_5jvKODiCN3IzmrmYDkctGfLfCWHszt27ogIt2LAyShvoPPRtnqWozgdAnN3hB01ILHxHA0w4CdgbKxC9d3cJfW19CON3zDVtAxTBfzzx_n1cqQSqeGb0ceK_x4nAGB5_enL3DzFwg2iL34vaOOZshb9DFNY2K4muJdAf0H_oOcAbuvAPGA_21JEel08wJEcKpHgRZYemFyYYeDPm7GbIuwwyfKFT1Iq8copW9u_nx5_OuZj1ttmX5DiYLG0KWETgGRjHQLy1Jx84EPjPQuUOGm264ovJOSA3KXXJXX8sqbCKKVSDZbwiaQJ8EdZ1CZBipqsSGeYfC3cuFcfQUL9PzJ3zF4HOAEd72-czeRHx_KLmOHW8S6i6Z-k4AaarT_5YG1HIz7KiyyUz--uyfvYXSq8z_9X4org2MLlv8qlz_iaMf7yHpuWrLKX0mlMZ1iVq0BhXYUFvAPi6IV7KktNDhKQPEPfprB7IyKx9zoWxsBJUY0W_pklA0Z6yiFjVnWl_sfe36mVsSLwrZI4ztQkcb1ax1ICNXydXahDPV-wFjzaTehAij-Vb6RDFBszFXmatY-igMBFlqRLn9MBPh1KWlS7cDDz4Q6UI1NNcrWr7CY2_9ECfqzBTTzlWdS5cQk5eQkuml8YiUBh1anr5u4Qe4MSlJb7am3AR4_YKuptwcW4hnqqfra8JUhEmgvrUEDNcMPqDiwkn9lcV9wivSyjLv7RGVQ4Y4A2ZFnqufuaTHrvUt3yprtcnMYhC8gjuYgRMtjrPqHhMuTaeUxqAdzXx9LMMr-ayuzr6w-HXEzVxqgE_4_BBnJzXXI4Xj7lLQCYaHEO4NZtWr2a0kaQWgiKOfKOCWFuMPtvxaqJONtoXWQVOywEaK6-dP54UbDDj0zoD3M4LKzbDFWgGJMBDN-RKQE93o6uhBqYM6MrGRBk0tMYwkHlSUen3w37FBqBQp_bpwgjfWnz9mBnhOLQJVo7hG9DUgAFXgu9NFFkl2S4KWyihK7EcpQ-u55DZwMdjUmbCTTGawgftuCSILi54YxmXnulGHF1ZM3L1IyzYWLwErerNgwZrjR0l6_UY74_4IGVyhLrm5yYsilN8YhQx7CpbFWiaHw-t4adi1FkQ71nc_PK21m22LORnBSO3vEE_OmpwFNtnFHxiRRNWdYuHuWCaDRoJ0wYPlRPmEh-MeewetJh2g9bmiNVDEkUtS9Yl9-zgUm6KV_1ta7E) (click on ""use latest dev"" to verify a future bug-fix)"
microsoft/vscode,2023-08-31 21:54:48,feature,"[Accessibility] Consider removing ""terminal.integrated.tabFocusMode""","
Type: <b>Feature Request</b>

Now that tabindex is removed from the terminal buffer area, I was wondering if ""terminal.integrated.tabFocusMode"" would be still useful. If not, please consider removing this option to officially deprecate this.

VS Code version: Code - Insiders 1.82.0-insider (3cd6f481266dcbd2ca2fcff43b4465d747c78e2f, 2023-08-31T17:34:55.916Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-30 23:05:56,feature,Add support for grouping root workspace folders,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
I'd like to nest workspace folders like this:

```json
""folders"": [
  {
    ""name"": ""e2e"",
    ""folders"": [
      {
        ""name"": ""app1"",
        ""path"": """"
      },
      {
        ""name"": ""app2"",
        """"
      }
    ]
  }
],
```

Functionally the folders can act the same as if the list were flat, but just in UI the nested structure is shown. My immediate need would also be solved by https://github.com/microsoft/vscode/issues/32693 but I've used this feature a bit in Visual Studio to group shared library projects where for other reasons the folder structure on disk needed to be different."
microsoft/vscode,2023-08-29 15:21:13,feature,[Improvement] Icons to expand and contract the hidden lines should be placed on top of each other in the diff view,The icon to expand the hidden lines is to the right of the editor gutter. The icon to contract the hidden lines is to the left of the editor gutter. Perhaps these icons could be positioned in the same spot so that the user can contract the hidden lines after the last expansion without moving the mouse.
microsoft/vscode,2023-08-28 18:35:10,feature,Make comment editor expandable,"The editor in the comment widget doesn't get any larger when the content doesn't fit. This makes editing long comments painful:

![image](https://github.com/microsoft/vscode/assets/38270282/16e541ea-7f22-41a7-9e31-c056f0b11eb3)
"
microsoft/vscode,2023-08-28 17:51:30,feature,Make QuickChat styles closer to QuickPick,"This was done across multiple PRs to eventually get to this experience:


![Image](https://github.com/microsoft/vscode/assets/2644648/9a7dd1cd-0fe9-44cf-bbd0-770f8af51b0d)

https://github.com/microsoft/vscode/pull/190101
https://github.com/microsoft/vscode/pull/190780"
microsoft/vscode,2023-08-28 12:06:59,feature,[css] text-wrap: balance is css(unknownProperties),"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.81.1
- OS Version: Ventura 13.5

<img width=""480"" alt=""Screenshot 2023-08-28 at 14 05 44"" src=""https://github.com/microsoft/vscode/assets/3521624/6db91cec-b712-4fa2-870e-98714ad13be0"">

Steps to Reproduce:

1. write text-wrap: balance
2. observer error
"
microsoft/vscode,2023-08-24 21:09:33,feature,Add `preserveInput` for quick search,"There is currently a way to preserve the input for quick open and the command palette, but not for quick search. Add a setting for this."
microsoft/vscode,2023-08-23 23:07:30,feature,Go to next change doesn't show in command palette in diff editors,"Steps to Reproduce:

1. Open a git change in the scm view
2. Try using `Move to Next Change` in the command to navigate to a diff in the file


**Bug**
`Move to Next Change` doesn't show in the command palette, only in the toolbar. I see the command in normal text files


Related #136059
"
microsoft/vscode,2023-08-23 02:33:01,feature,Support binding to a unix domain socket instead of a TCP address in serve-web,">It doesn't look like this new CLI supports serving on a UNIX domain socket. Could we please get that added in too, like in https://github.com/microsoft/vscode-remote-release/issues/6940? We're going to need it in order to handle auth in a proxy. (I'm happy to open a new issue for that if you need)

_Originally posted by @leifwalsh in https://github.com/microsoft/vscode/issues/191014#issuecomment-1689095808_
            "
microsoft/vscode,2023-08-22 10:17:24,feature,Diff Editor: Don't align just whitespace,"

![Image](https://github.com/microsoft/vscode/assets/2931520/5c41d7b3-9475-4459-8f78-5af7767735b0)

[Repro](https://microsoft.github.io/monaco-editor/playground.html?source=v0.42.0-dev-20230809#XQAAAAKOBwAAAAAAAABBqQkHQ5NjdMjwa-jY7SIQ9S7DNlzs5W-mwj0fe1ZCDRFc9ws9XQE0SJE1jc2VKxhaLFIw9vEWSxW3yscxB_hCRgmSatbNyrNa50VLHWwDOn0YI7IfU0xJ0CGYU1vRtgnKPmZzQcQ1F9I-F9YcvQUj8HivueDk6xk10aTtNR3RAJjdvBxfoTGfcszve9sgLIoLXVmtphjl9ux0scTbqn8xJDJ_Vu3bQ0F0nkf4EFAzrz_o4urR-zwk3aaM_5g8NtmF0aIDYBdEIX1-uzWDGO8qM9NqETpjA77g4aeC2ouBFbqtZXc4BgMMq0rMeL2_ytGNfhnELoRtIMy01Fd-x9jvDYURVNW4XXqOKmYcNwywXX_EVXHKGESPwbWe76pI7_e2JadX9zPm8E6nWRqm6D1mnsZ480SeVg-yAEwblWLefKvKYP26ylb9duVmsKAZV6x3CXMzq57bBTtGhKaFanDsAwFtV1JjAApPKUq_EWzmTAVMNdp2Fay6AkJW_nNLZQsWMzo57zFXeFPhBLL_PADIxBHwsclGemqttG5gGybiSvsivuOUBZaE8tWMT3ULAFUlGxLAiDA6mw35w3ez-8Q5GfENNUCkg_bJ0EM4dhVuXRCs072DINsB9jAblUw2nA5fdLFHZdRn6D8JSNRoHD4j_oQUpeCG2IbRNIQoMDSE46etnzw4ByBuFj8yEufW4xciyUpn9VrQtPzbAmaOtdBX_ItJgajY3E-448EdliKgcdxsFq0B5xgasx0MTWKqAX5xt6Xar3gNBBQPnsUi2MJJLulgJ3Ro36oGtMMBEa0kp5QDK-iH2kjUvwzcMOunlklCcYCFbZNVi_IAzT1BfRXgw3ZkN5UV2QgTl5zRi4DRQJEeE6jxRmKSI_QEuBfpdwUEx_rD4Jg)"
microsoft/vscode,2023-08-21 17:45:09,feature,Explore RelatedInformation Provider,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

This would replace [SemanticSimilarity](https://github.com/microsoft/vscode/blob/a29a3782af70d01cedacf77e850e451066128f7f/src/vscode-dts/vscode.proposed.semanticSimilarity.d.ts#L7).

Proposal:

```ts
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

declare module 'vscode' {

	// https://github.com/microsoft/vscode/issues/190909

	export enum RelatedInformationType {
		SymbolInformation = 1,
		CommandInformation = 2,
		SearchInformation = 3,
		SettingInformation = 4
	}

	interface RelatedInformationBaseResult {
		type: RelatedInformationType;
		weight: number;
	}

	// TODO: Symbols and Search

	export interface CommandInformationResult extends RelatedInformationBaseResult {
		type: RelatedInformationType.CommandInformation;
		command: string;
	}

	export interface SettingInformationResult extends RelatedInformationBaseResult {
		type: RelatedInformationType.SettingInformation;
		setting: string;
	}

	export type RelatedInformationResult = CommandInformationResult | SettingInformationResult;

	export interface RelatedInformationProvider {
		provideRelatedInformation(query: string, token: CancellationToken): ProviderResult<RelatedInformationResult[]>;
	}

	export interface EmbeddingVectorProvider {
		provideEmbeddingVector(strings: string[], token: CancellationToken): ProviderResult<number[][]>;
	}

	export namespace ai {
		export function getRelatedInformation(query: string, types: RelatedInformationType[], token: CancellationToken): Thenable<RelatedInformationResult[]>;
		export function registerRelatedInformationProvider(type: RelatedInformationType, provider: RelatedInformationProvider): Disposable;
		export function registerEmbeddingVectorProvider(model: string, provider: EmbeddingVectorProvider): Disposable;
	}
}
```"
microsoft/vscode,2023-08-21 14:20:27,feature,Diff Editor v2: setting for number of untouched lines around unchanged regions,"There is now diffEditor.hideUnchangedRegions.contextLineCount.

Verification steps:
Set it to a value (e.g. 7), open a diff where there are many unchanged lines and verify that the distance between a changed line and the closest collapsed code block is at least as many lines as specified."
microsoft/vscode,2023-08-18 19:33:54,feature,quick text search: show open files first,"related to https://github.com/microsoft/vscode/issues/189964

Since quick picks don't support streaming results via callback, the 'quick text search' seems a bit slow. If we show some synchronous results (from open editors) ahead of time using the `FastAndSlowPicks`, it might give the user something initial to look at."
microsoft/vscode,2023-08-16 05:02:10,feature,[themes] follow `window.autoDetectColorScheme` when switching profiles,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.81.1
- OS Version: windows11 23H2 22631.2191

Steps to Reproduce:

1. Switching to the Default profile 
2. Switching the Windows to dark theme
3.  Switching to the other profile, but the VS Code remains the light theme
"
microsoft/vscode,2023-08-15 15:26:15,feature,Show Extension Dependents,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

I just discovered that the [.NET Install Tool for Extension Authors](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.vscode-dotnet-runtime&ssr=false#review-details) was installed without my interaction. I had no idea where this came from or why it was suddenly added. It wasn't until I tried to uninstall it that I saw a warning that the C# extension depends on it, I had no other way of knowing.

Please add a tab to the Extension info page to show what extensions depend on a given extension.
~~It would also be great to see what a given extension depends on.~~ I never noticed the Dependencies tab on extensions until I was looking into this issue and now it's very strange that there isn't the ""reverse"" for installed dependencies.


"
microsoft/vscode,2023-08-14 07:54:54,feature,diff giving more priority to blank lines,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->

Version: 1.81.1 (user setup)
Commit: 6c3e3dba23e8fadc360aed75ce363ba185c49794
Date: 2023-08-09T22:22:42.175Z
OS: Windows_NT x64 10.0.19045

Steps to Reproduce:

1. Open two new/blank editors
2. Compare both the editors 
(Open Editors `ctrl-k e` > select both `shift-up/down` > right click > compare selected)
3. Paste this on one side, and that on the other (mind the empty lines)
4. Now, on ""that"" side: try to make it match the left side by say:
    * removing one empty line from starting, or 
    * putting `# ` before `async`

<details><summary>this and that</summary>

this: 

```

# async def handle(request):
#     keyvals = request.match_info
#     return web.Response(text=keyvals)


async def fetch_name(request):
    pass


async def insert_name(request):
    pass
```

that:

```


async def handle(request):
    keyvals = request.match_info
    return web.Response(text=keyvals)
```

</details>

wrong diff result:

<img src=""https://github.com/microsoft/vscode/assets/19423063/70add44f-989a-457d-81c8-474b003cceef"" width=550px/>

after the step 4 given above - i.e. on increasing similarity; it detects common part correctly:

<img src=""https://github.com/microsoft/vscode/assets/19423063/43a515dc-8e31-4d70-b2bc-020c827dd052"" width=550px/>


https://github.com/microsoft/vscode/assets/19423063/6cccdcac-64b3-4bcd-a38b-281c91c621a9


"
microsoft/vscode,2023-08-13 18:26:38,feature,Dim terminal text should have half the minimum contrast ratio,"See https://github.com/microsoft/vscode/issues/178162 for an example of why this is an issue

Repro:

- Set a high minimum contrast ratio in settings
- Run `echo -e '\\x1b[31mNormal \\x1b[31;2mDim\\x1b[0m'`, 🐛 provided the minimum contrast ratio is not too high, the colors should differ

Actual:

![Image](https://github.com/microsoft/vscode/assets/2193314/11aa5ec6-da63-4eba-8d6b-b125d0d52e69)

Expected:



![Image](https://github.com/microsoft/vscode/assets/2193314/3ca6b31d-c0be-4f05-b7e6-353d50b326ac)


"
microsoft/vscode,2023-08-11 15:43:07,feature,"Side by side Compare (diffs) should leverage editor groups instead of nested ""subgroups""","Developers often work with two editor groups (side by side).  When switching between editing and comparing your changes to the existing code, the UX is not great.  I prefer to use side-by-side diffs rather than inline.  When opening a compare, the side-by-side compare editor is squeezed into whichever editor group is active, which means the ""before"" and ""after"" sides of the compare editor end up with 1/4 of the total available editor width.  Even on a 5k monitor this is cramped:

<img width=""972"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/7581987/dd16f4a7-7e5a-4bac-85e2-297fab9f2f1a"">

So I end up merging all of the editor groups.  When I close the compare and switch back to editing, I've lost my editor organization.

Would it be possible for split compares to just open two linked editors?  The left and right editors would have their own tabs in side-by-side editor groups.  Activating/Closing one would activate/close the other, scrolling would still be linked between the two, etc.  This could have other advantages, for example breadcrumbs and stickiness today is only supported for the right half of the compare editor (even though these features are left-aligned).

If two adjoining groups don't exist, a new group could be added with some kind of ""transient"" flag, such that it goes away when it becomes empty (if the user explicitly moves something into that group, it maybe clears that flag?)"
microsoft/vscode,2023-08-10 09:51:43,feature,renderSideBySide: never | auto | always,"Instead of renderSideBySide: boolean, we could have renderSideBySide: never | auto | always.

As a downside, when a user switches from the inline view to the side by side view, they probably switch to ""renderSideBySide: never"" and not ""auto"", even though ""never"" does not make much sense."
microsoft/vscode,2023-08-08 23:01:04,feature,Notebook toolbar foreground color cannot be modified by custom styles:,"The unavailable foreground color has been marked with a red arrow, please see the image


Expected behavior:
Notebook toolbar foreground color can be modified through custom styles.

Unexpected behavior:
Notebook toolbar foreground color cannot be modified through custom styles.

VS Code Version: 1.81 | 1.82
OS Version: Windows10
"
microsoft/vscode,2023-08-08 20:41:01,feature,Consider adding `ctrl/cmd+shift+.` as go to symbol keybinding in accessible view,cc @jooyoungseo
microsoft/vscode,2023-08-06 19:36:35,feature,[Accessibility] Add a custom setting always moving focus to terminal buffer after sending selection to terminal,"Type: <b>Feature Request</b>

For screen reader users, terminal buffer is the great landing area where they can verify executed commands.

Currently, the focus always moves to terminal input when we use the following command:

> Terminal: Run Selected Text In Active Terminal

Given the immediate need of accessing the terminal buffer for screen reader users, please add a custom setting to always move focus in terminal buffer area instead of the terminal input. This will greatly improve the accessibility, navigability, and alertability for screen reader users.

VS Code version: Code - Insiders 1.82.0-insider (83fc3ad9bd553869e8fea3d370d1d2bd438f9e54, 2023-08-04T05:35:09.023Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-06 03:45:09,feature,Update search results after enter pressed in files to include/exclude text fields.,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
When the user has a high debounce delay and changes the files to include/exclude text fields it can take a couple of seconds for the search results to update. This could be fixed by giving the user the option to skip this delay by pressing enter. This already happens with the search text field.

It seams like calling triggerQueryChange(); after the user presses enter in one of the fields would fix this problem. 

Maybe somewhere in setSearchParameters (line 1,329) at src/workbench/contrib/search/browser/media/searchView.ts?
"
microsoft/vscode,2023-08-04 20:05:10,feature,Support public/private port toggle in tunnel forwarding,"@derekbekoe

> While testing [microsoft/vscode-internalbacklog#4382](https://github.com/microsoft/vscode-internalbacklog/issues/4382) via the instructions in [microsoft/vscode-remote-release#8751](https://github.com/microsoft/vscode-remote-release/issues/8751), I noticed that switching port visibility has no effect and the port stays ""Private"".
> 
> Public visibility would be helpful for scenarios such as testing webhooks.
> 
> _Also, there are a few vs code repos but hopefully this is an appropriate one to file this._
> 
> cc: @connor4312

"
microsoft/vscode,2023-08-03 16:31:38,feature,Rich content results for naive output in closed notebooks,"Currently, we show rich content results for inputs in closed notebooks. It would be nice to show some output results info before we enable this experimental feature for insiders, since some people might want to search in outputs (even if it's not fully a ""rich content result"")"
microsoft/vscode,2023-08-02 17:22:56,feature,Menu bar unnecessarily changes to hamburger when window width is reduced,"This feels similar to #152906 but that's marked as closed.

I don't like the hamburger menu, I want to always see the normal menu bar. It already supports overflowing, but for some reason as soon as the Go menu overflows, it seems to be entirely replaced by the hamburger. I don't understand why this is (when there's already an overflow), and I would prefer it to just move more items into the overflow. The hamburger adds an extra click to get to the File menu (which is almost always the menu I'm using the mouse for).

https://github.com/microsoft/vscode/assets/1078012/a2b654e5-395e-4020-a8a2-30ce63443494

I've tried changing various settings, including setting ""Menu Bar Visibility"" to ""Visible"", but nothing seems to fix this (except disabling Command Center, but I feel like that shouldn't be necessary because a) there's an overflow for the menu and b) the command center appears to basically just be a mouse hit target, so could probably shrink in size?)."
microsoft/vscode,2023-08-02 15:45:59,feature,[Feature] Collapse Region In Sticky Scroll,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
In the Sticky Scroll section, it would be nice to be able to collapse those regions. This would allow us to move to the next region more quickly when we're finished with the current one."
microsoft/vscode,2023-08-01 15:06:39,feature,Render terminal cursor in the webgl canvas,"Incoming change from xterm.js: https://github.com/xtermjs/xterm.js/issues/4082 https://github.com/xtermjs/xterm.js/pull/4568

To verify, check all combinations of `terminal.integrated.cursor*`, moving the cursor around in the terminal a bit and ensure they work."
microsoft/vscode,2023-07-31 22:07:15,feature,[Accessibility] Add keybindings going between terminal input and output buffer back and forth just like Copilot Chat view,"
Type: <b>Feature Request</b>

Currently, to navigate between terminal input and output, users are required to use the Tab and Shift+Tab keys. While this does offer a method for moving around, it's not an ideal solution. The tab cycle can include other tabbable elements which may not be relevant to the user's immediate needs.

I would like to point out the new navigation model introduced in the Copilot Chat view. This new navigation system is both efficient and user-friendly. By pressing Ctrl+UpArrow while in the chat input, users' focus is shifted directly to the chat output, regardless of how many times the Ctrl+UpArrow key is pressed. To return to the chat input from the output view, users simply press Ctrl+DownArrow.

By implementing a similar system for navigating between terminal input and output, VSCode could greatly improve the user experience. The intuitive and user-friendly design of the Copilot Chat view's navigation system makes it a perfect candidate to be extended into other areas of VSCode UI.

I believe many screen reader users would appreciate this change, as it would streamline their interactions with the terminal input and output buffer.

VS Code version: Code - Insiders 1.81.0-insider (9800cf6dd6bf4634889d60720ef46a400f3a7298, 2023-07-28T12:08:04.472Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-31 10:17:15,feature,"""Restart running task"" command shouldn't show quick pick if there's only one task to restart","<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
"
microsoft/vscode,2023-07-28 15:47:18,feature,Add snippets as a language,"There's a good community grammar for snippets at https://github.com/jeff-hykin/better-snippet-syntax, which would improve our snippets experience. We could include this as one of our built in languages. "
microsoft/vscode,2023-07-26 19:14:18,feature,Allow specifying prompt prefix via Environment variable collection,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
```typescript
export interface EnvironmentVariableCollection {
    /**
     * A string that will be prepended to the existing prompt in the terminal. Keep it short and only use it if
     * it's really needed, as it modifies all terminals, even those not related to the extension.
     * 
     * Note this only applies if shell integration is enabled.
     */
    promptPrefix: string;
}
```
The idea is to use shell integration to apply this parameter. This can be used by Python extension to indicate an environment is activated in Powershell or fish where there is no other way to set the prompt."
microsoft/vscode,2023-07-25 17:50:48,feature,Mouse click shortcut to split view right,"Sublime Text 4 has a great feature that allows us to simply ""CTRL + Left Click"" on an editor tab to split view that tab with the currently selected open editor tab. Right now the only way to do this in VS Code is by right clicking the tab and selecting ""Split Right"".

To demonstrate what I'm asking for, let's say we currently have 3 open editors, file 1, file 2, and file 3. Let's say the currently selected open editor tab is file 1. What I'd like to do now is to Split Right file 2. In order to do this with VS Code, I must right click file 2 and select ""Split Right"". What I'd like is the ability to do this exact same scenario by simply holding CTRL + left clicking file 2's tab.

VS Code v1.80.1
OS: Windows_NT x64 10.0.19045"
microsoft/vscode,2023-07-25 14:47:25,feature,Commands do not work in single question mode,"Testing #188542

Looks like they are not supported:

![image](https://github.com/microsoft/vscode/assets/900690/f152ccb7-adc8-427b-9254-0fb7197cd993)
"
microsoft/vscode,2023-07-25 09:29:14,feature,Settings editor doesn't respect ctrl+up and ctrl+down,"Testing #188536

Not sure if the settings editor is intended to support this, but it seems very similar to the other places that do support it.

"
microsoft/vscode,2023-07-24 23:06:39,feature,Add tunnel activation event,"With https://github.com/microsoft/vscode/pull/188270, extensions can now contribute tunnel factories. However, extensions doing this need to get activated on `*` / startupFinished to be shown there. It'd be nice if there was some kind of ""tunnel"" activation event that would only pick up when a tunnel or requested, or perhaps if the Ports view is interacted with, to avoid this.

Mentioned in https://github.com/microsoft/vscode-remote-tunnels/pull/661#discussion_r1272804131"
microsoft/vscode,2023-07-24 17:31:13,feature,Allow terminal quick fix providers to call vscode commands,Currently quick fixes can run a command in the terminal or open a URI. To fix with copilot we need to run a command which will then do the work in order to suggest the result (which could take some time).
microsoft/vscode,2023-07-23 13:19:11,feature,Disable autosave while debugging,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

I would like to be able to disable autosave while debugging. It's a problem if you are using hot reload."
microsoft/vscode,2023-07-21 09:22:36,feature,Open Preview to support spawning new tabs,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Currently, when opening for example a markdown file in preview the VS Code editor only uses the first tab to present the markdown. As Shown below:
![Animation](https://github.com/microsoft/vscode/assets/24381727/24352b90-a953-4608-ab1d-9d824630e7b5)

It would be nice to make it possible to open multiple files in preview mode and spawn new window tabs. "
microsoft/vscode,2023-07-20 20:07:18,feature,Diff Editor v2: hide unchanged code command,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

in the new diff editor you can hide unchanged code, but there's no way to fold or unfold all regions at once. They all come folded but you must unfold each region manually, and must also fold them back. It would be nice to have a command to un/fold all regions at once, just like with code. 
![image](https://github.com/microsoft/vscode/assets/73979580/98d54f36-e80d-458c-9075-289a59370a93)

there's no need for all code folding functionalities but at least fold and unfold all would be very useful"
microsoft/vscode,2023-07-20 16:20:07,feature,[json] set a user agent when attempting to retrieve `$schema` JSON Schemas,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.79.2
- OS Version: Darwin x64 22.5.0

Steps to Reproduce:

1. Start a webserver at `http://localhost:8080` serving a single schema at `foo.json` containing `{""required"": [""bar""]}` (the precise contents don't really matter)
2. Open a file bar.json, and paste in:


```json
{
  ""$schema"": ""http://localhost:8080/""
}
```

3. Place the cursor between the quotes just after the trailing slash
4. Type foo.json, and look at the webserver logs, observing no user agent was sent"
microsoft/vscode,2023-07-19 20:32:20,feature,add accessible view hint to aria label for hovers,"we can pretty easily do this for editor hovers, but I'm not sure how straightforward this will be to apply to the aria labels of extension contributed ones via the context view service"
microsoft/vscode,2023-07-19 14:48:47,feature,pressing enter on deleted lines should take me to old file,"Verification steps:
* Open Diff Editor
* Press F7 to open accessible diff viewer
* Select a deleted line and press enter
* verify focus is in original editor
* Press F7 again
* Select a modified line and press enter
* verify focus is in modified editor"
microsoft/vscode,2023-07-19 04:24:52,feature,"Turning off debug settings Focus Editor On Break, Focus Window On Break, or set the Open Debug to neverOpen,  doesn't work ","
Type: <b>Bug</b>

I have `main.js` and import it to `main.debug.js`. In `main.debug.js` I have a breakpoint, either by clicking the breakpoint dot or by the `debugger` line. In `launch.json` I set:
```js
""program"": ""main.debug.js"",
```
If I open `main.js` and hit F5, then when the debugger hit the breakpoint on `main.debug.js`, the editor will automatically switch to that file. Is there a way to set this off? In the setting i have tried to turn of Focus Editor On Break, Focus Window On Break, and set the Open Debug to neverOpen, but it still switches.

![](https://i.imgur.com/YkfO26Wm.png)
![](https://i.imgur.com/CrXyGLLm.png)


VS Code version: Code 1.80.1 (74f6148eb9ea00507ec113ec51c489d6ffb4b771, 2023-07-12T17:22:07.651Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz (8 x 2112)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.84GB (0.53GB free)|
|Process Argv|--crash-reporter-id a6dbf1b7-4d72-49e8-badf-07a408420f74|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (39)</summary>

Extension|Author (truncated)|Version
---|---|---
Bookmarks|ale|13.4.1
htmlplay|bia|0.0.10
markdown-mermaid|bie|1.19.0
mermaid-markdown-syntax-highlighting|bpr|1.5.2
vscode-search-long-paths|car|0.0.3
regex|chr|0.4.0
vscode-markdownlint|Dav|0.51.0
vscode-eslint|dba|2.4.2
githistory|don|0.6.20
gitlens|eam|14.1.1
RunOnSave|eme|0.2.0
url-encode|fle|1.1.0
ftp-simple|hum|0.7.6
graphviz-previewer-web|ijm|0.0.8
copy-markdown-as-html|jer|1.1.0
vscode-graphviz|joa|0.0.6
vscode-autohotkey-plus-plus|mar|3.3.2
json|Mee|0.1.2
isort|ms-|2023.10.1
python|ms-|2023.12.0
vscode-pylance|ms-|2023.7.20
jupyter|ms-|2023.6.1101941928
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-wsl|ms-|0.80.2
powershell|ms-|2023.6.0
vscode-markdown-paste-image|tel|1.0.0
graphviz-interactive-preview|tin|0.3.5
intellicode-api-usage-examples|Vis|0.2.7
vscodeintellicode|Vis|1.2.30
vscode-mermaid-preview|vst|1.6.3
quokka-vscode|Wal|1.0.547
wordpress-toolbox|wor|1.3.15
JavaScriptSnippets|xab|1.8.0
yautohotkey|yed|1.1.3
esm-cjs-converter|zha|1.0.7
vitest-explorer|Zix|0.2.42


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vscaac:30438847
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
89544117:30613380
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
hideindicator:30785051
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30779714
pythonidxpt:30784022
pythonnoceb:30776495
h7j2d465:30786200
h0f32768:30792100
dsvsc013:30789517

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-18 19:15:13,feature,adopt `next/previous` in chat response accessible view,"Useful so a screen reader user doesn't have to escape the view, navigate to the next element, and reopen the view.

This is possible now in notifications and should also be possible for notebook output cc @amunger "
microsoft/vscode,2023-07-18 10:54:55,feature,"While editing multiline using ctrl + d if a right import suggestion is accepted, it will only effect on the first occurrence's spelling.","<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Not sure

While editing multiline using ctrl + d if a right import suggestion is accepted, it will only affect on the first occurrence's spelling.

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.80.1
- OS Version: Windows 11  

Steps to Reproduce:

1. For example, in a file, I have a variable type called `UserService `and I want to change it to `CustomUserService` and there are at least two mentions of it, the type.
2. I select both of them using `ctrl + d` and start typing `Customuserservice`  **(Notice the small letter u and s in the name).**
After that I `ctrl + .` it for suggestions and when I accept the suggestion it will update the spelling of the first occurrence only and will leave the subsequent occurrences just like that.
"
microsoft/vscode,2023-07-17 14:14:14,feature,The dismissed search results appear after search term changes even a letter,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

When I use multi-file search (by Ctrl+Shift+F), I may use the dismiss button. But after adding another letter to the term, the dismissed item shows up again.
![VS-Code-Search-Dismiss-Functionality](https://github.com/microsoft/vscode/assets/39086573/3595a575-5874-4708-85e0-062400b7c08b)
I started not using this functionality (the dismiss button) any more, because it shows up right after a new letter.

Proposed solution:
- Can you please add the dismissed items to ""files to exclude"" part after clicking on dismiss button
- Or the dismissed items can stay dismissed until whole word gets deleted or changes (This may require another button to stop dismissing)

"
microsoft/vscode,2023-07-17 12:23:02,feature,Diff editor shows funny word alignments,"* compare the two versions of the file
* the word alignment is confusing


<img width=""1101"" alt=""Screenshot 2023-07-17 at 14 19 08"" src=""https://github.com/microsoft/vscode/assets/1794099/06d073d6-ee63-4d4f-abde-3a13cc5402fa"">

[Monaco Editor Repro](https://microsoft.github.io/monaco-editor/playground.html?source=v0.41.0-dev.20230714#XQAAAALbIwAAAAAAAABBqQkHQ5NjdMjwa-jY7SIQ9S7DNlzs5W-mwj0fe1ZCDRFc9ws9XQE0SJE1jc2VKxhaLFIw9vEWSxW3yscyF9EyRcr8RpNwTtQoWnafH-c5BRtefkDu604ZM4ROe9e-YnVdisV7TPVzqs8Q_u7S_fIq8UwCYtItkxtCmCxKIXwk50DDww8Q47mLU6GPdDeGYPiQWq18IKTqIGbTCrKUfS1xwrdV70F9TYvGh1jySRMnzkuPqd0t2Qs7oiwNTT_8lKMAU41WjKvIiR8DIws8r8Tyj9hgLZbm0ywu7h6m4dqcGtqAtERzVn3BUy39DH_XhEC5-6vynVP3VoVEm6tmURqOcAiP0-kZh_ADEq8rwmcb3hdPUGjeCfRQxS8wxQa-WR0mwTy2H8Jzo19vU9Z9CXf8viUWsoQzU6vn-0bnPskvkHtmiDYTwWWJa-9o1WztScg1_RPPSYaDkCDGLpAHZnpDKc3kUYkmRbghwbMYYrGN4yDPk7eNU_CiDU9CNpqDTzBaQXn62oVQVSHcJ_BKWdkNir2hLQ5w2q02iLXOhHq7FOUFrf_eq1gCJDuzjyw2cgU-Ibk4DcLpwjv0RlLET-b011FphyF4a7xpGPfzL0S8Dgg2fMNOXDZ_toeioY2jy0Rmhmmq8l_gXREcBgSK8E8QqjWTNX8E2e-uQxyr5JcNkp3vYo1XpEvKya1RDSV6TxmU9ZSzOhzELurkn7zm935O96-3QDzZP5N6hHLH7qLo1HmbFkthmXCwKxXKlAunfZjEs1tN9ZLw0FWa0MFhD16ehqOnpSA-0kt5aFk9Q0ylZQ-OpXBdLa62vlrkj0XmYQjkFHw_FTU3kkMsHI0CYR91Z1OXn6UOjT_4VSbHPsuhQ-Q7YP4EseifR7802lkuzV8JpWB1yBkbSpGDrXKQxpfa6SLxatV3ZE3Wp5cdPYFnaeWnb8ktWL79fbLGsA3Gzj0WoJl2bEueDC6c8Xk5qf3wdAguk1cov7Eq4GqOU1V2NEBxasHVSdwasMAyIStkrvIgZXumnOMH1vDaoN1Iw4AZoXq_f2FkKVY8AXBmeoWVDow6Aq_k3KjDXfGdAUI6IwpDEXSNTb3DORi4RP1GehsSeIokNXDbBwm8d5DyLjfDMRabM42JChkxaWopVCukZImitqej25GP9CHQtFaYKAq7lsRQyhtFlJSOTNMwFV_UynBh2i-ZoagHHqsRCAyhEy5TY8Hv7haBLsXnDmVTpA_H0IyjwakyjxSrRMeD6E_vVJuGHiAMe0s5nrRrkYEBjNzTIdk1mE-p6sT30wctxTKs2QjIf1Kd8YigWHxJLdMKhX1Cor69m5MCJLxzKjWZwpaZF09rLFBZKIgck6S3G94y3MXJfX_Qe04OEHmHLQbZE2fH_HvPiApxzEUNtj-DaYsSxzMGrdcet2BHT4bFoE3_ESnIvKuOf1kWnLh6A0pJLyvdcBqFv3HY4xb-JmhqJ0sFFTCeezvC_V-Ja76_kbFpILptAN2cazyekFEHgKoqR0vI4g5qzuX-kOzZ6bq8FQhW0AgdxTRwBc2j3tPXNkuydfNs794aSdU-sOR3FwbevbCbUA4HQDcixNPkcOoHhoaz34Itma5aB45vIj0JadkyOqCDVBHCKYYRTAj1Nd2IYRlHErT61Nx71Q_RFqU72V4DFD57VtbvckZJePTZ54RbT0OK91gEajUR-_RC5j4ODMEyAR69Nca24_zeaYogLUCURJCjT84DXJTZvSzycxONtUr4vuIYb8sViaZwfH76yAeTShwIFnQMmPcXNCBU84mHN909-OTbdFdYZwg81MMs2KJIeX6AdKH1OXd-s-CtI26D7D10dZUhVKbjGr_0LgU0G-a5HkTEYodR96e2RsUXOrfNtmE4kQEP0SLODQpzkptiYzS1vxwCZO4Eerx9wqXXyV3AHSbaVqz438dASSqt1t-KArgObeOrp0S0932ZNJx38qI_WYAHwUXtmTX_dCTFOzoYdXpw1pF_6_lIK6NrQwQ8nMun3T6z-i5DNsrUycESTRDzoffe6TAe4LNhvdHojNrDvPI2Z7xloEk-WXGIVddniaVGTAFmBmOljEzHPewD38A6GM8UAH-YnxdZz8DfchgDf-9rxntqJH0VN4VraROR76SUh7mN6qt_ZbSqRbHTWTlpf5DpBIHYsu4Lz9uslmLfxvk5QlfaCglACeDIopFU_GfWuwlh58RlDPYU2awNpCfFiz1pADoqX-vH-ompwVmM00G07zyyCUBjfJIRlAZ24BGWWjveiiPlHQJfC_Vt4du9IHkF2_WrQsXK8tgo-6CuYTjNy2ugaIqCtwDhjAlhUJa2Qmz3AbL1IOcsyUrWs9PcD62XlqQSZNtrgh7v4YlDEh_3GiU2GUDbHyc-zxWl62pa8foK8XEoRm2R_Tnf1vpPJkvihP4awiwZ4ECjIgrplCVfgGH3-EzGLfjg-ylLZwgEWWBCeB9V6MZB9Z1wiESFNqG6mSRg-ZikDO5YtEtLo_hZNSnjZC5N-kNgdQtmvHRvDQzApx2Ay3f_fSizfA)"
microsoft/vscode,2023-07-16 06:15:30,feature,Firefox: Support opening local files and folders,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

As stated in [the docs](https://code.visualstudio.com/docs/remote/codespaces#_how-do-i-allow-vs-code-in-a-browser-to-access-local-files-and-folders), opening local folders in vscode.dev requires the File System Access API support of the browser. According to [File System Access API - browser compatibility](https://developer.mozilla.org/en-US/docs/Web/API/File_System_Access_API#browser_compatibility), as of 2023/03/14 Firefox 111+ added support for the File System Access API. So, could the support for Firefox be added?"
microsoft/vscode,2023-07-14 15:58:45,feature,Allow trusting the session instead of the folder,"              There needs to be a way to trust ""just once"" for the current open editor. I don't want to have to maintain a list of trusted folders.

_Originally posted by @teohhanhui in https://github.com/microsoft/vscode/issues/106488#issuecomment-1504827035_
            "
microsoft/vscode,2023-07-14 03:17:24,feature,Selectable Soft Dependencies,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Able to select what dependencies should not install while installing an extension."
microsoft/vscode,2023-07-13 14:00:04,feature,Diff Editor: Show Progress Indicator,"https://github.com/microsoft/vscode/blob/d40162dd41d14dfc23b3026edc0ff4b9a8eaeeb2/src/vs/editor/browser/widget/diffEditorWidget.ts#L433-L440

To verify:
* Open the diff editor and notice that a progress indicator appears when diffing big files (appears after 1s of waiting):

![Code_-_OSS_JxDqVGxkIK](https://github.com/microsoft/vscode/assets/2931520/d59154a1-5587-4b07-849b-570a0e9683ed)
"
microsoft/vscode,2023-07-12 17:06:52,feature,Fallback to release version if the pack/dependency extension does not have compatible pre-release,Fallback to release version if the pack/dependency extension does not have compatible pre-release
microsoft/vscode,2023-07-12 00:08:34,feature,"Parent Function Identifier on ""Go To References"" Window","<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

In the image below I have functions 1 and 2, they are found inside different functions P1 and P2 – ""parent functions"".

I'd like to see the proper parent function name on the top bar at the end of the file path and before ""References (5)"" when I have a reference focused.

![image](https://github.com/microsoft/vscode/assets/54267712/6fe1be62-8fae-42df-bdac-2d817be8d6ce)

"
microsoft/vscode,2023-07-11 22:58:11,feature,Surface dev tunnel usage limits more clearly,"- Check dev tunnel limits asynchronously when we try to connect to a tunnel, and show a modal notification if they're exceeded
- Have a ""Show Usage Limits"" command for users to monitor their limits
- Link to documentation both places with more information"
microsoft/vscode,2023-07-11 08:56:04,feature,Image preview on hover ,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

It would be awesome to have (optional) image previews for e.g. .jpeg and .png images when hovering over these files in the Explorer or the Quick Open promt. 

This would allow to find images faster not just by their name but also visually.

"
microsoft/vscode,2023-07-10 17:00:48,feature,When chosen to install pre-release install the latest release version if there is no compatible pre-release version available,"1. Install VS Code 1.80
2. Install Copilot Chat pre-release
3. Get this error message
    
<img width=""460"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/30305945/fc1160c8-5faf-4a18-b08b-30945cf6bf4e"">

4. Install Copilot Chat stable
5. Try to switch to pre-release
6. :bug: extension description view optimistically switches to pre-release view, but I am still on stable
<img width=""857"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/30305945/2f07c1d2-7186-460f-8ccb-54ba3d4b0a2c"">
"
microsoft/vscode,2023-07-10 15:27:58,feature,Add an explicit toggle for terminal bracketed paste mode support,The sub-shell experience can have problems without a toggle.
microsoft/vscode,2023-07-10 13:58:01,feature,"CTRL+P on selected text must fill search input ""Search file by name..."", such as happens in CTRL+F","<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

I'm working on a legacy huge project that has many files references inside other files, and It's not able to be clickable to navigate in because It's using a different aproach to import files, so to navigate inside the referenced file, I have to copy the file name and then press CTRL+P to open Search Input, then I paste the copied file name. It's good for small changes, but when I'm doing big changes It's can be a few exhausting.

The suggested behavior is like happens with CTRL+F:
Select the file name (any text), then press CTRL+P and the search input must be fullfilled with the selected text with the search's results already selected the first match, to hit enter and navigate into the selected file....

<!-- Describe the feature you'd like. -->"
microsoft/vscode,2023-07-10 09:13:36,feature,Moved code polishing,"```[tasklist]
### Tasks
- [ ] #185498
- [ ] https://github.com/microsoft/vscode/issues/189540
- [ ] #191255
```

Moved out:
- [ ] #185957
- [ ] #186337"
microsoft/vscode,2023-07-10 08:11:51,feature,[Feature] auto unfold code when navigate symbols,"![image](https://github.com/microsoft/vscode/assets/41773861/6d4a616d-caf9-41a6-8e7c-8203e65e47ec)
"
microsoft/vscode,2023-07-08 15:08:43,feature,Improve Run and Debug,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

Hi, I wonder whether it would be possible to improve output in Run And Debug pane and make it more dev-friendly?
(I could not find any similar issue/feature request on this, though I might have missed.)

Shortly background of the feature request - I come from another PHP IDE - PHPEd by NuSphere, which uses own PHP debugger client & server module (not XDebug). The debugging output is much more developer-friendly than in VSCode. I am not using PHPEd anymore on new projects because it has memory issues and no development or new features last few years. VSCode works much better, but debugging experience cannot really compare to PHPEd's. I could not find any extension that would make debugging output more friendly. So here is what I would love to have VSCode improved in pane ""Run And Debug"" (note: this strictly applies to PHP/XDebug, since I do not have experience with other languages):

* possibility to move ""RUN and Debug"" into bottom of screen to allow wider layout
* possibility to have separate TABS for Locals (variables) - Globals - Immediate evaluation - Call stack
* formatting variables into a table with 3 columns (name - value - type) - see screen bellow
* less cluttered output, better readable/legible - e.g. change font size, less padding, increase/decrease line height
* possibility to sort variables by name (e.g. modes: NOT_SORTED, ASC, DESC)
* highlight changed values between 2 breakpoints (or against previous debug step)

If there already exists such an extension, please provide link. 
If not, how difficult would it be to implement features above - how much time would it take?
I would be willing to pay for it, if someone could provide costs estimate.

Screenshot VSCode debug output vs. PHPEd output:

https://i.ibb.co/N3crZdt/screen-php-friendly-debug-output2.png

<img src='https://i.ibb.co/N3crZdt/screen-php-friendly-debug-output2.png'/>


https://i.ibb.co/X4xrnn1/screen-debug-improvement-VSCode-fix.png

<img src='https://i.ibb.co/X4xrnn1/screen-debug-improvement-VSCode-fix.png'/>


"
microsoft/vscode,2023-07-06 20:44:23,feature,"Replace preview: add ""jump to this line"" feature","<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

I'm in the middle of global find-and-replace with 1,000 changes to make. But I want to manually edit one of the lines that is about to get changed.

In this instance I am trying to review all usage of Title Case and switch to sentence case.

In the REPLACE PREVIEW window, it would be nice if I can right click and ""jump to this line"". This would open the original file at that line so that I could edit that line however I want.

<img width=""1289"" alt=""Screenshot 2023-07-06 at 16 40 48"" src=""https://github.com/microsoft/vscode/assets/382183/c1d0b0d6-8a2e-4ff1-a948-470c4bbab59c"">"
microsoft/vscode,2023-07-06 18:48:05,feature,Suggestion window styling/snippet styling,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Can we get suggestion styling. The suggestion windows on the right where is the description. I am new to the github sorry for messing up. If this feature already exists could you give me a link or examples.
![image](https://github.com/microsoft/vscode/assets/86359152/aaa3144b-450d-434d-9a05-da41e47d4996)
here you type the code and the suggestion pops up and when you open description

I saw some styling for the suggestion box but not for the description box.
Would be nice to be able to change text color, size, font weight. Very general formatting when writing snippets."
microsoft/vscode,2023-07-06 15:09:13,feature,"Information on updates prior to using ""Restart to Update""","<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

It would be great if users could know what changes an update will apply to VSCode before we choose ""Restart to Update"". A link to a ""What's New"" or some log would probably suffice.

<img width=""313"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/10928388/d14a435c-bf92-42cd-8ec4-5f7670f3ace0"">
"
microsoft/vscode,2023-07-06 10:15:12,feature,Allow search to be sorted by shortest match.,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

When using a regex search in a project, it's often likely that the shortest match is the one closest to what you need. It would be nice if there was some way to make this a search option in the Ctrl+Shift+F menu."
microsoft/vscode,2023-07-04 21:51:30,feature,"Pull new CSS grammar for colors, lengths, etc.","This issue will describe the changes pulled in by PRs on `vscode-css` (https://github.com/microsoft/vscode-css/pull/4, https://github.com/microsoft/vscode-css/pull/5, https://github.com/microsoft/vscode-css/pull/6, https://github.com/microsoft/vscode-css/pull/12). This updates highlighting for colors (gradients and `color-mix` function), length units, math functions, and adding the `text-decoration-thickness` property.

To verify that this is working, paste this string into a css file. 
```css
body {
    background-image: 
      linear-gradient(
        to right in oklch longer hue, 
        red 0% 100%
      )
    ;
  }

h1 {
    font-size: 10vb;
    text-decoration-line: underline;
    text-decoration-thickness: 30px;
}

.shape {
    width: calc(10px * pow(5, 2));
    height: 100px;
    background-color:#fff;
}
```

If you're using the default dark theme, then it should look like this. 
<img width=""236"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/31675041/803e2d51-7f36-4536-8b65-6526766b0f46"">

In particular make sure that that:
- `hue` is the same color as `longer` and `oklch`. 
- `10vb` is all one color, like how you would see `10px`.
- `text-decoration-thickness` is the same color as the other properties
- `pow()` is formatted as a css function like `calc()` is
"
microsoft/vscode,2023-07-03 20:48:26,feature,Developer Tools Settings Sync,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

![image](https://github.com/microsoft/vscode/assets/42837531/44886b6c-82d9-41b1-85c3-d67f42f700ef)

The button doesn't do anything. Why not integrate it into VSCode's existing settings sync? I do have a lot of preferences set there, so it'd be helpful since I frequently have to diagnose lots of extensions in the same way across machines."
microsoft/vscode,2023-07-03 00:37:13,feature,Add command to manually trigger Proxy Login dialog,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
## The Problem
My company has a proxy password that changes daily. Because vscode caches the proxy password, if vscode is left open past midnight it loses the ability to access the internet.

This causes a variety of issues, including inability to install extensions, ""XHR failed"" errors, etc.

The current workaround is to quit and reopen vscode, but this is a sledgehammer where a scalpel would suffice... 

## Proposed Solution
I would like to propose the addition of a command to the command palette that manually triggers the [Proxy Login dialog (ProxyAuthHandler() vscode:openProxyAuthenticationDialog)](https://github.com/microsoft/vscode/blob/main/src/vs/code/electron-main/auth.ts#L197)."
microsoft/vscode,2023-06-30 18:55:56,feature,Allow better extension of the search UI,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
I was trying to build out some features to extend the search results UI since it is a very natural place for the work I was doing.
In general there were two limitations I encountered 1 that has been flagged and delayed and 1 that has not.

1. Context menu actions or additional action buttons like `replace` are not able to be added.
Being able to add context menu actions to search can enable workflows that are more context specific to that result but possibly more intelligent. For instance being able to right click a result and look at the quick actions for that result inline.

What if we wanted to add an option for each result to process it in some way, say convert it to a functional component from a class component? If we could have a way to specify `when` a result matches some criteria show this additional action it would be awesome. Enabling the context menu would also achieve this.

2. Replacements are 1:1 with find, it would be very powerful if you could instead suggest a custom replacement for each found result in the API.

When triggering the command `workbench.action.findInFiles` you are allowed to pass a `replace` value. This value has all the power of the UI's `replace` field but is pretty limiting when trying to build a stronger tool here. It would be awesome if you could provide one of the following as well

## Pass a replacement function
```tsx
replace: string | async (current: string) => string
```
This function could be executed when rendering the UI for the replacement and would allow a custom replacement to be computed from the original. This means you could have all the power of javascript to compute these replacements instead of being limited to only regex style computations.

You could load the file into an AST and make a decision for instance?


## Allow re-use of the existing search UI
If you allowed instead for the extension to just provide a list of results it would keep a similar UI experience but provide
similar power.
```tsx
		vscode.commands.executeCommand('workbench.action.showInFindAndReplace', {
		    query: { type: 'custom', representation: ""AST Query"" },
		    results: [{
		       match: { file: './file.ts', line: 24, start: 0, end: 1 },
		       replacement: ""foo""
		    }],
		    triggerSearch: true,
		    preserveCase: true,
		    useExcludeSettingsAndIgnoreFiles: true,
		    isRegex: true,
		    isCaseSensitive: false,
		    matchWholeWord: false,
		    filesToInclude: ""./**/*.ts,./**/*.tsx"",
		  })
```

This could be made even more powerful if you actually let extension developers leverage the search functionality in the extension as well. Something like

```tsx
		vscode.commands.executeCommand('workbench.action.findInFiles', (matches: Match[]) => ({
		    query: { type: 'custom', representation: ""AST Query"" },
		    results: matches.map(v => computeReplacement(match)),
		    triggerSearch: true,
		    preserveCase: true,
		    useExcludeSettingsAndIgnoreFiles: true,
		    isRegex: true,
		    isCaseSensitive: false,
		    matchWholeWord: false,
		    filesToInclude: ""./**/*.ts,./**/*.tsx"",
		  }))
```"
microsoft/vscode,2023-06-30 08:08:19,feature,CustomBuiltinExtensions FromLocations will not automatically load the correct `package.nls.{locale}.json`,"https://github.com/microsoft/vscode/blob/7406a9bdfca18f82a3977ba5eac908d41df7ccac/src/vs/workbench/services/extensionManagement/browser/webExtensionsScannerService.ts#L490C7-L490C7

The code here, when loading the extension through `additionalBuiltinExtensions`, does not pass `packageNLSUris` parameters, is it because it cannot read all nls-related file lists for matching?
"
microsoft/vscode,2023-06-29 21:31:42,feature,add accessible view provider for inline chat response,"cc @jooyoungseo

Panel chat responses can be read char by char, line by line via `alt+f2`. We should do the same for the inline chat response."
microsoft/vscode,2023-06-29 19:06:26,feature,"Worst usability in ""Preventing dirty writes"". Please fix it ()","Hello

I hope you rate it right away that if the usability is terrible that this is a product defect because it makes the product no longer reasonably useful.

<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.79.2 (system setup)
- OS Version: Windows_NT x64 10.0.19045

Steps to Reproduce:

1. Create a situation, in which VS Code offers the annoying [Preventing dirty writes](https://code.visualstudio.com/docs/getstarted/tips-and-tricks#_preventing-dirty-writes) mode
2. Select yes, so that VS Code allows you to merge changes

Now the problems start for probably more than 99% of the users:

1. **It is terribly difficult to see what content is displayed in the left and right windows.** 
    This is the most important use case for any merge process: users can see at a glance (without having to scan the screen) which data he can see. But VS Code displays this information in small printed text.
    Because it's not obvious which data is on the left / right side, it happens again and again that users merge the wrong way around and they ask _""where is the backup??""_.
3. This is a shame: **basic merge commands are missing**. 
    Of course, one often uses the command to merge *all* changes to the left or to the right. But because VS Code allows to navigate between the individual changes, it also means that sometimes customers want to merge individual changes in one direction. But those commands are missing or somewhere hidden!
5. **If something fails: where is the backup?** 
     It can happen that someone synchronizes the data in the wrong direction due to a mistake. Therefore, it should be configurable and enabled by default that a backup is created automatically or that the merge process asks whether a backup should be created.
6. **Please allow us to disable this new ""feature"" Preventing dirty writes**
    In the end, in the last decade, I've never once had the problem of a 'dirty write' and when I ask our many dozens of engineers, they felt the same way: VS code solves a problem that pretty much only occurs in very rare / special situations. 
    But VS Code now forces users to merge data every now and then, even though it was never necessary before.
    Please allow to re-enable the old mode, where everything worked perfectly.


Thanks a lot, kind regards,
Thomas
"
microsoft/vscode,2023-06-29 15:57:14,feature,Toggle Inline Diff not discoverable in inline chat,"Followup to https://github.com/microsoft/vscode/issues/185040#issuecomment-1612399427

I spent quite some time messing with the inline chat preview mode setting to get the diff to appear, without success. It didn't occur to me to look in the Discard dropdown for the Toggle Inline Diff action, since I don't associate diffing with discarding. Have we considered surfacing this another way, maybe as a separate icon or through a keybinding with some helper text below the result?"
microsoft/vscode,2023-06-29 01:54:29,feature,Add Context Key for when cursor is at end of line in cell,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Having the same issue as [this post](https://stackoverflow.com/questions/69006054/how-to-make-down-arrow-on-vscode-to-go-to-end-of-line-in-jupyter-notebooks/76577602), I decided to try to create my own keybindings within Jupyter vscode in order to replicate the behavior of the old Jupyter interface, regarding the effect of `downarrow`:
1. When the cursor is not at the bottom of a cell, move the cursor down
2. When the cursor is at the bottom of a cell, but not at the end of the line, move cursor to the end of the line
3. When the cursor is at the bottom of a cell and at the end of the line, move to the next cell

In order to do this, however, I need to use a ""when clause context"" to detect when the cursor is at the end of a line. I can't seem to find such a context key. (There is, however, `notebookCursorEditorAtBoundary == 'bottom'`, which I believe detects if the cursor is at the bottom of a cell.)
"
microsoft/vscode,2023-06-28 09:32:13,feature,Feature Request: Show Code Variations,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

In this type of feature if I select a block of code, it will display different and optimized variation to execute a particular block of code.

for example:
Basic JavaScript Code For Mapping
```javascript
const inputArray = [1, 2, 3, 4, 5];
const outputArray = [];

for (let i = 0; i < inputArray.length; i++) {
  const mappedValue = inputArray[i] * 2;
  outputArray.push(mappedValue);
}

console.log(outputArray);
```

Optimized JavaScript Code Variation
```javascript
const inputArray = [1, 2, 3, 4, 5];
const outputArray = inputArray.map((value) => value * 2);
console.log(outputArray);
```

"
microsoft/vscode,2023-06-28 00:00:00,feature,Extend serverReadyAction to support startDebugging with provided DebugConfiguration ,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
`serverReadyAction` only seems to support [`name`](https://github.com/microsoft/vscode/blob/0f8598bf4664686876f64731b08b3ecdefcf69d8/extensions/debug-server-ready/package.json#L150-L154) for starting a new browser debug session. 

This feature request is to extend it to support a new entry called `config` that will be used for the `vscode.debug.startDebugging` call.

E.g.
```jsonc
""name"": {
   ""type"": ""object"",
   ""markdownDescription"": ""%debug.server.ready.config.description%"",
   ""default"": {
      ""name"": ""Launch Browser"",
      ""type"": ""edge"",
      ""request"": ""launch""
   },
   ""properties"": {
       /* vscode.DebugConfiguration */
   }
}, 
```"
microsoft/vscode,2023-06-27 18:35:47,feature,"Difference Review, Improve Voice Over","Testing #186213

Maybe this is related to https://github.com/microsoft/vscode/issues/186402, but as I tried it I got different results from that mode but it never seemed to read what I expected

I enable screenreader mode and voiceover, and every time I press F7, this is what it reads. I don't really know what the first part is telling me, and also it says ""7 lines changed"" but this was a file with 2 change chunks, each with just one changed line, so no idea where it is getting 7.

<img width=""662"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/323878/fd680884-95e3-409c-9228-2b1486b7cea5"">
"
microsoft/vscode,2023-06-27 18:10:49,feature,"""Collapse unchanged regions"" looks disabled","Testing #186213

<img width=""273"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/323878/0334000a-1820-4edb-9a88-435d39a95562"">

Should use a toggle state instead, or a new icon. You can see it looks the same as the other disabled action"
microsoft/vscode,2023-06-27 10:04:10,feature,Add Accessibility View and Accessibility Help Menu for Copilot Inline Suggestions,"Testing #186214

If you already have an issue for future plans feel free to close this one.
I think the Copilot Inline (Ghost Text) Suggestions could also profit from the Accessibility View. Currently users are depending on the Copilot View on the side which might get deprecated in the future. And I think we need a native solution for this, so IntelliCode also profits.
I am not sure how exactly to integrate this with the Inline Suggestion Hover.

A potential start would be. Whenever there is an Inline Suggestion, we play an audio cue (as we do today), and a user can open Accessibility View to inspect the exact suggestion.

fyi @hediet
"
microsoft/vscode,2023-06-26 20:34:48,feature,Inform SR users about `Open Accessible View`,Maybe as an aria hint for hovers and in the chat accessibility help menu
microsoft/vscode,2023-06-26 15:12:14,feature,Support trailing colon in --goto,"It'd be useful if `code --goto file:1:2:` works with a trailing comma.

This'd be useful because many tools add a comma after file[:line[:col]]. For example:

Clang:

```
src/main.rs:1:1: error: unknown type name 'fn'
```

Gcc:

```
src/main.rs:1:1: error: unknown type name ‘fn’
```

Ld:

```
ld:src/main.rs: file format not recognized; treating as linker script
```

Bash:

```
src/main.rs: line 1: syntax error near unexpected token `('
```

Awk:

```
awk: src/main.rs:1: (FILENAME=- FNR=1) fatal: function `main' not defined
```

Make:

```
src/main.rs:1: *** missing separator.  Stop.
```

And so on."
microsoft/vscode,2023-06-25 02:47:44,feature,add compare feature on tab menu,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
can add compare feature on tab menu?
![image](https://github.com/microsoft/vscode/assets/5095500/4ffe438f-09a0-4a94-9334-c90f2750eef2)
![image](https://github.com/microsoft/vscode/assets/5095500/a7cfb947-c721-4309-a5c4-039784adbdf9)
![image](https://github.com/microsoft/vscode/assets/5095500/1192b898-a152-417a-b9a5-9edf8e202380)

"
microsoft/vscode,2023-06-23 19:27:19,feature,Filetype specific autosave,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
In my project, I have a mixture of javascript and python files. The javascript files are connected to an auto-reloading React app, thus I would like to retain autosave on them. The python files control a running server (also auto-reload). However, making a change to the python file takes longer, so I would like to control the saving of those more directly. Is it possible to have `files.autoSave` be settable on a filetype granularity?"
microsoft/vscode,2023-06-22 11:02:14,feature,Allow to disable editor group maximize on double click,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

Occasionally a mouse click turns into a double click (which is hard to avoid), but I don't want to maximize the editing group and have to get it back every time I accidentally maximize it.

I can't find the relevant settings in the Settings, I hope this feature can be turned off, thank you very much!"
microsoft/vscode,2023-06-21 13:36:49,feature,Tab sizing option fixed,"Type: <b>Feature Request</b>

I am very happy that you introduced this feature, for quickly closing many tabs:
`workbench.editor.tabSizingFixedMaxWidth`

However, with fixed width, the tabs become so small that it is hard to distinguish files with the same first 3 or 4 characters. Can you also add a minimum width setting? `workbench.editor.tabSizingFixedMinWidth`

This would allow each developer to set a minimum width based on their file naming convention (e.g. if they have many files starting with the first 6 characters, they can set the minimum to see at least 8 or 9 characters).

Thank you.

VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.19045
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-06-21 02:53:46,feature,[FR] Search editor syntax highlighting based on extensions,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Currently, the search editor uses a fixed list to do syntax highlighting, which cannot be dynamically changed based on which extensions are installed. It would be nice to support that.

Ref: https://github.com/microsoft/vscode/issues/185430#issuecomment-1599437522"
microsoft/vscode,2023-06-20 18:48:35,feature,Keyboard shortcut to move tabs left and right,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

I'm a very visual person, and I work better when I drag similar tabs together. I can do that using the cursor, but I'd love to be able to do that using the keyboard.

Ideally, there would be keyboard shortcuts to move a tab:
 - to the left
 - to the right
 - to the further left side
 - to the further right side

Basically, I'd love to be able to do in VSCode what I can do in Chrome using [this extension](https://chrome.google.com/webstore/detail/rearrange-tabs/ccnnhhnmpoffieppjjkhdakcoejcpbga)."
microsoft/vscode,2023-06-20 15:00:27,feature,Move off of Keytar,"With [node-keytar](https://github.com/atom/node-keytar) now archived and unmaintained, we need a path forward for securely storing secrets and additionally, reflect the fact that we do not need to follow the shape of keytar anymore.

On Desktop, we will take advantage of Electron's [safeStorage](https://www.electronjs.org/docs/latest/api/safe-storage) API. We will also get rid of `vscode-encrypt` because it would be providing no benefit in this new world.

Additionally, we will remove the KeytarShim that has been in the product. This was the solution to secrets before the [SecretStorage API](https://code.visualstudio.com/api/references/vscode-api#SecretStorage).

Outlined are the steps to get this done:
```[tasklist]
### Tasks
- [x] Implement new `EncryptionService` & `SecretStorageService` services with a migration story. Use new services for extension SecretStorage API
- [ ] https://github.com/microsoft/vscode/issues/186241
- [x] Write new docs for troubleshooting keyring issues & update remote docs
- [x] Notify top X extensions of KeytarShim that we will remove it
- [x] Make discussion post: https://github.com/microsoft/vscode-discussions/discussions/662
- [ ] https://github.com/microsoft/vscode/issues/115215
```
"
microsoft/vscode,2023-09-29 02:43:22,question,Started VS-Code,"Type: <b>Bug</b>

Arch Linux. Trying to get VS-Code to find yarn berry packages for intellisense

VS Code version: Code - OSS 1.82.0 (8b617bd08fd9e3fc94d14adb8d358b56e3f72314, 2023-09-11T16:30:45.959Z)
OS version: Linux x64 6.5.3-arch1-1
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-5350U CPU @ 1.80GHz (4 x 2700)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: disabled_software<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: disabled_off|
|Load (avg)|5, 4, 3|
|Memory (System)|7.66GB (3.61GB free)|
|Process Argv|--unity-launch|
|Screen Reader|no|
|VM|0%|
|DESKTOP_SESSION|plasma|
|XDG_CURRENT_DESKTOP|KDE|
|XDG_SESSION_DESKTOP|KDE|
|XDG_SESSION_TYPE|x11|
</details><details><summary>Extensions (9)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-zipfs|arc|2.4.0-rc.5
better-toml|bun|0.3.2
EditorConfig|Edi|0.16.6
vscode-npm-script|eg2|0.3.11
python|ms-|2023.16.0
vscode-twoslash-queries|Ort|1.2.2
rome|rom|0.28.0
rust-analyzer|rus|0.3.1665
volar|Vue|1.8.15

(2 theme extensions excluded)

</details>
<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-28 17:57:02,question,Error: EBUSY: resource busy or locked,"Filed to save “html file” :unable to write file ‘disk\\folder\\htmlfile’ (unknown(FileSystemError):Error:EBUSY:resource busy or locked, open ‘disk;\\folder\\htmlfile’)



suddenly this error occured when i make change in the code and save'


"
microsoft/vscode,2023-09-28 09:27:07,question,running a selection of code is not working while it runs when the program is executed,"Type: <b>Performance Issue</b>

I am using python IDE When i run some part of my code, i get errors like nameerrors, syntaxerrors, but when the program is run as a whole, the code executes as it should. How do i fix it? I'd like to keep running portions of the program without necessarily executing the whole program.
Section of code:

a= int(input(""Enter number a: ""))
b= int(input(""Enter number b: ""))
sum= 0
if a> b:
    a,b= b,a
start= a
while start<= b:
    sum+= start
    start+=1
print(f""The sum between {a} and {b} is, {sum}"")



VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-6300U CPU @ 2.40GHz (4 x 2496)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.42GB (2.34GB free)|
|Process Argv|--crash-reporter-id 50ce0f66-2b2b-4d87-98c3-dad345dd3f4c|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    0	    96	  5476	code main
    0	    28	  2468	   crashpad-handler
    0	    73	  5008	fileWatcher [1]
    0	    91	  5388	shared-process
    0	   182	  5652	window [1] (● Countup problems.py - Python_exercises - Visual Studio Code)
    0	   160	  6212	   gpu-process
    0	    38	  7908	   utility-network-service
    0	    85	  8420	ptyHost
    0	     7	  1904	     conpty-agent
    0	    68	  4900	     C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe
    0	     7	  6452	     conpty-agent
    0	    69	  7176	     C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	    11	  3184	       ""C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\python.exe""
    0	     7	  7584	     conpty-agent
    0	    69	 10752	     C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	   149	 11400	extensionHost [1]
    0	   157	 13348	     electron-nodejs (""C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node c:\\Users\\LENOVO\\.vscode\\extensions\\ms-python.vscode-pylance-2023.9.20\\dist\\server.bundle.js --cancellationReceive=file:abcf6af201ba576b327857c8d9c8120d3b66f81992 --node-ipc --clientProcessId=11400)
    0	    92	 13844	window [2] (Issue Reporter)
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (● Countup problems.py - Python_exercises - Visual Studio Code)
|    Folder (Python_exercises): 5 files
|      File types: py(3) gitignore(1)
|      Conf files:;
```

</details>
<details><summary>Extensions (3)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-pull-request-github|Git|0.72.0
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.20


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
89544117:30613380
showlangstatbar:30737416
0bi6i642:30841073
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
copilotsettingc:30839828
asynctok:30821568
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30821571
dsvsc015:30845448

```

</details>

<!-- generated by issue reporter -->
```[tasklist]
### Tasks
```
"
microsoft/vscode,2023-09-27 09:52:14,question,Inlay hints do not show when using Workspace TypeScript version,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.82.2
- OS Version: macOS 13.5.2

Steps to Reproduce:

1. Have a `.vscode/settings.json` with 
```json
{
    ""typescript.tsdk"": ""node_modules/typescript/lib"",
}
``` 
2. Command Palette -> 'TypeScript: Select TypeScript Version'. Choose between workspace + default VS code version

When default TS version is selected (5.2.2):
<img width=""289"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/146182459/3e180137-9c48-4546-b507-cfa4bae1bc16"">

When workspace TS is selected (4.0.8):
<img width=""265"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/146182459/904e56bf-8373-4d66-8929-3b547c099194"">

However, TS definitely knows what type it is, since when I hover over, it displays the type correctly:
<img width=""258"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/146182459/5857d8d9-8d95-48ed-aeea-a148ca8b46d3"">
"
microsoft/vscode,2023-09-26 10:48:21,question,Non existent issue with URL mapping,"
![Screenshot 2023-09-26 114624](https://github.com/microsoft/vscode/assets/132494417/bdc3d97e-0fd7-4436-90ee-613c1f347bbd)
![Screenshot 2023-09-26 114642](https://github.com/microsoft/vscode/assets/132494417/b6a2fb83-4e86-4b5b-8417-502c82d9695a)
![Screenshot 2023-09-26 114748](https://github.com/microsoft/vscode/assets/132494417/03a74646-e41d-4847-8364-4a248bb3471e)
Type: <b>Bug</b>

VSC is currently giving me 404 messages when I run the development server. Despite me correctly mapping out the urls to the relavant pages, your piece of shit software of giving me error 404 (webpage not found) messages. End of my teather with your product. Sort it out! 

VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-9400F CPU @ 2.90GHz (6 x 2904)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.95GB (8.06GB free)|
|Process Argv|--crash-reporter-id ae970a20-b9e5-4217-b646-c75742ce9184|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (22)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-intelephense-client|bme|1.9.5
composer-php-vscode|DEV|1.39.13943
phptools-vscode|DEV|1.39.13943
profiler-php-vscode|DEV|1.39.13943
compilemql4|Kei|0.0.1
mql-tools|L-I|2.0.2
file-downloader|min|1.0.12
vscode-html-format|moh|0.1.2
vscode-azureresourcegroups|ms-|0.7.5
vscode-azurestorage|ms-|0.15.3
python|ms-|2023.16.0
azure-account|ms-|0.11.5
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
live-server|ms-|0.4.9
powershell|ms-|2023.6.0
mq4|ner|1.0.4
mql-over-cpp|nic|0.0.3
quick-html-template|Pen|1.0.6
bitmagic|yaz|0.0.15
html-css-class-completion|Zig|1.20.0

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263cf:30792227
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
2e4cg342:30602488
89544117:30613380
2i9eh265:30646982
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
copilotsettingt:30839829
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30845448

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-25 16:34:25,question,Python input() function does not read input (SSH Remote VM),"I'm using VS Code to SSH into a remote VM.
When running python scripts (in the terminal window) that request input .e.g. `query = input(""\\nEnter a query: "")` it does not read the provided input but waits forever."
microsoft/vscode,2023-09-25 05:46:09,question,MSYS2 UCRT64 terminal profile can't integrate under TERMINAL tab,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No
Yes
<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version:  1.82.2
- OS Version: Microsoft Windows 10 家庭中文版

Steps to Reproduce:

1. Installed MSYS2.
2. Adding following in settings.json:
```javascript
        ""terminal.integrated.profiles.windows"": {
        ""UCRT64"": {
          ""path"": ""D:\\\\Program Files\\\\msys64\\\\ucrt64.exe""
        }
  	},
    ""terminal.integrated.defaultProfile.windows"":  ""UCRT64"",
``` 
3.  Click 'UCRT64' in terminal profiles dropdown:

![image](https://github.com/microsoft/vscode/assets/50125911/f01acc3f-0224-4d11-96f8-2014ddc026d0)

4.  The UCRT64 terminal run but not under the TERMINAL tab
    
![image](https://github.com/microsoft/vscode/assets/50125911/ffe340d3-4148-4e58-99a3-e6bef377e5e3)"
microsoft/vscode,2023-09-23 08:03:50,question,"Unable to resolve your shell environment: Unexpected exit code from spawned shell (code 9, signal null)","<img width=""533"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/68364445/38fd80b8-048f-447c-8c21-5ba7ab8318e5"">

I'm facing this issue in viscose on my Mac... I have removed NODE_OPTIONS from the .zshrc file still the error isn't going away... need fix ASAP"
microsoft/vscode,2023-09-22 15:46:04,question,music store database,"Type: <b>Bug</b>

Details about customers,city ,amount and most preferred employee

VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.22621
Modes: Restricted

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 3 3250U with Radeon Graphics          (4 x 2595)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|5.95GB (0.58GB free)|
|Process Argv|C:\\\\Users\\\\sajna\\\\Downloads\\\\music store database analysis project on postgresql --crash-reporter-id 8020f3a6-a5dd-4b63-85d2-d5897bf9dd78|
|Screen Reader|no|
|VM|0%|
</details>Extensions: none<details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
2e4cg342:30602488
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
copilotsettingc:30839828
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015cf:30829746

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-22 07:55:28,question,markdown format problem,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
can you add specific icon to avoid plugin or anything else aiming at formating autoly deleting the space at the end of line?I need double space at the end of line to elegant line break.
Anyhting else,if there's another way to elegant line break gracefully,please tell me
"
microsoft/vscode,2023-09-21 17:07:17,question,breakpoints not working on vscode extension development,"Type: <b>Bug</b>

I'm developing an extension for vscode and breakpoints don't work. I can set them without any problem, but when I launch F5, it just won't stop on them.

I have tried disabling all the extensions and it still happens.

Related to https://github.com/microsoft/vscode/issues/192507.


VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i7-11800H @ 2.30GHz (16 x 2304)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|31.79GB (17.12GB free)|
|Process Argv|--crash-reporter-id ccedd11e-cbe3-4aab-835a-b81d8cc295d7|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (40)</summary>

Extension|Author (truncated)|Version
---|---|---
codesnap|adp|1.3.4
tsl-problem-matcher|amo|0.6.2
ng-template|Ang|16.1.8
cssrem|cip|3.1.1
continue|Con|0.0.394
vscode-eslint|dba|2.4.2
es7-react-js-snippets|dsz|4.4.3
gitlens|eam|14.3.0
prettier-vscode|esb|10.1.0
fetch-client|Gan|1.3.0
todo-tree|Gru|0.0.226
Angular2|joh|16.0.1
vscode-peacock|joh|4.2.2
vscode-colorize|kam|0.11.1
git-graph|mhu|1.30.0
isort|ms-|2023.10.1
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.20
live-server|ms-|0.4.9
vsliveshare|ms-|1.0.5883
vscode-versionlens|pfl|1.7.3
postman-for-vscode|Pos|0.9.0
vscode-thunder-client|ran|2.12.1
fabric8-analytics|red|0.7.0
java|red|1.22.1
vscode-xml|red|0.26.1
vscode-yaml|red|1.14.0
vs-code-prettier-eslint|rve|5.1.0
partial-diff|ryu|1.4.3
errorlens|use|3.13.0
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.14
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
vscode-icons|vsc|12.5.0
JavaScriptSnippets|xab|1.8.0
markdown-all-in-one|yzh|3.5.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
3biah626:30602489
89544117:30613380
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
copilotsettingc:30839828
synctok:30821570
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015cf:30829746

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-20 21:14:16,question,intellisense ,"
Type: <b>Bug</b>

when i press tab to complete the line of code like :
``` const btn = docoment.querySelector("" ```
didn't finish the hole line with brackets 

VS Code version: Code 1.82.0 (8b617bd08fd9e3fc94d14adb8d358b56e3f72314, 2023-09-06T22:07:07.438Z)
OS version: Windows_NT x64 10.0.22621
Modes: Unsupported

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i7-11800H @ 2.30GHz (16 x 2304)|
|GPU Status|2d_canvas: unavailable_software<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: disabled_software<br>multiple_raster_threads: enabled_on<br>opengl: disabled_off<br>rasterization: disabled_software<br>raw_draw: disabled_off_ok<br>video_decode: disabled_software<br>video_encode: disabled_software<br>vulkan: disabled_off<br>webgl: unavailable_software<br>webgl2: unavailable_software<br>webgpu: unavailable_software|
|Load (avg)|undefined|
|Memory (System)|31.71GB (20.31GB free)|
|Process Argv|--crash-reporter-id 20bc9b53-fa17-49c9-9684-dcdebd4c9d7e|
|Screen Reader|no|
|VM|67%|
</details><details><summary>Extensions (130)</summary>

Extension|Author (truncated)|Version
---|---|---
codesnap|adp|1.3.4
vscode-css-formatter|aes|1.0.2
auto-add-brackets|ali|0.12.2
laravel-extra-intellisense|ami|0.6.3
bootstrap5-vscode|Anb|0.4.2
ng-template|Ang|16.1.8
browse-lite|ant|0.3.2
vite|ant|0.2.5
musicplayer|arj|1.0.3
blackbox|Bla|1.1.66
auto-align|bla|0.0.13
vscode-intelephense-client|bme|1.9.5
bracket-pair-color-dlw|Bra|0.0.6
vscode-tailwindcss|bra|0.10.0
exe-runner|bra|0.2.1
phpserver|bra|3.0.2
simple-react-snippets|bur|1.2.7
multi-cursor-case-preserve|Car|1.0.5
turbo-console-log|Cha|2.9.6
npm-intellisense|chr|1.4.4
path-intellisense|chr|2.8.4
codeium|Cod|1.2.88
logical-properties|cod|0.1.11
laravel-goto-view|cod|1.3.9
postcss|css|1.0.9
php-namespace-resolver|ctf|0.5.3
vs-phpclassgen|dam|0.1.1
vscode-jq|dan|1.2.0
dart-code|Dar|3.72.2
flutter|Dar|3.72.0
vscode-eslint|dba|2.4.2
composer-php-vscode|DEV|1.39.13943
phptools-vscode|DEV|1.39.13943
profiler-php-vscode|DEV|1.39.13943
css-minify|Die|0.1.13
chatgpt-code|dog|0.1.3
jquerysnippets|don|0.0.1
es7-react-js-snippets|dsz|4.4.3
chatgpt-gpt4-gpt3-vscode|Eas|1.1.8
vscode-html-css|ecm|1.13.1
vscode-great-icons|emm|2.1.102
prettier-vscode|esb|10.1.0
auto-close-tag|for|0.5.14
auto-complete-tag|for|0.1.0
auto-rename-tag|for|0.1.10
code-runner|for|0.12.0
vscode-mysql|for|0.4.1
cypress-runner|G-F|2.0.0
chatgpt-sql-vscode-plugin|gao|3.2.2
remotehub|Git|0.60.0
php-awesome-snippets|hak|1.1.3
CppSnippets|har|0.0.15
vue-snippets|hol|1.0.4
cypress-snippets|iJS|1.0.0
fontawesome-autocomplete|Jan|1.3.1
css-snippets|joy|1.0.4
code-background|Kat|2.8.0
vsc-python-indent|Kev|1.18.0
pretty-php|lkr|0.4.28
next-js-ts-snippets|loc|2.0.3
json|Mee|0.1.2
php-namespace-resolver|Meh|1.1.9
fluent-icons|mig|0.0.18
vscode-docker|ms-|1.26.1
csharp|ms-|2.1.2
vscode-dotnet-runtime|ms-|1.7.3
isort|ms-|2023.10.1
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.309.0
azure-repos|ms-|0.36.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
live-server|ms-|0.4.9
powershell|ms-|2023.6.0
remote-repositories|ms-|0.38.1
vscode-typescript-next|ms-|5.3.20230919
awesome-flutter-snippets|Nas|4.0.1
vetur|oct|0.37.3
laravel-blade|one|1.34.0
laravel5-snippets|one|1.17.0
convert-css-in-js|pau|1.1.3
phpstorm-snippets|phi|1.1.2
material-icon-theme|PKi|4.30.1
vscode-css-peek|pra|4.4.1
vscode-yaml|red|1.14.0
format-html-in-php|rif|1.7.0
LiveServer|rit|5.7.9
vs-code-prettier-eslint|rve|5.1.0
laravel-artisan|rya|0.0.31
vscode-javascript-booster|sbu|14.0.1
vue-vscode-snippets|sdr|3.1.1
background|sha|1.2.12
vscode-cy-helper|She|1.2.2
vscode-blade-formatter|shu|0.23.1
vscode-scss-formatter|sib|3.0.0
html5-boilerplate|sid|1.1.1
indenticator|Sir|0.7.0
js-jsx-snippets|sky|11.0.1
music-time|sof|2.2.43
react-next-js-code-snippets|soh|0.1.22
html-to-css-autocompletion|sol|1.1.2
css-auto-prefix|spo|0.1.7
autoimport|ste|1.5.4
tabnine-vscode|Tab|3.16.0
vscode-pets|ton|1.25.0
cmake|twx|0.0.17
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
properties-validator|viv|0.0.6
volar|Vue|1.8.13
vscode-typescript-vue-plugin|Vue|1.8.13
quokka-vscode|Wal|1.0.564
wordpress-toolbox|wor|1.3.15
eno|Wsc|2.3.53
qf|Wsc|6.8.122
php-debug|xde|1.33.0
php-pack|xde|1.0.3
reactcssautocomplete|Zac|0.0.4
tailwind-snippets|Zar|1.0.2
material-theme|zhu|3.16.0
html-css-class-completion|Zig|1.20.0
classnametocss|zit|0.0.7
php-intellisense|zob|1.3.3

(10 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vstes627:30244334
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
3biah626:30602489
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
copilotsettingc:30839828
synctok:30821570
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015cf:30829746

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-20 05:31:44,question,Unable to save file,"
Type: <b>Bug</b>

Failed to save 'app.component.html': Insufficient permissions. Select 'Retry as Admin' to retry as administrator.

VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz (4 x 2195)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.92GB (0.71GB free)|
|Process Argv|D:\\\\Angular Projects\\\\proclient --crash-reporter-id 29348f64-479a-4fdb-be59-b118dc28dd1d|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (9)</summary>

Extension|Author (truncated)|Version
---|---|---
ng-template|Ang|16.1.8
npm-intellisense|chr|1.4.4
path-intellisense|chr|2.8.4
prettier-vscode|esb|10.1.0
auto-rename-tag|for|0.1.10
code-runner|for|0.12.0
copilot|Git|1.113.423
LiveServer|rit|5.7.9
html-css-class-completion|Zig|1.20.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
3biah626:30602489
89544117:30613380
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
copilotsettingt:30839829
asynctok:30821568
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-18 09:57:56,question,Code not working correctly for a specific number 3,"Type: <b>Bug</b>

`#include<iostream>
using namespace std;


void frequency(int arr[], int n){
    int count = 1;
    
    for (int i = 0; i < n ; i++) {
        if (arr[i] == arr[i + 1]) {
            count++;
        }
        else{
            cout << arr[i] << "" : "" << count << endl;
            count = 1;
        }
    }
}

int main()
{
    int n=4;
    int arr[n] = {1,2,3,3};
    frequency(arr, n);
    return  0;
}`

Above is the code to print frequency of each element of sorted array, for the test case 

int n=4;
int arr[n]={1,2,3,3};

output:
PS C:\\Users\\Himanshu> cd ""c:\\Users\\Himanshu\\Desktop\\DSA\\cpp_vscode\\"" ; if ($?) { g++ gfg.cpp -o gfg } ; if ($?) { .\\gfg }
1 : 1
2 : 1

the vs code is not giving right output else everywhere it working fine;
and also for the test case

int n=4;
int arr[n]={1,2,4,4};

output:
PS C:\\Users\\Himanshu\\Desktop\\DSA\\cpp_vscode> cd ""c:\\Users\\Himanshu\\Desktop\\DSA\\cpp_vscode\\"" ; if ($?) { g++ gfg.cpp -o gfg } ; if ($?) { .\\gfg }
1 : 1
2 : 1
4 : 2

it is working fine

VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (8 x 2419)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.77GB (0.70GB free)|
|Process Argv|--crash-reporter-id 3be531c0-eff7-462a-89a9-a053520d62c8|
|Screen Reader|no|
|VM|40%|
</details><details><summary>Extensions (16)</summary>

Extension|Author (truncated)|Version
---|---|---
html-end-tag-labels|ant|1.0.0
prettier-vscode|esb|10.1.0
auto-rename-tag|for|0.1.10
code-runner|for|0.12.0
copilot|Git|1.111.404
unibeautify-vscode|Gla|0.8.2
next-js-ts-snippets|loc|2.0.3
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
cpptools|ms-|1.17.5
LiveServer|rit|5.7.9


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263cf:30792227
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
282f8724:30602487
89544117:30613380
2i9eh265:30646982
showlangstatbar:30737416
962ge761:30835153
a2ce3375:30757347
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
asynctok:30821568
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-16 20:22:53,question,react ,"Type: <b>Feature Request</b>

react is not installed

VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:55:25.390Z)
OS version: Windows_NT x64 10.0.19045
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-16 09:42:21,question,"Problem with ""unused variable""","
Type: <b>Bug</b>

Sometimes there is such an error, when reopening it may not happen again.
*idx* declared but not used


VS Code version: Code 1.82.2 (abd2f3db4bdb28f9e95536dfa84d8479f1eb312d, 2023-09-14T05:51:20.981Z)
OS version: Linux x64 5.15.0-83-generic
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-9300H CPU @ 2.40GHz (8 x 2400)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: disabled_software<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: disabled_off|
|Load (avg)|1, 1, 0|
|Memory (System)|7.60GB (4.56GB free)|
|Process Argv|--unity-launch --crash-reporter-id a927cb51-7c20-45d0-b062-ab7a5fc00084|
|Screen Reader|no|
|VM|0%|
|DESKTOP_SESSION|cinnamon|
|XDG_CURRENT_DESKTOP|X-Cinnamon|
|XDG_SESSION_DESKTOP|cinnamon|
|XDG_SESSION_TYPE|x11|
</details><details><summary>Extensions (39)</summary>

Extension|Author (truncated)|Version
---|---|---
common|Clo|0.0.15
github-authentication|Clo|0.0.5
doxdocgen|csc|1.4.0
gdb-debug|Dam|1.0.7
vscode-markdownlint|Dav|0.51.0
vscode-pull-request-github|Git|0.72.0
go|gol|0.39.1
todo-tree|Gru|0.0.226
vscode-drawio|hed|1.6.6
plantuml|jeb|2.17.5
better-cpp-syntax|jef|1.17.2
cmake-language-support-vscode|jos|0.0.9
vscode-docker|ms-|1.26.0
vscode-language-pack-ru|MS-|1.82.2023091309
vscode-dotnet-runtime|ms-|1.7.3
isort|ms-|2023.10.1
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.309.0
remote-ssh|ms-|0.106.4
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.3
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
remote-explorer|ms-|0.4.1
vsliveshare|ms-|1.0.5883
rust-analyzer|rus|0.3.1657
crates|ser|0.6.2
cmake|twx|0.0.17
vscode-lldb|vad|1.10.0
vscode-todo-highlight|way|1.0.5
debug|web|0.26.1
markdown-all-in-one|yzh|3.5.1

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
89544117:30613380
showlangstatbar:30737416
962ge761:30835153
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-14 12:58:19,question,cursor control,"Type: <b>Performance</b>

Cursor speed is very high it scroll the whole page at once  it is very difficult to navigate because the whole page is scroll at once and I'm unable to scroll a single line or double line 

VS Code version: Code 1.82.1 (6509174151d557a81c9d0b5f8a5a1e9274db5585, 2023-09-08T08:45:05.575Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i3-6006U CPU @ 2.00GHz (4 x 1992)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.91GB (2.86GB free)|
|Process Argv|C:\\\\WorkSpace\\\\Test_projects\\\\TourOfHeroes --crash-reporter-id 6616f29d-de03-47a4-95d4-ba60bdab8111|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (7)</summary>

Extension|Author (truncated)|Version
---|---|---
ng-template|Ang|16.1.8
csdevkit|ms-|0.4.10
csharp|ms-|2.2.10
vscode-dotnet-runtime|ms-|1.7.2
vscodeintellicode-csharp|ms-|0.1.26
vs-keybindings|ms-|0.2.1
LiveServer|rit|5.7.9


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes516:30244333
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
3biah626:30602489
89544117:30613380
showlangstatbar:30737416
962ge761:30835153
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30821571
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-13 15:43:55,question,open a file in a new tab,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 
- OS Version: 

Steps to Reproduce:

1. when I double click a file to open it in a new tab, it's not
2. then I go back in navigation history, the elder file replaced by the new one is opened again in a new tab.
I tried to do a quick video with camtasia, and then, recording, the problem disappears. 🤔 
I'm using the fact to open new files in the same project when right-clicking on a file. And not opening a new project (default behavior).  I don't know if it's linked, but just to tell...
"
microsoft/vscode,2023-09-13 11:01:23,question,svg path is not working,"
Type: <b>Bug</b>

whenever i paste svg code in vs code then svg path is not coming an decrypted code coming in vs code while pasting . please help me and resolve my problem as soon as possible.

VS Code version: Code 1.82.1 (6509174151d557a81c9d0b5f8a5a1e9274db5585, 2023-09-08T08:45:05.575Z)
OS version: Windows_NT x64 10.0.22621
Modes: Unsupported

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 5 5500U with Radeon Graphics          (12 x 2096)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.39GB (1.03GB free)|
|Process Argv|C:\\\\Users\\\\ASUS\\\\Desktop\\\\Snkr plts --crash-reporter-id fd6ca2a9-f709-43bb-8832-12c2822e613a|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (35)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-django|bat|1.11.0
vscode-tailwindcss|bra|0.11.8
java-run|cao|1.1.4
python-environment-manager|don|1.2.2
python-extension-pack|don|1.7.0
vscode-html-css|ecm|1.13.1
gitpod-desktop|git|0.0.157
beautify|Hoo|1.5.0
vsc-python-indent|Kev|1.18.0
isort|ms-|2023.10.1
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10
jupyter|ms-|2023.8.1002501831
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-ssh|ms-|0.106.4
remote-ssh-edit|ms-|0.86.0
remote-explorer|ms-|0.4.1
autodocstring|njp|0.6.1
java|red|1.22.0
LiveServer|rit|5.7.9
background|sha|1.2.12
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-gradle|vsc|3.12.7
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.14
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
vscode-icons|vsc|12.5.0
jinja|who|0.0.8
html-css-class-completion|Zig|1.20.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
3biah626:30602489
89544117:30613380
vscrpc:30673769
a9j8j154:30646983
showlangstatbar:30737416
0bi6i642:30835152
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
asynctok:30821568
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-12 19:13:54,question,command line --help does not show cli help,"Type: <b>Bug</b>

Hello VS Code crew 🤘
## Found:
The documentation https://code.visualstudio.com/docs/editor/command-line
shows one shall type `code --help` to get help for the command line interface. But this seems broken. What I get is:

```
C:\\Users\\eric\\AppData\\Local\\Programs\\Microsoft VS Code>code --help

C:\\Users\\eric\\AppData\\Local\\Programs\\Microsoft VS Code>
[14780:0912/210820.464:ERROR:cache_util_win.cc(20)] Unable to move the cache: Access is denied. (0x5)
[14780:0912/210820.464:ERROR:disk_cache.cc(205)] Unable to create cache
```
and then a new VS Code window opens.
The short `-h` works just the same way.

## Expected:
* the [CLI options](https://code.visualstudio.com/docs/editor/command-line#_core-cli-options) are printed
* no window opens
* no confusing errors

VS Code version: Code 1.82.1 (6509174151d557a81c9d0b5f8a5a1e9274db5585, 2023-09-08T08:45:05.575Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-1065G7 CPU @ 1.30GHz (8 x 1498)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.74GB (6.50GB free)|
|Process Argv|--crash-reporter-id acdf514f-7def-4641-88b6-fa6e0a8d7631|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (9)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-office|cwe|3.1.6
vscode-autohotkey-plus-plus|mar|5.0.3
perforce|mjc|4.15.7
black-formatter|ms-|2023.4.1
pylint|ms-|2023.7.12211006
python|ms-|2023.17.12551009
vscode-pylance|ms-|2023.9.10
hexeditor|ms-|1.9.12
material-theme|zhu|3.16.0

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
89544117:30613380
showlangstatbar:30737416
962ge761:30835153
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015cf:30829746

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-10 07:28:08,question,modules,"Type: <b>Feature Request</b>

i installed the external module pandas using pip install pandas command in terminal. In problems its showing import ""pandas"" could not be resolved Pylance

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.19045
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-09 10:30:51,question,terminal issue,"Type: <b>Performance Issue</b>

why is my terminal not running my python code


VS Code version: Code 1.82.0 (8b617bd08fd9e3fc94d14adb8d358b56e3f72314, 2023-09-06T22:07:07.438Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD 3020e with Radeon Graphics                  (2 x 1200)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: disabled_off<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|5.94GB (1.27GB free)|
|Process Argv|C:\\\\Users\\\\chdnk\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\Code.exe --crash-reporter-id 58aadbbe-dca1-4641-af33-26e4cdf0cc2d|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    3	   141	 19240	code main
    0	   181	  1124	window [3] (demo.py - Visual Studio Code)
    0	    86	  3328	ptyHost
    0	    69	  2348	     C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\chdnk\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	     7	  6180	     conpty-agent
    0	     7	  9856	     conpty-agent
    0	     7	 10192	     conpty-agent
    0	    72	 14660	     C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\chdnk\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	    61	 18112	     C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\chdnk\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	   123	  7008	   gpu-process
    0	    94	  8056	shared-process
    0	    28	  8140	   crashpad-handler
    0	    87	 11300	fileWatcher [3]
    0	   136	 13468	extensionHost [1]
    0	   138	 10176	     electron-nodejs (""C:\\Users\\chdnk\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node c:\\Users\\chdnk\\.vscode\\extensions\\ms-python.vscode-pylance-2023.9.12\\dist\\server.bundle.js --cancellationReceive=file:19aab41bae3689461d83bca46521ed33608166c89f --node-ipc --clientProcessId=13468)
    0	   154	 16248	window [1] (demo.py - Visual Studio Code)
    0	   148	 17360	extensionHost [3]
    0	   166	 15432	     electron-nodejs (""C:\\Users\\chdnk\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node c:\\Users\\chdnk\\.vscode\\extensions\\ms-python.vscode-pylance-2023.9.12\\dist\\server.bundle.js --cancellationReceive=file:1200e540246f3ac587b529c6690b8c613b2181dee2 --node-ipc --clientProcessId=17360)
    0	    73	 17532	fileWatcher [1]
    0	    49	 17804	   utility-network-service
    2	    91	 18732	window [4] (Issue Reporter)
```

</details>
<details>
<summary>Workspace Info</summary>

```
;
```

</details>
<details><summary>Extensions (2)</summary>

Extension|Author (truncated)|Version
---|---|---
python|ms-|2023.16.0
vscode-pylance|ms-|2023.9.10


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931cf:30280410
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263cf:30792227
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
3biah626:30602489
89544117:30613380
showlangstatbar:30737416
a2ce3375:30757347
7ij38806:30736111
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
synctok:30821570
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30821571
dsvsc015cf:30829746

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-08 15:51:03,question,coke project wrong checking error,"CS50 coke project checking is giving wrong results. I think my program is correct but checking shows error however those errors were directed to next prompts even though the project asks for next prompt. 

https://submit.cs50.io/check50/7d0ecfa176a0bc412a69f971ca53ac67fdd1aac4

Version: 1.82.0
Commit: 8b617bd08fd9e3fc94d14adb8d358b56e3f72314
User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.62
Embedder: codespaces

<!-- generated by web issue reporter -->"
microsoft/vscode,2023-09-08 11:37:43,question,error while Compiling/running c code,"Type: <b>Bug</b>

#include <stdio.h>
#include <stdlib.h>
#include <time.h>

int main()
{
  const int MIN = 1;
  const int MAX = 5;
  int guess;
  int guesses;
  int answer;
  
  srand(time(0));
  
  answer = rand() % MAX + MIN;
  
  do{
      printf(""Enter your guess: "");
      scanf(""%d"",&guess);
      if(guess > answer)
      {
          printf(""Too high!\\n"");
      }
      else if( guess < answer)
      {
          printf(""Too low!\\n"");
      }
      else
      {
          printf(""Correct! you got this\\n"");
      }
      guesses++;
      
  }while(guess != answer);
  
  printf(""**************\\n"");
  printf(""Answer: %d\\n"",answer);
  printf(""Tries: %d\\n"",guesses);
  printf(""**************"");
  
  return 0;
  
}



The result must provide me with the  answer and the total amount of tries(guesses), I get the answer printed correctly but the number of tries isn't accurate, I tried running the same code on online compilers to see if my code had some problem, the online compilers gave me the correct answer and the number of tries  but there seems to be something wrong with VSCode when it comes to the ""tries"" part

VS Code version: Code 1.82.0 (8b617bd08fd9e3fc94d14adb8d358b56e3f72314, 2023-09-06T22:07:07.438Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 5 4600H with Radeon Graphics          (12 x 2994)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: enabled_on<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.42GB (5.57GB free)|
|Process Argv|--crash-reporter-id f807df9d-ec96-48b8-9397-90b59ddd654e|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (5)</summary>

Extension|Author (truncated)|Version
---|---|---
code-runner|for|0.12.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
cmake|twx|0.0.17

(2 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
282f8724:30602487
89544117:30613380
vscrpc:30673769
showlangstatbar:30737416
0bi6i642:30831757
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
asynctok:30821568
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-07 17:17:21,question,zsh: killed ,"Type: <b>Bug</b>

I have this problem in my terminal on my Mac and in the terminal on Visual studio Code. When I type python3 and python3 -version it gives me zsh: killed. Im new to coding and it didnt do this before im not sure how to fix it. 

<img width=""697"" alt=""Screenshot 2023-09-07 at 12 06 07 PM"" src=""https://github.com/microsoft/vscode/assets/109396688/a3d30217-e883-4356-8f41-fef33d05ea92"">



VS Code version: Code 1.81.1 (Universal) (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:20:33.924Z)
OS version: Darwin arm64 22.6.0
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Apple M2 (8 x 24)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>metal: disabled_off<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|2, 2, 2|
|Memory (System)|8.00GB (0.05GB free)|
|Process Argv|--crash-reporter-id 60b21ea6-cb30-45b4-8a90-5210e66abae0|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (7)</summary>

Extension|Author (truncated)|Version
---|---|---
python|ms-|2023.14.0
vscode-pylance|ms-|2023.9.10
jupyter|ms-|2023.7.1002162226
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931cf:30280410
vshan820:30294714
vstes263cf:30335440
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
2e4cg342:30602488
f6dab269:30613381
showlangstatbar:30737416
0bi6i642:30823812
a2ce3375:30757347
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
synctok:30821570
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572
dsvsc015:30829745

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-07 05:33:59,question,zoom challenge,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 
- OS Version: 

Steps to Reproduce:

1. 
2. 
![vsc](https://github.com/microsoft/vscode/assets/92901571/e8c81ba4-2f60-4115-8890-e317d73bed7f)
"
microsoft/vscode,2023-09-04 10:48:41,question,Error in calculating 5 cube to check weather 153 is armstrong number or not,"Type: <b>Bug</b>

I wrote a code to check weather 153 is a armstrong number or not(It is an armstrong number) as per a question in vs code . when i print cube of every digit using pow it show 5 cube as 124 instead of 125.while same code run perfectly on Devc++ software. but other cubes are correct
 Code is provided below for your ease to confirm my problem

#include<stdio.h>
#include<math.h>


int main(){
    int i=153,a,ans=0,n=0;
a=i;
while(a>0){
            n=pow((a%10),3);
            printf(""cube  of each digits \\n%d"",n);
            ans+=n;
            a/=10;}
        if(i==ans){
            printf(""\\n%d"",ans);}
return 0;}


VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.23536
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i3-1115G4 @ 3.00GHz (4 x 2995)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.75GB (1.19GB free)|
|Process Argv|--crash-reporter-id 10b0f727-de92-42e6-8eb1-a3bfc470a2bb|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (9)</summary>

Extension|Author (truncated)|Version
---|---|---
code-runner|for|0.12.0
c-cpp-runner|fra|8.1.0
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.50
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
cmake|twx|0.0.17
vscode-lldb|vad|1.9.2

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931cf:30280410
vshan820:30294714
vstes263cf:30335440
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
f6dab269:30613381
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-04 05:10:26,question,Coming out of program,"Type: <b>Bug</b>

My code  automatically comes out after taking only one input


VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i7-12650H (16 x 2688)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.68GB (5.86GB free)|
|Process Argv|--crash-reporter-id 5559ba75-7fa7-46c0-87ef-65b447fd9419|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (33)</summary>

Extension|Author (truncated)|Version
---|---|---
blackbox|Bla|1.0.97
vscode-html-css|ecm|1.13.1
EditorConfig|Edi|0.16.4
vsc-material-theme|Equ|33.10.5
vsc-material-theme-icons|equ|3.0.4
prettier-vscode|esb|10.1.0
code-runner|for|0.12.0
chatgpt-vscode|gen|0.0.8
isort|ms-|2023.10.1
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.50
jupyter|ms-|2023.7.1002162226
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-wsl|ms-|0.81.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
java|red|1.21.0
java-generate-setters-getters|soh|8.0.0
code-spell-checker|str|2.20.5
tabnine-vscode|Tab|3.8.8
cmake|twx|0.0.17
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.13
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
JavaScriptSnippets|xab|1.8.0

(2 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes516:30244333
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263cf:30792227
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
2e4cg342:30602488
f6dab269:30613381
showlangstatbar:30737416
962ge761:30823813
a2ce3375:30757347
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
asynctok:30821568
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-03 09:54:33,question,i can't run the code,"Type: <b>Bug</b>

when i try to run my come, vs shows "" Timed out waiting launcher to connect "" 
I search for all info in internet but nothing helped


VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 6.2.9200
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 5 5600H with Radeon Graphics          (12 x 3294)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|13.86GB (8.20GB free)|
|Process Argv|--crash-reporter-id fbfc43f9-8b65-458d-bbea-1e1d06f60383|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (6)</summary>

Extension|Author (truncated)|Version
---|---|---
gc-excelviewer|Gra|4.2.58
json2csv|kha|0.0.1
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.50
atom-keybindings|ms-|3.3.0
vscode-icons|vsc|12.5.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263cf:30792227
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
3biah626:30602489
89544117:30613380
vscrpc:30673769
a9j8j154:30646983
showlangstatbar:30737416
0bi6i642:30823812
a2ce3375:30757347
57b77579:30736110
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
asynctok:30821568
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30821571

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-01 20:24:38,question,Markdown files doesn't show as expected,"Type: <b>Feature Request</b>

I'm testing IntelliJ after using VS Code for a year and I've noticed that md-files display more like I expect in IntelliJ. That's a pitty. Both are not opimal though since marked lists are not very visible i IntelliJ and absent in VS code.

https://www.markdownguide.org/cheat-sheet/

Example
- [x] Write the press release
- [ ] Update the website
- [ ] Contact the media

Definition lists
: definition

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-09-01 09:06:38,question,extension name too lang cause UI not good,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
see this picture,when extension name too lang ，UI seems
![image](https://github.com/microsoft/vscode/assets/26430393/34a4f5d9-a18b-4fcf-8855-166b95370ee1)
"
microsoft/vscode,2023-08-31 05:52:26,question,"same program, different outputs","Type: <b>Bug</b>

#include <iostream>
#include <cmath>
using namespace std;

int main(){
    cout<<""Enter a number :"";
    int n;
    cin>>n;
    int i=0,bit=0,binary=0;
    cout<<n;
    while(n!=0){
       bit=n&1;
       //To store a number in same order
       binary= (bit*pow(10,i))+binary;
       i++;
       n=n>>1;
    }
    cout<<"" in binary is ""<<binary<<endl;
}

/* Let's take n=7 ,then the output should be  111 ,but on visual studio this program gives it to be 110.
I copied the same program and ran it on some online c++ compiler and got the desired output i.e 111 */

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i5-1235U (12 x 2496)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.73GB (7.92GB free)|
|Process Argv|--crash-reporter-id 7463add3-7d3b-4071-a81a-03f05de84b90|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (14)</summary>

Extension|Author (truncated)|Version
---|---|---
c-cpp-compile-run|dan|1.0.50
code-runner|for|0.12.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.5
cpptools-extension-pack|ms-|1.3.0
java|red|1.21.0
cmake|twx|0.0.17
intellicode-api-usage-examples|Vis|0.2.8
vscodeintellicode|Vis|1.2.30
vscode-java-debug|vsc|0.54.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.13
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
2e4cg342:30602488
f6dab269:30613381
2i9eh265:30646982
showlangstatbar:30737416
0bi6i642:30823812
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-30 15:23:58,question,settings.json,"Without noticing i removed something in the code, in settings.json and it now shows Incorrect type. Expected ""null"". [Ln4, Col 5]. and as a beginner in coding i have no idea how to correct that. help me please. I just need the original to copy and paste it back.
![1](https://github.com/microsoft/vscode/assets/143534661/a5103447-c542-40a7-877a-0977386afc53)
![2](https://github.com/microsoft/vscode/assets/143534661/feefdb13-3be6-40ea-a5e9-7030ed1b2eb5)


{
    ""python.defaultInterpreterPath"": ""C:\\\\Users\\\\hp\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\python.exe"",
    ""files.autoSave"": ""onFocusChange"",
    ""terminal.integrated.automationProfile.windows"": {
},
    ""code-runner.runInTerminal"": true,
    ""code-runner.executorMap"": {

           
        ""javascript"": ""node"",
        ""java"": ""cd $dir && javac $fileName && java $fileNameWithoutExt"",
        ""c"": ""cd $dir && gcc $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        ""zig"": ""zig run"",
        ""cpp"": ""cd $dir && g++ $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        ""objective-c"": ""cd $dir && gcc -framework Cocoa $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        ""php"": ""php"",
        ""python"": "" python -u"",
        ""perl"": ""perl"",
        ""perl6"": ""perl6"",
        ""ruby"": ""ruby"",
        ""go"": ""go run"",
        ""lua"": ""lua"",
        ""groovy"": ""groovy"",
        ""powershell"": ""powershell -ExecutionPolicy ByPass -File"",
        ""bat"": ""cmd /c"",
        ""shellscript"": ""bash"",
        ""fsharp"": ""fsi"",
        ""csharp"": ""scriptcs"",
        ""vbscript"": ""cscript //Nologo"",
        ""typescript"": ""ts-node"",
        ""coffeescript"": ""coffee"",
        ""scala"": ""scala"",
        ""swift"": ""swift"",
        ""julia"": ""julia"",
        ""crystal"": ""crystal"",
        ""ocaml"": ""ocaml"",
        ""r"": ""Rscript"",
        ""applescript"": ""osascript"",
        ""clojure"": ""lein exec"",
        ""haxe"": ""haxe --cwd $dirWithoutTrailingSlash --run $fileNameWithoutExt"",
        ""rust"": ""cd $dir && rustc $fileName && $dir$fileNameWithoutExt"",
        ""racket"": ""racket"",
        ""scheme"": ""csi -script"",
        ""ahk"": ""autohotkey"",
        ""autoit"": ""autoit3"",
        ""dart"": ""dart"",
        ""pascal"": ""cd $dir && fpc $fileName && $dir$fileNameWithoutExt"",
        ""d"": ""cd $dir && dmd $fileName && $dir$fileNameWithoutExt"",
        ""haskell"": ""runghc"",
        ""nim"": ""nim compile --verbosity:0 --hints:off --run"",
        ""lisp"": ""sbcl --script"",
        ""kit"": ""kitc --run"",
        ""v"": ""v run"",
        ""sass"": ""sass --style expanded"",
        ""scss"": ""scss --style expanded"",
        ""less"": ""cd $dir && lessc $fileName $fileNameWithoutExt.css"",
        ""FortranFreeForm"": ""cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        ""fortran-modern"": ""cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        ""fortran_fixed-form"": ""cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        ""fortran"": ""cd $dir && gfortran $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        ""sml"": ""cd $dir && sml $fileName""
    },
    ""terminal.integrated.defaultProfile.windows"": ""Command Prompt"",
    ""code-runner.clearPreviousOutput"": true,
    ""code-runner.executorMapByFileExtension"": {

        "".vb"": ""cd $dir && vbc /nologo $fileName && $dir$fileNameWithoutExt"",
        "".vbs"": ""cscript //Nologo"",
        "".scala"": ""scala"",
        "".jl"": ""julia"",
        "".cr"": ""crystal"",
        "".ml"": ""ocaml"",
        "".zig"": ""zig run"",
        "".exs"": ""elixir"",
        "".hx"": ""haxe --cwd $dirWithoutTrailingSlash --run $fileNameWithoutExt"",
        "".rkt"": ""racket"",
        "".scm"": ""csi -script"",
        "".ahk"": ""autohotkey"",
        "".au3"": ""autoit3"",
        "".kt"": ""cd $dir && kotlinc $fileName -include-runtime -d $fileNameWithoutExt.jar && java -jar $fileNameWithoutExt.jar"",
        "".kts"": ""kotlinc -script"",
        "".dart"": ""dart"",
        "".pas"": ""cd $dir && fpc $fileName && $dir$fileNameWithoutExt"",
        "".pp"": ""cd $dir && fpc $fileName && $dir$fileNameWithoutExt"",
        "".d"": ""cd $dir && dmd $fileName && $dir$fileNameWithoutExt"",
        "".hs"": ""runhaskell"",
        "".nim"": ""nim compile --verbosity:0 --hints:off --run"",
        "".csproj"": ""dotnet run --project"",
        "".fsproj"": ""dotnet run --project"",
        "".lisp"": ""sbcl --script"",
        "".kit"": ""kitc --run"",
        "".v"": ""v run"",
        "".vsh"": ""v run"",
        "".sass"": ""sass --style expanded"",
        "".cu"": ""cd $dir && nvcc $fileName -o $fileNameWithoutExt && $dir$fileNameWithoutExt"",
        "".ring"": ""ring"",
        "".sml"": ""cd $dir && sml $fileName""
    }
}"
microsoft/vscode,2023-08-29 11:14:37,question,Intellisense,"Type: <b>Performance Issue</b>

In my Laptop the intellisense is not working 

even after re installing it from the website

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (8 x 1800)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.87GB (6.64GB free)|
|Process Argv|--crash-reporter-id c9ec38c8-1f08-45ed-bf55-4e3bd456d151|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    0	   106	 20940	code main
    0	    45	  1376	   utility-network-service
    0	   164	  1380	extensionHost [1]
    0	    79	  7832	     electron-nodejs (""C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node c:\\Users\\User\\.vscode\\extensions\\formulahendry.auto-rename-tag-0.1.10\\packages\\server\\dist\\serverMain.js --node-ipc --clientProcessId=1380)
    0	    80	 23284	     electron-nodejs (""C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node ""c:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\extensions\\json-language-features\\server\\dist\\node\\jsonServerMain"" --node-ipc --clientProcessId=1380)
    0	    86	 28004	     electron-nodejs (""C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node c:\\Users\\User\\.vscode\\extensions\\pranaygp.vscode-css-peek-4.4.1\\server\\out\\server.js --node-ipc --clientProcessId=1380)
    0	    80	  6460	fileWatcher [1]
    0	    27	  9312	   crashpad-handler
    0	   101	 14484	shared-process
    1	   182	 22828	   gpu-process
    0	    96	 26052	ptyHost
    0	     6	  2044	     conpty-agent
    0	    84	  2496	     C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	    84	 19892	     C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	     6	 22692	     conpty-agent
    0	     6	 26924	     conpty-agent
    0	    84	 28048	     C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	   195	 26472	window [1] (● App.js - practice - Visual Studio Code)
    1	    92	 28824	window [2] (Issue Reporter)
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (● App.js - practice - Visual Studio Code)
|    Folder (practice): 30 files
|      File types: js(10) json(3) png(2) css(2) gitignore(1) ico(1) html(1)
|                  txt(1) md(1) svg(1)
|      Conf files: package.json(1);
```

</details>
<details><summary>Extensions (11)</summary>

Extension|Author (truncated)|Version
---|---|---
simple-react-snippets|bur|1.2.7
es7-react-js-snippets|dsz|4.4.3
vscode-html-css|ecm|1.13.1
prettier-vscode|esb|10.1.0
auto-rename-tag|for|0.1.10
vscode-css-peek|pra|4.4.1
LiveServer|rit|5.7.9
html5-boilerplate|sid|1.1.1
open-in-browser|tec|2.0.0
vscode-icons|vsc|12.5.0
JavaScriptSnippets|xab|1.8.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
2e4cg342:30602488
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30821572

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-24 13:18:04,question,multiple file does not open in new tab,"
Type: <b>Feature Request</b>

when a file is open then if i wanna open a new file it replace the tab with older one not in the new tab.


VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-23 23:53:57,question,All multi-cursors now disappear when navigating by word,"Type: <b>Bug</b>

Take any test with multiple lines.

Use Ctrl+Shift+Alt-Down to create a multi-cursor, one per line.

Navigating by character (Left/Right) works as expected: all cursors navigate.
Navigating by line (Up/Down or Home/End) also works as expected, and all cursors do it.
Navigating by word (Ctrl+Left/Right) doesn't. All cursors but one disappear as soon as you do this.

This just started happening out of the blue, possibly after an update. I don't know (just came back from vacation).


VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.22621
Modes:
Connection to 'SSH: ttdrazzle' could not be established  Canceled

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 9 7950X 16-Core Processor             (32 x 4491)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|127.14GB (84.80GB free)|
|Process Argv|--crash-reporter-id 51152fc6-57cf-45c0-ba26-7ec617922cec|
|Screen Reader|yes|
|VM|0%|

Connection to 'SSH: ttdrazzle' could not be established  Canceled
</details><details><summary>Extensions (26)</summary>

Extension|Author (truncated)|Version
---|---|---
midl3-language-server|Ale|0.0.31
vscode-research|dev|1.2022.1111005
vulnerability-extension|dev|1.2023.807004
xml|Dot|2.5.1
gitlens|eam|14.2.1
x8664assembly|fre|0.1.0
vscode-pull-request-github|Git|0.70.0
todo-tree|Gru|0.0.226
vscode-graphviz|joa|0.0.6
tdpcode|Mic|10.2304.707
vscode-azdo-codereview|Mic|1.2023.331002
wavework|Mic|1.2023.810005
csharp|ms-|2.0.376
vscode-dotnet-runtime|ms-|1.7.0
sarif-viewer|MS-|3.4.1
remote-ssh|ms-|0.102.0
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.4
remote-explorer|ms-|0.4.1
remote-server|ms-|1.4.3
vsliveshare|ms-|1.0.5883
windbg-debug|rez|0.3.4
cmake|twx|0.0.17
markdown-all-in-one|yzh|3.5.1


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vstes627:30244334
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263cf:30792227
vscaat:30438848
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
282f8724:30602487
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
asynctok:30810527
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30810525

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-23 09:05:50,question,Java compilation error,"Type: <b>Bug</b>

Java compilation error

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22631
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i3-1115G4 @ 3.00GHz (4 x 2995)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.80GB (1.43GB free)|
|Process Argv|--crash-reporter-id efb292f6-6bae-43c1-9ac1-d943ac88d6ec|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (20)</summary>

Extension|Author (truncated)|Version
---|---|---
bracket-pair-colorizer-2|Coe|0.2.4
prettier-vscode|esb|10.1.0
auto-rename-tag|for|0.1.10
vscode-javac|geo|0.2.46
vscode-power-mode|hoo|3.0.2
remote-wsl|ms-|0.81.0
powershell|ms-|2023.6.0
vscode-thunder-client|ran|2.10.5
java|red|1.21.0
LiveServer|rit|5.7.9
p5-vscode|sam|1.2.14
intellicode-api-usage-examples|Vis|0.2.7
vscodeintellicode|Vis|1.2.30
vscode-java-debug|vsc|0.53.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.13
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
es7-react-js-snippets|woo|2.5.1
ReactSnippets|xab|2.4.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vscaac:30438847
vsclangdc:30486549
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
3biah626:30602489
89544117:30613380
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30812748

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-21 23:42:30,question,How to detect if there is a snippets list in the editor?,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

How to detect if there is a snippets list in the editor as user type keystrokes? By meaning snippets list, I mean dropdown menu in the picture. Thanks. I am building a completion provider which want to trigger only when there is no dropdown suggestions list. How to achieve it?


![Screenshot 2023-08-21 at 4 39 57 PM](https://github.com/microsoft/vscode/assets/136044586/171cccfa-b274-4b12-accd-6df17e10ef09)

"
microsoft/vscode,2023-08-21 17:17:15,question,About Winerror 87,"when i import eel lib on my python code it keeps shown me this error on ""eel.start('index.html')"" 
is there a problem with my code or it's a bug?"
microsoft/vscode,2023-08-19 19:03:59,question,transform function not working,"Type: <b>Bug</b>

i am using css transform function which is not working

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 5 2500U with Radeon Vega Mobile Gfx   (8 x 1996)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|6.96GB (2.31GB free)|
|Process Argv|--crash-reporter-id 7ddaedf5-adeb-4e7a-aa82-02d910600357|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (11)</summary>

Extension|Author (truncated)|Version
---|---|---
tailwindshades|bou|0.0.5
turbo-console-log|Cha|2.9.6
es7-react-js-snippets|dsz|4.4.3
vscode-html-css|ecm|1.13.1
prettier-vscode|esb|10.1.0
vscode-typescript-next|ms-|5.3.20230818
sqltools|mtx|0.28.0
LiveServer|rit|5.7.9
vs-code-prettier-eslint|rve|5.1.0
ayu|tea|1.0.5
JavaScriptSnippets|xab|1.8.0

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vstes627:30244334
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
89544117:30613380
2i9eh265:30646982
showlangstatbar:30737416
03d35959:30757346
7ij38806:30736111
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
synctok:30815622
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30812748

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-18 11:08:08,question,Problema com salvar as comfigurações do vscode,"Type: <b>Bug</b>

Eu instalai a extensão dracula, porém quando eu fecho o vscode ela simplesmente sai e eu tenho que reabilitar ela

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 3 5400U with Radeon Graphics          (8 x 2595)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.31GB (1.32GB free)|
|Process Argv|C:\\\\Users\\\\Familia\\\\OneDrive\\\\Documentos\\\\Estudos\\\\HTML-CSS\\\\Exercicios\\\\ex014 --crash-reporter-id 3c8e9e65-b787-465e-baa9-ba80177a6eea|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (6)</summary>

Extension|Author (truncated)|Version
---|---|---
codesnap|adp|1.3.4
bracket-pair-color-dlw|Bra|0.0.6
vscode-language-pack-pt-BR|MS-|1.81.2023081609
color-highlight|nau|2.5.0
indent-rainbow|ode|8.3.1
material-icon-theme|PKi|4.29.0

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vscaac:30438847
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
2e4cg342:30602488
f6dab269:30613381
2i9eh265:30646982
showlangstatbar:30737416
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30812748

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-18 01:34:57,question,#include path error ,"Type: <b>Bug</b>

my include path error is coming again and again . kindly resolve my issue . i have just done everything changing its include path like everything which i can do form my side now pls help me to resolve this issue .

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i3-1115G4 @ 3.00GHz (4 x 2995)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.73GB (1.82GB free)|
|Process Argv|--crash-reporter-id 7a7d5bee-7e26-469e-b5f5-4f06501ac25c|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (7)</summary>

Extension|Author (truncated)|Version
---|---|---
exe-runner|bra|0.2.1
code-runner|for|0.12.0
icie|mik|1.0.0
cmake-tools|ms-|1.15.31
cpptools|ms-|1.17.3
cpptools-extension-pack|ms-|1.3.0
cmake|twx|0.0.17

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyonecf:30548226
vsccc:30803844
282f8724:30602487
89544117:30613380
2i9eh265:30646982
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv2:30812749

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-16 22:13:38,question,how can i close the auto save i want to control saving?,"ADD ISSUE DESCRIPTION HERE

Version: 1.81.1
Commit: 6c3e3dba23e8fadc360aed75ce363ba185c49794
User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36 Edg/115.0.1901.203
Embedder: codespaces

<!-- generated by web issue reporter -->"
microsoft/vscode,2023-08-16 10:23:18,question,"in my vs code t is not working whenever i enter t key vs code give an error by saying the key combination (T,T) is not command please help me","<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 
- OS Version: 

Steps to Reproduce:

1. 
2. 

```[tasklist]
### Tasks
```
"
microsoft/vscode,2023-08-15 07:13:06,question,> sign has accidentally replaced $ sign at cursor in terminal window of vs code. How can I get $ sign back at cursor,"ADD ISSUE DESCRIPTION HERE

Version: 1.81.1
Commit: 6c3e3dba23e8fadc360aed75ce363ba185c49794
User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36
Embedder: codespaces

<!-- generated by web issue reporter -->"
microsoft/vscode,2023-08-15 03:15:01,question,issues in c++ program running,"i am running c++ program and i it not running properly ,
i have tried run in terminal only it is not running at all.
{fix this} "
microsoft/vscode,2023-08-14 09:32:54,question,BUG in in-built function pow (power function).,"Type: <b>Bug</b>

Hello developers hope you are doing well. so while solving my class asignment problem i have found bug in following program as i am getting unexpected output for certain value that is for input = 5; for other values it is working fine but on entering input 5 it is printing unexpected output.
code -
#include <stdio.h>
#include <math.h>
int power(int a);

int main()
{
    int a = 5;
    int k = power(a);
    printf(""pow is = %d"", k);
}
int power(int a)
{
    int b = pow(a,2);

    return b;
}

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22000
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (8 x 2419)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.76GB (0.94GB free)|
|Process Argv|--crash-reporter-id fa9f32f2-72d6-48d1-948e-bdac79ea866a|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (13)</summary>

Extension|Author (truncated)|Version
---|---|---
exe-runner|bra|0.2.1
prettier-vscode|esb|10.1.0
isort|ms-|2023.10.1
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.20
jupyter|ms-|2023.7.1002162226
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
cmake-tools|ms-|1.15.31
cpptools|ms-|1.16.3
cpptools-extension-pack|ms-|1.3.0
indent-rainbow|ode|8.3.1
cmake|twx|0.0.17

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263:30792226
vscaac:30438847
vsclangdc:30486549
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
3biah626:30602489
89544117:30613380
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076
diffeditorv1:30812748

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-12 13:02:43,question,armstrong3.c,"We have written the needed data into your clipboard because it was too large to send. Please paste

Type: <b>Performance Issue</b>

#include<stdio.h>
#include<math.h>

int main(){

 int n, rem, p, s = 0;
    printf(""\\nEnter Number :"");
    scanf(""%d"", &n);
    p = n;
    while (n>0)
    {
        rem = n % 10;
        
        s = s + pow(rem,3);
       
        n = n/10;
    }
    if (s == p)
    {
        printf(""\\n%d is a armstrong number "", p);
    }
    else
    { 
        printf(""\\nsum %d"", s);
        printf(""\\nNot a armstrong number "");
    }


return 0;
}




The output is showing me 152 and i even tried the same source code on other ide's they worked well and gave me expected output as 153 please solve this issue , i talked to my friend and he experienced the same thing why is this happening .

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i5-11300H @ 3.10GHz (8 x 3110)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.79GB (8.22GB free)|
|Process Argv|--crash-reporter-id 00c502d4-7eb0-4e69-8ccb-7261192381eb|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    0	   115	 21172	code main
    0	    87	  7764	window [2] (Issue Reporter)
    0	   227	  9584	   gpu-process
    0	   193	 10200	extensionHost [1]
    0	    28	  2768	     ""c:\\Users\\Tushal dewasi\\.vscode\\extensions\\ms-vscode.cpptools-1.16.3-win32-x64\\bin\\cpptools.exe""
    0	    11	  4256	       C:\\WINDOWS\\system32\\conhost.exe 0x4
    0	     4	 21020	       ""c:\\Users\\Tushal dewasi\\.vscode\\extensions\\ms-vscode.cpptools-1.16.3-win32-x64\\bin\\cpptools.exe""
    0	    16	  5448	         ""c:\\Users\\Tushal dewasi\\.vscode\\extensions\\ms-vscode.cpptools-1.16.3-win32-x64/bin/cpptools-srv.exe"" 2768 {3C644793-B351-45B1-973C-CF71BE990FC8}
    0	    11	 13588	           C:\\WINDOWS\\system32\\conhost.exe 0x4
    0	    77	 10040	     electron-nodejs (""C:\\Users\\Tushal dewasi\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node ""c:\\Users\\Tushal dewasi\\.vscode\\extensions\\formulahendry.auto-rename-tag-0.1.10\\packages\\server\\dist\\serverMain.js"" --node-ipc --clientProcessId=10200)
    0	   618	 22280	     ""c:\\Users\\Tushal dewasi\\.vscode\\extensions\\redhat.java-1.21.0-win32-x64\\jre\\17.0.7-win32-x86_64\\bin\\java"" --add-modules=ALL-SYSTEM --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/sun.nio.fs=ALL-UNNAMED -Declipse.application=org.eclipse.jdt.ls.core.id1 -Dosgi.bundles.defaultStartLevel=4 -Declipse.product=org.eclipse.jdt.ls.core.product -Djava.import.generatesMetadataFilesAtProjectRoot=false -Dfile.encoding=utf8 -XX:+UseParallelGC -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90 -Dsun.zip.disableMemoryMapping=true -Xmx1G -Xms100m -Xlog:disable ""-javaagent:c:\\Users\\Tushal dewasi\\.vscode\\extensions\\redhat.java-1.21.0-win32-x64\\lombok\\lombok-1.18.28.jar"" -XX:+HeapDumpOnOutOfMemoryError ""-XX:HeapDumpPath=c:\\Users\\Tushal dewasi\\AppData\\Roaming\\Code\\User\\workspaceStorage\\bfd811242260c75c11defd2d2b60bc80\\redhat.java"" -Daether.dependencyCollector.impl=bf -jar ""c:\\Users\\Tushal dewasi\\.vscode\\extensions\\redhat.java-1.21.0-win32-x64\\server\\plugins\\org.eclipse.equinox.launcher_1.6.500.v20230717-2134.jar"" -configuration ""c:\\Users\\Tushal dewasi\\AppData\\Roaming\\Code\\User\\globalStorage\\redhat.java\\1.21.0\\config_win"" -data ""c:\\Users\\Tushal dewasi\\AppData\\Roaming\\Code\\User\\workspaceStorage\\bfd811242260c75c11defd2d2b60bc80\\redhat.java\\jdt_ws""
    0	    43	 12392	   utility-network-service
    0	   204	 14128	window [1] (armstrong3.c - Untitled (Workspace) - Visual Studio Code)
    0	    28	 16176	   crashpad-handler
    0	    91	 18868	shared-process
    0	    82	 21340	     electron-nodejs (""C:\\Users\\Tushal dewasi\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node ""c:\\Users\\Tushal dewasi\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\bootstrap-fork"" ms-vscode.cppdbg ""{\\""common.vscodemachineid\\"":\\""cd7ed736ee8427943b89b704cff0647a508ec907f33e7a6c4ad5b0f79a12bd09\\"",\\""common.vscodesessionid\\"":\\""f87104dd-dd6c-4d67-a458-756de437d35a1691844211630\\""}"" 0c6ae279ed8443289764825290e4f9e2-1a736e7c-1324-4338-be46-fc2a58ae4d14-7255)
    0	    79	 19640	fileWatcher [1]
    0	    79	 22100	ptyHost
    0	    71	  1404	     C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\Tushal dewasi\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	     8	 20564	     conpty-agent
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (armstrong3.c - Untitled (Workspace) - Visual Studio Code)
|    Folder (coding): 190 files
|      File types: c(155) exe(13) py(2) cpp(1) class(1) java(1)
|      Conf files:;
```

</details>
<details><summary>Extensions (31)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-django|bat|1.10.0
python-environment-manager|don|1.0.4
python-extension-pack|don|1.7.0
vscode-html-css|ecm|1.13.1
prettier-vscode|esb|10.1.0
auto-close-tag|for|0.5.14
auto-rename-tag|for|0.1.10
code-runner|for|0.12.0
vsc-python-indent|Kev|1.18.0
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.20
jupyter|ms-|2023.7.1002162226
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
cmake-tools|ms-|1.15.31
cpptools|ms-|1.16.3
cpptools-extension-pack|ms-|1.3.0
autodocstring|njp|0.6.1
java|red|1.21.0
LiveServer|rit|5.7.9
cmake|twx|0.0.17
intellicode-api-usage-examples|Vis|0.2.7
vscodeintellicode|Vis|1.2.30
vscode-java-debug|vsc|0.53.0
vscode-java-dependency|vsc|0.23.1
vscode-java-pack|vsc|0.25.13
vscode-java-test|vsc|0.39.1
vscode-maven|vsc|0.42.0
jinja|who|0.0.8

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
2e4cg342:30602488
f6dab269:30613381
showlangstatbar:30737416
03d35959:30757346
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-11 12:26:47,question,cant run my code properly ,"Type: <b>Feature Request</b>

Respected Mam/Sir
i am humbly requesting kindly fix my vs code via any online connecting souces like anydesk its showing ""open.launch.json"".
kindly help me out i am stuck in this loop for this i will be forever thankful to you guys

VS Code version: Code 1.81.1 (6c3e3dba23e8fadc360aed75ce363ba185c49794, 2023-08-09T22:22:42.175Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-11 07:56:58,question,Custom view container menu action contribute ,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

I want to be able to add actions to custom view container.
I've tried : 
```json
""commands"" : [
  {
    ""command"": ""test_command_id"",
    ""title"": ""Test command"",
    ""icon"": ""$(zap)""
  }
],
""viewsContainers"" : {
  ""activitybar"": [
    {
      ""id"": ""custiom_view_container"",
      ""title"": ""Test title"",
      ""icon"": ""$(zap)""
    }
  ]
},
""menus"": {
  ""view/title"": [
    {
      ""command"": ""test_command_id"",
      ""when"": ""view == custiom_view_container"",
      ""group"": ""navigation""
    }
  ],
  ""custiom_view_container/title"": [
    {
      ""command"": ""test_command_id"",
      ""when"": ""true"",
      ""group"": ""navigation""
    }
  ]
}

```
Non of this works, however i am able to add command for built in containers : 
```json
""menus"": {
  ""scm/title"": [
    {
      ""command"": ""test_command_id"",
      ""when"": ""true"",
      ""group"": ""navigation""
    }
  ]
}
```

"
microsoft/vscode,2023-08-10 13:20:55,question,Bug in CodeSpace,"
Type: <b>Bug</b>

In codespace jupyter template:
when i create a new jupyter template and run the first python clock in notebooks/image-classifier.ipynb, it shows an error:

ModuleNotFoundError: No module named '_lzma'
(caused by the second line ""import torchvision"")

VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.22000
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 7 4800U with Radeon Graphics          (16 x 1797)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.37GB (9.07GB free)|
|Process Argv|--crash-reporter-id 8067c5ac-fbff-4695-b384-5ccac3278cfc|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (12)</summary>

Extension|Author (truncated)|Version
---|---|---
codespaces|Git|1.14.15
vscode-pylance|ms-|2023.8.20
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.304.0
remote-ssh|ms-|0.102.0
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.0
cpptools|ms-|1.7.1
remote-explorer|ms-|0.4.1


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
3biah626:30602489
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-10 09:56:21,question,subscribing to the response of CLI command ,"I am developing an extension, and there is a CLI command which subscribes to server and keep listening to it until stopped manually. I want to use this command to implement a feature in the extension , so that it will keep listening to the server and whenever there is some event happened on server side it will give a response and we can read it and use it.

This command will get fired as soon as the extension activates and will stop when extension deactivates.

I tried executing with spawn() but it executed the command as there was not response at that time from the CLI command. it got exit

how can I implement this?
"
microsoft/vscode,2023-08-09 20:56:24,question,Import,"
Type: <b>Bug</b>

I have installed polars but it is not importing in the code says module not found error 

VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz (8 x 1992)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.90GB (7.95GB free)|
|Process Argv|--crash-reporter-id 738576e0-ec7f-4111-aaaf-2e7fa748845c|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (34)</summary>

Extension|Author (truncated)|Version
---|---|---
matlab-formatter|Aff|2.11.0
matlab-interactive-terminal|apo|0.4.0
matlab-extension-pack|bat|0.1.0
matlab-code-run|bra|1.0.2
sld-docker-builder|del|0.0.1
vscode-npm-script|eg2|0.3.29
docker-explorer|for|0.1.7
docker-extension-pack|for|0.0.1
docker-run|geo|1.1.0
matlab|Gim|3.0.2
composer|ika|0.8.0
mongodb-vscode|mon|1.1.0
vscode-docker|ms-|1.26.0
isort|ms-|2023.10.1
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.10
jupyter|ms-|2023.7.1002162226
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-wsl|ms-|0.81.0
vsliveshare|ms-|1.0.5877
docker-compose|p1c|0.5.0
vsc-octave-debugger|pau|0.5.11
sas|pvp|0.0.1
sas-lsp|SAS|1.1.0
sasjs-for-vscode|SAS|2.5.1
matlab-complete|Sla|1.1.1
octave-debug|tia|0.0.3
intellicode-api-usage-examples|Vis|0.2.7
vscode-java-debug|vsc|0.53.0
wordup-code|wor|0.3.2
php-debug|xde|1.33.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263:30792226
vsclangdc:30486549
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
3biah626:30602489
f6dab269:30613381
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-08 15:52:22,question,Test Results tab in VS Code keep popping up even if closed after each test run,"Type: <b>Bug</b>

**Context:**
- Playwright Version:1.36.2
- Operating System: Mac
- Node.js version: v20.4.0
- Visual Studio Code version: Version: 1.81.0
Commit: 6445d93c81ebe42c4cbd7a60712e0b17d9463e97
Date: 2023-08-02T12:38:28.722Z
Electron: 22.3.18
ElectronBuildId: 22689846
Chromium: 108.0.5359.215
Node.js: 16.17.1
V8: 10.8.168.25-electron.0
OS: Darwin arm64 22.6.0
- Playwright for VSCode extension version: v1.0.15


When running a test - the tab with Test Results always pops-up.
This started happening with recent VS Code update. No matter what I do - it keeps popping-up. Before it was never showed up if not on demand.



VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:38:28.722Z)
OS version: Darwin arm64 22.6.0
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Apple M1 Pro (10 x 24)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>metal: disabled_off<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|4, 4, 5|
|Memory (System)|32.00GB (0.40GB free)|
|Process Argv|--crash-reporter-id 3dc3f68f-23e6-4d9e-a0b7-614e6fcd461a|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (27)</summary>

Extension|Author (truncated)|Version
---|---|---
atlascode|atl|3.0.4
vscode-generate-getter-setter|DSK|0.5.0
gitlens|eam|14.2.0
prettier-vscode|esb|10.1.0
code-runner|for|0.12.0
rainbow-csv|mec|3.7.0
template-string-converter|meg|0.6.1
vscode-azureresourcegroups|ms-|0.7.5
vscode-azurevirtualmachines|ms-|0.6.5
playwright|ms-|1.0.15
remote-containers|ms-|0.304.0
remote-ssh|ms-|0.102.0
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.81.0
vscode-remote-extensionpack|ms-|0.24.0
azure-account|ms-|0.11.5
powershell|ms-|2023.6.0
remote-explorer|ms-|0.4.1
remote-server|ms-|1.4.0
vsliveshare|ms-|1.0.5877
vscode-thunder-client|ran|2.10.2
vscode-yaml|red|1.14.0
code-spell-checker|str|2.20.5
icons|tal|3.7.0
tcv-typescript-constructor-generator|toa|0.2.0
colonize|vms|2.2.2
gistfs|vsl|0.4.1


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931cf:30280410
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
2e4cg342:30602488
89544117:30613380
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
7ij38806:30736111
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofa:30804715
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->
![image](https://github.com/microsoft/vscode/assets/40281293/e0e57d99-14f8-4336-830b-a5168aa04ce1)
"
microsoft/vscode,2023-08-07 18:12:31,question,i want to put my name in output,"Type: <b>Feature Request</b>

i want to my name in output in default

VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.22621
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-06 19:23:51,question,Problems with the Fetch API,"
Type: <b>Bug</b>

I am not sure if this is really a problem with VS Code or not. I use the Fetch API in JavaScript. When I run the Fetch directly in JavaScript with a Chrome browser, I have no problems. The Fetch API executes fine. A very important point is that I don't see an OPTIONS request being sent. However, when I run the same Fetch using exactly the same JavaScript (using VS Code) I do see an OPTIONS being sent. Even worse, the Fetch (under JavaScript, under Chrome, under VS Code) does not wait for the OPTIONS to complete. The Fetch just fails with a 'failed to fetch' error. I don't understand this. Why should VS Code make any difference? What am I doing wrong? What additional information should I provide? How should this problem be debugged?

This is not a question. This is (probably) a bug. VSC has a behavior that native JavaScript does not. Either VSC should be fixed or some sort of circumvention should be devised.

VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-4702HQ CPU @ 2.20GHz (8 x 2195)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: unavailable_off<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.91GB (5.05GB free)|
|Process Argv|--folder-uri file:///c%3A/Users/Peter/Documents/Visual%20Studio%20Code/Projects/WebApplication5/WebApplication5 --crash-reporter-id 7c17602d-d116-41bf-9eeb-6f288773aaef|
|Screen Reader|no|
|VM|0%|
</details>Extensions: none<details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
f6dab269:30613381
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-06 15:09:42,question,Problems with the Fetch API,"
Type: <b>Bug</b>

I am not sure if this is really a problem with VS Code or not. I use the Fetch API in JavaScript. When I run the Fetch directly in JavaScript with a Chrome browser, I have no problems. The Fetch API executes fine. A very important point is that I don't see an OPTIONS request being sent. However, when I run the same Fetch using exactly the same JavaScript (using VS Code) I do see an OPTIONS being sent. Even worse, the Fetch (under JavaScript, under Chrome, under VS Code) does not wait for the OPTIONS to complete. The Fetch just fails with a 'failed to fetch' error. I don't understand this. Why should VS Code make any difference? What am I doing wrong? What additional information should I provide? How should this problem be debugged?

VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-4702HQ CPU @ 2.20GHz (8 x 2195)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: unavailable_off<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.91GB (5.79GB free)|
|Process Argv|--folder-uri file:///c%3A/Users/Peter/Documents/Visual%20Studio%20Code/Projects/WebApplication5/WebApplication5 --crash-reporter-id 7c17602d-d116-41bf-9eeb-6f288773aaef|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (10)</summary>

Extension|Author (truncated)|Version
---|---|---
copilot|Git|1.100.306
python|ms-|2023.14.0
vscode-pylance|ms-|2023.8.10
jupyter|ms-|2023.7.1002162226
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
live-server|ms-|0.4.9
LiveServer|rit|5.7.9


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
f6dab269:30613381
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-05 08:48:58,question,webpages didn't load in chrome,"[Type:](url) <b>Performance Issue</b>

when I run the html,css,js code it shows again and again localhost:8080,
localhost refused error I cant load my webpages I feel great if you reply me

VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.22631
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|11th Gen Intel(R) Core(TM) i3-1115G4 @ 3.00GHz (4 x 2995)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.65GB (2.54GB free)|
|Process Argv|--crash-reporter-id 63f06613-4867-44e6-9261-e04554d095e2|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    1	    90	 17104	code main
    0	   109	  2988	extensionHost [1]
    0	   113	  8616	     electron-nodejs (""C:\\Program Files\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node --max-old-space-size=3072 ""c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js"" --useInferredProjectPerProjectRoot --enableTelemetry --cancellationPipeName C:\\Users\\hp\\AppData\\Local\\Temp\\vscode-typescript\\6126cc3695a9be66c6ba\\tscancellation-b10b20c4d0a60e94376a.tmp* --locale en --noGetErrOnBackgroundUpdate --validateDefaultNpmLocation --useNodeIpc)
    0	    79	 14660	       electron-nodejs (""C:\\Program Files\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node ""c:/Program Files/Microsoft VS Code/resources/app/extensions/node_modules/typescript/lib/typingsInstaller.js"" --globalTypingsCacheLocation C:/Users/hp/AppData/Local/Microsoft/TypeScript/5.1 --enableTelemetry --typesMapLocation ""c:/Program Files/Microsoft VS Code/resources/app/extensions/node_modules/typescript/lib/typesMap.json"" --validateDefaultNpmLocation)
    0	   119	  9260	     electron-nodejs (""C:\\Program Files\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node --max-old-space-size=3072 ""c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js"" --serverMode partialSemantic --useInferredProjectPerProjectRoot --disableAutomaticTypingAcquisition --cancellationPipeName C:\\Users\\hp\\AppData\\Local\\Temp\\vscode-typescript\\6126cc3695a9be66c6ba\\tscancellation-ce1d0f50734ce3c1f720.tmp* --locale en --noGetErrOnBackgroundUpdate --validateDefaultNpmLocation --useNodeIpc)
    0	    80	  5360	shared-process
    1	   218	  6808	window [1] (app.js - js - Visual Studio Code)
    0	    74	  6920	fileWatcher [1]
    0	    26	 11284	   crashpad-handler
    1	    84	 12132	window [2] (Issue Reporter)
    1	   166	 15848	   gpu-process
    0	    42	 15856	   utility-network-service
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (app.js - js - Visual Studio Code)
|    Folder (js): 2 files
|      File types: js(1) html(1)
|      Conf files:;
```

</details>
<details><summary>Extensions (4)</summary>

Extension|Author (truncated)|Version
---|---|---
auto-close-tag|for|0.5.14
code-runner|for|0.12.0
remote-wsl|ms-|0.81.0
LiveServer|rit|5.7.9


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30803845
3biah626:30602489
89544117:30613380
2i9eh265:30646982
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-04 09:05:27,question,error ,"
Type: <b>Bug</b>



User
Microsoft Windows [Versión 10.0.22621.1992]
(c) Microsoft Corporation. Todos los derechos reservados.

C:\\Users\\primo\\OneDrive\\Escritorio\\otro\\ClonTwitter>rails s
=> Booting Puma
=> Rails 7.0.6 application starting in development 
=> Run `bin/rails server --help` for more startup options
*** SIGUSR2 not implemented, signal based restart unavailable!
*** SIGUSR1 not implemented, signal based restart unavailable!
*** SIGHUP not implemented, signal based logs reopening unavailable!
Puma starting in single mode...
* Version 5.0.0 (ruby 3.1.3-p185), codename: Spoony Bard
* Min threads: 5, max threads: 5
* Environment: development
Exiting
C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:242:in `initialize': Only one usage of each socket address (protocol/network address/port) is normally permitted. - bind(2) for ""127.0.0.1"" port 3000 (Errno::EADDRINUSE)
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:242:in `new'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:242:in `add_tcp_listener'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:236:in `block in add_tcp_listener'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:235:in `each'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:235:in `add_tcp_listener'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:122:in `block in parse'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:106:in `each'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/binder.rb:106:in `parse'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/runner.rb:137:in `load_and_bind'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/single.rb:43:in `run'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/puma/launcher.rb:171:in `run'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/puma-5.0.0/lib/rack/handler/puma.rb:71:in `run'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/rack-2.2.7/lib/rack/server.rb:327:in `start'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/railties-7.0.6/lib/rails/commands/server/server_command.rb:38:in `start'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/railties-7.0.6/lib/rails/commands/server/server_command.rb:143:in `block in perform'
        from <internal:kernel>:90:in `tap'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/railties-7.0.6/lib/rails/commands/server/server_command.rb:134:in `perform'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/thor-1.2.2/lib/thor/command.rb:27:in `run'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/thor-1.2.2/lib/thor/invocation.rb:127:in `invoke_command'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/thor-1.2.2/lib/thor.rb:392:in `dispatch'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/railties-7.0.6/lib/rails/command/base.rb:87:in `perform'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/railties-7.0.6/lib/rails/command.rb:48:in `invoke'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/railties-7.0.6/lib/rails/commands.rb:18:in `<main>'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/bootsnap-1.16.0/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:32:in `require'
        from C:/Ruby31-x64/lib/ruby/gems/3.1.0/gems/bootsnap-1.16.0/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:32:in `require'
        from bin/rails:4:in `<main>'

VS Code version: Code 1.80.2 (2ccd690cbff1569e4a83d7c43d45101f817401dc, 2023-07-27T20:40:28.909Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz (12 x 2592)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.88GB (8.85GB free)|
|Process Argv|C:\\\\Users\\\\primo\\\\OneDrive\\\\Escritorio\\\\ejercitando --crash-reporter-id ddbab503-a4a8-47c1-aa4e-da7cea102e39|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (22)</summary>

Extension|Author (truncated)|Version
---|---|---
rails-partial|aki|0.3.4
ruby-and-rails-snippets|Cja|1.0.0
codespaces|Git|1.14.14
remotehub|Git|0.60.0
vscode-github-actions|git|0.25.8
vscode-pull-request-github|Git|0.68.1
beautify|Hoo|1.5.0
rails-snippets|Hri|1.0.8
vscode-peacock|joh|4.2.2
vscode-language-pack-es|MS-|1.80.2023071209
remote-wsl|ms-|0.80.2
azure-repos|ms-|0.36.0
live-server|ms-|0.4.9
remote-repositories|ms-|0.38.1
indent-rainbow|ode|8.3.1
sqlite-viewer|qwt|0.2.5
vscode-thunder-client|ran|2.10.0
ruby|reb|0.28.1
LiveServer|rit|5.7.9
docxreader|Sha|1.0.0
vscode-icons|vsc|12.4.0
vscode-ruby|win|0.28.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
282f8724:30602487
89544117:30613380
2i9eh265:30646982
showlangstatbar:30737416
vsctsb:30748421
pythonfmttext:30731395
pythoncmvfstrcf:30756944
9b8hh234:30694863
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxptcf:30805731
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-03 21:11:30,question,Can't connect emulators,"
Type: <b>Bug</b>

I have tries all posible answers but no luck. Path; re-installation, etc. I can't test my apps. I have windows 10 home edition.

VS Code version: Code 1.81.0 (6445d93c81ebe42c4cbd7a60712e0b17d9463e97, 2023-08-02T12:37:13.485Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-4210U CPU @ 1.70GHz (4 x 2394)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|11.91GB (6.88GB free)|
|Process Argv|--crash-reporter-id 77e77cea-893a-42b9-ad6c-1c3dd2e42ab1|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (4)</summary>

Extension|Author (truncated)|Version
---|---|---
dart-code|Dar|3.70.0
flutter|Dar|3.70.0
emulate|Die|1.6.0
gitlens|eam|14.1.1


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyonecf:30548226
vscccc:30803845
2e4cg342:30602488
89544117:30613380
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30805244
pythongtdpath:30769146
i26e3531:30792625
gsofb:30804716
pythonnosmt12:30797651
pythonidxpt:30805730
pythonnoceb:30805159
e537b577:30795824
dsvsc013:30795093
dsvsc014:30804076

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-01 21:09:25,question,Trying to get to SRCPF on PUB400,"Type: <b>Bug</b>

I'm getting an odd error trying to access my SRCPF's on PUB400. Getting CPF2207: Not authorized to ise object ILEDITOR in library QSYS type *LIB. 
Can anyone assist?

VS Code version: Code 1.80.2 (2ccd690cbff1569e4a83d7c43d45101f817401dc, 2023-07-27T20:40:28.909Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i5-1245U (12 x 2496)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.69GB (6.15GB free)|
|Process Argv|--crash-reporter-id 905bb75d-c64b-4889-8027-c54522ac4b5c|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (17)</summary>

Extension|Author (truncated)|Version
---|---|---
ibmi-languages|bar|0.6.14
cobol|bit|9.7.23
vscode-rpgfree|Bri|0.0.26
ibmi-snippets|for|1.0.0
copilot|Git|1.99.289
code-for-ibmi|hal|2.0.2
ibm-i-development-pack|hal|0.1.0
vscode-db2i|hal|0.3.3
vscode-displayfile|hal|0.1.2
vscode-ibmi-notebooks|hal|0.0.6
vscode-ibmi-walkthroughs|hal|0.3.1
vscode-rpgle|hal|0.19.3
ibmidebug|IBM|1.0.0
vscode-clle|IBM|1.1.1
ibm-i-run-sql-from-acs|Nie|0.0.4
errorlens|use|3.12.0
vscode-todo-highlight|way|1.0.5


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30803844
3biah626:30602489
89544117:30613380
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
24365598:30736109
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30785052
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonnoceb:30797650
e537b577:30795824
dsvsc013:30795093
dsvsc014cf:30797590
cmakesidepanelv2:30779593

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-08-01 00:43:16,question,Failed to install the app.,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- - VS Code Version: 1.63.2
- - OS Version: Windows_NT x64 10.0.19045

Steps to Reproduce:

1. Create a project regardless of reaction native cli / expocli.
ex) npx create-expo-app my-app
2. Run the project on the Android emulator. 
ex) expo start -> a (run on emulator)

If you run an Android app project in the current Visual Studio, the emulator will run properly, but the app installation will continue to fail. Is there any additional configuration that I should set? Currently, I have set the sdk/platform-tools/jdk/android home environment variable. Even though it runs normally in Android studio, it doesn't run only in visual studio code. I don't think I can make a Java machine properly, can you help me?

I also posted an issue on the react native collar, but I didn't get any help. I'm attaching the link together just in case.
https://github.com/facebook/react-native/issues/38657


This is my error
```
npx react-native run-android
info Starting JS server...
* daemon not running; starting now at tcp:5037
* daemon started successfully
info Launching emulator...
info Successfully launched emulator.
info Installing the app...
Unrecognized option: -xmx64m
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.

error Failed to install the app. Make sure you have the Android development environment set up: https://reactnative.dev/docs/environment-setup.
Error: Command failed: gradlew.bat app:installDebug -PreactNativeDevServerPort=8081
Unrecognized option: -xmx64m
Error: A fatal exception has occurred. Program will exit.

    at makeError (D:\\Android\\AwesomeProject\\node_modules\\@react-native-community\\cli-platform-android\\node_modules\\execa\\index.js:174:9)
    at D:\\Android\\AwesomeProject\\node_modules\\@react-native-community\\cli-platform-android\\node_modules\\execa\\index.js:278:16
    at processTicksAndRejections (node:internal/process/task_queues:96:5)
    at async runOnAllDevices (D:\\Android\\AwesomeProject\\node_modules\\@react-native-community\\cli-platform-android\\build\\commands\\runAndroid\\runOnAllDevices.js:109:5)     
    at async Command.handleAction (D:\\Android\\AwesomeProject\\node_modules\\@react-native-community\\cli\\build\\index.js:142:9)
info Run CLI with --verbose flag for more details.
```"
microsoft/vscode,2023-07-31 10:40:53,question,code-oss configure display language is invalid,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.80.1
- OS Version: Windows_NT x64 10.0.22621

About info:
Version: 1.80.1 (user setup)
Commit: Unknown
Date: 2023-07-31T10:01:18.853Z
Electron: 22.3.14
ElectronBuildId: undefined
Chromium: 108.0.5359.215
Node.js: 16.17.1
V8: 10.8.168.25-electron.0
OS: Windows_NT x64 10.0.22621

Steps to Reproduce:

1. build vscode source (yarn gulp vscode-win32-x64)
2. install chinese extension(zh-cn)
3. configure display language and select to zh-cn,reload it's still Englist(es)
4. same as yarn gulp vscode-win32-x64-user-setup

the argv.json had set locale to ""zh-cn""
![image](https://github.com/microsoft/vscode/assets/47603705/da61be11-65a4-47ae-8f51-dc3eefa7c676)
"
microsoft/vscode,2023-07-28 17:53:00,question,Snippet Requires extra tab to move to next placeholder,"Type: <b>Bug</b>

This is my Snippets file:

```
{
	// Place your global snippets here. Each snippet is defined under a snippet name and has a scope, prefix, body and
	// description. Add comma separated ids of the languages where the snippet is applicable in the scope field. If scope
	// is left empty or omitted, the snippet gets applied to all languages. The prefix is what is
	// used to trigger the snippet and the body will be expanded and inserted. Possible variables are:
	// $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders.
	// Placeholders with the same ids are connected.
	// Example:
	// ""Print to console"": {
	// 	""scope"": ""javascript,typescript"",
	// 	""prefix"": ""log"",
	// 	""body"": [
	// 		""console.log('$1');"",
	// 		""$2""
	// 	],
	// 	""description"": ""Log output to console""
	// }
	""CDRL"": {
		""scope"": ""html"",
		""prefix"": ""cdrl"",
		""body"": [
			""<a class=\\""${1|pdf,xls,mpp,doc,zip,ppt,sam|}\\"" href=\\""/doc/cdrls/A0$2/$3\\"">$3</a>""
		],
		""description"": ""Insert href for CDRLs""
	},

	""FLDR"":{
		""scope"": ""html"",
		""prefix"": ""fldr"",
		""body"": [
			""<div class=\\""pkg\\""><h3><strong>$1</strong></h3>"",
			""\\t<div class=\\""pkg-body\\"">"",
			""\\t\\t<!-- CDRL PLACEHOLDER -->"",
			""\\t</div>"",
			""</div>""
		],
		""description"": ""Creates a new 'folder'""
	}
}

```
Steps to reproduce:
1 - create a new text file and chose html as the language.
2 - type cdrl  & press [tab] -- Snippet is displayed
3 - press [tab] on 1st placeholder to select pdf.
4 - type 01 & press [tab] to move to 3rd placeholder
5 - type test1 and press [tab] then [enter] to go to new line.

6 - repeat steps 2 - 4.  Must enter a second tab to move to 3rd placeholder

If you repeat this process again but use ""02"" instead of ""01"" it will work fine, unless you have used 02 before.

This wasn't an issue in the May or June 2023 release, but started during the July 2023 release.  I verified using the insiders version with no extentions loaded.

Just to note I have folders named A001 - A047 that have new files added monthly so I use this snippet often.





VS Code version: Code - Insiders 1.81.0-insider (9800cf6dd6bf4634889d60720ef46a400f3a7298, 2023-07-28T12:08:04.472Z)
OS version: Windows_NT x64 10.0.19043
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz (8 x 3392)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: unavailable_off<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: unavailable_off<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: unavailable_off<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|31.92GB (20.75GB free)|
|Process Argv|--crash-reporter-id be61bc57-8ced-40aa-bcc2-ba594673b68d|
|Screen Reader|no|
|VM|0%|
</details>Extensions: none<details>
<summary>A/B Experiments</summary>

```
vsliv695:30137379
vsins829:30139715
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
pythontb:30258533
pythonptprofiler:30281269
vshan820:30294714
vscod805:30301674
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30404738
py29gd2263:30784851
vsclangdf:30492506
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30618038
2i9eh265:30646982
showlangstatbar:30737417
24365598:30687740
pythonfmttext:30716741
pythoncmvfstr:30726892
fixshowwlkth:30771523
hideindicator:30766887
pythongtdpath:30726887
i26e3531:30792625
gsofa:30797620
pythonnosmt12:30779711
pythonidxpt:30768918
pythonnoceb:30776497
copilotsettingc:30767685
e537b577:30772214
h0f32768:30792099
asynctokenver:30799129
dsvsc013:30777762
dsvsc014:30777825
diffeditorv2:30786206

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-28 10:57:37,question,not executing code,"Type: <b>Bug</b>

please make it correct
sometimes my c program is compiled and executed but sometimes it dont neither compiled and executed


VS Code version: Code 1.80.2 (2ccd690cbff1569e4a83d7c43d45101f817401dc, 2023-07-27T20:40:28.909Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i5-1240P (16 x 2112)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (8.13GB free)|
|Process Argv|--crash-reporter-id 8e9450ea-3bf5-452f-a58b-bb9d7be856e5|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (5)</summary>

Extension|Author (truncated)|Version
---|---|---
node-snippets|chr|1.3.3
vscode-eslint|dba|2.4.2
code-runner|for|0.12.0
live-server-preview|neg|0.1.4
JavaScriptSnippets|xab|1.8.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263cf:30335440
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyonecf:30548226
2e4cg342:30602488
89544117:30613380
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30785052
pythongtdpath:30769146
i26e3531:30792625
pythonnosmt12:30797651
pythonnoceb:30797650
e537b577:30795824
dsvsc013:30795093
dsvsc014:30797589

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-24 03:14:44,question,Can we activate vs code extension through activation event by reading url from particular file,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 
- OS Version: 

Steps to Reproduce:

1. We a config file inside folder .git  
2. we need to read the url inside that file and activate the extension
"
microsoft/vscode,2023-07-22 08:44:11,question,Click on file tab shows folder of file,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Hey Guys,
good job but I'm missing the use case of the subject:

Maybe on the pane ""git"" is open. I continue to code and want to check other files of one active file.
So I would like to click on the tab of the file and then the file-pane should open and the active folder is the one I clicked on.
Maybe it makes sense to offer this feature as an option and to explain it with clicked the first time on it ?

Best Robert"
microsoft/vscode,2023-07-19 23:20:19,question,Tabs showing green line above them.,"
![ProblemWithVSCode](https://github.com/microsoft/vscode/assets/83024106/8aac3a00-ac62-4365-8af5-a9216c4553b3)
<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No 

This occurs regardless of whether all the extensions are disabled. I don't think it's an extension issue.

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.80.1
- OS Version: 10.0.22621 Build 22621
- Microsoft Windows 11 Home


Steps to Reproduce:
I don't know what caused it. I just opened it today and it looked like this now."
microsoft/vscode,2023-07-19 08:41:33,question,MongoDB Atlas,"I plan to work on a project in GitHub codespaces.
However, I cannot find any good documentation on how to connect an Express.js application to Mongodb Atlas.
Can anyone help?


Version: 1.80.1
Commit: 74f6148eb9ea00507ec113ec51c489d6ffb4b771
User Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36
Embedder: codespaces

<!-- generated by web issue reporter -->"
microsoft/vscode,2023-07-18 20:24:32,question,program not running ,"Type: <b>Bug</b>

showing bellow erorr again and again:
c:/mingw/bin/../lib/gcc/mingw32/6.3.0/../../../libmingw32.a(main.o):(.text.startup+0xa0): undefined reference to `WinMain@16'
collect2.exe: error: ld returned 1 exit status

VS Code version: Code 1.80.1 (74f6148eb9ea00507ec113ec51c489d6ffb4b771, 2023-07-12T17:22:07.651Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i5-1240P (16 x 2112)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.71GB (7.13GB free)|
|Process Argv|--crash-reporter-id 9ab42a03-3f6e-4d15-a0d2-495bc5fbc45a|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (13)</summary>

Extension|Author (truncated)|Version
---|---|---
exe-runner|bra|0.2.1
dscodegpt|Dan|2.1.14
code-runner|for|0.12.0
python|ms-|2023.12.0
jupyter|ms-|2023.6.1101941928
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
cmake-tools|ms-|1.14.34
cpptools-extension-pack|ms-|1.3.0
cmake|twx|0.0.17
vscode-lldb|vad|1.9.2

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492:30256859
vstes627:30244334
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
89544117:30613380
showlangstatbar:30737416
vsctsb:30748421
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
hideindicator:30785051
pythongtdpath:30769146
i26e3531:30792625
pythonnosm12tcf:30779713
pythonidxpt:30784022
pythonnoceb:30776495
e537b577:30786199
h0f32768:30792100
dsvsc013cf:30789518

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-18 07:18:27,question,Error comes node.jc file not found ,"Type: <b>Bug</b>

#include <isotream?

using namespace std;

int main ()

{count << 5 + 2 << endl;
    return 0; }

i am a beginner i start code c++ and save this file with cpp format but when i got to run file error come node.jc not found

VS Code version: Code 1.80.1 (74f6148eb9ea00507ec113ec51c489d6ffb4b771, 2023-07-12T17:22:07.651Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 7 3700X 8-Core Processor              (16 x 3593)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.95GB (8.25GB free)|
|Process Argv|--crash-reporter-id 1caba4ac-3bc7-4895-b129-6d3213830191|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (4)</summary>

Extension|Author (truncated)|Version
---|---|---
cmake-tools|ms-|1.14.34
cpptools|ms-|1.16.3
cpptools-extension-pack|ms-|1.3.0
cmake|twx|0.0.17

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931cf:30280410
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30792226
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30610678
3biah626:30602489
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
2i9eh265:30646982
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
03d35959:30757346
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30785052
pythongtdpath:30769146
bgfeh915:30780428
pythonnosmt12:30779714
pythonidxpt:30784022
pythonnocebcf:30776496
e537b577:30786199
dsvsc013:30789517
dsvsc014:30791935
cmakesidepanelv2:30779593

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-17 15:10:36,question,import pptx not working,"
Type: <b>Feature Request</b>

Why can't I install pptx on VSCODE to do my powerpoint presentations


VS Code version: Code 1.80.1 (74f6148eb9ea00507ec113ec51c489d6ffb4b771, 2023-07-12T17:22:07.651Z)
OS version: Windows_NT x64 10.0.19045
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-15 16:09:40,question,Explorer has disappeared and the shortcut key (Ctrl+Shift+E) in View menu is also gone,"Explorer has disappeared and the shortcut key (Ctrl+Shift+E) in View menu is also gone as shown below. 
<img width=""357"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/21034326/1da74e94-2c2a-40ae-9cec-fe2859317653"">
The context menu (mouse right click) of the Activity Bar also does not have the Explorer option. 
<img width=""269"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/21034326/30bc6daa-84e2-4a74-a242-db0edc36971a"">

<img width=""319"" alt=""image"" src=""https://github.com/microsoft/vscode/assets/21034326/82e6e856-9616-42e0-a4bf-d1467bb05db1"">

Please advise how I can get the Explorer back?"
microsoft/vscode,2023-07-14 23:20:44,question,"javascript, websocket","Type: <b>Bug</b>

Hello,

how are you? i'am am programmer and i am having a issue what i can't solve on my own anymore. It's probably too offtopic and i still count good people helping a vegan out.

I logic to work with code, excellent software, no problems at all, working on Linux Lite 6.4 Ubuntu. I do program a computer game, browser based, java backend and javascript frontend, webgl for rendering.

Right now i'am writing the interface and having a issue with one of the fundamental functions of javascript. Hopefully you have some experience with websockets, if not then i might have to ask google next.

Usualy the payload-length is calculated by the send method of the websocket object. Unfortunetily the byte representation of the payload length does never match the length of the submitted string.

You at microsoft are very smart people, i like you alot, and if you have some idea how to solve that, i would very appreciate that. For a experienced programmer the string is sent by the index.js and received by the class transmissions, building the websocket there before creating a seperate object for it. Everything else is working fine. 

It is that project: https://github.com/indetale-git/helloworld.git

If my imagination work, than thank you in advance bill.

Kind regards,
indetale
marcel otte

VS Code version: Code 1.80.1 (74f6148eb9ea00507ec113ec51c489d6ffb4b771, 2023-07-12T17:22:25.257Z)
OS version: Linux x64 5.15.0-76-generic
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5 CPU       M 460  @ 2.53GHz (4 x 2534)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: disabled_software<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: disabled_off|
|Load (avg)|0, 1, 1|
|Memory (System)|7.43GB (5.57GB free)|
|Process Argv|--crash-reporter-id 64f67b50-832e-4253-befc-3cd3ea0198a8|
|Screen Reader|no|
|VM|0%|
|DESKTOP_SESSION|xfce|
|XDG_CURRENT_DESKTOP|XFCE|
|XDG_SESSION_DESKTOP|xfce|
|XDG_SESSION_TYPE|x11|
</details><details><summary>Extensions (2)</summary>

Extension|Author (truncated)|Version
---|---|---
java|red|1.20.0
vscode-java-debug|vsc|0.52.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263cf:30789497
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
2e4cg342:30602488
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
hideindicator:30785051
pythongtdpath:30769146
bgfeh915:30780428
pythonnosmt12:30779714
pythonidxpt:30784022
pythonnoceb:30776495
e537b577:30786199
dsvsc013cf:30789518

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-14 03:12:34,question,Task definition does not work,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 
- OS Version: 

Steps to Reproduce:

1. 
2. 
"
microsoft/vscode,2023-07-13 10:33:22,question,"setting ""workbench.editorAssociations"" not work","Type: <b>Bug</b>

I just installed ""Office Viewer"" Plugin from market,  

after setting  ""workbench.editorAssociations"" ，“*.md”'s first use plugin，it not work。 

So... I try to setting “*.md” to the original vscode preview，and it not work，

everytime i open a markdown file，always open in raw editor......everything can not change that

VS Code version: Code 1.80.0 (660393deaaa6d1996740ff4880f1bad43768c814, 2023-07-04T15:06:02.407Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 7 4800H with Radeon Graphics          (16 x 2895)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.37GB (5.50GB free)|
|Process Argv|E:\\\\笔记本\\\\Office\\\\Word.md --crash-reporter-id 14045251-9976-465b-b795-5ae7eab81d84|
|Screen Reader|no|
|VM|44%|
</details><details><summary>Extensions (39)</summary>

Extension|Author (truncated)|Version
---|---|---
better-comments|aar|3.0.2
shell|bbe|0.3.0
doxdocgen|csc|1.4.0
vscode-office|cwe|3.1.6
gitlens|eam|14.0.1
prettier-vscode|esb|9.19.0
code-runner|for|0.12.0
latex-workshop|Jam|9.12.3
better-cpp-syntax|jef|1.17.2
kite|kit|0.147.0
rainbow-csv|mec|3.7.0
vscode-language-pack-zh-hans|MS-|1.80.2023071209
csharp|ms-|1.26.0
anaconda-extension-pack|ms-|1.0.1
isort|ms-|2023.10.1
python|ms-|2023.12.0
vscode-pylance|ms-|2023.7.20
jupyter|ms-|2023.6.1101941928
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.299.0
remote-ssh|ms-|0.102.0
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.80.2
cmake-tools|ms-|1.14.34
cpptools|ms-|1.16.3
cpptools-extension-pack|ms-|1.3.0
remote-explorer|ms-|0.4.1
java|red|1.20.0
vscode-yaml|red|1.13.0
latex-support|tor|3.10.0
cmake|twx|0.0.17
vscode-java-debug|vsc|0.52.0
vscode-java-dependency|vsc|0.23.0
vscode-java-pack|vsc|0.25.12
vscode-java-test|vsc|0.39.0
vscode-maven|vsc|0.41.0

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscorecescf:30445987
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30610679
282f8724:30602487
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
2i9eh265:30646982
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
hideindicator:30785051
pythongtdpath:30769146
bgfeh915:30780428
pythonnosmt12:30779714
pythonidxpt:30784022
pythonnocebcf:30776496
e537b577:30786199
cmakesidepanelv2:30779593

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-12 12:59:46,question,Frequently closes itself,"Type: <b>Performance Issue</b>

I'm trying to build a website, writing some html, css files, and it keeps on closing.

VS Code version: Code 1.80.0 (660393deaaa6d1996740ff4880f1bad43768c814, 2023-07-04T15:06:02.407Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz (8 x 1190)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.78GB (2.54GB free)|
|Process Argv|--crash-reporter-id 496058d9-381b-42de-b2fb-fc9b00570406|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    0	    94	  7112	code main
    0	    27	  1180	   crashpad-handler
    0	    87	  3564	window [2] (Issue Reporter)
    0	   160	  8280	extensionHost [1]
    0	    79	 15124	     electron-nodejs (""C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node ""c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\extensions\\json-language-features\\server\\dist\\node\\jsonServerMain"" --node-ipc --clientProcessId=8280)
    0	   124	 10832	shared-process
    0	   182	 13840	   gpu-process
    0	    76	 14980	ptyHost
    0	    79	 15196	fileWatcher [1]
    0	   193	 15680	window [1] (detect.html - Untitled (Workspace) - Visual Studio Code)
    0	    43	 16280	   utility-network-service
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (detect.html - Untitled (Workspace) - Visual Studio Code)
|    Folder (NewFolder): 8 files
|      File types: py(3) pyc(2) ipynb(1) txt(1)
|      Conf files:
|    Folder (CropDiseaseDetector-Hustlers): 13 files
|      File types: html(8) ipynb(1) js(1) css(1)
|      Conf files:;
```

</details>
<details><summary>Extensions (30)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-django|bat|1.10.0
django-html|bib|1.3.0
vscode-intelephense-client|bme|1.9.5
doxdocgen|csc|1.4.0
vscode-html-css|ecm|1.13.1
code-runner|for|0.12.0
gc-excelviewer|Gra|4.2.57
better-cpp-syntax|jef|1.17.2
vscode-django-support|jun|1.0.23
vscode-docker|ms-|1.25.2
isort|ms-|2023.10.0
python|ms-|2023.12.0
vscode-pylance|ms-|2023.7.10
jupyter|ms-|2023.6.1101941928
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.17
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.299.0
remote-ssh|ms-|0.102.0
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.80.2
cmake-tools|ms-|1.14.34
cpptools|ms-|1.16.3
cpptools-extension-pack|ms-|1.3.0
remote-explorer|ms-|0.4.1
material-icon-theme|PKi|4.28.0
LiveServer|rit|5.7.9
html5-boilerplate|sid|1.1.1
cmake|twx|0.0.17

(2 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931cf:30280410
vshan820:30294714
vstes263cf:30335440
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
vscaat:30438848
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
3biah626:30602489
pyind779:30671433
f6dab269:30613381
pythonsymbol12:30671437
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
03d35959:30757346
57b77579:30736110
pythonfmttext:30731395
pythoncmv:30756943
f8hc8238:30694864
fixshowwlkth:30771522
showindicator:30785052
pythongtdpath:30769146
bgfeh915:30780428
pythonnosmt12:30779714
pythonidxpt:30784022
pythonnocebcf:30776496
h7j2d465:30786200

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-11 05:27:16,question,"i3wm vscode cannot open appimage formate browser like edge,chrome","when i sync github, vscode just have open browser , but my system not have install browser, i use appimage format browser.
i cannot load vscode sync.

or i install firefox-esr, and it can not open too, it always jump to new tab,"
microsoft/vscode,2023-07-08 15:11:35,question,pip can't be installed,"Type: <b>Bug</b>

I can't able to install pip package in terminal. I have tried several ways but failed.

VS Code version: Code 1.80.0 (660393deaaa6d1996740ff4880f1bad43768c814, 2023-07-04T15:06:02.407Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 5 5500U with Radeon Graphics          (12 x 2096)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.33GB (1.42GB free)|
|Process Argv|--crash-reporter-id a876346b-064e-4bde-b064-bdd2003e0923|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (2)</summary>

Extension|Author (truncated)|Version
---|---|---
python|ms-|2023.12.0
vscode-pylance|ms-|2023.7.10


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263cf:30784848
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
2i9eh265:30646982
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
a2ce3375:30757347
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
showindicator:30785052
pythongtdpath:30769146
bgfeh915:30780428
pythonnosmt12:30779714
pythonidxpt:30784022
pythonnocebcf:30776496
cmakestatusbarv2:30779594

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-07 18:48:07,question,TS Server fatal error:  UNC host '172.25.30.27' access is not allowed,"
Type: <b>Bug</b>

❗️❗️❗️ Please fill in the sections below to help us diagnose the issue ❗️❗️❗️

**TypeScript Version:** 5.0.4

**Steps to reproduce crash**

1.
2.
3.

**TS Server Log**

❗️ Server logging disabled. To help us fix crashes like this, please enable logging by setting:

```json
""typescript.tsserver.log"": ""verbose""
```

After enabling this setting, future crash reports will include the server log.

**TS Server Error Stack**

Server: `semantic`

```
Error [ERR_UNC_HOST_NOT_ALLOWED]: UNC host '172.25.30.27' access is not allowed
    at Object.watchFile (node:fs:2342:14)
    at fsWatchFileWorker (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8594:11)
    at c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8243:15
    at createSingleWatcherPerName (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:7764:16)
    at pollingWatchFile (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8238:12)
    at watchFile2 (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8073:16)
    at watchMissingFileSystemEntry (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8331:14)
    at fsWatchHandlingExistenceOnHost (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8262:72)
    at c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8252:15
    at createSingleWatcherPerName (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:7764:16)
    at fsWatch (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8247:12)
    at Object.watchFile2 [as watchFile] (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:8098:16)
    at watchFile (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:116881:67)
    at Object.watchFile (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:116900:284)
    at c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:174627:164
    at _ProjectService.forEachConfigFileLocation (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:174677:22)
    at _ProjectService.startWatchingConfigFilesForInferredProjectRoot (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:174620:10)
    at InferredProject2.addRoot (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:172893:25)
    at _ProjectService.assignOrphanScriptInfoToInferredProject (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:174418:13)
    at _ProjectService.assignProjectToOpenedScriptInfo (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:176043:12)
    at c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:176273:64
    at flatMap (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:2556:17)
    at _ProjectService.applyChangesInOpenFiles (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:176273:24)
    at updateOpen (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:177418:29)
    at c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:179985:69
    at IpcIOSession.executeWithRequestId (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:179977:14)
    at IpcIOSession.executeCommand (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:179985:29)
    at IpcIOSession.onMessage (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:180027:51)
    at process.<anonymous> (c:\\Program Files\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js:181594:14)
    at process.emit (node:events:513:28)
    at emit (node:internal/child_process:958:14)
    at process.processTicksAndRejections (node:internal/process/task_queues:84:21)
```

VS Code version: Code 1.78.2 (b3e4e68a0bc097f0ae7907b217c1119af9e03435, 2023-05-10T14:39:26.248Z)
OS version: Windows_NT x64 10.0.22621
Modes:
Sandboxed: Yes

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i7-1260P (16 x 2496)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|31.70GB (9.50GB free)|
|Process Argv|--crash-reporter-id d532a383-f5a0-4ea2-99af-58b07f7daa19|
|Screen Reader|yes|
|VM|0%|
</details><details><summary>Extensions (10)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-intelephense-client|bme|1.9.5
ini-for-vscode|Dav|0.0.4
vscode-html-css|ecm|1.13.1
inifmt|lkr|0.1.5
vscode-autohotkey-plus-plus|mar|3.3.2
nc-gcode|ML2|0.14.1
sqltools|mtx|0.28.0
log-booster|nvi|0.0.7
vscode-powerquery|Pow|0.1.53
vscode-xml|red|0.25.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30773603
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
03d35959:30757346
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
pythongtdpath:30769146
dh2dc718:30770000
pythonidxpt:30772539
pythondjangotscf:30772537
pythonnoceb:30773526
e537b577:30772215

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-06 17:06:26,question,#include <cs50.h>,"ADD ISSUE DESCRIPTION HERE

Version: 1.79.2
Commit: 695af097c7bd098fbf017ce3ac85e09bbc5dda06
User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36
Embedder: codespaces

<!-- generated by web issue reporter -->"
microsoft/vscode,2023-07-04 14:44:14,question,tkinter,"Type: <b>Feature Request</b>

why is not defined Tk()?


VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.19045
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-03 14:56:01,question,Intellisense font is incredibly small.,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: **Yes**

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: `1.79.2`
- OS Version: Fedora 38 (`6.3.8-200.fc38.x86_64`)
- Device: Framework Laptop (2256x1504)

Steps to Reproduce:

1. Open Vscode 
2. Write some code such that vscode can provide a suggestion
3. Press ctrl + space to open intellisense
4. Observe the Intellisense font is incredibly small

![Screenshot from 2023-07-03 09-52-40](https://github.com/microsoft/vscode/assets/4002969/1df4c5ba-1b21-4fee-900e-2077fcded0d6)

"
microsoft/vscode,2023-07-02 08:11:10,question,My terminal is splitting a file name into seperated parts and then showing directory not found.,"Type: <b>Bug</b>

Say my file name is Hello world.c . When i run it on my terminal its showing :-
gcc.exe: error: Hello: No such file or directory
gcc.exe: error: world.c: No such file or directory
gcc.exe: error: world: No such file or directory
gcc.exe: fatal error: no input files
compilation terminated.
what to do 

VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-6500U CPU @ 2.50GHz (4 x 2592)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.89GB (1.60GB free)|
|Process Argv|--crash-reporter-id cd1c98e5-0ad5-411a-a3b0-5fa596baad88|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (5)</summary>

Extension|Author (truncated)|Version
---|---|---
code-runner|for|0.12.0
cmake-tools|ms-|1.14.34
cpptools|ms-|1.16.3
cpptools-extension-pack|ms-|1.3.0
cmake|twx|0.0.17

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931:30280409
vshan820:30294714
vstes263cf:30335440
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
py29gd2263:30776702
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vsccc:30610678
2e4cg342:30602488
pyind779:30671433
f6dab269:30613381
pythonsymbol12:30671437
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
a2ce3375:30757347
ecj1e332:30736112
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30771522
pythongtdpath:30769146
bgfeh915:30780428
pythonnosm12tcf:30779713
pythonidxptcf:30772540
pythonnocebcf:30776496
e537b577:30772215

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-07-01 13:57:45,question,"Commande ""./hello"" ne fonctionne pas","Good morning,

I need support, because when i type de commande ""./hello"", the notification i receive is ""permission denied"". Please help me."
microsoft/vscode,2023-06-30 05:32:05,question,Add a method to switch between open windows,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
Developers often need to keep multiple VS Code windows open at the same time.

Providing a method to switch between the open windows would be greatly useful.

The method can be:

- A UI to show open windows (e.g. like Open Editors)
- A Keyboard shortcut"
microsoft/vscode,2023-06-29 07:20:44,question,Cant see terminal text,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 
- OS Version:
![image](https://github.com/microsoft/vscode/assets/28706220/96b9666e-be53-4d80-a31d-04be0a50b457) 

What is happening?
It's been a week haha. I've tried all kinds of terminal but same issue.
![image](https://github.com/microsoft/vscode/assets/28706220/a800c5dc-98e4-44c9-8f33-9b40fea6ba42)
"
microsoft/vscode,2023-06-28 19:15:29,question,Need a quick way to run or debug the last test I ran,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
I often repeatedly run or debug a test as I work on it. I'd like a quick way to run or debug the last test I ran.
Ideally something I can assign to a single keystroke. 
Currently, I have to find the test's first line in my code, in the testing panel or in test results."
microsoft/vscode,2023-06-28 15:48:35,question,can not run any code on vs code,"Type: <b>Performance Issue</b>

I am new to vs code and i can not run any of my code on vs code. so please help me out as this is so irritating.

VS Code version: Code 1.79.2 (Universal) (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:58:52.392Z)
OS version: Darwin arm64 22.1.0
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Apple M1 (8 x 24)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>metal: disabled_off<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|1, 2, 2|
|Memory (System)|8.00GB (0.12GB free)|
|Process Argv|--crash-reporter-id 7a18136b-e19f-4e1f-b9a7-cc052e7734ec|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
   14	   139	  1960	code main
    1	    66	  1963	   gpu-process
    0	    33	  1965	   utility-network-service
    0	   246	  1966	window [1] (main.c — pythonn.py)
    0	    49	  1976	ptyHost
    0	    90	  1977	shared-process
    0	     0	  2021	     /bin/ps -ax -o pid=,ppid=,pcpu=,pmem=,command=
    0	    49	  1978	fileWatcher [1]
    0	   115	  1979	extensionHost [1]
    0	    25	  1983	     /Users/rakeshkumarjagdev/.vscode/extensions/ms-vscode.cpptools-1.16.3-darwin-arm64/bin/cpptools
    0	    98	  2014	window [2] (Issue Reporter)
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (main.c — pythonn.py)
|    Folder (pythonn.py): 12 files
|      File types: json(2) c(1) plist(1) python(1)
|      Conf files: launch.json(1) tasks.json(1);
```

</details>
<details><summary>Extensions (7)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-html-css|ecm|1.13.1
code-runner|for|0.12.0
cmake-tools|ms-|1.14.33
cpptools|ms-|1.16.3
cpptools-extension-pack|ms-|1.3.0
LiveServer|rit|5.7.9
cmake|twx|0.0.17

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383:30185418
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30776702
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30610679
282f8724:30602487
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
2i9eh265:30646982
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
03d35959:30757346
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
hideindicator:30766889
pythongtdpath:30769146
dh2dc718:30776458
pythonidxpt:30772539
pythondjangotscf:30772537
pythonnoceb:30776495

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-06-26 18:46:42,question,VSCode JS issue: JSDoc Intellisense behavior in array variables are weird after version 1.79.0+,"Type: <b>Bug</b>

```
/**
   @type {[{a: String, b: String}]}
*/
let arr = [
   {
       a: ""abc"",
       b: ""def""
   },
   {
        //intelliSense not working here
   }
]
```

It works normally for the first element, but start to show intellisense of array (at, reduce, ...) 
instead of normal behavior (a, b)

It works fine at Version 1.78.1

VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.22621
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|12th Gen Intel(R) Core(TM) i9-12900F (24 x 2419)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|31.86GB (16.80GB free)|
|Process Argv|--crash-reporter-id ee865e3c-17be-4371-91aa-080e6ea972ea|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (3)</summary>

Extension|Author (truncated)|Version
---|---|---
gitlens|eam|14.0.1
git-graph|mhu|1.30.0
custom-code-template|yin|0.0.2


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931:30280409
vshan820:30294714
vstes263:30335439
vscoreces:30445986
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593cf:30376535
pythonvs932:30410667
py29gd2263:30773603
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30610679
3biah626:30602489
pyind779:30671433
f6dab269:30613381
pythonsymbol12:30671437
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
a2ce3375:30757347
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
showindicator:30766890
pythongtdpath:30769146
gsof2:30774497
dh2dc718:30770000
pythonidxpt:30772539
pythondjangotscf:30772537

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-06-24 05:27:02,question,Intellisense for MongoDB doesnt working!,"Type: <b>Bug</b>

Well i am working on project using MongoDB/Atlas, and i created regular model and controller for it. It was working in model..but when i started typing functions in controller it stops..also i tried everything like: updates for VSC, extensions, deleting models, packages and restarting VSC. Still doesnt working please help me!

VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.19045
Modes:


<!-- generated by issue reporter -->"
microsoft/vscode,2023-06-23 17:36:34,question,"Add keyboard shortcut for ""Select Language Mode""","<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->

The little thing in the bottom-right corner where you can select language mode would be a useful candidate for adding a keyboard shortcut. It doesn't even have to have a real shortcut by default, but in my case I would find it very useful to have the ability to assign a shortcut to it.

Here's an example workflow where it would come in handy. (I find myself doing this a lot and wish there were a way to add a shortcut.)

1. Graph some code from somewhere (a SQL query from Slack, or a GraphQL query from the Network tab, or some YAML printed from a debug log) and copy-paste it into a new tab in VSCode.
2. VSCode doesn't correctly figure out what language the code is in.
3. Go to the bottom right corner, click the (sometimes very small) button to `Select Language Mode`. (This is the part I want a keyboard shortcut for.)
4. Select the correct language.
5. Hit `alt-shift-F` to format the code.

And you're done. Basically these steps allow you to take code from some random source, where it's probably unformatted and may not be syntax-highlighted, and allow you to format & inspect it in VSCode. If Step 3 above were able to be automated via a keyboard shortcut, it would make this process quite a bit more ergonomic.

What do you think? If there's already a way to do this, I'm open to hearing it. As of right now, I open `Keyboard Shortcuts` and search for `Select Language Mode` but nothing pops up, so it appears that a new keyboard shortcut needs to be added."
microsoft/vscode,2023-06-22 21:07:41,question,Problem with VSC,"
![img_20230622_205601](https://github.com/microsoft/vscode/assets/122379822/1bf94806-8546-4798-bc78-128b265f5490)
<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 
- OS Version: 

Steps to Reproduce:

1. Hello, I have a problem with VSC. Today I saw that when I write code in React, plugins turn off. I will not format the code well, the program does not tell me the names of components when writing the code. Thank you in advance for your help
2. 
![img_20230622_211443](https://github.com/microsoft/vscode/assets/122379822/99ad3ded-895c-4c67-b0d7-eb10b0612932)
![img_20230622_205601](https://github.com/microsoft/vscode/assets/122379822/153d9ee4-be9e-4a97-944b-f08ca2c98277)

"
microsoft/vscode,2023-06-22 10:40:33,question,Removed keybinding not trigger global hotkey,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.79.2
- OS Version: win 11

Steps to Reproduce:

1. Remove keybinding `f1`

![image](https://github.com/microsoft/vscode/assets/18096089/9f781ae2-74aa-41e9-8811-7d938d984514)

2. Press `f1` to trigger my global screenshot hotkey (snipaste app default hotkey), but it is not work

![keyboard troubleshooting](https://github.com/microsoft/vscode/assets/18096089/036dc094-2550-46e0-ae00-e42fc620b594)

"
microsoft/vscode,2023-06-21 09:51:05,question,AddEventListener not calling function,"Type: <b>Bug</b>

I am currently doing a tutorial with a game logic. The game has buttons which are meant to call on specific functions however upon writing:

...Btn.addEventlistener('click', function) 

function remains blank in color indictacting it has not been declared

VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i5-7200U CPU @ 2.50GHz (4 x 2712)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.85GB (3.59GB free)|
|Process Argv|--crash-reporter-id 502cda83-bb40-405c-98b6-9a6402af3c74|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (42)</summary>

Extension|Author (truncated)|Version
---|---|---
project-manager|ale|12.7.0
LinkCheckMD|bla|0.3.1
gitignore|cod|0.9.0
vscode-markdownlint|Dav|0.51.0
vscode-eslint|dba|2.4.0
docs-article-templates|doc|1.0.1
docs-authoring-pack|doc|1.0.0
docs-build|doc|0.4.1
docs-images|doc|1.0.0
docs-linting|doc|0.0.13
docs-markdown|doc|1.0.1
docs-metadata|doc|1.0.9
docs-preview|doc|1.0.2
docs-scaffolding|doc|0.0.17
docs-yaml|doc|1.0.0
git-extension-pack|don|0.1.3
githistory|don|0.6.20
es7-react-js-snippets|dsz|4.4.3
gitlens|eam|14.0.1
prettier-vscode|esb|9.15.0
auto-close-tag|for|0.5.14
auto-rename-tag|for|0.1.10
dotenv|mik|1.0.1
vscode-edge-devtools|ms-|2.1.2
python|ms-|2023.10.1
vscode-pylance|ms-|2023.6.20
jupyter|ms-|2023.5.1001582324
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.15
cpptools|ms-|1.15.4
vsliveshare|ms-|1.0.5873
vscode-react-native|msj|1.11.0
material-icon-theme|PKi|4.28.0
vscode-yaml|red|1.13.0
LiveServer|rit|5.7.9
easysass|spo|0.0.6
code-spell-checker|str|2.20.5
vscode-icons|vsc|12.4.0
quokka-vscode|Wal|1.0.546
JavaScriptSnippets|xab|1.8.0
material-theme|zhu|3.15.17
vscode-open-in-github|ziy|1.3.6


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368cf:30146710
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vswsl492cf:30256860
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdc:30486549
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
pyind779:30671433
f6dab269:30613381
pythonsymbol12:30671437
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
03d35959:30757346
pythonfmttext:30731395
pythoncmv:30756943
fixshowwlkth:30771522
pythongtdpath:30769146
bgfeh915:30769767
dh2dc718:30770000
pythonidxpt:30772539
pythondjangotscf:30772537

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-06-18 14:38:55,question,npm start is not starting my react app again i dont know if i mistakenly delete something,"Type: <b>Performance Issue</b>

help me restore the deleted files on my project because npm start is not starting my application again.

VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Pentium(R) CPU  N3710  @ 1.60GHz (4 x 1600)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|3.85GB (0.65GB free)|
|Process Argv|--crash-reporter-id e69cf78d-06f6-44cc-993a-c6fd4a9d96f1|
|Screen Reader|no|
|VM|0%|
</details><details>
<summary>Process Info</summary>

```
CPU %	Mem MB	   PID	Process
    3	    82	  2332	code main
    0	    30	  7408	ptyHost
    0	     6	  7232	     console-window-host (Windows internal process)
    0	    69	 10352	     C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -noexit -command ""try { . \\""c:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\contrib\\terminal\\browser\\media\\shellIntegration.ps1\\"" } catch {}""
    0	     3	  7524	   crashpad-handler
    0	    42	  7600	shared-process
    3	    85	  8300	window [4] (Issue Reporter)
    0	   115	  9904	   gpu-process
    0	    61	 10656	extensionHost [3]
    0	    58	  2584	     electron-nodejs (""C:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node --max-old-space-size=3072 ""c:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js"" --serverMode partialSemantic --useInferredProjectPerProjectRoot --disableAutomaticTypingAcquisition --cancellationPipeName C:\\Users\\DAFE\\AppData\\Local\\Temp\\vscode-typescript\\2e05939c857e1e12a620\\tscancellation-c6fb6f8df58661951fc6.tmp* --locale en --noGetErrOnBackgroundUpdate --validateDefaultNpmLocation --useNodeIpc)
    0	    58	  8936	     electron-nodejs (""C:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node ""c:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\extensions\\json-language-features\\server\\dist\\node\\jsonServerMain"" --node-ipc --clientProcessId=10656)
    0	   104	 12104	     electron-nodejs (""C:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node --max-old-space-size=3072 ""c:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\extensions\\node_modules\\typescript\\lib\\tsserver.js"" --useInferredProjectPerProjectRoot --enableTelemetry --cancellationPipeName C:\\Users\\DAFE\\AppData\\Local\\Temp\\vscode-typescript\\2e05939c857e1e12a620\\tscancellation-0050db3ad7f4a29fd639.tmp* --locale en --noGetErrOnBackgroundUpdate --validateDefaultNpmLocation --useNodeIpc)
    0	    39	 10900	       electron-nodejs (""C:\\Users\\DAFE\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe"" --ms-enable-electron-run-as-node ""c:/Users/DAFE/AppData/Local/Programs/Microsoft VS Code/resources/app/extensions/node_modules/typescript/lib/typingsInstaller.js"" --globalTypingsCacheLocation C:/Users/DAFE/AppData/Local/Microsoft/TypeScript/5.1 --enableTelemetry --typesMapLocation ""c:/Users/DAFE/AppData/Local/Programs/Microsoft VS Code/resources/app/extensions/node_modules/typescript/lib/typesMap.json"" --validateDefaultNpmLocation)
    0	    12	 12040	   utility-network-service
    0	   153	 12620	window [3] (Home.jsx - ARC.JS (Workspace) - Visual Studio Code)
    0	    24	 12948	fileWatcher [3]
```

</details>
<details>
<summary>Workspace Info</summary>

```
|  Window (Home.jsx - ARC.JS (Workspace) - Visual Studio Code)
|    Folder (ARC.JS): 131 files
|      File types: png(23) css(15) jpg(15) jsx(15) js(7) json(5) webp(5)
|                  txt(3) map(3) ico(2)
|      Conf files: package.json(1);
```

</details>
<details><summary>Extensions (4)</summary>

Extension|Author (truncated)|Version
---|---|---
dart-code|Dar|3.66.0
flutter|Dar|3.66.0
vscode-language-babel|mgm|0.0.39
vscode-react-native|msj|1.11.0


</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vsdfh931:30280409
vshan820:30294714
vstes263:30335439
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
vscccc:30610679
282f8724:30602487
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
03d35959:30757346
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixhidewlkth:30730051
hideindicator:30766889
pythongtdpath:30769146
e440d664:30770001
pythondjangots:30768919

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-06-18 12:17:46,question,Localhost Error,"Type: <b>Bug</b>

i am aways getting localhost refused to connect error on my laptop  whenever i am trying to make a html file on VS code terminal to use JAVA SCRIPT



VS Code version: Code 1.79.2 (695af097c7bd098fbf017ce3ac85e09bbc5dda06, 2023-06-14T08:57:04.379Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|Intel(R) Core(TM) i7-5600U CPU @ 2.60GHz (4 x 2594)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|7.69GB (1.81GB free)|
|Process Argv|--crash-reporter-id 6d89a0c5-7158-4824-8d2a-40596e2895f4|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (11)</summary>

Extension|Author (truncated)|Version
---|---|---
dart-code|Dar|3.66.0
isort|ms-|2023.9.11661018
python|ms-|2023.10.1
vscode-pylance|ms-|2023.6.20
jupyter|ms-|2023.5.1001582324
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.15
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
sqltools|mtx|0.27.1
material-theme|zhu|3.15.17

(1 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vslsvsres303:30308271
vserr242:30382549
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805:30301674
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012cf:30540253
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
pyind779:30671433
89544117:30613380
pythonsymbol12:30671437
a9j8j154:30646983
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
a2ce3375:30757347
pythonfmttext:30731395
pythoncmv:30756943
fixhidewlkth:30730051
hideindicator:30766889
pythongtdpath:30769146
dh2dc718:30770000
pythondjangots:30768919

```

</details>

<!-- generated by issue reporter -->"
microsoft/vscode,2023-06-16 22:46:47,question,Eu quero setar o arquivo a ser executado quando clicar em play.,"<!-- ⚠️⚠️ Do Not Delete This! feature_request_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- Please search existing issues to avoid creating duplicates. -->

<!-- Describe the feature you'd like. -->
![image](https://github.com/microsoft/vscode/assets/38570195/cf59b5a8-26a0-4278-b9e4-d68e01fd31d0)
"
microsoft/vscode,2023-06-15 13:22:34,question,bug -- File Saving Error,"<!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!-- 🕮 Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!-- 🔎 Search existing issues to avoid creating duplicates. -->
<!-- 🧪 Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!-- 💡 Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->
<!-- 🔧 Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes/No

<!-- 🪓 If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!-- 📣 Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
- VS Code Version: 1.79.1 (Universal)
- OS Version: macOS

Steps to Reproduce:

1. Save the file
2. Get error:
<img width=""447"" alt=""Screenshot 2023-06-15 at 8 20 29 AM"" src=""https://github.com/microsoft/vscode/assets/97198910/6259ea23-c93a-44bc-9a01-2ed1070f7d06"">

"
microsoft/vscode,2023-06-15 09:11:19,question,Markdown preview doesn't work,"Type: <b>Bug</b>

Step 1: Try to open any .md file.
Step 2: Try to show markdown preview by any of the available command.
Result: Markdown preview doesn't work.
Expected Result: Markdown preview should (according to vscode) work out of the box.

Things I tried: Apart from trying to use default set of commands I found on the vscode documentation and on the internet; I tried reinstalling various third party extension for markdown preview. I restarted vscode itself and my pc as well.

VS Code version: Code 1.79.1 (4cb974a7aed77a74c7813bdccd99ee0d04901215, 2023-06-12T16:14:05.102Z)
OS version: Windows_NT x64 10.0.19045
Modes:

<details>
<summary>System Info</summary>

|Item|Value|
|---|---|
|CPUs|AMD Ryzen 5 4600H with Radeon Graphics          (12 x 2994)|
|GPU Status|2d_canvas: enabled<br>canvas_oop_rasterization: disabled_off<br>direct_rendering_display_compositor: disabled_off_ok<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>opengl: enabled_on<br>rasterization: enabled<br>raw_draw: disabled_off_ok<br>video_decode: enabled<br>video_encode: enabled<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled<br>webgpu: enabled|
|Load (avg)|undefined|
|Memory (System)|15.36GB (10.63GB free)|
|Process Argv|--crash-reporter-id 59c088fe-0302-4503-ae22-25d7a3fc3048|
|Screen Reader|no|
|VM|0%|
</details><details><summary>Extensions (85)</summary>

Extension|Author (truncated)|Version
---|---|---
vscode-sqlite|ale|0.14.1
tailwind-docs|aus|2.0.0
vscode-django|bat|1.10.0
vscode-intelephense-client|bme|1.9.5
vscode-tailwindcss|bra|0.9.11
simple-react-snippets|bur|1.2.7
npm-intellisense|chr|1.4.4
path-intellisense|chr|2.8.4
doxdocgen|csc|1.4.0
dart-code|Dar|3.66.0
flutter|Dar|3.66.0
vscode-eslint|dba|2.4.0
python-environment-manager|don|1.0.4
gitlens|eam|14.0.0
vscode-html-css|ecm|1.13.1
vsc-material-theme|Equ|33.8.0
vsc-material-theme-icons|equ|2.8.0
prettier-vscode|esb|9.13.0
copilot|Git|1.89.156
vscode-pull-request-github|Git|0.66.1
gc-excelviewer|Gra|4.2.57
vscode-auto-open-markdown-preview|hnw|0.0.4
vscode-power-mode|hoo|3.0.2
ionic|Ion|1.45.4
Ionide-fsharp|Ion|7.5.4
better-cpp-syntax|jef|1.17.2
cmake-language-support-vscode|jos|0.0.9
vsc-python-indent|Kev|1.18.0
wsl-path|kgr|0.1.0
gitlab-notifications|log|0.0.8
MagicPython|mag|1.1.0
vscode-language-babel|mgm|0.0.39
document|min|2.2.1
vscode-docker|ms-|1.25.1
csharp|ms-|1.25.9
vscode-dotnet-pack|ms-|1.0.12
vscode-dotnet-runtime|ms-|1.6.0
black-formatter|ms-|2023.2.0
isort|ms-|2022.8.0
python|ms-|2023.10.1
vscode-pylance|ms-|2023.6.20
jupyter|ms-|2023.5.1001582324
jupyter-keymap|ms-|1.1.2
jupyter-renderers|ms-|1.0.15
vscode-jupyter-cell-tags|ms-|0.1.8
vscode-jupyter-slideshow|ms-|0.1.5
remote-containers|ms-|0.295.0
remote-ssh|ms-|0.102.0
remote-ssh-edit|ms-|0.86.0
remote-wsl|ms-|0.79.5
vscode-remote-extensionpack|ms-|0.24.0
cmake-tools|ms-|1.14.33
cpptools|ms-|1.15.4
cpptools-extension-pack|ms-|1.3.0
js-debug-nightly|ms-|2023.6.1315
live-server|ms-|0.4.8
powershell|ms-|2023.6.0
remote-explorer|ms-|0.4.0
remote-server|ms-|1.2.1
vscode-typescript-next|ms-|5.2.20230614
vsliveshare|ms-|1.0.5873
vscode-react-native|msj|1.11.0
sqltools|mtx|0.27.1
sqltools-driver-sqlite|mtx|0.5.0
autodocstring|njp|0.6.1
vscode-versionlens|pfl|1.5.0
gcc-md|pha|0.0.1
material-icon-theme|PKi|4.28.0
sqlite-viewer|qwt|0.2.5
r-debugger|RDe|0.5.4
LiveServer|rit|5.7.9
html5-boilerplate|sid|1.1.1
code-spell-checker|str|2.20.5
node-pack|Swe|0.1.16
vscode-djaneiro|the|1.4.2
pdf|tom|1.2.2
cmake|twx|0.0.17
intellicode-api-usage-examples|Vis|0.2.7
vscodeintellicode|Vis|1.2.30
vscodeintellicode-completions|Vis|1.0.22
vscodeintellicode-insiders|Vis|1.1.10
jinja|who|0.0.8
vue|Wsc|1.0.26
php-debug|xde|1.32.1
vue|znc|0.12.0

(3 theme extensions excluded)

</details><details>
<summary>A/B Experiments</summary>

```
vsliv368:30146709
vsreu685:30147344
python383cf:30185419
vspor879:30202332
vspor708:30202333
vspor363:30204092
vstes627:30244334
vslsvsres303:30308271
vserr242cf:30382550
pythontb:30283811
vsjup518:30340749
pythonptprofiler:30281270
vshan820:30294714
vstes263:30335439
vscod805cf:30301675
binariesv615:30325510
bridge0708:30335490
bridge0723:30353136
vsaa593:30376534
pythonvs932:30410667
vsclangdf:30486550
c4g48928:30535728
dsvsc012:30540252
pynewext54:30695312
azure-dev_surveyone:30548225
282f8724:30602487
pyind779:30671433
f6dab269:30613381
pythonsymbol12:30671437
showlangstatbar:30737416
vsctsb:30748421
pythonms35:30701012
a2ce3375:30757347
pythonfmttext:30731395
pythoncmvfstrcf:30756944
fixshowwlkth:30730052
hideindicator:30766889
pythongtdpathcf:30739705
dh2dc718:30763024
pythonnosmt12:30765603

```

</details>

<!-- generated by issue reporter -->"
bitcoin/bitcoin,2023-09-10 04:57:29,feature,#F,#
bitcoin/bitcoin,2023-09-10 04:51:31,feature,#F,#
bitcoin/bitcoin,2023-08-30 04:25:33,feature,a native token protocol,"### Please describe the feature you'd like to see added.

a native token protocol can be implemented on btc
A UTXO-based blockchain structure with a native token method, which I call ""dye coins.""
1. The transaction output class needs to add a new field called ""color"".
2. The block header needs to add a new field called ""color"".
3. The validation of ordinary transactions needs to add additional validation logic.
4. The validation of Coinbase transactions needs to add additional validation logic.
5. The validation of blocks needs to add new validation logic.

Specific logic is as follows:
1. After the transaction output has the color tag field, there are only two results, 0 (all 0) indicates not marked, non-0 indicates marked.
2. To verify that a normal transaction (non-coinbase) is valid, additional validation logic needs to be added. Specifically, it means that the input and output of all transactions must be traversed to ensure that the output values of all colors are less than or equal to the input values of the corresponding colors.
3. Miners need to verify that all or some of the normal transactions in the transaction pool that need to be packaged meet 2, and calculate the difference between all the corresponding colors in all these transactions as utxo (can be single or multiple) added to the Coinbase output.
4. A coinbase transaction is a special transaction that essentially has no input and only output. In addition to the utxo generated by the block miner fee, the coinbase transaction itself has a certain number of native token rewards.
5. The structure of a coinbase transaction that does not participate in color marking is as follows:
* 	Assuming that the current block reward is 50 white coins, and the transaction output generated by the miner fee contains 10 red coins, 10 green coins, and 10 white coins.
* 	When constructing a coinbase transaction, 3 red coin outputs (3 red coin outputs total 10) can be output, 2 green coin outputs (2 green coin outputs total 10) and 1 white coin output (output quantity is equal to 60)
6. The structure of a coinbase transaction that participates in color marking is as follows:
* 	Assuming that the current block reward is 50 white coins, and the transaction output generated by the miner fee contains 10 red coins, 10 green coins, and 10 white coins.
* 	When constructing a coinbase transaction, 3 red coin outputs (3 red coin outputs total 10) can be output, 2 green coin outputs (2 green coin outputs total 10), and the remaining 60 white coins will be dyed yellow as a single output (or multiple outputs). However, 60 white coins cannot be dyed yellow, 30 blue, and white coins can only be dyed the same color and a color that has not appeared before (how to determine if the color exists will be mentioned later), otherwise the transaction will fail.
7. Next, the miner will pack all the transactions to generate the Merkle tree, and assign the color value of the dye in the coinbase transaction to the color field in the block header, and then start Proof of Work to generate the block.
8. After the miner generates the block, it will broadcast the block to the entire network.
9. Other miners will verify the validity of the block. This includes verifying the validity of each transaction, especially the coinbase transaction. It must be ensured that the only color that can be dyed in the coinbase transaction is one color (not that there is only one color of output), and that this color has never appeared before (it can be obtained by traversing all the block headers or caching all the colors locally). Otherwise, the transaction will fail. If there is no dyeing (meaning that the output of the coinbase transaction does not produce a new color utxo, and the number of utxo tokens of other colors does not increase), the traversal process can be skipped.
10. Verify whether the color value in the block header (0 if no dyeing) is equal to the new color value in the coinbase transaction. If equal, the block is valid, the block is added to the blockchain, and the next block is mined. If not equal, the block is invalid and the block is rejected.
11. [Note] There is no inflation problem here, because inflation can be achieved simply by adding one more color utxo, for example, green and red are marked as US dollars.
if interested, pls contact me zhangguoqing0906@icloud.com

### Is your feature related to a problem, if so please describe it.

_No response_

### Describe the solution you'd like

_No response_

### Describe any alternatives you've considered

_No response_

### Please leave any additional context

_No response_"
bitcoin/bitcoin,2023-07-26 07:39:16,feature,Add Bech32.cpp LocateErrors case to check for minimum length.,"### Please describe the feature you'd like to see added.

Add a ""Bech32 string too short"" case to Bech32.cpp LocateErrors to reduce ambiguity and collisions with ""Invalid separator position"" case.

### Is your feature related to a problem, if so please describe it.

Error representation when calling LocateErrors within ```src/test/bech32_tests.cpp``` is ambiguous and incorrect in some cases because of a missing bech32 string to short case. Not having a too short case causes a fall though into the conditions of ```""Invalid separator position"" || ""Missing separator""```

### Describe the solution you'd like

Simply add a check for a minimum Bech32 string size after or during the check for the maximum size which is already implemented.

Cascading effects of this would be seen in DecodeDestination if https://github.com/bitcoin/bitcoin/blob/32c15237b656209b932c5d6d2e20736c0e3d5a34/src/key_io.cpp#L85-L86 was patched to not consider bech32 invalid then attempt to Base58Decode it becuase of the incorrect HRP for the current chain.

Referenced in 
https://github.com/bitcoin/bitcoin/issues/26290

PR 
https://github.com/bitcoin/bitcoin/pull/27260

### Describe any alternatives you've considered

You could case this into other logic on a case by case basis in code. Example make a speical case inside DecodeDestination to display the correct error message to the user by if LocateErrors returns 'Invalid ```""separator position"" || ""Missing separator""``` then you check to see if the string is to short.

### Please leave any additional context

As an aside there is already a check for string length greater than 90 (MAX LEN)

in src/test/bech32_tests.cpp both [""10a06t8"",""1qzzfhee""] produce ```{""Invalid separator position"", {0}}``` The former is non conformant to BIP173 due not even having enough chars to represent a BASE32 string and the second genuinely has a wrong separator position. "
bitcoin/bitcoin,2023-06-27 08:30:39,feature,Add maxrelaytxfee,"### Please describe the feature you'd like to see added.

Just an example (this feature request is not related to mutinynet in any way) - https://mutinynet.com/tx/68be05aec97b7d114e978185f0df76e494196e2b160330c97870b284f444e1c4

Let's suppose the miner wants to recycle coins (and shrink the total number of UTXOs) by making an all-fee transaction and eventually mining it. Any other miner would be happy to mine such a transaction if it is relayed to the network.

### Is your feature related to a problem, if so please describe it.

_No response_

### Describe the solution you'd like

Add `maxrelaytxfee` parameter, similar to its `min` equivalent which is present at least since 9d14e689c8, later it became a configurable.

The value could be in percentage of the amount sent. An absolute number (like the other similar configurables use) may be less helpful here when tho point is to stop broadcasting mostly all-fee transactions.

### Describe any alternatives you've considered

The usual way how UTXOs work is that they retain their full history back to the block from whose coinbase they come.

### Please leave any additional context

In case of large-scale recycling maybe the chainstate can get back below 6 GiB (at the moment it is 6.3 GiB big). Also the ""ordinals theory"" may require some rethinking."
bitcoin/bitcoin,2023-06-20 21:07:22,feature,change wording,"### Please describe the feature you'd like to see added.

""If you have chosen to limit block chain storage (pruning), the historical data must still be downloaded and processed, but will be deleted afterward to keep your disk usage low.""

change to

""If you have chosen to limit block chain storage (pruning), the historical data will be downloaded, processed, and deleted, to keep your disk usage low.""

### Is your feature related to a problem, if so please describe it.

_No response_

### Describe the solution you'd like

_No response_

### Describe any alternatives you've considered

_No response_

### Please leave any additional context

_No response_"
bitcoin/bitcoin,2023-06-05 11:26:19,feature,Use semantic analysis in lint-logs.py,"### Please describe the feature you'd like to see added.

Currently `test/lint/lint-logs.py` tries to parse the C++ manually which is prone to flaws. For example it does not support expressions that span more than one line and would be happy if there is `\\n""` anywhere (on the single line it checks). For example:

```cpp
        LogPrintLevel(BCLog::PROXY, 
                      BCLog::Level::Debug, 
                      ""This is fine, but lint-logs.py will report error\\n"");
```

```cpp
        LogPrintLevel(BCLog::PROXY, BCLog::Level::Debug, ""Not ok\\n""
                      "" but will be reported as ok"");
```

```cpp
        LogPrintLevel(BCLog::PROXY, BCLog::Level::Debug, ""even more /* Continued */ no newline, but is ok"");
```

```cpp
        /* LogPrintLevel() inside comment causes an error */
```

### Is your feature related to a problem, if so please describe it.

`lint-logs.py` requires to either write everything on line line or add `/* Continued */` comment.

### Describe the solution you'd like

It should be possible to use [libclang](https://pypi.org/project/libclang/) to properly parse the C++ code. Then the check should be something like:

```
for each call to `LogPrintLevel()`:
    get the third argument:
        it should be a string
        its last two chars should be `\\` and `n`
```

### Describe any alternatives you've considered

_No response_

### Please leave any additional context

_No response_"
bitcoin/bitcoin,2023-05-17 16:52:51,feature,Option to prevent sleep,"### Please describe the feature you'd like to see added.

There should be option to start Core which enable system to sleep only when net. act. is disabled!

### Is your feature related to a problem, if so please describe it.

_No response_

### Describe the solution you'd like

_To [notify](https://learn.microsoft.com/en-us/windows/win32/power/system-sleep-criteria) the system that your application is busy, use the.._

### Describe any alternatives you've considered

_constant disk activity about 5_ _MB/sec, occasionally it may drop to a smaller value but in general this 50 MB/sec_ [activity](https://github.com/bitcoin/bitcoin/issues/26063#issuecomment-1339086411) continues for very long periods of time._

_Creating a customized power plan_ is also not option because that would affect system even when Core is not running:
_More hours would be better, and best of all would be if you can run your node continuously._


### Please leave any additional context

_No response_"
bitcoin/bitcoin,2023-05-08 15:11:32,feature,rpc: Allow importing wallets by data instead of by filename,"### Please describe the feature you'd like to see added.

Right now we can only import wallets by filename. This means you can only execute that rpc if you are executing it from the system where the bitcoin node is running. But it could be that you are sending the rpc request from outside the node. In that case you don't have access to the file system. So it would be handy to allow passing the content of a wallet dump file instead and also allowing dumping the content not in a file but in the rpc result. 

It might be a good idea to check for other cases where the same is being done. 
"
bitcoin/bitcoin,2023-04-22 03:43:41,feature,Consider Removing Message Signing,"Signing arbitrary messages with Bitcoin private keys was always a bit strange. It was designed to handle only the narrow case of single-sig keys, and isn't well-defined for new address types. Worse, it doesn't allow for signing messages with more arbitrary scripts, and its not clear what the semantics for such things would be.

Sadly, the message signing feature is now being abused to ""verify wallets"" as a part of withdraw flows. This prevents Bitcoin users from using anything but an incredibly narrow set of scripts (in many cases *only* P2PKH, not even modern script formats, and definitely not multisig).

Rather than trying to rework it to avoid these things breaking Bitcoin, it seems like it'd be much better to simply remove the message signing logic entirely. If someone comes along with a proposal that considers a broader set of scripts and a more sensible design that could be considered."
bitcoin/bitcoin,2023-03-23 14:21:21,feature,Millisecond log timestamp (option),"### Please describe the feature you'd like to see added.

For some events, like two blocks at the same height being announced by multiple peers at the same time, it's nice to have millisecond precision on the log entries.

### Is your feature related to a problem, if so please describe it.

E.g. one of the ForkMonitor nodes saw two blocks at height 782,129 within the same second: https://twitter.com/BitMEXResearch/status/1638875082943520769

Other nodes saw those blocks in the opposite order.

### Describe the solution you'd like

Something like `-logtimestampprecision=` which would `second` by default, with `millisecond` as an option.

Log entries would look like:

```
2023-03-22T15:53:29Z
```

### Describe any alternatives you've considered

A more fancy solution would allow a custom date formatter.

### Please leave any additional context

_No response_"
bitcoin/bitcoin,2023-02-28 16:00:33,feature,Feature request: alert PR author in case of CI failure,"Would be nice to have a means of quickly getting alerted about the CI failing on a PR you authored. It's a bit cumbersome to keep an eye out on it manually, and a freshly created PR typically gets more eyes on it so having it in failing state is a bit of a waste of everyone's time. Creating this issue after brief [IRC discussion](https://bitcoin-irc.chaincode.com/bitcoin-core-dev/2023-02-28#1677593689-1677599148;).

I think the main requirements are:
- be able to opt out or easily ignore/hide
- only get a single notification per run, not for every single job failing
- low-touch, easy to maintain

Some potential approaches I see:
1. Use GitHub actions as [recommended](https://cirrus-ci.org/guide/notifications/) by Cirrus CI documention, e.g. here's a [sample email workflow](https://github.com/cirrus-actions/email)
  - can we get this to work so the PR author is notified?
2. Use [`bitcoin-git`](https://github.com/gkrizek/ghi) IRC bot to DM the nickname that corresponds to the PR author's GitHub nickname
  - people with a different username on IRC and GitHub would not get notifications
  - to opt-out, I think users could simply use `/ignore bitcoin-git`?
3. Use [drahtbot](https://github.com/marcofalke/drahtbot) to tag the author as assignee when CI fails (and remove them as assignee upon force push)
  - haven't come up with an elegant way for people to opt-out of this, but arguably it's also the least intrusive option and e.g. could be filtered on the mailbox level?"
bitcoin/bitcoin,2023-02-21 22:22:59,feature,Add support for sighash flags in PSBT (like SINGLE|ANYONECANPAY),"**Is your feature request related to a problem? Please describe.**
When using Bitcoin Core's GUI to sign a PSBT that has a UTXO with `sighash=SINGLE|ANYONECANPAY`, it throws following error:
```
Specified sighash value does not match value stored in PSBT
```

**Describe the solution you'd like**
I'd like it to successfully sign PSBTs containing `sighash=SINGLE|ANYONECANPAY`

**Describe alternatives you've considered**
The current non-idea workaround is to use the console window as described here:
https://github.com/orenyomtov/openordex/issues/1#issuecomment-1439162997

**Additional context**
Example PSBT:
```
cHNidP8BAF4CAAAAAXeYThreN2BAK3ExrpqGUIX/ZZZnz3ICQcL0HdIyNBraAAAAAAD/////ARCkAAAAAAAAIlEgVWMpPJTgiS8bEHeTZiizvHOP7LskZAgXa50KvKsv/2IAAAAAAAEAyAIAAAABtliktgpzhuZ4feeNzIMfd1gmwpdZVivt3Fs9jE62veQAAAAAakcwRAIgSRen/81qQ0C5MVYtZQjRa8zkXzv4TIAnCxBQgUHeqUECICINPEFntasthDMzMOryuQFWuHvJ8GUA3o0blSKi8kRXASEDs2NwiId+uHhKaiiSgNi+bs+C0mPlQzoLte4Vz8l4lOP9////AWweAAAAAAAAIlEgVWMpPJTgiS8bEHeTZiizvHOP7LskZAgXa50KvKsv/2LL3QsAAQMEgwAAAAAA
```
(taken from https://openordex.org/inscription?number=151969)
"
bitcoin/bitcoin,2023-02-05 20:30:32,feature,feature: lock inscriptions automatically,"Bitcoin Core is used a lot for inscriptions but they could be spent accidentally so lets freeze it.

We could not do it in past but  @meshcollider helped fix it in https://github.com/bitcoin/bitcoin/pull/23065

Lets lock inscriptions with by default it to help users

"
bitcoin/bitcoin,2023-01-31 16:55:04,feature,"decodescript could infer miniscript from given script in ""segwit"" context","I was playing around with a probably-too-cute script for LN channel smart contract, and was looking for something to decide for me if miniscript can infer the structure of the script.

f.e.

```
decodescript 82012088a914ffffffffffffffffffffffffffffffffffffffff8820ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffad51b2

{
  ""asm"": ""OP_SIZE 32 OP_EQUALVERIFY OP_HASH160 ffffffffffffffffffffffffffffffffffffffff OP_EQUALVERIFY ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff OP_CHECKSIGVERIFY 1 OP_CHECKSEQUENCEVERIFY"",
  ""desc"": ""raw(82012088a914ffffffffffffffffffffffffffffffffffffffff8820ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffad51b2)#5guaahuv"",
  ""type"": ""nonstandard"",
  ""p2sh"": ""33YyjgxsJYwSi8Wbp7TaCSFAuJBoUfYWDQ"",
  ""segwit"": {
    ""asm"": ""0 99f5d0b69f9828fea9363198cf812e95d7fc5e94c7881092b8e3f43984c1bd5c"",
    ""desc"": ""addr(bc1qn86apd5lnq50a2fkxxvvlqfwjhtlch55c7yppy4cu06rnpxph4wqrar3md)#wtlf0gwk"",
    ""hex"": ""002099f5d0b69f9828fea9363198cf812e95d7fc5e94c7881092b8e3f43984c1bd5c"",
    ""address"": ""bc1qn86apd5lnq50a2fkxxvvlqfwjhtlch55c7yppy4cu06rnpxph4wqrar3md"",
    ""type"": ""witness_v0_scripthash"",
    ""p2sh-segwit"": ""3MRJN2wTnD2BVm31HLcBwueAYpbbximrtk""
  }
}
```

Since it's evaluated at ""top level for `desc` it cannot get any meaningful structure from it. Perhaps in `segwit` it could try infering the miniscript in the segwit context

"
bitcoin/bitcoin,2023-01-17 17:14:35,feature,Expose addrman size info via RPC ,"If #26847 gets merged, addrman will maintain counts of addresses stored on the new & tried tables, broken down by network. This is useful information for monitoring the state of our addrman when we run it with different network configs on mainnet.

Currently when running a node, we can get a rough estimate into this information using the cli argument `-addrinfo`. However, this is just an estimate because it uses the RPC endpoint `getnodeaddresses`, which calls through to `Addrman::GetAddr`. Although this logic path skips the addr caching logic we apply for results propagated to the p2p network, it still applies some logic to filter results. For example it removes addresses that meet the `IsTerrible` attributes. It also doesn’t distinguish between the new and tried tables. 

So, I recommend we expose the raw counts to provide a better picture of addrman’s workings, especially since addrman & network integrations are particularly hard to test via our automated tooling. We can breakdown the counts by network & new vs tried. 

There are a few different options for how we can expose this information. I expect this feature to primarily be used by bitcoin core contributors or super-users that understand bitcoind’s inner workings. Thus, I suggest we expose it as a new, hidden RPC. That enables exposing the information to devs without having to guarantee a stable RPC interface over future versions. The name of the RPC can be something generic like  `addrmaninfo`, to allow for future extensions for other debugging information. 

For more historic context around bitcoin cli’s `-addrinfo` and conversation about cli vs RPC, see [#21595](https://github.com/bitcoin/bitcoin/pull/21595).  If we do end up implementing a new RPC endpoint, we could consider reworking the cli to use these values directly rather than trying to compute them with partial information. 
"
bitcoin/bitcoin,2022-12-30 21:28:35,feature,Pathing Guide for Installation using macOS,"**Is your feature request related to a problem? Please describe.**

Yes. One common problem with software setups is the pathing is corrupted. Proper pathing is one of the most important parts of getting started with any new software because if the path is depreciated the software will not properly run. This is the problem I am currently working on with Bitcoin. I downloaded the software but am unable to interact with the network.

```
# In
bitcoin-cli getblocktemplate '{""rules"": [""segwit""]}'
# Out
zsh: command not found: bitcoin-cli
```

**Describe the solution you'd like**

Ideally, there would be clear instructions on how to install and get started using Bitcoin software that did not require extensive knowledge of software systems architecture and pathing. A great installation method would automatically install the software along the right path to prevent the pathing problem. A generalized solution would be really good, providing a clear guide to solving the pathing problem on any machine.

**Describe alternatives you've considered**

I've researched solving the problem in the [Bitcoin Forum](https://bitcointalk.org/index.php?topic=5365321.0) and on [StackOverflow](https://bitcoin.stackexchange.com/questions/43148/bitcoin-cli-not-found-on-osx). However, because this common problem is so unique to each local machine, a clear or generalized solution is hard to develop. One specific solution I tried from my research was to add additional context to the command.

```
# In
> curl --user username --data-binary '{""jsonrpc"": ""1.0"", ""id"": ""curltest"", ""method"": ""getblocktemplate"", ""params"": [{""rules"": [""segwit""]}]}' -H 'content-type: text/plain;' http://127.0.0.1:8332/
# Out
> curl: (7) Failed to connect to 127.0.0.1 port 8332: Connection refused
```

However, the command resulted in a connection refusal. I found a possible solution in the [Bitcoin Forum](https://bitcointalk.org/index.php?topic=5155612.0), but the problem with the proposed solution is that there is no `bitcoin.conf` file in the main Bitcoin repository. I found a `config` folder in the `src` directory, but there is no `bitcoin.conf` file. 

**Additional context**

I am running on MacOS. Thank you in advance for your attention and advice.
"
bitcoin/bitcoin,2022-11-29 15:49:32,feature,Erlay status in getpeerinfo,"When running with `-txreconciliation` (added in #23443, but off by default and hidden under `--help-debug`) it's currently rather tedious to see which of your peers have this enabled. It basically involves loooking at the p2p log.  It would be nice to have Erlay status under `getpeerinfo`."
bitcoin/bitcoin,2022-11-19 23:52:46,feature,Include estimated time to synchronize blockchain in bitcoind,"**Is your feature request related to a problem? Please describe.**
No

**Describe the solution you'd like**
Currently, the estimated time to synchronize to the Bitcoin blockchain is only shown in the Qt GUI. It would be useful to display the estimated remaining time to synchronize to the blockchain via the Bitcoin daemon's logs as well.

**Describe alternatives you've considered**
Display estimated time in the Bitcoin daemon synchronizing logs.
"
bitcoin/bitcoin,2022-10-06 00:02:23,feature,setminrelayfee,"I think this is something within my ability to add.

**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->
The ability to change minrelaytxfee without restarting. 

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->
I would like the ability to set the relayfee by a bitcoin-cli rpc call.
```
setminrelayfee amount

Set the transaction fee rate in BTC/kvB for this wallet. Overrides the global -setminrelayfee config parameter.
Can be deactivated by passing 0 as the fee. In that case automatic default min fee will be used.

Arguments:
1. amount    (numeric or string, required) The transaction fee rate in BTC/kvB

Result:
true|false    (boolean) Returns true if successful

Examples:
> bitcoin-cli setminrelayfee 0.00001
> curl --user myusername --data-binary '{""jsonrpc"": ""1.0"", ""id"": ""curltest"", ""method"": ""setminrelayfee"", ""params"": [0.00001]}' -H 'content-type: text/plain;' http://127.0.0.1:8332/
```

**Describe alternatives you've considered**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->

**Additional context**
<!-- Add any other context or screenshots about the feature request here. -->
I encountered this while hooking up a lightning network node. My relay fee was too high from bad conf settings and was blocking funding transactions. I wasn't able to change this value and had to restart bitcoind instead of just making  an rpc call.
"
bitcoin/bitcoin,2022-09-08 02:03:23,feature,dumpprivkey doesn't work in descriptor wallet,"In a descriptor wallet it returns ""This type of wallet does not support this command"" instead of the private key. Even though the wallet doesn't store the key directly it obviously knows how to build it since it can spend the funds so it should do that and return it. There are just too many cases where a private key needs to be dumped and it shouldn't be a nightmare of RPC calls and 3rd party scripts to try to get it, that just doesn't make sense usability-wise.

Just a common case point for us for example, we still use p2sh-segwit for our users since too many places still don't support  bech32 and pretty regularly people still send LTC to our BTC addresses (smh, I know) and we need to easily be able to dump the key to recover it for them."
bitcoin/bitcoin,2022-07-28 12:21:46,feature,rpc: `listunspent` doesn't return immature coinbase outputs,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->
I need to know all the utxos I have in my wallet, including the immature ones. When using listunspent, the immature coinbases are not returned:
```  
❯ bitcoin-cli listtransactions
[
  {
    ""address"": ""bcrt1q0epv47eaxhyenhqcjp8v7wytjx26k35r6w2py6"",
    ""category"": ""immature"",
    ""amount"": 50.00000000,
    ""label"": """",
    ""vout"": 0,
    ""confirmations"": 1,
    ""generated"": true,
    ""blockhash"": ""334996db387320711e1176f2591dfc16fe8d92f617af47ae65b97c2a817758b0"",
    ""blockheight"": 102,
    ""blockindex"": 0,
    ""blocktime"": 1658995253,
    ""txid"": ""480f0340a98755cfb095743b5464e87d0cf1b0200d204507ec8448962bcafbe6"",
    ""walletconflicts"": [
    ],
    ""time"": 1658995253,
    ""timereceived"": 1658995253,
    ""bip125-replaceable"": ""no""
  }
]
❯ bitcoin-cli listunspent
[
]
```

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->
What do you think of adding a `include_immature_coinbase` (default to false) parameter to `listunspent`? If you think it'd be useful, I can start working on this myself.

**Describe alternatives you've considered**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->
At the moment I'm calling `listtransaction` and adding to the utxo list every immature output I see (https://github.com/bitcoindevkit/bdk/pull/687). This works just fine, but having the `include_immature` parameter would make the code a bit cleaner (and it would save one RPC call!)."
bitcoin/bitcoin,2022-07-26 06:40:36,feature,Add EnsureWalletIsUnlocked to rescanblockchain RPC?,"It seems that it would otherwise silently skip the rescan for pre-backup used keys that are still waiting to be generated into the keypool?

See also #11249 "
bitcoin/bitcoin,2022-07-02 21:04:30,feature,Progress for opening wallet,"While there is progress for importing private keys and rescanning, there is good reason to also add progress for wallet opening.
Now you need to look into debug.log and trace it for progress, so adding a progress bar for opening wallet (it is rescan in the end) would be a very nice feature."
bitcoin/bitcoin,2022-06-02 23:44:41,feature,Allow groups of accounts to access the RPC cookie file,"**Context**
I have multiple accounts on the same box that need to run clients of bitcoind. In particular it's LND and electrs. Bitcoind itself runs in a separate account. I have other accounts that I don't want to have access to bitcoin: e.g. Grafana (graphs/charts web UI). So, the cookie file can be shared amount the relevant accounts via a group. On the file system a group read permissions can be set on each file.  I call the group ""bitcoinclients"". I setup a directory where new files will inherit the bitcoinclients group and will be created with the u=rw,g=r,o= permission. This means bticoin account can write the file, bitcoinclinets group can read it, and no one else has access.

**Is your feature request related to a problem? Please describe.**
The problem is that when `bitcoind` is restarted it drops the group read permission on the cookie file so clients in other unix accounts can't read the file.
 
**Describe the solution you'd like**
There should be a config that allows controlling permissions of the cookie file. Just a boolean that sets the read permissions on the group would be sufficient.

**Describe alternatives you've considered**
I setup a [chronos workaround](https://github.com/alevchuk/minibank/blob/first/bitcoin/README.md#bitcoin-cookie) but I bet more people will have to re-invent this wheel as the cookie file gets wider adoption.

**Additional context**
[Cookie file](https://github.com/bitcoin/bitcoin/blob/25ad2c623af30056ffb36dcd203a52edda2b170f/src/httprpc.cpp#L252) has [more security](https://github.com/Kixunil/security_writings/blob/master/cookie_files.md) over user+password auth. User+password auth is being deprecated in favor of the cookie file."
bitcoin/bitcoin,2022-05-13 15:40:59,feature,"gettransaction does not contain the field ""abandoned"" for abandoned receiving tx","In specter https://github.com/cryptoadvance/specter-desktop/issues/1491#issuecomment-1126145011  a user can abandon an **receiving** tx that was evicted from the mempool (for example because it was double spent). The tx is marked via [abandontransaction](https://github.com/bitcoin-dot-org/developer.bitcoin.org/blob/master/reference/rpc/abandontransaction.rst) as abandoned in bitcoin core.

However [gettransaction](https://github.com/bitcoin-dot-org/developer.bitcoin.org/blob/master/reference/rpc/gettransaction.rst) and [listtransactions](https://github.com/bitcoin-dot-org/developer.bitcoin.org/blob/master/reference/rpc/listtransactions.rst) do not return the field `abandoned`, even though this is visible in the GUI:

![image](https://user-images.githubusercontent.com/60378539/168316171-45c1aa29-de52-4d9a-ae2b-3293aeadd663.png)

**Consequence**: Specter cannot get the `abandoned` information from bitcoin rpc, and will fetch the abandoned tx back again via [listtransactions](https://github.com/bitcoin-dot-org/developer.bitcoin.org/blob/master/reference/rpc/listtransactions.rst) after it was deleted in specter.   

**Describe the solution you'd like**
Always return the `abandoned` field in https://github.com/bitcoin/bitcoin/blob/225e5b57b2ee2bc1acd7f09c89ccccc15ef8c85f/src/wallet/rpc/transactions.cpp#L345  and not only in this special case https://github.com/bitcoin/bitcoin/blob/225e5b57b2ee2bc1acd7f09c89ccccc15ef8c85f/src/wallet/rpc/transactions.cpp#L375
That should then automatically solve  [gettransaction](https://github.com/bitcoin-dot-org/developer.bitcoin.org/blob/master/reference/rpc/gettransaction.rst)  via https://github.com/bitcoin/bitcoin/blob/225e5b57b2ee2bc1acd7f09c89ccccc15ef8c85f/src/wallet/rpc/transactions.cpp#L795

**Describe alternatives you've considered**
If specter can't get the information about abandoned tx from bitcoin, it would have to keep an internal list. That is possible, but redundant and can lead to many edge cases.

**Steps to reproduce**

- Wallet A:  Send 1 BTC to Wallet B  (rbf)
- Wallet A:  Replace tx with rbf to send all funds to wallet A
- Wallet B: Abandon tx (because no longer in mempool)
- Wallet B:  [gettransaction](https://github.com/bitcoin-dot-org/developer.bitcoin.org/blob/master/reference/rpc/gettransaction.rst) will not show the  `abandoned` field"
bitcoin/bitcoin,2022-04-11 20:05:33,feature,Export a watch wallet only (with descriptors and without private keys) for an air gap setup,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->
For long time I've seen users looking for a way to do an air gap setup with Bitcoin Core, since there were no easy way people tend to go with other solutions such as armory, electrum which offers an easy and friendly way to do it.

Since Bitcoin Core v 22.0 and with the command  listdescriptors it can be done easily:

OFFLINE PC - Create a wallet with descriptors=true, export descriptors with ""listdescriptors"".
ONLINE PC - Create a wallet without privatekeys, descriptors=true, and importdescriptors to have a functional watch only wallet for receiving funds and create unsigned transactions.

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->

Instead of creating two wallets, one offline and a watch only and manually have to export/import descriptors, the wallet containing the private keys could offer an option like ""exportwatchonly"" that would generate a ""watch_wallet.dat"" without private keys and all descriptors already imported. Making very easy and user friendly the process to create an air gap setup."
bitcoin/bitcoin,2022-04-06 11:23:47,feature,"CI, tracing: run tracepoint interface tests in the CI","The first tracepoint tests were merged in #24358. However, they are skipped in the CI. I've already done some experiments running them in the CI in https://github.com/bitcoin/bitcoin/issues/23296, however I haven't been successful with it yet. The main issue was the limited capabilities inside the CirrusCI docker container.

An option would be to ask CirrusCI for help, another would be to run this part in a VM, if it's not to much overhead."
bitcoin/bitcoin,2022-03-29 15:47:25,feature,Enable consistency checks by default with `--enable-debug`,"Now that most consistency checks have been made a runtime option instead of configure option (see commit 803ef70fd9f65ef800567ff9456fac525bc3e3c2), it could make sense to enable them on `--enable-debug`. Otherwise they are only run when explicitly passed the runtime setting."
bitcoin/bitcoin,2022-03-21 23:39:52,feature,IsStandard should check the witnessprogram is a valid point on the field,"**Is your feature request related to a problem? Please describe.**
A v1 taproot witness program must be a valid point on secp256k1 otherwise it is essentially a black hole.

**Describe the solution you'd like**
Add a check in IsStandard that will check the witnessprogram in the case where WITNESS_V1 is returned. If the witness program is not the X value of a valid point, return false. (https://github.com/bitcoin/bitcoin/blob/v22.0/src/policy/policy.cpp#L53-L74)"
bitcoin/bitcoin,2022-02-16 12:07:09,feature,edit src/index/base.cpp,"**Is your feature request related to a problem? Please describe.**
txindex sync message will print more than exactly twice a minute
because current_time and last_log_time are in seconds, it jitters
by one second
https://github.com/bitcoin/bitcoin/blob/1e8aa02ec5cc2819c67ef40a7573c4b23a4c11cc/src/index/base.cpp#L168

**Describe the solution you'd like**
change '<' with '<=' makes the message
appear [twice exactly a minute][0], in
https://github.com/bitcoin/bitcoin/blob/1e8aa02ec5cc2819c67ef40a7573c4b23a4c11cc/src/index/base.cpp#L168
for consistency, probably as well in
https://github.com/bitcoin/bitcoin/blob/1e8aa02ec5cc2819c67ef40a7573c4b23a4c11cc/src/index/base.cpp#L174
(among others?) but I'm not interested in analyzing implications of
changing that line 174

**Describe alternatives you've considered**
I suppose there's a way to change this by using millisec resolution in these time variables.

**Additional context**
thanks!

[0]: https://github.com/bitcoin/bitcoin/blob/1e8aa02ec5cc2819c67ef40a7573c4b23a4c11cc/src/index/base.cpp#L21
"
bitcoin/bitcoin,2022-02-12 03:04:35,feature,CI testing with minimum supported versions,It would be nice if we could get a CI that always tests our minimum supported versions. Maybe we can use Guix for it?
bitcoin/bitcoin,2022-02-02 02:49:05,feature,Feature request: automatically upgrade legacy to HD wallet,"Since Bitcoin Core 0.17 the startup option `upgradewallet` has been available, allowing users to upgrade old legacy wallets to HD wallets. 
However many users with non-HD wallets are yet to upgrade their wallet, to reduce complexity, and or various issues related to non-HD wallets, I am wondering if it may be a good idea to require users to upgrade.

Two different ways of implementing this (off the top of my head):
- when all addresses in a keypool are marked used, automatically upgrade wallet and notify user to make a backup.
- on startup upgrade wallet and notify user to make a backup

Are there any reasons for why Bitcoin Core doesn't already do this? "
bitcoin/bitcoin,2022-01-28 06:36:42,feature,[RPC] Removal of signmessage and verifymessage,"Those two features are present for a long in Bitcoin Core, but has been scarcely used over the years.

However, this is going to change with [AOPP](https://gitlab.com/aopp/address-ownership-proof-protocol/-/blob/master/wallet_guide.md) who directly link at [this code](https://github.com/bitcoin/bitcoin/blob/13d27b452d4b60010c54d4f80757dea9805076be/src/util/message.cpp) in the protocol's implementation."
bitcoin/bitcoin,2022-01-19 00:16:56,feature,Proof of Advanced Delegation,"If we remove the consensus protocol (blockchain and mining) what do we get?  We're left with what Satoshi Nakamoto had before he added the consensus protocol.  No blockchain, no mining, just the transaction history with nothing to protect it from double spend attacks.

Here I present what I call ""proof of advanced delegation"" (PAD).  PAD eliminates double spends by spending them in advance. When an output is created, the transaction that spends it is created too and it's txid is embedded in the output before it gets published.  The output of the last transaction is not yet spent so it remains unpublished.

Beginning with an arbitrary transaction in the ledger, A, it's output is A1.  The unpublished transaction that spends it is B and it's output is B1.  To make a payment, the sender:
1. Creates a new transaction C that splits B1 between two new outputs, C1 payment and C2 change.
2. Generates the txid of C and embeds it in B1.
3. Creates another transaction E that spends C2 and embeds it's txid in C2.
4. Publishes transactions B (advanced delegation).
5. Sends transaction C with sigs to the receiver in secret.

The receiver then:
1. Sees transaction B on the network which validates and binds it to transaction C.
2. Creates two new transactions of his own, D and F.  D spends C1 and F spends D1.
3. Publishes C and D as a pair and saves F until he's ready to spend it.

Since every published output is bound to the txid of the unpublished transaction that spends it, there is no opportunity to double spend them therefore no consensus mechanism is required."
bitcoin/bitcoin,2021-12-30 19:10:05,feature,fuzz: prototype for cross-language differential fuzzing,"Since differential fuzzing is strongest when different programming languages are involved, I’d like to fuzz cpp code against python code.

**Solution**:
Use sockets to establish a TCP client/server connection.

- **Server** - a python file which listens and accepts client communications from the fuzz target, performs the required operations in python and sends back the computed python output as a response back to the client.
- **Client** - A fuzzing harness which can send requests to the python server to perform certain operations, receives python output computed in the server file and compares cpp output with the python output to see if they match.

Since this requires a slight architectural change in the fuzzing harness to allow python subprocesses, I’d like to know if this solution is acceptable. 

**Additional context**
I’ve implemented a prototype which performs cross-language differential fuzzing of chacha20 on [this branch](https://github.com/stratospher/bitcoin/commits/socket_diff_fuzz_chacha20) and would love to hear opinions/feedback on how to proceed.

**Test instructions**

1. Start server: `python3 src/test/fuzz/script.py`
2. Run the fuzz test: `FUZZ=crypto_diff_fuzz_pychacha20 src/test/fuzz/fuzz`"
bitcoin/bitcoin,2021-12-27 14:14:31,feature,add ability to remove (dust) UTXOs,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->
problem: i have a lot of 0 sat UTXOs (after flooding the testnet lol)

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->
an rpc call to remove UTXOs
for example: `bitcoin-cli removeutxos`
with an argument to remove everything with less than the specified amount

**Describe alternatives you've considered**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->

making a new wallet, sending coins from the old one to the new one, remove the old wallet

**Additional context**
<!-- Add any other context or screenshots about the feature request here. -->
"
bitcoin/bitcoin,2021-12-17 21:20:08,feature,Improve Test Framework Time With Run Order Directive,"If you could leave a directive in one of the commits in your tree, e.g.

```
> run-priority: feature_blah.py
```

and we could use that to instruct the CI to run that test _first_, that would be pretty helpful in speeding up CI if there's a particular e.g. new or impacted test that should see failures before others.

It won't help with passing, but it could help with 'fail fast'."
bitcoin/bitcoin,2021-12-15 16:50:09,feature,allow positional and named arguments in `bitcoin-cli`,"**Is your feature request related to a problem? Please describe.**
`bitcoin-cli sendtoaddress ""bc1q09vm5lfy0j5reeulh4x5752q25uqqvz34hufdl"" 0.1 """" """" true false 0 unset true 1 true`
or
`bitcoin-cli -named sendtoaddress address=""bc1q09vm5lfy0j5reeulh4x5752q25uqqvz34hufdl"" amount=0.1 verbose=true`
?

**Describe the solution you'd like**
`bitcoin-cli sendtoaddress bc1q09vm5lfy0j5reeulh4x5752q25uqqvz34hufdl 0.1 verbose=true`

add the ability to use positional and named arguments in one rpc call"
bitcoin/bitcoin,2021-12-09 20:20:02,feature,Make rescans faster,"This issue aggregates ideas for making wallet rescans substantially faster.

Using compact block filters, when available, could substantially speed up wallet rescans although it is not clear to me how this might work for non-descriptor-based (legacy) wallets.

Currently, #20664 proposes to add an RPC that will use compact block filters to scan for blocks relevant to a given script descriptor. This gives a listing of blocks that correspond to the descriptor, but the user then has to do something with that list of blocks to find transactions relevant to their wallet. 

It would be nice to integrate scanblocks' use of block filters opaquely into `rescanblockchain` (wallet rescanning) so that if block filters are available, the faster method of consulting them could be used instead of scanning the entire chain, or forcing the user to do something more roundabout with the output of `scanblocks`.


From @sipa: 
> regarding faster rescanning, i think there is some lower-hanging fruit, like (a) rescanning all wallets at startup in parallel rather than one by one and (b) building a set of scriptPubKeys to look for and using that for (legacy wallet) rescanning, instead of calling IsMine for each (especially with achow101's migrate-to-descriptor code, i think there should be a way of computing that set for legacy wallets too)

### Possible changes

- [ ] integrate compact block filter usage into `rescanblockchain` to allow faster rescans when the compact block index is available, otherwise falling back to the standard scanning method. A first approach could possibly use filters only when dealing with a non-legacy descriptor wallet
    - Currently proposed in https://github.com/bitcoin/bitcoin/pull/23549
- [ ] allow pruned nodes with the block filter index to rescan quickly by getting a list of relevant blocks to the wallet, requesting the download of blocks, and then parsing the blocks for relevant transactions
- [ ] rescanning all wallets at startup in parallel (instead of one-by-one): https://github.com/bitcoin/bitcoin/issues/11756
- [ ] building a set of scriptPubKeys to look for when using a legacy wallet based on @achow101's migrate-to-descriptor code"
bitcoin/bitcoin,2021-11-17 17:14:10,feature,add benchmark to test large scale of hardware,"I'm not sure if there are any benchmarks that could be easily used to test large scale of hardware wrt type of bottleneck (CPU/SSD bound). I recall I saw something on Twitter mentioned by @sipa but not sure now what it was about.

Benching CPUs, RAMs and SSDs is my daily job and I've been wanting to have some Bitcoin related benchmarks in my suite. Last month I was rebenching 14 CPUs and I wish I had relevant data on their performance in bitcoin software.

It would be best if we could have such benchmarks as part of https://github.com/phoronix-test-suite/phoronix-test-suite and https://openbenchmarking.org/ so we could bench all kind of hardware and different versions of bitcoin core with single command. That way we could have a lot of open data which I'm sure could be useful to development."
bitcoin/bitcoin,2021-10-17 14:42:20,feature,tracing: include tracepoints in GUIX builds,"There has been light conceptual agreement on including the USDT based tracepoints in Bitcoin Core release builds. This, for example, enables user to hook into production deployments, if they need to. Binaries don't have to be switched out. This is possible because we don't do [expensive computations](https://github.com/bitcoin/bitcoin/blob/master/doc/tracing.md#no-expensive-computations-for-tracepoints) only for the tracepoints and the tracepoints are NOPs when not used.

There is a slight chance that the GUIX build on the current master already includes the tracepoints. I have not done an GUIX build on a branch with the tracepoints merged yet. This can be tested on a `bitcoind` binary using one of the methods mentioned in the [tracing documentation section ""Listing avaliable tracepoints""](https://github.com/bitcoin/bitcoin/blob/master/doc/tracing.md#listing-available-tracepoints).

If not present, making the `systemtap` headers (`sys/sdt.h`) available during the GUIX build should build `bitcoind` with the tracepoints.
"
bitcoin/bitcoin,2021-10-12 06:18:12,feature,Return fee in `getrawtransaction`,"Similar to how the fee is returned in `getblock` (#18771), it should be returned in `getrawtransaction`.


#### Useful skills:

Understanding of undo data, the RPC interface and the functional tests.

#### Want to work on this issue?

For guidance on contributing, please read [CONTRIBUTING.md](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md) before opening your pull request.
"
bitcoin/bitcoin,2021-10-05 13:44:26,feature,RPC: support fee bumping with external inputs,"External inputs are currently only supported for initial transaction creation functions. Extend `solving_data` arguments as necessary to support fee bumping wallet transactions with non-wallet inputs.

https://github.com/bitcoin/bitcoin/pull/17211#issuecomment-897653994"
bitcoin/bitcoin,2021-10-04 20:57:30,feature,Other platform support for Linux syscall sandboxing,"Now that #20487 is merged, it would be nice if syscall sandboxing was extended to the other Linux platforms that have release binaries as well:

- [x] `x86_64-linux-gnu` 
- [ ] `arm-linux-gnueabihf `
- [ ] `aarch64-linux-gnu`
- [ ] `riscv64-linux-gnu`
- [ ] `powerpc64-linux-gnu`
- [ ] `powerpc64le-linux-gnu`
"
bitcoin/bitcoin,2021-09-30 13:23:19,feature,"Plumb ""too-long-mempool-chain"" to RPC error for send/sendtoaddress","**Is your feature request related to a problem? Please describe.**

If coin selection fails as part of `send` or `sendtoaddress`, the error message returned to the RPC client is `Insufficient funds`, even if the actual cause is due to `too-long-mempool-chain`.  This is likely to alarm users unnecessarily, as they will believe this means their funds have permanently vanished rather than being temporarily inaccessible.

**Describe the solution you'd like**

If coin selection fails due to `too-long-mempool-chain`, the `send` and `sendtoaddress` methods should pass that error back to the RPC client, instead of `Insufficient funds`.

**Describe alternatives you've considered**

It would be even nicer from a UX standpoint if the limit on mempool chain length were removed, but AIUI [that's a DoS vector](https://github.com/bitcoin/bitcoin/issues/9752#issuecomment-281464014), so is not going to happen.

**Additional context**

Apparently this is [already done for `sendrawtransaction`](https://github.com/bitcoin/bitcoin/pull/10015#issuecomment-288597075).  The discussion in https://github.com/bitcoin/bitcoin/pull/10015 is relevant (it appears that the PR was withdrawn for reasons unrelated to my request).
"
bitcoin/bitcoin,2021-09-23 09:07:43,feature,Auto-generate MSVC version information,"Right now, bumping the version involves updating the version in two places:

- `configure.ac`
- `build_msvc/bitcoin_config.h` (in multiple places—see for example commit f277b1782c5aae0fab83e3d678189c150ae0f263)

I think it should be doable to parse the information from `configure.ac` in `msvc-autogen.py`, so that this is no longer something error-prone that has to be done manually.

If you do this, also update [the release process](https://github.com/bitcoin/bitcoin/blob/master/doc/release-process.md).

#### Useful skills:

Python, MSVC

#### Want to work on this issue?

For guidance on contributing, please read [CONTRIBUTING.md](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md) before opening your pull request.
"
bitcoin/bitcoin,2021-09-14 15:38:09,feature,fuzz: Invoking python interpreter from a C++ file,"I'm interested in reimplementing a python version of the new [ChaCha20Poly1305@Bitcoin AEAD](https://github.com/bitcoin/bitcoin/pull/20962) and fuzzing it against the C++ implementation. However since it involves invoking a python interpreter from inside a C++ file, I'm confused on how to proceed.

**Possible Approaches**
1. using pipes to call the python script from the C++ file.
2. using [pybind11](https://pybind11.readthedocs.io/en/latest/index.html) to create the python C++ interface (idea from [this PR](https://github.com/bitcoin/bitcoin/pull/22851)). However the python to C++ code for the AEAD wouldn't be very readable here.

Would method 1 be ok? I'd love to hear your thoughts on how to proceed.
"
bitcoin/bitcoin,2021-09-08 11:10:06,feature,rpc: Add level 3 verbosity to getblock RPC call (#21245 modified),"Author of #21245 expressed [time issues](https://github.com/bitcoin/bitcoin/pull/21245#issuecomment-902332088) in the original PR. Given that #21245 has received a lot of review*, I have decided to open this new pull request with [modifications required to get ACK from luke-jr ](https://github.com/bitcoin/bitcoin/pull/21245#issuecomment-905150806) and a few nits of mine.

### Original PR description

> Display the prevout in transaction inputs when calling getblock level 3 verbosity. This PR affects the existing `/rest/block` API by adding a `prevout` fields to tx inputs. This is mentioned in the change to the release notes.
> 
> I added some functional tests that
> 
>     * checks that the RPC call still works when TxUndo can't be found
> 
>     * Doesn't display the ""value"" or ""scriptPubKey"" of the previous output when at a lower verbosity level
> 
> 
> This ""completes"" the issue #18771

### Possible improvements

* https://github.com/kiminuo/bitcoin/commit/b0bf4f255f86aeaddce68889087c22f9068f4d97 - I can include even this commit to this PR if deemed useful or I can leave it for a follow-up PR. See https://github.com/bitcoin/bitcoin/pull/21245#issuecomment-894853784 for more context.

### Examples

Examples of the `getblock` output with various verbose levels. Note that `000000000000001f682b188971cc1a121546be4e9d5baf22934fdc7f538288d5` contains only 2 transactions.

(See: https://github.com/bitcoin/bitcoin/pull/21245#issuecomment-893313612)

#### Verbose level 0

```bash
./bitcoin-cli -testnet getblock 000000000000001f682b188971cc1a121546be4e9d5baf22934fdc7f538288d5 0
```

##### Verbose level 1

```bash
./bitcoin-cli -testnet getblock 000000000000001f682b188971cc1a121546be4e9d5baf22934fdc7f538288d5 1
```

##### Verbose level 2

```bash
./bitcoin-cli -testnet getblock 000000000000001f682b188971cc1a121546be4e9d5baf22934fdc7f538288d5 2
```

##### Verbose level 3

```bash
./bitcoin-cli -testnet getblock 000000000000001f682b188971cc1a121546be4e9d5baf22934fdc7f538288d5 3
```

#### REST

```bash
curl -H ""content-type:text/plain;"" http://127.0.0.1:18332/rest/block/000000000000001f682b188971cc1a121546be4e9d5baf22934fdc7f538288d5.json
```

<sub>* ... and my everyday obsessive checking of my email inbox whether the PR moves forward.</sub>

Edit laanwj: Removed at symbol from message, and large example output to prevent it from all ending up in the commit message."
bitcoin/bitcoin,2021-08-20 06:11:28,feature,rpc/wallet: add simulaterawtransaction RPC,"(note: this was originally titled ""add analyzerawtransaction RPC"")

This command iterates over the inputs and outputs of the given transactions, and tallies up the balance change for the given wallet. This can be useful e.g. when verifying that a coin join like transaction doesn't contain unexpected inputs that the wallet will then sign for unintentionally.

I originally proposed this to Elements (https://github.com/ElementsProject/elements/pull/1016) and it was suggested that I propose this upstream.

There is an alternative #22776 to instead add this info to `getbalances` when providing an optional transaction as argument."
bitcoin/bitcoin,2021-08-12 15:54:02,feature,fuzz: investigate test adequacy (unit and fuzz) via mutation testing,"@MarcoFalke / @practicalswift I'm starting some mutation analysis using https://github.com/agroce/universalmutator

A couple of questions:

- At random I picked `tx_verify.cpp` as a file with high coverage that is likely critical, where any missed non-equivalent mutants should be carefully investigated.  Is this a good choice to get the workflow going on?

- Is there any mapping from fuzz targets to code expected to be covered?  I can run all targets, of course, but knowing which ones might possibly detect `tx_verify.cpp`mutants would be helpful.

"
bitcoin/bitcoin,2021-08-05 17:46:06,feature,"createwallet with external signer always picks the first external signer, regardless of how many are connected","**Is your feature request related to a problem? Please describe.**

While testing `22.0rc2` external signer feature, I noticed that if multiple HW wallets are connected to the computer, `createwallet` will always pick the first one without alerting the user in any way. This led to the following unexpected behavior:

1. attach a trezor and create a wallet using `bitcoin-cli createwallet`
2. attach a coldcard while the trezor is still connected and create a second wallet with `bitcoin-cli createwallet`

Both wallets were created fine with no errors, but on further inspection I realized both wallets were connected to the trezor, despite having different names. This is related to #22635 

**Describe the solution you'd like**

Ideally, if multiple external signers are returned from `enumeratesigners` and I then try to create a wallet, I would want `createwallet` to fail and warn me there are multiple external signers. Additionally, an option to specify the fingerprint of the device would be useful, but I think simply failing would be sufficient for now.

**Describe alternatives you've considered**

Granted, this is a rare case where a user would have multiple HW's connected while creating a single sig wallet, so perhaps just documenting that you should only have one connected at a time is a viable solution.
"
bitcoin/bitcoin,2021-07-19 15:01:06,feature,"netinfo: display addr_{processed, rate_limited, relay_enabled} and relaytxes data","Update CLI -netinfo to display the getpeerinfo `addr_processed`, `addr_rate_limited`, `addr_relay_enabled` and `relaytxes` data with auto-adjusting column widths.

```
$ ./src/bitcoin-cli -netinfo help

  txn      Time since last novel transaction received from the peer and accepted into our mempool, in minutes
           ""*"" - the peer requested we not relay transactions to it (relaytxes is false)

  addrp    Total number of addresses processed, excluding those dropped due to rate limiting
           ""."" - we do not relay addresses to this peer (addr_relay_enabled is false)

  addrl    Total number of addresses dropped due to rate limiting
```

![Screenshot from 2021-08-22 14-31-40](https://user-images.githubusercontent.com/2415484/130355514-f6fd4f21-79d6-463b-9791-de01ebef20b1.png)
"
bitcoin/bitcoin,2021-07-10 19:34:19,feature,Sub wallet for dirty coins,"**Is your feature request related to a problem? Please describe.**

- Unable to spend unconfirmed UTXO
- OUTPUT_GROUP_MAX_ENTRIES = 100

The combination of these two things affects privacy which is discussed in detail here: https://github.com/bitcoin/bitcoin/issues/22018

**Describe the solution you'd like**
![image](https://user-images.githubusercontent.com/13405205/125175429-a7932500-e1e9-11eb-99f0-60fd382ec84b.png)




We are already marking used addresses as 'grey' in https://github.com/bitcoin/bitcoin/pull/17355. Can improve this by marking 'red' for addresses used twice or more for receiving bitcoin. Grey color for addresses used once. Once we have dirty coins (received bitcoin twice or more), they should be locked automatically, dump private keys associated with the addresses and import them in a new wallet (sub-wallet for dirty coins).

Not sure if there should be a sub wallet for each address or all dirty coins go in one sub wallet.

**Describe alternatives you've considered**
Use other wallets

**Additional context**

This will improve following things:

1. No wallet fingerprinting
2. Keep things separate
3. Manage [forced address reuse](https://en.bitcoin.it/wiki/Privacy#Forced_address_reuse) in a better way
4. Neither UTXOs being confirmed nor value for `OUTPUT_GROUP_MAX_ENTRIES` will matter anymore. The user can decide how to spend dirty coins in future. Either use all in one transaction or do coinjoin or something else.


Looking for Concept ACKs and discussion about this solution so that implementation can be planned if enough people agree to add this feature.

Thanks @harding for suggesting idea about sub-wallets in https://github.com/bitcoin/bitcoin/issues/22018#issuecomment-850803134"
bitcoin/bitcoin,2021-05-24 14:49:58,feature,Nulldata treated as nonstandard,"bitcoind returns 'nonstandard' addresses from scripts started from OP_RETURN.
E.g. in first 300 kiloblocks (bk.tx.vout):

- 229712.129.1
- 257727.91.1
- 257727.93.1
- 283396.596.1
- 296195.12.0
- 299571.10.2

As an example - vout 229712.129.1 (block height 229712, tx 129, vout 1):

```json
{
  ""value"": 0.00000000,
  ""n"": 1,
  ""scriptPubKey"": {
    ""asm"": ""OP_RETURN OP_DUP OP_HASH160 cd2b3298b7f455f39805377e5f213093df3cc09a OP_EQUALVERIFY OP_CHECKSIG"",
    ""hex"": ""6a76a914cd2b3298b7f455f39805377e5f213093df3cc09a88ac"",
    ""type"": ""nonstandard""
  }
}
```"
bitcoin/bitcoin,2021-05-20 18:42:36,feature,wallet: add destination (output) and bump fee,"This would allow ad hoc transaction batching. When a wallet transaction is unconfirmed, I'd like to be able to add an additional destination / output. [BIP 125](https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki) requires that such a transaction also increases the fee rate.

One approach would be to create a new wallet RPC `addoutput, which takes a transaction hash, address, amount and fee rate (difference).

A better approach imo would be to add a new argument `extra_outputs` to `bumpfee` (and `psbtbumpfee`).  This would have the same format as `outputs` in [send](https://bitcoincore.org/en/doc/0.21.0/rpc/wallet/send/).

Two complications come to mind:
1. If the original transaction used `subtract_fee_from_outputs` we don't store that information (see also #11122), so either:
   a) the user has to provide that array again for us to subtract the additional fee correctly; or
   b) the extra fee is paid entirely from change
2. If the previous transaction confirms, rather than the new one, the user has to figure this out and manually craft a new transaction"
bitcoin/bitcoin,2021-05-09 10:59:06,feature,Enable reading of pchCommand before Complete(),"I always found it useful to be able to see what message was incoming from another node as soon as the header had been received, but since #16202 it no longer appears to be possible to discern the pchCommand until the complete message has been received.

Is there a way to determine the message as soon as the header has been received? This could be useful functionality in order to be able to reduce bandwidth, and for logging and debugging."
bitcoin/bitcoin,2021-05-07 14:47:30,feature,Broadcast a transaction to specific nodes,"**Is your feature request related to a problem? Please describe.**
There is no argument in [`sendrawtransaction`](https://bitcoincore.org/en/doc/0.21.0/rpc/rawtransactions/sendrawtransaction/) to mention the peers 

**Describe the solution you'd like**
Add an argument in `sendrawtransaction` that accepts one or more addresses for nodes.

**Describe alternatives you've considered**

https://github.com/libbtc/libbtc#send-a-raw-transaction-to-specific-peers-on-mainnet-and-show-debug-infos-use-a-timeout-of-5s

**Additional context**

> Note that the transaction will be sent unconditionally to **all peers**, so using this
for manual rebroadcast may degrade **privacy** by leaking the transaction's origin, as
nodes will normally not rebroadcast non-wallet transactions already in their mempool.

<sup>https://bitcoincore.org/en/doc/0.21.0/rpc/rawtransactions/sendrawtransaction/</sup>

Rebroadcast thing mentioned above will be fixed in https://github.com/bitcoin/bitcoin/pull/21061 however this option will still be useful."
bitcoin/bitcoin,2021-04-18 15:40:37,feature,Develop watch-only wallet,"**Is your feature request related to a problem? Please describe.**
I'm trying to create a watch only wallet on bitcoin-qt with bitcoin core.

**Describe the solution you'd like**
Password/PIN protected, QR-code capability."
bitcoin/bitcoin,2021-04-14 21:29:40,feature,Style Guide Enum Bool Thoughts,"In many places we use `bool` parameters to denote some effect.

I suggest that throughout the codebase, we make an effort to (where feasible/touched) replace these with enum class.

It's a bit more verbose, but it's already a norm to do `f(/* confusing bool */ true)`, and it would be nice if our compiler helped us out.

Further, it makes it easier should later code extend the functionality to add more/different options.

In order to reduce clutter we could make a macro `BoolEnum(Argument, EnabledName, DisabledName)`

Not high importance, so I don't think we should make a project out of it, but I was looking at some code recently where it would have been nice.

Con: we don't need more structs."
bitcoin/bitcoin,2021-04-04 16:28:01,feature,How to tell compilers to not drop the lock stack when using Assume/Assert?,"It would be nice if there was a way to tell compilers not to drop the lock stack and thus issue warnings when accessing a symbol that needs a lock inside `Assume`/`Assert`.

Hit by (at least): @ajtowns , @jnewbery , me."
bitcoin/bitcoin,2021-03-31 10:22:46,feature,Add mitigation for disk fill via logging attacks,"Short version:

It would be nice if we could render ""disk fill via logging"" vulnerabilities unexploitable by introducing a mitigation like the one suggested in the ""up for grabs"" PR #19995. That PR was Concept ACK:ed by @naumenkogs, @laanwj and @jnewbery, but unfortunately closed due to lack of time. Volunteers welcome!

---

Long version:

A disk fill attack is an attack where an untrusted party (such as a peer) is able to cheaply make your node log to disk excessively. The excessive logging may fill your disk and thus make your node crash either cleanly (best case: if disk fill rate is relatively slow) or uncleanly (worst case: if disk fill rate is relatively fast).

It is easy to accidentally introduce a disk fill vulnerability: all it takes is a `LogPrintf` in a code path which is easily and cheaply triggered by a remote attacker.

It would be nice if we could kill this vulnerability bug class by introducing a general mitigation mechanism which would remove the ability exploit such such a misplaced `LogPrintf`. (Our first line of defence would obviously be to never misplace a `LogPrintf`, but realistically logging mistakes happen and that's where mitigations kick in as a _second_ line of defence.)

One possible mitigation was suggested in PR #19995 which received Concept ACKs from @naumenkogs, @laanwj and @jnewbery. The reviewers came up with some good ideas for improvements which need to be implemented. Unfortunately I don't have time to implement those changes myself, but if someone is looking for ""up for grabs"" PRs then #19995 would be a very good choice. It is seldom one gets the chance to kill an entire vulnerability bug class :) I'd be glad to review and help out.

The solution suggested in the referenced PR is one of many possible solutions, but regardless of which solution we choose I think we need _some_ disk fill attack mitigation to kill this bug class once and for all :)"
bitcoin/bitcoin,2021-03-01 08:37:11,feature,contrib: Current systemd usage doesn't allow for dependencies,"The current [systemd service](https://github.com/bitcoin/bitcoin/blob/master/contrib/init/bitcoind.service) does not allow gracefully for services to depend on `bitcoind`. All dependent units will be launched immediately, regardless of current status. So if it is to work at all, they need an inefficient polling loop.

In the service file the service type is specified as `Type=forking` but we don't heed the behavior specified. From the `systemd.service(5)` man page:

> If set to forking, it is expected that the process configured with ExecStart= will call fork() as part of its start-up. The parent process is expected to exit when start-up is complete and all communication channels are set up.

A possible solution is #21007, which adds `-daemonwait` so that the control is only returned to the parent process when startup is complete. In combination with `Type=forking`, I think this achieves the proper functionality: to start dependent units only when RPC functionality is working.

With that the only change to the service file needed would be to use `-daemonwait` instead of `-daemon`.

An alternative would be to implement support for `Type=notify` and do readyness notification through `sd_notify`. But I opted for daemonwait because it seems more generally useful. The advantage of using a native notification mechanism, however, would be that it is still possible to have logging through stdout to the journal. The drawback that it introduces an optional dependency on `libsystemd`."
bitcoin/bitcoin,2021-02-23 17:43:12,feature,Solve for %51 attact,"**Is your feature request related to a problem? Please describe.**
Yes, this problem is security problem for pow consensus protocol.

**Describe the solution you'd like**
Solution is basic, the new consensus algorithm Safe Proof of Work, blocks will have a two hash block, and miner select from random, first hash mining or second hash mining. this is changed all mining proccess. And add into the hash, the merkle root of the blocks of the blockchain the miners wants to add. If first hash blocks merkler root not equal second hash blocks merkle root, all nodes and miners restart process.


**Describe alternatives you've considered**
If you want to know more, you can check the my github repository. (onuratakan/SPOW) I published with mozilla public license.
"
bitcoin/bitcoin,2021-02-20 06:14:36,feature,"guix: Prints ""g++: not found"" when building depends","Steps to reproduce: Start a guix build on a system without gcc.


```
/bin/sh: 1: gcc: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: g++: not found
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin18/native/bin/clang': No such file or directory
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin18/native/bin/clang': No such file or directory
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin18/native/bin/clang++': No such file or directory
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin18/native/bin/clang++': No such file or directory
Found macOS SDK at '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/SDKs/Xcode-11.3.1-11C505-extracted-SDK-with-libcxx-headers', using...
make: Entering directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
/bin/sh: 1: gcc: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: g++: not found
make[1]: Entering directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
/bin/sh: 1: gcc: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: g++: not found
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin/native/bin/clang': No such file or directory
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin/native/bin/clang': No such file or directory
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin/native/bin/clang++': No such file or directory
env: '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends/x86_64-apple-darwin/native/bin/clang++': No such file or directory
make[1]: Leaving directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
make[1]: Entering directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
/bin/sh: 1: gcc: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: g++: not found
make[1]: Leaving directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
make[1]: Entering directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
/bin/sh: 1: gcc: not found
/bin/sh: 1: gcc: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: g++: not found
/bin/sh: 1: x86_64-w64-mingw32-gcc: not found
/bin/sh: 1: x86_64-w64-mingw32-gcc: not found
/bin/sh: 1: x86_64-w64-mingw32-g++: not found
/bin/sh: 1: x86_64-w64-mingw32-g++: not found
make[1]: Leaving directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
make: Leaving directory '/home/micap/temp/scratch/guix/bitcoin/bitcoin/depends'
INFO: Building commit a4903f747ccd for platform triple x86_64-linux-gnu:"
bitcoin/bitcoin,2021-02-18 09:15:46,feature,"Refactor (move-only) into a ""block storage"" module","See:

* https://github.com/bitcoin/bitcoin/pull/15946/files#r281221080
* https://github.com/bitcoin/bitcoin/pull/21030#issuecomment-771384797"
bitcoin/bitcoin,2021-02-16 15:57:04,feature,Add Ranges to to Output Descriptors,"[Output Descriptors](https://github.com/bitcoin/bitcoin/blob/master/doc/descriptors.md#multisig) do not contain support for ranges.

BIP44/49/84 account uses two chains (for receiving addresses and for change addresses).

Having possibility to express ranges would allow us to capture the essence of BIP44/49/84 accounts in one Output Descriptor, e.g.

```
pkh([d34db33f/44'/0'/0']xpub6ERApfZwUNrhLCkDtcHTcxd75RbzS1ed54G1LkBUHQVHQKqhMkhgbmJbZRkrgZw4koxb5JaHWkY4ALHY2grBGRjaDMzQLcgJvLJuZZvRcEL/[0-1]/*)
```

(note the `[0-1]/*` at the end)."
bitcoin/bitcoin,2021-02-15 09:18:27,feature,Github <> Slack integration,"**Is your feature request related to a problem? Please describe.**
No

**Describe the solution you'd like**
Can you add the slack github integration to this repo (https://slack.github.com/), so that changes can be easily tracked in slack

**Describe alternatives you've considered**
I understand that email notifications can be used, but in my opinion slack notifications provides easier team organisation.

**Additional context**
None
"
bitcoin/bitcoin,2021-02-06 12:57:07,feature,Feature: Add EditorConfig,"### Motivation

Developers are supposed to follow [Coding style](https://github.com/bitcoin/bitcoin/blob/master/doc/developer-notes.md#coding-style-general). However, [from time to time](https://github.com/bitcoin/bitcoin/pull/21075#discussion_r570125634) a PR is created and then its author is asked to change tabs to spaces, for example.

Introducing an `.editorconfig` file can mitigate these formatting issues:

### User story

A contributor wants to create a new PR. She clones Bitcoin Core repo, opens her editor, the editor loads `.editorconfig` rules and writes her patch with correct formatting rules. Less Coding Style issues is then discovered in the PR review process and thus less CI runs are needed.

### What is EditorConfig file?

https://editorconfig.org provides very well and concise explanation:

> What is EditorConfig?

> EditorConfig helps maintain consistent coding styles for multiple developers working on the same project across various editors and IDEs. The EditorConfig project consists of a file format for defining coding styles and a collection of text editor plugins that enable editors to read the file format and adhere to defined styles. EditorConfig files are easily readable and they work nicely with version control systems.

### Support

`.editorconfig` is supported in many IDEs and text editors. Sometimes, the support is out-of-box and sometimes a plugin is needed. However, for example, VS Code detects `.editorconfig` presence and automatically offers you to install the missing plugin. 

See https://editorconfig.org/#pre-installed for details on support. Visual Studio is supported, VS Code and IntelliJ IDEA are supported and many others.

### My editor does not support `.editorconfig`

Then nothing really changes for you.

### `.editorconfig` vs `.clang-format`

As explained [here](https://devblogs.microsoft.com/cppblog/clangformat-support-in-visual-studio-2017-15-7-preview-1/):

> Note that Visual Studio also supports EditorConfig, which works in a similar way. ClangFormat, however, has a [much larger variety of style options](https://clang.llvm.org/docs/ClangFormatStyleOptions.html) than EditorConfig, including some very C++ specific rules that can be set, and it is already used by C++ developers today.

Having both `.editorconfig` and `.clang-format` in a project, may not always work correctly though, I think. As some editors may have a plugin for `.editorconfig` and a plugin for `clang-formatter` which may not work correctly in unison.

### Proposed `.editorconfig`

This proposal is based on [Developer Notes](https://github.com/bitcoin/bitcoin/blob/master/doc/developer-notes.md#coding-style-general):

```yaml
# This is the top-most EditorConfig file.
root = true

# For all files.
[*]
charset = utf-8
end_of_line = lf
insert_final_newline = false

# Shell scripts
[*.sh]
indent_size = 4
indent_style = space
trim_trailing_whitespace = true

# C++ files
[*.{h,cpp}]
indent_size = 4
indent_style = space
trim_trailing_whitespace = true

# Python files
[*.py]
indent_size = 4
indent_style = space
trim_trailing_whitespace = true

# Makefiles
[Makefile,*.am]
indent_style = tab
trim_trailing_whitespace = true

# Markdown files
[*.md]
trim_trailing_whitespace = true

# .cirrus.yml, .appveyor.yml, .fuzzbuzz.yml, etc.
[*.yml]
indent_style = space
indent_size = 2
trim_trailing_whitespace = true
```

Note that the syntax can be much shorter but it is not my goal here, I prefer clarity at this point.

So what is this specifying:

* `charset`: Use `UTF-8` in all files.
* `end_of_line`: Line endings should be `LF` by default in all files.
* `insert_final_newline`: Do not add a blank line at the end of a file by default.

And then there are rules for various types of files.

The rules does not cover everything. One can see that there actually many different file types (meaning, unique file extensions) using this simple PowerShell script:

```powershell
Get-ChildItem -Recurse | % {$_.Extension.ToLower()} | sort | unique
```

with the following output:

```
.1
.ac
.adoc
.am
.bash-completion
.bat
.bmp
.c
.cc
.cert
.cfg
.clang_complete
.clang-format
.cmake
.cmd
.cnf
.com
.conf
.cpp
.css
.csv
.doxyfile
.dtd
.empty
.exe
.exp
.gci
.gitattributes
.github
.gitignore
.gitmodules
.guess
.h
.hex
.hpp
.html
.icns
.ico
.idb
.ilk
.in
.include
.ini
.init
.ipp
.jam
.js
.json
.lastbuildstate
.lib
.list
.log
.m
.m4
.md
.mk
.mm
.moc
.obj
.openrc
.openrcconf
.patch
.pc
.pdb
.pl
.plist
.png
.po
.pro
.py
.python-version
.qbk
.qm
.qml
.qrc
.raw
.rb
.rc
.recipe
.res
.s
.sage
.sass
.scm
.scss
.service
.sgml
.sh
.sln
.spec
.sub
.supp
.svg
.targets
.td
.tlog
.ts
.tx
.txt
.ui
.user
.v2
.vcxproj
.verbatim
.vscode
.xml
.xpm
.xsl
.y
.yapf
.yml
.yy
```

What do you think?"
bitcoin/bitcoin,2021-02-03 11:05:33,feature,Modify `testmempoolaccept` to handle client's `max_raw_tx_fee` check failure,See https://github.com/bitcoin/bitcoin/pull/21062#discussion_r568583132
bitcoin/bitcoin,2021-02-01 20:12:05,feature,log: Add debug log category prefix,"I wanted to log (especially incoming) onion connections.
Was unsure if category `net` or `tor` would do that.

In the debug log you do not see which debug message is of what category, or if it is of no debug category at all (standard log).

I would like if debug log categories are logged e.g. with a `[<debug log category>] ` prefix.
E.g. for `net` debug category log line, the line is currently logged like this (I hope I am right that this belongs to `net`category, so this is an example of the uncertainty that results in the current absence of the category logging):
`2021-02-01T19:33:08Z SOCKS5 connected zncs3yn6h4l7c3z7.onion`

My wish would be that it would be logged like this:

`2021-02-01T19:33:08Z [net] SOCKS5 connected zncs3yn6h4l7c3z7.onion`

If that would have any drawback like log gets bloated, an option to toggle debug log category prefix logging could be introduced, e.g. `debugcategorylogging=<1|0>`"
bitcoin/bitcoin,2021-01-27 20:43:37,feature,RPC field to indicate which of the conflicted wallet transactions is in the mempool,"`listtransactions`/`listsinceblock` don't currently indicate which of the conflicted unconfirmed wallet transactions are considered 'active' (in the node's mempool) and which aren't.

To determine this, one currently has to issue an additional `getmempoolentry` rpc call and check if that fails or not. It would be useful if this information was more readily available, without requiring additional calls.

~~Additionally, it appears that there's an inconsistency between `gettransaction` and `listtransactions`. Normally, `listtransactions` returns a flattened concatenated list of the `details` for all the wallet transactions, with one entry per `detail` entry. But in this case, `gettransaction` returns an empty `details` array for 'non active' transactions, which should to my understanding translate to the transaction not showing up in `listtransactions` at all, yet it does.~~ (this is wrong, it was a PEBMAC)

My preference would be for 'non active' unconfirmed transactions to show up in both, but with a flag that indicates their status (similarly to `confirmations < 0` for transactions that conflict with confirmed transactions)."
bitcoin/bitcoin,2021-01-21 17:00:56,feature,Threshold signing for releases,"For signing the SHA256SUMS.asc in the distribution I would like to move away from using a signing key that I solely, personally possess. I'm not entirely sure how, threshold signing is only a possibility there might be others.

I think it would be ideal if we could distribute the process over multiple people, like a M out of N scheme. For example, a few (relatively) trusted gitian builders.

The resulting signature should ideally be verifiable in the same way as it is now (with `gnupg`), getting people to adapt a custom tool for validation is going to be difficult."
bitcoin/bitcoin,2020-12-31 02:53:11,feature,Better errors for address use from wrong network,"I spent too long to figure out I was putting mainnet addresses to regtest node, errors weren't helpful at `getaddressinfo` and `validateaddress`.

Seems like a good first issue to augment the error messages when prefix/hrp don't match current network."
bitcoin/bitcoin,2020-12-23 17:53:39,feature,`decodescript` returns wrong reqSigs for complex scripts,"This issue may be related to https://github.com/bitcoin/bitcoin/issues/20102 but I don't think it is, because I get the expected reqSigs for other p2sh / p2wsh scripts.

Create a redeem script that includes both OP_CHECKMULTISIG and some other condition such as OP_CHECKLOCKTIMEVERIFY

Feed the redeem script into the `decodescript` RPC 

**Expected behavior**

I expect reqSigs to match the number corresponding to the OP_CHECKMULTISIG portion of the redeem script.

**Actual behavior**

The output has ""reqSigs"" set to 1.

**To reproduce**

Example script:

```
$ ./bitcoin-cli -testnet -named decodescript hexstring=03bcef1cb175532102e47b8a3f7cd012c08369814af843cbb545cf9ba7f8e037d385e6213678a7f272210364c573ac74edd46bfa3e6ae1cd3aad2c6607af0a8d6ff3751147a8d73c6968d52102173becdbff83c43653d0273838a774d6ae42e1ea63ad7b9af53bd7b65bbbb04321033eb39dedc8527c796a9d619ba3ed3e9f611ef3fbb76a33b42806c0d138124a0021037a40c9aaa3c402ac95b0072dfe6e48486e30c0c0138aef7544e325d0b8faaa4e55ae

{
  ""asm"": ""1896380 OP_CHECKLOCKTIMEVERIFY OP_DROP 3 02e47b8a3f7cd012c08369814af843cbb545cf9ba7f8e037d385e6213678a7f272 0364c573ac74edd46bfa3e6ae1cd3aad2c6607af0a8d6ff3751147a8d73c6968d5 02173becdbff83c43653d0273838a774d6ae42e1ea63ad7b9af53bd7b65bbbb043 033eb39dedc8527c796a9d619ba3ed3e9f611ef3fbb76a33b42806c0d138124a00 037a40c9aaa3c402ac95b0072dfe6e48486e30c0c0138aef7544e325d0b8faaa4e 5 OP_CHECKMULTISIG"",
  ""type"": ""nonstandard"",
  ""p2sh"": ""2MtWVwxQiEeHaUNB6YgAWDo2fiLb5pivGrJ"",
  ""segwit"": {
    ""asm"": ""0 9767ecace7e49ced3cfa047924760497cb4717473b1ef35d3227d6a23360fa4a"",
    ""hex"": ""00209767ecace7e49ced3cfa047924760497cb4717473b1ef35d3227d6a23360fa4a"",
    ""reqSigs"": 1,
    ""type"": ""witness_v0_scripthash"",
    ""addresses"": [
      ""tb1qjan7et88ujww6086q3ujgasyjl95w9688v00xhfjylt2yvmqlf9qzpqkl5""
    ],
    ""p2sh-segwit"": ""2Mu6nuTgpQ4cC7S557FXidPHa1WbzqEr3uN""
  }
}
```

**System information**

Bitcoin Core 0.20.1

Ubuntu 20.04

Using bitcoin-cli against local node.
"
bitcoin/bitcoin,2020-12-12 08:29:49,feature,Can we create a non proof-of-childs documentation to install and run properly this repo?,"I have tried several times to install and run this repo in a fresh ubuntu 20.04 operative system. 

All the documentation I have found is outdated. And there is not an evident clear path to successfully install this repo in at least an OS. 

I would like to suggest if possible, an exhaustive doc that explains how to install this repo in any Linux distribution.  "
bitcoin/bitcoin,2020-12-02 17:32:39,feature,Please split the `-msghand` thread into multiple threads.,"It seems when using good storage that this thread act as bottleneck in a way that other threads are waiting completion from it a the cpu level when performing initial full node synchronisation.

As a result, Bitcoin is mostly single threaded in that case (the `-msghand` thread take 100% of a single core leaving other cores idle even on a core duo cpu).

This what currently prevents syncing a full node with `-txindex` in less than 1 hour."
bitcoin/bitcoin,2020-11-26 22:07:09,feature,Partially Signed Bitcoin Transaction (PSBT) GUI for Bitcoin Core Request,"Dear Developers,

Do you fine people plan on adding a GUI to Bitcoin Core so that users can create a PSBT and  also sign a PSBT for cold storage users? I would love this feature!!!!! I think you can do this with command line but it's risky and not simple. I ask because I only use Bitcoin Core as my wallet and don't have easy cold storage spending method without bringing all online.

Thank you and I love you all!

**Is your feature request related to a problem? Please describe.**
No

**Describe the solution you'd like**
an easy to use GUI to create a PSBT and to sign a PSBT for cold storage.

**Describe alternatives you've considered**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->

**Additional context**
<!-- Add any other context or screenshots about the feature request here. -->
"
bitcoin/bitcoin,2020-11-20 21:39:48,feature,"Add ""walletpassphrasechange"" command in bitcoin-wallet.exe","This is an underrated useful tool. Dear devs, please add this ""feature"". Thanks."
bitcoin/bitcoin,2020-11-11 14:03:53,feature,Add macOS ARM build (universal or additional binaries),"First ARM based Macs are available now.
See the porting guide https://developer.apple.com/documentation/xcode/porting_your_macos_apps_to_apple_silicon and the architectural differences: https://developer.apple.com/documentation/apple_silicon/addressing_architectural_differences_in_your_macos_code

Things to do:
* [x] fix depends build on ARM with macOS 10.16 (done in merged #20482)
* [x] fix CRC32 build issue (fix in #20603)
* [x] update macOS build readme (if required)
* [x] allow cross compiling ARM64 Mac on linux/gitian
* [x] fix `make deploy` on ARM64"
bitcoin/bitcoin,2020-11-09 01:02:17,feature,GUI-Feedback on calculating transaction fees ,"
I stumbled across fee calculation messing up units. 
Please take a look at this [discussion](https://bitcoin.stackexchange.com/questions/99915/bitcoin-qt-ignored-user-input-for-fee-calculation/99917#99917) which is related [to](https://github.com/bitcoin-core/gui/issues/64).

Therefore, I'd like to suggest the following use case: 
User selects manually editing fee and user asks for sending.
Next bitcoin-qt calculates the fee added to the transaction then GUI shows to user the calculated fee and ask for confirmation.
If ok, then send transaction else edit fee calculation and repeat.

"
bitcoin/bitcoin,2020-10-25 19:41:27,feature,Hardcoded seeds for Torv3 addresses,"For the 0.22 release we'll want to start hardcoding Torv3 addresses instead of (or in addition to) Torv2.

The biggest challenge here is not how to hardcode them, although that will require a few minor script and code changes, but how to collect them. The release process is to get the addresses from DNS seeders, however these currently don't support the `addrv2` message nor Torv3 addresses in the first place. Nor do they really have a need to."
bitcoin/bitcoin,2020-10-20 17:25:19,feature,Dandelion++,"**Is your feature request related to a problem? Please describe.**
+ BIP 156 never got implemented in Bitcoin Core which could improve privacy: https://github.com/bitcoin/bips/blob/master/bip-0156.mediawiki
+ Reasons: (TLDR: Denial of Service) 
https://github.com/bitcoin/bitcoin/pull/13947#issuecomment-513858189

     https://bitcoin.stackexchange.com/a/81504/
+ Dandelion++ proposed for Bitcoin: https://arxiv.org/pdf/1805.11060.pdf
+ Implemented in Monero: https://github.com/monero-project/monero/pull/6314


**Describe the solution you'd like**
Implement Dandelion++ in Bitcoin Core and if it involves any risks, let's test, try to find solutions or workarounds.

**Describe alternatives you've considered**
Tor

**Additional context**
Not sure how much is this PR and associated project related to this issue: 
https://github.com/bitcoin/bitcoin/pull/18038

Also there is no option to specify Tor for `sendrawtransaction` RPC command : 
https://bitcoin.stackexchange.com/questions/99442/in-bitcoin-core-how-to-use-tor-for-broadcasting-new-transactions-only"
bitcoin/bitcoin,2020-10-17 12:01:45,feature,Support Tor v3 seeding,"**Is your feature request related to a problem? Please describe.**

DNS seeding for Tor V3 Edwards curve nodes is not possible in the current A/AAAA design.

**Describe the solution you'd like**

Support for Tor v3 seeding:
By creating a BIP that outlines how that can be done.

Until we have that:
Add at least some fixed v3 node addresses in the vSeeds list.

DNS seeding for Tor V3 nodes is not possible in the current A/AAAA design.
When v2 fades out seeders are unable to hand over learned known V3 onions
encoded in there DNS A/AAAA answer records.

Not that enable DNS seeding while using Tor is a good privacy idea anyway,
but since some users are behind chains of NAT's
and just like or must bootstrap over Tor, we should support that.

With the next release, users will be reachable by V3 onions the node created and gossip them but be unable to get also those onion V3 seeds by the build in seeders or 
there own DNS Tor v2/ipv4/6 seeders in the usual fashion on a clean bootstrap.

So to mitigate against fragmentation,
at least we should add some build in v3 node addresses i.e.
from the known seeder nodes.
So nodes have a chance to stay solely in Tor and v3 and are not forced to leak.

Or/and think about building for and using something like the lightning mechanism
to support also seeding like we used to now also for Tor v3 onions.
https://github.com/lightningnetwork/lightning-rfc/blob/master/10-dns-bootstrap.md

general caveat of long v3 onion names is that we can no longer bootstarp in out of ip4/ip6 by use of
A and AAAA records that fit the now long onion address, but might be forced to support
DNS SRV calls for the long names but SRV DNS calls are not supported by Tor and the socks5 proxy.
So the task is that we must find a way to bootstrap in a private maner before Tor v2 fades out.

**Describe alternatives you've considered**

Until we have that:
Add at least some fixed v3 node addresses in the vSeeds list.

**Additional context**
https://github.com/lightningnetwork/lightning-rfc/blob/master/10-dns-bootstrap.md"
bitcoin/bitcoin,2020-10-14 20:29:11,feature,Document supported methods for backups and restore,Existing literature on backing up and restoring are on external sites and forums and may become outdated. They may also be recommending methods that could result in wallet file corruption. We should document the supported backup and restoration methods in repo or on the website so that people can refer to those as the officially supported methods. This also lets us update them as files and folder structures change.
bitcoin/bitcoin,2020-10-12 07:19:58,feature,"Validate user input and keep path in a separate argument for importwallet, createwallet and dumpwallet","**Is your feature request related to a problem? Please describe.**

Wallets with weird names possible which can be exploited in vulnerable web applications that use Bitcoin Core and allow the users to create and import/export wallet

`../testwallet` for Linux
`..\\testwallet` for Windows

Tried on Bitcoin Core v 0.20.0

https://github.com/bitcoin/bitcoin/pull/20080#issuecomment-706766527


**Describe the solution you'd like**
+ Keep two arguments: 
`wallet_name` and `wallet_path` for `createwallet` 
`filename` and `filepath` for `dumpwallet` `importwallet`

+ Validate user input. Name should not contain special characters. Path should be optional and if not specified use a default value.

**Describe alternatives you've considered**
Web developers should create secure web apps that use Bitcoin Core.

**Additional context**

![image](https://user-images.githubusercontent.com/13405205/95716478-2a05ad00-0c89-11eb-9e35-2720c82bad61.png)


I understand its not a vulnerability in Bitcoin Core and only affects vulnerable web apps that use Bitcoin Core. However we can at least consider it a bug that may affect something in future or other projects that use Bitcoin Core. Basic checks for user input can improve the security. In 2017 I had a website in which someone had reported a vulnerability that could be used to change price of flight tickets and book with almost zero bitcoin. It was an issue with the website and we had to fix it although nobody could exploit it because the third party APIs that we were using to book the fight tickets were validating all the things. So a ticket couldn't be processed after tampering and changing the price by attacker. Similarly, if any web developer makes a mistake and using Bitcoin Core for the web app would still be unaffected if Bitcoin Core itself doesn't allow such things for wallet names. 

There have been lot of directory traversal related vulnerabilities, recently one was reported in Facebook android app:

https://portswigger.net/daily-swig/vulnerability-in-facebook-android-app-nets-10k-bug-bounty

"
bitcoin/bitcoin,2020-10-07 12:33:31,feature,Use orange icon for bitcoin account,"Currently the account that hosts this repo and several others uses the black bitcoin icon which (as far as I'm concerned) is the Bitcoin Core brand icon. Would it not be more on-brand to use the orange icon for this account and the black Bitcoin Core icon for the bitcoin-core account? A discussions was had several weeks ago around branding here https://github.com/bitcoin-core/gui/issues/89 

Visualized below:

![Group 114](https://user-images.githubusercontent.com/55287964/95338088-1fdc5b00-08e5-11eb-8c5f-208e55df038b.png)

[Here](https://www.figma.com/file/4dO1LqPY0WAgp5d1Bz3U8j/Bitcoin-Core-Designs?node-id=16%3A14) is the orange icon on Figma that can be exported (as SVG, PNG, JPG etc.) and used.

Posted an issue over at https://github.com/bitcoin-core/gui/issues/100 regarding changing the orange icon to black for the bitcoin-core account.


"
bitcoin/bitcoin,2020-10-05 16:29:48,feature,Wallet: Reenable -fallbackfee by default for regtest and signet (and maybe testnet too)?,"This [PR](https://github.com/bitcoin/bitcoin/pull/16524) merged in October 2019 disabled `-fallbackfee` by default across all chains (mainnet, testnet, regtest). 

The only motivation for doing this for regtest (and maybe testnet too) that I can see is:

> Now it is 0 by default for all chains, thus there's no need to call Params(). ([comment](https://github.com/bitcoin/bitcoin/pull/16524#issue-303550511))

However, this does mean that if you don't set a fee or enable `-fallbackfee` you get this error.

```
error code: -4
error message:
Fee estimation failed. Fallbackfee is disabled. Wait a few blocks or enable -fallbackfee.
```
Any thoughts on reenabling `-fallbackfee` by default for regtest, signet (and maybe testnet too)? I think it makes sense to continue to have it disabled by default for real money on mainnet.

If I'm missing context please direct me to it and I'll close this.

Bitcoin StackExchange post: https://bitcoin.stackexchange.com/questions/97174/when-using-bitcoin-cli-i-get-an-error-regarding-fallback-fees-when-trying-to-sen
"
bitcoin/bitcoin,2020-09-24 17:52:51,feature,"split policy/error consensus codes for CLEANSTACK, MINAMALIF","Discussion here https://github.com/bitcoin/bitcoin/pull/20006#issuecomment-698487304

"
bitcoin/bitcoin,2020-09-11 14:14:49,feature,"""Good First Review"" label","I would like to suggest a small idea that I had, to make it easier for beginner to review their first PRs. Analogous to the ""Good first issue"" label, I am suggesting a ""Good first review"" label.

As a general guideline, labeled pull requests should have some (ideally all) of the following characteristics:
- Complexity level low
- A tentative small change (<100 LoC)
- A detailed description of the PR background if needed
- General instructions/hints on how to test/reproduce

Examples of pulls that generally tend to be good first reviews:
- A newly added RPC that can be easily manually tested to verify functionality
- A PR that only adds new functional test coverage since these tend to be self-documenting
- A documentation change that can be verified to be correct with manual testing

Similar to other labels the creator of the pull could ask for the label to be applied or contributors with the power to give labels could apply the proactively."
bitcoin/bitcoin,2020-09-09 09:26:44,feature,Onion address in Bitcoin Core Wallet,"**Is your feature request related to a problem? Please describe.**

I am not sure if there is a RPC method available to directly get the onion address used so I checked it in `localaddresses` returned by `getnetworkinfo` https://developer.bitcoin.org/reference/rpc/getnetworkinfo.html

It was also mentioned in debug.log file:

![image](https://user-images.githubusercontent.com/13405205/92579623-0e367200-f2ab-11ea-9815-f549f3a3756e.png)


**Describe the solution you'd like**

I would love to see an onion address and maybe qr code in the wallet if it is listening on Tor similar to [ABCore](https://github.com/greenaddress/abcore/blob/cc629a854f3083cf4bd1a743de80a254c72aa8ea/app/src/main/java/com/greenaddress/abcore/RPCIntentService.java#L134):

![image](https://user-images.githubusercontent.com/13405205/92579987-800ebb80-f2ab-11ea-9d02-fc8744a9c10c.png)


**Describe alternatives you've considered**

Check the onion address in debug.log or `localaddresses` returned for `getnetworkinfo`

**Additional context**

Linked to https://github.com/bitcoin/bitcoin/issues/19923 because if we add such option to check the onion address, it will have to be added in the [Tor documentation](https://github.com/bitcoin/bitcoin/blob/master/doc/tor.md).
"
bitcoin/bitcoin,2020-09-09 02:55:06,feature,Fatal performance when importing 151M private keys,"Earlier I was importing several thousands of private keys to Bitcoin Core and it took much time, especially rescan of the blockchain. Few hours, >3 surely.

But now, when I am importing 151M private keys (10 GB file with keys) the import process is now taking 2 days and I have 65% for now.

How badly Bitcoin Core is written is unbelivable. There is no other way to scan such an amount of keys, because other apps are for private, limited use and do not offer scanning the blockchain with such a large amount of keys.

Will this be fixed or even rewritten?"
bitcoin/bitcoin,2020-09-01 13:35:09,feature,Revisit the chain view cache policy,Oops wrong repo. Sorry :-)
bitcoin/bitcoin,2020-08-27 11:03:24,feature,rpc: pipe support for submitblock,"If you use the `submitblock` RPC with a large enough block you'll run into ""argument list too long"". Using a pipe should fix this, at least on Linux / macOS.

The `submitblock` RPC can be useful to check validity of a stale block that never made it into the main chain (and that your node never fetched): call `invalidateblock` on its same-height-sibling and then feed it the raw block.

Easiest workaround is to use a library that connects directly to `bitcoind` via RPC (be careful to avoid a line break character at the end). Using the GUI console fails with ""Block decode failed"" for me, but haven't tested that extensively.   "
bitcoin/bitcoin,2020-08-25 20:01:10,feature,Manual-pruning cursor rewind,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->
Setting a lower-than-current prune height via `pruneblockchain` currently requires a full resync. On slower machines, this can take a very long time. It is also unnecessary.

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->
Since all block headers are retained for PoW and chain reorg purposes, bitcoind could feasibly re-download the raw blocks that are lower than the *old* cursor, and above the *new* cursor, and check their validity against the retained headers.
"
bitcoin/bitcoin,2020-08-10 13:19:41,feature,Decouple build system from source. Use CMake to help newcomers and ecosystem!,"### Problem

#### New Developers unable to quickly get up and going in their IDE

The current  build system is very brittle and the custom tailored nature of  it leaves the development team having to address constant breaking changes and new architectures etc. It also leaves new comers to the project in a state of despair when they realize that the current IDE cannot pick up the project. 

For example in this issue #13694 , the user asked ""where I could find the guide on how to install an IDE and debug the code?"" because his top of the line IDE, CLion works by using CMake. The other well known C/C++ IDEs that are currently used are able to and appear to prefer the CMake build system. Sadly, the sarcastic response (i hope) from @sipa was ""Most developers don't use IDEs as far as I know"".

For the Windows users out there, in issue #14118 , the issue got alot of support to the idea of adding CMake, as one is able to quickly work on C/C++ projects given Visual Studio's and VSCode support for CMake projects.

#### Improve ecosystem by having option to build shared libraries

This last point will be a simple theory, but if CMake is added, one could imagine that the ecosystem to grow and flourish and bring in new support and tooling with it. For instance, if i wanted to instead wrap around the C++ code using CFFI and call directly from Python/JS/Whatever I am unable to as where would I even begin to get started on compiling a library as opposed to the executable in a neat manner? Right now the best way to interact with bitcoin is via the rpc it seems, but why not directly ?

The other direct benefits of having a ""simple"" CMake build system is we can undo the tight coupling of what should be the ""build"" with the source code. When developing, the sanitizers can be added and help ensure there is strong checks with proper memory usage and addressing etc.

#### Proper sanitizing and bug catching 

For instance, I found a buffer overflow in the tests within the ctaes library (inside crypto) which was found trivially after setting up a proper standalone CMake file for it. This was found within hours of me poking around and was there for a number of years. Makes one wonder how many other bugs are simple low hanging fruit, just waiting to be picked.

### Solution
According to [The Developer Ecosystem in 2020: How C++ is Doing](https://blog.jetbrains.com/clion/2020/06/dev-eco-cpp-2020/) , the C++ community is moving with conviction to CMake as their build system of choice. Over the last couple years its gone from 34% to 53% of developers choosing it over Makefiles or Visual Studio. If the trend continues, it is imperative the project invests in improving the current status quo.

Begin adding CMake files to cover the major OSs Windows, OSX, Linux on the major processors x86_64. Then expand out to ARM and the smaller targets like Raspberry Pis and the like. Eschew the many optimizations and custom-tailored functions/modules for specific architectures and just add the generic standard library versions until the entire project builds and tests properly.

While this is a ""monumental task"" as noted by @sipa , the hardest part will be decoupling of the many build steps with source code, but thats more tedious and repetitive than anything. 

I can and already have a couple CMake files for some modules like crypto and ctaes to start off. What I am not sure of exactly is the flow of direction between the libraries in the ""bitcoin-core"" project and this one. Which one follows which?

"
bitcoin/bitcoin,2020-08-05 03:49:02,feature,Testnet reset?,"I was thinking, since it looks like the testnet is very hard to mine and has already had many halvings (I know they are faster). What are your thoughts on a testnet reset for the next release of Bitcoin Core? The testnet I believe should get a refresher as it's been many years since the launch of testnet3 and many altcoins are on testnet4. If you all like this, I'll submit a PR to reset the testnet."
bitcoin/bitcoin,2020-08-02 09:09:52,feature,Provide skeleton bitcoin.conf during datadir generation,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->

It would be helpful to provide the example bitcoin.conf provided in the source code to the users that just download the binary/install from their package manager. 

Secondly, a new bitcoind user may not be aware that bitcoin.conf file is an available option. While bitcoin.conf is mentioned in the man page, one would have to know what to look for or read a bit to get to the -conf section. By providing a skeleton file, a new user is more exposed to such an option.

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->

Automatically generate a skeleton bitcoin.conf with something like the one found at ```share/examples/bitcoin.conf``` when first starting bitcoind.

**Describe alternatives you've considered**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->

**Additional context**
<!-- Add any other context or screenshots about the feature request here. -->
"
bitcoin/bitcoin,2020-07-27 11:40:09,feature,"CVE-2012-2459, possible code and performance improvement","ok so, in my effort to create a fullnode from scratch both for learning purpose and need (not a topic for discussion, thanks), I was looking at the code that check Merkle Root to not be vulnerable to CVE-2012-2459.

That vulnerability basically allows you to create a block that has a valid merkle root but contains duplicate transactions, causing a node that receive such block before the correct one, to be stuck on a fork (because that block will be flagged as incorrect and having the same hash of a correct block will prevent the node to ask again for that block, causing a node to be stuck.

Anyway, this is an old CVE that was fixed back in 2012 and code changed during time.
Now in bitcoin core the code is not that pretty and the method to compute merkle root are polluted from a boolean parameter that when read back reflects if the block has been mutated (malleated) or not.

The code is this
```
uint256 ComputeMerkleRoot(std::vector<uint256> hashes, bool* mutated) {
    bool mutation = false;
    while (hashes.size() > 1) {
        if (mutated) {
            for (size_t pos = 0; pos + 1 < hashes.size(); pos += 2) {
                if (hashes[pos] == hashes[pos + 1]) mutation = true;
            }
        }
        if (hashes.size() & 1) {
            hashes.push_back(hashes.back());
        }
        SHA256D64(hashes[0].begin(), hashes[0].begin(), hashes.size() / 2);
        hashes.resize(hashes.size() / 2);
    }
    if (mutated) *mutated = mutation;
    if (hashes.size() == 0) return uint256();
    return hashes[0];
}
```

now thinking about the problem, I think I found a better approach that is O(log n) and allows to have a better code too (without having to pass the `mutated` flag around)... if it works and the logic isn't flawled... so I'd like to know your thought about this.
my paint skill can show you some of the logic:

[![\\[12:37\\]][1]][1]
A, B, C... etc... are transactions

the vertical line is what I call ""safe point"", basically all transactions before that safe point are guaranteed to be not duplicable (this is one of the assumption I do and one thing to check if it's correct)

then, based on how merkle root is computed and how the CVE uses that to do nasty things, you can see some example of malleated blocks

I created then a gist, containing a LINQPad code that can be run as it is and produce outputs to see if the logc is correct and can spot malleated blocks.


https://gist.github.com/MithrilMan/27985e4f5bcc3853e792aa39631b9647


this is an output example of that gist

[![enter image description here][2]][2]

The core logic relies into checking the last transaction against the previous, moving exponentially to the left at each iteration (see the picture with the vertical blue arrows showing which element it checks, or see the linqpad result where it's explicitly detailed)

I handle both the cases where the tx count is even or odd.
To me it seems to work but would like to have some more eyes on that to see if the logic sounds correct or not.
Note how for 9000 tx I have just to compare 14 transactions instead of thousands like current bitcoin code is doing.
Apart from that in my case it has another pros that allow me to split the markle computation and markle cve check in two different places, without having to use a solution like that `mutated` boolean parameter

(actually I can't setup an environment to check if my intuition is correct and benchmark it so I can't provide numbers, but I'm more interested about the check logic itself)

  [1]: https://i.stack.imgur.com/b6BuM.png
  [2]: https://i.stack.imgur.com/go0WH.png"
bitcoin/bitcoin,2020-07-23 07:41:01,feature,Change address selected randomly causes problem with hw. wallet,"Using Core with hardware wallets (ColdCard in this case) comes with a problem:
When you create a PSBT with walletcreatefundedpsbt it pulls a **random** change address. Problem is: ColdCard (I think justly) says: it is out of order and displays a strong warning. Like in our case in a pool of 1000 addresses ColdCard scans and accepts the first 200.

**Solution:**
It would be nice to have an option (default?) to pull change addresses in the derivation order.

**Alternative:**
Right now we can importmulti 200 addresses, so any random address falls into the accepted first 200. Problem is: it's easy to run out of that 200.

I believe pulling random change addresses form a HD wallet gives no extra privacy."
bitcoin/bitcoin,2023-09-09 08:33:15,question,Boundary Limit ?,"@luke-jr @glozow @fanquake @MarcoFalke:

Shouldn't be here in code ""less equal than"" i.e. ""<="" for determination if an UXTO is to be considered ""dust""?
https://github.com/bitcoin/bitcoin/blob/4e1a38c6df91f96ca8a2ef07413ffdb1d59c30cc/src/policy/policy.cpp#L67"
bitcoin/bitcoin,2023-09-05 14:03:18,question,bitcoin-wallet reported as Wacatac malware,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

Running gpg verified binaries leads to ""An active 'Wacatac' malware was prevented""


### Expected behaviour

Not triggering the incident

### Steps to reproduce

Follow https://bitcoin.org/en/full-node#mac-os-x-yosemite-1010x:

- curl -O https://bitcoin.org/bin/bitcoin-core-25.0/ar -zxf bitcoin-25.0-arm64-apple-darwin.tar.gz
- cd Downloads && gpg --verify SHA256SUMS.asc
- tar -zxf bitcoin-25.0-arm64-apple-darwin.tar.gz
- sudo cp bitcoin-25.0/bin/bitcoin* /usr/local/bin/.
- run bitcoind

### Relevant log output

An active 'Wacatac' malware was prevented

### How did you obtain Bitcoin Core

Pre-built binaries

### What version of Bitcoin Core are you using?

25.0-arm64-apple-darwin

### Operating system and version

macOS Ventura 13.5.1

### Machine specifications

apple silicone chip"
bitcoin/bitcoin,2023-08-16 06:19:40,question,What is depends BUILD_ID_SALT ?,"Is it unused? If not, how can it be used? If yes, can it be removed?

References:

```
$ git grep '\\<build_id\\>'
depends/Makefile:#        they rely on the build_id variables
depends/Makefile:build_id:=$(shell env CC='$(build_CC)' C_STANDARD='$(C_STANDARD)' CXX='$(build_CXX)' CXX_STANDARD='$(CXX_STANDARD)' AR='$(build_AR)' RANLIB='$(build_RANLIB)' STRIP='$(build_STRIP)' SHA256SUM='$(build_SHA256SUM)' DEBUG='$(DEBUG)' LTO='$(LTO)' NO_HARDEN='$(NO_HARDEN)' ./gen_id '$(BUILD_ID_SALT)' 'GUIX_ENVIRONMENT=$(realpath $(GUIX_ENVIRONMENT))')
```

The cache is not invalidated:

```
$ (cd depends/ && BUILD_ID_SALT=salt make boost && echo done ) 
done
$ (cd depends/ && BUILD_ID_SALT=salty make boost && echo done ) 
done
"
bitcoin/bitcoin,2023-08-12 16:25:55,question,Regtest mode loses unspents after day,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

Testing in regtest mode, I have noticed that after 1 day of send some funds from A wallet to B, the unspent inputs disappear from wallet B.

**bitcoin.conf**

```bash
# Generated by https://jlopp.github.io/bitcoin-core-config-generator/

# This config should be placed in following path:
# ~/.bitcoin/bitcoin.conf

# [chain]
# Run this node on its own independent test network. Equivalent to -chain=regtest
regtest=1

# [core]
# Specify a non-default location to store blockchain and other data.
datadir=/home/debian/.bitcoin
# Reduce storage requirements by only storing most recent N MiB of block. This mode is incompatible with -txindex and -coinstatsindex. WARNING: Reverting this setting requires re-downloading th>
prune=0

# [wallet]
# Bech32
addresstype=bech32
# Bech32
changetype=bech32
# Specify wallet database path. Can be specified multiple times to load multiple wallets. Path is interpreted relative to <walletdir> if it is not absolute and will be created if it does not ex>
wallet=default

# [Sections]
# Most options automatically apply to mainnet, testnet, and regtest networks.
# If you want to confine an option to just one network, you should add it in the relevant section.
# EXCEPTIONS: The options addnode, connect, port, bind, rpcport, rpcbind and wallet
# only apply to mainnet unless they appear in the appropriate section below.

# Options only for mainnet
[main]

# Options only for testnet
[test]

# Options only for regtest
[regtest]
# Accept command line and JSON-RPC commands.
server=1
# Bind to given address to listen for JSON-RPC connections. This option is ignored unless -rpcallowip is also passed. Port is optional and overrides -rpcport. Use [host]:port notation for IPv6.>
rpcbind=127.0.0.1
# Listen for JSON-RPC connections on this port
rpcport=10001
# Allow JSON-RPC connections from specified source. Valid for <ip> are a single IP (e.g. 1.2.3.4), a network/netmask (e.g. 1.2.3.4/255.255.255.0) or a network/CIDR (e.g. 1.2.3.4/24). This optio>
rpcallowip=127.0.0.1
# Username and hashed password for JSON-RPC connections. The field <userpw> comes in the format: <USERNAME>:<SALT>$<HASH>. RPC clients connect using rpcuser=<USERNAME>/rpcpassword=<PASSWORD> ar>
rpcauth=bitcoin:6e0efb08ebd20eff65959edc38d17bc4$9bc0e273f35e583d9b70071cfd71dc78034ff639d1900c780e3412d7011aab1f
```

### Expected behaviour

Obtain unspent inputs

### Steps to reproduce

```bash
// Send unspent
bitcoin-core.cli -named send outputs='{""bcrt1qugd904ne5z0ks45fgmdcne2qe37s2fv7jqra24"": 0.034}' fee_rate=25

// Generate blocks
bitcoin-core.cli generatetoaddress 6 bcrt1qpg03lyd93mfvz56p92rl6e0mxzasrfskccn77k

// List unspent
bitcoin-core.cli  listunspent 0 9999999 [\\""bcrt1qugd904ne5z0ks45fgmdcne2qe37s2fv7jqra24\\""]
```

After day, trying again to list with `listunspent` and the result is empty.

### Relevant log output

_No response_

### How did you obtain Bitcoin Core

Package manager

### What version of Bitcoin Core are you using?

v0.25

### Operating system and version

Debian 11

### Machine specifications

_No response_"
bitcoin/bitcoin,2023-08-05 17:51:01,question,fuzz:crc32c::ExtendArm64 Undefined symbols for architecture arm64:,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

configure success
make failed



### Expected behaviour

make Failed

### Steps to reproduce

./configure --enable-fuzz --disable-asm 
....
Build Options:
  with external callbacks = no
  with benchmarks         = no
  with tests              = yes
  with ctime tests        = no
  with coverage           = no
  with examples           = no
  module ecdh             = no
  module recovery         = yes
  module extrakeys        = yes
  module schnorrsig       = yes
  module ellswift         = yes

  asm                     = no
  ecmult window size      = 15
  ecmult gen prec. bits   = 4

  valgrind                = no
  CC                      = gcc
  CPPFLAGS                = 
  SECP_CFLAGS             = -O2  -std=c89 -pedantic -Wno-long-long -Wnested-externs -Wshadow -Wstrict-prototypes -Wundef -Wno-overlength-strings -Wall -Wno-unused-function -Wextra -Wcast-align -Wconditional-uninitialized -Wreserved-identifier -fvisibility=hidden 
  CFLAGS                  = -g -O2
  LDFLAGS                 = 

Options used to compile and link:
  external signer = no
  multiprocess    = no
  with libs       = no
  with wallet     = yes
    with sqlite   = yes
    with bdb      = yes
  with gui / qt   = no
  with zmq        = no
  with test       = not building test_bitcoin because fuzzing is enabled
  with fuzz binary = yes
  with bench      = no
  with upnp       = no
  with natpmp     = no
  use asm         = no
  USDT tracing    = no
  sanitizers      = 
  debug enabled   = no
  gprof enabled   = no
  werror          = no
  LTO             = no

  target os       = darwin22.6.0
  build os        = darwin22.6.0

  CC              = gcc
  CFLAGS          = -pthread -g -O2
  CPPFLAGS        =  -DABORT_ON_FAILED_ASSUME  -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=3  -DHAVE_BUILD_INFO -Xclang -internal-isystem/usr/local/include -DMAC_OSX -DOBJC_OLD_DISPATCH_PROTOTYPES=0 -DPROVIDE_FUZZ_MAIN_FUNCTION 
  CXX             = g++ -std=c++17
  CXXFLAGS        =    -Wstack-protector -fstack-protector-all  -Wall -Wextra -Wgnu -Wformat -Wformat-security -Wvla -Wshadow-field -Wthread-safety -Wloop-analysis -Wredundant-decls -Wunused-member-function -Wdate-time -Wconditional-uninitialized -Woverloaded-virtual -Wsuggest-override -Wunreachable-code-loop-increment -Wimplicit-fallthrough -Wdocumentation  -Wno-unused-parameter -Wno-self-assign    -g -O2
  LDFLAGS         =  -lpthread  -Wl,-bind_at_load -Wl,-fixup_chains   -Wl,-headerpad_max_install_names -Wl,-dead_strip -Wl,-dead_strip_dylibs 
  AR              = /usr/bin/ar
  ARFLAGS         = cr
....
make

### Relevant log output

  AR       libbitcoin_util.a
  CXX      libbitcoin_consensus_a-arith_uint256.o
  CXX      consensus/libbitcoin_consensus_a-merkle.o
  CXX      consensus/libbitcoin_consensus_a-tx_check.o
  CXX      libbitcoin_consensus_a-hash.o
  CXX      primitives/libbitcoin_consensus_a-block.o
  CXX      primitives/libbitcoin_consensus_a-transaction.o
  CXX      libbitcoin_consensus_a-pubkey.o
  CXX      script/libbitcoin_consensus_a-bitcoinconsensus.o
  CXX      script/libbitcoin_consensus_a-interpreter.o
  CXX      script/libbitcoin_consensus_a-script.o
  CXX      libbitcoin_consensus_a-uint256.o
  AR       libbitcoin_consensus.a
  CXX      crypto/libbitcoin_crypto_base_la-chacha_poly_aead.lo
  CXX      crypto/libbitcoin_crypto_base_la-chacha20.lo
  CXX      crypto/libbitcoin_crypto_base_la-poly1305.lo
  CXX      crypto/libbitcoin_crypto_base_la-muhash.lo
  CXX      crypto/libbitcoin_crypto_base_la-ripemd160.lo
  CXX      crypto/libbitcoin_crypto_base_la-sha1.lo
  CXX      crypto/libbitcoin_crypto_base_la-sha256.lo
  CXX      crypto/libbitcoin_crypto_base_la-sha3.lo
  CXX      crypto/libbitcoin_crypto_base_la-sha512.lo
  CXX      crypto/libbitcoin_crypto_base_la-siphash.lo
  CXXLD    crypto/libbitcoin_crypto_base.la
  CXX      rpc/libbitcoin_cli_a-client.o
  AR       libbitcoin_cli.a
  CXXLD    test/fuzz/fuzz
Undefined symbols for architecture arm64:
  ""crc32c::ExtendArm64(unsigned int, unsigned char const*, unsigned long)"", referenced from:
      crc32c::Extend(unsigned int, unsigned char const*, unsigned long) in libcrc32c.a(libcrc32c_la-crc32c.o)
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[2]: *** [test/fuzz/fuzz] Error 1
make[1]: *** [all-recursive] Error 1
make: *** [all-recursive] Error 1

### How did you obtain Bitcoin Core

Compiled from source

### What version of Bitcoin Core are you using?

25.x

### Operating system and version

MacOS Ventura 13.5

### Machine specifications

M1 MacBook Pro 16"" 10/32/64GB 1TB"
bitcoin/bitcoin,2023-07-21 13:54:45,question,Bitcoin Core v25.0 Crashes,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

Bitcoin Core keeps crashing and won't stay up. I have been running a Bitcoin node on a Windows 10 computer for several years and had never experienced a Bitcoin Core crash before. 

I had been running Bitcoin Core v0.21.1 since if first came out but left the node unattended for a few weeks this summer. I restarted it earlier this week and the Bitcoin Core log window showed its data base was several thousand blocks out of sync. The last I saw on the Bitcoin Core log window was that it had some 50 blocks to go to complete the synchronization. I do not know if the synchronization finished or not, but a few hours later I noticed the Bitcoin Core log window gone and the bitcoin-qt.exe process disappeared from the task manager process list. 

I restarted Bitcoin Core and surprisingly the log window showed its data base was more than one thousand blocks out of sync. In other words, it lost a large number of blocks in the crash. I rebooted the windows computer and restarted Bitcoin Core three more times but it crashed within a few hours each time. I updated Bitcoin Core to v25.0 hoping that the latest version would fix the problem. Unfortunately, I tried v25.0 several times and it crashes within a few hours each time. 

I reran Bitcoin Core from the command prompt window (bitcoind.exe) with the debug option and wrote its output to a file (bitcoinlog.txt), which I am including below to help identify the problem. I would really appreciate it if anyone would could give me some guidance on how to fix this problem, so I can get my Bitcoin node back up and running. 

### Expected behaviour

Expected my Bitcoin node to sync up to the Bitcoin blockchain and continue to load new blocks like it has reliably done for several years now.

### Steps to reproduce

Restarted Bitcoin Core (bitcoin-qt.exe) after some 4 or 5 weeks offline.

### Relevant log output

[bitcoinlog.txt](https://github.com/bitcoin/bitcoin/files/12127528/bitcoinlog.txt)


### How did you obtain Bitcoin Core

Pre-built binaries

### What version of Bitcoin Core are you using?

v25.0

### Operating system and version

Windows 10 Version 22H2

### Machine specifications

Using a Windows 10 computer running Intel Core i7-8565 CPU with 8 GB RAM and 2 TB HDD."
bitcoin/bitcoin,2023-06-17 16:07:59,question,"Failure running CI locally: ""#0 15.01 Error: Unable to find a match: glibc-devel.x86_64 libstdc++-devel.x86_64 glibc-devel.i686 libstdc++-devel.i686""","### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

I'm following the guide in `ci/README.md` but I can't get any of the environments to run successfully.


### Expected behaviour

Run CI locally

### Steps to reproduce


macOS:
```
--> docker -v
Docker version 24.0.2, build cb74dfc
--> uname -a
Darwin   21.6.0 Darwin Kernel Version 21.6.0: Thu Mar  9 20:10:19 PST 2023; root:xnu-8020.240.18.700.8~1/RELEASE_ARM64_T8101 arm64
```

command:
`FILE_ENV=""./ci/test/00_setup_env_i686_centos.sh"" ./ci/test_run_all.sh`



### Relevant log output

Full log: https://gist.github.com/pinheadmz/912bbb8dc55bc9e95ca8dda660f3800b

end of log:
```
#0 7.735 + bash -c 'dnf -y --allowerasing install gcc-c++ glibc-devel.x86_64 libstdc++-devel.x86_64 glibc-devel.i686 libstdc++-devel.i686 ccache libtool make git python3 python3-pip which patch lbzip2 xz procps-ng dash rsync coreutils bison util-linux '
#0 25.06 Extra Packages for Enterprise Linux 9 - aarch64 1.0 MB/s |  18 MB     00:17    
#0 30.34 Extra Packages for Enterprise Linux 9 - Next -  448 kB/s | 606 kB     00:01    
#0 30.75 Last metadata expiration check: 0:00:01 ago on Sat Jun 17 16:06:48 2023.
#0 31.46 No match for argument: glibc-devel.x86_64
#0 31.47 No match for argument: libstdc++-devel.x86_64
#0 31.47 No match for argument: glibc-devel.i686
#0 31.48 No match for argument: libstdc++-devel.i686
#0 31.48 Package python3-3.9.16-2.el9.aarch64 is already installed.
#0 31.53 Error: Unable to find a match: glibc-devel.x86_64 libstdc++-devel.x86_64 glibc-devel.i686 libstdc++-devel.i686
```

### How did you obtain Bitcoin Core

Compiled from source

### What version of Bitcoin Core are you using?

master 
f0758d8a6696657269d9c057e7aa079ffa9e1c16                                                                                                                                                                        


### Operating system and version

macOS 12.6.5

### Machine specifications

_No response_"
bitcoin/bitcoin,2023-06-03 06:04:35,question,Build fails on Fedora 36 - configure failed for src/secp256k1,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

Found a recent similar issue but didn't help:
https://github.com/bitcoin/bitcoin/issues/27550

I'm trying to run a build on Fedora 36 and I'm seeing the same error.
When I run ./configure I see the following:

configure: WARNING: Bitcoin Core requires this library for BDB (legacy) wallet support
configure: WARNING: Passing --without-bdb will suppress this warning
checking for SQLITE... yes
checking whether to build wallet with support for sqlite... yes
checking whether Userspace, Statically Defined Tracing tracepoints are supported... no
checking for natpmp.h... yes
checking for initnatpmp in -lnatpmp... yes
checking for boostlib >= 1.64.0 (106400)... yes
checking whether Boost.Process can be used... yes
checking for seccomp-bpf (Linux x86-64)... yes
checking for EVENT... yes
checking for EVENT_PTHREADS... yes
checking if evhttp_connection_get_peer expects const char**... no
checking for ZMQ... yes
checking for LIBMULTIPROCESS... no
checking whether to build bitcoind... yes
checking whether to build bitcoin-cli... yes
checking whether to build bitcoin-tx... yes
checking whether to build bitcoin-wallet... yes
checking whether to build bitcoin-util... yes
checking whether to build experimental bitcoin-chainstate... no
checking whether to build libraries... yes
checking if ccache should be used... yes
checking whether C compiler accepts -fdebug-prefix-map=A=B... yes
checking whether C preprocessor accepts -fmacro-prefix-map=A=B... yes
checking if wallet should be enabled... yes
checking whether to build with support for UPnP... no
checking whether to build with support for NAT-PMP... yes
checking whether to build with NAT-PMP enabled by default... no
checking whether to build test_bitcoin... yes
checking whether to reduce exports... no
checking that generated files are newer than configure... done
configure: creating ./config.status
config.status: creating libbitcoinconsensus.pc
config.status: creating Makefile
config.status: creating src/Makefile
config.status: creating doc/man/Makefile
config.status: creating share/setup.nsi
config.status: creating share/qt/Info.plist
config.status: creating test/config.ini
config.status: creating contrib/devtools/split-debug.sh
config.status: creating src/config/bitcoin-config.h
config.status: src/config/bitcoin-config.h is unchanged
config.status: executing depfiles commands
config.status: executing libtool commands
=== configuring in src/secp256k1 (/home/kau/Code/Bitcoin/bitcoin/src/secp256k1)
configure: running /bin/sh ./configure --disable-option-checking '--prefix=/usr/local' '--without-miniupnpc' '--disable-bench' '--without-gui' '--disable-shared' '--with-pic' '--enable-benchmark=no' '--enable-module-recovery' '--enable-module-schnorrsig' --cache-file=/dev/null --srcdir=.
configure: error: cannot find required auxiliary files: compile missing
configure: error: ./configure failed for src/secp256k1

Would be appreciate if you can guide if this error is because of a recent change.

### Expected behaviour

Configure script completes successfully. 

### Steps to reproduce

run the following on master:

./configure --without-miniupnpc --disable-bench --without-gui

### Relevant log output

Already pasted above

### How did you obtain Bitcoin Core

Compiled from source

### What version of Bitcoin Core are you using?

master@ba616b9

### Operating system and version

Fedora 36

### Machine specifications

_No response_"
bitcoin/bitcoin,2023-05-26 15:20:50,question,Allow accepting non-standard transactions on mainnet via local rpc,"To mitigate mempool divergence between nodes and miners, node operators should have the ability to submit non-standard transactions to their local mempools. One of the reasons to do so is to improve the quality of fee estimates.

Acceptance via the p2p network has been discussed in https://github.com/bitcoin/bitcoin/pull/27578 and is deemed to be problematic. This issue is for enabling non-standard transaction submission for the `sendrawtransaction` rpc only.
"
bitcoin/bitcoin,2023-05-18 07:27:48,question,dumpprivkey - This type of wallet does not support this command (code -4),"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

Hello.

When I try export private key for bitcoin address i got:
This type of wallet does not support this command (code -4)

I tried on all 4 types of bitcoin address base58 and bech32 (legacy, segwit...).

I'm using ZIP version of Bitcoin Core v23.1.0 downloaded from:
https://bitcoincore.org/bin/bitcoin-core-23.1/bitcoin-23.1-win64.zip

### Expected behaviour

It should display private key.

Bitcoin address cannot be found?!

If I insert random value for bitcoin address i got this error.

### Steps to reproduce

1. Run Bitcoin Core v23.1.0
2. Select Help >Console
3. Insert command and press enter
dumpprivkey <bitcoin_address>

### Relevant log output

_No response_

### How did you obtain Bitcoin Core

Compiled from source

### What version of Bitcoin Core are you using?

Bitcoin Core v23.1.0

### Operating system and version

Windows

### Machine specifications

/"
bitcoin/bitcoin,2023-05-10 12:53:02,question,Method not found,"### Issues, reports or feature requests related to the GUI should be opened directly on the GUI repo

- [X] I still think this issue should be opened here

### Report

<img width=""1018"" alt=""企业微信截图_958a8dcb-6942-407e-a01b-14eee3df3e14"" src=""https://github.com/bitcoin/bitcoin/assets/39093109/8059bcd8-967f-41b9-9eb6-3a9425f97b2e"">
I build the node with ubuntu20.04 and 24.0.1. But some api return the error as the picture. The run command ""bitcoind -datadir=/data2/.btc/data -rpcuser=""xxxx"" -rpcpassword=""xxx"" -server -txindex=1"""
bitcoin/bitcoin,2023-04-19 10:17:01,question,Compiling a bitcoin core version that accepts transactions over 100vkb,"### Please describe the feature you'd like to see added.

i couldnt manage to find any label that fits this,
when people try to inscribe ordinals that are bigger than 400kb they can not be able to because bitcoin core doesnt allow transactions over 100kvb
even though that would require the person to be a miner or pay miners for it but it still would be nice to guide us on how to compile such bitcoin core version

### Is your feature related to a problem, if so please describe it.

_No response_

### Describe the solution you'd like

a guide on what code changes should be done to compile such version

### Describe any alternatives you've considered

trying to look through the code to understand it and do it myself

### Please leave any additional context

_No response_"
bitcoin/bitcoin,2023-04-01 10:03:31,question,get block or transaction data via rpc api when in the ibd process,"### Please describe the feature you'd like to see added.

Can I get the block or transaction data via the rpc api when the bitcoin core is still in the ibd process that has not been finished?
For example , can I get the downloaded block data via calling the `getblock` api while the client is still in the ibd process?

### Is your feature related to a problem, if so please describe it.

_No response_

### Describe the solution you'd like

_No response_

### Describe any alternatives you've considered

_No response_

### Please leave any additional context

_No response_"
bitcoin/bitcoin,2023-03-03 07:08:11,question,Bitcoin-core. MacOs,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->

When i install bitcoin core for my mac from official site. I used data_dir to my deskop but i did not found `.bitcoin` folder. and i checked out `/Users/${USER}/Library/Application Support` but did not get any folder here too. 
I am unable add to my path of mac but bitcoin-core app running properly. I'm stuck now please help 
**Expected behavior**

<!--- What behavior did you expect? -->

**Actual behavior**

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2023-02-23 20:02:08,question,test: p2p_message_capture.py fails with undefined sanitizer,"On Ubuntu 22.10

Relevant configure variable: `--with-sanitizers=undefined`

```
$ test/functional/p2p_message_capture.py 
2023-02-23T19:55:57.251000Z TestFramework (INFO): PRNG seed is: 8604348948412116696
2023-02-23T19:55:57.251000Z TestFramework (INFO): Initializing test directory /tmp/bitcoin_func_test_v2mn0yad
2023-02-23T19:55:57.666000Z TestFramework (INFO): Stopping nodes
Traceback (most recent call last):
  File ""test/functional/p2p_message_capture.py"", line 72, in <module>
    MessageCaptureTest().main()
  File ""/home/sjors/dev/bitcoin/test/functional/test_framework/test_framework.py"", line 157, in main
    exit_code = self.shutdown()
  File ""/home/sjors/dev/bitcoin/test/functional/test_framework/test_framework.py"", line 313, in shutdown
    self.stop_nodes()
  File ""/home/sjors/dev/bitcoin/test/functional/test_framework/test_framework.py"", line 577, in stop_nodes
    node.stop_node(wait=wait, wait_until_stopped=False)
  File ""/home/sjors/dev/bitcoin/test/functional/test_framework/test_node.py"", line 356, in stop_node
    raise AssertionError(""Unexpected stderr {} != {}"".format(stderr, expected_stderr))
AssertionError: Unexpected stderr streams.h:556:19: runtime error: null pointer passed as argument 1, which is declared to never be null != 
[node 0] Cleaning up leftover process

```

Seems pretty consistent on the latest master."
bitcoin/bitcoin,2023-02-17 17:02:45,question,Hidden fee (about 15% of sum) while send,"<!-- Describe the issue -->
Hello,

My wallet is [3KxxEaECid1H1h5Ya2XnjsxLx8fK6TToQj](https://www.blockchain.com/explorer/addresses/btc/3KxxEaECid1H1h5Ya2XnjsxLx8fK6TToQj) - 18 transactions total.

I sent 0.1BTC, but in blockchain I found 2 transactions: my own (0.1BTC) + unknown fee (0.01999241BTC) - 20% of sum!
TXID: [70a951a496a809597b79753be7b4f05a7b13ece1d09d8d0ae643b0190ace1fba](https://www.blockchain.com/explorer/transactions/btc/70a951a496a809597b79753be7b4f05a7b13ece1d09d8d0ae643b0190ace1fba)

Next I sent 0.1BTC, but in blockchain I found 2 transactions: my own (0.1BTC) + unknown fee (0.00997949BTC) - 10% of sum!
TXID: [60488ac88ed0390cb24b4659aa2256c5eacf4dee102749cd828ea18c293ea090](https://www.blockchain.com/explorer/transactions/btc/60488ac88ed0390cb24b4659aa2256c5eacf4dee102749cd828ea18c293ea090)

I do not understand how this could happen.  In Bitcoin Core I see ONLY my transactions, but blockchain show me more 2 transactions to unknown wallets ([bc1qg3ds029ydsum9pgldpfhmcp94sncrvhqzltp5q](https://www.blockchain.com/explorer/addresses/BTC/bc1qg3ds029ydsum9pgldpfhmcp94sncrvhqzltp5q), [3Be8ZPdgUqxXbagjJ5imvG7nYZzgLxaHHR](https://www.blockchain.com/explorer/addresses/btc/3Be8ZPdgUqxXbagjJ5imvG7nYZzgLxaHHR))

So, total balance in blockchain is less then in Bitcoin Core on this amount (0.02997189BTC)
Bitcoin Core show me 1.38994437 BTC, but blockchain show me 1.35997247BTC (minus two fees above)

What is my really balance? What are these hidden payments? Tell me more about it, please. What can I do to solve this problems in future? Screens from my Bitcoin Core is attached below. Thanks!

**Expected behavior**

<!--- What behavior did you expect? -->

**Actual behavior**

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

Bitcoin Core version v0.18.0 (64-bit) - from official site.

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

Linux blockchain 4.15.0-48-generic #51-Ubuntu SMP Wed Apr 3 08:28:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
![balance](https://user-images.githubusercontent.com/41526801/219715795-1dc5fb27-11f6-4379-a854-4ae23d3730ee.png)
![sent1](https://user-images.githubusercontent.com/41526801/219715797-5b02a4c5-1641-46e8-bf98-9f16d67c10c2.png)
![sent2](https://user-images.githubusercontent.com/41526801/219715802-552becc3-619d-4bfd-80ed-953251bf2f4f.png)
![transactions](https://user-images.githubusercontent.com/41526801/219715806-d1ca757e-9f7b-4c6a-b20c-ea64fa410e8c.png)
![version](https://user-images.githubusercontent.com/41526801/219715810-9b1fb483-8c8a-4246-9b30-d22e02da3b6b.png)
"
bitcoin/bitcoin,2023-02-02 15:07:28,question,BitCoin BlockChain Download Alternate,"please anyone out there having knowledge help me that **How can I deploy a node and start transactions on BTC Core without downloading the complete blockchain**, as its more than 350GB Right now.

I want to know if there is any possible solution to it?
<img width=""659"" alt=""Screenshot 2023-02-02 at 8 06 19 PM"" src=""https://user-images.githubusercontent.com/101569763/216361805-d200b047-e4c9-47fa-8494-826c267f0177.png"">

"
bitcoin/bitcoin,2023-01-30 13:36:58,question,How to interpret the asm section of scriptSig,"I tried asking the question in [this post](https://bitcoin.stackexchange.com/questions/116947/the-asm-section-of-scriptsig) on bitcoin.stackexchange.com but got no answer. The question is this:

I am trying to understand the output from `bitcoin-cli`. The sample transaction's txid is `061959f1a3360d3781a870b2d43f73f7105b194b22f3765fcb9b8f545f9c8317`, from block 222,222.

The `asm` section of `scriptPubKey` (i.e., `OP_DUP OP_HASH160 28dce60cf7ba4d749afce5fd9781a403d293b74a OP_EQUALVERIFY OP_CHECKSIG`) is more understandable, it decodes `hex` and shows the assembly in a (sort of) human-readable format:
```
""vout"": [
    {
      ""value"": 0.63918136,
      ""n"": 0,
      ""scriptPubKey"": {
        ""asm"": ""OP_DUP OP_HASH160 28dce60cf7ba4d749afce5fd9781a403d293b74a OP_EQUALVERIFY OP_CHECKSIG"",
        ""hex"": ""76a91428dce60cf7ba4d749afce5fd9781a403d293b74a88ac"",
        ""address"": ""14j4eyoxaAwA4SHj9YcEyVJ7FsqyWvUh9B"",
        ""type"": ""pubkeyhash""
      }
    },
...
]
```
The question arises when it comes to the `asm` section of `scriptSig`:
```
{
  ""txid"": ""b66e78c919e36a6c563ceb1b29cfec26f7dec3c3fc1b3631c84056f3ae147f2f"",
  ""vout"": 1,
  ""scriptSig"": {
    ""asm"": ""3045022100dceb566dec99cf195aba5d6313f1e95eb7bfc74c93a794c4bfd6dd9f4082d8a002203b495b70b917b3dffdcbe70fc6ff7de910d1697efccc14f3eea6944bda87d21c[ALL] 0445554717c4d3240d818f400ab66fd4de438f2fd9174641ea76480b95cd6e883ec274a10b0691d85ac2cb87dcb9eef58b3abb8ee4bd277c8d6fea09eace2bc24a"",
    ""hex"": ""483045022100dceb566dec99cf195aba5d6313f1e95eb7bfc74c93a794c4bfd6dd9f4082d8a002203b495b70b917b3dffdcbe70fc6ff7de910d1697efccc14f3eea6944bda87d21c01410445554717c4d3240d818f400ab66fd4de438f2fd9174641ea76480b95cd6e883ec274a10b0691d85ac2cb87dcb9eef58b3abb8ee4bd277c8d6fea09eace2bc24a""
}
```
As you can see, it is `304502206ee08c76923816e4ba287142e9f147fe9cd0f26e6bd58b9a43f2283b1c614f46022100d5de298b627407bc7d5ac0a40259cafb865c30c6a67db926c7284da96ff71abd[ALL] 040841958a405ca1c05de4dcf04dfdfd6e7de5e7cb106744977e3d99eab3e59a2b5bc2441e0ad179055c14200745feb2da2d1b4485087e3a9a2a88a6531a6d6b02`, which isn't really decoded.

I checked the same transaction from [blockstream.info](
https://blockstream.info/api/block/00000000000000b8b49d0b61b14994b5c0a511c4b48a1e251ff2b479b2e6f678/txs/725). It's result is: `OP_PUSHBYTES_72 304502206ee08c76923816e4ba287142e9f147fe9cd0f26e6bd58b9a43f2283b1c614f46022100d5de298b627407bc7d5ac0a40259cafb865c30c6a67db926c7284da96ff71abd01 OP_PUSHBYTES_65 040841958a405ca1c05de4dcf04dfdfd6e7de5e7cb106744977e3d99eab3e59a2b5bc2441e0ad179055c14200745feb2da2d1b4485087e3a9a2a88a6531a6d6b02`
which looks more readable and I can understand that this `scriptSig` pushes two byte arrays into the Bitcoin VM's stack.

So the questions are:
1. Why `bitcoin-cli`'s output is like this?
1. How to interpret it? Especially, how to understand the `[ALL]` part in its `asm`? (Perhaps you can just give me a RTFM link?)"
bitcoin/bitcoin,2023-01-28 05:34:25,question,Sender always unknown on the laatest version.,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->
Sender always show unknown. is there any way to see senders in order to make our own accounting?

**Expected behavior**
to see sender too.
<!--- What behavior did you expect? -->

**Actual behavior**

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2022-11-25 14:24:29,question,SHA256SUMS.asc  - Using untrusted key!,"Getting warning `using untrusted key!` when running gpg verification:

```
gpg --keyserver hkp://keyserver.ubuntu.com  \\
    --auto-key-retrieve                     \\
    --trust-model always                    \\
    --verify SHA256SUMS.asc SHA256SUMS
```

Output and warning:
```
#14 22.71 gpg: requesting key 0A41BDC3F4FAFF1C from hkp server keyserver.ubuntu.com
#14 22.99 gpg: key 0A41BDC3F4FAFF1C: public key ""Aaron Clauson (sipsorcery) <aaron@sipsorcery.com>"" imported
#14 22.99 gpg: Total number processed: 1
#14 22.99 gpg:               imported: 1
#14 22.99 gpg: Good signature from ""Aaron Clauson (sipsorcery) <aaron@sipsorcery.com>"" [unknown]
#14 22.99 gpg: WARNING: Using untrusted key!
#14 22.99 gpg: Signature made Thu Nov 17 21:23:22 2022 UTC
#14 22.99 gpg:                using RSA key ED9BDF7AD6A55E232E84524257FF9BDBCC301009
#14 22.99 gpg: requesting key 57FF9BDBCC301009 from hkp server keyserver.ubuntu.com
#14 23.34 gpg: key 57FF9BDBCC301009: 3 duplicate signatures removed
#14 23.34 gpg: key 57FF9BDBCC301009: public key ""Sjors Provoost <sjors@sprovoost.nl>"" imported
#14 23.34 gpg: Total number processed: 1
#14 23.34 gpg:               imported: 1
#14 23.34 gpg: Good signature from ""Sjors Provoost <sjors@sprovoost.nl>"" [unknown]
#14 23.34 gpg:                 aka ""Sjors Provoost <sjors@freedom.nl>"" [unknown]
#14 23.34 gpg: WARNING: Using untrusted key!
#14 23.34 gpg: Signature made Tue Nov 22 11:04:28 2022 UTC
#14 23.34 gpg:                using RSA key 6A8F9C266528E25AEB1D7731C2371D91CB716EA7
#14 23.34 gpg:                issuer ""sebastian.falbesoner@gmail.com""
#14 23.86 gpg: requesting key C2371D91CB716EA7 from hkp server keyserver.ubuntu.com
#14 24.12 gpg: key C2371D91CB716EA7: public key ""Sebastian Falbesoner (theStack) <sebastian.falbesoner@gmail.com>"" imported
#14 24.12 gpg: Total number processed: 1
#14 24.12 gpg:               imported: 1
#14 24.13 gpg: Good signature from ""Sebastian Falbesoner (theStack) <sebastian.falbesoner@gmail.com>"" [unknown]
#14 24.13 gpg: WARNING: Using untrusted key!
#14 24.13 gpg: Signature made Thu Nov 17 19:35:52 2022 UTC
#14 24.13 gpg:                using RSA key 28E72909F1717FE9607754F8A7BEB2621678D37D
#14 24.13 gpg:                issuer ""vertion@protonmail.com""
#14 25.35 gpg: key DA43140F88B4E81F: public key ""vertion@protonmail.com <vertion@protonmail.com>"" imported
#14 25.35 gpg: Total number processed: 1
#14 25.35 gpg:               imported: 1
#14 25.35 gpg: requesting key A7BEB2621678D37D from hkp server keyserver.ubuntu.com
#14 25.58 gpg: key A7BEB2621678D37D: public key ""vertion <vertion@protonmail.com>"" imported
#14 25.58 gpg: Total number processed: 1
#14 25.58 gpg:               imported: 1
#14 25.58 gpg: Good signature from ""vertion <vertion@protonmail.com>"" [unknown]
#14 25.58 gpg: WARNING: Using untrusted key!

```


"
bitcoin/bitcoin,2022-11-04 21:14:06,question,Flushing block file to disk failed when using external drive on macOS Ventura,"I kept getting an error regarding Flushing Block to disk. I've tried to use bitcoin core V0.23 and it doesn't help; although V0.22 was better at loading the backup file, but I couldn't send any of my bitcoin out. I can't seem to load the wallet or the backup file properly. Not a coder and hoping someone can help. I don't think it's an issue with the hard drive. Any suggestion? I'm on MacOSx Ventura 13.0. 



Debug.log file:

2022-11-04T20:34:28Z Using wallet /Volumes/Extreme SSD/bruceltd wallet.dat
2022-11-04T20:34:28Z BerkeleyEnvironment::Open: LogDir=/Volumes/Extreme SSD/database ErrorFile=/Volumes/Extreme SSD/db.log
.
.
.
2022-11-04T20:58:16Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-04T20:58:16Z ERROR: SerializeFileDB: Failed to flush file /Volumes/Extreme SSD/peers.176f

db.log file:
fsync: Inappropriate ioctl for device
PANIC: Inappropriate ioctl for device
txn_checkpoint: failed to flush the buffer cache: DB_RUNRECOVERY: Fatal error, run database recovery


"
bitcoin/bitcoin,2022-11-01 14:04:57,question,Add ability to ignore `SCRIPT_VERIFY_DISCOURAGE_x` flags when broadcasting transactions on test networks.,"After bugs like: https://github.com/btcsuite/btcd/issues/1906 it would be useful to be able to reproduce these bugs in regtest. Currently to do so you would need to manually edit the code and comment out the script flag, then compile your self. It would be beneficial if we could disable these flags to create more reproducible tests."
bitcoin/bitcoin,2022-11-01 11:41:47,question,initialblockdownload set to false prematurely,"<!-- Describe the issue -->

**Expected behavior**

getblockchaininfo.initialblockdownload stays true until all blocks are imported

**Actual behavior**

`getblockchaininfo.initialblockdownload` becomes false before before all blocks are imported:

```
2022-11-01T11:16:39Z UpdateTip: new best=00000000000000000006f01ad0649cefc26c86c24a2808109c584bdcdc0d5293 height=761091 version=0x20f0c000 log2_work=93.816484 tx=776463417 date='2022-10-31T11:13:46Z' progress=0.999730 cache=338.3MiB(2269631txo)
2022-11-01T11:16:39Z Leaving InitialBlockDownload (latching to false)
2022-11-01T11:16:42Z UpdateTip: new best=000000000000000000078315da1efb6937a0d06015891b0412164dc2531e3004 height=761092 version=0x20c00000 log2_work=93.816497 tx=776466523 date='2022-10-31T11:29:40Z' progress=0.999733 cache=338.7MiB(2273000txo)
<snip 162 lines of UpdateTip>
2022-11-01T11:16:57Z UpdateTip: new best=00000000000000000004656d346fbac96ddcec6ee31b6abd696a241cd6994181 height=761255 version=0x2e4a6000 log2_work=93.818629 tx=776748676 date='2022-11-01T11:09:42Z' progress=0.999999 cache=375.6MiB(2573669txo)
```

Observe the 15 seconds it took my (reasonably fast) machine to import the remaining blocks. This is a problem for me since my application relies on this field to determine if syncing is complete. We can not rely on `getblockchaininfo.verificationprogress` either due to https://github.com/bitcoin/bitcoin/issues/26433

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

Start a node that hasn't been synced in a while and observe the log output.

**System information**

Observed on version 22 from the website.
<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2022-10-26 11:51:39,question,SQLite version vulnerability,"https://github.com/bitcoin/bitcoin/blob/69b10212ea5370606c7a5aa500a70c36b4cbb58f/depends/packages/sqlite.mk#L2

SQLite version is before vulnerability [CVE-2022-35737](https://nvd.nist.gov/vuln/detail/CVE-2022-35737) was fixed, details of which are described [here](https://blog.trailofbits.com/2022/10/25/sqlite-vulnerability-july-2022-library-api/)."
bitcoin/bitcoin,2022-10-13 14:54:53,question,estimatesmartfee returns 50 sat/vB on an empty mempool for inclusion in 1008 blocks,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->

**Expected behavior**

<!--- What behavior did you expect? -->

when the mempool is empty, i expect something really low, at least smaller than 3 sat/vB, but not 50 sat/vB

**Actual behavior**

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

```
$ bitcoin-cli -testnet estimatesmartfee 1
{
  ""feerate"": 0.00050106,
  ""blocks"": 2
}
```
```
$ bitcoin-cli -testnet estimatesmartfee 1008
{
  ""feerate"": 0.00050106,
  ""blocks"": 111
}
```

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

run `bitcoin-cli -testnet estimatesmartfee` on the testnet when the difficulty drops to 1 (happens every few months or so i dont know why)

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

bitcoincore.org download v23

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

**Any extra information that might be useful in the debugging process.**

blocks were *flowing* in like every few seconds a block got mined

<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2022-10-06 13:31:15,question,CentOS compilation error-  No rule to make target,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue!

Any report, issue or feature request related to the GUI should be reported at
https://github.com/bitcoin-core/gui/issues/
-->

<!-- Describe the issue -->
I'm trying to compile bitcoin v23.0 tag (commit id: `fcf6c8f`). During the compilation I received this error:
```
make[2]: *** No rule to make target '%reldir%/lib/univalue.cpp', needed by '%reldir%/lib/libunivalue_la-univalue.lo'.  Stop.
```

OS: CentOS 7
Compiler GCC 11.2.0

<!--- What behavior did you expect? -->

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2022-10-02 03:17:47,question,bitcoin core's  sync has stop for days!,"![image](https://user-images.githubusercontent.com/76834109/193436303-1e58832f-9dc5-4b00-a7de-005beba69019.png)

![image](https://user-images.githubusercontent.com/76834109/193436350-b6f248a6-af6c-48d4-89c0-a44b43d523f1.png)

![image](https://user-images.githubusercontent.com/76834109/193436357-36b56a3a-b59d-4bc7-99c0-e23c0b5084e3.png)

OS info:
windows11  21H2

what should i do?"
bitcoin/bitcoin,2022-09-11 19:02:07,question,Sync slow,"Syncing blockchain is sometimes very slow. I think this has become more common in the past months.

Here's a screenshot from Network Traffic window in the GUI, see how there are long periods of absolutely no traffic. Also see how it only downloaded about 100 MB during the first 30minutes of syncing. It's also often connected to just 1 or 2 peers which is weird.

![bitcointrafficverylowandslow](https://user-images.githubusercontent.com/79941375/189544394-3cb3dd32-b384-437e-a785-456b149b0258.png)

Internet is stable and I can easily download 10 MB/second.
CPU load stays mostly low so lack of CPU resources doesn't explain this.
Memory usage is also not high. I have set the memory option in the settings menu to 4 GB.

Sometimes it starts to work faster if you close and restart the program. But as I said this has become worse in the past months. 

Why doesn't it download blocks faster than this? If the problem is that peers can't provide blocks faster, why isn't it looking for more peers?

I'm using the latest master from git as of today."
bitcoin/bitcoin,2022-09-05 14:19:36,question,Conan build system,"<!-- Describe the issue -->
Does bitcoin support building with conan (https://conan.io/) build system?
Is there a way to build bitcoin and the `depends` library with conan?
<!--- What behavior did you expect? -->

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2022-08-28 01:16:28,question,Is there an alternative to the -blockmaxsize option available in the client?,"The -blockmaxsize option for bitcoind was removed with issue #12640, and I need to be able to limit my block creation size, is there an alternative setting that will accomplish this or is there no control of this now beyond restricting my mempool with fees?"
bitcoin/bitcoin,2022-08-20 12:16:48,question,I can't define bitcoin.conf file in different folder as default,"I installed the bitcoin libraries on /mnt/volume_fra1_02, ran it via the following setting

bitcoind -datadir=/mnt/volume_fra1_02/.bitcoin -conf=/mnt/volume_fra1_02/.bitcoin/bitcoin.conf

i get an error when i want to create a new wallet

bitcoin-cli createwallet adminwallet

response : 
No authentication cookie could be found, and RPC password is not set. See -rpcpassword and -stdinrpcpass. Configuration file: (/root/.bitcoin/bitcoin.conf)

Probably still based on ""/root/.bitcoin/bitcoin.conf"" directory.

Could you help?"
bitcoin/bitcoin,2022-08-17 20:25:06,question,./configure hang up,"I am using Mac OS 13.0.1 

i get to this point everytime everyway I try to configure the code from source....

```
checking dependency style of g++... gcc3
checking whether g++ supports C++17 features with -std=c++17... yes
checking whether std::filesystem can be used without link library... no
checking whether std::filesystem needs -lstdc++fs... no
checking whether std::filesystem needs -lc++fs... configure: error: in `/bitcoin/bitcoin-cli':
configure: error: cannot figure out how to use std::filesystem
See `config.log' for more details
```

what can i do to remedy the situation?"
bitcoin/bitcoin,2022-08-08 11:31:15,question,bitcoin-cli createwallet error : Compiled without sqlite support,"I installed bitcoin core on ubuntu server (I got help from: https://baloian.medium.com/how-to-setup-and-run-a-bitcoin-full-node-on-ubuntu-a106fb86dbb3).

The following commands work fine:

bitcoin-cli -getinfo

bitcoin-cli getblockchaininfo

bitcoin-cli getnetworkinfo

bitcoin-cli getpeerinfo
I get this error when I want to create a new wallet: request :

bitcoin-cli createwallet adminwallet
response :

error code: -4

error message:

Compiled without sqlite support (required for descriptor wallets)"
bitcoin/bitcoin,2022-08-01 21:37:30,question,feature_config_args.py failure,"
Run test: `python3 feature_config_args.py`

Results in error:

> 
> 2022-08-01T21:05:29.574000Z TestFramework (INFO): Initializing test directory /tmp/bitcoin_func_test_die2tixp
> 2022-08-01T21:05:30.306000Z TestFramework (INFO): Test config args logging
> 2022-08-01T21:05:30.564000Z TestFramework (INFO): Test seed peers
> 2022-08-01T21:05:40.697000Z TestFramework (ERROR): Assertion failed
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 133, in main
>     self.run_test()
>   File ""/home/user/bitcoin/test/functional/feature_config_args.py"", line 229, in run_test
>     self.test_seed_peers()
>   File ""/home/user/bitcoin/test/functional/feature_config_args.py"", line 175, in test_seed_peers
>     self.start_node(0, extra_args=['-dnsseed=1', '-fixedseeds=1', f'-mocktime={start}'])
>   File ""/usr/lib/python3.9/contextlib.py"", line 124, in __exit__
>     next(self.gen)
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 423, in assert_debug_log
>     self._raise_assertion_error('Expected messages ""{}"" does not partially match log:\\n\\n{}\\n\\n'.format(str(expected_msgs), print_log))
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 167, in _raise_assertion_error
>     raise AssertionError(self._node_msg(msg))
> AssertionError: [node 0] Expected messages ""['Loaded 0 addresses from peers.dat', '0 addresses found from DNS seeds', 'opencon thread start']"" does not partially match log:
> 
>  
>   
>   
>   
>  
>  2022-08-01T21:05:30.776965Z [init] [init/common.cpp:127] [LogPackageVersion] Bitcoin Core version v23.99.0-ce3b75690d10 (release build)
>  2022-08-01T21:05:30.777017Z [init] [init.cpp:657] [InitParameterInteraction] InitParameterInteraction: parameter interaction: -bind set -> setting -listen=1
>  2022-08-01T21:05:30.777088Z [init] [init.cpp:922] [AppInitParameterInteraction] Validating signatures for all blocks.
>  2022-08-01T21:05:30.777094Z [init] [init.cpp:933] [AppInitParameterInteraction] Setting nMinimumChainWork=0000000000000000000000000000000000000000000000000000000000000000
>  2022-08-01T21:05:30.777164Z (mocktime: 2022-08-01T21:05:30Z) [init] [kernel/context.cpp:21] [Context] Using the 'sse4(1way),sse41(4way),avx2(8way)' SHA256 implementation
> 2022-08-01T21:05:30.777175Z (mocktime: 2022-08-01T21:05:30Z) [init] [random.cpp:100] [ReportHardwareRand] Using RdSeed as an additional entropy source
>  2022-08-01T21:05:30.777180Z (mocktime: 2022-08-01T21:05:30Z) [init] [random.cpp:103] [ReportHardwareRand] Using RdRand as an additional entropy source
>  2022-08-01T21:05:30.778975Z (mocktime: 2022-08-01T21:05:30Z) [init] [init/common.cpp:98] [StartLogging] Default data directory /home/user/.bitcoin
>  2022-08-01T21:05:30.778985Z (mocktime: 2022-08-01T21:05:30Z) [init] [init/common.cpp:99] [StartLogging] Using data directory /tmp/bitcoin_func_test_die2tixp/node0/regtest
>   2022-08-01T21:05:30.778998Z (mocktime: 2022-08-01T21:05:30Z) [init] [init/common.cpp:104] [StartLogging] Config file: /tmp/bitcoin_func_test_die2tixp/node0/bitcoin.conf
>   2022-08-01T21:05:30.779015Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: regtest=""1""
>   2022-08-01T21:05:30.779025Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] bind=""127.0.0.1""
>   2022-08-01T21:05:30.779032Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] discover=""0""
>   2022-08-01T21:05:30.779039Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] dnsseed=""0""
>   2022-08-01T21:05:30.779047Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] fallbackfee=""0.0002""
>   2022-08-01T21:05:30.779053Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] fixedseeds=""0""
>   2022-08-01T21:05:30.779060Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] keypool=""1""
>   2022-08-01T21:05:30.779067Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] listenonion=""0""
>   2022-08-01T21:05:30.779074Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] natpmp=""0""
>   2022-08-01T21:05:30.779082Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] peertimeout=""999999999""
>   2022-08-01T21:05:30.779089Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] port=""11093""
>   2022-08-01T21:05:30.779096Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] printtoconsole=""0""
>   2022-08-01T21:05:30.779104Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] rpcdoccheck=""1""
>   2022-08-01T21:05:30.779112Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] rpcport=""16093""
>   2022-08-01T21:05:30.779119Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] server=""1""
>   2022-08-01T21:05:30.779127Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] shrinkdebugfile=""0""
>   2022-08-01T21:05:30.779134Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] unsafesqlitesync=""1""
>   2022-08-01T21:05:30.779141Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Config file arg: [regtest] upnp=""0""
>   2022-08-01T21:05:30.779149Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: datadir=""/tmp/bitcoin_func_test_die2tixp/node0""
>   2022-08-01T21:05:30.779156Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: debug=""""
>   2022-08-01T21:05:30.779164Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: debugexclude=""libevent""
>   2022-08-01T21:05:30.779171Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: debugexclude=""leveldb""
>   2022-08-01T21:05:30.779178Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: dnsseed=""1""
>   2022-08-01T21:05:30.779184Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: fixedseeds=""1""
>   2022-08-01T21:05:30.779192Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: logsourcelocations=""""
>   2022-08-01T21:05:30.779199Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: logthreadnames=""""
>   2022-08-01T21:05:30.779206Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: logtimemicros=""""
>   2022-08-01T21:05:30.779213Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: mocktime=""1659387930""
>   2022-08-01T21:05:30.779224Z (mocktime: 2022-08-01T21:05:30Z) [init] [util/system.cpp:1118] [logArgsPrefix] Command-line arg: uacomment=""testnode0""
>   2022-08-01T21:05:30.779232Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1148] [AppInitMain] Using at most 125 automatic connections (1024 file descriptors available)
>   2022-08-01T21:05:30.788089Z (mocktime: 2022-08-01T21:05:30Z) [init] [script/sigcache.cpp:101] [InitSignatureCache] Using 16 MiB out of 32/2 requested for signature cache, able to store 524288 elements
>   2022-08-01T21:05:30.796940Z (mocktime: 2022-08-01T21:05:30Z) [init] [validation.cpp:1669] [InitScriptExecutionCache] Using 16 MiB out of 32/2 requested for script execution cache, able to store 524288 elements
>   2022-08-01T21:05:30.796987Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1175] [AppInitMain] Script verification uses 1 additional threads
>   2022-08-01T21:05:30.797361Z (mocktime: 2022-08-01T21:05:30Z) [scheduler] [util/thread.cpp:18] [TraceThread] scheduler thread start
>   2022-08-01T21:05:30.806770Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:184] [InitHTTPAllowList] [http] Allowing HTTP connections from: 127.0.0.0/8 ::1/128 
>   2022-08-01T21:05:30.806890Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:321] [HTTPBindAddresses] [http] Binding RPC on address ::1 port 16093
>   2022-08-01T21:05:30.807109Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:321] [HTTPBindAddresses] [http] Binding RPC on address 127.0.0.1 port 16093
>   2022-08-01T21:05:30.807155Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:401] [InitHTTPServer] [http] Initialized HTTP server
>   2022-08-01T21:05:30.807167Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:403] [InitHTTPServer] [http] creating work queue of depth 16
>   2022-08-01T21:05:30.807177Z (mocktime: 2022-08-01T21:05:30Z) [init] [rpc/server.cpp:291] [StartRPC] [rpc] Starting RPC
>   2022-08-01T21:05:30.807193Z (mocktime: 2022-08-01T21:05:30Z) [init] [httprpc.cpp:296] [StartHTTPRPC] [rpc] Starting HTTP RPC server
>   2022-08-01T21:05:30.807201Z (mocktime: 2022-08-01T21:05:30Z) [init] [httprpc.cpp:245] [InitRPCAuthentication] Using random cookie authentication.
>   2022-08-01T21:05:30.807297Z (mocktime: 2022-08-01T21:05:30Z) [init] [rpc/request.cpp:106] [GenerateAuthCookie] Generated RPC authentication cookie /tmp/bitcoin_func_test_die2tixp/node0/regtest/.cookie
>   2022-08-01T21:05:30.807312Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:676] [RegisterHTTPHandler] [http] Registering HTTP handler for / (exactmatch 1)
>   2022-08-01T21:05:30.807321Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:676] [RegisterHTTPHandler] [http] Registering HTTP handler for /wallet/ (exactmatch 0)
>   2022-08-01T21:05:30.807335Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:425] [StartHTTPServer] [http] Starting HTTP server
>   2022-08-01T21:05:30.807343Z (mocktime: 2022-08-01T21:05:30Z) [init] [httpserver.cpp:427] [StartHTTPServer] [http] starting 4 worker threads
>   2022-08-01T21:05:30.807552Z (mocktime: 2022-08-01T21:05:30Z) [http] [httpserver.cpp:287] [ThreadHTTP] [http] Entering http event loop
>   2022-08-01T21:05:30.807784Z (mocktime: 2022-08-01T21:05:30Z) [init] [wallet/load.cpp:51] [VerifyWallets] Using wallet directory /tmp/bitcoin_func_test_die2tixp/node0/regtest/wallets
>   2022-08-01T21:05:30.807801Z (mocktime: 2022-08-01T21:05:30Z) [init] [noui.cpp:56] [noui_InitMessage] init message: Verifying wallet(s)…
>   2022-08-01T21:05:30.807840Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1261] [AppInitMain] Using /16 prefix for IP bucketing
>   2022-08-01T21:05:30.807850Z (mocktime: 2022-08-01T21:05:30Z) [init] [noui.cpp:56] [noui_InitMessage] init message: Loading P2P addresses…
>   2022-08-01T21:05:30.808116Z (mocktime: 2022-08-01T21:05:30Z) [init] [logging/timer.h:57] [Log] [addrman] CheckAddrman: new 0, tried 0, total 0 started
>   2022-08-01T21:05:30.808228Z (mocktime: 2022-08-01T21:05:30Z) [init] [logging/timer.h:57] [Log] [addrman] CheckAddrman: completed (0.00ms)
>   2022-08-01T21:05:30.808242Z (mocktime: 2022-08-01T21:05:30Z) [init] [addrdb.cpp:194] [LoadAddrman] Loaded 0 addresses from peers.dat  0ms
>   2022-08-01T21:05:30.808586Z (mocktime: 2022-08-01T21:05:30Z) [init] [noui.cpp:56] [noui_InitMessage] init message: Loading banlist…
>   2022-08-01T21:05:30.808626Z (mocktime: 2022-08-01T21:05:30Z) [init] [banman.cpp:38] [LoadBanlist] [net] Loaded 0 banned node addresses/subnets  0ms
>   2022-08-01T21:05:30.808645Z (mocktime: 2022-08-01T21:05:30Z) [init] [net.cpp:1523] [SetTryNewOutboundPeer] [net] setting try another outbound peer=false
>   2022-08-01T21:05:30.808654Z (mocktime: 2022-08-01T21:05:30Z) [init] [net.cpp:2170] [SetNetworkActive] SetNetworkActive: true
>   2022-08-01T21:05:30.810409Z (mocktime: 2022-08-01T21:05:30Z) [init] [policy/fees.cpp:455] [Read] [estimatefee] Reading estimates: 190 buckets counting confirms up to 48 blocks
>   2022-08-01T21:05:30.810608Z (mocktime: 2022-08-01T21:05:30Z) [init] [policy/fees.cpp:455] [Read] [estimatefee] Reading estimates: 190 buckets counting confirms up to 12 blocks
>   2022-08-01T21:05:30.811134Z (mocktime: 2022-08-01T21:05:30Z) [init] [policy/fees.cpp:455] [Read] [estimatefee] Reading estimates: 190 buckets counting confirms up to 1008 blocks
>   2022-08-01T21:05:30.811253Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1403] [AppInitMain] Cache configuration:
>   2022-08-01T21:05:30.811267Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1404] [AppInitMain] * Using 2.0 MiB for block index database
>   2022-08-01T21:05:30.811276Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1412] [AppInitMain] * Using 8.0 MiB for chain state database
>   2022-08-01T21:05:30.811290Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1428] [AppInitMain] * Using 440.0 MiB for in-memory UTXO set (plus up to 286.1 MiB of unused mempool space)
>   2022-08-01T21:05:30.811315Z (mocktime: 2022-08-01T21:05:30Z) [init] [noui.cpp:56] [noui_InitMessage] init message: Loading block index…
>   2022-08-01T21:05:30.811330Z (mocktime: 2022-08-01T21:05:30Z) [init] [validation.cpp:4710] [InitializeChainstate] Switching active chainstate to Chainstate [ibd] @ height -1 (null)
>   2022-08-01T21:05:30.811367Z (mocktime: 2022-08-01T21:05:30Z) [init] [dbwrapper.cpp:150] [CDBWrapper] Opening LevelDB in /tmp/bitcoin_func_test_die2tixp/node0/regtest/blocks/index
>   2022-08-01T21:05:30.826887Z (mocktime: 2022-08-01T21:05:30Z) [init] [dbwrapper.cpp:158] [CDBWrapper] Opened LevelDB successfully
>   2022-08-01T21:05:30.826920Z (mocktime: 2022-08-01T21:05:30Z) [init] [dbwrapper.cpp:183] [CDBWrapper] Using obfuscation key for /tmp/bitcoin_func_test_die2tixp/node0/regtest/blocks/index: 0000000000000000
>   2022-08-01T21:05:30.827091Z (mocktime: 2022-08-01T21:05:30Z) [init] [node/blockstorage.cpp:331] [LoadBlockIndexDB] LoadBlockIndexDB: last block file = 0
>   2022-08-01T21:05:30.827110Z (mocktime: 2022-08-01T21:05:30Z) [init] [node/blockstorage.cpp:335] [LoadBlockIndexDB] LoadBlockIndexDB: last block file info: CBlockFileInfo(blocks=1, size=293, heights=0...0, time=2011-02-02...2011-02-02)
>   2022-08-01T21:05:30.827119Z (mocktime: 2022-08-01T21:05:30Z) [init] [node/blockstorage.cpp:346] [LoadBlockIndexDB] Checking all blk files are present...
>   2022-08-01T21:05:30.827164Z (mocktime: 2022-08-01T21:05:30Z) [init] [dbwrapper.cpp:150] [CDBWrapper] Opening LevelDB in /tmp/bitcoin_func_test_die2tixp/node0/regtest/chainstate
>   2022-08-01T21:05:30.846337Z (mocktime: 2022-08-01T21:05:30Z) [init] [dbwrapper.cpp:158] [CDBWrapper] Opened LevelDB successfully
>   2022-08-01T21:05:30.846444Z (mocktime: 2022-08-01T21:05:30Z) [init] [dbwrapper.cpp:183] [CDBWrapper] Using obfuscation key for /tmp/bitcoin_func_test_die2tixp/node0/regtest/chainstate: 223bb69586684f13
>   2022-08-01T21:05:30.846548Z (mocktime: 2022-08-01T21:05:30Z) [init] [validation.cpp:3894] [LoadChainTip] Loaded best chain: hashBestChain=0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206 height=0 date=2011-02-02T23:16:42Z progress=1.000000
>   2022-08-01T21:05:30.846567Z (mocktime: 2022-08-01T21:05:30Z) [init] [noui.cpp:56] [noui_InitMessage] init message: Verifying blocks…
>   2022-08-01T21:05:30.846583Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1474] [AppInitMain]  block index              35ms
>   2022-08-01T21:05:30.847557Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1631] [AppInitMain] block tree size = 1
>   2022-08-01T21:05:30.847581Z (mocktime: 2022-08-01T21:05:30Z) [init] [init.cpp:1643] [AppInitMain] nBestHeight = 0
>   2022-08-01T21:05:30.847637Z (mocktime: 2022-08-01T21:05:30Z) [loadblk] [util/thread.cpp:18] [TraceThread] loadblk thread start
>   2022-08-01T21:05:30.847728Z (mocktime: 2022-08-01T21:05:30Z) [loadblk] [kernel/mempool_persist.cpp:121] [LoadMempool] Imported mempool transactions from disk: 0 succeeded, 0 failed, 0 expired, 0 already there, 0 waiting for initial broadcast
>   2022-08-01T21:05:30.847748Z (mocktime: 2022-08-01T21:05:30Z) [loadblk] [util/thread.cpp:20] [TraceThread] loadblk thread exit
>   2022-08-01T21:05:30.847790Z (mocktime: 2022-08-01T21:05:30Z) [init] [net.cpp:2103] [BindListenPort] Bound to 127.0.0.1:11093
>   2022-08-01T21:05:30.847830Z (mocktime: 2022-08-01T21:05:30Z) [init] [net.cpp:2103] [BindListenPort] Bound to 127.0.0.1:18445
>   2022-08-01T21:05:30.847866Z (mocktime: 2022-08-01T21:05:30Z) [init] [addrdb.cpp:228] [ReadAnchors] Loaded 0 addresses from ""anchors.dat""
>   2022-08-01T21:05:30.847936Z (mocktime: 2022-08-01T21:05:30Z) [init] [net.cpp:2277] [Start] 0 block-relay-only anchors will be tried for connections.
>   2022-08-01T21:05:30.847950Z (mocktime: 2022-08-01T21:05:30Z) [init] [noui.cpp:56] [noui_InitMessage] init message: Starting network threads…
>   2022-08-01T21:05:30.848029Z (mocktime: 2022-08-01T21:05:30Z) [net] [util/thread.cpp:18] [TraceThread] net thread start
>   2022-08-01T21:05:30.848098Z (mocktime: 2022-08-01T21:05:30Z) [addcon] [util/thread.cpp:18] [TraceThread] addcon thread start
>   2022-08-01T21:05:30.848236Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [util/thread.cpp:18] [TraceThread] opencon thread start
>   2022-08-01T21:05:30.848301Z (mocktime: 2022-08-01T21:05:30Z) [msghand] [util/thread.cpp:18] [TraceThread] msghand thread start
>   2022-08-01T21:05:30.848322Z (mocktime: 2022-08-01T21:05:30Z) [init] [noui.cpp:56] [noui_InitMessage] init message: Done loading
>   2022-08-01T21:05:30.848394Z (mocktime: 2022-08-01T21:05:30Z) [dnsseed] [util/thread.cpp:18] [TraceThread] dnsseed thread start
>   2022-08-01T21:05:30.848416Z (mocktime: 2022-08-01T21:05:30Z) [dnsseed] [net.cpp:1456] [ThreadDNSAddressSeed] Loading addresses from DNS seed dummySeed.invalid.
>   2022-08-01T21:05:30.857530Z (mocktime: 2022-08-01T21:05:30Z) [dnsseed] [addrman.cpp:612] [AddSingle] [addrman] Added 1.0.0.1:18444 mapped to AS0 to new[81][35]
>   2022-08-01T21:05:30.857563Z (mocktime: 2022-08-01T21:05:30Z) [dnsseed] [addrman.cpp:684] [Add_] [addrman] Added 1 addresses (of 1) from jzva5xo5xttqfkfm.internal: 0 tried, 1 new
>   2022-08-01T21:05:30.857575Z (mocktime: 2022-08-01T21:05:30Z) [dnsseed] [net.cpp:1485] [ThreadDNSAddressSeed] 1 addresses found from DNS seeds
>   2022-08-01T21:05:30.857585Z (mocktime: 2022-08-01T21:05:30Z) [dnsseed] [util/thread.cpp:20] [TraceThread] dnsseed thread exit
>   2022-08-01T21:05:30.921809Z (mocktime: 2022-08-01T21:05:30Z) [http] [httpserver.cpp:240] [http_request_cb] [http] Received a POST request for / from 127.0.0.1:43440
>   2022-08-01T21:05:30.921886Z (mocktime: 2022-08-01T21:05:30Z) [httpworker.1] [rpc/request.cpp:179] [parse] [rpc] ThreadRPCServer method=getblockcount user=__cookie__
>   2022-08-01T21:05:30.923628Z (mocktime: 2022-08-01T21:05:30Z) [http] [httpserver.cpp:240] [http_request_cb] [http] Received a POST request for / from 127.0.0.1:43440
>   2022-08-01T21:05:30.923856Z (mocktime: 2022-08-01T21:05:30Z) [httpworker.0] [rpc/request.cpp:179] [parse] [rpc] ThreadRPCServer method=getmempoolinfo user=__cookie__
>   2022-08-01T21:05:31.349127Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:31.349201Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [net.cpp:455] [ConnectNode] [net:debug] trying connection 1.0.0.1:18444 lastseen=146.9hrs
>   2022-08-01T21:05:31.354156Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [net.cpp:2729] [CNode] [net] Added connection peer=0
>   2022-08-01T21:05:31.354233Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [net.cpp:2745] [PushMessage] [net] sending version (114 bytes) peer=0
>   2022-08-01T21:05:31.354306Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [net_processing.cpp:1303] [PushNodeVersion] [net] send version message: version 70016, blocks=0, txrelay=1, peer=0
>   2022-08-01T21:05:31.854950Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:32.356882Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:32.857649Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:33.359252Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:33.860731Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:34.361696Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:34.863290Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:35.364832Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:35.867734Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:36.369805Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:36.870817Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:37.372111Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:37.873116Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:38.374390Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:38.875975Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:39.377264Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:39.878563Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
>   2022-08-01T21:05:40.380302Z (mocktime: 2022-08-01T21:05:30Z) [opencon] [addrman.cpp:769] [Select_] [addrman] Selected 1.0.0.1:18444 from new
> 
> 
> 2022-08-01T21:05:40.709000Z TestFramework (INFO): Stopping nodes
> 2022-08-01T21:05:40.862000Z TestFramework (WARNING): Not cleaning up dir /tmp/bitcoin_func_test_die2tixp
> 2022-08-01T21:05:40.862000Z TestFramework (ERROR): Test failed. Test logging available at /tmp/bitcoin_func_test_die2tixp/test_framework.log
> 2022-08-01T21:05:40.862000Z TestFramework (ERROR): 
> 2022-08-01T21:05:40.862000Z TestFramework (ERROR): Hint: Call /home/user/bitcoin/test/functional/combine_logs.py '/tmp/bitcoin_func_test_die2tixp' to consolidate all logs
> 2022-08-01T21:05:40.863000Z TestFramework (ERROR): 
> 2022-08-01T21:05:40.863000Z TestFramework (ERROR): If this failure happened unexpectedly or intermittently, please file a bug and provide a link or upload of the combined log.
> 2022-08-01T21:05:40.863000Z TestFramework (ERROR): https://github.com/bitcoin/bitcoin/issues
> 2022-08-01T21:05:40.863000Z TestFramework (ERROR):

Logs:
`python3 /home/user/bitcoin/test/functional/combine_logs.py '/tmp/bitcoin_func_test_die2tixp'`

Pasted here:
https://pastebin.com/SZtnGvEK



"
bitcoin/bitcoin,2022-06-20 01:45:26,question,LoadWalletInternal logic check,"In the RPC method:
https://github.com/bitcoin/bitcoin/blob/master/src/wallet/rpc/wallet.cpp
When the RPC method ""loadwallet"" is called, it will call loadwallet(https://github.com/bitcoin/bitcoin/blob/master/src/wallet/wallet.cpp)
and LoadWalletInternal.  When the user repeatedly call the loadwallet with same wallet name. In the LoadWalletInternal funcntion, although it does not call  Addwallet repeatedly to add to context.wallets and avoid open SQLite database repeatedly. But it will make new SQLiteDatabase unique_ptr and do some series checks.  
Is it better to use GetWallet to determine if the wallet is already loaded before calling LoadWalletInternal?
"
bitcoin/bitcoin,2022-06-16 03:12:57,question,Reproducible Test Failures,"I've been having issues performing tests on PRs, so I've tried it multiple times now on master, deleting the directory and starting fresh. This is what I get each time:

`make`

> ...
> ...
> AR       minisketch/libminisketch_clmul.a
>   CXXLD    test/test_bitcoin
> collect2: fatal error: ld terminated with signal 9 [Killed]
> compilation terminated.
> make[2]: *** [Makefile:7539: test/test_bitcoin] Error 1
> make[2]: Leaving directory '/home/user/bitcoin/src'
> make[1]: *** [Makefile:18626: all-recursive] Error 1
> make[1]: Leaving directory '/home/user/bitcoin/src'
> make: *** [Makefile:818: all-recursive] Error 1

`make` a second time, successful

> ...
> ...
> CXX      util/libbitcoinconsensus_la-strencodings.lo
>   CXXLD    libbitcoinconsensus.la
> make[2]: Leaving directory '/home/user/bitcoin/src'
> make[1]: Leaving directory '/home/user/bitcoin/src'
> Making all in doc/man
> make[1]: Entering directory '/home/user/bitcoin/doc/man'
> make[1]: Nothing to be done for 'all'.
> make[1]: Leaving directory '/home/user/bitcoin/doc/man'
> make[1]: Entering directory '/home/user/bitcoin'
> make[1]: Nothing to be done for 'all-am'.
> make[1]: Leaving directory '/home/user/bitcoin'

user@localhost:~/bitcoin$ `make check`

>  Making check in src
> make[1]: Entering directory '/home/user/bitcoin/src'
> make[2]: Entering directory '/home/user/bitcoin/src'
> make[3]: Entering directory '/home/user/bitcoin'
> make[3]: Leaving directory '/home/user/bitcoin'
> make  check-TESTS check-local
> make[3]: Entering directory '/home/user/bitcoin/src'
> make[4]: Entering directory '/home/user/bitcoin/src'
> PASS: minisketch/test
> PASS: univalue/test/object
> PASS: univalue/test/unitester
> PASS: univalue/test/no_nul
> make[5]: Entering directory '/home/user/bitcoin'
> make[5]: Leaving directory '/home/user/bitcoin'
> PASS: qt/test/test_bitcoin-qt
> Testsuite summary for Bitcoin Core 23.99.0
> '# TOTAL: 5
> '# PASS:  5
> '# SKIP:  0
> '# XFAIL: 0
> '# FAIL:  0
> '# XPASS: 0
> '# ERROR: 0
> make[4]: Leaving directory '/home/user/bitcoin/src'
> Running tests: addrman_tests from test/addrman_tests.cpp
> /bin/bash: line 2: test/test_bitcoin: Permission denied
> make[3]: *** [Makefile:20866: test/addrman_tests.cpp.test] Error 1
> make[3]: Leaving directory '/home/user/bitcoin/src'
> make[2]: *** [Makefile:18969: check-am] Error 2
> make[2]: Leaving directory '/home/user/bitcoin/src'
> make[1]: *** [Makefile:18626: check-recursive] Error 1
> make[1]: Leaving directory '/home/user/bitcoin/src'
> make: *** [Makefile:818: check-recursive] Error 1

Errors also.

user@localhost:~/bitcoin$ `sudo make install`

(No issues).

user@localhost:~/bitcoin/test/functional$ `python3 test_runner.py --extended`

> feature_block.py                                   | ✖ Failed  | 83 s
> feature_dbcrash.py                                 | ✖ Failed  | 2812 s
> feature_pruning.py                                 | ✖ Failed  | 582 s

Details for each failed test:

> 9/245 - feature_block.py failed, Duration: 83 s 

> stdout:
> 2022-06-16T00:32:59.996000Z TestFramework (INFO): Initializing test directory /tmp/test_runner_₿_🏃_20220615_202813/feature_block_235
> 2022-06-16T00:33:02.154000Z TestFramework (INFO): Reject block with invalid tx: OutputMissing
> 2022-06-16T00:33:02.380000Z TestFramework (INFO): Reject block with invalid tx: InputMissing
> 2022-06-16T00:33:02.587000Z TestFramework (INFO): Reject block with invalid tx: BadInputOutpointIndex
> 2022-06-16T00:33:02.800000Z TestFramework (INFO): Reject block with invalid tx: DuplicateInput
> 2022-06-16T00:33:03.025000Z TestFramework (INFO): Reject block with invalid tx: PrevoutNullInput
> 2022-06-16T00:33:03.195000Z TestFramework (INFO): Reject block with invalid tx: NonexistentInput
> 2022-06-16T00:33:03.411000Z TestFramework (INFO): Reject block with invalid tx: SpendTooMuch
> 2022-06-16T00:33:03.593000Z TestFramework (INFO): Reject block with invalid tx: CreateNegative
> 2022-06-16T00:33:03.769000Z TestFramework (INFO): Reject block with invalid tx: CreateTooLarge
> 2022-06-16T00:33:03.980000Z TestFramework (INFO): Reject block with invalid tx: CreateSumTooLarge
> 2022-06-16T00:33:04.192000Z TestFramework (INFO): Reject block with invalid tx: TooManySigops
> 2022-06-16T00:33:04.464000Z TestFramework (INFO): Don't reorg to a chain of the same length
> 2022-06-16T00:33:04.571000Z TestFramework (INFO): Reorg to a longer chain
> 2022-06-16T00:33:04.724000Z TestFramework (INFO): Reorg back to the original chain
> 2022-06-16T00:33:05.109000Z TestFramework (INFO): Reject a chain with a double spend, even if it is longer
> 2022-06-16T00:33:05.454000Z TestFramework (INFO): Reject a block where the miner creates too much coinbase reward
> 2022-06-16T00:33:05.665000Z TestFramework (INFO): Reject a chain where the miner creates too much coinbase reward, even if the chain is longer
> 2022-06-16T00:33:06.023000Z TestFramework (INFO): Reject a chain where the miner creates too much coinbase reward, even if the chain is longer (on a forked chain)
> 2022-06-16T00:33:06.314000Z TestFramework (INFO): Accept a block with lots of checksigs
> 2022-06-16T00:33:06.442000Z TestFramework (INFO): Reject a block with too many checksigs
> 2022-06-16T00:33:06.698000Z TestFramework (INFO): Reject a block with a spend from a re-org'ed out tx
> 2022-06-16T00:33:06.908000Z TestFramework (INFO): Reject a block with a spend from a re-org'ed out tx (on a forked chain)
> 2022-06-16T00:33:07.227000Z TestFramework (INFO): Reject a block spending an immature coinbase.
> 2022-06-16T00:33:07.440000Z TestFramework (INFO): Reject a block spending an immature coinbase (on a forked chain)
> 2022-06-16T00:33:07.715000Z TestFramework (INFO): Accept a block of weight MAX_BLOCK_WEIGHT
> 2022-06-16T00:33:07.983000Z TestFramework (INFO): Reject a block of weight MAX_BLOCK_WEIGHT + 4
> 2022-06-16T00:33:08.378000Z TestFramework (INFO): Reject a block with coinbase input script size out of range
> 2022-06-16T00:33:09.150000Z TestFramework (INFO): Accept a block with the max number of OP_CHECKMULTISIG sigops
> 2022-06-16T00:33:09.277000Z TestFramework (INFO): Reject a block with too many OP_CHECKMULTISIG sigops
> 2022-06-16T00:33:09.447000Z TestFramework (INFO): Accept a block with the max number of OP_CHECKMULTISIGVERIFY sigops
> 2022-06-16T00:33:09.509000Z TestFramework (INFO): Reject a block with too many OP_CHECKMULTISIGVERIFY sigops
> 2022-06-16T00:33:09.741000Z TestFramework (INFO): Accept a block with the max number of OP_CHECKSIGVERIFY sigops
> 2022-06-16T00:33:09.818000Z TestFramework (INFO): Reject a block with too many OP_CHECKSIGVERIFY sigops
> 2022-06-16T00:33:10.069000Z TestFramework (INFO): Reject a block spending transaction from a block which failed to connect
> 2022-06-16T00:33:10.434000Z TestFramework (INFO): Check P2SH SIGOPS are correctly counted
> 2022-06-16T00:33:18.330000Z TestFramework (INFO): Reject a block with too many P2SH sigops
> 2022-06-16T00:33:57.687000Z TestFramework (INFO): Accept a block with the max number of P2SH sigops
> 2022-06-16T00:34:01.161000Z TestFramework (INFO): Build block 44 manually
> 2022-06-16T00:34:01.182000Z TestFramework (INFO): Reject a block with a non-coinbase as the first tx
> 2022-06-16T00:34:01.393000Z TestFramework (INFO): Reject a block with no transactions
> 2022-06-16T00:34:01.605000Z TestFramework (INFO): Reject a block with invalid work
> 2022-06-16T00:34:01.835000Z TestFramework (INFO): Reject a block with a timestamp >2 hours in the future
> 2022-06-16T00:34:01.897000Z TestFramework (INFO): Reject a block with invalid merkle hash
> 2022-06-16T00:34:02.059000Z TestFramework (INFO): Reject a block with incorrect POW limit
> 2022-06-16T00:34:02.271000Z TestFramework (INFO): Reject a block with two coinbase transactions
> 2022-06-16T00:34:02.478000Z TestFramework (INFO): Reject a block with duplicate transactions
> 2022-06-16T00:34:02.800000Z TestFramework (INFO): Reject a block with timestamp before MedianTimePast
> 2022-06-16T00:34:03.020000Z TestFramework (INFO): Accept a previously rejected future block at a later time
> 2022-06-16T00:34:03.150000Z TestFramework (INFO): Reject a block with a duplicate transaction in the Merkle Tree (but with a valid Merkle Root)
> 2022-06-16T00:34:03.371000Z TestFramework (INFO): Reject a block with two duplicate transactions in the Merkle Tree (but with a valid Merkle Root)
> 2022-06-16T00:34:03.797000Z TestFramework (INFO): Reject a block with a transaction with prevout.n out of range
> 2022-06-16T00:34:04.011000Z TestFramework (INFO): Reject a block with a transaction with outputs > inputs
> 2022-06-16T00:34:04.325000Z TestFramework (INFO): Reject a block with a transaction with a duplicate hash of a previous transaction (BIP30)
> 2022-06-16T00:34:04.656000Z TestFramework (INFO): Reject a block with a transaction with a nonfinal locktime
> 2022-06-16T00:34:04.865000Z TestFramework (INFO): Reject a block with a coinbase transaction with a nonfinal locktime
> 2022-06-16T00:34:05.073000Z TestFramework (INFO): Accept a valid block even if a bloated version of the block has previously been sent
> 2022-06-16T00:34:05.450000Z TestFramework (INFO): Accept a block with a transaction spending an output created in the same block
> 2022-06-16T00:34:05.558000Z TestFramework (INFO): Reject a block with a transaction spending an output created later in the same block
> 2022-06-16T00:34:05.773000Z TestFramework (INFO): Reject a block with a transaction double spending a transaction created in the same block
> 2022-06-16T00:34:05.991000Z TestFramework (INFO): Reject a block trying to claim too much subsidy in the coinbase transaction
> 2022-06-16T00:34:06.204000Z TestFramework (INFO): Accept a block claiming the correct subsidy in the coinbase transaction
> 2022-06-16T00:34:06.310000Z TestFramework (INFO): Reject a block containing a transaction spending from a non-existent input
> 2022-06-16T00:34:06.523000Z TestFramework (INFO): Reject a block containing a duplicate transaction but with the same Merkle root (Merkle tree malleability
> 2022-06-16T00:34:06.857000Z TestFramework (INFO): Reject a block containing too many sigops after a large script element
> 2022-06-16T00:34:07.248000Z TestFramework (INFO): Check sigops are counted correctly after an invalid script element
> 2022-06-16T00:34:07.732000Z TestFramework (INFO): Test transaction resurrection during a re-org
> 2022-06-16T00:34:08.332000Z TestFramework (INFO): Accept a block with invalid opcodes in dead execution paths
> 2022-06-16T00:34:08.450000Z TestFramework (INFO): Test re-orging blocks with OP_RETURN in them
> 2022-06-16T00:34:09.177000Z TestFramework (INFO): Test a re-org of one week's worth of blocks (1088 blocks)
> 
> 
> stderr:





> 21/245 - feature_pruning.py failed, Duration: 582 s

    

> stdout:
> 2022-06-16T00:28:16.191000Z TestFramework (INFO): Initializing test directory /tmp/test_runner_₿_🏃_20220615_202813/feature_pruning_244
> 2022-06-16T00:28:29.460000Z TestFramework (INFO): Warning! This test requires 4GB of disk space
> 2022-06-16T00:28:29.502000Z TestFramework (INFO): Mining a big blockchain of 995 blocks
> 2022-06-16T00:33:30.483000Z TestFramework (INFO): Check that we haven't started pruning yet because we're below PruneAfterHeight
> 2022-06-16T00:33:30.605000Z TestFramework (INFO): Success
> 2022-06-16T00:33:30.617000Z TestFramework (INFO): Though we're already using more than 550MiB, current usage: 592.1861438751221
> 2022-06-16T00:33:30.617000Z TestFramework (INFO): Mining 25 more blocks should cause the first block file to be pruned
> 2022-06-16T00:33:39.588000Z TestFramework (INFO): Success
> 2022-06-16T00:33:39.589000Z TestFramework (INFO): Usage should be below target: 480.31389808654785
> 2022-06-16T00:33:39.592000Z TestFramework (INFO): Check that we'll exceed disk space target if we have a very high stale block rate
> 2022-06-16T00:33:39.597000Z TestFramework (INFO): Mine 24 (stale) blocks on Node 1, followed by 25 (main chain) block reorg from Node 0, for 12 rounds
> 2022-06-16T00:35:52.780000Z TestFramework (INFO): Usage can be over target because of high stale rate: 512.3138980865479
> 2022-06-16T00:35:52.845000Z TestFramework (INFO): Check that we can survive a 288 block reorg still
> 2022-06-16T00:35:52.849000Z TestFramework (INFO): Current block height: 1320
> 2022-06-16T00:35:52.850000Z TestFramework (INFO): Invalidating block 44af5766f16112c8b04c19385700828e5ac236f42808804330eaf46e1312f4fb at height 1033
> 2022-06-16T00:35:57.785000Z TestFramework (INFO): New best height: 1032
> 2022-06-16T00:35:57.901000Z TestFramework (INFO): Generating new longer chain of 300 more blocks
> 2022-06-16T00:35:59.900000Z TestFramework (INFO): Reconnect nodes
> 2022-06-16T00:37:25.231000Z TestFramework (ERROR): JSONRPC error
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 166, in _get_response
>     http_response = self.__conn.getresponse()
>   File ""/usr/lib/python3.9/http/client.py"", line 1347, in getresponse
>     response.begin()
>   File ""/usr/lib/python3.9/http/client.py"", line 307, in begin
>     version, status, reason = self._read_status()
>   File ""/usr/lib/python3.9/http/client.py"", line 268, in _read_status
>     line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1"")
>   File ""/usr/lib/python3.9/socket.py"", line 704, in readinto
>     return self._sock.recv_into(b)
> socket.timeout: timed out
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 133, in main
>     self.run_test()
>   File ""/home/user/bitcoin/test/functional/feature_pruning.py"", line 418, in run_test
>     self.reorg_test()  # (1033, )
>   File ""/home/user/bitcoin/test/functional/feature_pruning.py"", line 217, in reorg_test
>     self.sync_blocks(self.nodes[0:3], timeout=120)
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 676, in sync_blocks
>     best_hash = [x.getbestblockhash() for x in rpc_connections]
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 676, in <listcomp>
>     best_hash = [x.getbestblockhash() for x in rpc_connections]
>   File ""/home/user/bitcoin/test/functional/test_framework/coverage.py"", line 49, in __call__
>     return_val = self.auth_service_proxy_instance.__call__(*args, **kwargs)
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 142, in __call__
>     response, status = self._request('POST', self.__url.path, postdata.encode('utf-8'))
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 108, in _request
>     return self._get_response()
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 168, in _get_response
>     raise JSONRPCException({
> test_framework.authproxy.JSONRPCException: 'getbestblockhash' RPC took longer than 60.000000 seconds. Consider using larger timeout for calls that take longer to return. (-344)
> 2022-06-16T00:37:50.789000Z TestFramework (INFO): Stopping nodes
> 2022-06-16T00:37:50.808000Z TestFramework.node0 (ERROR): Unable to stop node.
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 336, in stop_node
>     self.stop(wait=wait)
>   File ""/home/user/bitcoin/test/functional/test_framework/coverage.py"", line 49, in __call__
>     return_val = self.auth_service_proxy_instance.__call__(*args, **kwargs)
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 142, in __call__
>     response, status = self._request('POST', self.__url.path, postdata.encode('utf-8'))
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 107, in _request
>     self.__conn.request(method, path, postdata, headers)
>   File ""/usr/lib/python3.9/http/client.py"", line 1255, in request
>     self._send_request(method, url, body, headers, encode_chunked)
>   File ""/usr/lib/python3.9/http/client.py"", line 1266, in _send_request
>     self.putrequest(method, url, **skips)
>   File ""/usr/lib/python3.9/http/client.py"", line 1092, in putrequest
>     raise CannotSendRequest(self.__state)
> http.client.CannotSendRequest: Request-sent
> [node 5] Cleaning up leftover process
> [node 2] Cleaning up leftover process
> [node 1] Cleaning up leftover process
> [node 0] Cleaning up leftover process
> 
> 
> stderr:
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/feature_pruning.py"", line 486, in <module>
>     PruneTest().main()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 156, in main
>     exit_code = self.shutdown()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 311, in shutdown
>     self.stop_nodes()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 571, in stop_nodes
>     node.wait_until_stopped()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 382, in wait_until_stopped
>     wait_until_helper(self.is_node_stopped, timeout=timeout, timeout_factor=self.timeout_factor)
>   File ""/home/user/bitcoin/test/functional/test_framework/util.py"", line 265, in wait_until_helper
>     if predicate():
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 372, in is_node_stopped
>     assert return_code == 0, self._node_msg(
> AssertionError: [node 0] Node returned non-zero exit code (-9) when stopping






> 245/245 - feature_dbcrash.py failed, Duration: 2812 s

                  

> stdout:
> 2022-06-16T00:28:16.295000Z TestFramework (INFO): Initializing test directory /tmp/test_runner_₿_🏃_20220615_202813/feature_dbcrash_243
> 2022-06-16T00:28:46.954000Z TestFramework (INFO): Prepped 5000 utxo entries
> 2022-06-16T00:28:50.396000Z TestFramework (INFO): Iteration 0, generating 2500 transactions [0, 0, 0]
> 2022-06-16T00:31:57.072000Z TestFramework (INFO): Iteration 1, generating 2500 transactions [0, 0, 0]
> 2022-06-16T00:34:58.594000Z TestFramework (INFO): Iteration 2, generating 2500 transactions [0, 0, 0]
> 2022-06-16T00:38:52.851000Z TestFramework (INFO): Iteration 3, generating 2500 transactions [0, 0, 0]
> 2022-06-16T00:40:32.251000Z TestFramework (INFO): Iteration 4, generating 2500 transactions [0, 0, 0]
> 2022-06-16T00:42:39.525000Z TestFramework (INFO): Iteration 5, generating 2500 transactions [0, 0, 0]
> 2022-06-16T00:47:05.828000Z TestFramework (INFO): Iteration 6, generating 2500 transactions [0, 0, 0]
> 2022-06-16T00:48:43.793000Z TestFramework (INFO): Iteration 7, generating 2500 transactions [1, 1, 0]
> 2022-06-16T00:50:17.816000Z TestFramework (INFO): Iteration 8, generating 2500 transactions [2, 1, 0]
> 2022-06-16T00:51:41.498000Z TestFramework (INFO): Iteration 9, generating 2500 transactions [3, 1, 0]
> 2022-06-16T00:52:50.168000Z TestFramework (INFO): Iteration 10, generating 2500 transactions [4, 1, 0]
> 2022-06-16T00:53:23.849000Z TestFramework (INFO): Iteration 11, generating 2500 transactions [4, 1, 0]
> 2022-06-16T00:54:00.627000Z TestFramework (INFO): Iteration 12, generating 2500 transactions [4, 1, 0]
> 2022-06-16T00:54:38.547000Z TestFramework (INFO): Iteration 13, generating 2500 transactions [4, 1, 0]
> 2022-06-16T00:55:19.742000Z TestFramework (INFO): Iteration 14, generating 2500 transactions [5, 2, 0]
> 2022-06-16T00:55:58.554000Z TestFramework (INFO): Iteration 15, generating 2500 transactions [5, 2, 0]
> 2022-06-16T00:56:40.740000Z TestFramework (INFO): Iteration 16, generating 2500 transactions [5, 3, 0]
> 2022-06-16T00:57:20.679000Z TestFramework (INFO): Iteration 17, generating 2500 transactions [6, 3, 0]
> 2022-06-16T00:57:59.576000Z TestFramework (INFO): Iteration 18, generating 2500 transactions [6, 3, 0]
> 2022-06-16T00:58:38.372000Z TestFramework (INFO): Iteration 19, generating 2500 transactions [6, 3, 0]
> 2022-06-16T00:59:17.384000Z TestFramework (INFO): Iteration 20, generating 2500 transactions [6, 3, 0]
> 2022-06-16T00:59:56.572000Z TestFramework (INFO): Iteration 21, generating 2500 transactions [6, 3, 0]
> 2022-06-16T01:00:38.183000Z TestFramework (INFO): Iteration 22, generating 2500 transactions [6, 4, 0]
> 2022-06-16T01:01:19.304000Z TestFramework (INFO): Iteration 23, generating 2500 transactions [7, 4, 0]
> 2022-06-16T01:02:01.291000Z TestFramework (INFO): Iteration 24, generating 2500 transactions [7, 5, 0]
> 2022-06-16T01:02:44.272000Z TestFramework (INFO): Iteration 25, generating 2500 transactions [7, 5, 0]
> 2022-06-16T01:03:30.375000Z TestFramework (INFO): Iteration 26, generating 2500 transactions [8, 6, 0]
> 2022-06-16T01:04:14.778000Z TestFramework (INFO): Iteration 27, generating 2500 transactions [8, 6, 0]
> 2022-06-16T01:05:05.355000Z TestFramework (INFO): Iteration 28, generating 2500 transactions [9, 7, 0]
> 2022-06-16T01:05:49.274000Z TestFramework (INFO): Iteration 29, generating 2500 transactions [9, 7, 0]
> 2022-06-16T01:06:36.106000Z TestFramework (INFO): Iteration 30, generating 2500 transactions [9, 7, 0]
> 2022-06-16T01:07:23.495000Z TestFramework (INFO): Iteration 31, generating 2500 transactions [10, 7, 0]
> 2022-06-16T01:08:13.103000Z TestFramework (INFO): Iteration 32, generating 2500 transactions [10, 8, 0]
> 2022-06-16T01:09:02.471000Z TestFramework (INFO): Iteration 33, generating 2500 transactions [10, 8, 0]
> 2022-06-16T01:09:54.083000Z TestFramework (INFO): Iteration 34, generating 2500 transactions [11, 8, 0]
> 2022-06-16T01:10:46.416000Z TestFramework (INFO): Iteration 35, generating 2500 transactions [12, 8, 0]
> 2022-06-16T01:11:35.339000Z TestFramework (INFO): Iteration 36, generating 2500 transactions [12, 8, 0]
> 2022-06-16T01:12:24.634000Z TestFramework (INFO): Iteration 37, generating 2500 transactions [12, 8, 0]
> 2022-06-16T01:13:19.854000Z TestFramework (INFO): Iteration 38, generating 2500 transactions [12, 8, 0]
> 2022-06-16T01:14:13.032000Z TestFramework (INFO): Iteration 39, generating 2500 transactions [12, 8, 0]
> 2022-06-16T01:15:00.597000Z TestFramework (ERROR): Unexpected exception caught during testing
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 108, in _request
>     return self._get_response()
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 166, in _get_response
>     http_response = self.__conn.getresponse()
>   File ""/usr/lib/python3.9/http/client.py"", line 1347, in getresponse
>     response.begin()
>   File ""/usr/lib/python3.9/http/client.py"", line 307, in begin
>     version, status, reason = self._read_status()
>   File ""/usr/lib/python3.9/http/client.py"", line 276, in _read_status
>     raise RemoteDisconnected(""Remote end closed connection without""
> http.client.RemoteDisconnected: Remote end closed connection without response
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 133, in main
>     self.run_test()
>   File ""/home/user/bitcoin/test/functional/feature_dbcrash.py"", line 263, in run_test
>     self.wallet.rescan_utxos()
>   File ""/home/user/bitcoin/test/functional/test_framework/wallet.py"", line 106, in rescan_utxos
>     res = self._test_node.scantxoutset(action=""start"", scanobjects=[self.get_descriptor()])
>   File ""/home/user/bitcoin/test/functional/test_framework/coverage.py"", line 49, in __call__
>     return_val = self.auth_service_proxy_instance.__call__(*args, **kwargs)
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 142, in __call__
>     response, status = self._request('POST', self.__url.path, postdata.encode('utf-8'))
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 113, in _request
>     self.__conn.request(method, path, postdata, headers)
>   File ""/usr/lib/python3.9/http/client.py"", line 1255, in request
>     self._send_request(method, url, body, headers, encode_chunked)
>   File ""/usr/lib/python3.9/http/client.py"", line 1301, in _send_request
>     self.endheaders(body, encode_chunked=encode_chunked)
>   File ""/usr/lib/python3.9/http/client.py"", line 1250, in endheaders
>     self._send_output(message_body, encode_chunked=encode_chunked)
>   File ""/usr/lib/python3.9/http/client.py"", line 1010, in _send_output
>     self.send(msg)
>   File ""/usr/lib/python3.9/http/client.py"", line 950, in send
>     self.connect()
>   File ""/usr/lib/python3.9/http/client.py"", line 921, in connect
>     self.sock = self._create_connection(
>   File ""/usr/lib/python3.9/socket.py"", line 843, in create_connection
>     raise err
>   File ""/usr/lib/python3.9/socket.py"", line 831, in create_connection
>     sock.connect(sa)
> ConnectionRefusedError: [Errno 111] Connection refused
> 2022-06-16T01:15:05.618000Z TestFramework (INFO): Stopping nodes
> 2022-06-16T01:15:05.743000Z TestFramework.node3 (ERROR): Unable to stop node.
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 336, in stop_node
>     self.stop(wait=wait)
>   File ""/home/user/bitcoin/test/functional/test_framework/coverage.py"", line 49, in __call__
>     return_val = self.auth_service_proxy_instance.__call__(*args, **kwargs)
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 142, in __call__
>     response, status = self._request('POST', self.__url.path, postdata.encode('utf-8'))
>   File ""/home/user/bitcoin/test/functional/test_framework/authproxy.py"", line 107, in _request
>     self.__conn.request(method, path, postdata, headers)
>   File ""/usr/lib/python3.9/http/client.py"", line 1255, in request
>     self._send_request(method, url, body, headers, encode_chunked)
>   File ""/usr/lib/python3.9/http/client.py"", line 1266, in _send_request
>     self.putrequest(method, url, **skips)
>   File ""/usr/lib/python3.9/http/client.py"", line 1092, in putrequest
>     raise CannotSendRequest(self.__state)
> http.client.CannotSendRequest: Request-sent
> [node 3] Cleaning up leftover process
> 
> 
> stderr:
> Traceback (most recent call last):
>   File ""/home/user/bitcoin/test/functional/feature_dbcrash.py"", line 288, in <module>
>     ChainstateWriteCrashTest().main()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 156, in main
>     exit_code = self.shutdown()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 311, in shutdown
>     self.stop_nodes()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_framework.py"", line 571, in stop_nodes
>     node.wait_until_stopped()
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 382, in wait_until_stopped
>     wait_until_helper(self.is_node_stopped, timeout=timeout, timeout_factor=self.timeout_factor)
>   File ""/home/user/bitcoin/test/functional/test_framework/util.py"", line 265, in wait_until_helper
>     if predicate():
>   File ""/home/user/bitcoin/test/functional/test_framework/test_node.py"", line 372, in is_node_stopped
>     assert return_code == 0, self._node_msg(
> AssertionError: [node 3] Node returned non-zero exit code (-9) when stopping



Try failed tests individually:



user@localhost:~/bitcoin/test/functional$ `python3 feature_block.py`

> ...
> ...
> 2022-06-16T01:48:03.457000Z TestFramework (INFO): Test re-orging blocks with OP_RETURN in them
> 2022-06-16T01:48:04.208000Z TestFramework (INFO): Test a re-org of one week's worth of blocks (1088 blocks)
> Killed

I didn't terminate, not sure why this was killed.


user@localhost:~/bitcoin/test/functional$ `python3 feature_dbcrash.py`

> ...
> ...
> 2022-06-16T02:22:04.399000Z TestFramework (INFO): Iteration 39, generating 2500 transactions [14, 6, 5]
> 2022-06-16T02:22:45.148000Z TestFramework (INFO): Verifying utxo hash matches for all nodes
> 2022-06-16T02:22:45.611000Z TestFramework (INFO): Restarted nodes: [14, 6, 5]; crashes on restart: 19
> 2022-06-16T02:22:45.735000Z TestFramework (INFO): Stopping nodes
> 2022-06-16T02:22:46.082000Z TestFramework (INFO): Cleaning up /tmp/bitcoin_func_test_dlvz7p5v on exit
> 2022-06-16T02:22:46.084000Z TestFramework (INFO): Tests successful

This succeeds when tested individually




user@localhost:~/bitcoin/test/functional$ `python3 feature_pruning.py`

> ...
> ...
> 2022-06-16T02:30:49.127000Z TestFramework (INFO): Done
> 2022-06-16T02:30:49.208000Z TestFramework (INFO): Stopping nodes
> 2022-06-16T02:30:49.584000Z TestFramework (INFO): Cleaning up /tmp/bitcoin_func_test_l2tv3kpn on exit
> 2022-06-16T02:30:49.584000Z TestFramework (INFO): Tests successful

This also succeeds



user@localhost:~/bitcoin/test/util$ `python3 test_runner.py`

Successful

`bitcoin-qt` opens as expected

Machine details:

Qubes 4.1
Up to date Debian 11 Standard VM
Coreboot 4.14
x86
"
bitcoin/bitcoin,2022-05-25 09:59:00,question,Issues with compiling Bitcoin using the Depends folder Bitcoin Core version 23.0,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->
Hello everyone. I have ran into a make host issue while doing the steps needed to compile Bitcoin on my computer. Below is a screenshot of the situation and the steps detailed I used to get this program working. For another reference, I followed the steps to compile Bitcoin from these links: 
https://github.com/bitcoin/bitcoin/blob/master/doc/build-windows.md#building-for-64-bit-windows

https://github.com/bitcoin/bitcoin/blob/master/depends/README.md
The screen shot below shows everything else. Thank you for your time.
![New Bitcoin issue](https://user-images.githubusercontent.com/42873006/170236050-1605460f-15b5-4ebc-9ee3-507762db8693.png)


**Expected behavior**
To compile normally to finish compiling the core on my laptop
<!--- What behavior did you expect? -->

**Actual behavior**
A makefile error
<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
I am using Bitcoin Core 23.0
<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
I am using Windows 11 as my operating system and WSL for the terminal.
<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2022-05-24 07:37:32,question,Bitcoin core will not compile on Windows 11,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue!

Any report, issue or feature request related to the GUI should be reported at
https://github.com/bitcoin-core/gui/issues/
-->

<!-- Describe the issue -->
I have ran into several issues during my compiling of Bitcoin. I have tried to compile this thing but each time I try to do so, there is a new issue. For reference I am using Ubuntu Bash terminal to compile Bitcoin. My operating system is Windows 11 and I have tried everything I know to troubleshoot this issue. I have downloaded clang, mingw g++ and I will attach the a photo to explain this issue. Each time I try to use the ./configure, ./autogen.sh and sudo make, there seems to be issues and this will not compile at all. Any help will be greatly appreciated. Thank you! PS. I have also created a virtual environment and I have installed the necessary tools for it as well. 
![Bitcoin Error](https://user-images.githubusercontent.com/42873006/169974755-3155d988-6051-426b-b339-d0a7a326a9d4.png)


<!--- What behavior did you expect? --> I expected the Bitcoin Core to compile.

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? --> 

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? --> The version of Bitcoin core is version 23.0 I have forked it from the bitcoin GitHub Bitcoin page.

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? --> I am using an ASUS X555Y series Laptop.

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? --> My operating system is Windows 11.

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
[config.log](https://github.com/bitcoin/bitcoin/files/8760431/config.log)

"
bitcoin/bitcoin,2022-05-07 07:21:43,question,"walletpassphrase gives error ""must request wallet RPC through /wallet/<filename>""","When issuing an RPC for walletpassphrase, the following error is returned:

_{\\""result\\"":null,\\""error\\"":{\\""code\\"":-19,\\""message\\"":\\""Wallet file not specified (must request wallet RPC through /wallet/<filename> uri-path).\\""},\\""id\\"":0}_

Documentation from here:
_https://bitcoincore.org/en/doc/0.20.0/rpc/wallet/walletpassphrase/_
states sample call looks like this:
_As a JSON-RPC call
> curl --user myusername --data-binary '{""jsonrpc"": ""1.0"", ""id"": ""curltest"", ""method"": ""walletpassphrase"", ""params"": [""my pass phrase"", 60]}' -H 'content-type: text/plain;' http://127.0.0.1:8332/_
(e.g. no /wallet/<filename> in the RPC)

Further, my issue stems from wallet names with embedded spaces, for example ""encrypted with space"".  QT allows for the creation of wallet names with spaces (and other characters), which are not valid in a URI, at least as plain text.

The CLI functions as expected when issued with the rpcwallet parameter, and allows for spaces because the wallet name is enclosed in double quotes.

At a minimum the docs should reflect the proper usage of the RPC call, however its unclear how support for wallet names with internal spaces would be supported at all given the current design.  A better design would be to add the wallet name as a parameter in the array to avoid using different URIs which is inconsistent with the usage of all other RPCs in core.

BTC 0.21

"
bitcoin/bitcoin,2022-04-26 08:54:53,question,Multiplication result may overflow,I believe there is chance of overflow due to multiplication in [this](https://github.com/bitcoin/bitcoin/blob/master/src/crypto/muhash.cpp#L49) line of code.
bitcoin/bitcoin,2022-04-17 16:24:00,question,wallet address issue ,"good time 
i have bitcoin core wallet fully update it 
whenever i try to do sending using the wallet 
the address box alwayes become red color 
how this issue can be resolved 
pls i need help 

thank u so much "
bitcoin/bitcoin,2022-03-29 04:04:42,question,Cannot sync with limited RAM and Swap,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue!

Any report, issue or feature request related to the GUI should be reported at
https://github.com/bitcoin-core/gui/issues/
-->

<!-- Describe the issue -->
While syncing headers with bitcoin-qt my device runs out of memory. I have a computer with only 1GB of RAM and no swap; while syncing headers it runs out of memory. Approximately, 600,000 headers is where it runs out.

<!--- What behavior did you expect? -->
I expected to be able to sync all the headers and then start downloading/verifying the blockchain.

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->
While syncing the headers my device runs out of memory.

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->
I can reproduce this issue every time. Simply, start the bitcoin-qt application and wait until it runs out of memory at approximately 600,000 headers.

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
debian package 22.0-1

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
Orange Pi One http://www.orangepi.org/orangepione/
CPU: H3 Quad-core Cortex-A7 H.265/HEVC 4K
Drive: 256GB microSD

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->

This issue is probably caused because all the headers are stored in RAM.

Eventually this will become a problem with common lower end computers even if they have swap when the index becomes too large.

It is an important issue to consider so that cheap nodes can be run in third world countries to ensure good decentralization of the network.
"
bitcoin/bitcoin,2022-02-08 11:20:28,question,Ubuntu Jammy can't compile fuzz tests with libc++?,"Steps to reproduce on a fresh Ubuntu install:

```
export DEBIAN_FRONTEND=noninteractive && apt update && apt install curl wget htop git vim ccache -y && git clone https://github.com/bitcoin/bitcoin.git bitcoin-core && cd bitcoin-core && apt install build-essential libtool autotools-dev automake pkg-config bsdmainutils python3-zmq     libevent-dev libboost-system-dev libboost-test-dev  clang llvm libc++-dev libc++abi-dev  -y   &&  ./autogen.sh && ./configure CC=clang CXX='clang++ -stdlib=libc++'   --enable-fuzz --with-sanitizers=fuzzer && make -j$(nproc)
```

Ubuntu Focal: (Passes)
Ubuntu Jammy: (fails)

```
checking whether the linker accepts -fsanitize=fuzzer... no
configure: error: linker did not accept requested flags, you are missing required libraries
```

"
bitcoin/bitcoin,2022-01-19 07:15:23,question,Does the Txcount obtained by getwalletinfo represent the number of transaction hashes?,"The length of the array obtained by listtransaction and the value obtained by txcount are different.
Careful observation revealed duplicate tx_ids."
bitcoin/bitcoin,2022-01-03 00:42:17,question,importprivkey - This type of wallet does not support this command,"When I run importprivkey it returns unsupported wallet instead of importing. Code:

bitcoin-cli importprivkey ""priv_key"" ""label"" false
error code: -4
error message:
**This type of wallet does not support this command**

Version
bitcoin-cli -version
**Bitcoin Core RPC client version v22.99.0-9d099b02d8f0**

Node fully synced (full node)
Chain: main
Blocks: 716934
Headers: 716934
Verification progress: 99.9999%
Difficulty: 24272331996979.97

![image](https://user-images.githubusercontent.com/75843061/147893495-3d5724ab-f727-44f8-8451-9d027e9d6a08.png)
"
bitcoin/bitcoin,2021-12-29 20:33:25,question,Cannot install Bitcoin v22.0 on Ubuntu 20.04 with current Berkeley DB version (18.1.4),"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

A fresh install of Bitcoin v22.0 is not going through on Ubuntu 20.04, with an underlying fresh install of Berkeley DB version 18.1.4. The same error was obtained on two completely unrelated systems.

**Expected behavior**

No error on installation

**Actual behavior**

The following error:
```console
Making all in src
make[1]: Entering directory '/mnt/projects/crypto/bitcoin/src'
make[2]: Entering directory '/mnt/projects/crypto/bitcoin/src'
make[3]: Entering directory '/mnt/projects/crypto/bitcoin'
make[3]: Leaving directory '/mnt/projects/crypto/bitcoin'
  CXXLD    bitcoind
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_verify_callback':
repmgr_net.c:(.text+0x247): undefined reference to `X509_STORE_CTX_get_current_cert'
/usr/bin/ld: repmgr_net.c:(.text+0x252): undefined reference to `X509_STORE_CTX_get_error_depth'
/usr/bin/ld: repmgr_net.c:(.text+0x25d): undefined reference to `X509_STORE_CTX_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x28c): undefined reference to `X509_get_issuer_name'
/usr/bin/ld: repmgr_net.c:(.text+0x29c): undefined reference to `X509_NAME_oneline'
/usr/bin/ld: repmgr_net.c:(.text+0x2be): undefined reference to `X509_get_subject_name'
/usr/bin/ld: repmgr_net.c:(.text+0x2ce): undefined reference to `X509_NAME_oneline'
/usr/bin/ld: repmgr_net.c:(.text+0x2f0): undefined reference to `X509_verify_cert_error_string'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_conn_info_setup.isra.0':
repmgr_net.c:(.text+0x446): undefined reference to `SSL_free'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_set_ssl_ctx':
repmgr_net.c:(.text+0x138d): undefined reference to `OPENSSL_init_ssl'
/usr/bin/ld: repmgr_net.c:(.text+0x1399): undefined reference to `OPENSSL_init_ssl'
/usr/bin/ld: repmgr_net.c:(.text+0x13a5): undefined reference to `OPENSSL_init_crypto'
/usr/bin/ld: repmgr_net.c:(.text+0x13b1): undefined reference to `TLS_method'
/usr/bin/ld: repmgr_net.c:(.text+0x13b9): undefined reference to `SSL_CTX_new'
/usr/bin/ld: repmgr_net.c:(.text+0x13d9): undefined reference to `SSL_CTX_set_verify'
/usr/bin/ld: repmgr_net.c:(.text+0x13f6): undefined reference to `SSL_CTX_set_cipher_list'
/usr/bin/ld: repmgr_net.c:(.text+0x147b): undefined reference to `SSL_CTX_use_certificate_file'
/usr/bin/ld: repmgr_net.c:(.text+0x14ee): undefined reference to `SSL_CTX_set_default_passwd_cb_userdata'
/usr/bin/ld: repmgr_net.c:(.text+0x1502): undefined reference to `SSL_CTX_use_PrivateKey_file'
/usr/bin/ld: repmgr_net.c:(.text+0x1512): undefined reference to `SSL_CTX_check_private_key'
/usr/bin/ld: repmgr_net.c:(.text+0x1530): undefined reference to `SSL_CTX_load_verify_locations'
/usr/bin/ld: repmgr_net.c:(.text+0x1541): undefined reference to `SSL_CTX_set_default_verify_paths'
/usr/bin/ld: repmgr_net.c:(.text+0x1584): undefined reference to `SSL_CTX_set_verify_depth'
/usr/bin/ld: repmgr_net.c:(.text+0x1600): undefined reference to `SSL_CTX_free'
/usr/bin/ld: repmgr_net.c:(.text+0x174d): undefined reference to `SSL_CTX_free'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_accept':
repmgr_net.c:(.text+0x1842): undefined reference to `SSL_new'
/usr/bin/ld: repmgr_net.c:(.text+0x1858): undefined reference to `SSL_set_fd'
/usr/bin/ld: repmgr_net.c:(.text+0x1874): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x187c): undefined reference to `SSL_accept'
/usr/bin/ld: repmgr_net.c:(.text+0x18cf): undefined reference to `SSL_is_init_finished'
/usr/bin/ld: repmgr_net.c:(.text+0x18fb): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x1905): undefined reference to `SSL_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x19c0): undefined reference to `SSL_free'
/usr/bin/ld: repmgr_net.c:(.text+0x19c5): undefined reference to `ERR_clear_error'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_connect':
repmgr_net.c:(.text+0x1c53): undefined reference to `SSL_new'
/usr/bin/ld: repmgr_net.c:(.text+0x1c71): undefined reference to `SSL_set_fd'
/usr/bin/ld: repmgr_net.c:(.text+0x1c76): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x1c7e): undefined reference to `SSL_connect'
/usr/bin/ld: repmgr_net.c:(.text+0x1cd8): undefined reference to `SSL_is_init_finished'
/usr/bin/ld: repmgr_net.c:(.text+0x1cfb): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x1d06): undefined reference to `SSL_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x1d5c): undefined reference to `SSL_new'
/usr/bin/ld: repmgr_net.c:(.text+0x1e7a): undefined reference to `SSL_free'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_shutdown':
repmgr_net.c:(.text+0x20c4): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x20cc): undefined reference to `SSL_shutdown'
/usr/bin/ld: repmgr_net.c:(.text+0x20f3): undefined reference to `SSL_shutdown'
/usr/bin/ld: repmgr_net.c:(.text+0x20fb): undefined reference to `SSL_free'
/usr/bin/ld: repmgr_net.c:(.text+0x221b): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_write':
repmgr_net.c:(.text+0x2d72): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x2d80): undefined reference to `SSL_write'
/usr/bin/ld: repmgr_net.c:(.text+0x2e03): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x2e0e): undefined reference to `SSL_get_error'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_readv':
repmgr_net.c:(.text+0x4e2d): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x4e64): undefined reference to `SSL_read'
/usr/bin/ld: repmgr_net.c:(.text+0x4e76): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x4e82): undefined reference to `SSL_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x4eb6): undefined reference to `SSL_shutdown'
/usr/bin/ld: repmgr_net.c:(.text+0x4ffa): undefined reference to `SSL_pending'
/usr/bin/ld: repmgr_net.c:(.text+0x5042): undefined reference to `SSL_pending'
/usr/bin/ld: repmgr_net.c:(.text+0x51be): undefined reference to `SSL_shutdown'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_read_possible':
repmgr_net.c:(.text+0x5325): undefined reference to `SSL_pending'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_posix.o): in function `__repmgr_conn_work':
repmgr_posix.c:(.text+0x380): undefined reference to `SSL_pending'
/usr/bin/ld: repmgr_posix.c:(.text+0x3d7): undefined reference to `SSL_pending'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_sel.o): in function `__repmgr_read_from_site':
repmgr_sel.c:(.text+0x3e58): undefined reference to `SSL_pending'
collect2: error: ld returned 1 exit status
make[2]: *** [Makefile:5933: bitcoind] Error 1
make[2]: Leaving directory '/mnt/projects/crypto/bitcoin/src'
make[1]: *** [Makefile:16186: all-recursive] Error 1
make[1]: Leaving directory '/mnt/projects/crypto/bitcoin/src'
make: *** [Makefile:821: all-recursive] Error 1
```

**To reproduce**

I followed a flow inspired from [this gist](https://gist.github.com/nschmeller/b0c046bf39f2d6c2760a55a08ec0149c)

1. Install all required dependencies
```bash
sudo apt install build-essential libtool autotools-dev autoconf pkg-config libssl-dev libboost-all-dev libminiupnpc-dev libzmq3-dev libqt5gui5 libqt5core5a libqt5dbus5 qttools5-dev qttools5-dev-tools libprotobuf-dev protobuf-compiler libqrencode-dev
```
2. Get and install current Berkeley DB version
```bash
cd /mnt/projects/crypto
wget http://download.oracle.com/berkeley-db/db-18.1.40.tar.gz
tar -xvzf db-18.1.40.tar.gz
cd db-18.1.40/build_unix
mkdir /mnt/projects/crypto/berkeley-db
BDB_PREFIX=/mnt/projects/crypto/berkeley-db
../dist/configure --disable-shared --enable-cxx --with-pic --prefix=$BDB_PREFIX
mkdir ../docs/bdb-sql ../docs/gsg_db_server
sudo make install
```
3. Get the latest Bitcoin stable version and install
```bash
cd /mnt/projects/crypto
git clone git@github.com:bitcoin/bitcoin.git
cd bitcoin
git checkout v22.0
./autogen.sh
mkdir /mnt/projects/crypto/bitcoin_build
./configure CPPFLAGS=""-I${BDB_PREFIX}/include/ -O2"" LDFLAGS=""-L${BDB_PREFIX}/lib/"" --with-gui --with-incompatible-bdb --with-zmq --enable-zmq --prefix=/mnt/projects/crypto/bitcoin_build
```
4. Get the error
```console
Making all in src
make[1]: Entering directory '/mnt/projects/crypto/bitcoin/src'
make[2]: Entering directory '/mnt/projects/crypto/bitcoin/src'
make[3]: Entering directory '/mnt/projects/crypto/bitcoin'
make[3]: Leaving directory '/mnt/projects/crypto/bitcoin'
  CXXLD    bitcoind
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_verify_callback':
repmgr_net.c:(.text+0x247): undefined reference to `X509_STORE_CTX_get_current_cert'
/usr/bin/ld: repmgr_net.c:(.text+0x252): undefined reference to `X509_STORE_CTX_get_error_depth'
/usr/bin/ld: repmgr_net.c:(.text+0x25d): undefined reference to `X509_STORE_CTX_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x28c): undefined reference to `X509_get_issuer_name'
/usr/bin/ld: repmgr_net.c:(.text+0x29c): undefined reference to `X509_NAME_oneline'
/usr/bin/ld: repmgr_net.c:(.text+0x2be): undefined reference to `X509_get_subject_name'
/usr/bin/ld: repmgr_net.c:(.text+0x2ce): undefined reference to `X509_NAME_oneline'
/usr/bin/ld: repmgr_net.c:(.text+0x2f0): undefined reference to `X509_verify_cert_error_string'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_conn_info_setup.isra.0':
repmgr_net.c:(.text+0x446): undefined reference to `SSL_free'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_set_ssl_ctx':
repmgr_net.c:(.text+0x138d): undefined reference to `OPENSSL_init_ssl'
/usr/bin/ld: repmgr_net.c:(.text+0x1399): undefined reference to `OPENSSL_init_ssl'
/usr/bin/ld: repmgr_net.c:(.text+0x13a5): undefined reference to `OPENSSL_init_crypto'
/usr/bin/ld: repmgr_net.c:(.text+0x13b1): undefined reference to `TLS_method'
/usr/bin/ld: repmgr_net.c:(.text+0x13b9): undefined reference to `SSL_CTX_new'
/usr/bin/ld: repmgr_net.c:(.text+0x13d9): undefined reference to `SSL_CTX_set_verify'
/usr/bin/ld: repmgr_net.c:(.text+0x13f6): undefined reference to `SSL_CTX_set_cipher_list'
/usr/bin/ld: repmgr_net.c:(.text+0x147b): undefined reference to `SSL_CTX_use_certificate_file'
/usr/bin/ld: repmgr_net.c:(.text+0x14ee): undefined reference to `SSL_CTX_set_default_passwd_cb_userdata'
/usr/bin/ld: repmgr_net.c:(.text+0x1502): undefined reference to `SSL_CTX_use_PrivateKey_file'
/usr/bin/ld: repmgr_net.c:(.text+0x1512): undefined reference to `SSL_CTX_check_private_key'
/usr/bin/ld: repmgr_net.c:(.text+0x1530): undefined reference to `SSL_CTX_load_verify_locations'
/usr/bin/ld: repmgr_net.c:(.text+0x1541): undefined reference to `SSL_CTX_set_default_verify_paths'
/usr/bin/ld: repmgr_net.c:(.text+0x1584): undefined reference to `SSL_CTX_set_verify_depth'
/usr/bin/ld: repmgr_net.c:(.text+0x1600): undefined reference to `SSL_CTX_free'
/usr/bin/ld: repmgr_net.c:(.text+0x174d): undefined reference to `SSL_CTX_free'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_accept':
repmgr_net.c:(.text+0x1842): undefined reference to `SSL_new'
/usr/bin/ld: repmgr_net.c:(.text+0x1858): undefined reference to `SSL_set_fd'
/usr/bin/ld: repmgr_net.c:(.text+0x1874): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x187c): undefined reference to `SSL_accept'
/usr/bin/ld: repmgr_net.c:(.text+0x18cf): undefined reference to `SSL_is_init_finished'
/usr/bin/ld: repmgr_net.c:(.text+0x18fb): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x1905): undefined reference to `SSL_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x19c0): undefined reference to `SSL_free'
/usr/bin/ld: repmgr_net.c:(.text+0x19c5): undefined reference to `ERR_clear_error'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_connect':
repmgr_net.c:(.text+0x1c53): undefined reference to `SSL_new'
/usr/bin/ld: repmgr_net.c:(.text+0x1c71): undefined reference to `SSL_set_fd'
/usr/bin/ld: repmgr_net.c:(.text+0x1c76): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x1c7e): undefined reference to `SSL_connect'
/usr/bin/ld: repmgr_net.c:(.text+0x1cd8): undefined reference to `SSL_is_init_finished'
/usr/bin/ld: repmgr_net.c:(.text+0x1cfb): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x1d06): undefined reference to `SSL_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x1d5c): undefined reference to `SSL_new'
/usr/bin/ld: repmgr_net.c:(.text+0x1e7a): undefined reference to `SSL_free'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_shutdown':
repmgr_net.c:(.text+0x20c4): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x20cc): undefined reference to `SSL_shutdown'
/usr/bin/ld: repmgr_net.c:(.text+0x20f3): undefined reference to `SSL_shutdown'
/usr/bin/ld: repmgr_net.c:(.text+0x20fb): undefined reference to `SSL_free'
/usr/bin/ld: repmgr_net.c:(.text+0x221b): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_write':
repmgr_net.c:(.text+0x2d72): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x2d80): undefined reference to `SSL_write'
/usr/bin/ld: repmgr_net.c:(.text+0x2e03): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x2e0e): undefined reference to `SSL_get_error'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_readv':
repmgr_net.c:(.text+0x4e2d): undefined reference to `ERR_clear_error'
/usr/bin/ld: repmgr_net.c:(.text+0x4e64): undefined reference to `SSL_read'
/usr/bin/ld: repmgr_net.c:(.text+0x4e76): undefined reference to `ERR_print_errors_fp'
/usr/bin/ld: repmgr_net.c:(.text+0x4e82): undefined reference to `SSL_get_error'
/usr/bin/ld: repmgr_net.c:(.text+0x4eb6): undefined reference to `SSL_shutdown'
/usr/bin/ld: repmgr_net.c:(.text+0x4ffa): undefined reference to `SSL_pending'
/usr/bin/ld: repmgr_net.c:(.text+0x5042): undefined reference to `SSL_pending'
/usr/bin/ld: repmgr_net.c:(.text+0x51be): undefined reference to `SSL_shutdown'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_net.o): in function `__repmgr_ssl_read_possible':
repmgr_net.c:(.text+0x5325): undefined reference to `SSL_pending'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_posix.o): in function `__repmgr_conn_work':
repmgr_posix.c:(.text+0x380): undefined reference to `SSL_pending'
/usr/bin/ld: repmgr_posix.c:(.text+0x3d7): undefined reference to `SSL_pending'
/usr/bin/ld: /mnt/projects/crypto/berkeley-db/lib//libdb_cxx.a(repmgr_sel.o): in function `__repmgr_read_from_site':
repmgr_sel.c:(.text+0x3e58): undefined reference to `SSL_pending'
collect2: error: ld returned 1 exit status
make[2]: *** [Makefile:5933: bitcoind] Error 1
make[2]: Leaving directory '/mnt/projects/crypto/bitcoin/src'
make[1]: *** [Makefile:16186: all-recursive] Error 1
make[1]: Leaving directory '/mnt/projects/crypto/bitcoin/src'
make: *** [Makefile:821: all-recursive] Error 1
```

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
Bitcoin Core v22.0 from Github (cf commands above)

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
Tested on both Ubuntu 20.04 as host system (no VM) and Ubuntu 20.04 as guest system (as VM)

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
Please note this was highly reproducible as fresh install on two different Ubuntu 20.04 systems.

<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2021-11-28 05:44:24,question,rpc: getnetworkinfo subversion has spurious trailing 0,"Reported by @k9ert: https://github.com/cryptoadvance/specter-desktop/pull/1482#discussion_r756783512

Confirmed on the 22.0x branch:

```
bitcoin-cli getnetworkinfo
{
  ""version"": 220000,
  ""subversion"": ""/Satoshi:22.0.0/"",
...
```

cc @achow101"
bitcoin/bitcoin,2021-11-20 11:19:50,question,'event2/buffer.h' file not found,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue!

Any report, issue or feature request related to the GUI should be reported at
https://github.com/bitcoin-core/gui/issues/
-->

<!-- Describe the issue -->
*What behavior did you expect?*

Building BitcoinCore on MacOS BigSur 11.6 Mac Mini M1 2020


*What was the actual behavior (provide screenshots if the issue is GUI-related)?*

% make HOST=arm-apple-darwin20

fails:

 ....
  CXX      test/fuzz/fuzz-http_request.o
test/fuzz/http_request.cpp:12:10: fatal error: 'event2/buffer.h' file not found
#include <event2/buffer.h>
         ^~~~~~~~~~~~~~~~~
1 error generated.
make[2]: *** [test/fuzz/fuzz-http_request.o] Error 1
make[1]: *** [all-recursive] Error 1
make: *** [all-recursive] Error 1


*How reliably can you reproduce the issue, what are the steps to do so?*

% cd depends/
% make
% cd -
% ./autogen.sh
% export BOOST_ROOT=/opt/homebrew/opt/boost
% ./configure --prefix=$PWD/depends/arm-apple-darwin20.2.0 --with-boost=$BOOST_ROOT
% make HOST=arm-apple-darwin20

*What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)?*
 
Did a `git pull` today Nov 20, 2021

*What type of machine are you observing the error on (OS/CPU and disk type)?*

MacOS BigSur 11.6 Mac Mini M1 2020

*GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell?*

Not a GUI related issue.

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2021-10-17 09:43:51,question,A bug: The wallet passphrase entered was incorrect,"Hi~

I'm new to bitcoin, so I just start to use Bitcoin core on my Ubuntu server.

I first created 2 wallet, one of which is called 'testwallet'. 
```
$  bitcoin-cli createwallet testwallet false false -passphrase=""test1234567"" false false true 
```

However, when I try to unlock it for 60s:
```
$  bitcoin-cli -rpcwallet=""testwallet"" walletpassphrase ""test1234567"" 60
```
error returned:
```
error code: -14
error message:
Error: The wallet passphrase entered was incorrect.
```
It's a little bit confusing, because another one wallet seemed to be normal.
Is it because I use one more wallets?

Here is the environment of my machine and bitcoin-core:
```
$ uname -a
Linux <servername> 5.4.0-050400-generic #201911242031 SMP Mon Nov 25 01:35:10 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux

$ bitcoin-cli getnetworkinfo
{
  ""version"": 220000,
  ""subversion"": ""/Satoshi:22.0.0/"",
  ""protocolversion"": 70016,
  ""localservices"": ""0000000000000409"",
  ""localservicesnames"": [
    ""NETWORK"",
    ""WITNESS"",
    ""NETWORK_LIMITED""
  ],
  ""localrelay"": true,
  ""timeoffset"": 0,
  ""networkactive"": true,
  ""connections"": 10,
  ""connections_in"": 0,
  ""connections_out"": 10,
  ""networks"": [
    {
      ""name"": ""ipv4"",
      ""limited"": false,
      ""reachable"": true,
      ""proxy"": """",
      ""proxy_randomize_credentials"": false
    },
    {
      ""name"": ""ipv6"",
      ""limited"": false,
      ""reachable"": true,
      ""proxy"": """",
      ""proxy_randomize_credentials"": false
    },
    {
      ""name"": ""onion"",
      ""limited"": true,
      ""reachable"": false,
      ""proxy"": """",
      ""proxy_randomize_credentials"": false
    },
    {
      ""name"": ""i2p"",
      ""limited"": true,
      ""reachable"": false,
      ""proxy"": """",
      ""proxy_randomize_credentials"": false
    }
  ],
  ""relayfee"": 0.00001000,
  ""incrementalfee"": 0.00001000,
  ""localaddresses"": [
  ],
  ""warnings"": """"
}

```
Hope somebody could help. Thanks a lot!

"
bitcoin/bitcoin,2021-10-01 19:42:23,question,In file included from util/strencodings.cpp:6:0: fatal error: charconv: No such file.,"Hello. I have a trouble.

`make[3]: выход из каталога «/usr/local/src/wallets/bitcoin»
  CXX      util/libbitcoinconsensus_la-strencodings.lo
  CXX      bitcoind-bitcoind.o
In file included from util/strencodings.cpp:6:0:
./util/strencodings.h:15:10: fatal error: charconv: Нет такого файла или каталога
 #include <charconv>
          ^~~~~~~~~~
compilation terminated.
Makefile:11830: recipe for target 'util/libbitcoinconsensus_la-strencodings.lo' failed
make[2]: *** [util/libbitcoinconsensus_la-strencodings.lo] Error 1
make[2]: *** Ожидание завершения заданий…
In file included from ./netaddress.h:19:0,
                 from ./chainparams.h:11,
                 from bitcoind.cpp:10:
./util/strencodings.h:15:10: fatal error: charconv: Нет такого файла или каталога
 #include <charconv>
          ^~~~~~~~~~
compilation terminated.
`
What i have to do?

Ubuntu 18.04 x64 noGUI"
bitcoin/bitcoin,2021-08-20 07:41:06,question,how to quicken the make process after modifing the codes?,"Hello, I am just learning the bitcoin codes of version bitcoin-0.20. 
So I compiled the codes for a very long time to generate the bitcoind and so on.
After a period of learning , I want to modify some codes in order to verify some ideas. 
By the way , I run the bitcoin on my WSL of the windows10 . However, I found the makefile period is a very long time despite I only modify  one sentence codes. 
Hence, would you please tell me how to quicken the make process after modifing the bitcoin codes?
Thank you very much."
bitcoin/bitcoin,2021-08-18 06:28:42,question,"300GB of Blockchain in dir, prune is set to 20GB",I assume its just rubbish from old client versions of bitcoin core. how to identify files that are not used any more?
bitcoin/bitcoin,2021-08-02 16:40:24,question,Is listtransactions correct? ,"```
ubuntu:~/environment $ bitcoin-cli -datadir=btcdir -testnet -rpcwallet=tomo2 listtransactions ""*"" 
[
  {
    ""address"": ""tb1qdvx8rmj8e94a43lsj5jq4ja6hu2efgps50s0kk"",
    ""category"": ""receive"",
    ""amount"": 0.00010000,
    ""label"": ""user1"",
    ""vout"": 0,
    ""confirmations"": 12,
    ""blockhash"": ""000000000ea24c66faac775cca0a1963a183d03bd4f37cc9890f166d9a75fe90"",
    ""blockheight"": 2062825,
    ""blockindex"": 91,
    ""blocktime"": 1627916153,
    ""txid"": ""9786cbc553d528be721a34502cfb8322ab5f269633aaab9cdc8f8df1e35f732d"",
    ""walletconflicts"": [
    ],
    ""time"": 1627915291,
    ""timereceived"": 1627915291,
    ""bip125-replaceable"": ""no""
  },
  {
    ""address"": ""tb1qdcvdnq46qxk7yxzmvwmscnzalpltaxt7k74nle"",
    ""category"": ""receive"",
    ""amount"": 0.00010000,
    ""label"": ""user2"",
    ""vout"": 1,
    ""confirmations"": 12,
    ""blockhash"": ""000000000ea24c66faac775cca0a1963a183d03bd4f37cc9890f166d9a75fe90"",
    ""blockheight"": 2062825,
    ""blockindex"": 113,
    ""blocktime"": 1627916153,
    ""txid"": ""01eff63265abbcc5647b1f06402aa50fb4be5f6c1d2f4128a3bdb637c6535e7d"",
    ""walletconflicts"": [
    ],
    ""time"": 1627915300,
    ""timereceived"": 1627915300,
    ""bip125-replaceable"": ""no""
  },
  {
    ""address"": ""tb1ql7w62elx9ucw4pj5lgw4l028hmuw80sndtntxt"",
    ""category"": ""send"",
    ""amount"": -0.00010000,
    ""vout"": 1,
    ""fee"": -0.00000208,
    ""confirmations"": 9,
    ""blockhash"": ""00000000ff6e1692ed86533b03d527a183e44ad3382b429075466515582a3a6a"",
    ""blockheight"": 2062828,
    ""blockindex"": 102,
    ""blocktime"": 1627918629,
    ""txid"": ""e08d12afb8aebe4571a293acaa7e0b84d0baccafb1d242cb0fc1d936f65d29f0"",
    ""walletconflicts"": [
    ],
    ""time"": 1627917768,
    ""timereceived"": 1627917768,
    ""bip125-replaceable"": ""no"",
    ""abandoned"": false
  },
  {
    ""address"": ""tb1ql7w62elx9ucw4pj5lgw4l028hmuw80sndtntxt"",
    ""category"": ""send"",
    ""amount"": -0.00005000,
    ""vout"": 0,
    ""fee"": -0.00000141,
    ""confirmations"": 9,
    ""blockhash"": ""00000000ff6e1692ed86533b03d527a183e44ad3382b429075466515582a3a6a"",
    ""blockheight"": 2062828,
    ""blockindex"": 103,
    ""blocktime"": 1627918629,
    ""txid"": ""6e0c2ace9900b668c9b633e7045a9c0895bb9754c6f41c70cfde628bb3562d6a"",
    ""walletconflicts"": [
    ],
    ""time"": 1627918027,
    ""timereceived"": 1627918027,
    ""bip125-replaceable"": ""no"",
    ""abandoned"": false
  },
  {
    ""address"": ""tb1ql7w62elx9ucw4pj5lgw4l028hmuw80sndtntxt"",
    ""category"": ""send"",
    ""amount"": -0.00001000,
    ""vout"": 1,
    ""fee"": -0.00000141,
    ""confirmations"": 3,
    ""blockhash"": ""000000000000002f727825f1de5b724f33a4b4aca5ab16c9bfafb508824afa4e"",
    ""blockheight"": 2062834,
    ""blockindex"": 25,
    ""blocktime"": 1627920653,
    ""txid"": ""1e674af169748c15d5017b22a93e6e524e039e409c5f2b714d146a31ba61fcc7"",
    ""walletconflicts"": [
    ],
    ""time"": 1627920400,
    ""timereceived"": 1627920400,
    ""bip125-replaceable"": ""no"",
    ""comment"": ""cooment=move"",
    ""abandoned"": false
  },
  {
    ""address"": ""tb1ql7w62elx9ucw4pj5lgw4l028hmuw80sndtntxt"",
    ""category"": ""send"",
    ""amount"": -0.00001000,
    ""vout"": 0,
    ""fee"": -0.00000141,
    ""confirmations"": 2,
    ""blockhash"": ""000000000000001f09fea29302386f747e2ad871dad1707396aed27823566d42"",
    ""blockheight"": 2062835,
    ""blockindex"": 78,
    ""blocktime"": 1627920941,
    ""txid"": ""22e365f45981c8550484be576ac8c9aa62400d9320873be057ed20404cae7f5c"",
    ""walletconflicts"": [
    ],
    ""time"": 1627920839,
    ""timereceived"": 1627920839,
    ""bip125-replaceable"": ""no"",
    ""comment"": ""cooment_to=move"",
    ""abandoned"": false
  }
]
ubuntu:~/environment $ bitcoin-cli -datadir=btcdir -testnet -rpcwallet=tomo2 listtransactions ""*"" 3 3
[
  {
    ""address"": ""tb1qdvx8rmj8e94a43lsj5jq4ja6hu2efgps50s0kk"",
    ""category"": ""receive"",
    ""amount"": 0.00010000,
    ""label"": ""user1"",
    ""vout"": 0,
    ""confirmations"": 12,
    ""blockhash"": ""000000000ea24c66faac775cca0a1963a183d03bd4f37cc9890f166d9a75fe90"",
    ""blockheight"": 2062825,
    ""blockindex"": 91,
    ""blocktime"": 1627916153,
    ""txid"": ""9786cbc553d528be721a34502cfb8322ab5f269633aaab9cdc8f8df1e35f732d"",
    ""walletconflicts"": [
    ],
    ""time"": 1627915291,
    ""timereceived"": 1627915291,
    ""bip125-replaceable"": ""no""
  },
  {
    ""address"": ""tb1qdcvdnq46qxk7yxzmvwmscnzalpltaxt7k74nle"",
    ""category"": ""receive"",
    ""amount"": 0.00010000,
    ""label"": ""user2"",
    ""vout"": 1,
    ""confirmations"": 12,
    ""blockhash"": ""000000000ea24c66faac775cca0a1963a183d03bd4f37cc9890f166d9a75fe90"",
    ""blockheight"": 2062825,
    ""blockindex"": 113,
    ""blocktime"": 1627916153,
    ""txid"": ""01eff63265abbcc5647b1f06402aa50fb4be5f6c1d2f4128a3bdb637c6535e7d"",
    ""walletconflicts"": [
    ],
    ""time"": 1627915300,
    ""timereceived"": 1627915300,
    ""bip125-replaceable"": ""no""
  },
  {
    ""address"": ""tb1ql7w62elx9ucw4pj5lgw4l028hmuw80sndtntxt"",
    ""category"": ""send"",
    ""amount"": -0.00010000,
    ""vout"": 1,
    ""fee"": -0.00000208,
    ""confirmations"": 9,
    ""blockhash"": ""00000000ff6e1692ed86533b03d527a183e44ad3382b429075466515582a3a6a"",
    ""blockheight"": 2062828,
    ""blockindex"": 102,
    ""blocktime"": 1627918629,
    ""txid"": ""e08d12afb8aebe4571a293acaa7e0b84d0baccafb1d242cb0fc1d936f65d29f0"",
    ""walletconflicts"": [
    ],
    ""time"": 1627917768,
    ""timereceived"": 1627917768,
    ""bip125-replaceable"": ""no"",
    ""abandoned"": false
  }
]

I want to skip 3 past transactions.

However, it seems that the three latest transactions have been eliminated.

Is this the correct behavior?


ideal
> bitcoin-cli listtransactions ""*"" 20 100
List transactions 100 to 120

realty
> bitcoin-cli listtransactions ""*"" 20 100
List transactions 0 to 20


2021-08-02T13:23:29Z Bitcoin Core version v0.21.1 (release build)"
bitcoin/bitcoin,2021-07-15 09:27:28,question,Cannot sign a transaction with P2WSH/P2SH while using signrawtransactionwithwallet,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue!

Any report, issue or feature request related to the GUI should be reported at
https://github.com/bitcoin-core/gui/issues/
-->

<!-- Describe the issue -->
I'm creating a raw transaction using the RPC command `createrawtransaction`  When I'm signing the transaction with the RPC command `signrawtransactionwithwallet`- I'm receiving the following error: 
```
response code: 500 responseMessage Internal Server Error, response: {""result"":null,""error"":{""code"":-8,""message"":""redeemScript/witnessScript does not match scriptPubKey""},""id"":""1""
```
When I'm using `signrawtransactionwithkey` the transaction signed (and sent) correctly.

Bitcoin version: 0.21
OS: Linux/Windows
<!--- What behavior did you expect? -->

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2021-07-06 18:00:21,question,Rate limits for `ping` RPC,"### Issue
What are the rate limits for [`ping`](https://bitcoincore.org/en/doc/0.21.0/rpc/network/ping/) RPC which was added in https://github.com/bitcoin/bitcoin/pull/2937?

If no rate limits, do we need them? 

### What behavior did you expect?

I was expecting some errors in bitcoind or maybe peers ban my node based on the rate limits mentioned in https://bitcointalk.org/index.php?topic=279652.msg3002232#msg3002232

> I added a ratelimit to RPC-requested ping, so that it will limit to 1/second per peer.  The regular automated keepalive ping is immune to this.

But this comment says there is no rate limit:

> Got rid of the idea of rate-limiting user-requested RPC pings, that simplifies a chunk of code.

https://github.com/bitcoin/bitcoin/pull/2937#issuecomment-23245689

### What was the actual behavior ?

No errors. Peers did not ban my node. I was sending 50-100 `ping` per second

### How reliably can you reproduce the issue, what are the steps to do so?

Its easy to reproduce. Everyone can use different ways to send `ping`. I used the below steps:

1. Run `bitcoind` with bitcoin.conf:

   ```
   testnet=1
   server=1
   
   test.rpcport=18444
   rpcuser=user3
   rpcpassword=password3
   ```
2. Use intruder in Burp Suite to brute force and send `ping` RPC with different id in each request.

   Request:

   ```
   POST / HTTP/1.1
   Host: 127.0.01:18444
   Authorization: Basic dXNlcjM6cGFzc3dvcmQz
   Content-Type: text/plain
   Content-Length: 68

   {""jsonrpc"": ""1.0"", ""id"": ""$curltest$"", ""method"": ""ping"", ""params"": []}
   ```

3. Check peers with `-netinfo` and `getpeerinfo`. Keep an eye on bitcoind for errors.

```
$ bitcoin-cli -netinfo
Bitcoin Core v21.99.0-bb4790816d84 testnet - 70016/Satoshi:21.99.0/

        ipv4    ipv6   onion   total   block
in         0       0       1       1
out        6       0       4      10       2
total      6       0       5      11

Local addresses
eadtub66sw6z4rtzf753aplvy7psthggirtgowr3rsnebbpsws2vyxyd.onion     port  18333    score      4

```

`getpeerinfo` : https://pastebin.com/vKi5sfK2

Requests sent at 06 Jul 2021 17:28:01 GMT (72111 - 72028 = 83)

<details><summary>First</summary>

![image](https://user-images.githubusercontent.com/13405205/124644027-692afc80-deaf-11eb-8fae-a6d6cc56daae.png)

</details>

<details><summary>Last</summary>

![image](https://user-images.githubusercontent.com/13405205/124644109-82cc4400-deaf-11eb-9951-2c7dbe9ec241.png)

</details>

### Bitcoin Core version

Bitcoin Core v21.99.0-bb4790816d84 (Had compiled yesterday for testing PR 17355)

### What type of machine are you observing the error on (OS/CPU and disk type)? 

Linux (Pop!_OS) as VM

Related question: https://bitcoin.stackexchange.com/questions/107431/what-is-ping-rpc-used-for


"
bitcoin/bitcoin,2021-06-29 12:10:50,question,the 2 block relay connections don't seem to be providing any value,"In all my time running the code where 2 block relays are allocated, I have never seen them receiving any blocks - it's always the ""full relay"" nodes that are receiving the blocks.

Perhaps I am misunderstanding the purpose of these 2 connections - but so far I am seeing no benefit in them - my understanding was that they were in some way more likely to be ready to receive a block than the ""full delay"" nodes, but this is not what happens from several weeks of observation."
bitcoin/bitcoin,2021-06-20 14:40:14,question,Need help understanding parts of span.h,"Hi, in span.h you define a strange macro
https://github.com/bitcoin/bitcoin/blob/965e93743454112c0c3c66bf24852f63ee07b862/src/span.h#L14

could someone please tell me the reasoning behind this? 
It doesn't seem to be mentionned in the comments, maybe I overlooked it. 

The reason I don't understand is that it, as far as I know, does not have to change anything whatsoever in terms of code generation.
Static initialization can happen without constexpr. (In fact it's a sneaky way to introduce bugs whenever you have a global std::map… It's a lot of ""fun"" but I digress). 

Then we have this 
https://github.com/bitcoin/bitcoin/blob/965e93743454112c0c3c66bf24852f63ee07b862/src/span.h#L116-L125
Now I'm very confused. 
Is this checking if an incomplete type is convertible to another incomplete type? 
I don't know how that template could possibly do anything else. It's not checking if `T**` is implicitly convertible to `C**`, is it? **I don't know what that does.** 

Why is it only constexpr when not in debug? 
Why is it only doing this, rather important looking, assertion in debug? 
Does it become valid to violate that assertion in prod? 
Why? It seems odd and bug prone. 

Thank you for your time. "
bitcoin/bitcoin,2021-06-04 12:48:22,question,EXCEPTION: N5boost10filesystem16filesystem_errorE,"I got this message when I run bitcoind

EXCEPTION: N5boost10filesystem16filesystem_errorE
boost:: filesytem:: create_directory: File exists: ""home/sats/.bitcoin""
bitcoind: chainparambase.cpp:36: const CBaseChainParams& Base Params() Assertion GlobalChainBaseParams failed
Aborted (core dumped)


Any ideas whats happening?"
bitcoin/bitcoin,2021-05-09 03:34:17,question,Why don't we have more checkpoints?,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->
`src/chainparams.cpp:146` has few checkpoints for the mainnet using a table of block and blockhash. Why does it end at block 295000?

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->
Either add a comment with an explanation for given number checkpoints or add checkpoints at an agreed block interval.

**Describe alternatives you've considered**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->

**Additional context**
<!-- Add any other context or screenshots about the feature request here. -->
![Screen Shot 2021-05-09 at 8 58 49 AM](https://user-images.githubusercontent.com/6998593/117559740-82791d80-b0a5-11eb-8ee7-3aeb0689c304.png)
"
bitcoin/bitcoin,2021-04-15 15:02:24,question,Failed to start bitcoind using Ubuntu 20.10,"Hey I keep getting this error when I run sudo systemctl start bitcoind.service

Job for bitcoind.service failed because the control process exited with error code.
See ""systemctl status bitcoind.service"" and ""journalctl -xe"" for details.

When I input sudo journalctl -xe I get this.

░░ The job identifier is 6033.
abr 15 16:16:36 sats-desktop bitcoind[7207]: Error: Error parsing command line arguments: Invalid parameter -daemonwait
abr 15 16:16:36 sats-desktop systemd[1]: bitcoind.service: Control process exited, code=exited, status=1/FAILURE
░░ Subject: Unit process exited
░░ Defined-By: systemd
░░ Support: http://www.ubuntu.com/support
░░ 
░░ An ExecStart= process belonging to unit bitcoind.service has exited.
░░ 
░░ The process' exit code is 'exited' and its exit status is 1.
abr 15 16:16:36 sats-desktop systemd[1]: bitcoind.service: Failed with result 'exit-code'.
░░ Subject: Unit failed
░░ Defined-By: systemd
░░ Support: http://www.ubuntu.com/support
░░ 
░░ The unit bitcoind.service has entered the 'failed' state with result 'exit-code'.
abr 15 16:16:36 sats-desktop systemd[1]: Failed to start Bitcoin daemon.
░░ Subject: A start job for unit bitcoind.service has failed
░░ Defined-By: systemd
░░ Support: http://www.ubuntu.com/support
░░ 
░░ A start job for unit bitcoind.service has finished with a failure.
░░ 
░░ The job identifier is 6033 and the job result is failed.
abr 15 16:16:36 sats-desktop systemd[1]: bitcoind.service: Scheduled restart job, restart counter is at 5.
░░ Subject: Automatic restarting of a unit has been scheduled
░░ Defined-By: systemd
░░ Support: http://www.ubuntu.com/support
░░ 
░░ Automatic restarting of the unit bitcoind.service has been scheduled, as the result for
░░ the configured Restart= setting for the unit.
abr 15 16:16:36 sats-desktop systemd[1]: Stopped Bitcoin daemon.
░░ Subject: A stop job for unit bitcoind.service has finished
░░ Defined-By: systemd
░░ Support: http://www.ubuntu.com/support
░░ 
░░ A stop job for unit bitcoind.service has finished.
░░ 
░░ The job identifier is 6113 and the job result is done.
abr 15 16:16:36 sats-desktop systemd[1]: bitcoind.service: Start request repeated too quickly.
abr 15 16:16:36 sats-desktop systemd[1]: bitcoind.service: Failed with result 'exit-code'.
░░ Subject: Unit failed
░░ Defined-By: systemd
░░ Support: http://www.ubuntu.com/support
░░ 
░░ The unit bitcoind.service has entered the 'failed' state with result 'exit-code'.
abr 15 16:16:36 sats-desktop systemd[1]: Failed to start Bitcoin daemon.
░░ Subject: A start job for unit bitcoind.service has failed
░░ Defined-By: systemd
░░ Support: http://www.ubuntu.com/support
░░ 
░░ A start job for unit bitcoind.service has finished with a failure.
░░ 
░░ The job identifier is 6113 and the job result is failed.
lines 1841-1894/1894 (END)


When I input systemctl status bitcoind.service I get this:
bitcoind.service - Bitcoin daemon
     Loaded: loaded (/etc/systemd/system/bitcoind.service; enabled; vendor preset: enabled)
     Active: failed (Result: exit-code) since Thu 2021-04-15 14:13:16 CEST; 21min ago
       Docs: https://github.com/bitcoin/bitcoin/blob/master/doc/init.md
    Process: 5604 ExecStart=/usr/local/bin/bitcoind -daemonwait -pid=/run/bitcoind/bitcoind.pid -conf=/home/sats/.bitcoin/bitcoin.conf -datadir=/home/sats/.bitcoin (code=exited, status=1/FAILURE)

abr 15 14:13:16 sats-desktop systemd[1]: bitcoind.service: Scheduled restart job, restart counter is at 5.
abr 15 14:13:16 sats-desktop systemd[1]: Stopped Bitcoin daemon.
abr 15 14:13:16 sats-desktop systemd[1]: bitcoind.service: Start request repeated too quickly.
abr 15 14:13:16 sats-desktop systemd[1]: bitcoind.service: Failed with result 'exit-code'.
abr 15 14:13:16 sats-desktop systemd[1]: Failed to start Bitcoin daemon.
~

Some idea how can I solve the problem??


"
bitcoin/bitcoin,2021-03-29 14:46:30,question,PSBT strange behavior,"<!-- Describe the issue -->
Hi,

I am trying to set-up a ColdCard to work air-gapped with Bitcoin Core (via SD card). Latest Bitcoin Core 0.21.0 and latest ColdCard firmware used.

**Expected behavior**
<!--- What behavior did you expect? -->

I Create a watch-only non-descriptor wallet and I execute the importmulti command created by ColdCard (2x5000 addresses).

- I do a two simple (1in 1 out) test transactions (main-net) all looks good. Core exports the PSBT file ~600 bytes. Coldcard signs it and creates the final TXN ~400 bytes. All good.
- 
I believe the exported unsigned PSBT should stay small, but it's not.
**Actual behavior**

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->
Nothing changed (I mean Core closed and reopened few hours later, that's all). New TX arrives in. Trying to do the same spend and PSBT export. Exported PSBT file is now ~176 Kilobytes(!!). See attached partial file.
[PSBTPartial.txt](https://github.com/bitcoin/bitcoin/files/6222545/PSBTPartial.txt)

Takes minutes while ColdCard digs through all of that and finally signs the one used and produces a ~400 bytes TXN with the one input one output.

Nothing fancy is going on, no multisig used, no nothing. Why does Core include a lot/all addresses in a PSBT? Also it's not doing it at the beginning.

**To reproduce**
- Create a watch-only non-descriptor wallet and I execute the importmulti command created by ColdCard (2x5000 addresses)
importdescriptors '[{""range"": [0, 5000], ""timestamp"": ""now"", ""active"": true, ""watchonly"": true, ""desc"": ""pkh([XX/44h/0h/0h]xpubXX/0/*)#XX"", ""internal"": false}, {""range"": [0, 5000], ""timestamp"": ""now"", ""active"": true, ""watchonly"": true, ""desc"": ""pkh([XX/44h/0h/0h]xpubXX/1/*)#XX"", ""internal"": true}]'
- Check you received the correct addresses from Core
- Make two receive and send (full) amount transaction to/from on other wallet
- Now you should see the huge PSBT file now.

I have done this from scratch with BIP44 and BIP84 addresses and both suffer from the same issue.

**System information**
Core v0.21.0 from download
AMD 2920X Win10 x64
"
bitcoin/bitcoin,2021-02-14 11:45:39,question,Bitcoins im jahr  2009 hier angelegt   komme nicht mehr  drauf zu,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->

**Expected behavior**

<!--- What behavior did you expect? -->

**Actual behavior**

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2021-02-03 02:50:00,question,Use of testmempoolaccept is not clear. testmempoolaccept yields unexpected error.,"**Expected behavior**

I would expect to get no error message when using `testmempoolaccept` on a raw transaction that decodes just fine using `decoderawtransaction` or at least a hint at what went wrong.

**Actual behavior**

```
getrawtransaction ea369e4d7cbb9f2a2fd58dff4d0923112a00674faa1b35bfd6424f89c94ab653
0200000000010175c0e156c5c2545db4cf009a756a433677cce7d845f7626559329681379998950...
decoderawtransaction ""0200000000010175c0e156c5c2545db4cf009a756a433677cce7d845...""
{
  ""txid"": ""ea369e4d7cbb9f2a2fd58dff4d0923112a00674faa1b35bfd6424f89c94ab653"",
  ...
testmempoolaccept [""0200000000010175c0e156c5c2545db4cf009a756a433677cce7d845f...""]
Error: Error parsing JSON: [0200000000010175c0e156c5c2545db4cf009a756a433677cce...
```

**To reproduce**

Probably always reproducible with confirmed transactions?

**System information**

bitcoin core 0.18.1 tgz, 0.20.0 snap and tgz"
bitcoin/bitcoin,2021-01-02 16:41:44,question,Cannot generate change address on descriptor wallets.,"I am trying to create an unsigned transaction in a wallet that contains a 3 of 7 public key descriptor.

**Expected behavior**

To be able to send half a UTXO and bitcoin core to handle the change address generation

**Actual behavior**

Instead, I get this error on clicking ""create unsigned"". ""Transaction needs a change address, but we can't generate it. Please call keypoolrefill first.""

**To reproduce**

*To create descriptor*
1. Create a standard wallet using bitcoin core 
2. Run ""getnewaddress"" to generate an address
3. Run ""dumpprivkey"" using the address previously generated to get a WIF key
4. XOR the WIF key with 256 ""1""s to create a unique key(not to add security or randomness)
4. Create a new standard wallet and run ""sethdseed"" with the modified WIF key
5. Dump the second wallet to get the xpriv 
6. Repeat steps 2-5 to generate 7 xprivs
7. Using the xprivs create the 3 of 7 descriptor example below
wsh(multi(3,'xpriv1'/*,'xpriv2'/*,'xpriv3'/*,'xpriv4'/*,'xpriv5'/*,'xpriv6'/*,'xpriv7'/*))
Remove ' from the above string.
8. In the first wallet Run ""getdescriptorinfo"" to both generate the checksum for the xpriv descriptor and the xpub descriptor itself

*To reproduce error*
1. Create a descriptor wallet with disabled private keys
2. Import the public key descriptor with ""importdescriptors"" example bellow
importdescriptors '[{ ""desc"":""wsh(multi(3,'xpriv1'/*,'xpriv2'/*,'xpriv3'/*,'xpriv4'/*,'xpriv5'/*,'xpriv6'/*,'xpriv7'/*))#'checksum'"", ""timestamp"": ""now"", ""active"": true}]'
Remove ' from the above string.
3. Click ""Create new receiving address"" in the bitcoin core UI
4. Send a small amount to the address
5. In the Send tab enter a recipient and then attempt to send half of the original amount sent to the address.
6. You should get an error ""Transaction needs a change address, but we can't generate it. Please call keypoolrefill first.""

**System info**
I am using ubuntu 20 with bitcoin core 0.21.0 rc3

"
bitcoin/bitcoin,2020-12-12 15:56:06,question,Can't sync signet using 0.21-rc3,"I downloaded bitcoin-0.21.0rc3-x86_64-linux-gnu.tar.gz from bitcoincore.org/bin/.. and ran it with no prior .bitcoin folder. Output:

```
$ ./bitcoind -signet
2020-12-12T15:39:04Z Bitcoin Core version v0.21.0rc3 (release build)
2020-12-12T15:39:04Z Signet derived magic (message start): 0a03cf40
2020-12-12T15:39:04Z Assuming ancestors of block 0000002a1de0f46379358c1fd09906f7ac59adf3712323ed90eb59e4c183c020 have valid signatures.
2020-12-12T15:39:04Z Setting nMinimumChainWork=00000000000000000000000000000000000000000000000000000019fd16269a
2020-12-12T15:39:04Z Using the 'sse4(1way),sse41(4way),avx2(8way)' SHA256 implementation
2020-12-12T15:39:04Z Using RdSeed as additional entropy source
2020-12-12T15:39:04Z Using RdRand as an additional entropy source
2020-12-12T15:39:04Z Default data directory /home/twitch/.bitcoin
2020-12-12T15:39:04Z Using data directory /home/twitch/.bitcoin/signet
2020-12-12T15:39:04Z Config file: /home/twitch/.bitcoin/bitcoin.conf (not found, skipping)
2020-12-12T15:39:04Z Command-line arg: signet=""""
2020-12-12T15:39:04Z Using at most 125 automatic connections (1024 file descriptors available)
2020-12-12T15:39:04Z Using 16 MiB out of 32/2 requested for signature cache, able to store 524288 elements
2020-12-12T15:39:04Z Using 16 MiB out of 32/2 requested for script execution cache, able to store 524288 elements
2020-12-12T15:39:04Z Script verification uses 7 additional threads
2020-12-12T15:39:05Z scheduler thread start
2020-12-12T15:39:05Z HTTP: creating work queue of depth 16
2020-12-12T15:39:05Z Using random cookie authentication.
2020-12-12T15:39:05Z Generated RPC authentication cookie /home/twitch/.bitcoin/signet/.cookie
2020-12-12T15:39:05Z HTTP: starting 4 worker threads
2020-12-12T15:39:05Z Using wallet directory /home/twitch/.bitcoin/signet/wallets
2020-12-12T15:39:05Z init message: Verifying wallet(s)...
2020-12-12T15:39:05Z init message: Loading banlist...
2020-12-12T15:39:05Z ERROR: DeserializeFileDB: Failed to open file /home/twitch/.bitcoin/signet/banlist.dat
2020-12-12T15:39:05Z Invalid or missing banlist.dat; recreating
2020-12-12T15:39:05Z SetNetworkActive: true
2020-12-12T15:39:05Z Using /16 prefix for IP bucketing
2020-12-12T15:39:05Z Cache configuration:
2020-12-12T15:39:05Z * Using 2.0 MiB for block index database
2020-12-12T15:39:05Z * Using 8.0 MiB for chain state database
2020-12-12T15:39:05Z * Using 440.0 MiB for in-memory UTXO set (plus up to 286.1 MiB of unused mempool space)
2020-12-12T15:39:05Z init message: Loading block index...
2020-12-12T15:39:05Z Switching active chainstate to Chainstate [ibd] @ height -1 (null)
2020-12-12T15:39:05Z Opening LevelDB in /home/twitch/.bitcoin/signet/blocks/index
2020-12-12T15:39:05Z Opened LevelDB successfully
2020-12-12T15:39:05Z Using obfuscation key for /home/twitch/.bitcoin/signet/blocks/index: 0000000000000000
2020-12-12T15:39:05Z LoadBlockIndexDB: last block file = 0
2020-12-12T15:39:05Z LoadBlockIndexDB: last block file info: CBlockFileInfo(blocks=0, size=0, heights=0...0, time=1970-01-01...1970-01-01)
2020-12-12T15:39:05Z Checking all blk files are present...
2020-12-12T15:39:05Z Initializing databases...
2020-12-12T15:39:05Z Pre-allocating up to position 0x1000000 in blk00000.dat
2020-12-12T15:39:05Z Opening LevelDB in /home/twitch/.bitcoin/signet/chainstate
2020-12-12T15:39:05Z Opened LevelDB successfully
2020-12-12T15:39:05Z Wrote new obfuscate key for /home/twitch/.bitcoin/signet/chainstate: 170005111e9356f3
2020-12-12T15:39:05Z Using obfuscation key for /home/twitch/.bitcoin/signet/chainstate: 170005111e9356f3
2020-12-12T15:39:05Z init message: Rewinding blocks...
2020-12-12T15:39:05Z  block index              34ms
2020-12-12T15:39:05Z loadblk thread start
2020-12-12T15:39:05Z UpdateTip: new best=00000008819873e925422c1ff0f99f7cc9bbb232af63a077a480a3633bee1ef6 height=0 version=0x00000001 log2_work=22.206105 tx=1 date='2020-09-01T00:00:00Z' progress=0.000064 cache=0.0MiB(0txo)
2020-12-12T15:39:05Z block tree size = 1
2020-12-12T15:39:05Z nBestHeight = 0
2020-12-12T15:39:05Z Failed to open mempool file from disk. Continuing anyway.
2020-12-12T15:39:05Z loadblk thread exit
2020-12-12T15:39:05Z torcontrol thread start
2020-12-12T15:39:05Z Bound to [::]:38333
2020-12-12T15:39:05Z Bound to 0.0.0.0:38333
2020-12-12T15:39:05Z Bound to 127.0.0.1:38334
2020-12-12T15:39:05Z init message: Loading P2P addresses...
2020-12-12T15:39:05Z ERROR: DeserializeFileDB: Failed to open file /home/twitch/.bitcoin/signet/peers.dat
2020-12-12T15:39:05Z Invalid or missing peers.dat; recreating
2020-12-12T15:39:05Z ERROR: DeserializeFileDB: Failed to open file /home/twitch/.bitcoin/signet/anchors.dat
2020-12-12T15:39:05Z 0 block-relay-only anchors will be tried for connections.
2020-12-12T15:39:05Z init message: Starting network threads...
2020-12-12T15:39:05Z dnsseed thread start
2020-12-12T15:39:05Z Loading addresses from DNS seed 2a01:7c8:d005:390::5
2020-12-12T15:39:05Z net thread start
2020-12-12T15:39:05Z init message: Done loading
2020-12-12T15:39:05Z opencon thread start
2020-12-12T15:39:05Z addcon thread start
2020-12-12T15:39:05Z msghand thread start
2020-12-12T15:39:05Z Loading addresses from DNS seed 178.128.221.177
2020-12-12T15:39:05Z Loading addresses from DNS seed ntv3mtqw5wt63red.onion:38333
2020-12-12T15:39:05Z 0 addresses found from DNS seeds
2020-12-12T15:39:05Z dnsseed thread exit
2020-12-12T15:39:06Z New outbound peer connected: version: 70016, blocks=15726, peer=0 (full-relay)
2020-12-12T15:39:06Z Cannot create socket for ntv3mtqw5wt63red.onion:38333: unsupported network
2020-12-12T15:40:06Z Adding fixed seed nodes as DNS doesn't seem to be available.
```

If I switch back to rc2 it works fine.

I expect rc3 to sync, but it doesn't.
"
bitcoin/bitcoin,2020-11-27 11:36:29,question,generatetoaddress blocks don't include tx'es from mempool,"I mined in offline mode >101 test blocks. Then i try to send some test coins on other wallet. Coins stay unconfirmed even after 14 new blocks made by generatetoaddress command in console.

**Expected behavior**

Generated blocks by command generatetoaddress include tx'es from mempool.

**Actual behavior**

All new blocks made by generatetoaddress command have only one tx. It don't use mempool.

**To reproduce**

1. Run new installation of Bitcoin Core in offline mode
2. Generate > 101 blocks by command in console:
  ```generatetoaddress 102 getnewaddress() -1```
3. Create new Wallet and send some coins on it
4. Generate more blocks by command in console:
  ```generatetoaddress 10 getnewaddress() -1```

**System information**

v0.19.0.1"
bitcoin/bitcoin,2020-11-11 09:48:23,question,compile_commands.json generated ERROR with ccls under VIM mode,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->
$ ./autogen.sh
$ ./configure -without-gui
$ compliedb -n make 

when I use vim to open the project , the are some warning information display as follow:
![WX20201111-174002](https://user-images.githubusercontent.com/7480459/98795824-a258bd00-2445-11eb-9936-ae5ca372700c.png)

which are all about c++ standard library. does it have relationship to Makefile which was auto generated by autopen.sh?
**Expected behavior**
NO ERROR DISPLAY
<!--- What behavior did you expect? -->

**Actual behavior**

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**
bitcoin version: commit-id  218fe60d91a9190aa0ee561479044df368214766
<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2020-11-05 21:54:56,question,Q: cs_main protection for referencing m_blockman/g_chainman?,"While making my [de-globalize ChainstateManager](https://github.com/bitcoin/bitcoin/pull/20158) changes, I noticed something that I wasn't sure what to make of: both the global instance of `ChainstateManager` `g_chainman` and the `BlockManager` member of `g_chainman` are protected by `::cs_main`.

This means that changes like the following where I'm simply passing a `BlockManager` to a function have to add an awkward `WITH_LOCK` in order to appease thread safety analysis.

Examples:
1. [`d227dfe` (#20158)](https://github.com/bitcoin/bitcoin/pull/20158/commits/d227dfedfdfc5f8df05f13ee31a475a5a716c151#diff-ccc24453c13307f815879738d3bf00eec351417537fbf10dde1468180cacd2f1)
2. [`f8e91ed` (#20158)](https://github.com/bitcoin/bitcoin/pull/20158/commits/f8e91ed44a8f4deb9440e0c4d2829733399bcda2#diff-1ef3b6a1936b50f3d5ec4a1786d9e2d63d1a3e1815b103e67f20601995f355b4)

However, I'm not entirely sure if these `::cs_main` protections should be required for referencing these objects themselves, especially since `ChainstateManager` and `BlockManagers`'s member variables/functions are already well annotated w/re locks.

Any insights would be useful :-)"
bitcoin/bitcoin,2020-10-25 11:16:39,question,Test Failure in Alpine Linux - 'Ensure adding witness outputs with uncompressed pubkeys fails',"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->

**Expected behavior**

Pass the test

**Actual behavior**

Failed the test

**To reproduce**

run `make check`:

```
 'Creates a new transaction with a single 2-of-3 multisig in a P2WSH output',
 'Creates a new transaction with a single 2-of-3 multisig in a P2WSH output (output in json)',
 'Creates a new transaction with a single 2-of-3 multisig in a P2WSH output, wrapped in P2SH',
 'Creates a new transaction with a single 2-of-3 multisig in a P2WSH output, wrapped in P2SH (output in json)',
 'Uncompressed pubkeys should work just fine for non-witness outputs',
 'Ensure adding witness outputs with uncompressed pubkeys fails']
make[3]: *** [Makefile:19028: check-local] Error 1
make[3]: Leaving directory '/home/stuart/aports/community/bitcoin/src/bitcoin-0.20.1/src'
make[2]: *** [Makefile:17578: check-am] Error 2
make[2]: Leaving directory '/home/stuart/aports/community/bitcoin/src/bitcoin-0.20.1/src'
make[1]: *** [Makefile:17263: check-recursive] Error 1
make[1]: Leaving directory '/home/stuart/aports/community/bitcoin/src/bitcoin-0.20.1/src'
make: *** [Makefile:781: check-recursive] Error 1
>>> ERROR: bitcoin: check failed
```

**System information**

- Bitcoin `0.20.1`
- Alpine Linux Edge (`3.12.1` currently) LXC container


"
bitcoin/bitcoin,2020-09-24 03:53:37,question,bitcoin-cli does not include wallet functionalities when compiling dependencies,"## Behavior

When compiling bitcoin on linux 64bit (Ubuntu 20.04.1 LTS):

```
git clone https://github.com/bitcoin/bitcoin.git
git checkout v0.20.1
./autogen.sh
cd depends
make NO_QT=1
cd ..
./configure --prefix=$PWD/depends/x86_64-pc-linux-gnu --with-gui=no --disable-tests --disable-gui-tests
make && make install
./depends/x86_64-pc-linux-gnu/bin/bitcoin-cli getnewaddress
```

Expected behaviour: shows `getnewaddress` help
Actual behaviour:
```
error code: -32601
error message:
Method not found
```

None of the wallet commands are available.

I understand that the wallet feature should enabled by default.

Did I mess up a step?

<details><summary>./config.log</summary>

```
This file contains any messages produced by compilers while
running configure, to aid debugging if configure makes a mistake.

It was created by Bitcoin Core configure 0.20.1, which was
generated by GNU Autoconf 2.69.  Invocation command line was

  $ ./configure --prefix=/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu --with-gui=no --disable-tests --disable-gui-tests --enable-wallet

## --------- ##
## Platform. ##
## --------- ##

hostname = nuc
uname -m = x86_64
uname -r = 5.4.0-47-generic
uname -s = Linux
uname -v = #51-Ubuntu SMP Fri Sep 4 19:50:52 UTC 2020

/usr/bin/uname -p = unknown
/bin/uname -X     = unknown

/bin/arch              = unknown
/usr/bin/arch -k       = unknown
/usr/convex/getsysinfo = unknown
/usr/bin/hostinfo      = unknown
/bin/machine           = unknown
/usr/bin/oslevel       = unknown
/bin/universe          = unknown

PATH: /home/dante/bin
PATH: /var/lib/gems/1.8/bin
PATH: /home/dante/.cargo/bin
PATH: /home/dante/bin
PATH: /home/dante/bin
PATH: /var/lib/gems/1.8/bin
PATH: /usr/local/sbin
PATH: /usr/local/bin
PATH: /usr/sbin
PATH: /usr/bin
PATH: /sbin
PATH: /bin
PATH: /usr/games
PATH: /usr/local/games
PATH: /snap/bin
PATH: /sbin
PATH: /home/dante/.gem/ruby/1.8/bin
PATH: /sbin
PATH: /usr/local/scripts
PATH: /usr/local/bin
PATH: /home/dante/go/bin
PATH: /sbin
PATH: /home/dante/.gem/ruby/1.8/bin
PATH: /sbin
PATH: /usr/local/scripts
PATH: /usr/local/bin


## ----------- ##
## Core tests. ##
## ----------- ##

configure:2943: loading site script /home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/config.site
| depends_prefix=""`dirname ${ac_site_file}`/..""
|
| cross_compiling=maybe
| host_alias=x86_64-pc-linux-gnu
| ac_tool_prefix=${host_alias}-
|
| if test -z $with_boost; then
|   with_boost=$depends_prefix
| fi
| if test -z $with_qt_plugindir; then
|   with_qt_plugindir=$depends_prefix/plugins
| fi
| if test -z $with_qt_translationdir; then
|   with_qt_translationdir=$depends_prefix/translations
| fi
| if test -z $with_qt_bindir && test -z ""1""; then
|   with_qt_bindir=$depends_prefix/native/bin
| fi
|
| if test -z $with_qrencode && test -n """"; then
|   with_qrencode=no
| fi
|
| if test -z $enable_wallet && test -n """"; then
|   enable_wallet=no
| fi
|
| if test -z $with_miniupnpc && test -n """"; then
|   with_miniupnpc=no
| fi
|
| if test -z $with_gui && test -n ""1""; then
|   with_gui=no
| fi
|
| if test -z $enable_zmq && test -n """"; then
|   enable_zmq=no
| fi
|
| if test xlinux = xdarwin; then
|   BREW=no
|   PORT=no
| fi
|
| if test xlinux = xmingw32; then
|   if test -z $with_qt_incdir; then
|     with_qt_incdir=$depends_prefix/include
|   fi
|   if test -z $with_qt_libdir; then
|     with_qt_libdir=$depends_prefix/lib
|   fi
| fi
|
| PATH=$depends_prefix/native/bin:$PATH
| PKG_CONFIG=""`which pkg-config` --static""
|
| # These two need to remain exported because pkg-config does not see them
| # otherwise. That means they must be unexported at the end of configure.ac to
| # avoid ruining the cache. Sigh.
| export PKG_CONFIG_PATH=$depends_prefix/share/pkgconfig:$depends_prefix/lib/pkgconfig
| if test -z """"; then
|   export PKG_CONFIG_LIBDIR=$depends_prefix/lib/pkgconfig
| fi
|
| CPPFLAGS=""-I$depends_prefix/include/ $CPPFLAGS""
| LDFLAGS=""-L$depends_prefix/lib $LDFLAGS""
|
| if test -n ""gcc -m64"" -a -z ""${CC}""; then
|   CC=""gcc -m64""
| fi
| if test -n ""g++ -m64"" -a -z ""${CXX}""; then
|   CXX=""g++ -m64""
| fi
| PYTHONPATH=$depends_prefix/native/lib/python3/dist-packages:$PYTHONPATH
|
| if test -n ""ar""; then
|   AR=ar
|   ac_cv_path_ac_pt_AR=${AR}
| fi
|
| if test -n ""ranlib""; then
|   RANLIB=ranlib
|   ac_cv_path_ac_pt_RANLIB=${RANLIB}
| fi
|
| if test -n ""nm""; then
|   NM=nm
|   ac_cv_path_ac_pt_NM=${NM}
| fi
|
| if test -n """"; then
|   enable_reduce_exports=no
| fi
|
| if test -n ""-pipe -O2""; then
|   CFLAGS=""-pipe -O2 $CFLAGS""
| fi
| if test -n ""-pipe -O2""; then
|   CXXFLAGS=""-pipe -O2 $CXXFLAGS""
| fi
| if test -n """"; then
|   CPPFLAGS="" $CPPFLAGS""
| fi
| if test -n """"; then
|   LDFLAGS="" $LDFLAGS""
| fi
configure:3088: checking build system type
configure:3102: result: x86_64-pc-linux-gnu
configure:3122: checking host system type
configure:3135: result: x86_64-pc-linux-gnu
configure:3178: checking for a BSD-compatible install
configure:3246: result: /usr/bin/install -c
configure:3257: checking whether build environment is sane
configure:3312: result: yes
configure:3369: checking for x86_64-pc-linux-gnu-strip
configure:3399: result: no
configure:3409: checking for strip
configure:3425: found /usr/bin/strip
configure:3436: result: strip
configure:3461: checking for a thread-safe mkdir -p
configure:3500: result: /bin/mkdir -p
configure:3507: checking for gawk
configure:3523: found /usr/bin/gawk
configure:3534: result: gawk
configure:3545: checking whether make sets $(MAKE)
configure:3567: result: yes
configure:3596: checking whether make supports nested variables
configure:3613: result: yes
configure:3732: checking whether to enable maintainer-specific portions of Makefiles
configure:3741: result: yes
configure:3766: checking whether make supports nested variables
configure:3783: result: yes
configure:3912: checking for C++ compiler version
configure:3921: g++ -m64 --version >&5
g++ (Ubuntu 9.3.0-10ubuntu2) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

configure:3932: $? = 0
configure:3921: g++ -m64 -v >&5
Using built-in specs.
COLLECT_GCC=g++
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none:hsa
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 9.3.0-10ubuntu2' --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu2)
configure:3932: $? = 0
configure:3921: g++ -m64 -V >&5
g++: error: unrecognized command line option '-V'
g++: fatal error: no input files
compilation terminated.
configure:3932: $? = 1
configure:3921: g++ -m64 -qversion >&5
g++: error: unrecognized command line option '-qversion'; did you mean '--version'?
g++: fatal error: no input files
compilation terminated.
configure:3932: $? = 1
configure:3952: checking whether the C++ compiler works
configure:3974: g++ -m64 -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:3978: $? = 0
configure:4026: result: yes
configure:4029: checking for C++ compiler default output file name
configure:4031: result: a.out
configure:4037: checking for suffix of executables
configure:4044: g++ -m64 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:4048: $? = 0
configure:4070: result:
configure:4092: checking whether we are cross compiling
configure:4100: g++ -m64 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:4104: $? = 0
configure:4111: ./conftest
configure:4115: $? = 0
configure:4103: result: no
configure:4108: checking for suffix of object files
configure:4130: g++ -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:4134: $? = 0
configure:4155: result: o
configure:4159: checking whether we are using the GNU C++ compiler
configure:4178: g++ -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:4178: $? = 0
configure:4187: result: yes
configure:4196: checking whether g++ -m64 accepts -g
configure:4216: g++ -m64 -c -g -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:4216: $? = 0
configure:4257: result: yes
configure:4283: checking whether make supports the include directive
configure:4298: make -f confmf.GNU && cat confinc.out
this is the am__doit target
configure:4301: $? = 0
configure:4320: result: yes (GNU style)
configure:4345: checking dependency style of g++ -m64
configure:4456: result: gcc3
configure:4494: checking whether g++ -m64 supports C++11 features with -std=c++11
configure:4790: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:4790: $? = 0
configure:4799: result: yes
configure:4843: checking whether std::atomic can be used without link library
configure:4861: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:4861: $? = 0
configure:4863: result: yes
configure:4932: checking for x86_64-pc-linux-gnu-g++
configure:4959: result: g++ -m64 -std=c++11
configure:5028: checking for Objective C++ compiler version
configure:5037: g++ -m64 -std=c++11 --version >&5
g++ (Ubuntu 9.3.0-10ubuntu2) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

configure:5048: $? = 0
configure:5037: g++ -m64 -std=c++11 -v >&5
Using built-in specs.
COLLECT_GCC=g++
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none:hsa
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 9.3.0-10ubuntu2' --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu2)
configure:5048: $? = 0
configure:5037: g++ -m64 -std=c++11 -V >&5
g++: error: unrecognized command line option '-V'
g++: fatal error: no input files
compilation terminated.
configure:5048: $? = 1
configure:5037: g++ -m64 -std=c++11 -qversion >&5
g++: error: unrecognized command line option '-qversion'; did you mean '--version'?
g++: fatal error: no input files
compilation terminated.
configure:5048: $? = 1
configure:5052: checking whether we are using the GNU Objective C++ compiler
configure:5071: g++ -m64 -std=c++11 -c  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.mm >&5
g++: fatal error: cannot execute 'cc1objplus': execvp: No such file or directory
compilation terminated.
configure:5071: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
| #ifndef __GNUC__
|        choke me
| #endif
|
|   ;
|   return 0;
| }
configure:5080: result: no
configure:5089: checking whether g++ -m64 -std=c++11 accepts -g
configure:5109: g++ -m64 -std=c++11 -c -g -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.mm >&5
g++: fatal error: cannot execute 'cc1objplus': execvp: No such file or directory
compilation terminated.
configure:5109: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:5124: g++ -m64 -std=c++11 -c  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.mm >&5
g++: fatal error: cannot execute 'cc1objplus': execvp: No such file or directory
compilation terminated.
configure:5124: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:5140: g++ -m64 -std=c++11 -c -g -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.mm >&5
g++: fatal error: cannot execute 'cc1objplus': execvp: No such file or directory
compilation terminated.
configure:5140: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:5150: result: no
configure:5175: checking dependency style of g++ -m64 -std=c++11
configure:5284: result: gcc3
configure:5348: checking how to print strings
configure:5375: result: printf
configure:5404: checking for x86_64-pc-linux-gnu-gcc
configure:5431: result: gcc -m64
configure:5700: checking for C compiler version
configure:5709: gcc -m64 --version >&5
gcc (Ubuntu 9.3.0-10ubuntu2) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

configure:5720: $? = 0
configure:5709: gcc -m64 -v >&5
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/9/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none:hsa
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 9.3.0-10ubuntu2' --with-bugurl=file:///usr/share/doc/gcc-9/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++,gm2 --prefix=/usr --with-gcc-major-version-only --program-suffix=-9 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib=auto --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none,hsa --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu2)
configure:5720: $? = 0
configure:5709: gcc -m64 -V >&5
gcc: error: unrecognized command line option '-V'
gcc: fatal error: no input files
compilation terminated.
configure:5720: $? = 1
configure:5709: gcc -m64 -qversion >&5
gcc: error: unrecognized command line option '-qversion'; did you mean '--version'?
gcc: fatal error: no input files
compilation terminated.
configure:5720: $? = 1
configure:5724: checking whether we are using the GNU C compiler
configure:5743: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:5743: $? = 0
configure:5752: result: yes
configure:5761: checking whether gcc -m64 accepts -g
configure:5781: gcc -m64 -c -g -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:5781: $? = 0
configure:5822: result: yes
configure:5839: checking for gcc -m64 option to accept ISO C89
configure:5902: gcc -m64  -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:5902: $? = 0
configure:5915: result: none needed
configure:5940: checking whether gcc -m64 understands -c and -o together
configure:5962: gcc -m64 -c conftest.c -o conftest2.o
configure:5965: $? = 0
configure:5962: gcc -m64 -c conftest.c -o conftest2.o
configure:5965: $? = 0
configure:5977: result: yes
configure:5996: checking dependency style of gcc -m64
configure:6107: result: gcc3
configure:6122: checking for a sed that does not truncate output
configure:6186: result: /bin/sed
configure:6204: checking for grep that handles long lines and -e
configure:6262: result: /bin/grep
configure:6267: checking for egrep
configure:6329: result: /bin/grep -E
configure:6334: checking for fgrep
configure:6396: result: /bin/grep -F
configure:6431: checking for ld used by gcc -m64
configure:6498: result: /usr/bin/ld
configure:6505: checking if the linker (/usr/bin/ld) is GNU ld
configure:6520: result: yes
configure:6532: checking for BSD- or MS-compatible name lister (nm)
configure:6586: result: nm
configure:6716: checking the name lister (nm) interface
configure:6723: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:6726: nm ""conftest.o""
configure:6729: output
0000000000000000 B some_variable
configure:6730: result: BSD nm
configure:6733: checking whether ln -s works
configure:6737: result: yes
configure:6745: checking the maximum length of command line arguments
configure:6876: result: 1572864
configure:6924: checking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format
configure:6964: result: func_convert_file_noop
configure:6971: checking how to convert x86_64-pc-linux-gnu file names to toolchain format
configure:6991: result: func_convert_file_noop
configure:6998: checking for /usr/bin/ld option to reload object files
configure:7005: result: -r
configure:7039: checking for x86_64-pc-linux-gnu-objdump
configure:7069: result: no
configure:7079: checking for objdump
configure:7095: found /usr/bin/objdump
configure:7106: result: objdump
configure:7138: checking how to recognize dependent libraries
configure:7338: result: pass_all
configure:7383: checking for x86_64-pc-linux-gnu-dlltool
configure:7413: result: no
configure:7423: checking for dlltool
configure:7453: result: no
configure:7483: checking how to associate runtime and link libraries
configure:7510: result: printf %s\\n
configure:7527: checking for x86_64-pc-linux-gnu-ar
configure:7554: result: ar
configure:7635: checking for archiver @FILE support
configure:7652: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:7652: $? = 0
configure:7655: ar cr libconftest.a @conftest.lst >&5
configure:7658: $? = 0
configure:7663: ar cr libconftest.a @conftest.lst >&5
ar: conftest.o: No such file or directory
configure:7666: $? = 1
configure:7665: result: @
configure:7683: checking for x86_64-pc-linux-gnu-strip
configure:7710: result: strip
configure:7782: checking for x86_64-pc-linux-gnu-ranlib
configure:7809: result: ranlib
configure:7951: checking command to parse nm output from gcc -m64 object
configure:8104: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:8107: $? = 0
configure:8111: nm conftest.o | sed -n -e 's/^.*[        ]\\([ABCDGIRSTW][ABCDGIRSTW]*\\)[         ][      ]*\\([_A-Za-z][_A-Za-z0-9]*\\)$/\\1 \\2 \\2/p' | sed '/ __gnu_lto/d' > conftest.nm
configure:8177: gcc -m64 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.c conftstm.o >&5
configure:8180: $? = 0
configure:8218: result: ok
configure:8265: checking for sysroot
configure:8295: result: no
configure:8302: checking for a working dd
configure:8340: result: /bin/dd
configure:8344: checking how to truncate binary pipes
configure:8359: result: /bin/dd bs=4096 count=1
configure:8495: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:8498: $? = 0
configure:8648: checking for x86_64-pc-linux-gnu-mt
configure:8678: result: no
configure:8688: checking for mt
configure:8704: found /bin/mt
configure:8715: result: mt
configure:8738: checking if mt is a manifest tool
configure:8744: mt '-?'
configure:8752: result: no
configure:9429: checking how to run the C preprocessor
configure:9460: gcc -m64 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c
configure:9460: $? = 0
configure:9474: gcc -m64 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c
conftest.c:10:10: fatal error: ac_nonexistent.h: No such file or directory
   10 | #include <ac_nonexistent.h>
      |          ^~~~~~~~~~~~~~~~~~
compilation terminated.
configure:9474: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:9499: result: gcc -m64 -E
configure:9519: gcc -m64 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c
configure:9519: $? = 0
configure:9533: gcc -m64 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c
conftest.c:10:10: fatal error: ac_nonexistent.h: No such file or directory
   10 | #include <ac_nonexistent.h>
      |          ^~~~~~~~~~~~~~~~~~
compilation terminated.
configure:9533: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:9562: checking for ANSI C header files
configure:9582: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9582: $? = 0
configure:9655: gcc -m64 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.c  >&5
configure:9655: $? = 0
configure:9655: ./conftest
configure:9655: $? = 0
configure:9666: result: yes
configure:9679: checking for sys/types.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for sys/stat.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for stdlib.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for string.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for memory.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for strings.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for inttypes.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for stdint.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9679: checking for unistd.h
configure:9679: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9679: $? = 0
configure:9679: result: yes
configure:9693: checking for dlfcn.h
configure:9693: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:9693: $? = 0
configure:9693: result: yes
configure:9958: checking for objdir
configure:9973: result: .libs
configure:10237: checking if gcc -m64 supports -fno-rtti -fno-exceptions
configure:10255: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -fno-rtti -fno-exceptions conftest.c >&5
cc1: warning: command line option '-fno-rtti' is valid for C++/D/ObjC++ but not for C
configure:10259: $? = 0
configure:10272: result: no
configure:10636: checking for gcc -m64 option to produce PIC
configure:10643: result: -fPIC -DPIC
configure:10651: checking if gcc -m64 PIC flag -fPIC -DPIC works
configure:10669: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -fPIC -DPIC -DPIC conftest.c >&5
configure:10673: $? = 0
configure:10686: result: yes
configure:10715: checking if gcc -m64 static flag -static works
configure:10743: result: yes
configure:10758: checking if gcc -m64 supports -c -o file.o
configure:10779: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -o out/conftest2.o conftest.c >&5
configure:10783: $? = 0
configure:10805: result: yes
configure:10813: checking if gcc -m64 supports -c -o file.o
configure:10860: result: yes
configure:10893: checking whether the gcc -m64 linker (/usr/bin/ld -m elf_x86_64) supports shared libraries
configure:12156: result: yes
configure:12193: checking whether -lc should be explicitly linked in
configure:12201: gcc -m64 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.c >&5
configure:12204: $? = 0
configure:12219: gcc -m64 -shared  -fPIC -DPIC conftest.o  -v -Wl,-soname -Wl,conftest -o conftest 2\\>\\&1 \\| /bin/grep  -lc  \\>/dev/null 2\\>\\&1
configure:12222: $? = 0
configure:12236: result: no
configure:12396: checking dynamic linker characteristics
configure:12977: gcc -m64 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  -Wl,-rpath -Wl,/foo conftest.c  >&5
configure:12977: $? = 0
configure:13226: result: GNU/Linux ld.so
configure:13348: checking how to hardcode library paths into programs
configure:13373: result: immediate
configure:13921: checking whether stripping libraries is possible
configure:13926: result: yes
configure:13961: checking if libtool supports shared libraries
configure:13963: result: yes
configure:13966: checking whether to build shared libraries
configure:13991: result: yes
configure:13994: checking whether to build static libraries
configure:13998: result: yes
configure:10797: checking how to run the C++ preprocessor
configure:10824: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp
configure:10824: $? = 0
configure:10838: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp
conftest.cpp:22:10: fatal error: ac_nonexistent.h: No such file or directory
   22 | #include <ac_nonexistent.h>
      |          ^~~~~~~~~~~~~~~~~~
compilation terminated.
configure:10838: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:10863: result: g++ -m64 -std=c++11 -E
configure:10883: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp
configure:10883: $? = 0
configure:10897: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp
conftest.cpp:22:10: fatal error: ac_nonexistent.h: No such file or directory
   22 | #include <ac_nonexistent.h>
      |          ^~~~~~~~~~~~~~~~~~
compilation terminated.
configure:10897: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:11059: checking for ld used by g++ -m64 -std=c++11
configure:11126: result: /usr/bin/ld -m elf_x86_64
configure:11133: checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld
configure:11148: result: yes
configure:11203: checking whether the g++ -m64 -std=c++11 linker (/usr/bin/ld -m elf_x86_64) supports shared libraries
configure:12276: result: yes
configure:12312: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:12315: $? = 0
configure:12796: checking for g++ -m64 -std=c++11 option to produce PIC
configure:12803: result: -fPIC -DPIC
configure:12811: checking if g++ -m64 -std=c++11 PIC flag -fPIC -DPIC works
configure:12829: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -fPIC -DPIC -DPIC conftest.cpp >&5
configure:12833: $? = 0
configure:12846: result: yes
configure:12869: checking if g++ -m64 -std=c++11 static flag -static works
configure:12897: result: yes
configure:12909: checking if g++ -m64 -std=c++11 supports -c -o file.o
configure:12930: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -o out/conftest2.o conftest.cpp >&5
configure:12934: $? = 0
configure:12956: result: yes
configure:12961: checking if g++ -m64 -std=c++11 supports -c -o file.o
configure:13008: result: yes
configure:13038: checking whether the g++ -m64 -std=c++11 linker (/usr/bin/ld -m elf_x86_64) supports shared libraries
configure:13081: result: yes
configure:13222: checking dynamic linker characteristics
configure:13979: result: GNU/Linux ld.so
configure:14044: checking how to hardcode library paths into programs
configure:14069: result: immediate
configure:12965: checking for x86_64-pc-linux-gnu-ar
configure:12998: result: no
configure:13008: checking for ar
configure:13038: result: ar
configure:13063: checking for x86_64-pc-linux-gnu-ranlib
configure:13096: result: no
configure:13106: checking for ranlib
configure:13136: result: ranlib
configure:13161: checking for x86_64-pc-linux-gnu-strip
configure:13194: result: no
configure:13204: checking for strip
configure:13222: found /usr/bin/strip
configure:13234: result: /usr/bin/strip
configure:13259: checking for x86_64-pc-linux-gnu-gcov
configure:13292: result: no
configure:13302: checking for gcov
configure:13320: found /usr/bin/gcov
configure:13332: result: /usr/bin/gcov
configure:13356: checking for lcov
configure:13389: result: no
configure:13398: checking for python3.5
configure:13416: found /usr/bin/python3.5
configure:13428: result: /usr/bin/python3.5
configure:13441: checking for genhtml
configure:13474: result: no
configure:13481: checking for git
configure:13499: found /usr/bin/git
configure:13511: result: /usr/bin/git
configure:13521: checking for ccache
configure:13554: result: no
configure:13561: checking for xgettext
configure:13594: result: no
configure:13601: checking for hexdump
configure:13619: found /usr/bin/hexdump
configure:13631: result: /usr/bin/hexdump
configure:13642: checking for x86_64-pc-linux-gnu-readelf
configure:13675: result: no
configure:13685: checking for readelf
configure:13703: found /usr/bin/readelf
configure:13715: result: /usr/bin/readelf
configure:13740: checking for x86_64-pc-linux-gnu-c++filt
configure:13773: result: no
configure:13783: checking for c++filt
configure:13801: found /usr/bin/c++filt
configure:13813: result: /usr/bin/c++filt
configure:13838: checking for x86_64-pc-linux-gnu-objcopy
configure:13871: result: no
configure:13881: checking for objcopy
configure:13899: found /usr/bin/objcopy
configure:13911: result: /usr/bin/objcopy
configure:13935: checking for doxygen
configure:13968: result: no
configure:13974: WARNING: Doxygen not found
configure:14222: checking whether C++ compiler accepts -Werror
configure:14241: g++ -m64 -std=c++11 -c -pipe -O2   -Werror -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:14241: $? = 0
configure:14249: result: yes
configure:15407: checking whether C++ compiler accepts -msse4.2
configure:15426: g++ -m64 -std=c++11 -c -pipe -O2  -Werror -msse4.2 -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15426: $? = 0
configure:15435: result: yes
configure:15444: checking whether C++ compiler accepts -msse4.1
configure:15463: g++ -m64 -std=c++11 -c -pipe -O2  -Werror -msse4.1 -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15463: $? = 0
configure:15472: result: yes
configure:15481: checking whether C++ compiler accepts -mavx -mavx2
configure:15500: g++ -m64 -std=c++11 -c -pipe -O2  -Werror -mavx -mavx2 -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15500: $? = 0
configure:15509: result: yes
configure:15518: checking whether C++ compiler accepts -msse4 -msha
configure:15537: g++ -m64 -std=c++11 -c -pipe -O2  -Werror -msse4 -msha -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15537: $? = 0
configure:15546: result: yes
configure:15557: checking for SSE4.2 intrinsics
configure:15583: g++ -m64 -std=c++11 -c -pipe -O2  -msse4.2 -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15583: $? = 0
configure:15584: result: yes
configure:15596: checking for SSE4.1 intrinsics
configure:15615: g++ -m64 -std=c++11 -c -pipe -O2  -msse4.1 -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15615: $? = 0
configure:15616: result: yes
configure:15630: checking for AVX2 intrinsics
configure:15649: g++ -m64 -std=c++11 -c -pipe -O2  -mavx -mavx2 -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15649: $? = 0
configure:15650: result: yes
configure:15664: checking for SHA-NI intrinsics
configure:15685: g++ -m64 -std=c++11 -c -pipe -O2  -msse4 -msha -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
configure:15685: $? = 0
configure:15686: result: yes
configure:15700: checking whether C++ compiler accepts -march=armv8-a+crc+crypto
configure:15719: g++ -m64 -std=c++11 -c -pipe -O2  -Werror -march=armv8-a+crc+crypto -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
cc1plus: error: bad value ('armv8-a+crc+crypto') for '-march=' switch
cc1plus: note: valid arguments to '-march=' switch are: nocona core2 nehalem corei7 westmere sandybridge corei7-avx ivybridge core-avx-i haswell core-avx2 broadwell skylake skylake-avx512 cannonlake icelake-client icelake-server cascadelake bonnell atom silvermont slm goldmont goldmont-plus tremont knl knm x86-64 eden-x2 nano nano-1000 nano-2000 nano-3000 nano-x2 eden-x4 nano-x4 k8 k8-sse3 opteron opteron-sse3 athlon64 athlon64-sse3 athlon-fx amdfam10 barcelona bdver1 bdver2 bdver3 bdver4 znver1 znver2 btver1 btver2 native
configure:15719: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:15728: result: no
configure:15739: checking for ARM CRC32 intrinsics
configure:15758: g++ -m64 -std=c++11 -c -pipe -O2   -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  conftest.cpp >&5
conftest.cpp:27:14: fatal error: arm_acle.h: No such file or directory
   27 |     #include <arm_acle.h>
      |              ^~~~~~~~~~~~
compilation terminated.
configure:15758: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| /* end confdefs.h.  */
|
|     #include <arm_acle.h>
|     #include <arm_neon.h>
|
| int
| main ()
| {
|
|     __crc32cb(0, 0); __crc32ch(0, 0); __crc32cw(0, 0); __crc32cd(0, 0);
|     vmull_p64(0, 0);
|
|   ;
|   return 0;
| }
configure:15762: result: no
configure:17195: checking for x86_64-pc-linux-gnu-pkg-config
configure:17225: result: /usr/bin/pkg-config --static
configure:17293: checking pkg-config is at least version 0.9.0
configure:17296: result: yes
configure:17408: checking whether byte ordering is bigendian
configure:17423: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:27:9: error: expected unqualified-id before 'not' token
   27 |         not a universal capable compiler
      |         ^~~
configure:17423: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| /* end confdefs.h.  */
| #ifndef __APPLE_CC__
|              not a universal capable compiler
|            #endif
|            typedef int dummy;
|
configure:17468: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:17468: $? = 0
configure:17486: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp: In function 'int main()':
conftest.cpp:33:8: error: 'big' was not declared in this scope
   33 |    not big endian
      |        ^~~
configure:17486: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| /* end confdefs.h.  */
| #include <sys/types.h>
|               #include <sys/param.h>
|
| int
| main ()
| {
| #if BYTE_ORDER != BIG_ENDIAN
|                not big endian
|               #endif
|
|   ;
|   return 0;
| }
configure:17614: result: no
configure:17816: checking whether gcc -m64 is Clang
configure:17841: result: no
configure:17964: checking whether pthreads work with -pthread
configure:18058: gcc -m64 -o conftest -pipe -O2  -pthread -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.c   >&5
configure:18058: $? = 0
configure:18067: result: yes
configure:18086: checking for joinable pthread attribute
configure:18104: gcc -m64 -o conftest -pipe -O2  -pthread -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.c   >&5
configure:18104: $? = 0
configure:18112: result: PTHREAD_CREATE_JOINABLE
configure:18126: checking whether more special flags are required for pthreads
configure:18139: result: no
configure:18147: checking for PTHREAD_PRIO_INHERIT
configure:18163: gcc -m64 -o conftest -pipe -O2  -pthread -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.c   >&5
configure:18163: $? = 0
configure:18172: result: yes
configure:18282: checking for special C compiler options needed for large files
configure:18327: result: no
configure:18333: checking for _FILE_OFFSET_BITS value needed for large files
configure:18358: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:18358: $? = 0
configure:18390: result: no
configure:18475: checking whether strerror_r is declared
configure:18475: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:18475: $? = 0
configure:18475: result: yes
configure:18488: checking for strerror_r
configure:18488: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:18488: $? = 0
configure:18488: result: yes
configure:18497: checking whether strerror_r returns char *
configure:18521: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:18521: $? = 0
configure:18559: result: yes
configure:18583: checking for __attribute__((visibility))
configure:18607: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:18607: $? = 0
configure:18620: result: yes
configure:18636: checking for __attribute__((dllexport))
configure:18657: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
conftest.cpp:34:62: warning: 'dllexport' attribute directive ignored [-Wattributes]
   34 |                     __attribute__((dllexport)) int foo( void ) { return 0; }
      |                                                              ^
configure:18657: $? = 0
configure:18670: result: no
configure:18686: checking for __attribute__((dllimport))
configure:18707: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
conftest.cpp:34:62: warning: 'dllimport' attribute directive ignored [-Wattributes]
   34 |                     int foo( void ) __attribute__((dllimport));
      |                                                              ^
configure:18707: $? = 0
configure:18720: result: no
configure:18840: checking for library containing clock_gettime
configure:18871: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:18871: $? = 0
configure:18888: result: none required
configure:19019: checking whether C++ compiler accepts -fPIC
configure:19038: g++ -m64 -std=c++11 -c -pipe -O2   -fPIC -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19038: $? = 0
configure:19046: result: yes
configure:19056: checking whether C++ compiler accepts -fstack-reuse=none
configure:19075: g++ -m64 -std=c++11 -c -pipe -O2   -fstack-reuse=none -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19075: $? = 0
configure:19083: result: yes
configure:19093: checking whether C++ compiler accepts -Wstack-protector
configure:19112: g++ -m64 -std=c++11 -c -pipe -O2   -Wstack-protector -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19112: $? = 0
configure:19120: result: yes
configure:19128: checking whether C++ compiler accepts -fstack-protector-all
configure:19147: g++ -m64 -std=c++11 -c -pipe -O2   -fstack-protector-all -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19147: $? = 0
configure:19155: result: yes
configure:19165: checking whether C++ preprocessor accepts -D_FORTIFY_SOURCE=2
configure:19184: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS  -D_FORTIFY_SOURCE=2 conftest.cpp
configure:19184: $? = 0
configure:19192: result: yes
configure:19196: checking whether C++ preprocessor accepts -U_FORTIFY_SOURCE
configure:19215: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS  -U_FORTIFY_SOURCE conftest.cpp
configure:19215: $? = 0
configure:19223: result: yes
configure:19241: checking whether the linker accepts -Wl,--dynamicbase
configure:19260: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib   -Wl,--dynamicbase conftest.cpp  >&5
/usr/bin/ld: unrecognized option '--dynamicbase'
/usr/bin/ld: use the --help option for usage information
collect2: error: ld returned 1 exit status
configure:19260: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:19269: result: no
configure:19277: checking whether the linker accepts -Wl,--nxcompat
configure:19296: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib   -Wl,--nxcompat conftest.cpp  >&5
/usr/bin/ld: unrecognized option '--nxcompat'
/usr/bin/ld: use the --help option for usage information
collect2: error: ld returned 1 exit status
configure:19296: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:19305: result: no
configure:19313: checking whether the linker accepts -Wl,--high-entropy-va
configure:19332: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib   -Wl,--high-entropy-va conftest.cpp  >&5
/usr/bin/ld: unrecognized option '--high-entropy-va'
/usr/bin/ld: use the --help option for usage information
collect2: error: ld returned 1 exit status
configure:19332: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:19341: result: no
configure:19349: checking whether the linker accepts -Wl,-z,relro
configure:19368: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib   -Wl,-z,relro conftest.cpp  >&5
configure:19368: $? = 0
configure:19377: result: yes
configure:19385: checking whether the linker accepts -Wl,-z,now
configure:19404: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib   -Wl,-z,now conftest.cpp  >&5
configure:19404: $? = 0
configure:19413: result: yes
configure:19422: checking whether the linker accepts -fPIE -pie
configure:19441: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  -Werror -fPIE -pie conftest.cpp  >&5
configure:19441: $? = 0
configure:19451: result: yes
configure:19662: checking endian.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking endian.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking for endian.h
configure:19662: result: yes
configure:19662: checking sys/endian.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:66:10: fatal error: sys/endian.h: No such file or directory
   66 | #include <sys/endian.h>
      |          ^~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| #include <sys/endian.h>
configure:19662: result: no
configure:19662: checking sys/endian.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
conftest.cpp:33:10: fatal error: sys/endian.h: No such file or directory
   33 | #include <sys/endian.h>
      |          ^~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| /* end confdefs.h.  */
| #include <sys/endian.h>
configure:19662: result: no
configure:19662: checking for sys/endian.h
configure:19662: result: no
configure:19662: checking byteswap.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking byteswap.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking for byteswap.h
configure:19662: result: yes
configure:19662: checking stdio.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking stdio.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking for stdio.h
configure:19662: result: yes
configure:19662: checking for stdlib.h
configure:19662: result: yes
configure:19662: checking for unistd.h
configure:19662: result: yes
configure:19662: checking for strings.h
configure:19662: result: yes
configure:19662: checking for sys/types.h
configure:19662: result: yes
configure:19662: checking for sys/stat.h
configure:19662: result: yes
configure:19662: checking sys/select.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking sys/select.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking for sys/select.h
configure:19662: result: yes
configure:19662: checking sys/prctl.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking sys/prctl.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking for sys/prctl.h
configure:19662: result: yes
configure:19662: checking sys/sysctl.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
In file included from conftest.cpp:75:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:21:2: warning: #warning ""The <sys/sysctl.h> header is deprecated and will be removed."" [-Wcpp]
   21 | #warning ""The <sys/sysctl.h> header is deprecated and will be removed.""
      |  ^~~~~~~
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking sys/sysctl.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
In file included from conftest.cpp:42:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:21:2: warning: #warning ""The <sys/sysctl.h> header is deprecated and will be removed."" [-Wcpp]
   21 | #warning ""The <sys/sysctl.h> header is deprecated and will be removed.""
      |  ^~~~~~~
configure:19662: $? = 0
configure:19662: result: yes
configure:19662: checking for sys/sysctl.h
configure:19662: result: yes
configure:19662: checking vm/vm_param.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:10: fatal error: vm/vm_param.h: No such file or directory
   76 | #include <vm/vm_param.h>
      |          ^~~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| #include <vm/vm_param.h>
configure:19662: result: no
configure:19662: checking vm/vm_param.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
conftest.cpp:43:10: fatal error: vm/vm_param.h: No such file or directory
   43 | #include <vm/vm_param.h>
      |          ^~~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| /* end confdefs.h.  */
| #include <vm/vm_param.h>
configure:19662: result: no
configure:19662: checking for vm/vm_param.h
configure:19662: result: no
configure:19662: checking sys/vmmeter.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:10: fatal error: sys/vmmeter.h: No such file or directory
   76 | #include <sys/vmmeter.h>
      |          ^~~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| #include <sys/vmmeter.h>
configure:19662: result: no
configure:19662: checking sys/vmmeter.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
conftest.cpp:43:10: fatal error: sys/vmmeter.h: No such file or directory
   43 | #include <sys/vmmeter.h>
      |          ^~~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| /* end confdefs.h.  */
| #include <sys/vmmeter.h>
configure:19662: result: no
configure:19662: checking for sys/vmmeter.h
configure:19662: result: no
configure:19662: checking sys/resources.h usability
configure:19662: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:10: fatal error: sys/resources.h: No such file or directory
   76 | #include <sys/resources.h>
      |          ^~~~~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| #include <sys/resources.h>
configure:19662: result: no
configure:19662: checking sys/resources.h presence
configure:19662: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
conftest.cpp:43:10: fatal error: sys/resources.h: No such file or directory
   43 | #include <sys/resources.h>
      |          ^~~~~~~~~~~~~~~~~
compilation terminated.
configure:19662: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| /* end confdefs.h.  */
| #include <sys/resources.h>
configure:19662: result: no
configure:19662: checking for sys/resources.h
configure:19662: result: no
configure:19673: checking FD_ZERO memcpy dependence
configure:19696: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19696: $? = 0
configure:19697: result: no
configure:19737: checking whether getifaddrs is declared
configure:19737: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19737: $? = 0
configure:19737: result: yes
configure:19750: checking whether freeifaddrs is declared
configure:19750: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19750: $? = 0
configure:19750: result: yes
configure:19764: checking whether strnlen is declared
configure:19764: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19764: $? = 0
configure:19764: result: yes
configure:19776: checking whether daemon is declared
configure:19776: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19776: $? = 0
configure:19776: result: yes
configure:19788: checking whether le16toh is declared
configure:19788: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19788: $? = 0
configure:19788: result: yes
configure:19803: checking whether le32toh is declared
configure:19803: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19803: $? = 0
configure:19803: result: yes
configure:19818: checking whether le64toh is declared
configure:19818: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19818: $? = 0
configure:19818: result: yes
configure:19833: checking whether htole16 is declared
configure:19833: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19833: $? = 0
configure:19833: result: yes
configure:19848: checking whether htole32 is declared
configure:19848: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19848: $? = 0
configure:19848: result: yes
configure:19863: checking whether htole64 is declared
configure:19863: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19863: $? = 0
configure:19863: result: yes
configure:19878: checking whether be16toh is declared
configure:19878: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19878: $? = 0
configure:19878: result: yes
configure:19893: checking whether be32toh is declared
configure:19893: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19893: $? = 0
configure:19893: result: yes
configure:19908: checking whether be64toh is declared
configure:19908: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19908: $? = 0
configure:19908: result: yes
configure:19923: checking whether htobe16 is declared
configure:19923: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19923: $? = 0
configure:19923: result: yes
configure:19938: checking whether htobe32 is declared
configure:19938: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19938: $? = 0
configure:19938: result: yes
configure:19953: checking whether htobe64 is declared
configure:19953: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19953: $? = 0
configure:19953: result: yes
configure:19970: checking whether bswap_16 is declared
configure:19970: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19970: $? = 0
configure:19970: result: yes
configure:19983: checking whether bswap_32 is declared
configure:19983: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19983: $? = 0
configure:19983: result: yes
configure:19996: checking whether bswap_64 is declared
configure:19996: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:19996: $? = 0
configure:19996: result: yes
configure:20011: checking whether __builtin_clz is declared
configure:20011: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20011: $? = 0
configure:20011: result: yes
configure:20021: checking whether __builtin_clzl is declared
configure:20021: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20021: $? = 0
configure:20021: result: yes
configure:20031: checking whether __builtin_clzll is declared
configure:20031: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20031: $? = 0
configure:20031: result: yes
configure:20043: checking for getmemoryinfo
configure:20056: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20056: $? = 0
configure:20057: result: yes
configure:20068: checking for mallopt M_ARENA_MAX
configure:20081: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20081: $? = 0
configure:20082: result: yes
configure:20093: checking for visibility attribute
configure:20102: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:20102: $? = 0
configure:20107: result: yes
configure:20126: checking for thread_local support
configure:20140: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  -pthread conftest.cpp  >&5
configure:20140: $? = 0
configure:20155: result: yes
configure:20172: checking for gmtime_r
configure:20185: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20185: $? = 0
configure:20186: result: yes
configure:20220: checking for Linux getrandom syscall
configure:20235: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20235: $? = 0
configure:20236: result: yes
configure:20247: checking for getentropy
configure:20260: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp: In function 'int main()':
conftest.cpp:75:12: warning: ignoring return value of 'int getentropy(void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
   75 |  getentropy(nullptr, 32)
      |  ~~~~~~~~~~^~~~~~~~~~~~~
configure:20260: $? = 0
configure:20261: result: yes
configure:20272: checking for getentropy via random.h
configure:20286: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp: In function 'int main()':
conftest.cpp:77:12: warning: ignoring return value of 'int getentropy(void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]
   77 |  getentropy(nullptr, 32)
      |  ~~~~~~~~~~^~~~~~~~~~~~~
configure:20286: $? = 0
configure:20287: result: yes
configure:20298: checking for sysctl
configure:20315: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
In file included from conftest.cpp:74:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:21:2: warning: #warning ""The <sys/sysctl.h> header is deprecated and will be removed."" [-Wcpp]
   21 | #warning ""The <sys/sysctl.h> header is deprecated and will be removed.""
      |  ^~~~~~~
conftest.cpp:79:6: error: #error ""Don't use sysctl on Linux, it's deprecated even when it works""
   79 |     #error ""Don't use sysctl on Linux, it's deprecated even when it works""
      |      ^~~~~
conftest.cpp: In function 'int main()':
conftest.cpp:81:52: warning: 'int sysctl(int*, int, void*, size_t*, void*, size_t)' is deprecated [-Wdeprecated-declarations]
   81 |     sysctl(nullptr, 2, nullptr, nullptr, nullptr, 0);
      |                                                    ^
In file included from conftest.cpp:74:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:70:12: note: declared here
   70 | extern int sysctl (int *__name, int __nlen, void *__oldval,
      |            ^~~~~~
conftest.cpp:81:52: warning: 'int sysctl(int*, int, void*, size_t*, void*, size_t)' is deprecated [-Wdeprecated-declarations]
   81 |     sysctl(nullptr, 2, nullptr, nullptr, nullptr, 0);
      |                                                    ^
In file included from conftest.cpp:74:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:70:12: note: declared here
   70 | extern int sysctl (int *__name, int __nlen, void *__oldval,
      |            ^~~~~~
configure:20315: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| /* end confdefs.h.  */
| #include <sys/types.h>
|   #include <sys/sysctl.h>
| int
| main ()
| {
|  #ifdef __linux__
|     #error ""Don't use sysctl on Linux, it's deprecated even when it works""
|     #endif
|     sysctl(nullptr, 2, nullptr, nullptr, nullptr, 0);
|   ;
|   return 0;
| }
configure:20321: result: no
configure:20327: checking for sysctl KERN_ARND
configure:20345: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
In file included from conftest.cpp:74:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:21:2: warning: #warning ""The <sys/sysctl.h> header is deprecated and will be removed."" [-Wcpp]
   21 | #warning ""The <sys/sysctl.h> header is deprecated and will be removed.""
      |  ^~~~~~~
conftest.cpp:79:6: error: #error ""Don't use sysctl on Linux, it's deprecated even when it works""
   79 |     #error ""Don't use sysctl on Linux, it's deprecated even when it works""
      |      ^~~~~
conftest.cpp: In function 'int main()':
conftest.cpp:81:37: error: 'KERN_ARND' was not declared in this scope; did you mean 'KERN_RANDOM'?
   81 |     static int name[2] = {CTL_KERN, KERN_ARND};
      |                                     ^~~~~~~~~
      |                                     KERN_RANDOM
conftest.cpp:82:49: warning: 'int sysctl(int*, int, void*, size_t*, void*, size_t)' is deprecated [-Wdeprecated-declarations]
   82 |     sysctl(name, 2, nullptr, nullptr, nullptr, 0);
      |                                                 ^
In file included from conftest.cpp:74:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:70:12: note: declared here
   70 | extern int sysctl (int *__name, int __nlen, void *__oldval,
      |            ^~~~~~
conftest.cpp:82:49: warning: 'int sysctl(int*, int, void*, size_t*, void*, size_t)' is deprecated [-Wdeprecated-declarations]
   82 |     sysctl(name, 2, nullptr, nullptr, nullptr, 0);
      |                                                 ^
In file included from conftest.cpp:74:
/usr/include/x86_64-linux-gnu/sys/sysctl.h:70:12: note: declared here
   70 | extern int sysctl (int *__name, int __nlen, void *__oldval,
      |            ^~~~~~
configure:20345: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| /* end confdefs.h.  */
| #include <sys/types.h>
|   #include <sys/sysctl.h>
| int
| main ()
| {
|  #ifdef __linux__
|     #error ""Don't use sysctl on Linux, it's deprecated even when it works""
|     #endif
|     static int name[2] = {CTL_KERN, KERN_ARND};
|     sysctl(name, 2, nullptr, nullptr, nullptr, 0);
|   ;
|   return 0;
| }
configure:20351: result: no
configure:20357: checking for if type char equals int8_t
configure:20371: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp: In function 'int main()':
conftest.cpp:78:44: error: static assertion failed
   78 |  static_assert(std::is_same<int8_t, char>::value, """");
      |                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~
configure:20371: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| /* end confdefs.h.  */
| #include <stdint.h>
|   #include <type_traits>
| int
| main ()
| {
|  static_assert(std::is_same<int8_t, char>::value, """");
|   ;
|   return 0;
| }
configure:20377: result: no
configure:20383: checking for fdatasync
configure:20396: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20396: $? = 0
configure:20397: result: yes
configure:20406: checking for F_FULLFSYNC
configure:20419: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp: In function 'int main()':
conftest.cpp:77:11: error: 'F_FULLFSYNC' was not declared in this scope
   77 |  fcntl(0, F_FULLFSYNC, 0);
      |           ^~~~~~~~~~~
configure:20419: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| /* end confdefs.h.  */
| #include <fcntl.h>
| int
| main ()
| {
|  fcntl(0, F_FULLFSYNC, 0);
|   ;
|   return 0;
| }
configure:20423: result: no
configure:20429: checking for O_CLOEXEC
configure:20442: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20442: $? = 0
configure:20443: result: yes
configure:20452: checking for __builtin_prefetch
configure:20469: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20469: $? = 0
configure:20470: result: yes
configure:20479: checking for _mm_prefetch
configure:20496: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20496: $? = 0
configure:20497: result: yes
configure:20506: checking for strong getauxval support in the system headers
configure:20525: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:74:14: fatal error: arm_acle.h: No such file or directory
   74 |     #include <arm_acle.h>
      |              ^~~~~~~~~~~~
compilation terminated.
configure:20525: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| /* end confdefs.h.  */
|
|     #include <arm_acle.h>
|     #include <arm_neon.h>
|     #include <sys/auxv.h>
|
| int
| main ()
| {
|
|     getauxval(AT_HWCAP);
|
|   ;
|   return 0;
| }
configure:20529: result: no
configure:20535: checking for weak getauxval support in the compiler
configure:20553: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:20553: $? = 0
configure:20554: result: yes
configure:20601: checking for std::system
configure:20615: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
configure:20615: $? = 0
configure:20616: result: yes
configure:20628: checking for ::_wsystem
configure:20642: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp  >&5
conftest.cpp: In function 'int main()':
conftest.cpp:78:15: error: '::_wsystem' has not been declared
   78 |  int nErr = ::_wsystem("""");
      |               ^~~~~~~~
configure:20642: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| /* end confdefs.h.  */
|
| int
| main ()
| {
|  int nErr = ::_wsystem("""");
|
|   ;
|   return 0;
| }
configure:20648: result: no
configure:24653: checking whether to build Bitcoin Core GUI
configure:24687: result: no
configure:24711: checking for Berkeley DB C++ headers
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: bdb4.8/db_cxx.h: No such file or directory
   76 |         #include <bdb4.8/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <bdb4.8/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: libdb4.8/db_cxx.h: No such file or directory
   76 |         #include <libdb4.8/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <libdb4.8/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: db4.8/db_cxx.h: No such file or directory
   76 |         #include <db4.8/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <db4.8/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: bdb48/db_cxx.h: No such file or directory
   76 |         #include <bdb48/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <bdb48/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: libdb48/db_cxx.h: No such file or directory
   76 |         #include <libdb48/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <libdb48/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: db48/db_cxx.h: No such file or directory
   76 |         #include <db48/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <db48/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: bdb4/db_cxx.h: No such file or directory
   76 |         #include <bdb4/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <bdb4/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: libdb4/db_cxx.h: No such file or directory
   76 |         #include <libdb4/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <libdb4/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: db4/db_cxx.h: No such file or directory
   76 |         #include <db4/db_cxx.h>
      |                  ^~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <db4/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: bdb5/db_cxx.h: No such file or directory
   76 |         #include <bdb5/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <bdb5/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: libdb5/db_cxx.h: No such file or directory
   76 |         #include <libdb5/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <libdb5/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: db5/db_cxx.h: No such file or directory
   76 |         #include <db5/db_cxx.h>
      |                  ^~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <db5/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: bdb5.3/db_cxx.h: No such file or directory
   76 |         #include <bdb5.3/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <bdb5.3/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: libdb5.3/db_cxx.h: No such file or directory
   76 |         #include <libdb5.3/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <libdb5.3/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: db5.3/db_cxx.h: No such file or directory
   76 |         #include <db5.3/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <db5.3/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: bdb/db_cxx.h: No such file or directory
   76 |         #include <bdb/db_cxx.h>
      |                  ^~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <bdb/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: libdb/db_cxx.h: No such file or directory
   76 |         #include <libdb/db_cxx.h>
      |                  ^~~~~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <libdb/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
conftest.cpp:76:18: fatal error: db/db_cxx.h: No such file or directory
   76 |         #include <db/db_cxx.h>
      |                  ^~~~~~~~~~~~~
compilation terminated.
configure:24741: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| /* end confdefs.h.  */
|
|         #include <db/db_cxx.h>
|
| int
| main ()
| {
|
|         #if !((DB_VERSION_MAJOR == 4 && DB_VERSION_MINOR >= 8) || DB_VERSION_MAJOR > 4)
|           #error ""failed to find bdb 4.8+""
|         #endif
|
|   ;
|   return 0;
| }
configure:24741: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:24741: $? = 0
configure:24770: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:24770: $? = 0
configure:24813: result: default
configure:24836: checking for main in -ldb_cxx-4.8
configure:24855: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp -ldb_cxx-4.8   >&5
configure:24855: $? = 0
configure:24865: result: yes
configure:24887: checking miniupnpc/miniwget.h usability
configure:24887: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking miniupnpc/miniwget.h presence
configure:24887: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking for miniupnpc/miniwget.h
configure:24887: result: yes
configure:24892: checking for upnpDiscover in -lminiupnpc
configure:24917: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp -lminiupnpc   >&5
configure:24917: $? = 0
configure:24926: result: yes
configure:24887: checking miniupnpc/miniupnpc.h usability
configure:24887: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking miniupnpc/miniupnpc.h presence
configure:24887: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking for miniupnpc/miniupnpc.h
configure:24887: result: yes
configure:24892: checking for upnpDiscover in -lminiupnpc
configure:24926: result: yes
configure:24887: checking miniupnpc/upnpcommands.h usability
configure:24887: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking miniupnpc/upnpcommands.h presence
configure:24887: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking for miniupnpc/upnpcommands.h
configure:24887: result: yes
configure:24892: checking for upnpDiscover in -lminiupnpc
configure:24926: result: yes
configure:24887: checking miniupnpc/upnperrors.h usability
configure:24887: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp >&5
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking miniupnpc/upnperrors.h presence
configure:24887: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:24887: $? = 0
configure:24887: result: yes
configure:24887: checking for miniupnpc/upnperrors.h
configure:24887: result: yes
configure:24892: checking for upnpDiscover in -lminiupnpc
configure:24926: result: yes
configure:24942: checking whether miniUPnPc API version is supported
configure:24963: g++ -m64 -std=c++11 -E -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS conftest.cpp
configure:24963: $? = 0
configure:24965: result: yes
configure:25080: checking for boostlib >= 1.47.0 (104700) includes in ""/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include""
configure:25084: result: yes
configure:25088: checking for boostlib >= 1.47.0 (104700) lib path in ""/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib/x86_64-linux-gnu""
configure:25098: result: no
configure:25088: checking for boostlib >= 1.47.0 (104700) lib path in ""/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib64""
configure:25098: result: no
configure:25088: checking for boostlib >= 1.47.0 (104700) lib path in ""/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../libx32""
configure:25098: result: no
configure:25088: checking for boostlib >= 1.47.0 (104700) lib path in ""/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib""
configure:25092: result: yes
configure:25132: checking for boostlib >= 1.47.0 (104700)
configure:25164: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include conftest.cpp >&5
configure:25164: $? = 0
configure:25166: result: yes
configure:25361: checking whether the Boost::System library is available
configure:25386: g++ -m64 -std=c++11 -c  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include conftest.cpp >&5
configure:25386: $? = 0
configure:25401: result: yes
configure:25416: checking for exit in -lboost_system-mt-x64
configure:25441: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib conftest.cpp -lboost_system-mt-x64   >&5
conftest.cpp:88:6: warning: declaration of 'char exit()' conflicts with built-in declaration 'void exit(int)' [-Wbuiltin-declaration-mismatch]
   88 | char exit ();
      |      ^~~~
configure:25441: $? = 0
configure:25451: result: yes
configure:25606: checking whether the Boost::Filesystem library is available
configure:25630: g++ -m64 -std=c++11 -c -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include conftest.cpp >&5
configure:25630: $? = 0
configure:25644: result: yes
configure:25655: checking for exit in -lboost_filesystem-mt-x64
configure:25680: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib conftest.cpp -lboost_filesystem-mt-x64   -lboost_system-mt-x64 >&5
conftest.cpp:89:6: warning: declaration of 'char exit()' conflicts with built-in declaration 'void exit(int)' [-Wbuiltin-declaration-mismatch]
   89 | char exit ();
      |      ^~~~
configure:25680: $? = 0
configure:25690: result: yes
configure:25840: checking whether the Boost::Thread library is available
configure:25873: g++ -m64 -std=c++11 -c -pthread -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include conftest.cpp >&5
configure:25873: $? = 0
configure:25888: result: yes
configure:25917: checking for exit in -lboost_thread-mt-x64
configure:25942: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib conftest.cpp -lboost_thread-mt-x64   >&5
conftest.cpp:90:6: warning: declaration of 'char exit()' conflicts with built-in declaration 'void exit(int)' [-Wbuiltin-declaration-mismatch]
   90 | char exit ();
      |      ^~~~
configure:25942: $? = 0
configure:25952: result: yes
configure:26404: checking for mismatched boost c++11 scoped enums
configure:26432: g++ -m64 -std=c++11 -o conftest -pipe -O2  -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS -DBOOST_SP_USE_STD_ATOMIC -DBOOST_AC_USE_STD_ATOMIC -pthread -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib  conftest.cpp -L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib -lboost_system-mt-x64 -lboost_filesystem-mt-x64 -lboost_thread-mt-x64 -lpthread  >&5
conftest.cpp: In function 'int main()':
conftest.cpp:100:5: error: 'choke' was not declared in this scope
  100 |     choke;
      |     ^~~~~
configure:26432: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME ""Bitcoin Core""
| #define PACKAGE_TARNAME ""bitcoin""
| #define PACKAGE_VERSION ""0.20.1""
| #define PACKAGE_STRING ""Bitcoin Core 0.20.1""
| #define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
| #define PACKAGE_URL ""https://bitcoincore.org/""
| #define HAVE_CXX11 1
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define LT_OBJDIR "".libs/""
| #define USE_ASM 1
| #define ENABLE_SSE41 1
| #define ENABLE_AVX2 1
| #define ENABLE_SHANI 1
| #define HAVE_PTHREAD_PRIO_INHERIT 1
| #define HAVE_PTHREAD 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| #define STRERROR_R_CHAR_P 1
| #define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
| #define HAVE_ENDIAN_H 1
| #define HAVE_BYTESWAP_H 1
| #define HAVE_STDIO_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_PRCTL_H 1
| #define HAVE_SYS_SYSCTL_H 1
| #define HAVE_DECL_GETIFADDRS 1
| #define HAVE_DECL_FREEIFADDRS 1
| #define HAVE_DECL_STRNLEN 1
| #define HAVE_DECL_DAEMON 1
| #define HAVE_DECL_LE16TOH 1
| #define HAVE_DECL_LE32TOH 1
| #define HAVE_DECL_LE64TOH 1
| #define HAVE_DECL_HTOLE16 1
| #define HAVE_DECL_HTOLE32 1
| #define HAVE_DECL_HTOLE64 1
| #define HAVE_DECL_BE16TOH 1
| #define HAVE_DECL_BE32TOH 1
| #define HAVE_DECL_BE64TOH 1
| #define HAVE_DECL_HTOBE16 1
| #define HAVE_DECL_HTOBE32 1
| #define HAVE_DECL_HTOBE64 1
| #define HAVE_DECL_BSWAP_16 1
| #define HAVE_DECL_BSWAP_32 1
| #define HAVE_DECL_BSWAP_64 1
| #define HAVE_DECL___BUILTIN_CLZ 1
| #define HAVE_DECL___BUILTIN_CLZL 1
| #define HAVE_DECL___BUILTIN_CLZLL 1
| #define HAVE_MALLOC_INFO 1
| #define HAVE_MALLOPT_ARENA_MAX 1
| #define HAVE_VISIBILITY_ATTRIBUTE 1
| #define HAVE_THREAD_LOCAL 1
| #define HAVE_GMTIME_R 1
| #define HAVE_SYS_GETRANDOM 1
| #define HAVE_GETENTROPY 1
| #define HAVE_GETENTROPY_RAND 1
| #define HAVE_STD__SYSTEM 1
| #define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
| #define HAVE_MINIUPNPC_MINIWGET_H 1
| #define HAVE_MINIUPNPC_MINIUPNPC_H 1
| #define HAVE_MINIUPNPC_UPNPCOMMANDS_H 1
| #define HAVE_MINIUPNPC_UPNPERRORS_H 1
| #define HAVE_BOOST /**/
| #define HAVE_BOOST_SYSTEM /**/
| #define HAVE_BOOST_FILESYSTEM /**/
| #define HAVE_BOOST_THREAD /**/
| /* end confdefs.h.  */
|
|   #include <boost/config.hpp>
|   #include <boost/version.hpp>
|   #if !defined(BOOST_NO_SCOPED_ENUMS) && !defined(BOOST_NO_CXX11_SCOPED_ENUMS) && BOOST_VERSION < 105700
|   #define BOOST_NO_SCOPED_ENUMS
|   #define BOOST_NO_CXX11_SCOPED_ENUMS
|   #define CHECK
|   #endif
|   #include <boost/filesystem.hpp>
|
| int
| main ()
| {
|
|   #if defined(CHECK)
|     boost::filesystem::copy_file(""foo"", ""bar"");
|   #else
|     choke;
|   #endif
|
|   ;
|   return 0;
| }
configure:26436: result: ok
configure:26532: checking for EVENT
configure:26539: $PKG_CONFIG --exists --print-errors ""libevent >= 2.0.21""
configure:26542: $? = 0
configure:26556: $PKG_CONFIG --exists --print-errors ""libevent >= 2.0.21""
configure:26559: $? = 0
configure:26597: result: yes
configure:26604: checking for EVENT_PTHREADS
configure:26611: $PKG_CONFIG --exists --print-errors ""libevent_pthreads >= 2.0.21""
configure:26614: $? = 0
configure:26628: $PKG_CONFIG --exists --print-errors ""libevent_pthreads >= 2.0.21""
configure:26631: $? = 0
configure:26669: result: yes
configure:26679: checking for ZMQ
configure:26686: $PKG_CONFIG --exists --print-errors ""libzmq >= 4""
configure:26689: $? = 0
configure:26703: $PKG_CONFIG --exists --print-errors ""libzmq >= 4""
configure:26706: $? = 0
configure:26754: result: yes
configure:27163: checking whether to build bitcoind
configure:27173: result: yes
configure:27176: checking whether to build bitcoin-cli
configure:27186: result: yes
configure:27189: checking whether to build bitcoin-tx
configure:27199: result: yes
configure:27202: checking whether to build bitcoin-wallet
configure:27212: result: yes
configure:27215: checking whether to build libraries
configure:27232: result: yes
configure:27243: checking if ccache should be used
configure:27256: result: no
configure:27297: checking if wallet should be enabled
configure:27300: result: yes
configure:27313: checking whether to build with support for UPnP
configure:27324: result: yes
configure:27326: checking whether to build with UPnP enabled by default
configure:27334: result: no
configure:27406: checking whether to build test_bitcoin
configure:27413: result: no
configure:27418: checking whether to reduce exports
configure:27424: result: no
configure:27836: checking that generated files are newer than configure
configure:27842: result: done
configure:27998: creating ./config.status

## ---------------------- ##
## Running config.status. ##
## ---------------------- ##

This file was extended by Bitcoin Core config.status 0.20.1, which was
generated by GNU Autoconf 2.69.  Invocation command line was

  CONFIG_FILES    =
  CONFIG_HEADERS  =
  CONFIG_LINKS    =
  CONFIG_COMMANDS =
  $ ./config.status

on nuc

config.status:1452: creating libbitcoinconsensus.pc
config.status:1452: creating Makefile
config.status:1452: creating src/Makefile
config.status:1452: creating doc/man/Makefile
config.status:1452: creating share/setup.nsi
config.status:1452: creating share/qt/Info.plist
config.status:1452: creating test/config.ini
config.status:1452: creating contrib/devtools/split-debug.sh
config.status:1452: creating src/config/bitcoin-config.h
config.status:1633: src/config/bitcoin-config.h is unchanged
config.status:1712: executing depfiles commands
config.status:1789: cd src       && sed -e '/# am--include-marker/d' Makefile         | make -f - am--depfiles
make: Nothing to be done for 'am--depfiles'.
config.status:1794: $? = 0
config.status:1712: executing libtool commands
configure:30523: === configuring in src/univalue (/home/dante/src/bitcoin/src/univalue)
configure:30586: running /bin/bash ./configure --disable-option-checking '--prefix=/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu'  '--with-gui=no' '--disable-tests' '--disable-gui-tests' '--enable-wallet' '--disable-shared' '--with-pic' '--enable-benchmark=no' '--with-bignum=no' '--enable-module-recovery' '--disable-jni' --cache-file=/dev/null --srcdir=.
configure:30523: === configuring in src/secp256k1 (/home/dante/src/bitcoin/src/secp256k1)
configure:30586: running /bin/bash ./configure --disable-option-checking '--prefix=/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu'  '--with-gui=no' '--disable-tests' '--disable-gui-tests' '--enable-wallet' '--disable-shared' '--with-pic' '--enable-benchmark=no' '--with-bignum=no' '--enable-module-recovery' '--disable-jni' --cache-file=/dev/null --srcdir=.

## ---------------- ##
## Cache variables. ##
## ---------------- ##

ac_cv_build=x86_64-pc-linux-gnu
ac_cv_c_bigendian=no
ac_cv_c_compiler_gnu=yes
ac_cv_cxx_compiler_gnu=yes
ac_cv_env_ARFLAGS_set=
ac_cv_env_ARFLAGS_value=
ac_cv_env_BDB_CFLAGS_set=
ac_cv_env_BDB_CFLAGS_value=
ac_cv_env_BDB_LIBS_set=
ac_cv_env_BDB_LIBS_value=
ac_cv_env_CCC_set=
ac_cv_env_CCC_value=
ac_cv_env_CC_set=
ac_cv_env_CC_value=
ac_cv_env_CFLAGS_set=
ac_cv_env_CFLAGS_value=
ac_cv_env_CPPFLAGS_set=
ac_cv_env_CPPFLAGS_value=
ac_cv_env_CPP_set=
ac_cv_env_CPP_value=
ac_cv_env_CXXCPP_set=
ac_cv_env_CXXCPP_value=
ac_cv_env_CXXFLAGS_set=
ac_cv_env_CXXFLAGS_value=
ac_cv_env_CXX_set=
ac_cv_env_CXX_value=
ac_cv_env_EVENT_CFLAGS_set=
ac_cv_env_EVENT_CFLAGS_value=
ac_cv_env_EVENT_LIBS_set=
ac_cv_env_EVENT_LIBS_value=
ac_cv_env_EVENT_PTHREADS_CFLAGS_set=
ac_cv_env_EVENT_PTHREADS_CFLAGS_value=
ac_cv_env_EVENT_PTHREADS_LIBS_set=
ac_cv_env_EVENT_PTHREADS_LIBS_value=
ac_cv_env_LDFLAGS_set=
ac_cv_env_LDFLAGS_value=
ac_cv_env_LIBS_set=
ac_cv_env_LIBS_value=
ac_cv_env_LT_SYS_LIBRARY_PATH_set=
ac_cv_env_LT_SYS_LIBRARY_PATH_value=
ac_cv_env_OBJCXXFLAGS_set=
ac_cv_env_OBJCXXFLAGS_value=
ac_cv_env_OBJCXX_set=
ac_cv_env_OBJCXX_value=
ac_cv_env_PKG_CONFIG_LIBDIR_set=
ac_cv_env_PKG_CONFIG_LIBDIR_value=
ac_cv_env_PKG_CONFIG_PATH_set=
ac_cv_env_PKG_CONFIG_PATH_value=
ac_cv_env_PKG_CONFIG_set=
ac_cv_env_PKG_CONFIG_value=
ac_cv_env_PYTHONPATH_set=
ac_cv_env_PYTHONPATH_value=
ac_cv_env_QR_CFLAGS_set=
ac_cv_env_QR_CFLAGS_value=
ac_cv_env_QR_LIBS_set=
ac_cv_env_QR_LIBS_value=
ac_cv_env_QT5_CFLAGS_set=
ac_cv_env_QT5_CFLAGS_value=
ac_cv_env_QT5_LIBS_set=
ac_cv_env_QT5_LIBS_value=
ac_cv_env_QTACCESSIBILITY_CFLAGS_set=
ac_cv_env_QTACCESSIBILITY_CFLAGS_value=
ac_cv_env_QTACCESSIBILITY_LIBS_set=
ac_cv_env_QTACCESSIBILITY_LIBS_value=
ac_cv_env_QTCGL_CFLAGS_set=
ac_cv_env_QTCGL_CFLAGS_value=
ac_cv_env_QTCGL_LIBS_set=
ac_cv_env_QTCGL_LIBS_value=
ac_cv_env_QTCLIPBOARD_CFLAGS_set=
ac_cv_env_QTCLIPBOARD_CFLAGS_value=
ac_cv_env_QTCLIPBOARD_LIBS_set=
ac_cv_env_QTCLIPBOARD_LIBS_value=
ac_cv_env_QTDEVICEDISCOVERY_CFLAGS_set=
ac_cv_env_QTDEVICEDISCOVERY_CFLAGS_value=
ac_cv_env_QTDEVICEDISCOVERY_LIBS_set=
ac_cv_env_QTDEVICEDISCOVERY_LIBS_value=
ac_cv_env_QTEVENTDISPATCHER_CFLAGS_set=
ac_cv_env_QTEVENTDISPATCHER_CFLAGS_value=
ac_cv_env_QTEVENTDISPATCHER_LIBS_set=
ac_cv_env_QTEVENTDISPATCHER_LIBS_value=
ac_cv_env_QTFB_CFLAGS_set=
ac_cv_env_QTFB_CFLAGS_value=
ac_cv_env_QTFB_LIBS_set=
ac_cv_env_QTFB_LIBS_value=
ac_cv_env_QTFONTDATABASE_CFLAGS_set=
ac_cv_env_QTFONTDATABASE_CFLAGS_value=
ac_cv_env_QTFONTDATABASE_LIBS_set=
ac_cv_env_QTFONTDATABASE_LIBS_value=
ac_cv_env_QTGRAPHICS_CFLAGS_set=
ac_cv_env_QTGRAPHICS_CFLAGS_value=
ac_cv_env_QTGRAPHICS_LIBS_set=
ac_cv_env_QTGRAPHICS_LIBS_value=
ac_cv_env_QTPLATFORM_CFLAGS_set=
ac_cv_env_QTPLATFORM_CFLAGS_value=
ac_cv_env_QTPLATFORM_LIBS_set=
ac_cv_env_QTPLATFORM_LIBS_value=
ac_cv_env_QTTHEME_CFLAGS_set=
ac_cv_env_QTTHEME_CFLAGS_value=
ac_cv_env_QTTHEME_LIBS_set=
ac_cv_env_QTTHEME_LIBS_value=
ac_cv_env_QTXCBQPA_CFLAGS_set=
ac_cv_env_QTXCBQPA_CFLAGS_value=
ac_cv_env_QTXCBQPA_LIBS_set=
ac_cv_env_QTXCBQPA_LIBS_value=
ac_cv_env_QT_DBUS_CFLAGS_set=
ac_cv_env_QT_DBUS_CFLAGS_value=
ac_cv_env_QT_DBUS_LIBS_set=
ac_cv_env_QT_DBUS_LIBS_value=
ac_cv_env_QT_TEST_CFLAGS_set=
ac_cv_env_QT_TEST_CFLAGS_value=
ac_cv_env_QT_TEST_LIBS_set=
ac_cv_env_QT_TEST_LIBS_value=
ac_cv_env_UNIVALUE_CFLAGS_set=
ac_cv_env_UNIVALUE_CFLAGS_value=
ac_cv_env_UNIVALUE_LIBS_set=
ac_cv_env_UNIVALUE_LIBS_value=
ac_cv_env_ZMQ_CFLAGS_set=
ac_cv_env_ZMQ_CFLAGS_value=
ac_cv_env_ZMQ_LIBS_set=
ac_cv_env_ZMQ_LIBS_value=
ac_cv_env_build_alias_set=
ac_cv_env_build_alias_value=
ac_cv_env_host_alias_set=
ac_cv_env_host_alias_value=
ac_cv_env_target_alias_set=
ac_cv_env_target_alias_value=
ac_cv_func_strerror_r=yes
ac_cv_func_strerror_r_char_p=yes
ac_cv_have_decl___builtin_clz=yes
ac_cv_have_decl___builtin_clzl=yes
ac_cv_have_decl___builtin_clzll=yes
ac_cv_have_decl_be16toh=yes
ac_cv_have_decl_be32toh=yes
ac_cv_have_decl_be64toh=yes
ac_cv_have_decl_bswap_16=yes
ac_cv_have_decl_bswap_32=yes
ac_cv_have_decl_bswap_64=yes
ac_cv_have_decl_daemon=yes
ac_cv_have_decl_freeifaddrs=yes
ac_cv_have_decl_getifaddrs=yes
ac_cv_have_decl_htobe16=yes
ac_cv_have_decl_htobe32=yes
ac_cv_have_decl_htobe64=yes
ac_cv_have_decl_htole16=yes
ac_cv_have_decl_htole32=yes
ac_cv_have_decl_htole64=yes
ac_cv_have_decl_le16toh=yes
ac_cv_have_decl_le32toh=yes
ac_cv_have_decl_le64toh=yes
ac_cv_have_decl_strerror_r=yes
ac_cv_have_decl_strnlen=yes
ac_cv_header_byteswap_h=yes
ac_cv_header_dlfcn_h=yes
ac_cv_header_endian_h=yes
ac_cv_header_inttypes_h=yes
ac_cv_header_memory_h=yes
ac_cv_header_miniupnpc_miniupnpc_h=yes
ac_cv_header_miniupnpc_miniwget_h=yes
ac_cv_header_miniupnpc_upnpcommands_h=yes
ac_cv_header_miniupnpc_upnperrors_h=yes
ac_cv_header_stdc=yes
ac_cv_header_stdint_h=yes
ac_cv_header_stdio_h=yes
ac_cv_header_stdlib_h=yes
ac_cv_header_string_h=yes
ac_cv_header_strings_h=yes
ac_cv_header_sys_endian_h=no
ac_cv_header_sys_prctl_h=yes
ac_cv_header_sys_resources_h=no
ac_cv_header_sys_select_h=yes
ac_cv_header_sys_stat_h=yes
ac_cv_header_sys_sysctl_h=yes
ac_cv_header_sys_types_h=yes
ac_cv_header_sys_vmmeter_h=no
ac_cv_header_unistd_h=yes
ac_cv_header_vm_vm_param_h=no
ac_cv_host=x86_64-pc-linux-gnu
ac_cv_lib_boost_filesystem_mt_x64___exit=yes
ac_cv_lib_boost_system_mt_x64___exit=yes
ac_cv_lib_boost_thread_mt_x64___exit=yes
ac_cv_lib_db_cxx_4_8___main=yes
ac_cv_lib_miniupnpc_upnpDiscover=yes
ac_cv_objcxx_compiler_gnu=no
ac_cv_objext=o
ac_cv_path_EGREP='/bin/grep -E'
ac_cv_path_FGREP='/bin/grep -F'
ac_cv_path_GIT=/usr/bin/git
ac_cv_path_GREP=/bin/grep
ac_cv_path_HEXDUMP=/usr/bin/hexdump
ac_cv_path_PKG_CONFIG='/usr/bin/pkg-config --static'
ac_cv_path_PYTHON=/usr/bin/python3.5
ac_cv_path_SED=/bin/sed
ac_cv_path_ac_pt_AR=ar
ac_cv_path_ac_pt_CPPFILT=/usr/bin/c++filt
ac_cv_path_ac_pt_GCOV=/usr/bin/gcov
ac_cv_path_ac_pt_NM=nm
ac_cv_path_ac_pt_OBJCOPY=/usr/bin/objcopy
ac_cv_path_ac_pt_RANLIB=ranlib
ac_cv_path_ac_pt_READELF=/usr/bin/readelf
ac_cv_path_ac_pt_STRIP=/usr/bin/strip
ac_cv_path_install='/usr/bin/install -c'
ac_cv_path_lt_DD=/bin/dd
ac_cv_path_mkdir=/bin/mkdir
ac_cv_prog_AR=ar
ac_cv_prog_AWK=gawk
ac_cv_prog_CC='gcc -m64'
ac_cv_prog_CPP='gcc -m64 -E'
ac_cv_prog_CXXCPP='g++ -m64 -std=c++11 -E'
ac_cv_prog_OBJCXX='g++ -m64 -std=c++11'
ac_cv_prog_RANLIB=ranlib
ac_cv_prog_STRIP=strip
ac_cv_prog_ac_ct_MANIFEST_TOOL=mt
ac_cv_prog_ac_ct_OBJDUMP=objdump
ac_cv_prog_ac_ct_STRIP=strip
ac_cv_prog_cc_c89=
ac_cv_prog_cc_g=yes
ac_cv_prog_cxx_g=yes
ac_cv_prog_make_make_set=yes
ac_cv_prog_objcxx_g=no
ac_cv_search_clock_gettime='none required'
ac_cv_sys_file_offset_bits=no
ac_cv_sys_largefile_CC=no
am_cv_CC_dependencies_compiler_type=gcc3
am_cv_CXX_dependencies_compiler_type=gcc3
am_cv_OBJCXX_dependencies_compiler_type=gcc3
am_cv_make_support_nested_variables=yes
am_cv_prog_cc_c_o=yes
ax_cv_PTHREAD_CLANG=no
ax_cv_PTHREAD_JOINABLE_ATTR=PTHREAD_CREATE_JOINABLE
ax_cv_PTHREAD_PRIO_INHERIT=yes
ax_cv_PTHREAD_SPECIAL_FLAGS=no
ax_cv_boost_filesystem=yes
ax_cv_boost_system=yes
ax_cv_boost_thread=yes
ax_cv_check_cxxcppflags___D_FORTIFY_SOURCE_2=yes
ax_cv_check_cxxcppflags___U_FORTIFY_SOURCE=yes
ax_cv_check_cxxflags___Werror=yes
ax_cv_check_cxxflags___Wstack_protector=yes
ax_cv_check_cxxflags___fPIC=yes
ax_cv_check_cxxflags___fstack_protector_all=yes
ax_cv_check_cxxflags___fstack_reuse_none=yes
ax_cv_check_cxxflags__march_armv8_apcrcpcrypto=no
ax_cv_check_cxxflags__mavx__mavx2=yes
ax_cv_check_cxxflags__msse4_1=yes
ax_cv_check_cxxflags__msse4_2=yes
ax_cv_check_cxxflags__msse4__msha=yes
ax_cv_check_ldflags___Wl___dynamicbase=no
ax_cv_check_ldflags___Wl___high_entropy_va=no
ax_cv_check_ldflags___Wl___nxcompat=no
ax_cv_check_ldflags___Wl__z_now=yes
ax_cv_check_ldflags___Wl__z_relro=yes
ax_cv_check_ldflags__fPIE__pie=yes
ax_cv_cxx_compile_cxx11__std_cpp11=yes
ax_cv_have_func_attribute_dllexport=no
ax_cv_have_func_attribute_dllimport=no
ax_cv_have_func_attribute_visibility=yes
lt_cv_ar_at_file=@
lt_cv_archive_cmds_need_lc=no
lt_cv_deplibs_check_method=pass_all
lt_cv_file_magic_cmd='$MAGIC_CMD'
lt_cv_file_magic_test_file=
lt_cv_ld_reload_flag=-r
lt_cv_nm_interface='BSD nm'
lt_cv_objdir=.libs
lt_cv_path_LD=/usr/bin/ld
lt_cv_path_LDCXX='/usr/bin/ld -m elf_x86_64'
lt_cv_path_NM=nm
lt_cv_path_mainfest_tool=no
lt_cv_prog_compiler_c_o=yes
lt_cv_prog_compiler_c_o_CXX=yes
lt_cv_prog_compiler_pic='-fPIC -DPIC'
lt_cv_prog_compiler_pic_CXX='-fPIC -DPIC'
lt_cv_prog_compiler_pic_works=yes
lt_cv_prog_compiler_pic_works_CXX=yes
lt_cv_prog_compiler_rtti_exceptions=no
lt_cv_prog_compiler_static_works=yes
lt_cv_prog_compiler_static_works_CXX=yes
lt_cv_prog_gnu_ld=yes
lt_cv_prog_gnu_ldcxx=yes
lt_cv_sharedlib_from_linklib_cmd='printf %s\\n'
lt_cv_shlibpath_overrides_runpath=yes
lt_cv_sys_global_symbol_pipe='sed -n -e '\\''s/^.*[       ]\\([ABCDGIRSTW][ABCDGIRSTW]*\\)[         ][      ]*\\([_A-Za-z][_A-Za-z0-9]*\\)$/\\1 \\2 \\2/p'\\'' | sed '\\''/ __gnu_lto/d'\\'''
lt_cv_sys_global_symbol_to_c_name_address='sed -n -e '\\''s/^: \\(.*\\) .*$/  {""\\1"", (void *) 0},/p'\\'' -e '\\''s/^[ABCDGIRSTW][ABCDGIRSTW]* .* \\(.*\\)$/  {""\\1"", (void *) \\&\\1},/p'\\'''
lt_cv_sys_global_symbol_to_c_name_address_lib_prefix='sed -n -e '\\''s/^: \\(.*\\) .*$/  {""\\1"", (void *) 0},/p'\\'' -e '\\''s/^[ABCDGIRSTW][ABCDGIRSTW]* .* \\(lib.*\\)$/  {""\\1"", (void *) \\&\\1},/p'\\'' -e '\\''s/^[ABCDGIRSTW][ABCDGIRSTW]* .* \\(.*\\)$/  {""lib\\1"", (void *) \\&\\1},/p'\\'''
lt_cv_sys_global_symbol_to_cdecl='sed -n -e '\\''s/^T .* \\(.*\\)$/extern int \\1();/p'\\'' -e '\\''s/^[ABCDGIRSTW][ABCDGIRSTW]* .* \\(.*\\)$/extern char \\1;/p'\\'''
lt_cv_sys_global_symbol_to_import=
lt_cv_sys_max_cmd_len=1572864
lt_cv_to_host_file_cmd=func_convert_file_noop
lt_cv_to_tool_file_cmd=func_convert_file_noop
lt_cv_truncate_bin='/bin/dd bs=4096 count=1'
pkg_cv_EVENT_CFLAGS=-I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/include
pkg_cv_EVENT_LIBS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/lib -levent'
pkg_cv_EVENT_PTHREADS_CFLAGS='-pthread -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/include'
pkg_cv_EVENT_PTHREADS_LIBS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/lib -levent_pthreads -levent'
pkg_cv_ZMQ_CFLAGS=-I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/include
pkg_cv_ZMQ_LIBS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/lib -lzmq -lpthread -lrt'

## ----------------- ##
## Output variables. ##
## ----------------- ##

ACLOCAL='${SHELL} /home/dante/src/bitcoin/build-aux/missing aclocal-1.16'
AMDEPBACKSLASH='\\'
AMDEP_FALSE='#'
AMDEP_TRUE=''
AMTAR='$${TAR-tar}'
AM_BACKSLASH='\\'
AM_DEFAULT_V='$(AM_DEFAULT_VERBOSITY)'
AM_DEFAULT_VERBOSITY='0'
AM_V='$(V)'
AR='ar'
ARFLAGS='cr'
ARM_CRC_CXXFLAGS=''
AUTOCONF='${SHELL} /home/dante/src/bitcoin/build-aux/missing autoconf'
AUTOHEADER='${SHELL} /home/dante/src/bitcoin/build-aux/missing autoheader'
AUTOMAKE='${SHELL} /home/dante/src/bitcoin/build-aux/missing automake-1.16'
AVX2_CXXFLAGS='-mavx -mavx2'
AWK='gawk'
BDB_CFLAGS=''
BDB_CPPFLAGS=''
BDB_LIBS='-ldb_cxx-4.8'
BITCOIN_CLI_NAME='bitcoin-cli'
BITCOIN_DAEMON_NAME='bitcoind'
BITCOIN_GUI_NAME='bitcoin-qt'
BITCOIN_TX_NAME='bitcoin-tx'
BITCOIN_WALLET_TOOL_NAME='bitcoin-wallet'
BOOST_CPPFLAGS='-DBOOST_SP_USE_STD_ATOMIC -DBOOST_AC_USE_STD_ATOMIC -pthread -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include'
BOOST_FILESYSTEM_LIB='-lboost_filesystem-mt-x64'
BOOST_LDFLAGS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib'
BOOST_LIBS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib -lboost_system-mt-x64 -lboost_filesystem-mt-x64 -lboost_thread-mt-x64 -lpthread'
BOOST_SYSTEM_LIB='-lboost_system-mt-x64'
BOOST_THREAD_LIB='-lboost_thread-mt-x64 -lpthread'
BOOST_UNIT_TEST_FRAMEWORK_LIB=''
BREW=''
BUILD_BITCOIND_FALSE='#'
BUILD_BITCOIND_TRUE=''
BUILD_BITCOIN_CLI_FALSE='#'
BUILD_BITCOIN_CLI_TRUE=''
BUILD_BITCOIN_LIBS_FALSE='#'
BUILD_BITCOIN_LIBS_TRUE=''
BUILD_BITCOIN_TX_FALSE='#'
BUILD_BITCOIN_TX_TRUE=''
BUILD_BITCOIN_WALLET_FALSE='#'
BUILD_BITCOIN_WALLET_TRUE=''
BUILD_DARWIN_FALSE=''
BUILD_DARWIN_TRUE='#'
CC='gcc -m64'
CCACHE=''
CCDEPMODE='depmode=gcc3'
CFLAGS='-pipe -O2 '
CLIENT_VERSION_BUILD='0'
CLIENT_VERSION_IS_RELEASE='true'
CLIENT_VERSION_MAJOR='0'
CLIENT_VERSION_MINOR='20'
CLIENT_VERSION_REVISION='1'
COMPAT_LDFLAGS=''
COPYRIGHT_HOLDERS='The %s developers'
COPYRIGHT_HOLDERS_FINAL='The Bitcoin Core developers'
COPYRIGHT_HOLDERS_SUBSTITUTION='Bitcoin Core'
COPYRIGHT_YEAR='2020'
CPP='gcc -m64 -E'
CPPFILT='/usr/bin/c++filt'
CPPFLAGS='-I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../include/  -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS'
CXX='g++ -m64 -std=c++11'
CXXCPP='g++ -m64 -std=c++11 -E'
CXXDEPMODE='depmode=gcc3'
CXXFLAGS='-pipe -O2 '
CYGPATH_W='echo'
DEBUG_CPPFLAGS=''
DEBUG_CXXFLAGS=''
DEFS='-DHAVE_CONFIG_H'
DEPDIR='.deps'
DLLTOOL='false'
DOXYGEN=''
DSYMUTIL=''
DUMPBIN=''
ECHO_C=''
ECHO_N='-n'
ECHO_T=''
EGREP='/bin/grep -E'
EMBEDDED_LEVELDB_FALSE='#'
EMBEDDED_LEVELDB_TRUE=''
EMBEDDED_UNIVALUE_FALSE='#'
EMBEDDED_UNIVALUE_TRUE=''
ENABLE_ARM_CRC_FALSE=''
ENABLE_ARM_CRC_TRUE='#'
ENABLE_AVX2_FALSE='#'
ENABLE_AVX2_TRUE=''
ENABLE_BENCH_FALSE='#'
ENABLE_BENCH_TRUE=''
ENABLE_FUZZ_FALSE=''
ENABLE_FUZZ_TRUE='#'
ENABLE_MAN_FALSE='#'
ENABLE_MAN_TRUE=''
ENABLE_QT_FALSE=''
ENABLE_QT_TESTS_FALSE=''
ENABLE_QT_TESTS_TRUE='#'
ENABLE_QT_TRUE='#'
ENABLE_SHANI_FALSE='#'
ENABLE_SHANI_TRUE=''
ENABLE_SSE41_FALSE='#'
ENABLE_SSE41_TRUE=''
ENABLE_SSE42_FALSE='#'
ENABLE_SSE42_TRUE=''
ENABLE_TESTS_FALSE=''
ENABLE_TESTS_TRUE='#'
ENABLE_WALLET_FALSE='#'
ENABLE_WALLET_TRUE=''
ENABLE_ZMQ_FALSE='#'
ENABLE_ZMQ_TRUE=''
ERROR_CXXFLAGS=''
EVENT_CFLAGS='-I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/include'
EVENT_LIBS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/lib -levent'
EVENT_PTHREADS_CFLAGS='-pthread -I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/include'
EVENT_PTHREADS_LIBS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/lib -levent_pthreads -levent'
EXEEXT=''
EXTENDED_FUNCTIONAL_TESTS=''
FGREP='/bin/grep -F'
GCOV='/usr/bin/gcov'
GENHTML=''
GENISOIMAGE=''
GIT='/usr/bin/git'
GLIBC_BACK_COMPAT_FALSE=''
GLIBC_BACK_COMPAT_TRUE='#'
GPROF_CXXFLAGS=''
GPROF_LDFLAGS=''
GREP='/bin/grep'
HARDENED_CPPFLAGS=' -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=2'
HARDENED_CXXFLAGS=' -fstack-reuse=none -Wstack-protector -fstack-protector-all'
HARDENED_LDFLAGS=' -Wl,-z,relro -Wl,-z,now -pie'
HARDEN_FALSE='#'
HARDEN_TRUE=''
HAVE_BUILTIN_PREFETCH='1'
HAVE_CXX11='1'
HAVE_DOXYGEN_FALSE=''
HAVE_DOXYGEN_TRUE='#'
HAVE_FDATASYNC='1'
HAVE_FULLFSYNC='0'
HAVE_GMTIME_R=''
HAVE_MM_PREFETCH='1'
HAVE_O_CLOEXEC='1'
HAVE_STRONG_GETAUXVAL='0'
HAVE_WEAK_GETAUXVAL='1'
HEXDUMP='/usr/bin/hexdump'
IMAGEMAGICK_CONVERT=''
INSTALLNAMETOOL=''
INSTALL_DATA='${INSTALL} -m 644'
INSTALL_PROGRAM='${INSTALL}'
INSTALL_SCRIPT='${INSTALL}'
INSTALL_STRIP_PROGRAM='$(install_sh) -c -s'
LCOV=''
LCOV_OPTS=''
LD='/usr/bin/ld -m elf_x86_64'
LDFLAGS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib '
LEVELDB_CPPFLAGS=''
LIBLEVELDB=''
LIBMEMENV=''
LIBOBJS=''
LIBS=''
LIBTOOL='$(SHELL) $(top_builddir)/libtool'
LIBTOOL_APP_LDFLAGS=''
LIPO=''
LN_S='ln -s'
LRELEASE=''
LTLIBOBJS=''
LT_SYS_LIBRARY_PATH=''
LUPDATE=''
MAINT=''
MAINTAINER_MODE_FALSE='#'
MAINTAINER_MODE_TRUE=''
MAKEINFO='${SHELL} /home/dante/src/bitcoin/build-aux/missing makeinfo'
MAKENSIS=''
MANIFEST_TOOL=':'
MINIUPNPC_CPPFLAGS=''
MINIUPNPC_LIBS='-lminiupnpc'
MKDIR_P='/bin/mkdir -p'
MOC=''
MOC_DEFS='-DHAVE_CONFIG_H -I$(srcdir)'
NM='nm'
NMEDIT=''
NOWARN_CXXFLAGS=''
OBJCOPY='/usr/bin/objcopy'
OBJCXX='g++ -m64 -std=c++11'
OBJCXXDEPMODE='depmode=gcc3'
OBJCXXFLAGS=''
OBJDUMP='objdump'
OBJEXT='o'
OTOOL64=''
OTOOL=''
PACKAGE='bitcoin'
PACKAGE_BUGREPORT='https://github.com/bitcoin/bitcoin/issues'
PACKAGE_NAME='Bitcoin Core'
PACKAGE_STRING='Bitcoin Core 0.20.1'
PACKAGE_TARNAME='bitcoin'
PACKAGE_URL='https://bitcoincore.org/'
PACKAGE_VERSION='0.20.1'
PATH_SEPARATOR=':'
PIC_FLAGS='-fPIC'
PIE_FLAGS='-fPIE'
PKG_CONFIG='/usr/bin/pkg-config --static'
PKG_CONFIG_LIBDIR='/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib/pkgconfig'
PKG_CONFIG_PATH='/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../share/pkgconfig:/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../lib/pkgconfig'
PTHREAD_CC='gcc -m64'
PTHREAD_CFLAGS='-pthread'
PTHREAD_LIBS=''
PYTHON='/usr/bin/python3.5'
PYTHONPATH='/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../native/lib/python3/dist-packages:'
QR_CFLAGS=''
QR_LIBS=''
QT5_CFLAGS=''
QT5_LIBS=''
QTACCESSIBILITY_CFLAGS=''
QTACCESSIBILITY_LIBS=''
QTCGL_CFLAGS=''
QTCGL_LIBS=''
QTCLIPBOARD_CFLAGS=''
QTCLIPBOARD_LIBS=''
QTDEVICEDISCOVERY_CFLAGS=''
QTDEVICEDISCOVERY_LIBS=''
QTEVENTDISPATCHER_CFLAGS=''
QTEVENTDISPATCHER_LIBS=''
QTFB_CFLAGS=''
QTFB_LIBS=''
QTFONTDATABASE_CFLAGS=''
QTFONTDATABASE_LIBS=''
QTGRAPHICS_CFLAGS=''
QTGRAPHICS_LIBS=''
QTPLATFORM_CFLAGS=''
QTPLATFORM_LIBS=''
QTTHEME_CFLAGS=''
QTTHEME_LIBS=''
QTXCBQPA_CFLAGS=''
QTXCBQPA_LIBS=''
QT_DBUS_CFLAGS=''
QT_DBUS_INCLUDES=''
QT_DBUS_LIBS=''
QT_INCLUDES=''
QT_LDFLAGS=''
QT_LIBS=''
QT_PIE_FLAGS=''
QT_SELECT='qt5'
QT_TEST_CFLAGS=''
QT_TEST_INCLUDES=''
QT_TEST_LIBS=''
QT_TRANSLATION_DIR='/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/share/../translations'
RANLIB='ranlib'
RCC=''
READELF='/usr/bin/readelf'
RELDFLAGS=''
RSVG_CONVERT=''
SANITIZER_CXXFLAGS=''
SANITIZER_LDFLAGS=''
SED='/bin/sed'
SET_MAKE=''
SHANI_CXXFLAGS='-msse4 -msha'
SHELL='/bin/bash'
SSE41_CXXFLAGS='-msse4.1'
SSE42_CXXFLAGS='-msse4.2'
STRIP='/usr/bin/strip'
TARGET_DARWIN_FALSE=''
TARGET_DARWIN_TRUE='#'
TARGET_WINDOWS_FALSE=''
TARGET_WINDOWS_TRUE='#'
TESTDEFS=''
TIFFCP=''
UIC=''
UNIVALUE_CFLAGS='-I$(srcdir)/univalue/include'
UNIVALUE_LIBS='univalue/libunivalue.la'
USE_ASM_FALSE='#'
USE_ASM_TRUE=''
USE_LCOV_FALSE=''
USE_LCOV_TRUE='#'
USE_QRCODE=''
USE_QRCODE_FALSE=''
USE_QRCODE_TRUE='#'
USE_UPNP=''
VERSION='0.20.1'
WARN_CXXFLAGS=''
WINDRES=''
WORDS_BIGENDIAN_FALSE=''
WORDS_BIGENDIAN_TRUE='#'
XGETTEXT=''
ZMQ_CFLAGS='-I/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/include'
ZMQ_LIBS='-L/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu/lib -lzmq -lpthread -lrt'
ac_ct_AR=''
ac_ct_CC=''
ac_ct_CXX=''
ac_ct_DUMPBIN=''
ac_ct_OBJCXX=''
am__EXEEXT_FALSE=''
am__EXEEXT_TRUE='#'
am__fastdepCC_FALSE='#'
am__fastdepCC_TRUE=''
am__fastdepCXX_FALSE='#'
am__fastdepCXX_TRUE=''
am__fastdepOBJCXX_FALSE='#'
am__fastdepOBJCXX_TRUE=''
am__include='include'
am__isrc=''
am__leading_dot='.'
am__nodep='_no'
am__quote=''
am__tar='$${TAR-tar} chof - ""$$tardir""'
am__untar='$${TAR-tar} xf -'
ax_pthread_config=''
bindir='${exec_prefix}/bin'
build='x86_64-pc-linux-gnu'
build_alias=''
build_cpu='x86_64'
build_os='linux-gnu'
build_vendor='pc'
datadir='${datarootdir}'
datarootdir='${prefix}/share'
docdir='${datarootdir}/doc/${PACKAGE_TARNAME}'
dvidir='${docdir}'
exec_prefix='${prefix}'
host='x86_64-pc-linux-gnu'
host_alias='x86_64-pc-linux-gnu'
host_cpu='x86_64'
host_os='linux-gnu'
host_vendor='pc'
htmldir='${docdir}'
includedir='${prefix}/include'
infodir='${datarootdir}/info'
install_sh='${SHELL} /home/dante/src/bitcoin/build-aux/install-sh'
libdir='${exec_prefix}/lib'
libexecdir='${exec_prefix}/libexec'
localedir='${datarootdir}/locale'
localstatedir='${prefix}/var'
mandir='${datarootdir}/man'
mkdir_p='$(MKDIR_P)'
oldincludedir='/usr/include'
pdfdir='${docdir}'
prefix='/home/dante/src/bitcoin/depends/x86_64-pc-linux-gnu'
program_transform_name='s,x,x,'
psdir='${docdir}'
runstatedir='${localstatedir}/run'
sbindir='${exec_prefix}/sbin'
sharedstatedir='${prefix}/com'
subdirs=' src/univalue src/secp256k1'
sysconfdir='${prefix}/etc'
target_alias=''

## ----------- ##
## confdefs.h. ##
## ----------- ##

/* confdefs.h */
#define PACKAGE_NAME ""Bitcoin Core""
#define PACKAGE_TARNAME ""bitcoin""
#define PACKAGE_VERSION ""0.20.1""
#define PACKAGE_STRING ""Bitcoin Core 0.20.1""
#define PACKAGE_BUGREPORT ""https://github.com/bitcoin/bitcoin/issues""
#define PACKAGE_URL ""https://bitcoincore.org/""
#define HAVE_CXX11 1
#define STDC_HEADERS 1
#define HAVE_SYS_TYPES_H 1
#define HAVE_SYS_STAT_H 1
#define HAVE_STDLIB_H 1
#define HAVE_STRING_H 1
#define HAVE_MEMORY_H 1
#define HAVE_STRINGS_H 1
#define HAVE_INTTYPES_H 1
#define HAVE_STDINT_H 1
#define HAVE_UNISTD_H 1
#define HAVE_DLFCN_H 1
#define LT_OBJDIR "".libs/""
#define USE_ASM 1
#define ENABLE_SSE41 1
#define ENABLE_AVX2 1
#define ENABLE_SHANI 1
#define HAVE_PTHREAD_PRIO_INHERIT 1
#define HAVE_PTHREAD 1
#define HAVE_DECL_STRERROR_R 1
#define HAVE_STRERROR_R 1
#define STRERROR_R_CHAR_P 1
#define HAVE_FUNC_ATTRIBUTE_VISIBILITY 1
#define HAVE_ENDIAN_H 1
#define HAVE_BYTESWAP_H 1
#define HAVE_STDIO_H 1
#define HAVE_STDLIB_H 1
#define HAVE_UNISTD_H 1
#define HAVE_STRINGS_H 1
#define HAVE_SYS_TYPES_H 1
#define HAVE_SYS_STAT_H 1
#define HAVE_SYS_SELECT_H 1
#define HAVE_SYS_PRCTL_H 1
#define HAVE_SYS_SYSCTL_H 1
#define HAVE_DECL_GETIFADDRS 1
#define HAVE_DECL_FREEIFADDRS 1
#define HAVE_DECL_STRNLEN 1
#define HAVE_DECL_DAEMON 1
#define HAVE_DECL_LE16TOH 1
#define HAVE_DECL_LE32TOH 1
#define HAVE_DECL_LE64TOH 1
#define HAVE_DECL_HTOLE16 1
#define HAVE_DECL_HTOLE32 1
#define HAVE_DECL_HTOLE64 1
#define HAVE_DECL_BE16TOH 1
#define HAVE_DECL_BE32TOH 1
#define HAVE_DECL_BE64TOH 1
#define HAVE_DECL_HTOBE16 1
#define HAVE_DECL_HTOBE32 1
#define HAVE_DECL_HTOBE64 1
#define HAVE_DECL_BSWAP_16 1
#define HAVE_DECL_BSWAP_32 1
#define HAVE_DECL_BSWAP_64 1
#define HAVE_DECL___BUILTIN_CLZ 1
#define HAVE_DECL___BUILTIN_CLZL 1
#define HAVE_DECL___BUILTIN_CLZLL 1
#define HAVE_MALLOC_INFO 1
#define HAVE_MALLOPT_ARENA_MAX 1
#define HAVE_VISIBILITY_ATTRIBUTE 1
#define HAVE_THREAD_LOCAL 1
#define HAVE_GMTIME_R 1
#define HAVE_SYS_GETRANDOM 1
#define HAVE_GETENTROPY 1
#define HAVE_GETENTROPY_RAND 1
#define HAVE_STD__SYSTEM 1
#define HAVE_SYSTEM HAVE_STD__SYSTEM || HAVE_WSYSTEM
#define HAVE_MINIUPNPC_MINIWGET_H 1
#define HAVE_MINIUPNPC_MINIUPNPC_H 1
#define HAVE_MINIUPNPC_UPNPCOMMANDS_H 1
#define HAVE_MINIUPNPC_UPNPERRORS_H 1
#define HAVE_BOOST /**/
#define HAVE_BOOST_SYSTEM /**/
#define HAVE_BOOST_FILESYSTEM /**/
#define HAVE_BOOST_THREAD /**/
#define ENABLE_ZMQ 1
#define HAVE_CONSENSUS_LIB 1
#define ENABLE_WALLET 1
#define USE_UPNP 0
#define CLIENT_VERSION_MAJOR 0
#define CLIENT_VERSION_MINOR 20
#define CLIENT_VERSION_REVISION 1
#define CLIENT_VERSION_BUILD 0
#define CLIENT_VERSION_IS_RELEASE true
#define COPYRIGHT_YEAR 2020
#define COPYRIGHT_HOLDERS ""The %s developers""
#define COPYRIGHT_HOLDERS_SUBSTITUTION ""Bitcoin Core""
#define COPYRIGHT_HOLDERS_FINAL ""The Bitcoin Core developers""

configure: exit 0
```

</details>"
bitcoin/bitcoin,2020-07-31 07:56:39,question,freebsd 12.1 build broken,"` ./configure --with-gui=no --disable-tests --disable-wallet MAKE=gmake`

`  CXXLD    bench/bench_bitcoin
/usr/local/bin/ld: libbitcoin_util.a(libbitcoin_util_a-system.o): in function `SetupEnvironment()':
/opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1103: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
/usr/local/bin/ld: /opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1105: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
collect2: error: ld returned 1 exit status
gmake[2]: *** [Makefile:7354: bitcoin-tx] Error 1
gmake[2]: *** Waiting for unfinished jobs....
/usr/local/bin/ld: libbitcoin_util.a(libbitcoin_util_a-system.o): in function `SetupEnvironment()':
/opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1103: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
/usr/local/bin/ld: /opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1105: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
collect2: error: ld returned 1 exit status
gmake[2]: *** [Makefile:7350: bitcoin-cli] Error 1
/usr/local/bin/ld: libbitcoin_util.a(libbitcoin_util_a-system.o): in function `SetupEnvironment()':
/opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1103: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
/usr/local/bin/ld: /opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1105: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
collect2: error: ld returned 1 exit status
gmake[2]: *** [Makefile:7362: bitcoind] Error 1
/usr/local/bin/ld: libbitcoin_util.a(libbitcoin_util_a-system.o): in function `SetupEnvironment()':
/opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1103: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
/usr/local/bin/ld: /opt/bitcoin/bitcoin-0.20.0/src/util/system.cpp:1105: undefined reference to `boost::filesystem::path::imbue(std::locale const&)'
collect2: error: ld returned 1 exit status
gmake[2]: *** [Makefile:7346: bench/bench_bitcoin] Error 1
gmake[2]: Leaving directory '/opt/bitcoin/bitcoin-0.20.0/src'
gmake[1]: *** [Makefile:17262: all-recursive] Error 1
gmake[1]: Leaving directory '/opt/bitcoin/bitcoin-0.20.0/src'
gmake: *** [Makefile:780: all-recursive] Error 1
`"
bitcoin/bitcoin,2020-05-31 13:10:08,question,How to reproduce -Werror=sign-compare failures locally?,"I tried gcc and clang, but those failures won't show for me. See https://github.com/bitcoin/bitcoin/pull/18637#issuecomment-636468355

While I like the warning and error, if developers can't see them on their boxes, it makes it tedious to fix those issues up."
bitcoin/bitcoin,2020-04-30 17:20:16,question,GetMedianTimePast: Can it be optimized with a simple index - 5?,"I was working on an blockchain indexer and explorer, and as I was trying to figure out how to calculate the returned ""medianTime"" from the ""getblockchaininfo"", I realized that the value is not what I was expecting it to be.

This was in an C# implementation of similar code to Bitcoin, so I initially thought it was a bug in the .NET implementation. Then I had a look at the C++ implementation and to me it appears to be the same.

```
    static constexpr int nMedianTimeSpan = 11;

    int64_t GetMedianTimePast() const
    {
        int64_t pmedian[nMedianTimeSpan];
        int64_t* pbegin = &pmedian[nMedianTimeSpan];
        int64_t* pend = &pmedian[nMedianTimeSpan];

        const CBlockIndex* pindex = this;
        for (int i = 0; i < nMedianTimeSpan && pindex; i++, pindex = pindex->pprev)
            *(--pbegin) = pindex->GetBlockTime();

        std::sort(pbegin, pend);
        return pbegin[(pend - pbegin)/2];
    }
```

From what I can understand, the method loops backwards through the blocks from the current block, populates the block time into an array, sort it (it's already sorted), then picks the middle one (5) and returns that.

Is that correctly assumed?

Wouldn't simply selecting index - 5 do the exact same thing? Of course one would need to calculate for genesis and the first 10 blocks, but that's easy.

I was expecting this method to do something else, namely take the diff time (not the timestamp) between each block, then picking the middle one, which would give the average time between each block for the last 10 blocks. Another quick way to calculate, would be take GetBlockTime from the block 10 indexes back, diff with current block and divide by 10, should give one type of average.

The current code populates an array of 10 timestamps, but it only picks the one in the middle. There is no reason to populate it with 10 timestamps, as the 5 oldest are not used for anything. It also doesn't use or calculate/care about any of the other blocks.

So if the last 5 blocks took:

1 hour
10 minutes
10 minutes
10 minutes
10 minutes
10 minutes
10 minutes
10 minutes
10 minutes
10 minutes

Then GetMedianTimePast will return a timestamp 1 hour and 40 minutes back in time from current block. I understand median is correct name for the method (it returns the middle of the sorted numbers), but is the numbers to be sorted suppose to be time between blocks (datediff) and not the actual timestamps?

The ""medianTime"" returned is also not the time between blocks, it is the time 5 blocks back. Which is why I'm wondering why not simply grab the datetime of the block 5 indexes back instead?

For for me to show the median time between blocks in the block explorer, I must take (BlockTime - MedianTime / 5). From what I know, I think the calculate is used for consensus/mining, and not suppose to be what I'm after (average block time), I can calculate that another way, but I stumbled upon this and initially thought it to be something else, and thought it could maybe be improved a bit?

Is that the way it is suppose to work, or am I not able to read the code properly? Thanks!"
bitcoin/bitcoin,2020-02-05 13:04:42,question,running full profiler,"How can I run a profiler to get the timings on each function of the overall executable? Looking to find out which functions are running slow, and to look more into them. "
bitcoin/bitcoin,2020-01-10 15:06:27,question,BIP 152 status,"I'm not sure where to put this issue, anyway reading BIP 152, that's active in the protocol, I see it has a Status reported as Draft.

For someone like me that's trying to implement the protocol following the specification, it's already difficult to dodge the official dev documentation `https://en.bitcoin.it/wiki/Protocol_documentation` with its dated (and even wrong) informations and reading BIPS it's not clear if a BIP is included or not for sure in a protocol without checking the code.

I'd expect official BIPs having at least a correct Status reported, but as just said, BIP 152 is reported as Draft that sounds confusing (and probably wrong)
![image](https://user-images.githubusercontent.com/5107375/72162886-085a5b00-33c3-11ea-99a0-985bf6a23a79.png)

As a side note, what's the most updated reference (not mentioning ""the code"") currently available?
Thanks"
bitcoin/bitcoin,2019-12-04 00:12:56,question,OSX Mojave (10.14.6) build fails compiling univalue,"Git pull origin - go in to ./src/univalue

./autogen.sh
./configure
make

make clean and two different coins attempted with same results.
OSX 10.14.6 (Mojave)

Please advise if this is incompatibility or if I'm missing something :)

gcc -v
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1
Apple clang version 11.0.0 (clang-1100.0.33.12)
Target: x86_64-apple-darwin18.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

Full output:
./autogen.sh
glibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'build-aux'.
glibtoolize: copying file 'build-aux/ltmain.sh'
glibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'build-aux/m4'.
glibtoolize: copying file 'build-aux/m4/libtool.m4'
glibtoolize: copying file 'build-aux/m4/ltoptions.m4'
glibtoolize: copying file 'build-aux/m4/ltsugar.m4'
glibtoolize: copying file 'build-aux/m4/ltversion.m4'
glibtoolize: copying file 'build-aux/m4/lt~obsolete.m4'

./configure
configure.ac:45: installing 'build-aux/compile'
configure.ac:45: installing 'build-aux/config.guess'
configure.ac:45: installing 'build-aux/config.sub'
configure.ac:28: installing 'build-aux/install-sh'
configure.ac:28: installing 'build-aux/missing'
Makefile.am: installing 'build-aux/depcomp'
parallel-tests: installing 'build-aux/test-driver'
machecking whether make supports nested variables... yes
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
kchecking for a thread-safe mkdir -p... build-aux/install-sh -c -d
checking for gawk... no
checking for mawk... no
checking for nawk... no
checking for awk... awk
checking whether make sets $(MAKE)... yes
echecking build system type...
x86_64-apple-darwin18.7.0
checking host system type... x86_64-apple-darwin18.7.0
checking how to print strings... printf
checking whether make supports the include directive... yes (GNU style)
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking whether gcc understands -c and -o together... yes
checking dependency style of gcc... gcc3
checking for a sed that does not truncate output... /usr/bin/sed
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for fgrep... /usr/bin/grep -F
checking for ld used by gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld
checking if the linker (/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld) is GNU ld... no
checking for BSD- or MS-compatible name lister (nm)... /usr/local/bin/nm -B
checking the name lister (/usr/local/bin/nm -B) interface... BSD nm
checking whether ln -s works... yes
checking the maximum length of command line arguments... 196608
checking how to convert x86_64-apple-darwin18.7.0 file names to x86_64-apple-darwin18.7.0 format... func_convert_file_noop
checking how to convert x86_64-apple-darwin18.7.0 file names to toolchain format... func_convert_file_noop
checking for /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... dlltool
checking how to associate runtime and link libraries... printf %s\\n
checking for ar... ar
checking for archiver @FILE support... @
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/local/bin/nm -B output from gcc object... ok
checking for sysroot... no
checking for a working dd... /bin/dd
checking how to truncate binary pipes... /bin/dd bs=4096 count=1
checking for mt... no
checking if : is a manifest tool... no
checking for dsymutil... dsymutil
checking for nmedit... nmedit
checking for lipo... lipo
checking for otool... otool
checking for otool64... no
checking for -single_module linker flag... yes
checking for -exported_symbols_list linker flag... yes
checking for -force_load linker flag... no
checking how to run the C preprocessor... gcc -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking for dlfcn.h... yes
checking for objdir... .libs
checking if gcc supports -fno-rtti -fno-exceptions... yes
checking for gcc option to produce PIC... -fno-common -DPIC
checking if gcc PIC flag -fno-common -DPIC works... yes
checking if gcc static flag -static works... no
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld) supports shared libraries... yes
checking dynamic linker characteristics... darwin18.7.0 dyld
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking dependency style of g++... gcc3
checking how to run the C++ preprocessor... g++ -E
checking for ld used by g++... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld
checking if the linker (/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld) is GNU ld... no
checking whether the g++ linker (/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld) supports shared libraries... yes
checking for g++ option to produce PIC... -fno-common -DPIC
checking if g++ PIC flag -fno-common -DPIC works... yes
checking if g++ static flag -static works... no
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ld) supports shared libraries... yes
checking dynamic linker characteristics... darwin18.7.0 dyld
checking how to hardcode library paths into programs... immediate
checking that generated files are newer than configure... done
configure: creating ./config.status
config.status: creating Makefile
config.status: creating pc/libunivalue.pc
config.status: creating pc/libunivalue-uninstalled.pc
config.status: creating univalue-config.h
config.status: executing depfiles commands
config.status: executing libtool commands

make
/Applications/Xcode.app/Contents/Developer/usr/bin/make  all-am
  CXX      test/object-object.o
  CXX      lib/libunivalue_la-univalue.lo
  CXX      lib/libunivalue_la-univalue_get.lo
  CXX      lib/libunivalue_la-univalue_read.lo
  CXX      lib/libunivalue_la-univalue_write.lo
  CXXLD    libunivalue.la
ar: `u' modifier ignored since `D' is the default (see `U')
  CXXLD    test/object
**ld: warning: ignoring file ./.libs/libunivalue.a, building for macOS-x86_64 but attempting to link with file built for unknown-unsupported file format ( 0x21 0x3C 0x61 0x72 0x63 0x68 0x3E 0x0A 0x2F 0x20 0x20 0x20 0x20 0x20 0x20 0x20 )
Undefined symbols for architecture x86_64:**
  ""UniValue::push_backV(std::__1::vector<UniValue, std::__1::allocator<UniValue> > const&)"", referenced from:
      univalue_array() in object-object.o
  ""UniValue::read(char const*, unsigned long)"", referenced from:
      univalue_typecheck() in object-object.o
      univalue_readwrite() in object-object.o
  ""UniValue::clear()"", referenced from:
      univalue_set() in object-object.o
      univalue_array() in object-object.o
      univalue_object() in object-object.o
  ""UniValue::pushKV(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, UniValue const&)"", referenced from:
      univalue_object() in object-object.o
      UniValue::pushKV(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, char const*) in object-object.o
  ""UniValue::setInt(long long)"", referenced from:
      univalue_set() in object-object.o
      univalue_object() in object-object.o
      UniValue::UniValue(long long) in object-object.o
      UniValue::UniValue(int) in object-object.o
  ""UniValue::setInt(unsigned long long)"", referenced from:
      univalue_set() in object-object.o
      UniValue::UniValue(unsigned long long) in object-object.o
  ""UniValue::setStr(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:
      univalue_set() in object-object.o
      univalue_array() in object-object.o
      UniValue::UniValue(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in object-object.o
      UniValue::UniValue(char const*) in object-object.o
  ""UniValue::pushKVs(UniValue const&)"", referenced from:
      univalue_object() in object-object.o
  ""UniValue::setBool(bool)"", referenced from:
      univalue_typecheck() in object-object.o
      univalue_set() in object-object.o
      UniValue::UniValue(bool) in object-object.o
  ""UniValue::setNull()"", referenced from:
      univalue_set() in object-object.o
  ""UniValue::__pushKV(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, UniValue const&)"", referenced from:
      univalue_object() in object-object.o
  ""UniValue::setArray()"", referenced from:
      univalue_set() in object-object.o
  ""UniValue::setFloat(double)"", referenced from:
      univalue_set() in object-object.o
      UniValue::UniValue(double) in object-object.o
  ""UniValue::push_back(UniValue const&)"", referenced from:
      univalue_array() in object-object.o
      UniValue::push_back(char const*) in object-object.o
  ""UniValue::setNumStr(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:
      univalue_constructor() in object-object.o
      univalue_typecheck() in object-object.o
      univalue_set() in object-object.o
  ""UniValue::setObject()"", referenced from:
      univalue_set() in object-object.o
      univalue_object() in object-object.o
  ""UniValue::checkObject(std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, UniValue::VType, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, UniValue::VType> > > const&) const"", referenced from:
      univalue_object() in object-object.o
  ""UniValue::write(unsigned int, unsigned int) const"", referenced from:
      univalue_readwrite() in object-object.o
  ""UniValue::findKey(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned long&) const"", referenced from:
      univalue_object() in object-object.o
  ""UniValue::getKeys() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::get_int() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::get_obj() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::get_str() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::get_bool() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::get_real() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::getObjMap(std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, UniValue, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, UniValue> > >&) const"", referenced from:
      univalue_object() in object-object.o
  ""UniValue::getValues() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::get_array() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::get_int64() const"", referenced from:
      univalue_typecheck() in object-object.o
  ""UniValue::operator[](std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const"", referenced from:
      univalue_object() in object-object.o
      univalue_readwrite() in object-object.o
  ""UniValue::operator[](unsigned long) const"", referenced from:
      univalue_array() in object-object.o
      univalue_readwrite() in object-object.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[1]: *** [test/object] Error 1
make: *** [all] Error 2"
bitcoin/bitcoin,2019-11-27 16:51:45,question,"[Question] Compiling only bitcoind, not others.","[Question]

Hi :) I'm working on bitcoind to write something to test locally.

When I type ```make``` In the working directory(top directory), the compile process(code) which is written in Makefile is very long time because others are compiled with.

So this is time-consuming in my current work. **I'd like to compile only bitcoind !**.

Can I get some guide? Thanks.
"
bitcoin/bitcoin,2019-11-11 16:56:50,question,Unable to start bitcoind after power failure,"Hi,

I'm unable to restart bitcoind after a power failure: 

Here is the debug.log error I am getting:

> bitcoin@raspberrypi:~ $ tail -f /home/bitcoin/.bitcoin/debug.log 
> 2019-11-11T16:49:54Z Opening LevelDB in /home/bitcoin/.bitcoin/chainstate
> 2019-11-11T16:49:54Z Fatal LevelDB error: Corruption: CURRENT file does not end with newline
> 2019-11-11T16:49:54Z You can use -debug=leveldb to get more complete diagnostic messages
> 2019-11-11T16:49:54Z Fatal LevelDB error: Corruption: CURRENT file does not end with newline
> 2019-11-11T16:49:54Z : Error opening block database.
> Please restart with -reindex or -reindex-chainstate to recover.
> 2019-11-11T16:49:54Z Aborted block database rebuild. Exiting.
> 2019-11-11T16:49:54Z Shutdown: In progress...
> 2019-11-11T16:49:54Z scheduler thread interrupt
> 2019-11-11T16:49:54Z Shutdown: done

I've tried running:

```
bitcoind -reindex 
bitcoin -reindex-chainstate
```

Not sure what I am doing wrong? "
bitcoin/bitcoin,2019-11-01 12:00:30,question,Missing entry to install ,"Bitcoin setup is not successfull on a clean ubuntu system following the install instructions https://github.com/bitcoin/bitcoin/blob/master/doc/build-unix.md

**Expected behavior**

I would expect that installation to complete and that my setup is able to build bitcoin

**Actual behavior**

Apparently `./configure` gave this error: ""configure: error: libdb_cxx headers missing, Bitcoin Core requires this library for wallet functionality (--disable-wallet to disable wallet functionality)"". next `make` does not work 

```
make
make: *** No targets specified and no makefile found.  Stop.
**System information**
```

**To reproduce**


<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
The bitcoin version this happens is b54666c849bad258d92d6d1e45a051d36055681e

**Fix **
there are many solutions specified in  https://github.com/bitcoin/bitcoin/issues/2998 but for me the woking one was the comment https://github.com/bitcoin/bitcoin/issues/2998#issuecomment-356455033 from @bellaj 

```  
sudo add-apt-repository ppa:bitcoin/bitcoin
sudo apt-get update
sudo apt-get install libdb4.8-dev libdb4.8++-dev
```

So I guess this could be added to the ubuntu section of https://github.com/bitcoin/bitcoin/blob/master/doc/build-unix.md  ?"
bitcoin/bitcoin,2019-10-26 09:22:58,question,wallet: decodepsbt & decoderawtransaction should show RBF status,"The `decodepsbt` and `decoderawtransaction` RPC calls return the `sequence` for each input, but I'd rather not have to manually determine if that implies RBF.

I mainly care about this for mempool transactions.

cc @instagibbs @achow101 "
bitcoin/bitcoin,2019-10-24 12:40:03,question,Serialization-deserialization roundtrip of CPubKey does not necessarily result in an equal object,"When fuzzing the serialization code for `CPubKey` I noticed that `Deserialize<CPubKey>(Serialize(obj)) == obj` does not hold true for all `CPubKey obj`.

Is there any reason to why `CPubKey` is deviating from the other serializable classes (for which equality is defined) in this regard? :)

Context:

```
template <typename T>
CDataStream Serialize(const T& obj)
{
    CDataStream ds(SER_NETWORK, INIT_PROTO_VERSION);
    ds << obj;
    return ds;
}

template <typename T>
T Deserialize(CDataStream ds)
{
    T obj;
    ds >> obj;
    return obj;
}
```

"
bitcoin/bitcoin,2019-10-15 10:05:59,question,Error: connect ECONNREFUSED v0.18.0,"my config is below, the Bitcoin Core version is v0.18.0
```
txindex=1
server=1
rpcuser=username
rpcpassword=password
rpcallowip= the ip I connect
rpcport=port
```

but I got error ` Error: connect ECONNREFUSED`"
bitcoin/bitcoin,2019-09-30 09:37:14,question,No addresses returned by getnodeaddresses RPC call,"## The issue
I am attempting to use the `getnodeaddresses` RPC call to return all addresses known by a node in a docker network. I'm using the `regtest` environment. The RPC call returns an empty array although nodes have been added on the referent node using the `add` RPC call.

## Expected behavior <!--- What behavior did you expect? -->
The `getnodeaddresses` RPC call should return nodes added via the `add` RPC call.

## Actual behavior <!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->
No addresses are returned, i.e., an empty array is returned:
 ```
bitcoin-cli -regtest --datadir=/root/.bitcoin/ getnodeaddresses 5
[
]
 ```
## Reproduction <!--- How reliably can you reproduce the issue, what are the steps to do so? -->
Setup a regtest network of 11 nodes. No mining has been done, and the `~/.bitcoin` folder contains only `bitcoin.conf` with the following content:
```
[regtest]
regtest=1
server=1
rpcport=8332
port=8333
```
Connect to the referent node and run the command:
`bitcoin-cli -regtest --datadir=/root/.bitcoin/ addnode ""$p:8333"" add` where `p` is the other node address  for every node the referent node wants to add.

Run the commands on the referent node:
```
bitcoin-cli -regtest --datadir=/root/.bitcoin/ getconnectioncount
10

bitcoin-cli -regtest --datadir=/root/.bitcoin/ getpeerinfo       

[
  {
    ""id"": 2,
    ""addr"": ""10.0.0.3:53378"",
     # Cut out part of response
{
    ""id"": 11,
    ""addr"": ""10.0.0.4:36236"",
    ""addrbind"": ""10.0.0.2:8333"",
    ""services"": ""000000000000040d"",
    ""relaytxes"": true,
    ""lastsend"": 1569835448,
    ""lastrecv"": 1569835448,
    ""bytessent"": 464,
    ""bytesrecv"": 488,
    ""conntime"": 1569835207,
    ""timeoffset"": 0,
    ""pingtime"": 0.001063,
    ""minping"": 0.000456,
    ""version"": 70015,
    ""subver"": ""/Satoshi:0.18.0/"",
    ""inbound"": true,
    ""addnode"": false,
    ""startingheight"": 303,
    ""banscore"": 0,
    ""synced_headers"": -1,
    ""synced_blocks"": -1,
    ""inflight"": [
    ],
    ""whitelisted"": false,
    ""minfeefilter"": 0.00001000,
    ""bytessent_per_msg"": {
      ""feefilter"": 32,
      ""ping"": 96,
      ""pong"": 96,
      ""sendcmpct"": 66,
      ""sendheaders"": 24,
      ""verack"": 24,
      ""version"": 126
    },
    ""bytesrecv_per_msg"": {
      ""feefilter"": 32,
      ""getaddr"": 24,
      ""ping"": 96,
      ""pong"": 96,
      ""sendcmpct"": 66,
      ""sendheaders"": 24,
      ""verack"": 24,
      ""version"": 126
    }
  }
]

bitcoin-cli -regtest --datadir=/root/.bitcoin getnodeaddresses 5
[
]

```
## Bitcoin core version <!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
```
bitcoin-cli -version
Bitcoin Core RPC client version v0.18.0.0-g2472733a24a9364e4c6233ccd04166a26a68cc65
bitcoind -version 
Bitcoin Core Daemon version v0.18.0.0-g2472733a24a9364e4c6233ccd04166a26a68cc65
```
Installed via the repository `ppa:bitcoin/bitcoin`

## OS<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
Docker container info:
```
lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 18.04.3 LTS
Release:	18.04
Codename:	bionic
```
Host info:
```
lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 18.04.3 LTS
Release:	18.04
Codename:	bionic

cat /proc/cpuinfo  | grep 'name'| uniq
model name	: Intel(R) Core(TM) i7-4600M CPU @ 2.90GHz
```
1 TB SSD disk

"
bitcoin/bitcoin,2019-08-20 01:28:26,question,Entity Too Large ,"Client error: POST <public IP address removed> resulted in a 413 Request Entity Too Large response:

I got error when using decoderawtransaction. I already set the post_max_size = 2G and upload_max_filesize = 2G in php.ini. In apache, I already set the LimitRequestBody 104857600.

Where do I need to change in order to pass this error? Thank you."
bitcoin/bitcoin,2019-07-25 03:14:49,question,BTC 0.18 Node,"Why can't docker use RPC commands directly through mount ports, as in previous versions? Does bitcoin.conf need special configuration?"
bitcoin/bitcoin,2019-07-14 19:17:31,question,[Feature] Get utxos for non-wallet addresses,"Hey team,

Adding a feature request here for the ability to query all utxos for a given address(s) regardless if it's in the nodes wallet or not.

I understand the reasoning here of why it's not included out-of-the-box as it could add a significant amount of overhead to the core requirements of running the node.

However, it's fairly concerning that the most of the articles about how to get this functionality just point to using an external api to fetch this info. Tutorials of how to get this functionality on the developer side are also painful when just trying to get this fairly common feature up and running. Isn't part of the point of running a full node to be able to get anything you need without the reliance of a third party? ""Don't trust, verify""

I would imagine the best implementation for this would be to add a flag in the `bitcoin.conf` of something like `indexAddrs=1` or something like that.

Anyway, just putting the idea out there. Thanks
"
bitcoin/bitcoin,2019-06-28 16:37:24,question,Cannot create low fee transaction via RPC,"**Issue**
We're running bitcoind + lnd on a raspberry pi with several other pieces of software. Because we want bitcoind to be really light weight, we set the maxmempool to be 20 mb. We don't really care about having mempool data itself, but we do care about being able to create transactions and broadcast those transactions to the network.

The problem we've been running into is that when the mempool is constricted like this (20 mb limit), mempoolminfee seams to start out at 0.00000001 at boot time, but then gets larger the longer bitcoind is online. We typically create transactions at 1 sat_per_byte because we don't care about them being validated immediately. The problem is we're getting this `[lncli] rpc error: code = Unknown desc = -26: mempool min fee not met, 143 < 2005 (code 66)`. This error is of course being propagated by bitcoind.

We set `mintxfee` to `0.00000001` and even `minrelaytxfee` to `0.00000001`, but neither seem to stop mempoolminfee from increasing over time.

Is there anyway to guarantee these transactions always get inserted into the mempool and broadcasted? I did some research and it looks like the mempool operates like that to avoid dos attacks. But, shouldn't rpc calls bypass these ddos issues. It makes sense that rpc calls should always work.

**Expected Behavior**
There are two appropriate ways I think this could be handled. 

1. Creating a transaction via RPC should always be accepted by the local mempool and broadcasted to peers that will accept that feerate. 
2. Creating a transaction via RPC should always be broadcasted to peers that will accept that feerate. 

**Actual Behavior**
The RPC call fails with an error message similar to this `mempool min fee not met, 143 < 2005 `

**Environment**
We compile our own docker containers. Important lines from the docker file are below. We are also using lnd 0.7.0. 
```
FROM ubuntu:18.04

ARG VERSION=0.18.0
ENV BINARY_LINK https://bitcoin.org/bin/bitcoin-core-${VERSION}/bitcoin-${VERSION}-x86_64-linux-gnu.tar.gz
```

**Machine Info**
This specifically is happening on a raspberry pi 3b+. But, I believe it is not machine based. 
"
bitcoin/bitcoin,2019-06-22 15:31:17,question,bitcoin.conf assumevalid=0 does not seem to be working,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->
assumevalid=0 does not seem to work when it is in the bitcoin.conf file but does when set as a cli argument.
<!--- What behavior did you expect? -->
I thought setting this in the config file would be enough to set this value.
<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->
When set in the config file, the log says it is still using the default hex value. It does work when set as a command line argument. 
![Screenshot from 2019-06-22 11-13-43](https://user-images.githubusercontent.com/24950563/59965734-09d43c80-94e0-11e9-914e-e741cec01a0c.png)
![Screenshot from 2019-06-22 11-13-26](https://user-images.githubusercontent.com/24950563/59965735-148ed180-94e0-11e9-9c90-9e53427b41c3.png)
![Screenshot from 2019-06-22 11-08-37](https://user-images.githubusercontent.com/24950563/59965737-1bb5df80-94e0-11e9-86a5-d0fe63457c4a.png)
<!--- How reliably can you reproduce the issue, what are the steps to do so? -->
Just setting the config option without the command line argument recreates the issue. I did test my config file by removing the dbcache setting and that was reflected in the logs.
![Screenshot from 2019-06-22 11-26-23](https://user-images.githubusercontent.com/24950563/59965803-e65dc180-94e0-11e9-8031-a26d69eb8cca.png)
![Screenshot from 2019-06-22 11-26-32](https://user-images.githubusercontent.com/24950563/59965805-eb227580-94e0-11e9-80ac-323d622d0029.png)
<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
I am using the downloaded release version 18.0.

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
I am using a laptop with Ubuntu and a platter hard drive.

<!-- For the GUI-related issue on Linux provide names and versions of a distro, a desktop environment and a graphical shell (if relevant). -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2019-06-13 03:04:45,question,How to compile and debug the latest version of bitcoin source code with Visual Studio 2015 or Visual Studio 2013,"Hello, everyone, my question is how to compile and debug the latest version of bitcoin source code with Visual Studio 2015 or Visual Studio 2013"
bitcoin/bitcoin,2019-06-09 23:09:14,question,getnewaddress always returns same type ,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->
<!--- What behavior did you expect? -->
When I run ""getnewaddress legacy"" I expect to get an address starting with a ""1"".
When I run ""getnewaddress p2sh-segwit"" I expect to get an address starting with a ""3"".
When I run ""getnewaddress bech32"" I expect to get an address starting with ""bc1"".

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->
I always get an address starting a ""3"". Another user I know always gets an address starting with a ""1"".

![getnewaddress-screenshot](https://user-images.githubusercontent.com/4021240/59165441-7444b000-8ad0-11e9-892d-6e6ccc66a6c9.png)

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->
This is reproducible both from command line running bitcoind, and also bitcoin-Qt. From bitcoind, I type:

bitcoin-cli getnewaddress legacy

Or from bitcoin-Qt I issue the commands from the debug window console, as shown in the screenshot above.
 
<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
Running version 0.18 downloaded from https://bitcoin.org/en/download

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
I'm running on macOS Mojave Version 10.14.5, and I always get an address starting with ""3"".
The other user I know runs Ubuntu, and always gets an address starting with a ""1"".

<!-- For the GUI-related issue on Linux provide names and versions of a distro, a desktop environment and a graphical shell (if relevant). -->
N//a

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2019-04-28 21:05:15,question,Transaction Fee calculated is only 1% of what it ought to be,"The transaction fee; recommended; only seems to be calculating 1% of what it should be and this is causing transactions to hang or not get processed in a timely manner.

I have spent three lots of coins from my bitcoin core wallet.  In each case the fee has been set to automatically calculate.  I do not believe I changed the parameter since installation and it is set to Confirmation Target Time of 60 minutes, which, when initially writing this, was supposed to be 0.00064232 BTC/kb. 

Three transactions - lastly a transaction size of 221 bytes (0.221 kbytes] the expected fee from two weeks ago, based on the 0.00091727 BTC/kb, should be about 0.000203.  However the fee charged is only about 1% of this 0.00000238 BTC, seemingly out by a factor of 100.   It is now confirmed but attempting to accelerate on pool.viabtc.com/tools/txaccelerator/ failed because the fee was too low!

Secondly - A similar small fee of 0.00000224 BTC was applied on a previous transaction two weeks earlier.  I have no idea of what the calculation BTC/kb would have then been.

And thirdly - a transaction another week earlier had a fee calculated of 0.00001194 BTC or 0.0000632 BTC/kb, I again have no idea of what the BTC/kb was at that time, but this is also seemingly out be a factor of 50 or 100.

If the calculation is out, using mBTC instead of satoshis or some such thing, then I worry any sudden change could adversely impact people who have identified the bug and have manually set their BTC/kb value to 100 times what it ought to be!!!

Any workaround setting the BTC/kb value manually is really worrisome for anyone not using wallets regularly, I would worry I could pay 100 time more than I ought to! 

"
bitcoin/bitcoin,2019-04-11 13:19:08,question,How to get onion addresses for seeds,"thank you @Emzy!
however, your list doesn't have onion addresses at all

_Originally posted by @laanwj in https://github.com/bitcoin/bitcoin/pull/15791#issuecomment-482106576_

I have no idea why.
My comandline is: 
./dnsseed -h dnsseed.emzy.de -n node3.emzy.de -m emzy.emzy.de -p 5353"
bitcoin/bitcoin,2019-03-09 22:42:09,question,"bitcoin-cli does'nt have ""getnewaddress"" method","I have installed bitcoin core running on my local machine.
I want to create a new address using bitcoin-cli, executing a command as follows then an error message was displayed.
How can I solve it?

```
$ bitcoin-cli getnewaddress
error code: -32601
error message:
Method not found
```

The version of bitcoin-core is as follows.
```
$ bitcoin-cli -version
Bitcoin Core RPC client version v0.18.0.0-742f7dd97
```

The machine running bitcoin core is virtual machine on VirtualBox on Windows7.
The guest OS is ubuntu server and version is as follows.
```
$ uname -a
Linux ubuntu 4.15.0-45-generic #48-Ubuntu SMP Tue Jan 29 16:28:13 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
```

"
bitcoin/bitcoin,2019-03-02 13:42:03,question,Why Bitcoin Core is a monolith?,"I don't understand why Bitcoin Core software was designed as a monolith and not as a microservices architecture.

Now the node, the gui, the cli, the wallet are all in one. 

For example, some people don't need the GUI, others don't need the CLI, or others don't need the wallet.

For example, some people can install a cli, set the node, and use it remotely, or some people can be take a wallet with a remote node.

So my question is, Why the core team deceided a monolith architecture? I don't find any reasonable fact for do this.
"
bitcoin/bitcoin,2019-02-20 17:21:50,question,Transaction broadcasting failed,"Cont: When i try to broadcast a raw hex transaction - all look nice, bitcoin-cli return a transaction id for the sended hex data, but i looking on blockchain explorer 
and nohing happens. A my txid not found, likely I dont have no one peers that known about it. In my debug log i not seen no one rejects for sendedded transaction, only inv\\getdata\\tx messagesd

bitcoin core version: v0.17.99.0-72bd4ab86-dirty
OS: Ubuntu 18.04

[tx.zip](https://github.com/bitcoin/bitcoin/files/2885742/tx.zip)
"
bitcoin/bitcoin,2019-01-27 05:31:41,question,"[Windows, MinGW] error windres -f invalid option","having the hardest time figuring out this issue for some reason it seems like its trying to pass -f option to windres during the check `@test -f $(WINDRES)` i dont see where -f is being passed to windres at all, i know i know i could just build it on linux but i am trying to bring back an old project(easywinbuilder) and this seems to be my last issue im really just stuck with no solution...
![image](https://user-images.githubusercontent.com/18357967/51796824-32b10980-21ae-11e9-9133-6938d319481b.png)
[config.log](https://github.com/bitcoin/bitcoin/files/2799800/config.log)
"
bitcoin/bitcoin,2019-01-04 05:12:05,question,RPC: Connection Refused,"I see that there has been some configuration updates which is why I am sure I am getting a connection refused.

i tried searching for an updated bitcoin.conf example but couldn't find anything. 

this is the config throwing the error:

rpcuser=user
rpcpassword=pass
rpcport=10301
rpcthreads=64
rpcallowip=127.0.0.1
rpcallowip=10.0.0.3
rpcallowip=10.0.0.2
rpcallowip=10.0.0.4
rpcallowip=10.0.0.7
rpcallowip=10.0.0.8
rpcallowip=10.0.0.9
rpcallowip=10.0.0.10
rpcallowip=10.0.0.11
maxconnections=25
daemon=1
gen=0

alertnotify=echo %s | mail -s ""Bitcoin alert!"" support@xxxx.xxx
blocknotify=blocknotify.sh PORT 6 %s
"
bitcoin/bitcoin,2018-12-23 05:40:30,question,Question: miner_tests.cpp with new data,"Hi Bitcoin Devs :smiley: 

https://github.com/bitcoin/bitcoin/blob/e2dfeb0146da046ad34655b17941e54e4b3d7769/src/test/miner_tests.cpp#L54

```cpp
    {4, 0xa4a3e223}, {2, 0x15c32f9e}, {1, 0x0375b547}, {1, 0x7004a8a5},
    {2, 0xce440296}, {2, 0x52cfe198}, {1, 0x77a72cd0}, {2, 0xbb5d6f84},
    {2, 0x83f30c2c}, {1, 0x48a73d5b}, {1, 0xef7dcd01}, {2, 0x6809c6c4},
    {2, 0x0883ab3c}, {1, 0x087bbbe2}, {2, 0x2104a814}, {2, 0xdffb6daa},
```

I want to do `miner_tests` with new data. Could you tell me how to create new one? `blockinfo` I would especially like to check blockchain data after segwit. This data is maybe outdated... :thinking: 

If I can, I would like to reinforce the test data and contribute to this project. :smile: I tried a lot. But I could not get the `extranonce` :sob:
"
bitcoin/bitcoin,2018-11-07 16:47:52,question,bitcoin-cli console walletpassphrase can't unlock wallet Password with some special characters will not work,"bitcoin-cli console walletpassphrase can't unlock wallet Password with some special characters will not work

<!-- Describe the issue -->
I am trying unlock my wallet by console using: **walletpassphrase**, my problem is in my password i have a lot special characters, like: **`^""\\'@-#&%*;_** I tried include **\\** before the special characters and did not help.

can you guys share for me what is considered be a special characters here in bitcoin cli? as well could guys give a sample of solve this problem here?

the commnand i used to open the wallet for 20 minutes was: **walletpassphrase ""`^""\\'@-#&%*;_""   1200**

so my question is how to fix this problem and make my wallet understand what is special characters and what is not.

thank you.
"
bitcoin/bitcoin,2018-11-03 01:44:00,question,Can't use signrawtransaction in the new version,"after I update the latest version of bitcoin core (0.17), I can't use ""signrawtransaction "" to signe my tx.
my cmd is this
```
bitcoin-cli -rpcuser=xxx -rpcpassword=xxx -rpcport=xxx signrawtransaction \\
02000000019ea1e1eb2b6d8fca57bb99e5747f2e3446b7aac64c1147f389c025d0af155a9e0000000000ffffffff02a00f00000000000017a914bee24fd1587112a9ab41b202fc2c01e1de59b47e87a87811000000000017a91477c56ac5820aaa6c667cc4856baad24e462a46748700000000
```
the log is
```
error code: -32
error message:
signrawtransaction was removed in v0.18.
Clients should transition to using signrawtransactionwithkey and signrawtransactionwithwallet
```
"
bitcoin/bitcoin,2023-09-13 17:34:31,bug,Fix virtual size limit enforcement in transaction package context,"(Alternative) Minimal subset of https://github.com/bitcoin/bitcoin/pull/28345 to:

1) Replace MAX_PACKAGE_SIZE with MAX_PACKAGE_WEIGHT which accounts for additional WU necessary to not exclude default chain limit transactions that would have been accepted individually. Avoids sigops vbyte confusion.
2) pass correct vsize to chain limit evaluations in package context
3) stop overly-large packages that have no existing mempool ancestors (also a bugfix by itself if someone sets non-standard chain limits)

This should fix the known issues while not blocking additional refactoring later."
bitcoin/bitcoin,2023-08-10 13:04:19,bug,validation: fix coins disappearing mid-package evaluation,"While we are evaluating a package, we split it into ""subpackages"" for evaluation (currently subpackages all have size 1 except the last one). If a subpackage has size 1, we may add a tx to mempool and call `LimitMempoolSize()`, which evicts transactions if the mempool gets full. We handle the case where the just-submitted transaction is evicted immediately, but we don't handle the case in which a transaction from a previous subpackage (either just submitted or already in mempool) is evicted. Mainly, since the coins created by the evicted transaction are cached in `m_view`, we don't realize the UTXO has disappeared until `CheckInputsFromMempoolAndCache` asserts that they exist. Also, the returned `PackageMempoolAcceptResult` reports that the transaction is in mempool even though it isn't anymore.

Fix this by not calling `LimitMempoolSize()` until the very end, and editing the results map with ""mempool full"" if things fall out.

Pointed out by instagibbs in https://github.com/bitcoin/bitcoin/commit/faeed687e5cde5e32750d93818dd1d4add837f24 on top of the v3 PR."
bitcoin/bitcoin,2023-06-19 13:09:41,bug,"rpc: signed-integer-overflow in analyzepsbt[""estimated_feerate""]","### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

crash/UB in https://github.com/bitcoin/bitcoin/blob/f0758d8a6696657269d9c057e7aa079ffa9e1c16/src/rpc/rawtransaction.cpp#L1906

### Expected behaviour

no crash

### Steps to reproduce

* Compile with ubsan
* `UBSAN_OPTIONS=""suppressions=$(pwd)/test/sanitizer_suppressions/ubsan:print_stacktrace=1:halt_on_error=1:report_error_type=1"" ./src/qt/bitcoin-qt`
* `analyzepsbt cHNidP8BACkgICAgAAEgICAgIP8DABYgICAgICAgICAgICAgICAgICAgICAgICAgIAAA`

### Relevant log output

```
    #0 0x55a94d97befd in CFeeRate::GetFee(unsigned int) const src/policy/feerate.cpp:29:63
    #1 0x55a94d4648ca in CFeeRate::GetFeePerK() const src/./policy/feerate.h:65:41
    #2 0x55a94d4648ca in analyzepsbt()::$_13::operator()(RPCHelpMan const&, JSONRPCRequest const&) const src/rpc/rawtransaction.cpp:1907:85
...
SUMMARY: UndefinedBehaviorSanitizer: signed-integer-overflow policy/feerate.cpp:29:63 in 
```

### How did you obtain Bitcoin Core

Compiled from source

### What version of Bitcoin Core are you using?

current master

### Operating system and version

Linux

### Machine specifications

_No response_"
bitcoin/bitcoin,2023-06-01 22:06:06,bug,Fuzz: Mitigate timeout in CalculateTotalBumpFees,"The slow fuzz seed described in #27799 was just slower than expected, not an endless loop. Ensuring that every anscestor is only processed once speeds up the termination of the graph traversal.

Fixes #27799"
bitcoin/bitcoin,2023-05-05 17:54:13,bug,fuzz: improve `coinselection`,"This PR:

- Moves coin creation to its own function called `CreateCoins`.
- Add coverage for `EligibleForSpending`
- Add coverage for `AddInputs`: get result of each algorithm (srd, knapsack and bnb), call `CreateCoins` and add into them.
- Add coverage for `GetShuffledInputVector` and `GetInputSet` using the result of each algorithm (srd, knapsack and bnb).
- Add coverage for `Merge`: Call SRD with the new utxos and, if successful, try to merge with the previous SRD result."
bitcoin/bitcoin,2023-04-18 15:16:35,bug,Bitcoin Core compiled with Ubuntu Focal gcc-8 immediately segfaults,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Current behaviour

segfault

### Expected behaviour

no segfault

### Steps to reproduce

* Fresh install of Ubuntu Focal
* `export DEBIAN_FRONTEND=noninteractive && apt update && apt install curl wget htop git vim ccache -y && git clone https://github.com/bitcoin/bitcoin.git  --depth=1 ./bitcoin-core && cd bitcoin-core && apt install build-essential libtool autotools-dev automake pkg-config bsdmainutils python3-zmq     libevent-dev libboost-dev gcc-8 g++-8     -y`
* `./autogen.sh && ./configure CC=gcc-8 CXX=g++-8    && make -j $(nproc) src/bitcoind`
* `valgrind ./src/bitcoind`

### Relevant log output

```
# valgrind ./src/bitcoind 
==19993== Memcheck, a memory error detector
==19993== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==19993== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info
==19993== Command: ./src/bitcoind
==19993== 
==19993== Invalid read of size 8
==19993==    at 0x1FD15F: ~vector (stl_vector.h:567)
==19993==    by 0x1FD15F: std::filesystem::__cxx11::path::~path() (fs_path.h:209)
==19993==    by 0x1FD18B: ~_Cmpt (fs_path.h:644)
==19993==    by 0x1FD18B: _Destroy<std::filesystem::__cxx11::path::_Cmpt> (stl_construct.h:98)
==19993==    by 0x1FD18B: __destroy<std::filesystem::__cxx11::path::_Cmpt*> (stl_construct.h:108)
==19993==    by 0x1FD18B: _Destroy<std::filesystem::__cxx11::path::_Cmpt*> (stl_construct.h:137)
==19993==    by 0x1FD18B: _Destroy<std::filesystem::__cxx11::path::_Cmpt*, std::filesystem::__cxx11::path::_Cmpt> (stl_construct.h:206)
==19993==    by 0x1FD18B: ~vector (stl_vector.h:567)
==19993==    by 0x1FD18B: std::filesystem::__cxx11::path::~path() (fs_path.h:209)
==19993==    by 0x1C5A7C: ~path (fs.h:30)
==19993==    by 0x1C5A7C: ArgsManager::GetConfigFilePath() const [clone .cold.494] (system.cpp:838)
==19993==    by 0x6057E0: ArgsManager::ReadConfigFiles(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, bool) (system.cpp:849)
==19993==    by 0x4F557F: common::InitConfig(ArgsManager&, std::function<bool (bilingual_str const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&)>) (init.cpp:24)
==19993==    by 0x1CC16E: AppInit (bitcoind.cpp:155)
==19993==    by 0x1CC16E: main (bitcoind.cpp:266)
==19993==  Address 0x2b is not stack'd, malloc'd or (recently) free'd
==19993== 
==19993== 
==19993== Process terminating with default action of signal 11 (SIGSEGV): dumping core
==19993==  Access not within mapped region at address 0x2B
==19993==    at 0x1FD15F: ~vector (stl_vector.h:567)
==19993==    by 0x1FD15F: std::filesystem::__cxx11::path::~path() (fs_path.h:209)
==19993==    by 0x1FD18B: ~_Cmpt (fs_path.h:644)
==19993==    by 0x1FD18B: _Destroy<std::filesystem::__cxx11::path::_Cmpt> (stl_construct.h:98)
==19993==    by 0x1FD18B: __destroy<std::filesystem::__cxx11::path::_Cmpt*> (stl_construct.h:108)
==19993==    by 0x1FD18B: _Destroy<std::filesystem::__cxx11::path::_Cmpt*> (stl_construct.h:137)
==19993==    by 0x1FD18B: _Destroy<std::filesystem::__cxx11::path::_Cmpt*, std::filesystem::__cxx11::path::_Cmpt> (stl_construct.h:206)
==19993==    by 0x1FD18B: ~vector (stl_vector.h:567)
==19993==    by 0x1FD18B: std::filesystem::__cxx11::path::~path() (fs_path.h:209)
==19993==    by 0x1C5A7C: ~path (fs.h:30)
==19993==    by 0x1C5A7C: ArgsManager::GetConfigFilePath() const [clone .cold.494] (system.cpp:838)
==19993==    by 0x6057E0: ArgsManager::ReadConfigFiles(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, bool) (system.cpp:849)
==19993==    by 0x4F557F: common::InitConfig(ArgsManager&, std::function<bool (bilingual_str const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&)>) (init.cpp:24)
==19993==    by 0x1CC16E: AppInit (bitcoind.cpp:155)
==19993==    by 0x1CC16E: main (bitcoind.cpp:266)
==19993==  If you believe this happened as a result of a stack
==19993==  overflow in your program's main thread (unlikely but
==19993==  possible), you can try to increase the size of the
==19993==  main thread stack using the --main-stacksize= flag.
==19993==  The main thread stack size used in this run was 8388608.
==19993== 
==19993== HEAP SUMMARY:
==19993==     in use at exit: 122,654 bytes in 1,182 blocks
==19993==   total heap usage: 2,545 allocs, 1,363 frees, 383,342 bytes allocated
==19993== 
==19993== LEAK SUMMARY:
==19993==    definitely lost: 0 bytes in 0 blocks
==19993==    indirectly lost: 0 bytes in 0 blocks
==19993==      possibly lost: 136 bytes in 1 blocks
==19993==    still reachable: 122,518 bytes in 1,181 blocks
==19993==         suppressed: 0 bytes in 0 blocks
==19993== Rerun with --leak-check=full to see details of leaked memory
==19993== 
==19993== For lists of detected and suppressed errors, rerun with: -s
==19993== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)
Segmentation fault (core dumped)


### How did you obtain Bitcoin Core

Compiled from source

### What version of Bitcoin Core are you using?

current master

### Operating system and version

-

### Machine specifications

_No response_"
bitcoin/bitcoin,2023-03-06 09:29:50,bug,Issue in `p2p_ibd_stalling.py` under Valgrind,"At 40c6c85c05812ee8bf824b639307b1ac17a001c4 with the native_valgrind job:
```bash
 test  2023-03-05T21:26:43.074000Z TestFramework.node0 (DEBUG): Connecting to 127.0.0.1:12173 outbound-full-relay 
 node0 2023-03-05T21:26:43.265731Z [msghand] [net_processing.cpp:5807] [SendMessages] [net] Requesting block 752405439cea869d584044084502582bc209e4ef97e4bf3b8c2ba3958acaf606 (21) peer=0 
 node0 2023-03-05T21:26:43.267295Z [msghand] [net.cpp:2816] [PushMessage] [net] sending getdata (37 bytes) peer=0 
 node0 2023-03-05T21:26:43.269862Z [http] [httpserver.cpp:239] [http_request_cb] [http] Received a POST request for / from 127.0.0.1:40916 
 node0 2023-03-05T21:26:43.271568Z [msghand] [net_processing.cpp:3169] [ProcessMessage] [net] received: headers (82947 bytes) peer=1 
 node0 2023-03-05T21:26:55.588032Z [httpworker.0] [rpc/request.cpp:179] [parse] [rpc] ThreadRPCServer method=addconnection user=__cookie__ 
 node0 2023-03-05T21:26:55.709062Z [httpworker.0] [net.cpp:457] [ConnectNode] [net:debug] trying connection 127.0.0.1:12173 lastseen=0.0hrs 
 node0 2023-03-05T21:26:55.731504Z [httpworker.0] [net.cpp:2803] [CNode] [net] Added connection peer=2 
 test  2023-03-05T21:27:43.097000Z TestFramework.utils (ERROR): wait_until() failed. Predicate: '''' 
                                           test_function = lambda: self.is_connected
                                   '''
 test  2023-03-05T21:27:43.097000Z TestFramework (ERROR): Assertion failed 
                                   Traceback (most recent call last):
                                     File ""/home/ubuntu/ci_scratch/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 134, in main
                                       self.run_test()
                                     File ""/home/ubuntu/ci_scratch/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/p2p_ibd_stalling.py"", line 77, in run_test
                                       peers.append(node.add_outbound_p2p_connection(P2PStaller(stall_block), p2p_idx=id, connection_type=""outbound-full-relay""))
                                     File ""/home/ubuntu/ci_scratch/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/test_node.py"", line 663, in add_outbound_p2p_connection
                                       p2p_conn.wait_for_connect()
                                     File ""/home/ubuntu/ci_scratch/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/p2p.py"", line 467, in wait_for_connect
                                       wait_until_helper(test_function, timeout=timeout, lock=p2p_lock)
                                     File ""/home/ubuntu/ci_scratch/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/util.py"", line 281, in wait_until_helper
                                       raise AssertionError(""Predicate {} not true after {} seconds"".format(predicate_source, timeout))
                                   AssertionError: Predicate ''''
                                           test_function = lambda: self.is_connected
                                   ''' not true after 60.0 seconds
 test  2023-03-05T21:27:43.102000Z TestFramework (DEBUG): Closing down network thread 
 test  2023-03-05T21:27:53.123000Z TestFramework.utils (ERROR): wait_until() failed. Predicate: '''' 
                                           wait_until_helper(lambda: not self.network_event_loop.is_running(), timeout=timeout)
                                   '''
 node0 2023-03-05T21:28:08.198208Z [msghand] [net_processing.cpp:2760] [UpdatePeerStateForReceivedHeaders] [net] Protecting outbound peer=1 from eviction 
 node0 2023-03-05T21:28:08.201820Z [msghand] [net.cpp:2816] [PushMessage] [net] sending sendheaders (0 bytes) peer=1 
```"
bitcoin/bitcoin,2023-03-02 11:54:22,bug,"Use of a wallet shouldn't be blocked in prune mode (""wallet loading failed... beyond pruned data"")","It is impossible to load and use a wallet neither in Bitcoin-qt GUI nor console/RPC commands. The wallet is only about 2 weeks old and typical settings are used (data pruned to 2 GB).

**Expected behavior**

- A wallet is loaded (either manually or automatically on startup) and addresses are shown in Bitcoin-qt, 
- successful execution of wallet RPC commands, e.g. getwalletinfo, dumpwallet, walletpassphrasechange etc. 

(not different from the way it had worked and looked the previous time a user started Bitcoin Core).

**Actual behavior**

![wallet loading failed  Prune](https://user-images.githubusercontent.com/111286121/222418406-67836dd2-f28b-4611-baeb-055ae21d9834.png)

> Wallet loading failed. Prune: last wallet synchronisation goes beyond pruned data. You need to -reindex (download the whole blockchain again in case of pruned node)

Also, RPC commands fail, for example: loadwallet, getwalletinfo, dumpwallet (except for listwallets).

**To reproduce**

1. Start Bitcoin-qt
2. Select File->Open Wallet->[Wallet name]

Reproducible every time in prune mode. The wallet was created at the time for which data were pruned. The wallet was created in bitcoin-qt.

**System information**

Official binary Bitcoin Core 24.0.1, Windows 11."
bitcoin/bitcoin,2023-02-22 10:47:49,bug,core stops to run with `Failed to read block` error,"**Expected behavior**

While my node was running it get an internal failure that force it to stop the running

```
2023-02-21T23:29:22Z Syncing basic block filter index with block chain from height 624447
2023-02-21T23:29:34Z ERROR: SerializeFileDB: Rename-into-place failed
2023-02-21T23:29:52Z Syncing basic block filter index with block chain from height 624889
2023-02-21T23:30:22Z ERROR: ReadBlockFromDisk: Deserialize or I/O error - ReadCompactSize(): size too large: iostream error at FlatFilePos(nFile=2030, nPos=82255446)
2023-02-21T23:30:22Z *** ThreadSync: Failed to read block 0000000000000000000def83407e184fbc5f53b47effdaef7b15e2d6f6b8579d from disk
2023-02-21T23:30:22Z Error: A fatal internal error occurred, see debug.log for details
```

The code is based on the commit `94070029fb6b783833973f9fe08a3a871994492f`

**To reproduce**

No idea how I can reproduce it, now I switch to the tagged version to see if this happens too

**System information**
```
➜  bitcoin git:(master) neofetch                                        
       _,met$$$$$gg.          vincent@x86 
    ,g$$$$$$$$$$$$$$$P.       ----------- 
  ,g$$P""     """"""Y$$."".        OS: Debian GNU/Linux 11 (bullseye) x86_64 
 ,$$P'              `$$$.     Host: OptiPlex 3050 
',$$P       ,ggs.     `$$b:   Kernel: 5.10.0-21-amd64 
`d$$'     ,$P""'   .    $$$    Uptime: 5 days, 16 hours, 33 mins 
 $$P      d$'     ,    $$P    Packages: 502 (dpkg) 
 $$:      $$.   -    ,d$$'    Shell: zsh 5.8 
 $$;      Y$b._   _,d$P'      Terminal: /dev/pts/1 
 Y$$.    `.`""Y$$$$P""'         CPU: Intel i5-7500T (4) @ 3.300GHz 
 `$$b      ""-.__              GPU: Intel HD Graphics 630 
  `Y$$                        Memory: 2214MiB / 7840MiB 
   `Y$$.
     `$$b.                                            
       `Y$$b.                                         
          `""Y$b._
              `""""""


```
<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2023-02-17 18:19:05,bug,"error: timeout on transient error: Could not connect to the server 127.0.0.1:8333 (error code 1 - ""EOF reached"")","<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->

When I'm trying to use `bitcoin-cli` while bitcoind running it displays error message : 
```error: timeout on transient error: Could not connect to the server 127.0.0.1:8333 (error code 1 - ""EOF reached"")
Make sure the bitcoind server is running and that you are connecting to the correct RPC port.```

<!--- What behavior did you expect? -->

running command : `bitcoin-cli getblockchaininfo` 

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

` bitcoind -txindex `
```[...] 2023-02-17T18:03:20Z Bound to 127.0.0.1:8334
2023-02-17T18:03:20Z Bound to [::]:8333
2023-02-17T18:03:20Z Bound to 0.0.0.0:8333
[...] ```

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

I am on MacOS Ventura 13.1 intel i5 MacBook Pro.

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

`2023-02-17T18:03:07Z Bitcoin Core version v24.0.1 (release build)`


<!-- Any extra information that might be useful in the debugging process. -->

I saw a related issue few years ago and apparently this issue should to be patched. 

"
bitcoin/bitcoin,2023-02-16 15:26:02,bug,decodescript miniscript functionality tops out at 520 bytes,"After https://github.com/bitcoin/bitcoin/pull/27037 miniscript is extracted from compatible scripts, unless the `FillableSigningProvider::AddCScript` check for `MAX_SCRIPT_ELEMENT_SIZE` fails, which then it falls back to legacy behavior.

@achow101 "
bitcoin/bitcoin,2023-02-10 17:18:34,bug,"RPC getdescriptorinfo shouldn't output undefined value of the ""descriptor""","**Expected behavior**

```
{
  ""descriptor"": ""tr(cUTFbLPUaBAPmTKwjcDs4rWHUSEUbUBfkPMogrbTmQFnJA3vgrLE)#tdkpah70"",
  ""checksum"": ""tdkpah70"",
  ""isrange"": false,
  ""issolvable"": true,
  ""hasprivatekeys"": true
}
```

**Actual behavior**

{
  ""descriptor"": ""tr(**967a9c6e1e189a8390e8ed870b918cc64742bebc372625071c410ac96b1aa580)#x9af7q5s**"",
  ""checksum"": ""tdkpah70"",
  ""isrange"": false,
  ""issolvable"": true,
  ""hasprivatekeys"": true
}

**To reproduce**

Execure the RPC command, e.g.: `getdescriptorinfo ""tr(cUTFbLPUaBAPmTKwjcDs4rWHUSEUbUBfkPMogrbTmQFnJA3vgrLE)""`

**System information**

Bitcoin 24.0.1"
bitcoin/bitcoin,2023-02-09 18:44:23,bug,Wallet passphrases silently ignore everything after a null character,"## Problem

Encrypting a wallet through JSON RPC or Qt *appears to* allow a user to include null characters in the passphrase, but silently ignores everything including and after the first null character.

For instance (on regtest), trying to set a passphrase of ""`a{null character}b`"":

`curl --user __cookie__ --data-binary '{""jsonrpc"": ""1.0"", ""id"":""curltest"", ""method"": ""encryptwallet"", ""params"": [""a\\u0000b""]}' -H 'content-type: text/plain;' http://127.0.0.1:18443/`

This will succeed, but allow the user to unlock with the passphrase ""`a`"", instead of the expected full passphrase (which also works):

`curl --user __cookie__ --data-binary '{""jsonrpc"": ""1.0"", ""id"":""curltest"", ""method"": ""walletpassphrase"", ""params"": [""a"",10]}' -H 'content-type: text/plain;' http://127.0.0.1:18443/`

I am also able to replicate it in Qt on my macOS machine by running `printf 'a\\0b' | pbcopy` and pasting the result into the passphrase dialog. 

My main concern is a user thinking that they're generating, say, 32 random bytes as a passphrase, and if they're unlucky and get a zero in the first few bytes, it unexpectedly cuts their security down to almost nothing. 

## Root Cause

The reason is due to our `SecureString` type. `SecureString` is a `std::string` specialization with a secure allocator. However, when assigned, it's treated like a C- string (no explicit length and null-terminated). See the [original PR](https://github.com/bitcoin/bitcoin/pull/666) for more details.

## Potential Solutions

I think there are two plausible approaches to take. The first (and my preference) is to allow and support null characters, and I will submit a PR that enables that (by making `SecureString` use the entire string). The second is to explicitly reject any passphrases that contain null characters.

One significant complication may be that, if anyone is *already* using a passphrase with a null, then my first solution would stop their wallet from unlocking. However, it would still be unlockable just by trimming the null and any subsequent characters."
bitcoin/bitcoin,2023-02-06 16:50:06,bug,every other change address is unused,"I'm seeing 50% of generated change addresses not being used. It's as if two are reserved for every one that is used.

This is happening in version v24.0.1.

Here's a sequence of commands that shows what I mean. Only the odd numbered change hdkeypaths are used:

```
$ /bin/rm -fr ~/.bitcoin/regtest
$ bitcoin-qt -regtest &
$ bitcoin-cli -regtest createwallet 1 > /dev/null
$ bitcoin-cli -regtest createwallet 2 > /dev/null
$ bitcoin-cli -regtest -rpcwallet=1 -generate 1 > /dev/null
$ bitcoin-cli -regtest -rpcwallet=2 -generate 100 > /dev/null
$ to=$(bitcoin-cli -regtest -rpcwallet=2 getnewaddress)
$ txs=$(for i in {1..5}; do bitcoin-cli -regtest -rpcwallet=1 sendtoaddress $to 1; done)
$ addrs=$(for i in $txs; do bitcoin-cli -regtest getrawtransaction $i true | jq -Mc '.vout[]|{value:.value,addr:.scriptPubKey.address}'; done | grep -v ':1,' | jq -r .addr)
$ for a in $addrs; do bitcoin-cli -regtest -rpcwallet=1 getaddressinfo $a | jq -r .hdkeypath; done
m/84'/1'/0'/1/1
m/84'/1'/0'/1/3
m/84'/1'/0'/1/5
m/84'/1'/0'/1/7
m/84'/1'/0'/1/9
```

This happens whether or not I create descriptor wallets. For example, with a descriptor wallet I get these descriptors for the change addresses:

```
wpkh([779aecf0/84'/1'/0'/1/1]029919052bd5b904afbf71d90afbec0a852d1f0181914b6d07bcab028a0d1ac3e4)#94rhf9lu
wpkh([779aecf0/84'/1'/0'/1/3]0360ecbba4ebaac3ab4f62f14b12a136c2cc5e8264ac1be2af1b5e4413944a2c6a)#lwjzrh62
wpkh([779aecf0/84'/1'/0'/1/5]03d3f72c2cc6085bdee5388ff3b96df7d27ac18d85b5cc8d8048e287b52777062e)#5q4fsvmd
wpkh([779aecf0/84'/1'/0'/1/7]02b77a29387f645bb5ed27ef25144ae67a984e056e41b35fce33bb377d199845ab)#mc608kvz
wpkh([779aecf0/84'/1'/0'/1/9]024988fafba17c2d6f5b2b27428e2fb65ca8a7882ac0fae1422e4fdf46c95dbc61)#mwxzye2v
```

and for a legacy wallet I get these:

```
wpkh([bcc40f8d/0'/1'/1']03d3cc823cd01dcb23dce0ac53f8b38c3cb8b9ddbdfc789550c280d25cba432932)#3vxlglf6
wpkh([bcc40f8d/0'/1'/3']03016e2243892459754e125954d205136247f67580e9379ca931f2ec374b924aef)#kxwx63p3
wpkh([bcc40f8d/0'/1'/5']0236dd8b3a6ebd26a4e1e9dc1d84bf053438c339babacd202000f44917bd452336)#jaq2hgn4
wpkh([bcc40f8d/0'/1'/7']03785884e52fad4588d2d0e1df48b8ba691dddfb3696667932a3b46cb0202132fa)#0d786n6s
wpkh([bcc40f8d/0'/1'/9']03ba88cdc9a37aa676a1152c6d7d970aa32324b99d8c6f775c4543e016161ea4d9)#vdvr44ar
```"
bitcoin/bitcoin,2023-02-02 08:14:51,bug,.,.
bitcoin/bitcoin,2023-02-01 13:57:12,bug,test: format-truncation warning in dbwrapper_tests,"Compiling master at e1bf5470f919cf212703466411968916db8ae61f on Ubuntu 22.10 (with depends):

```cpp
  CXX      test/test_bitcoin-dbwrapper_tests.o
test/dbwrapper_tests.cpp: In member function ‘void dbwrapper_tests::iterator_string_ordering::test_method()’:
test/dbwrapper_tests.cpp:365:41: error: ‘%d’ directive output may be truncated writing between 1 and 11 bytes into a region of size 10 [-Werror=format-truncation=]
  365 |             snprintf(buf, sizeof(buf), ""%d"", x);
      |                                         ^~
test/dbwrapper_tests.cpp:365:40: note: directive argument in the range [-2147483648, 9]
  365 |             snprintf(buf, sizeof(buf), ""%d"", x);
      |                                        ^~~~
In file included from /usr/include/stdio.h:906,
                 from /usr/include/c++/12/cstdio:42,
                 from /usr/include/c++/12/ext/string_conversions.h:43,
                 from /usr/include/c++/12/bits/basic_string.h:3960,
                 from /usr/include/c++/12/string:53,
                 from ./clientversion.h:30,
                 from ./dbwrapper.h:8,
                 from test/dbwrapper_tests.cpp:5:
In function ‘int snprintf(char*, size_t, const char*, ...)’,
    inlined from ‘void dbwrapper_tests::iterator_string_ordering::test_method()’ at test/dbwrapper_tests.cpp:365:21:
/usr/include/x86_64-linux-gnu/bits/stdio2.h:54:35: note: ‘__builtin___snprintf_chk’ output between 2 and 12 bytes into a destination of size 10
   54 |   return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,
      |          ~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   55 |                                    __glibc_objsize (__s), __fmt,
      |                                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   56 |                                    __va_arg_pack ());
      |                                    ~~~~~~~~~~~~~~~~~
```

(I ran with `--enable-werror`, otherwise it's merely a warning)

cc @achow101 "
bitcoin/bitcoin,2023-01-27 19:03:17,bug,Private Key import result with 3 Address generation.,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->
Private Key import result with 3 Address generation. 

**Expected behavior**
Therefore, it seems a bug but also future request assumes that as bitcoin address generation has choice of  version like segwit or leacy, the private key import should result within the setup.
<!--- What behavior did you expect? -->

**Actual behavior**
Generates 3 types wallet like Legacy, Segwit and P2PKH 
<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

**To reproduce**

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2023-01-12 11:18:45,bug,build: xproto fails to install on aarch64-unknown-linux-musl,"```bash
Staging xproto...
make[1]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5'
Making install in specs
make[2]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs'
Making install in SIAddresses
make[3]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs/SIAddresses'
make[4]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs/SIAddresses'
make[4]: Nothing to be done for 'install-exec-am'.
make[4]: Nothing to be done for 'install-data-am'.
make[4]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs/SIAddresses'
make[3]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs/SIAddresses'
make[3]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs'
make[4]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs'
make[4]: Nothing to be done for 'install-exec-am'.
make[4]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs'
make[3]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs'
make[2]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/specs'
make[2]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5'
make[3]: Entering directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5'
make[3]: Nothing to be done for 'install-exec-am'.
 ./install-sh -c -d '/bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/bitcoin/depends/aarch64-unknown-linux-musl/lib/pkgconfig'
 ./install-sh -c -d '/bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/bitcoin/depends/aarch64-unknown-linux-musl/include/X11'
 ./install-sh -c -d '/bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/bitcoin/depends/aarch64-unknown-linux-musl/include/X11'
mkdir: can't create directory '/bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/bitcoin/depends/aarch64-unknown-linux-musl/include': File exists
mkdir: can't create directory '/bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/bitcoin/depends/aarch64-unknown-linux-musl/include/X11': File exists
make[3]: *** [Makefile:487: install-nodist_xprotoHEADERS] Error 1
make[3]: *** Waiting for unfinished jobs....
 /usr/bin/install -c -m 644 xproto.pc '/bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/bitcoin/depends/aarch64-unknown-linux-musl/lib/pkgconfig'
 /usr/bin/install -c -m 644 ap_keysym.h DECkeysym.h HPkeysym.h keysymdef.h keysym.h Sunkeysym.h Xalloca.h Xarch.h Xatom.h Xdefs.h XF86keysym.h Xfuncs.h X.h Xmd.h Xosdefs.h Xos.h Xos_r.h Xproto.h Xprotostr.h Xthreads.h Xw32defs.h XWDFile.h Xwindows.h Xwinsock.h '/bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/bitcoin/depends/aarch64-unknown-linux-musl/include/X11'
make[3]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5'
make[2]: *** [Makefile:838: install-am] Error 2
make[2]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5'
make[1]: *** [Makefile:535: install-recursive] Error 1
make[1]: Leaving directory '/bitcoin/depends/work/build/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5'
make: *** [funcs.mk:289: /bitcoin/depends/work/staging/aarch64-unknown-linux-musl/xproto/7.0.31-074418fcbf5/.stamp_staged] Error 2
make: Leaving directory '/bitcoin/depends'
```
Does not happen when building just the package."
bitcoin/bitcoin,2023-01-11 08:11:48,bug,"intermittent issue in wallet_backwards_compatibility (BerkeleyEnvironment::Open: Error -30974 opening database environment: DB_RUNRECOVERY: Fatal error, run database recovery)","```
$ wget https://drahtbot.space/temp_scratch/wallet_backwards_compatibility_113.tar.xz
$ tar xvf wallet_backwards_compatibility_113.tar.xz
$ ./test/functional/combine_logs.py -c ./wallet_backwards_compatibility_113 | tail -525 | head -13
 node2 2023-01-11T00:21:39.903849Z [httpworker.2] [wallet/bdb.cpp:145] [Open] BerkeleyEnvironment::Open: LogDir=/root/bitcoin-core/ci/scratch/test_runner/test_runner_₿_🏃_20230111_000842/wallet_backwards_compatibility_113/node2/regtest/wallets/w1/database ErrorFile=/root/bitcoin-core/ci/scratch/test_runner/test_runner_₿_🏃_20230111_000842/wallet_backwards_compatibility_113/node2/regtest/wallets/w1/db.log 
 node2 2023-01-11T00:21:39.906405Z [httpworker.2] [wallet/bdb.cpp:172] [Open] BerkeleyEnvironment::Open: Error -30974 opening database environment: DB_RUNRECOVERY: Fatal error, run database recovery 
 test  2023-01-11T00:21:39.909000Z TestFramework (ERROR): JSONRPC error 
                                   Traceback (most recent call last):
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 134, in main
                                       self.run_test()
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/wallet_backwards_compatibility.py"", line 185, in run_test
                                       node.loadwallet(wallet_name)
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/coverage.py"", line 49, in __call__
                                       return_val = self.auth_service_proxy_instance.__call__(*args, **kwargs)
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/authproxy.py"", line 146, in __call__
                                       raise JSONRPCException(response['error'], status)
                                   test_framework.authproxy.JSONRPCException: Wallet file verification failed. Error initializing wallet database environment ""/root/bitcoin-core/ci/scratch/test_runner/test_runner_₿_🏃_20230111_000842/wallet_backwards_compatibility_113/node2/regtest/wallets/w1""! This error could occur if this wallet was not shutdown cleanly and was last loaded using a build with a newer version of Berkeley DB. If so, please use the software that last loaded this wallet (-4)
"
bitcoin/bitcoin,2023-01-09 13:14:17,bug,p2p_permissions intermittent timeout,"```sh
wget https://drahtbot.space/temp_scratch/p2p_permissions.tar.xz
tar -xvf p2p_permissions.tar.xz
test/functional/combine_logs.py -c ./p2p_permissions_15/ | tail -131 | head -33
 test  2023-01-09T13:02:23.385000Z TestFramework.utils (ERROR): wait_until() failed. Predicate: '''' 
                                               self.wait_until(lambda: txid in self.nodes[0].getrawmempool())
                                   '''
 test  2023-01-09T13:02:23.386000Z TestFramework (ERROR): Assertion failed 
                                   Traceback (most recent call last):
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 134, in main
                                       self.run_test()
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/p2p_permissions.py"", line 34, in run_test
                                       self.check_tx_relay()
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/p2p_permissions.py"", line 128, in check_tx_relay
                                       self.wait_until(lambda: txid in self.nodes[0].getrawmempool())
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 732, in wait_until
                                       return wait_until_helper(test_function, timeout=timeout, timeout_factor=self.options.timeout_factor)
                                     File ""/root/bitcoin-core/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/util.py"", line 281, in wait_until_helper
                                       raise AssertionError(""Predicate {} not true after {} seconds"".format(predicate_source, timeout))
                                   AssertionError: Predicate ''''
                                               self.wait_until(lambda: txid in self.nodes[0].getrawmempool())
                                   ''' not true after 2400.0 seconds
"
bitcoin/bitcoin,2023-01-05 17:36:52,bug,test: sqlite tests on freebsd fail with ModuleNotFoundError: No module named '_sqlite3',"It would be good if the test was skipped instead, or if the documentation explained how to install py-sqlite.


```
126/256 - wallet_descriptor.py --descriptors failed, Duration: 0 s
stdout:
stderr:
Traceback (most recent call last):
  File ""/tmp/cirrus-ci-build/bitcoin-core/test/functional/wallet_descriptor.py"", line 7, in <module>
    import sqlite3
  File ""/usr/local/lib/python3.9/sqlite3/__init__.py"", line 57, in <module>
    from sqlite3.dbapi2 import *
  File ""/usr/local/lib/python3.9/sqlite3/dbapi2.py"", line 27, in <module>
    from _sqlite3 import *
ModuleNotFoundError: No module named '_sqlite3'
"
bitcoin/bitcoin,2023-01-02 20:24:44,bug,Bitcoin Core startup is interrupted if there is the setting mintxfee=0 in bitcoin.conf,"**Expected behavior**
It is expected that Bitcoin Core is not shutdown automatically during startup. Moreover, it should be possible to set transaction fee at 0.

**Actual behavior**
![Bitcoin Core Error mintxfee](https://user-images.githubusercontent.com/111286121/210274894-e91adf7f-43f7-4c3f-b799-222c00dc34a0.png)

**To reproduce**

1) Click bitcoin-qt.exe.

**System information**

1) A wallet that contained unspent funds was opened previously.
2) The bitcoin.conf file contains ""mintxfee=0"".
3) Bitcoin Core 24.0.1 official binary for Windows (portable)."
bitcoin/bitcoin,2022-12-30 08:17:28,bug,contrib/install_db4.sh script fails on FreeBSD,"Running `contrib/install_db4.sh` to download and build libdb4 for legacy wallet support fails on FreeBSD.

```
$ ./contrib/install_db4.sh `pwd`
[...]
sha256sum: option requires an argument -- c
usage: sha256sum [-pqrtx] [-c file] [-s string] [files ...]
$
```

This is on FreeBSD 13.1

Fixed by: #26772
"
bitcoin/bitcoin,2022-12-19 01:03:24,bug,Intermittent failure in `tool_wallet.py`,https://cirrus-ci.com/task/5188420082335744?logs=functional_tests#L97
bitcoin/bitcoin,2022-12-17 20:58:32,bug,bitcoind.service: Start request repeated too quickly.,"I'm obtaining the following error when initializing bitcoind service:

```
× bitcoind.service - Bitcoin daemon
     Loaded: loaded (/etc/systemd/system/bitcoind.service; enabled; vendor preset: enabled)
     Active: failed (Result: exit-code) since Sat 2022-12-17 17:48:09 -03; 5min ago
    Process: 1141 ExecStart=/home/satoshi/snap/bitcoin-core/126/bin/bitcoind -daemon -pid=/run/bitcoind/bitcoind.pid -conf=/home/satoshi/sna>
        CPU: 24ms

dez 17 17:48:09 nakamoto systemd[1]: bitcoind.service: Scheduled restart job, restart counter is at 5.
dez 17 17:48:09 nakamoto systemd[1]: Stopped Bitcoin daemon.
dez 17 17:48:09 nakamoto systemd[1]: bitcoind.service: Start request repeated too quickly.
dez 17 17:48:09 nakamoto systemd[1]: bitcoind.service: Failed with result 'exit-code'.
dez 17 17:48:09 nakamoto systemd[1]: Failed to start Bitcoin daemon.
```

bitcoind.service file:

```
# It is not recommended to modify this file in-place, because it will
# be overwritten during package upgrades. If you want to add further
# options or overwrite existing ones then use
# $ systemctl edit bitcoind.service
# See ""man systemd.service"" for details.

# Note that almost all daemon options could be specified in
# /etc/bitcoin/bitcoin.conf, but keep in mind those explicitly
# specified as arguments in ExecStart= will override those in the
# config file.

[Unit]
Description=Bitcoin daemon
After=network.target

[Service]
ExecStart=/home/satoshi/snap/bitcoin-core/126/bin/bitcoind -daemon \\
                            -pid=/run/bitcoind/bitcoind.pid \\
                            -conf=/home/satoshi/snap/bitcoin-core/common/.bitcoin/bitcoin.conf \\
                            -datadir=/home/satoshi/snap/bitcoin-core/common/.bitcoin

# Make sure the config directory is readable by the service user
PermissionsStartOnly=true
#ExecStartPre=/bin/chgrp bitcoin /etc/bitcoin

# Process management
####################

Type=forking
PIDFile=/run/bitcoind/bitcoind.pid
Restart=on-failure
TimeoutStopSec=600

# Directory creation and permissions
####################################

# Run as bitcoin:bitcoin
User=satoshi
Group=satoshi

# /run/bitcoind
RuntimeDirectory=bitcoind
RuntimeDirectoryMode=0710

# /etc/bitcoin
ConfigurationDirectory=bitcoin
ConfigurationDirectoryMode=0710

# /var/lib/bitcoind
StateDirectory=bitcoind
StateDirectoryMode=0710

# Hardening measures
####################

# Provide a private /tmp and /var/tmp.
PrivateTmp=true

# Mount /usr, /boot/ and /etc read-only for the process.
ProtectSystem=full

# Deny access to /home, /root and /run/user
#ProtectHome=true

# Disallow the process and all of its children to gain
# new privileges through execve().
NoNewPrivileges=true

# Use a new /dev namespace only populated with API pseudo devices
# such as /dev/null, /dev/zero and /dev/random.
PrivateDevices=true

# Deny the creation of writable and executable memory mappings.
MemoryDenyWriteExecute=true

[Install]
WantedBy=multi-user.target
```
I've installed bitcoin-core via snap.

Bitcoin Core RPC client version v24.0.1
OS: Ubuntu 22.04.1 LTS x86_64"
bitcoin/bitcoin,2022-12-14 02:00:52,bug,bitcoind v23.0.0: traps: b-scheduler[3227] trap invalid opcode,"<!-- Describe the issue -->
Issue: bitcoind process ended abruptly
<!--- What behavior did you expect? -->
Expected behaviour: bitcoind should continue to run

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->
log output: nothing unusual
terminal output:
`1879 Illegal instruction     (core dumped)`
dmesg output:
`traps: b-scheduler[3227] trap invalid opcode ip:555ad42d5cb2 sp:7efc897f9590 error:0 in bitcoind[555ad3c91000+9b4000]`

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->
Cannot reproduce easily, this happened first time in last 4 years running bitcoind non-stop.

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
$ bitcoin-cli --version
Bitcoin Core RPC client version v23.0.0

Official build from the website, running normally from the user folder. No systemd, no service, but in screen session, in bash loop. Bash loop allows it to automatically restart, so I experienced no downtime, bitcoind has started again automatically.
Full command line bitcoind was running with is:
`/home/user/bitcoin/bitcoin-23.0/bin/bitcoind > /home/user/.bitcoin/logs/2022-11-14_02h04m24s.log 2>&1`
<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
Server-style machine with ECC RAM:
OS: Debian GNU/Linux 11 (bullseye) x86_64
CPU: AMD Ryzen 7 1700 (16) @ 3.000GHz [28.0°C]
RAM: 64GB RAM 2666 MT/s Multi-bit ECC
HDD: Btrfs raid10 mode, 4x 4TB Hard Drives. No issues with Btrfs or drives, all perfectly clean

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->
No GUI, bitcoind running in screen session, logging to a file

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
I could upload entire session debug.log (2.5MiB) on request. bitcoind process was running from 11 November to 13 December then crashed. Log file ends cleanly with no error messages, last few lines are:
```
2022-12-13T17:50:00Z Socks5() connect to xxx.onion:8333 failed: host unreachable
2022-12-13T17:50:44Z connect() to 127.0.0.1:7656 failed after wait: Connection refused (111)
2022-12-13T17:53:14Z connect() to 127.0.0.1:7656 failed after wait: Connection refused (111)
2022-12-13T17:57:22Z UpdateTip: new best=000000000000000000031509b87e82e97a74d09c703ed21ee0a91fd90b5c6656 height=767249 version=0x20a00000 log2_work=93.893910 tx=787817132 date='2022-12-13T17:57:18Z' progress=1.000000 cache=5.6MiB(23274txo)
2022-12-13T17:59:16Z connect() to 127.0.0.1:7656 failed after wait: Connection refused (111)
2022-12-13T17:59:34Z UpdateTip: new best=000000000000000000044c776b362f68b0e645a1d7366e3b50a10a7809af50fc height=767250 version=0x23778000 log2_work=93.893921 tx=787819399 date='2022-12-13T17:59:22Z' progress=1.000000 cache=6.6MiB(31759txo)
```"
bitcoin/bitcoin,2022-12-08 19:48:37,bug,Can't bump fee after abandoning child transaction,"Steps:
1. Send transaction (A) to a different wallet
2. Using the change, create another transaction (B) to a different wallet
3. `abandontransaction` B
4. `bumpfee` A fails with `Transaction has descendants in the wallet`"
bitcoin/bitcoin,2022-12-06 10:43:42,bug,"validation, bugfix: provide more info in *MempoolAcceptResult","This PR fixes a bug and improves the mempool accept interface to return information more predictably.

Bug: In package validation, we first try the transactions individually (see doc/policy/packages.md for more explanation) and, if they all failed for missing inputs and policy-related (i.e. fee) reasons, we'll try package validation. Otherwise, we'll just ""quit early"" since, for example, if a transaction had an invalid signature, adding a child will not help make it valid. Currently, when we quit early, we're not setting the `package_state` to be invalid, so the caller might think it succeeded. Also, we're returning no results - it makes more sense to return the individual transaction failure. Thanks instagibbs for catching https://github.com/bitcoin/bitcoin/pull/25038#discussion_r1013293248!

Also, make the package results interface generally more useful/predictable:
- Always return the feerate at which a transaction was considered for `CheckFeeRate` in `MempoolAcceptResult::m_effective_feerate` when it was successful. This can replace the current `PackageMempoolAcceptResult::m_package_feerate`, which only sometimes exists.
- Always provide an entry for every transaction in `PackageMempoolAcceptResult::m_tx_results` when the error is `PCKG_TX`."
bitcoin/bitcoin,2022-11-30 06:57:47,bug, The BTC module is not working with the latest Magento php 8.1 version ,"Hello Team,
Hope that you are doing well!
We are facing an issue with the BTC modules not working with the latest Magento PHP version 8.1. Kindly please check and let us know on this how we can use the module with PHP version 8.1. 
Looking forward to hearing from you soon. 
Thank you!"
bitcoin/bitcoin,2022-11-27 15:31:03,bug,new bitcoin ddos technique,"**edit**: the issue has been closed while the bug undergoes further review.

hi,

i will keep this concise as the attack is neither innovative nor sophisticated.

it is possible to slow and entirely halt external connections from communicating with a bitcoin-core node.

i don't know whether peer connections remain open or frequently disconnect/reconnect. what happens to sync'd nodes with active peers is yet to be seen. it's too early, at least for me, to know whether peers would drop a node under attack over timeouts and how bitcoind behaves with peers while tcp/8333 is under fire. so - further research required. this needs to be tested against sync'd nodes. there is a dos here - but also a (probably slim) possibility that a scaled attack would only result in new nodes being unable to enter the network.

it is accomplished by repeatedly sending a small request, e.g.

```
x
x


```

with thousands of concurrent socket requests. in this screen shot i'm using a handful of cheap digital ocean machines to attack 1 node.

![corn](https://user-images.githubusercontent.com/38997186/204143252-444fad55-0e03-452a-8fb2-6388710a2955.png)

as the script exhausts itself and finds trouble assigning itself open sockets the ddos becomes hit or miss in external requests. sometimes connecting, usually not connecting, and sometimes producing ""black hole"" events wherein it's impossible to disconnect from an external telnet request until it drops you — which is atypical behavior. the attack works the best within the first 20 seconds of the attack script being launched - and so may require further optimization.

am i missing something? because i'm definitely able to stress my own nodes with this technique. it is my opinion that a botnet could probably tango down the bitcoin network - or at least slow finality considerably.

i've opted for full disclosure for a variety of reasons.

-kev
https://twitter.com/123456"
bitcoin/bitcoin,2022-11-21 22:37:25,bug,test: intermittent failure in rpc_net.py,"See https://github.com/bitcoin/bitcoin/runs/9621443864 (master)

The problem here is is that calling `disconnect_p2ps` waits until `self.num_test_p2p_connections() == 0`.
`num_test_p2p_connections()` checks the field `subver` in `getpeerinfo` to distinguish p2p nodes from full nodes.
However, if we are dealing with a p2p connection that has never sent a version, the node has never received the special subversion and the wait is ineffective (we continue even though the disconnection is not yet completed)."
bitcoin/bitcoin,2022-11-18 14:05:34,bug,Breking in Mac OS,"I'm trying to use bitcoin core on mac OS
I want to record on an external hd

but i get the following error all the time

2022-11-17T22:07:44Z msghand thread exit
2022-11-17T22:07:44Z net thread exit
2022-11-17T22:07:44Z opencon thread exit
2022-11-17T22:07:44Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-17T22:07:44Z ERROR: SerializeFileDB: Failed to flush file /Volumes/Extreme SSD/bitcoin_core/peers.8611
2022-11-17T22:07:44Z DumpAnchors: Flush 2 outbound block-relay-only peer addresses to anchors.dat started
2022-11-17T22:07:44Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-17T22:07:44Z ERROR: SerializeFileDB: Failed to flush file /Volumes/Extreme SSD/bitcoin_core/anchors.ceb3
2022-11-17T22:07:44Z DumpAnchors: Flush 2 outbound block-relay-only peer addresses to anchors.dat completed (0.01s)
2022-11-17T22:07:44Z scheduler thread exit
2022-11-17T22:07:44Z Writing 0 unbroadcast transactions to disk.
2022-11-17T22:07:44Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-17T22:07:44Z Failed to dump mempool: FileCommit failed. Continuing anyway.
2022-11-17T22:07:45Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-17T22:07:45Z ERROR: Flush: failed to commit file 1
2022-11-17T22:07:45Z *** Flushing block file to disk failed. This is likely the result of an I/O error.
2022-11-17T22:07:45Z Error: A fatal internal error occurred, see debug.log for details
2022-11-17T22:07:45Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-17T22:07:45Z ERROR: Flush: failed to commit file 1
2022-11-17T22:07:45Z *** Flushing undo file to disk failed. This is likely the result of an I/O error.
2022-11-17T22:07:45Z Error: A fatal internal error occurred, see debug.log for details
2022-11-17T22:07:46Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-17T22:07:46Z ERROR: Flush: failed to commit file 1
2022-11-17T22:07:46Z *** Flushing block file to disk failed. This is likely the result of an I/O error.
2022-11-17T22:07:46Z Error: A fatal internal error occurred, see debug.log for details
2022-11-17T22:07:46Z FileCommit: fcntl F_FULLFSYNC failed: 25
2022-11-17T22:07:46Z ERROR: Flush: failed to commit file 1
2022-11-17T22:07:46Z *** Flushing undo file to disk failed. This is likely the result of an I/O error.
2022-11-17T22:07:46Z Error: A fatal internal error occurred, see debug.log for details
2022-11-17T22:07:46Z Shutdown: done
"
bitcoin/bitcoin,2022-11-11 13:34:16,bug,macOS reports error on shutdown of GUI,"macOS reports error on shutdown of GUI. ""Bitcoin Core quit unexpectedly..."" Although this may be hardware related , memory and cpu load seem normal (screenshots and logs attached.)

**Expected behavior**

Application closes without error message.

**Actual behavior**

Application quits (and restarts without error or corruption of data) but message persists.

**To reproduce**

The error message seems to persist every time under normal conditions, (closing the application invokes the message ""Bitcoin Core is shutting down, do not shut down the computer until this window has disappeared"" Then opens fine on relaunch.

**System information**

Bitcoin Core           23.0.0
Version:               23.0.0 (23.0.0)
Code Type:             X86-64 (Native)
Parent Process:        launchd [1]

OS Version:            macOS 13.0 (22A380)

[log2022-11-11.txt](https://github.com/bitcoin/bitcoin/files/9990546/log2022-11-11.txt)
<img width=""280"" alt=""Screenshot 2022-11-11 at 20 51 52"" src=""https://user-images.githubusercontent.com/1854925/201350529-5164f0ad-3781-4849-8914-09ddc8f760e2.png"">
<img width=""631"" alt=""Screenshot 2022-11-11 at 21 24 41"" src=""https://user-images.githubusercontent.com/1854925/201350606-918c0588-9f7f-4304-a7eb-fbca54ad3f7f.png"">
<img width=""615"" alt=""Screenshot 2022-11-11 at 21 24 48"" src=""https://user-images.githubusercontent.com/1854925/201350618-3e7d2e65-7fb8-4c7d-9651-a77c0a11b56a.png"">
"
bitcoin/bitcoin,2022-11-06 16:02:38,bug,whitelisting fails for nodes added with addnode,"Whitelisting works for subnets for outgoing and incoming connections, unless the node has been added using addnode, in which case the permissions are always ""N/A"" in the GUI and the node is disconnected as if there is no whitelisting (e.g. when historical block download is reached, or a mempool request comes in, etc)."
bitcoin/bitcoin,2022-11-01 16:51:38,bug,test: failure in interface_rest.py,"https://cirrus-ci.com/task/4924805592907776?logs=functional_tests#L2972
```bash
 test  2022-11-01T13:38:30.771000Z TestFramework (ERROR): Assertion failed 
                                   Traceback (most recent call last):
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\test_framework.py"", line 133, in main
                                       self.run_test()
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\interface_rest.py"", line 103, in run_test
                                       self.sync_all()
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\test_framework.py"", line 715, in sync_all
                                       self.sync_mempools(nodes)
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\test_framework.py"", line 708, in sync_mempools
                                       raise AssertionError(""Mempool sync timed out after {}s:{}"".format(
                                   AssertionError: Mempool sync timed out after 480s:
                                     {'cbd1d27c4d06b4dfd479c34aef4b57d3be14dfc20ccc74f2699fde370f17d1d3'}
                                     set()
 test  2022-11-01T13:38:30.771000Z TestFramework (DEBUG): Closing down network thread 
```"
bitcoin/bitcoin,2022-10-29 12:33:33,bug,Unable to cross compile Zeromq Dependency for arm64-apple-darwin,"<!-- Describe the issue -->

Trying to compile starting with dependencies fails with 

checking build system type... x86_64-pc-linux-gnu
checking host system type... Invalid configuration `arm64-apple-darwin': machine `arm64-apple' not recognized
configure: error: /bin/bash config/config.sub arm64-apple-darwin failed

**Expected behavior**

<!--- What behavior did you expect? -->

**Actual behavior**

checking for arm64-apple-darwin-pkg-config... no
checking for pkg-config... /usr/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for xmlto... no
checking for asciidoc... no
checking build system type... x86_64-pc-linux-gnu
checking host system type... Invalid configuration `arm64-apple-darwin': machine `arm64-apple' not recognized
configure: error: /bin/bash config/config.sub arm64-apple-darwin failed
make: *** [funcs.mk:289: /home/bitcoin/Downloads/bitcoin-master/depends/work/build/arm64-apple-darwin/zeromq/4.3.4-0f6f30942e0/./.stamp_configured] Error 1


**To reproduce**

command : make HOST=arm64-apple-darwin -j 8

**System information**

Master Branch
Ubuntu 20.04 
Core i5 intel 16GB RAM
"
bitcoin/bitcoin,2022-10-28 00:28:00,bug,Instability in `listunspent` after #24699,"I maintain a [wallet](https://github.com/bitcoinhodler/GlacierProtocol/tree/bitcoin-core-24) that uses `bitcoin-cli` for signing transactions, and its test system uses regtest to create a bunch of UTXOs for the signing tests to sign. These tests use a git-committed `wallet.dat` that is copied into the newly-created `datadir` before launching `bitcoind`.

For years, up until bc886fcb31e1afa7bbf7b86bfd93e51da7076ccf (part of #24699), this was stable and worked well. Occasionally I would need to recreate all the transactions when this project changed mining (#24732) or coin selection (#24584) but I could handle that.

What I can't handle is having the generated transactions be different each time I run the exact same sequence of `bitcoin-cli` commands starting from the same `wallet.dat`. Starting with bc886fcb31e1afa7bbf7b86bfd93e51da7076ccf, that's what happens.

Is this a supported use model, or is it unreasonable to expect this to be stable?

Summarizing:
* v0.20.0 -- stable
* v0.21.0 -- stable
* v22.0 -- stable
* v23.0 -- stable
* 272356024db978c92112167f8d8e4cc62adad63d (which is bc886fcb31e1afa7bbf7b86bfd93e51da7076ccf^) -- stable
* bc886fcb31e1afa7bbf7b86bfd93e51da7076ccf -- unstable
* v24.0rc2 -- unstable
* Current master (f37bd15d472fdc7dd3d40cafaba9e8dfddd6b530) -- unstable


<!-- Describe the issue -->

**Expected behavior**

The generated transactions should be identical given an identical series of `bitcoin-cli` calls.

**Actual behavior**

The generated transactions choose different input coins from the regtest blockchain every time I run.

**To reproduce**

In my [Glacier wallet fork](https://github.com/bitcoinhodler/GlacierProtocol/tree/bitcoin-core-24), run `t/online_regtest_wallet.py recreate-all-tests`; git commit the result. Run the same command again -- `git status` should show no changes.

When it's unstable, dozens of files change.

**System information**

Running on Whonix 16. Building inside the git repo as such:
```
(cd depends && make -j4 NO_QT=1) && ./autogen.sh && ./configure --prefix=`pwd`/depends/x86_64-pc-linux-gnu && make -j4
```"
bitcoin/bitcoin,2022-10-25 01:29:38,bug,signrawtransactionwithwallet fails with signed non-wallet inputs and breaks the existing signatures,"The error returned by the RPC is:
`Unable to sign input, invalid stack size (possibly missing key)`

It seems that this rpc alters the scriptSig of all of the inputs that were already signed.

The problem is very similar to https://github.com/bitcoin/bitcoin/issues/21151, which is already solved. 

Here's an example of the broken signatures after signing:
```diff
--- 0_before.txt	2022-10-24 17:46:31.105518559 -0300
+++ 1_after.txt	2022-10-24 17:46:31.146517797 -0300
@@ -1,18 +1,18 @@
 {
-  ""txid"": ""7107a82fd2d783d32e2926bf91b5dea5908203a3d81f8bb67b267f9aeab3c16d"",
-  ""hash"": ""7107a82fd2d783d32e2926bf91b5dea5908203a3d81f8bb67b267f9aeab3c16d"",
+  ""txid"": ""b4b09eebed1f427f7ae80004ca1e55688567bc8e01af7608311c7d0a31ffcf83"",
+  ""hash"": ""685100e81d34140941b3c15af9598e0d2ffdbee92b3706c82561ff2232c94cbc"",
   ""version"": 1,
-  ""size"": 406,
-  ""vsize"": 406,
-  ""weight"": 1624,
+  ""size"": 373,
+  ""vsize"": 291,
+  ""weight"": 1162,
   ""locktime"": 0,
   ""vin"": [
     {
       ""txid"": ""c2afc743b00acb7a9a9cccc9e9b2751f0ae17206a9492dc0537ec72f44c7f6e0"",
       ""vout"": 1,
       ""scriptSig"": {
-        ""asm"": ""0 30440220201b3d70770c2b325c8cac16593a4606cdcb29c094f67ec700d6aaadfdcc3bdf022057b70804b24d66664f1a82f7936773fbc3bcb15740a0e7b772ddf7bfe486b6fe[SINGLE|ANYONECANPAY] 3044022034eaf58c896885fc1597a848d268ad618e621b33be77bed67bcfa6180611ac31022073f947c7d2ebd81c1d52236030dd1a5d6b178c9361786ff9d6d3ef9740be1c76[SINGLE|ANYONECANPAY] 522103d28e83bfc9d2ab30f26f7b62ac4b64a932272ba124c6c4d29e901eaf8724aab7210366dc61fb53bce09777fe7c4766a55af9649cc26deb21b204ae6bf4e93413a46c2102439d6a6bc199460e4e0a6e5fdcb87162cafa5cae6ee4845d23d9dc5e840ffdb153ae"",
-        ""hex"": ""004730440220201b3d70770c2b325c8cac16593a4606cdcb29c094f67ec700d6aaadfdcc3bdf022057b70804b24d66664f1a82f7936773fbc3bcb15740a0e7b772ddf7bfe486b6fe83473044022034eaf58c896885fc1597a848d268ad618e621b33be77bed67bcfa6180611ac31022073f947c7d2ebd81c1d52236030dd1a5d6b178c9361786ff9d6d3ef9740be1c76834c69522103d28e83bfc9d2ab30f26f7b62ac4b64a932272ba124c6c4d29e901eaf8724aab7210366dc61fb53bce09777fe7c4766a55af9649cc26deb21b204ae6bf4e93413a46c2102439d6a6bc199460e4e0a6e5fdcb87162cafa5cae6ee4845d23d9dc5e840ffdb153ae""
+        ""asm"": ""0 0 522103d28e83bfc9d2ab30f26f7b62ac4b64a932272ba124c6c4d29e901eaf8724aab7210366dc61fb53bce09777fe7c4766a55af9649cc26deb21b204ae6bf4e93413a46c2102439d6a6bc199460e4e0a6e5fdcb87162cafa5cae6ee4845d23d9dc5e840ffdb153ae"",
+        ""hex"": ""00004c69522103d28e83bfc9d2ab30f26f7b62ac4b64a932272ba124c6c4d29e901eaf8724aab7210366dc61fb53bce09777fe7c4766a55af9649cc26deb21b204ae6bf4e93413a46c2102439d6a6bc199460e4e0a6e5fdcb87162cafa5cae6ee4845d23d9dc5e840ffdb153ae""
       },
       ""sequence"": 0
     },
@@ -23,6 +23,10 @@
         ""asm"": """",
         ""hex"": """"
       },
+      ""txinwitness"": [
+        ""304402202dc3e510dc053dcdd29be701441337c93f6923686cc5ba4a915dbc17073dd26c02207aa8b76a447bde52b4cb1146781745826692d4484327f2a78a73818183e5f37f01"",
+        ""0379d702db49e91dd63127278c06ed99ef05b43d15f2583bb28b4f0e9b49b9f50c""
+      ],
       ""sequence"": 0
     }
   ],
```

I've prepared a bash script that reproduces it (I used hal to merge the transactions):
```bash
#!/bin/bash

#set -x
set -e

shopt -s expand_aliases
alias b-dae=""~/opt/bitcoin/bin/bitcoind -datadir=$PWD -daemon=1""
alias b-cli=""~/opt/bitcoin/bin/bitcoin-cli -datadir=$PWD""

declare -a privkeys
declare -a pubkeys
declare -a multisigs
declare -a addresses
declare -a redeemScripts
declare -a txs
declare -a scriptPubKeys
declare -a vouts
declare -a mergetxs

#parameters for the multisig addreesses
addresstype=legacy
multisig_n=2
multisig_m=3
multisig_count=1
#create the keypairs
for i in $(seq 0 $((multisig_count * multisig_m - 1)));do
    KEYPAIR=$(hal key generate --regtest 2>/dev/null)
    privkeys[$i]=$(echo $KEYPAIR | jq -r .wif_private_key)
    pubkeys[$i]=$(echo $KEYPAIR | jq -r .public_key)
done

b-cli stop && sleep 5 || true
rm -rf regtest
b-dae
b-cli -rpcwait createwallet """"
echo

#create the multisig addresses
for i in $(seq 0 $((multisig_count - 1)));do
    mspubkeys='['
    sep=
    for j in $(seq $((i * multisig_m)) $((i * multisig_m + multisig_m -1)));do
        mspubkeys+=""$sep\\""${pubkeys[$j]}\\""""
        sep=','
    done
    mspubkeys+=']'
    echo b-cli createmultisig ${multisig_n} ""${mspubkeys}"" $addresstype
    multisigs[$i]=$(b-cli -rpcwait createmultisig ${multisig_n} ""${mspubkeys}"" $addresstype)
    addresses[$i]=$(echo ""${multisigs[$i]}"" | jq -r '.address')
    redeemScripts[$i]=$(echo ""${multisigs[$i]}"" | jq -r '.redeemScript')
done

echo ""pubkeys: ${pubkeys[@]}""
echo ""privkeys: ${privkeys[@]}""
#generate enough blocks to unlock the reward
DEST=$(b-cli getnewaddress)
b-cli generatetoaddress 101 $DEST >/dev/null 2>&1
#send 1 btc to each multisig address
for i in $(seq 0 $((multisig_count - 1)));do
    txs[$i]=$(b-cli sendtoaddress ""${addresses[$i]}"" 1)
    scriptPubKeys[$i]=$(b-cli decoderawtransaction $(b-cli getrawtransaction ${txs[$i]})| jq -r "".vout[] .scriptPubKey | select(.address == \\""${addresses[$i]}\\"") .hex"")
    vouts[$i]=$(b-cli decoderawtransaction $(b-cli getrawtransaction ${txs[$i]})| jq -r "".vout[] | select(.scriptPubKey.address == \\""${addresses[$i]}\\"") .n"")
    #echo ${txs[$i]} ${scriptPubKeys[$i]}
    b-cli generatetoaddress 1 $DEST >/dev/null 2>&1
done
echo

#each multisig sends its coins to a new wallet (destwallet) and signs the transaction using signrawtransactionwithkey
echo createwallet destwallet
b-cli createwallet destwallet
destaddress=$(b-cli -rpcwallet=destwallet getnewaddress)
echo unloadwallet destwallet
b-cli unloadwallet destwallet
for i in $(seq 0 $((multisig_count - 1)));do
    echo ""Sending utxo ${txs[$i]} to final address $destaddress""
    tx=$(b-cli createrawtransaction ""[{\\""txid\\"":\\""${txs[$i]}\\"",\\""vout\\"":${vouts[$i]}}]"" ""[{\\""$destaddress\\"":1}]"")

    prevtxs=""[{\\""txid\\"":\\""${txs[$i]}\\"",\\""vout\\"":${vouts[$i]},\\""scriptPubKey\\"":\\""${scriptPubKeys[$i]}\\"",\\""redeemScript\\"":\\""${redeemScripts[$i]}\\"",\\""amount\\"":1}]""
    #sign with keys one by one
    for j in $(seq $((i * multisig_m)) $((i * multisig_m + multisig_n - 1)));do
        tx=$(b-cli signrawtransactionwithkey $tx ""[\\""${privkeys[$j]}\\""]"" ""$prevtxs"" ""SINGLE|ANYONECANPAY"")
        tx=$(echo $tx|jq -r '.hex')
    done
    mergetxs[$i]=$tx
done
echo

finalinputs=""""
finaloutputs=""""

#create the transaction to provide the funds to pay for the previous transactions
fee_input=$(b-cli listunspent|jq -r '.[0]')
fee_input_amount=$(echo $fee_input|jq -r '.amount')
fee=0.0001
change_amount=$(bc -l <<< ""$fee_input_amount - $fee"")
changeaddress=$(b-cli getnewaddress)
change_tx=$(b-cli createrawtransaction ""[$fee_input]"" ""[{\\""$changeaddress\\"":$change_amount}]"")
mergetxs[$multisig_count]=$change_tx

sepin=""""
sepout=""""

#prepare a Json with the inputs, and another one with the outputs
for i in $(seq 0 $((multisig_count)));do
    decodedtx=$(hal tx decode ${mergetxs[$i]})
    inputno=$(echo $decodedtx| jq -r "".inputs | length -1"")
    for k in $(seq 0 $inputno);do
        input=$(echo $decodedtx| jq -r "".inputs[$k] | del(.sequence)"")
        finalinputs+=""$sepin$input""
        sepin="",""
    done
    outputno=$(echo $decodedtx| jq -r "".outputs | length -1"")
    for k in $(seq 0 $outputno);do
        output=$(echo $decodedtx| jq -r "".outputs[$k] | del(.n)"")
        finaloutputs+=""$sepout$output""
        sepout="",""
    done
done

fulltx=""
{
  \\""version\\"": 1,
  \\""locktime\\"": 0,
  \\""inputs\\"": [ $finalinputs ],
  \\""outputs\\"": [ $finaloutputs ]
}
""
echo $fulltx|jq >fulltx.txt

#create the transaction with all the inputs and outpts, and sign it using signrawtransactionwithwallet (fails...)
finaltx=$(echo $fulltx|jq|hal tx create 2>/dev/null)
b-cli decoderawtransaction $finaltx >0_before.txt
echo ""tx BEFORE signrawtransactionwithwallet: $finaltx""
signedfinaltx=$(b-cli signrawtransactionwithwallet $finaltx)
echo ""tx AFTER signrawtransactionwithwallet: $(echo $signedfinaltx|jq -r '.hex')""
b-cli decoderawtransaction $(echo $signedfinaltx|jq -r '.hex') >1_after.txt
diff -Naurwp 0_before.txt 1_after.txt >0.diff || true
signerror=$(echo $signedfinaltx|jq -r '.errors[0].error//empty')
if [ -n ""$signerror"" ];then
    echo ""Error signing with wallet ($signerror)""
    exit -1
fi

senttx=$(b-cli sendrawtransaction $(echo $signedfinaltx|jq -r '.hex'))
b-cli gettransaction $senttx
b-cli generatetoaddress 1 $DEST >/dev/null 2>&1
b-cli gettransaction $senttx
```
I've tested with Bitcoin Core 23.0.
Please let me know if there's anything else I can test."
bitcoin/bitcoin,2022-10-21 14:40:04,bug,Intermitted failure in p2p_sendtxrcncl.py,"I have seen `p2p_sendtxrcncl.py` fail randomly multiple times by now, e.g. : https://cirrus-ci.com/task/5513760365346816?logs=functional_tests. Also noted here: https://github.com/bitcoin/bitcoin/pull/23443#issuecomment-1281180599.

Log:

```
 node0 2022-10-21T14:09:17.893264Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\node\\txreconciliation.cpp:87] [PreRegisterPeer] [txreconciliation:debug] Pre-register peer=8 
 node0 2022-10-21T14:09:17.893346Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:2775] [PushMessage] [net] sending sendtxrcncl (14 bytes) peer=8 
 node0 2022-10-21T14:09:17.893450Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:2775] [PushMessage] [net] sending verack (0 bytes) peer=8 
 node0 2022-10-21T14:09:17.893570Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net_processing.cpp:3363] [ProcessMessage] [net] receive version message: /python-p2p-tester:0.0.3/: version 70016, blocks=-1, us=127.0.0.1:14312, txrelay=1, peer=8 
 node0 2022-10-21T14:09:17.893649Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net_processing.cpp:3146] [ProcessMessage] [net] received: verack (0 bytes) peer=8 
 node0 2022-10-21T14:09:17.893703Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:2775] [PushMessage] [net] sending sendcmpct (9 bytes) peer=8 
 node0 2022-10-21T14:09:17.893811Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\node\\txreconciliation.cpp:145] [ForgetPeer] [txreconciliation:debug] Forget txreconciliation state of peer=8 
 node0 2022-10-21T14:09:17.893898Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:2775] [PushMessage] [net] sending ping (8 bytes) peer=8 
 node0 2022-10-21T14:09:17.894111Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:2775] [PushMessage] [net] sending getheaders (645 bytes) peer=8 
 node0 2022-10-21T14:09:17.894243Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net_processing.cpp:5413] [SendMessages] [net] initial getheaders (199) to peer=8 (startheight:-1) 
 node0 2022-10-21T14:09:17.894355Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:2775] [PushMessage] [net] sending feefilter (8 bytes) peer=8 
 node0 2022-10-21T14:09:17.894489Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net_processing.cpp:3146] [ProcessMessage] [net] received: ping (8 bytes) peer=8 
 node0 2022-10-21T14:09:17.894554Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:2775] [PushMessage] [net] sending pong (8 bytes) peer=8 
 node0 2022-10-21T14:09:17.894682Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net_processing.cpp:3146] [ProcessMessage] [net] received: wtxidrelay (0 bytes) peer=8 
 node0 2022-10-21T14:09:17.894740Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net_processing.cpp:3460] [ProcessMessage] [net] wtxidrelay received after verack from peer=8; disconnecting 
 test  2022-10-21T14:09:17.954000Z TestFramework.p2p (DEBUG): Closed connection to: 127.0.0.1:14312 
 node0 2022-10-21T14:09:17.954581Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net.cpp:572] [CloseSocketDisconnect] [net] disconnecting peer=8 
 node0 2022-10-21T14:09:17.954849Z [C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\src\\net_processing.cpp:1528] [FinalizeNode] [net] Cleared nodestate for peer=8 
 test  2022-10-21T14:09:17.970000Z TestFramework (ERROR): Assertion failed 
                                   Traceback (most recent call last):
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\test_framework.py"", line 133, in main
                                       self.run_test()
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\p2p_sendtxrcncl.py"", line 138, in run_test
                                       peer.send_and_ping(msg_verack())
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\p2p.py"", line 553, in send_and_ping
                                       self.sync_with_ping(timeout=timeout)
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\p2p.py"", line 570, in sync_with_ping
                                       self.wait_until(test_function, timeout=timeout)
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\p2p.py"", line 463, in wait_until
                                       wait_until_helper(test_function, timeout=timeout, lock=p2p_lock, timeout_factor=self.timeout_factor)
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\util.py"", line 267, in wait_until_helper
                                       if predicate():
                                     File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\p2p.py"", line 460, in test_function
                                       assert self.is_connected
                                   AssertionError
```"
bitcoin/bitcoin,2022-10-19 15:55:53,bug,bitcoin-qt crashed after completing a full blockchain rescan,"While investigating #26317 I tried running:

    $ bitcoin-cli rescanblockchain

to rescan the full blockchain. It took about 9 hours to run the full rescan, and after the scan was complete bitcoin-qt crashed with this error in gdb:

    Thread 35 ""b-http"" received signal SIGPIPE, Broken pipe.

The end of the debug.log file showed this at the time of the crash:

    2022-10-19T09:15:07Z [chris] Still rescanning. At block 758431. Progress=0.997985
    2022-10-19T09:16:07Z [chris] Still rescanning. At block 759032. Progress=0.999291
    2022-10-19T09:16:39Z [chris] Scanning current mempool transactions.
    2022-10-19T09:16:39Z [chris] Rescan completed in        34260150ms

I posted the full backtraces in https://github.com/bitcoin/bitcoin/issues/26317#issuecomment-1284079889 before making a separate report for this crash.

This was bitcoin-qt built from git tag `v24.0rc1` on Debian Linux, running on Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz with SSD hard drives."
bitcoin/bitcoin,2022-10-18 08:29:49,bug,test: Intermittent failure in `feature_index_prune.py`,"https://cirrus-ci.com/task/5021369209978880
https://cirrus-ci.com/task/6533221721571328
https://cirrus-ci.com/task/5355957631320064"
bitcoin/bitcoin,2022-10-15 18:16:28,bug,`scanblocks` RPC result includes false-positives,"The recently introduced `scanblocks` RPC uses BIP157 block filters for quickly determining which blocks contain a specified set of output scripts. By nature this can lead to false-positive results, i.e. the filter set matches the block filter even though none of the contained txs spend or create UTXOs with the specified set of scriptPubKeys.

Can be reproduced on testnet with address `tb1qcxf2gv93c26s6mqz7y6etpqdf70zmn67dualgr` :

```
$ ./src/bitcoin-cli -testnet scanblocks start '[""addr(tb1qcxf2gv93c26s6mqz7y6etpqdf70zmn67dualgr)""]'
{
  ""from_height"": 0,
  ""to_height"": 2375004,
  ""relevant_blocks"": [
    ""000000000001bc35077dec4104e0ab1f667ae27059bd907f9a8fac55c802ae36"",
    ""00000000000120a9c50542d73248fb7c37640c252850f0cf273134ad9febaf61"",
    ""0000000000000082f7af3835da8b6146b0bfb243b8842f09c495fa1e74d454ed"",
    ""0000000000000094c32651728193bfbe91f6789683b8d6ac6ae2d22ebd3cb5d3""
  ],
  ""completed"": true
}
```

Looking closer at the first returned block 000000000001bc35077dec4104e0ab1f667ae27059bd907f9a8fac55c802ae36 (https://mempool.space/de/testnet/address/tb1qcxf2gv93c26s6mqz7y6etpqdf70zmn67dualgr), one can see that the contained single (coinbase) transaction is not related to the passed address:

```
$ ./src/bitcoin-cli -testnet getblock 000000000001bc35077dec4104e0ab1f667ae27059bd907f9a8fac55c802ae36 3
...
      ""vout"": [
        {
          ""value"": 12.50000000,
          ""n"": 0,
          ""scriptPubKey"": {
            ""asm"": ""OP_DUP OP_HASH160 ad0050c5a24b9496e34e34410f35c735f66584ca OP_EQUALVERIFY OP_CHECKSIG"",
            ""desc"": ""addr(mwHhaAQuafCYjJocy6qEzRg6sBLT6KCdaB)#shkcfhzk"",
            ""hex"": ""76a914ad0050c5a24b9496e34e34410f35c735f66584ca88ac"",
            ""address"": ""mwHhaAQuafCYjJocy6qEzRg6sBLT6KCdaB"",
            ""type"": ""pubkeyhash""
          }
        }
      ],
...
```

It might make sense to introduce an option that actives a second pass phase in which the found
blocks are inspected in order to filter out these false-positives.

I guess it is debatable if this can really be considered a bug (in practice it shouldn't be a problem),
but at the very least we should mention the possibility of false-positives in the RPC help to not confuse users."
bitcoin/bitcoin,2022-10-13 18:43:28,bug,add lock annotation for FeeFilterRounder::round(),"CI failure from #24407: https://github.com/bitcoin/bitcoin/runs/8876014446

Calling `WITH_LOCK()` on a non-recursive mutex requires not holding it beforehand."
bitcoin/bitcoin,2022-10-06 16:16:46,bug,bitcoind dumps core when deriveaddresses is called with index 2147483647 (2^31-1),"The `deriveaddresses` JSON-RPC endpoint accepts a descriptor and an index for the derivation.

Currently, the RPC interface caps the allowed index derivation range in the interval [0,2^31-1].

However, calling `deriveaddresses` using a range that includes the index `2147483647` (2^31-1) results in a crash of bitcoind (on an AMD64 machine):

```
bitcoin-cli deriveaddresses ""descriptor"" ""[2147483647, 2147483647]""

[bitcoind dumps core]
```

In the PR that addresses this pull request (#26275) is included a test case that causes the crash.
For convenience, here's the contents of a core dump generated with that test:

```
$ sudo coredumpctl debug bitcoind
           PID: 110184 (bitcoind)
           UID: 1000 (muxator)
           GID: 1000 (muxator)
        Signal: 6 (ABRT)
     Timestamp: Thu 2022-10-06 17:48:08 CEST (4min 56s ago)
  Command Line: <base>/src/bitcoind -datadir=/tmp/test_runner_₿_🏃_20221006_174805/rpc_deriveaddresses_crash_0/node0 -logtimemicros -debug -debugexclude=libevent -debugexclude=leveldb -uacomment=testnode0 -logthreadnames -logsourcelocations -loglevel=trace -sandbox=log-and-abort
    Executable: <base>/src/bitcoind
[...]
    Message: Process 110184 (bitcoind) of user 1000 dumped core.

[...]
                ELF object binary architecture: AMD x86-64

GNU gdb (GDB) Fedora 12.1-1.fc36
[...]
Core was generated by `<base>/src/bitcoind -datadir=/tmp/test_runner_₿_��'.
Program terminated with signal SIGABRT, Aborted.
#0  0x00007f55a8ac6c4c in __pthread_kill_implementation () from /lib64/libc.so.6
[Current thread is 1 (Thread 0x7f5576ffd640 (LWP 110197))]
Missing separate debuginfos, use: dnf debuginfo-install glibc-2.35-17.fc36.x86_64 libevent-2.1.12-6.fc36.x86_64 libgcc-12.2.1-2.fc36.x86_64 libstdc++-12.2.1-2.fc36.x86_64 sqlite-libs-3.36.0-5.fc36.x86_64 zlib-1.2.11-33.fc36.x86_64
(gdb) bt
#0  0x00007f55a8ac6c4c in __pthread_kill_implementation () from /lib64/libc.so.6
#1  0x00007f55a8a769c6 in raise () from /lib64/libc.so.6
#2  0x00007f55a8a607f4 in abort () from /lib64/libc.so.6
#3  0x00007f55a8c40c11 in __addvsi3 () from /lib64/libgcc_s.so.1
#4  0x0000563935a84d73 in operator() (__closure=0x7f5576ffbd50, self=..., request=...) at rpc/output_script.cpp:276
#5  0x0000563935a87ec2 in std::__invoke_impl<UniValue, deriveaddresses()::<lambda(const RPCHelpMan&, const JSONRPCRequest&)>&, const RPCHelpMan&, const JSONRPCRequest&>(std::__invoke_other, struct {...} &) (__f=...)
    at /usr/include/c++/12/bits/invoke.h:61
#6  0x0000563935a8773f in std::__invoke_r<UniValue, deriveaddresses()::<lambda(const RPCHelpMan&, const JSONRPCRequest&)>&, const RPCHelpMan&, const JSONRPCRequest&>(struct {...} &) (__fn=...) at /usr/include/c++/12/bits/invoke.h:116
#7  0x0000563935a86ec3 in std::_Function_handler<UniValue(const RPCHelpMan&, const JSONRPCRequest&), deriveaddresses()::<lambda(const RPCHelpMan&, const JSONRPCRequest&)> >::_M_invoke(const std::_Any_data &, const RPCHelpMan &, const JSONRPCRequest &) (__functor=..., __args#0=..., __args#1=...) at /usr/include/c++/12/bits/std_function.h:291
#8  0x00005639360b4641 in std::function<UniValue (RPCHelpMan const&, JSONRPCRequest const&)>::operator()(RPCHelpMan const&, JSONRPCRequest const&) const (this=0x7f5576ffbd50, __args#0=..., __args#1=...)
    at /usr/include/c++/12/bits/std_function.h:591
#9  0x00005639360a93b8 in RPCHelpMan::HandleRequest (this=0x7f5576ffbd30, request=...) at rpc/util.cpp:585
#10 0x00005639359cc1a2 in CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}::operator()(JSONRPCRequest const&, UniValue&, bool) const (__closure=0x5639368fbb00 <RegisterOutputScriptRPCCommands(CRPCTable&)::commands+320>, request=..., result=...) at ./rpc/server.h:109
#11 0x00005639359e0be3 in std::__invoke_impl<bool, CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool>(std::__invoke_other, CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool&&) (__f=...) at /usr/include/c++/12/bits/invoke.h:61
#12 0x00005639359da9ba in std::__invoke_r<bool, CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool>(CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}&, JSONRPCRequest const&, UniValue&, bool&&) (__fn=...) at /usr/include/c++/12/bits/invoke.h:114
#13 0x00005639359d4916 in std::_Function_handler<bool (JSONRPCRequest const&, UniValue&, bool), CRPCCommand::CRPCCommand(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RPCHelpMan (*)())::{lambda(JSONRPCRequest const&, UniValue&, bool)#1}>::_M_invoke(std::_Any_data const&, JSONRPCRequest const&, UniValue&, bool&&) (__functor=..., __args#0=..., __args#1=..., __args#2=@0x7f5576ffbf44: true) at /usr/include/c++/12/bits/std_function.h:290
#14 0x00005639359302c6 in std::function<bool (JSONRPCRequest const&, UniValue&, bool)>::operator()(JSONRPCRequest const&, UniValue&, bool) const (this=0x5639368fbb00 <RegisterOutputScriptRPCCommands(CRPCTable&)::commands+320>,
    __args#0=..., __args#1=..., __args#2=true) at /usr/include/c++/12/bits/std_function.h:591
#15 0x0000563935b0afd5 in ExecuteCommand (command=..., request=..., result=..., last_handler=true) at rpc/server.cpp:475
#16 0x0000563935b0abae in ExecuteCommands (commands=std::vector of length 1, capacity 1 = {...}, request=..., result=...) at rpc/server.cpp:440
#17 0x0000563935b0ad52 in CRPCTable::execute (this=0x5639368fc4c0 <tableRPC>, request=...) at rpc/server.cpp:460
#18 0x0000563935cbe3f5 in HTTPReq_JSONRPC (context=std::any containing node::NodeContext * = {...}, req=0x7f556c002da0) at httprpc.cpp:201
#19 0x0000563935cc0548 in operator() (__closure=0x7f556c001980, req=0x7f556c002da0) at httprpc.cpp:300
#20 0x0000563935cc1c3a in std::__invoke_impl<bool, StartHTTPRPC(const std::any&)::<lambda(HTTPRequest*, const std::string&)>&, HTTPRequest*, const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__invoke_other, struct {...} &) (__f=...) at /usr/include/c++/12/bits/invoke.h:61
#21 0x0000563935cc1a78 in std::__invoke_r<bool, StartHTTPRPC(const std::any&)::<lambda(HTTPRequest*, const std::string&)>&, HTTPRequest*, const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(struct {...} &) (__fn=...) at /usr/include/c++/12/bits/invoke.h:114
#22 0x0000563935cc182e in std::_Function_handler<bool(HTTPRequest*, const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&), StartHTTPRPC(const std::any&)::<lambda(HTTPRequest*, const std::string&)> >::_M_invoke(const std::_Any_data &, HTTPRequest *&&, const std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > &) (__functor=..., __args#0=@0x7f5576ffcb80: 0x7f556c002da0, __args#1="""")
    at /usr/include/c++/12/bits/std_function.h:290
#23 0x0000563935cd1c0c in std::function<bool (HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>::operator()(HTTPRequest*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const (this=0x7f556c003fb0, __args#0=0x7f556c002da0, __args#1="""") at /usr/include/c++/12/bits/std_function.h:591
#24 0x0000563935cd0fc2 in HTTPWorkItem::operator() (this=0x7f556c003f80) at httpserver.cpp:56
#25 0x0000563935cd326d in WorkQueue<HTTPClosure>::Run (this=0x563938765d10) at httpserver.cpp:111
#26 0x0000563935ccbf1d in HTTPWorkQueueRun (queue=0x563938765d10, worker_num=3) at httpserver.cpp:343
#27 0x0000563935cdfd51 in std::__invoke_impl<void, void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> (__f=@0x56393877e7f8: 0x563935ccbeb2 <HTTPWorkQueueRun(WorkQueue<HTTPClosure>*, int)>)
    at /usr/include/c++/12/bits/invoke.h:61
#28 0x0000563935cdfaaa in std::__invoke<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> (__fn=@0x56393877e7f8: 0x563935ccbeb2 <HTTPWorkQueueRun(WorkQueue<HTTPClosure>*, int)>)
    at /usr/include/c++/12/bits/invoke.h:96
#29 0x0000563935cdf8a6 in std::thread::_Invoker<std::tuple<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> >::_M_invoke<0ul, 1ul, 2ul> (this=0x56393877e7e8) at /usr/include/c++/12/bits/std_thread.h:252
#30 0x0000563935cdf7db in std::thread::_Invoker<std::tuple<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> >::operator() (this=0x56393877e7e8) at /usr/include/c++/12/bits/std_thread.h:259
#31 0x0000563935cdf60f in std::thread::_State_impl<std::thread::_Invoker<std::tuple<void (*)(WorkQueue<HTTPClosure>*, int), WorkQueue<HTTPClosure>*, int> > >::_M_run (this=0x56393877e7e0) at /usr/include/c++/12/bits/std_thread.h:210
#32 0x00007f55a8e15b03 in execute_native_thread_routine () from /lib64/libstdc++.so.6
#33 0x00007f55a8ac4e2d in start_thread () from /lib64/libc.so.6
#34 0x00007f55a8b4a1b0 in clone3 () from /lib64/libc.so.6
```

The affected code seems to be in frame 4, and corresponds to the following code:

```
(gdb) frame 4
#4  0x0000563935a84d73 in operator() (__closure=0x7f5576ffbd50, self=..., request=...) at rpc/output_script.cpp:276
276                 for (int i = range_begin; i <= range_end; ++i) {
```

I think the reason is that, while `range_begin` and `range_end` are `uint64_t`, `i` is an `int`, which on many platforms means `int32_t`.
When `i` is assigned `2^31-1` and is then incremented, it wraps back and causes the crash.
"
bitcoin/bitcoin,2022-10-03 06:23:41,bug,wallet/spend.cpp assertion error,"<!-- This issue tracker is only for technical issues related to Bitcoin Core.

General bitcoin questions and/or support requests are best directed to the Bitcoin StackExchange at https://bitcoin.stackexchange.com.

For reporting security issues, please read instructions at https://bitcoincore.org/en/contact/.

If the node is ""stuck"" during sync or giving ""block checksum mismatch"" errors, please ensure your hardware is stable by running memtest and observe CPU temperature with a load-test tool such as linpack before creating an issue! -->

<!-- Describe the issue -->

Bitcoind fails to determine a fee rate which ends up crashing

<!--- What behavior did you expect? -->

RPC method `sentoaddress` should work as intended and properly calculate the fee.

<!--- What was the actual behavior (provide screenshots if the issue is GUI-related)? -->

It throws and error and exits bitcoind

```
2022-10-03T03:19:42Z FeeEst: 48 > 85% decay 0.99520: feerate: 1000 from (0 - 1000) 99.11% 3063.7/(3067.7 0 mem 23.6 out) Fail: (-1 - -1) 0.00% 0.0/(0.0 0 mem 0.0 out)
2022-10-03T03:19:42Z FeeEst: 12 > 85% decay 0.96200: feerate: 1000 from (0 - 1000) 97.41% 331.8/(340.6 0 mem 0.0 out) Fail: (-1 - -1) 0.00% 0.0/(0.0 0 mem 0.0 out)
2022-10-03T03:19:42Z FeeEst: 612 > 95% decay 0.99931: feerate: 1000 from (0 - 1000) 100.00% 9445.0/(9445.0 0 mem 0.0 out) Fail: (-1 - -1) 0.00% 0.0/(0.0 0 mem 0.0 out)
bitcoind: wallet/spend.cpp:783: bool CWallet::CreateTransactionInternal(const std::vector<CRecipient>&, CTransactionRef&, CAmount&, int&, bilingual_str&, const CCoinControl&, FeeCalculation&, bool): Assertion `coin_selection_params.m_subtract_fee_outputs || fee_needed <= change_and_fee - change_amount' failed.
Aborted (core dumped)
```

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->

Can't reproduce, the error is seemingly random.

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

22.0

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

Windows 11 WSL Linux Ubuntu 20.04
Ryzen 9 5950X
64 GB RAM

<!-- GUI-related issue? What is your operating system and its version? If Linux, what is your desktop environment and graphical shell? -->

<!-- Any extra information that might be useful in the debugging process. -->
<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
"
bitcoin/bitcoin,2022-09-26 21:05:26,bug,`bitcoind` and `bitcoin-qt` crashes while creating PSBT,"`bitcoind` and `bitcoin-qt` crashes when creating a PSBT with `walletcreatefundedpsbt`

**Expected behavior**

`bitcoind` and `bitcoin-qt` should not crash and users should not see assertion errors on mainnet. Failing gracefully with some error message would be better. Although I was not able to reproduce this issue on Fedora so ideally this should be fixed.

**Actual behavior**

Error in bitcoind:

```
Assertion failed: selected_effective_value >= target, file wallet/coinselection.cpp, line 391
```

Error in bitcoin-qt:

![image](https://user-images.githubusercontent.com/94559964/192375828-d8e6f628-f52c-4aa8-ae99-19c2fe1a4934.png)


**To reproduce**

1. Create bitcoin.conf 

```
signet=1
txindex=1

signet.rpcport=38332
rpcuser=user
rpcpassword=pass

fallbackfee=0.0004
```

2. Add descriptor in a wallet using bitcoin-qt console:


```
importmulti '[{ ""desc"": ""sh(multi(2,[aa130fed]02de62833c851509cf13c0c63e0dc3ef7b74f7d86b17e9090fab68c09830cb2f2e,[00890d8d]03cf11a2bc1371dad3691bce59e37d85b12aae6b030b533d4e7c5aedeb47a5ec0e))#j8w6g6zg"", ""timestamp"":""now""}]'
```

3. Create PSBT using bitcoin-qt, click on different options in the error message and you will notice it creates PSBT with no change by clicking 'ignore' 3 times else crashes with others:

```
walletcreatefundedpsbt ""[{\\""txid\\"":\\""e911734bf711009dd6057c88bc598df2d31c18d1cc6bd6c790a704b519d77e68\\"",\\""vout\\"":0}]"" ""[{\\""tb1q9fxp2p0sm93jdlul8v3svzn7x69zcd9ljsgans\\"":\\""0.0009\\""}]""

```

4. Close bitcoin-qt and open powershell or command prompt to create PSBT:

```
bitcoind.exe
````

```
bitcoin-cli.exe -rpcwallet=M1 walletcreatefundedpsbt ""[{\\""txid\\"":\\""e911734bf711009dd6057c88bc598df2d31c18d1cc6bd6c790a704b519d77e68\\"",\\""vout\\"":0}]"" ""[{\\""tb1q9fxp2p0sm93jdlul8v3svzn7x69zcd9ljsgans\\"":\\""0.0009\\""}]""
```

**System information**

Windows 10

Bitcoin Core Master Branch

"
bitcoin/bitcoin,2022-09-23 17:52:29,bug,CI: Old versions of git can't handle merges,"It appears git versions older than 2.33 can't handle some simple merges, and many of our CI tasks use such old versions.

The simplest fix is probably to just use GitHub's generated merge branch rather than trying to merge in each CI instance, but I haven't tested it."
bitcoin/bitcoin,2022-09-16 11:22:52,bug,ci ERROR: Commit: Failed to commit latest coinstatsindex state,"This error happened in a push in https://github.com/bitcoin/bitcoin/pull/24897

I pushed the code again `git commit --amend` and didn't happen.
It seems to be intermittent.

https://cirrus-ci.com/task/6073485217759232?logs=ci#L3237

```
2022-09-15T14:46:12.481366Z (mocktime: 2020-08-31T15:34:12Z) [coinstatsindex] [util/system.h:50] [error] ERROR: Commit: Failed to commit latest coinstatsindex state
...
SUMMARY: ThreadSanitizer: data race on vptr (ctor/dtor vs virtual call) src/index/base.cpp:69:1 in BaseIndex::~BaseIndex()
```"
bitcoin/bitcoin,2022-09-12 20:27:03,bug,test: failure in wallet_resendwallettransactions.py,https://cirrus-ci.com/task/5603470202896384?logs=ci#L2681
bitcoin/bitcoin,2022-09-11 12:56:40,bug,I2P: Transient destinations should be SIGNATURE_TYPE=7,https://github.com/bitcoin/bitcoin/commit/2b781ad66e34000037f589c71366c203255ed058#r83655059
bitcoin/bitcoin,2022-09-07 07:58:17,bug,Don't assume signature grinding for external signers,"Since #13666 our fee calculation assumes that ECSDA signatures are a maximum of 71 bytes, rather than 72. However, not all hardware wallets implement R-value grinding.

This can cause us to underpay fees when using an external signer. That's especially problematic when the user picks 1 sat/vbyte as the fee, because it won't even get into our own mempool.

The easiest solution would be to modify `ExternalSignerScriptPubKeyMan` to assume 72 bytes for ECSDA signatures.

Slightly more advanced would be to expand HWI to keep track of which devices and firmware versions (if any) support R-value grinding. We'd then have to store that in the wallet in some new field. Personally I'd rather work on better Taproot support, which thanks to Schnorr avoids this issue altogether. "
bitcoin/bitcoin,2022-09-06 01:54:02,bug,Unknown descriptor in wallet crashes,"Attempting to load a wallet with an unknown descriptor causes a fatal error:

```
2022-09-06T01:51:06Z init message: Loading wallet…
2022-09-06T01:51:06Z [descriptor] Invalid descriptor: Can only have tr at top level: iostream error
2022-09-06T01:51:06Z [descriptor] Invalid descriptor: Can only have tr at top level: iostream error
2022-09-06T01:51:06Z [descriptor] Setting spkMan to active: id = 50e6032b4d1d62c020ebb6a4d0c8fafc6f01ea80f4d2a41c1a256086611636e9, type = legacy, internal = false
2022-09-06T01:51:06Z [descriptor] Setting spkMan to active: id = 7f709abbde61e8c253798375692bf41202e625ed74a65f9474d464be34fb2870, type = p2sh-segwit, internal = false
2022-09-06T01:51:06Z [descriptor] Setting spkMan to active: id = 2dc6c34099e0ca1235fc990a51042967ecbc8c8ac57062f964739cba2f451be8, type = bech32, internal = false
2022-09-06T01:51:06Z [descriptor] Setting spkMan to active: id = 8d3c63ea1ac9936e789713dc8bae857d328ff029ab9392e67c716752e9b11b0c, type = bech32m, internal = false
2022-09-06T01:51:06Z [descriptor] Releasing wallet
2022-09-06T01:51:06Z 

************************
EXCEPTION: St12out_of_range       
map::at       
bitcoin in Runaway exception       



************************
EXCEPTION: St12out_of_range       
map::at       
bitcoin in Runaway exception       

bitcoin-qt: ./checkqueue.h:204: CCheckQueue<CScriptCheck>::~CCheckQueue() [T = CScriptCheck]: Assertion `m_worker_threads.empty()' failed.
Aborted
```

> A fatal error occurred. Bitcoin Core can no longer continue safely and will quit.

To reproduce, a quick hack:

```c++
--- a/src/script/descriptor.cpp
+++ b/src/script/descriptor.cpp
@@ -1408,7 +1408,7 @@ std::unique_ptr<DescriptorImpl> ParseScript(uint32_t& key_exp_index, Span<const
         error = ""Can only have addr() at top level"";
         return nullptr;
     }
-    if (ctx == ParseScriptContext::TOP && Func(""tr"", expr)) {
+    if (ctx == ParseScriptContext::TOP && Func(""trx"", expr)) {
         auto arg = Expr(expr);
         auto internal_key = ParsePubkey(key_exp_index, arg, ParseScriptContext::P2TR, out, error);
         if (!internal_key) {
```"
bitcoin/bitcoin,2022-09-04 21:48:10,bug,fs: `_OVERLAPPED` missing initializers,"```bash
fs.cpp: In member function ‘bool fsbridge::FileLock::TryLock()’:
fs.cpp:129:32: error: missing initializer for member ‘_OVERLAPPED::InternalHigh’ [-Werror=missing-field-initializers]
  129 |     _OVERLAPPED overlapped = {0};
      |                                ^
fs.cpp:129:32: error: missing initializer for member ‘_OVERLAPPED::<anonymous>’ [-Werror=missing-field-initializers]
fs.cpp:129:32: error: missing initializer for member ‘_OVERLAPPED::hEvent’ [-Werror=missing-field-initializers]
```

https://github.com/bitcoin/bitcoin/pull/25972/checks?check_run_id=8137548993"
bitcoin/bitcoin,2022-08-30 19:08:24,bug,Segmentation fault when compiling with libfuzzer and lto (x86_64),"Steps to reproduce:

* Install fresh Ubuntu Jammy operating system
* `export DEBIAN_FRONTEND=noninteractive && apt update && apt install curl wget htop git vim ccache -y && git clone https://github.com/bitcoin/bitcoin.git bitcoin-core && cd bitcoin-core && apt install build-essential libtool autotools-dev automake pkg-config bsdmainutils python3-zmq     libevent-dev libboost-dev  libsqlite3-dev  libdb++-dev clang llvm libc++-dev libc++abi-dev  -y   &&  ./autogen.sh && ./configure CC='clang -flto' CXX='clang++ -flto'   --enable-fuzz --with-sanitizers=fuzzer && make -j$(nproc)`

Output:

```
  AR       minisketch/libminisketch.a
  AR       libbitcoin_wallet.a
  CXXLD    test/fuzz/fuzz
clang: error: unable to execute command: Segmentation fault (core dumped)
```

The same does not happen when compiling ""normally"" (dropping `--with-sanitizers=fuzzer`).


"
bitcoin/bitcoin,2022-08-26 20:12:09,bug,Intermittent failure in `wallet_groups.py`,"https://cirrus-ci.com/task/6569439897321472?logs=functional_tests#L2462 : 

```
File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\wallet_groups.py"", line 150, in run_test
                                       txid6 = self.nodes[4].sendtoaddress(self.nodes[0].getnewaddress(), 2.95)
(...)
AssertionError: [node 4] Expected messages ""['Fee non-grouped = 5520, grouped = 8240, using grouped']"" does not partially match log"
bitcoin/bitcoin,2022-08-21 21:24:35,bug,CheckBlockIndex stalls for extremely long time,"Stale chain tips can block the RPC and all other responses from the peer for very long time (more than 15 minutes, sometimes hours, or undefinetely).
During that time I can see that my local node no longer replies to ANY other peer (e.g. to bitnode.io core). And in process viewers, I can see that there's a single thread blocking ALL other threads in a tight loop using 100% CPU in a tight loop.

I've seen that this is occurs in any db indexer (notably the chainstate indexer during IBD, or the txindexer, or the coinstat db indexer), notably in some critical steps where new blocks are added to the chain (once every about 15 minutes). This seems to happen when a new block contains a transaction validating a better chain, and invalidating other blocks from dead branches. In that case, the ongoin indexer will fail with unchecked conditions in its internal iterator, apparently because it expect the next block to be present and locks it incorrectly, and is not able to release it and retry if that next valid block has been replaced by a better block in the chain.

```
2022-08-21T19:44:15.875834Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70015, blocks=750474, peer=58, peeraddr=[2604:a880:cad:d0::d9e:f001]:8333 (block-relay-only)
2022-08-21T19:44:45.012022Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 330879
2022-08-21T19:45:16.005414Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 331746
2022-08-21T19:45:47.003036Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 332578
2022-08-21T19:46:18.039548Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 333378
2022-08-21T19:46:49.007385Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 334219
2022-08-21T19:47:20.013586Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 334916
2022-08-21T19:47:51.022263Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 335794
2022-08-21T19:48:22.007479Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 336769
2022-08-21T19:48:53.009529Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 337743
2022-08-21T19:49:24.039053Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 338611
2022-08-21T19:49:55.041510Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 339322
2022-08-21T19:50:26.010515Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 340016
2022-08-21T19:50:57.016185Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 340630
2022-08-21T19:51:28.055804Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 341499
2022-08-21T19:52:08.460256Z [validation.cpp:2441] [UpdateTipLog] UpdateTip: new best=0000000000000000000758f0830f8c7cf41c06740b2004b4186e439b0b989062 height=750475 version=0x2281c000 log2_work=93.689008 tx=758464817 date='2022-08-21T19:50:59Z' progress=1.000000 cache=3.7MiB(27192txo)
2022-08-21T19:52:10.247487Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 341803
2022-08-21T19:52:30.568835Z [validation.cpp:2441] [UpdateTipLog] UpdateTip: new best=00000000000000000005d0b2bbb26ce7bb0eef932eed58853ebe6525ca71c85a height=750476 version=0x20000004 log2_work=93.689019 tx=758465224 date='2022-08-21T19:52:12Z' progress=1.000000 cache=3.9MiB(28964txo)
2022-08-21T19:52:41.785630Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 341814
2022-08-21T19:53:12.001085Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 342683
2022-08-21T19:53:43.027307Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 343432
2022-08-21T19:54:14.012871Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 344012
2022-08-21T19:54:45.022063Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 344718
2022-08-21T19:54:59.410934Z [validation.cpp:2441] [UpdateTipLog] UpdateTip: new best=000000000000000000098f79590f23c8bb78c3d4d22d1cd4bab3a0e94fc7e6be height=750477 version=0x2ab96000 log2_work=93.689030 tx=758465722 date='2022-08-21T19:54:36Z' progress=1.000000 cache=4.1MiB(30966txo)
2022-08-21T19:55:16.033929Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 344913
2022-08-21T19:56:00.985269Z [mapport.cpp:204] [ProcessUpnp] UPnP Port Mapping successful.
2022-08-21T20:16:01.005268Z [mapport.cpp:204] [ProcessUpnp] UPnP Port Mapping successful.
```

Finally later it may eventually detect that and detect the inconsistency, by eviting some peers.

```
2022-08-21T20:26:10.234268Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 344915
2022-08-21T20:26:10.236286Z [net_processing.cpp:4381] [CheckForStaleTipAndEvictPeers] Potential stale tip detected, will try using extra outbound peer (last tip update: 1871 seconds ago)
2022-08-21T20:26:10.877268Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70016, blocks=750480, peer=194, peeraddr=78.108.108.38:8333 (outbound-full-relay)
2022-08-21T20:26:18.436270Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70016, blocks=750480, peer=195, peeraddr=208.104.92.74:8333 (outbound-full-relay)
2022-08-21T20:26:20.609320Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70016, blocks=750480, peer=196, peeraddr=[2a01:5200:6c:6162:6263:6173:6861:6263]:8333 (outbound-full-relay)
2022-08-21T20:26:22.546436Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70016, blocks=750480, peer=198, peeraddr=141.95.45.187:30034 (outbound-full-relay)
2022-08-21T20:27:18.146310Z [validation.cpp:2441] [UpdateTipLog] UpdateTip: new best=00000000000000000007cb8a63d4c0f24bf0e1c3e6bedbf0436ebab43a3ee690 height=750478 version=0x20800000 log2_work=93.689041 tx=758467003 date='2022-08-21T20:05:24Z' progress=0.999995 cache=5.5MiB(41861txo)
2022-08-21T20:27:20.065326Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 344926
2022-08-21T20:27:51.486742Z [validation.cpp:2441] [UpdateTipLog] UpdateTip: new best=00000000000000000006e1bb77ce90948b3050df8ee2143d1913fd583ce3c765 height=750479 version=0x20c00000 log2_work=93.689052 tx=758468307 date='2022-08-21T20:08:38Z' progress=0.999996 cache=6.6MiB(48588txo)
2022-08-21T20:28:03.488188Z [validation.cpp:2441] [UpdateTipLog] UpdateTip: new best=0000000000000000000171f39891841e7128e85f45f386ddde82f65c12dd5773 height=750480 version=0x20400000 log2_work=93.689063 tx=758468706 date='2022-08-21T20:10:40Z' progress=0.999996 cache=6.8MiB(50180txo)
2022-08-21T20:28:05.362170Z [index/base.cpp:169] [ThreadSync] Syncing coinstatsindex with block chain from height 344927
2022-08-21T20:28:05.364170Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70015, blocks=750480, peer=205, peeraddr=116.203.112.73:8333 (outbound-full-relay)
2022-08-21T20:28:05.718559Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70016, blocks=750480, peer=208, peeraddr=[2404:7a85:4161:2b00:49a1:427a:fac:3409]:8333 (outbound-full-relay)
2022-08-21T20:28:08.302936Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70016, blocks=750480, peer=211, peeraddr=185.167.113.59:8333 (outbound-full-relay)
2022-08-21T20:28:21.039390Z [net_processing.cpp:2797] [ProcessMessage] New outbound peer connected: version: 70016, blocks=750480, peer=213, peeraddr=[240b:252:9480:9d00:e65f:1ff:fe10:d767]:8333 (outbound-full-relay)
```

And here again we see the deadlock occuring for long time in the coindb indexer (note the difference of time between the last too events). And in fact nothing else occured: no resposes to other peers, the coindb indexer was stalled, the RPC service stopped to respond even locally.

It seems then that there are malicious nodes on the P2P network sending bad blocks that ""partially pass"" the basic security, but can cause BitCoin Core to be blocked and become unresponsive. It can no longer respond even to a basic RPC such as ""bitcoin -getinfo"", or ""bitcoin -netinfo""

It will not even repond to a ""bitcoin-cli stop"": some threads are stopped, but not all, and the indexer thread is still running in its tight loop; if you are in that situation, the only way to recover is to KILL the process entirely, and you'll get the related index to become invalid as it was not committed, it will have to be reconstructed from zero.

Most often, you have no way to recover (given that the RPC service is not responsive, and even the CTRL+C breaker, or a simple kill -hangup"" will not work. You have to do an instant kill (kill -9 on Linux, or manual kill in the Process Viewer on Windows: nothing else will be synced to disk).

If the index was the IBD index, the chainstate can only be recovered by check level 4 (works often, but not necessarily always, but never with check level 3). If it does not work, then you have to rebuild the chainstate entirely.

But for any other index (such as the ""txindex"" or ""coinstats"" index, there's NO check at all with recovery at startup, so the only way to recover is to entirely delete the content of that index directory and rebuild it from zero (and this will take many hours, and may fail again in the middle, due to bad blocks sent by malicious peers and that may have still not been replaced by valid blocks in the main chain).

Apparently these bad blocks seem to come from unapproved forks (possibly implementing SegWit with too large block sizes?), which are not correctly detected and cause the indexer to fail or run into some infinite loops, or some bad signatures using unsupported/snon-standard bytecodes, taking extremely long time to validate or just discard rapidly as invalid.

Such events with bad blocks coming from malicious peers tend to be frequent now. Unfortunately it's not easy to track which nodes caused that bug as they may not even be connected since long: they have sent their garbage and have disconnected themselves as soon as done, just to crash specific versions of Bitcoin Core not detecting them.

(Note: this is once again occuring with the current unmodified release v23.0 from your official site; it affects both Linux and Windows versions).

Are there blocks that are extremely long to validate or index (taking much more than just about 1 minutes normally needed here to process every logged group of about 15 blocks, such as more than 30 minutes in the 1st break above, but still not completed after several hours at end of the logs above)? Isn't it one of the reasons why SegWit was asked for, with blocks grouping many signatures, for example those generated by very large miner pools and needing tons of transactions to validate all their micropayments to many participants?

----

See also Bug https://github.com/bitcoin/bitcoin/issues/25365 (may be related with the same race issue when there's a new chaintip updated while the indexer is running and iterating from the older chain view)

If this is the cause, the bug is manifested only when you run it on a machine with enough cores to allow more threads to run concurrently. The crashes/hangs I experiment are all runing with 8 cores activates; your test environment may just have 1 or 2 cores configured, most probably not enough to experiment the race issue between concurrent threads, and not experienced by people running it on cheap PC or notebooks, or in cheap/free VMs for Azure and Amazon (if you get just 1 or 2 non dedicated cores).

Note also that synchronization issues in code may even more likely to cause bugs on CPUs running multiple threads per core, or using more complex parallelism (e.g. new Intel processors with power-efficient and performance CPUs, with more complex caching layers, or needing special kernel-initiated firmware mitigations like Retpoline against attacks based on latency response time on caches and with speculative execution models; those possibile attacks and firmware or OS mitigations exist on many processors, and their effect on execution latency may vary, depending on the number of active concurrent threads; if you have low I/O latency on disk storage, this will also increase the likelyhood of race issues caused by improper synchronization. But in all these cases this greatly impacts the leveldb indexers, not properly iterating over the main chain of blocks.)

If you want to experiment it faster, you may want to test it on a machine with many more CPU cores, like newest AMD ThreadRipper (48 concurrent threads!). And then try running multiple indexers running in parallel (the chainstate indexer in IBD, the coinsdbindexer, the txindex, and the coinsdbindex: one of them will crash/hand, or report ""data corruption"", but not caused by any hardware issue, but incorrect synchronization in Bitcoin Core's code).

As well it seems that all bugs like https://github.com/bitcoin/bitcoin/issues/25894 (reported quite often, but always diagnosed in replies"" incorrectly as a ""hardware issue"", just supposed but never really verified) are also related to the same synchronization issues between any indexer thread and the thread handling any changes of the tips on the chainstate (notably if there's a change between concurrent forks for new blocks after establishing a consensus. They more likely occurs at end of a trading day, when more blocks are announced for compensating transactions made by major traders (it's then more frequent to get new blocks emitted more rapidly than just once every 10 minutes during the rest of the day.

----

Subsidiary question: Is there way to have a knonw list of trustable peers, and a blacklist for bad peers sending fake/corrupted data? Isn't Bitcoin missing some additional checks of the structure of these blocks (not just the validation of the individual attempted transactions, but basically its assumed format, includnig for complex multipart signature schemes, or peers attempting to force the use of a hard fork with a disappoved BIP proposal, or attemping to use it too early before a valid date and proper nogociation, if they run some specific subchains)?

One remote peer I remarked was always present when I saw crashes/hangs was this one:

<->   type   net  mping   ping send recv  txn  blk  hb addrp addrl  age id address                     version
out   full  ipv6     27     27    4    1    0           1002          1 11 [2001:41d0:303:2b2b::]:8333 70015/Satoshi:0.14.2(bitcore-sl)/UASF-Segwit:1.0(BIP148)/

I've seen it several times sending groups of 2 or 3 unconfirmed blocks with large transactions in a row. It is likely a non-upgraded miner node.

(According to WHOIS, is is hosted by OVH in France, and likely on a fiber access; it uses the most antique version of Satoshi I seen for a ""full node"", but with local patches trying to enforce BIP148 but with wrong version announcements).

Do I need to list it in my banlist?"
bitcoin/bitcoin,2022-08-19 16:32:33,bug,docfix: `sighash` parameter for `walletprocesspsbt`,I think the documentation is incorrect since #22514. See https://github.com/bitcoin/bitcoin/pull/22514#discussion_r895554745.
bitcoin/bitcoin,2022-08-11 16:23:42,bug,UndefinedBehaviorSanitizer: stack-overflow in miniscript (descriptor_parse),"To reproduce:

```
wget https://github.com/bitcoin/bitcoin/files/9309619/crash-2f09727aed5aca089c341208564876bc9c096ebf.bin.not.txt
FUZZ=descriptor_parse ./src/test/fuzz/fuzz ./crash-2f09727aed5aca089c341208564876bc9c096ebf.bin.not.txt  -rss_limit_mb=1000
```

```
==119584==ERROR: UndefinedBehaviorSanitizer: stack-overflow on address 0x7ffcf4e35ff8 (pc 0x55a9a0f40e0c bp 0x7ffcf4e36010 sp 0x7ffcf4e36000 T119584)
    #0 0x55a9a0f40e0c in void __gnu_cxx::new_allocator<miniscript::Node<unsigned int>>::destroy<miniscript::Node<unsigned int> const>(miniscript::Node<unsigned int> const*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/ext/new_allocator.h:152
    #1 0x55a9a0f3c96b in void std::allocator_traits<std::allocator<miniscript::Node<unsigned int>>>::destroy<miniscript::Node<unsigned int> const>(std::allocator<miniscript::Node<unsigned int>>&, miniscript::Node<unsigned int> const*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/alloc_traits.h:496:8
    #2 0x55a9a0f3c96b in std::_Sp_counted_ptr_inplace<miniscript::Node<unsigned int> const, std::allocator<miniscript::Node<unsigned int>>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:557:2
    #3 0x55a9a0f40eec in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:155:6
    #4 0x55a9a0f40eec in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:730:11
    #5 0x55a9a0f40eec in std::__shared_ptr<miniscript::Node<unsigned int> const, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:1169:31
    #6 0x55a9a0f40eec in void std::_Destroy<std::shared_ptr<miniscript::Node<unsigned int> const>>(std::shared_ptr<miniscript::Node<unsigned int> const>*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:98:19
    #7 0x55a9a0f40eec in void std::_Destroy_aux<false>::__destroy<std::shared_ptr<miniscript::Node<unsigned int> const>*>(std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:108:6
    #8 0x55a9a0f40eec in void std::_Destroy<std::shared_ptr<miniscript::Node<unsigned int> const>*>(std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:136:7
    #9 0x55a9a0f40eec in void std::_Destroy<std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>>(std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>*, std::allocator<std::shared_ptr<miniscript::Node<unsigned int> const>>&) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:206:7
    #10 0x55a9a0f40eec in std::vector<std::shared_ptr<miniscript::Node<unsigned int> const>, std::allocator<std::shared_ptr<miniscript::Node<unsigned int> const>>>::~vector() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_vector.h:677:2
    #11 0x55a9a0f40eec in miniscript::Node<unsigned int>::~Node() src/./script/miniscript.h:185:31
    #12 0x55a9a0f40eec in void __gnu_cxx::new_allocator<miniscript::Node<unsigned int>>::destroy<miniscript::Node<unsigned int> const>(miniscript::Node<unsigned int> const*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/ext/new_allocator.h:152:10
    #13 0x55a9a0f3c96b in void std::allocator_traits<std::allocator<miniscript::Node<unsigned int>>>::destroy<miniscript::Node<unsigned int> const>(std::allocator<miniscript::Node<unsigned int>>&, miniscript::Node<unsigned int> const*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/alloc_traits.h:496:8
    #14 0x55a9a0f3c96b in std::_Sp_counted_ptr_inplace<miniscript::Node<unsigned int> const, std::allocator<miniscript::Node<unsigned int>>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:557:2
...
...
...
+/9/bits/stl_vector.h:677:2
    #1475 0x55a9a0f40eec in miniscript::Node<unsigned int>::~Node() src/./script/miniscript.h:185:31
    #1476 0x55a9a0f40eec in void __gnu_cxx::new_allocator<miniscript::Node<unsigned int>>::destroy<miniscript::Node<unsigned int> const>(miniscript::Node<unsigned int> const*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/ext/new_allocator.h:152:10
    #1477 0x55a9a0f3c96b in void std::allocator_traits<std::allocator<miniscript::Node<unsigned int>>>::destroy<miniscript::Node<unsigned int> const>(std::allocator<miniscript::Node<unsigned int>>&, miniscript::Node<unsigned int> const*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/alloc_traits.h:496:8
    #1478 0x55a9a0f3c96b in std::_Sp_counted_ptr_inplace<miniscript::Node<unsigned int> const, std::allocator<miniscript::Node<unsigned int>>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:557:2
    #1479 0x55a9a0f40eec in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:155:6
    #1480 0x55a9a0f40eec in std::__shared_count<(__gnu_cxx::_Lock_policy)2>::~__shared_count() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:730:11
    #1481 0x55a9a0f40eec in std::__shared_ptr<miniscript::Node<unsigned int> const, (__gnu_cxx::_Lock_policy)2>::~__shared_ptr() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/shared_ptr_base.h:1169:31
    #1482 0x55a9a0f40eec in void std::_Destroy<std::shared_ptr<miniscript::Node<unsigned int> const>>(std::shared_ptr<miniscript::Node<unsigned int> const>*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:98:19
    #1483 0x55a9a0f40eec in void std::_Destroy_aux<false>::__destroy<std::shared_ptr<miniscript::Node<unsigned int> const>*>(std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:108:6
    #1484 0x55a9a0f40eec in void std::_Destroy<std::shared_ptr<miniscript::Node<unsigned int> const>*>(std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:136:7
    #1485 0x55a9a0f40eec in void std::_Destroy<std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>>(std::shared_ptr<miniscript::Node<unsigned int> const>*, std::shared_ptr<miniscript::Node<unsigned int> const>*, std::allocator<std::shared_ptr<miniscript::Node<unsigned int> const>>&) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_construct.h:206:7
    #1486 0x55a9a0f40eec in std::vector<std::shared_ptr<miniscript::Node<unsigned int> const>, std::allocator<std::shared_ptr<miniscript::Node<unsigned int> const>>>::~vector() /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/stl_vector.h:677:2
    #1487 0x55a9a0f40eec in miniscript::Node<unsigned int>::~Node() src/./script/miniscript.h:185:31
    #1488 0x55a9a0f40eec in void __gnu_cxx::new_allocator<miniscript::Node<unsigned int>>::destroy<miniscript::Node<unsigned int> const>(miniscript::Node<unsigned int> const*) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/ext/new_allocator.h:152:10

SUMMARY: UndefinedBehaviorSanitizer: stack-overflow /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/ext/new_allocator.h:152 in void __gnu_cxx::new_allocator<miniscript::Node<unsigned int>>::destroy<miniscript::Node<unsigned int> const>(miniscript::Node<unsigned int> const*)
```
"
bitcoin/bitcoin,2022-08-01 12:19:06,bug,test: failure in interface_usdt_validation.py ,"https://cirrus-ci.com/task/5553601580892160?logs=ci#L4244:
```bash
 test  2022-08-01T12:14:24.104000Z TestFramework (INFO): handle_blockconnected(): ConnectedBlock(hash=2f97f65fda63aba081bf2867f7f99657c39436306c4aed3c899264b8bde7c5ab height=202, transactions=1, inputs=1, sigops=0, duration=517) 
 test  2022-08-01T12:14:24.104000Z TestFramework (INFO): handle_blockconnected(): ConnectedBlock(hash=54d4bd414e5de85cee4dc5f1e7bcf4e358cf6e7ce556647debe2e9d007459ec7 height=201, transactions=1, inputs=1, sigops=0, duration=338) 
 test  2022-08-01T12:14:24.148000Z TestFramework (INFO): check that we traced 2 blocks 
 test  2022-08-01T12:14:24.149000Z TestFramework (ERROR): Assertion failed 
                                   Traceback (most recent call last):
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 133, in main
                                       self.run_test()
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/interface_usdt_validation.py"", line 131, in run_test
                                       assert_equal(BLOCKS_EXPECTED, blocks_checked)
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/util.py"", line 52, in assert_equal
                                       raise AssertionError(""not(%s)"" % "" == "".join(str(arg) for arg in (thing1, thing2) + args))
                                   AssertionError: not(2 == 0)
```"
bitcoin/bitcoin,2022-07-30 13:49:15,bug,psbt.h:644:51: runtime error: unsigned integer overflow: 0 - 1 cannot be represented in type 'unsigned long',"Steps to reproduce:

* Build with `integer` sanitizer
* `UBSAN_OPTIONS=""suppressions=$(pwd)/test/sanitizer_suppressions/ubsan:print_stacktrace=1:halt_on_error=1:report_error_type=1"" ./src/qt/bitcoin-qt`
* Enter into the RPC debug console: `decodepsbt ""cHNidP8BAKOro2MDAwMDA5ggCAAA////CQAtAAD+///1AAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJAAAAAAAAAAAAAAAAAAAAAAAAAD+///1Zm9ybmV3nWx1Y2vmelLmegAAAAAAAAAAAAAAAAAAAAMKAwMDAwMDAwMDAwMACvMBA3FkAAAAAAAAAAAABAAlAAAAAAAAACEWDQ0zDQ0NDQ0NDQ0NCwEAAH9/f39/fwMAAABNo6P///kAAA==""`"
bitcoin/bitcoin,2022-07-28 01:40:02,bug,Bitcoin Core 0.23 installer incompatible with Windows mandatory ASLR,"<!-- Describe the issue -->

Try downloading the current version 0.23 of Bitcoin Core for Windows from the official site : the installer (EXE) is corrupted (won't run, corrupted EXE format)

Only the ZIP file is correct.

Workaround: you can use the 0.22 installer, then download the 0.23 zip and extract the executables from there to overwrite the existing EXE files (qt.exe in the main Program Files\\Bitcoin folder, other executables in the ZIP go to the ""daemon"" subfolder)

So the EXE package was incorrectly built, or was incorrectly transfered/truncated on the download site on bitcoin.org.
"
bitcoin/bitcoin,2022-07-25 06:44:42,bug,psbt.h:896:51: runtime error: unsigned integer overflow: 0 - 1 cannot be represented in type 'unsigned long',"This needs a code change or suppression added:

```
$ UBSAN_OPTIONS=""suppressions=$(pwd)/scratch/fuzz_gen/code/test/sanitizer_suppressions/ubsan:print_stacktrace=1:halt_on_error=1:report_error_type=1"" FUZZ=partially_signed_transaction_deserialize /root/fuzz_dir/scratch/fuzz_gen/code/src/test/fuzz/fuzz /tmp/crash-e4a4fe6f63596cd582f208eea9be69b716f61165 
INFO: Running with entropic power schedule (0xFF, 100).
INFO: Seed: 3574901271
INFO: Loaded 1 modules   (322037 inline 8-bit counters): 322037 [0x555887da9f40, 0x555887df8935), 
INFO: Loaded 1 PC tables (322037 PCs): 322037 [0x555887df8938,0x5558882e2888), 
/root/fuzz_dir/scratch/fuzz_gen/code/src/test/fuzz/fuzz: Running 1 inputs 1 time(s) each.
Running: /tmp/crash-e4a4fe6f63596cd582f208eea9be69b716f61165
psbt.h:896:51: runtime error: unsigned integer overflow: 0 - 1 cannot be represented in type 'unsigned long'
    #0 0x555885271598 in void PSBTOutput::Unserialize<CDataStream>(CDataStream&) src/./psbt.h:896:51
    #1 0x555885233a4e in void Unserialize<CDataStream, PSBTOutput&>(CDataStream&, PSBTOutput&) src/./serialize.h:682:7
    #2 0x555885233a4e in CDataStream& CDataStream::operator>><PSBTOutput&>(PSBTOutput&) src/./streams.h:339:9
    #3 0x55588523024f in void PartiallySignedTransaction::Unserialize<CDataStream>(CDataStream&) src/./psbt.h:1191:15
    #4 0x55588522edee in void Unserialize<CDataStream, PartiallySignedTransaction&>(CDataStream&, PartiallySignedTransaction&) src/./serialize.h:682:7
    #5 0x55588522edee in CDataStream& CDataStream::operator>><PartiallySignedTransaction&>(PartiallySignedTransaction&) src/./streams.h:339:9
    #6 0x5558852067f5 in void (anonymous namespace)::DeserializeFromFuzzingInput<PartiallySignedTransaction>(Span<unsigned char const>, PartiallySignedTransaction&, std::optional<int>, int) src/./src/test/fuzz/deserialize.cpp:100:12
    #7 0x5558852067f5 in partially_signed_transaction_deserialize_fuzz_target(Span<unsigned char const>) src/./src/test/fuzz/deserialize.cpp:173:1
    #8 0x555885106682 in std::_Function_handler<void (Span<unsigned char const>), void (*)(Span<unsigned char const>)>::_M_invoke(std::_Any_data const&, Span<unsigned char const>&&) /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:300:2
    #9 0x55588549ae5a in std::function<void (Span<unsigned char const>)>::operator()(Span<unsigned char const>) const /usr/bin/../lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/bits/std_function.h:688:14
    #10 0x55588549aad6 in LLVMFuzzerTestOneInput src/./src/test/fuzz/fuzz.cpp:154:5
    #11 0x555885029372 in fuzzer::Fuzzer::ExecuteCallback(unsigned char const*, unsigned long) (/root/fuzz_dir/scratch/fuzz_gen/code/src/test/fuzz/fuzz+0x141a372) (BuildId: 8e23fc37575bb16be5b418c47853b5da4e548abb)
    #12 0x5558850138d0 in fuzzer::RunOneTest(fuzzer::Fuzzer*, char const*, unsigned long) (/root/fuzz_dir/scratch/fuzz_gen/code/src/test/fuzz/fuzz+0x14048d0) (BuildId: 8e23fc37575bb16be5b418c47853b5da4e548abb)
    #13 0x555885019587 in fuzzer::FuzzerDriver(int*, char***, int (*)(unsigned char const*, unsigned long)) (/root/fuzz_dir/scratch/fuzz_gen/code/src/test/fuzz/fuzz+0x140a587) (BuildId: 8e23fc37575bb16be5b418c47853b5da4e548abb)
    #14 0x555885042342 in main (/root/fuzz_dir/scratch/fuzz_gen/code/src/test/fuzz/fuzz+0x1433342) (BuildId: 8e23fc37575bb16be5b418c47853b5da4e548abb)
    #15 0x7fa7994a3082 in __libc_start_main /build/glibc-SzIz7B/glibc-2.31/csu/../csu/libc-start.c:308:16
    #16 0x55588500e1cd in _start (/root/fuzz_dir/scratch/fuzz_gen/code/src/test/fuzz/fuzz+0x13ff1cd) (BuildId: 8e23fc37575bb16be5b418c47853b5da4e548abb)

SUMMARY: UndefinedBehaviorSanitizer: unsigned-integer-overflow psbt.h:896:51 in 
```

```
$ base64 /tmp/crash-e4a4fe6f63596cd582f208eea9be69b716f61165 
rPcKGHBzYnT/AQA9AAAAAAF6AAGDEwEA+8QAAP9glCALb/ITYCf/BwABAR4AAAAAWAAAAAAAGHBz
YgEBTEtAIxPsMAEAAAn8/wABKwAH/ACOCcgAAAAF/AAAAPwEAAAAAAb8AAAAAWQAA/wAAAf8AI4J
yCQuAAf8AAIA/wgBAAf8AAAJyAAAACEH/AAAjQFkygAG/AAACSEAASsBKwAH/ACOCcgAAAAF/AAA
APwEAAAAAAb8AAAAAAAG/AArAAFkAAP8AAAH/ACOCQAAIQAG/AAA/wgBAAf8AAAJwgAAAAf8AAAw
AWTKAAb8AAABQA8AB/wAAAAJASsAB/wAjgnIAAAABfwAAAD8BAAAAAAG/AAAAAAAAAEG/ABkAAP8
AAAH/AAACcgAAAAH/AAANQFkygAG/AAAAUAPAAf8AAkhAAErAAf8AAAACfz/AAErAAf8jgkAAMgA
AAX8AAAA/AQAAAAABvwAAAAAAAb8AAABZAAD/AAAB/wAjgnIJi4AB/wAAgAAAAAG/AAA/wgAB/wA
ADABZMoABvwAAAFADwAH/AAJIQABKwAH/AAAAAn8/wABKwAH/ACOCcgAAAAF/AAAAPwEAAAAAAb8
AAAAAWQAA/wAAAf8AI4JyCYuAAf8AAIA/wgBAAf8AAAJyAAAAAf8AACNAWTKAAb8AAAJIQABKwEr
AAf8AI4JyAAAAAX8AAAA/AQAAAAABvwAAAAAAAb8AAABZAAD/AAAB/wAjgnIJi4AB/wAAgAAACEA
BvwAAP8IAQAH/AAACcIAAAAH/AAAMAFkygAG/AAAAUAPAAf8AAkhAPwAAAD8AAQAAAAG/AAAAAFk
AAP8AAAH/ACOCcgkLgAH/AACAP8IAQAH/AAACcgAAAAH/AAAjQFk/AAACcIAAAAH/AAAMAFkygAG
/AAAAUAPAAf8AAAACQErAAf8AI4JyAAAAAX8AAAA/AQAAAAABvwAAAAAAAABBvwAZAAD/AAAB/wA
AAnIAAAAB/wAADUBZMoABvwAAAFADwAH/AAJIQABKwAH/AAAAAn8/wABKwAH/ACOCcgAAAAF/AAA
APwEAAAAAAb8AAAAAAAG/AAAAWQAA/wAAAf8AI4JyCYuAAf8AAIAAAAABvwAAAAAAAAAAAAAAAAA
AAD/CAAH/AAAMAFkygAG/AAAAUAPAAf8AAkhAAErAAf8AAAACfz/AAErAAf8AI4JyAAAAAX8AAAA
/AQAAAAABvwAAAABZAAD/AAAB/wAjgnIJi4AA/wAAAf8AI4JyCQuAAf8AAIA/wgBAAf8AAAJyAAA
AAf8AACNQGTKAAb8AAAJIQABKwErAAf8AI4JyAAAAAX8AAAA/AQAAAAABvwAAAAAAAb8ACsAAWQA
A/wAAAf8AI4JAAAhAAb8AAD/CAEAB/wAAAnCAAAAB/wAADABZMoABvwAAAFADwAH/AAAAAkBKwAH
/ACOCcgAAAAF/AAAAPwEAAAAAAb8AAAAAAAAAQb8AGQAA/wAAAf8E2An/wcAAQEeAv0AAHAkA/kV
YI4A/wTEAAD/YJ4iIiIiIq4AAAAAAAA=
"
bitcoin/bitcoin,2022-07-19 11:24:29,bug,Intermittent failure in feature_startupnotify.py,"On the master branch: https://cirrus-ci.com/task/6066973032316928

```
172/245 - feature_startupnotify.py failed, Duration: 2 s
stdout:
2022-07-19T08:56:44.366000Z TestFramework (INFO): Initializing test directory C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\test_runner_₿_🏃_20220719_080912\\feature_startupnotify_71
2022-07-19T08:56:44.962000Z TestFramework (INFO): Test -startupnotify command is run when node starts
2022-07-19T08:56:46.019000Z TestFramework (INFO): Test -startupnotify is executed once
2022-07-19T08:56:46.019000Z TestFramework (ERROR): Assertion failed
Traceback (most recent call last):
  File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\test_framework.py"", line 133, in main
    self.run_test()
  File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\feature_startupnotify.py"", line 34, in run_test
    assert_equal(file_content.count(FILE_NAME), 1)
  File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\util.py"", line 51, in assert_equal
    raise AssertionError(""not(%s)"" % "" == "".join(str(arg) for arg in (thing1, thing2) + args))
AssertionError: not(0 == 1)
```

Didn't find an existing open issue but looks to be the same Win64 CI failure reported in https://github.com/bitcoin/bitcoin/issues/23967#issuecomment-1054485798."
bitcoin/bitcoin,2022-07-07 09:47:07,bug,"verifychain 4 111000 aborts with assertion ""hashPrevBlock == view.GetBestBlock()"" failed","Providing a low number of blocks works, however, it just crashed for me with 111000 blocks.

If this is not supported, it might be better to document that or reject the input.

Commit 691a08718beff31d1b821b192609ea3bfdb24d41

Output:

```
bitcoin-qt: validation.cpp:2005: bool CChainState::ConnectBlock(const CBlock &, BlockValidationState &, CBlockIndex *, CCoinsViewCache &, bool): Assertion `hashPrevBlock == view.GetBestBlock()' failed.
"
bitcoin/bitcoin,2022-07-05 23:45:12,bug,gui: Check for readlink buffer overflow and handle gracefully,"If readlink returns the size of the buffer, an overflow may have (safely) occurred.
Pass a buffer size of MAX_PATH+1 (the size of the actual buffer) to detect this scenario.
"
bitcoin/bitcoin,2022-06-30 13:07:42,bug,Confusing filtering by block hash behaviour in `listsinceblock`,"The reproduction speaks for itself:
```diff
diff --git a/test/functional/wallet_listsinceblock.py b/test/functional/wallet_listsinceblock.py
index fc06565983..e06fbf120a 100755
--- a/test/functional/wallet_listsinceblock.py
+++ b/test/functional/wallet_listsinceblock.py
@@ -32,13 +32,14 @@ class ListSinceBlockTest(BitcoinTestFramework):
         self.connect_nodes(1, 2)
         self.generate(self.nodes[2], COINBASE_MATURITY + 1)
 
-        self.test_no_blockhash()
-        self.test_invalid_blockhash()
-        self.test_reorg()
-        self.test_double_spend()
-        self.test_double_send()
-        self.double_spends_filtered()
-        self.test_targetconfirmations()
+        # self.test_no_blockhash()
+        # self.test_invalid_blockhash()
+        # self.test_reorg()
+        # self.test_double_spend()
+        # self.test_double_send()
+        # self.double_spends_filtered()
+        # self.test_targetconfirmations()
+        self.test_consistent_with_gettransaction()
 
     def test_no_blockhash(self):
         self.log.info(""Test no blockhash"")
@@ -383,5 +384,19 @@ class ListSinceBlockTest(BitcoinTestFramework):
         assert_equal(original_found, False)
         assert_equal(double_found, False)
 
+    def test_consistent_with_gettransaction(self):
+        """"""Test the filtering in listtransactions is consistent with gettransaction's
+        output.
+
+        The block hash parameter gives, according to the documentation, ""the block hash
+        to list transactions since"". Test that if we have a transaction confirmed at a
+        certain block, listing the coins since this block will output this transaction.
+        """"""
+        txid = self.nodes[2].sendtoaddress(self.nodes[2].getnewaddress(), 1)
+        self.generate(self.nodes[2], 1)
+        tx = self.nodes[2].gettransaction(txid)
+        coins = self.nodes[2].listsinceblock(tx[""blockhash""])[""transactions""]
+        assert txid in (c[""txid""] for c in coins)
+
 if __name__ == '__main__':
     ListSinceBlockTest().main()
```

Is it intended that filtering transaction ""since"" block N only output transactions confirmed from block N+1?"
bitcoin/bitcoin,2022-06-27 08:19:26,bug,qa: Intermittent failure in `wallet_encryption.py --descriptors`,"https://cirrus-ci.com/task/4615142003441664

<details><summary>log excerpt</summary>
<p>

```
177/244 - wallet_encryption.py --descriptors failed, Duration: 6 s

stdout:
2022-06-27T07:50:03.095000Z TestFramework (INFO): Initializing test directory C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\test_runner_₿_🏃_20220627_071202\\wallet_encryption_65

2022-06-27T07:50:08.820000Z TestFramework (INFO): Check a timeout less than the limit

2022-06-27T07:50:09.007000Z TestFramework (ERROR): Assertion failed

Traceback (most recent call last):

  File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\test_framework.py"", line 133, in main

    self.run_test()

  File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\wallet_encryption.py"", line 85, in run_test

    assert_greater_than(expected_time_with_buffer, actual_time)

  File ""C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\test_framework\\util.py"", line 56, in assert_greater_than

    raise AssertionError(""%s <= %s"" % (str(thing1), str(thing2)))

AssertionError: 1756315608.992383 <= 1756315609

2022-06-27T07:50:09.070000Z TestFramework (INFO): Stopping nodes

2022-06-27T07:50:09.211000Z TestFramework (WARNING): Not cleaning up dir C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\test_runner_₿_🏃_20220627_071202\\wallet_encryption_65

2022-06-27T07:50:09.211000Z TestFramework (ERROR): Test failed. Test logging available at C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\test_runner_₿_🏃_20220627_071202\\wallet_encryption_65/test_framework.log

2022-06-27T07:50:09.211000Z TestFramework (ERROR): 

2022-06-27T07:50:09.211000Z TestFramework (ERROR): Hint: Call C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\cirrus-ci-build\\test\\functional\\combine_logs.py 'C:\\Users\\ContainerAdministrator\\AppData\\Local\\Temp\\test_runner_₿_🏃_20220627_071202\\wallet_encryption_65' to consolidate all logs

2022-06-27T07:50:09.211000Z TestFramework (ERROR): 

2022-06-27T07:50:09.211000Z TestFramework (ERROR): If this failure happened unexpectedly or intermittently, please file a bug and provide a link or upload of the combined log.

2022-06-27T07:50:09.211000Z TestFramework (ERROR): https://github.com/bitcoin/bitcoin/issues

2022-06-27T07:50:09.211000Z TestFramework (ERROR): 
```

</p>
</details>"
bitcoin/bitcoin,2022-06-13 18:11:10,bug,ThreadSanitizer: data race on vptr (ctor/dtor vs virtual call) in BaseIndex,"https://cirrus-ci.com/task/6564394053140480?logs=ci#L3875:
```bash
WARNING: ThreadSanitizer: data race on vptr (ctor/dtor vs virtual call) (pid=24158)
  Write of size 8 at 0x7ffe0efae9f8 by main thread:
    #0 BaseIndex::~BaseIndex() src/index/base.cpp:53:1 (test_bitcoin+0xcc6b69)
    #1 CoinStatsIndex::~CoinStatsIndex() src/./index/coinstatsindex.h:17:7 (test_bitcoin+0x3b9b21)
    #2 coinstatsindex_tests::coinstatsindex_initial_sync::test_method() src/test/coinstatsindex_tests.cpp:84:1 (test_bitcoin+0x3b9b21)
    #3 coinstatsindex_tests::coinstatsindex_initial_sync_invoker() src/test/coinstatsindex_tests.cpp:32:1 (test_bitcoin+0x3b814b)
    #4 boost::detail::function::void_function_invoker0<void (*)(), void>::invoke(boost::detail::function::function_buffer&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:117:11 (test_bitcoin+0x2bbf1d)
    #5 boost::function0<void>::operator()() const /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:763:14 (test_bitcoin+0x220877)
    #6 boost::detail::forward::operator()() /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:1388:32 (test_bitcoin+0x220877)
    #7 boost::detail::function::function_obj_invoker0<boost::detail::forward, int>::invoke(boost::detail::function::function_buffer&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:137:18 (test_bitcoin+0x220877)
    #8 boost::function0<int>::operator()() const /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:763:14 (test_bitcoin+0x1ae59e)
    #9 int boost::detail::do_invoke<boost::shared_ptr<boost::detail::translator_holder_base>, boost::function<int ()> >(boost::shared_ptr<boost::detail::translator_holder_base> const&, boost::function<int ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:301:30 (test_bitcoin+0x1ae59e)
    #10 boost::execution_monitor::catch_signals(boost::function<int ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:903:16 (test_bitcoin+0x1ae59e)
    #11 boost::execution_monitor::execute(boost::function<int ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:1301:16 (test_bitcoin+0x1ae8c0)
    #12 boost::execution_monitor::vexecute(boost::function<void ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:1397:5 (test_bitcoin+0x1aa21b)
    #13 boost::unit_test::unit_test_monitor_t::execute_and_translate(boost::function<void ()> const&, unsigned long) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/unit_test_monitor.ipp:49:9 (test_bitcoin+0x1aa21b)
    #14 boost::unit_test::framework::state::execute_test_tree(unsigned long, unsigned long, boost::unit_test::framework::state::random_generator_helper const*) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:815:44 (test_bitcoin+0x1ddb63)
    #15 boost::unit_test::framework::state::execute_test_tree(unsigned long, unsigned long, boost::unit_test::framework::state::random_generator_helper const*) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:784:58 (test_bitcoin+0x1de1d8)
    #16 boost::unit_test::framework::state::execute_test_tree(unsigned long, unsigned long, boost::unit_test::framework::state::random_generator_helper const*) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:784:58 (test_bitcoin+0x1de1d8)
    #17 boost::unit_test::framework::run(unsigned long, bool) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:1721:29 (test_bitcoin+0x1a8e66)
    #18 boost::unit_test::unit_test_main(boost::unit_test::test_suite* (*)(int, char**), int, char**) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/unit_test_main.ipp:250:9 (test_bitcoin+0x1c19c6)
    #19 main /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/unit_test_main.ipp:306:12 (test_bitcoin+0x1c1ff6)
  Previous read of size 8 at 0x7ffe0efae9f8 by thread T1 (mutexes: write M603):
    #0 BaseIndex::SetBestBlockIndex(CBlockIndex const*)::$_1::operator()() const src/index/base.cpp:388:9 (test_bitcoin+0xcc74e6)
    #1 BaseIndex::SetBestBlockIndex(CBlockIndex const*) src/index/base.cpp:388:9 (test_bitcoin+0xcc74e6)
    #2 BaseIndex::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*) src/index/base.cpp:273:9 (test_bitcoin+0xcc9759)
    #3 CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_8::operator()() const::'lambda'(CValidationInterface&)::operator()(CValidationInterface&) const src/validationinterface.cpp:225:79 (test_bitcoin+0x10223a4)
    #4 void MainSignalsImpl::Iterate<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_8::operator()() const::'lambda'(CValidationInterface&)>(CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_8::operator()() const::'lambda'(CValidationInterface&)&&) src/validationinterface.cpp:86:17 (test_bitcoin+0x10223a4)
    #5 CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_8::operator()() const src/validationinterface.cpp:225:22 (test_bitcoin+0x10223a4)
    #6 CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9::operator()() const src/validationinterface.cpp:227:5 (test_bitcoin+0x10223a4)
    #7 decltype(static_cast<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9&>(fp)()) std::__1::__invoke<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9&>(CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9&) /usr/lib/llvm-13/bin/../include/c++/v1/type_traits:3918:1 (test_bitcoin+0x10223a4)
    #8 void std::__1::__invoke_void_return_wrapper<void, true>::__call<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9&>(CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9&) /usr/lib/llvm-13/bin/../include/c++/v1/__functional/invoke.h:61:9 (test_bitcoin+0x10223a4)
    #9 std::__1::__function::__alloc_func<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9, std::__1::allocator<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9>, void ()>::operator()() /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:171:16 (test_bitcoin+0x10223a4)
    #10 std::__1::__function::__func<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9, std::__1::allocator<CMainSignals::BlockConnected(std::__1::shared_ptr<CBlock const> const&, CBlockIndex const*)::$_9>, void ()>::operator()() /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:345:12 (test_bitcoin+0x10223a4)
    #11 std::__1::__function::__value_func<void ()>::operator()() const /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:498:16 (test_bitcoin+0x10b6b71)
    #12 std::__1::function<void ()>::operator()() const /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:1175:12 (test_bitcoin+0x10b6b71)
    #13 SingleThreadedSchedulerClient::ProcessQueue() src/scheduler.cpp:175:5 (test_bitcoin+0x10b6b71)
    #14 SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1::operator()() const src/scheduler.cpp:144:41 (test_bitcoin+0x10b8875)
    #15 decltype(static_cast<SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1&>(fp)()) std::__1::__invoke<SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1&>(SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1&) /usr/lib/llvm-13/bin/../include/c++/v1/type_traits:3918:1 (test_bitcoin+0x10b8875)
    #16 void std::__1::__invoke_void_return_wrapper<void, true>::__call<SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1&>(SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1&) /usr/lib/llvm-13/bin/../include/c++/v1/__functional/invoke.h:61:9 (test_bitcoin+0x10b8875)
    #17 std::__1::__function::__alloc_func<SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1, std::__1::allocator<SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1>, void ()>::operator()() /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:171:16 (test_bitcoin+0x10b8875)
    #18 std::__1::__function::__func<SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1, std::__1::allocator<SingleThreadedSchedulerClient::MaybeScheduleProcessQueue()::$_1>, void ()>::operator()() /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:345:12 (test_bitcoin+0x10b8875)
    #19 std::__1::__function::__value_func<void ()>::operator()() const /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:498:16 (test_bitcoin+0x10b5b5c)
    #20 std::__1::function<void ()>::operator()() const /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:1175:12 (test_bitcoin+0x10b5b5c)
    #21 CScheduler::serviceQueue() src/scheduler.cpp:62:17 (test_bitcoin+0x10b5b5c)
    #22 ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0::operator()() const src/test/util/setup_common.cpp:160:110 (test_bitcoin+0xa4e7b8)
    #23 decltype(static_cast<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0&>(fp)()) std::__1::__invoke<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0&>(ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0&) /usr/lib/llvm-13/bin/../include/c++/v1/type_traits:3918:1 (test_bitcoin+0xa4e7b8)
    #24 void std::__1::__invoke_void_return_wrapper<void, true>::__call<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0&>(ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0&) /usr/lib/llvm-13/bin/../include/c++/v1/__functional/invoke.h:61:9 (test_bitcoin+0xa4e7b8)
    #25 std::__1::__function::__alloc_func<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0, std::__1::allocator<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0>, void ()>::operator()() /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:171:16 (test_bitcoin+0xa4e7b8)
    #26 std::__1::__function::__func<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0, std::__1::allocator<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0>, void ()>::operator()() /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:345:12 (test_bitcoin+0xa4e7b8)
    #27 std::__1::__function::__value_func<void ()>::operator()() const /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:498:16 (test_bitcoin+0x115760f)
    #28 std::__1::function<void ()>::operator()() const /usr/lib/llvm-13/bin/../include/c++/v1/__functional/function.h:1175:12 (test_bitcoin+0x115760f)
    #29 util::TraceThread(char const*, std::__1::function<void ()>) src/util/thread.cpp:18:9 (test_bitcoin+0x115760f)
    #30 decltype(static_cast<void (*>(fp)(static_cast<char const*>(fp0), static_cast<ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0>(fp0))) std::__1::__invoke<void (*)(char const*, std::__1::function<void ()>), char const*, ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0>(void (*&&)(char const*, std::__1::function<void ()>), char const*&&, ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0&&) /usr/lib/llvm-13/bin/../include/c++/v1/type_traits:3918:1 (test_bitcoin+0xa4e3b1)
    #31 void std::__1::__thread_execute<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void (*)(char const*, std::__1::function<void ()>), char const*, ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0, 2ul, 3ul>(std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void (*)(char const*, std::__1::function<void ()>), char const*, ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0>&, std::__1::__tuple_indices<2ul, 3ul>) /usr/lib/llvm-13/bin/../include/c++/v1/thread:280:5 (test_bitcoin+0xa4e3b1)
    #32 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void (*)(char const*, std::__1::function<void ()>), char const*, ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0> >(void*) /usr/lib/llvm-13/bin/../include/c++/v1/thread:291:5 (test_bitcoin+0xa4e3b1)
  Location is stack of main thread.
  Location is global '??' at 0x7ffe0ef91000 ([stack]+0x00000001d9f8)
  Mutex M603 (0x558df2c934a0) created at:
    #0 pthread_mutex_init <null> (test_bitcoin+0x11cf6f)
    #1 std::__1::recursive_mutex::recursive_mutex() <null> (libc++.so.1+0x49fb3)
    #2 __libc_start_main <null> (libc.so.6+0x29eba)
  Thread T1 'b-scheduler' (tid=24216, running) created by main thread at:
    #0 pthread_create <null> (test_bitcoin+0x11b7fd)
    #1 std::__1::__libcpp_thread_create(unsigned long*, void* (*)(void*), void*) /usr/lib/llvm-13/bin/../include/c++/v1/__threading_support:443:10 (test_bitcoin+0xa47a76)
    #2 std::__1::thread::thread<void (&)(char const*, std::__1::function<void ()>), char const (&) [10], ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0, void>(void (&)(char const*, std::__1::function<void ()>), char const (&) [10], ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&)::$_0&&) /usr/lib/llvm-13/bin/../include/c++/v1/thread:307:16 (test_bitcoin+0xa47a76)
    #3 ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) src/test/util/setup_common.cpp:160:42 (test_bitcoin+0xa47a76)
    #4 TestingSetup::TestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) src/test/util/setup_common.cpp:198:7 (test_bitcoin+0xa47ed9)
    #5 TestChain100Setup::TestChain100Setup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) src/test/util/setup_common.cpp:246:7 (test_bitcoin+0xa48be3)
    #6 coinstatsindex_tests::coinstatsindex_initial_sync::coinstatsindex_initial_sync() src/test/coinstatsindex_tests.cpp:32:1 (test_bitcoin+0x3b7c8b)
    #7 coinstatsindex_tests::coinstatsindex_initial_sync_invoker() src/test/coinstatsindex_tests.cpp:32:1 (test_bitcoin+0x3b7c8b)
    #8 boost::detail::function::void_function_invoker0<void (*)(), void>::invoke(boost::detail::function::function_buffer&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:117:11 (test_bitcoin+0x2bbf1d)
    #9 boost::function0<void>::operator()() const /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:763:14 (test_bitcoin+0x220877)
    #10 boost::detail::forward::operator()() /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:1388:32 (test_bitcoin+0x220877)
    #11 boost::detail::function::function_obj_invoker0<boost::detail::forward, int>::invoke(boost::detail::function::function_buffer&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:137:18 (test_bitcoin+0x220877)
    #12 boost::function0<int>::operator()() const /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/function/function_template.hpp:763:14 (test_bitcoin+0x1ae59e)
    #13 int boost::detail::do_invoke<boost::shared_ptr<boost::detail::translator_holder_base>, boost::function<int ()> >(boost::shared_ptr<boost::detail::translator_holder_base> const&, boost::function<int ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:301:30 (test_bitcoin+0x1ae59e)
    #14 boost::execution_monitor::catch_signals(boost::function<int ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:903:16 (test_bitcoin+0x1ae59e)
    #15 boost::execution_monitor::execute(boost::function<int ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:1301:16 (test_bitcoin+0x1ae8c0)
    #16 boost::execution_monitor::vexecute(boost::function<void ()> const&) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/execution_monitor.ipp:1397:5 (test_bitcoin+0x1aa21b)
    #17 boost::unit_test::unit_test_monitor_t::execute_and_translate(boost::function<void ()> const&, unsigned long) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/unit_test_monitor.ipp:49:9 (test_bitcoin+0x1aa21b)
    #18 boost::unit_test::framework::state::execute_test_tree(unsigned long, unsigned long, boost::unit_test::framework::state::random_generator_helper const*) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:815:44 (test_bitcoin+0x1ddb63)
    #19 boost::unit_test::framework::state::execute_test_tree(unsigned long, unsigned long, boost::unit_test::framework::state::random_generator_helper const*) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:784:58 (test_bitcoin+0x1de1d8)
    #20 boost::unit_test::framework::state::execute_test_tree(unsigned long, unsigned long, boost::unit_test::framework::state::random_generator_helper const*) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:784:58 (test_bitcoin+0x1de1d8)
    #21 boost::unit_test::framework::run(unsigned long, bool) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/framework.ipp:1721:29 (test_bitcoin+0x1a8e66)
    #22 boost::unit_test::unit_test_main(boost::unit_test::test_suite* (*)(int, char**), int, char**) /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/unit_test_main.ipp:250:9 (test_bitcoin+0x1c19c6)
    #23 main /tmp/cirrus-ci-build/depends/x86_64-pc-linux-gnu/include/boost/test/impl/unit_test_main.ipp:306:12 (test_bitcoin+0x1c1ff6)
SUMMARY: ThreadSanitizer: data race on vptr (ctor/dtor vs virtual call) src/index/base.cpp:53:1 in BaseIndex::~BaseIndex()
==================
Exit status: 2
```"
bitcoin/bitcoin,2022-06-02 01:17:49,bug,./wallet/bdb.h:27:10: fatal error: db_cxx.h: No such file or directory,"I'm having build error with current master (1c7ef0abd11f35a27cc860ceb7e075b78f53cecf), with Gentoo Linux:
```
$ make clean
$ ./autogen.sh
$ ./configure
$ make
...
  CXX      qt/libbitcoinqt_a-rpcconsole.o
In file included from qt/rpcconsole.cpp:32:
./wallet/bdb.h:27:10: fatal error: db_cxx.h: No such file or directory
   27 | #include <db_cxx.h>
      |          ^~~~~~~~~~
compilation terminated.
$ locate db_cxx.h
/usr/include/db4.8/db_cxx.h
/usr/include/db5.3/db_cxx.h
```

Reverting 46a890960e4b07e5aec479aa8e07e9c34ce68aee (#25244) fixes the problem."
bitcoin/bitcoin,2022-05-27 13:20:02,bug,nlocktime bug in Bitcoin Core v23,"Recreating the bug report https://github.com/bitcoin/bitcoin/issues/25225 because the previous one closed by a party who doesn't know nothing about Bitcoin apparently.

**Block height** for nlocktime doesn't work and this poses a **serious risk for smart contracts**.

I have added block height to nlocktime and got converted to timestamp which corresponds to 1970/04/20 21:25:25 

Found this bug when verifying a raw transaction. "
bitcoin/bitcoin,2022-05-25 15:10:36,bug,"depends bdb -Werror=format-security ""format not a string literal and no format arguments""","Running `make -C depends` on nixos with gcc 10.3.0 results in

```c++
libtool: compile:  gcc -c -I. -I../dist/./.. -I/home/russ/work/bitcoin/depends/x86_64-pc-linux-gnu/include -D_GNU_SOURCE -D_REENTRANT -pipe -O2 -Wno-error=implicit-function-declaration ../dist/./../txn/txn.c  -fPIC -DPIC -o txn.o
../dist/./../txn/txn.c: In function ‘__txn_begin’:
../dist/./../txn/txn.c:171:3: error: format not a string literal and no format arguments [-Werror=format-security]
  171 |   __db_errx(env, TxnAlloc);
      |   ^~~~~~~~~
../dist/./../txn/txn.c: In function ‘__txn_compensate_begin’:
../dist/./../txn/txn.c:318:3: error: format not a string literal and no format arguments [-Werror=format-security]
  318 |   __db_errx(env, TxnAlloc);
      |   ^~~~~~~~~
cc1: some warnings being treated as errors
make[1]: *** [Makefile:1980: txn.o] Error 1
make[1]: Leaving directory '/home/russ/work/bitcoin/depends/work/build/x86_64-pc-linux-gnu/bdb/4.8.30-1205703c56a/build_unix'
make: *** [funcs.mk:288: /home/russ/work/bitcoin/depends/work/build/x86_64-pc-linux-gnu/bdb/4.8.30-1205703c56a/build_unix/.stamp_built] Error 2
make: Leaving directory '/home/russ/work/bitcoin/depends'
```

I could work around it with

```diff
diff --git a/depends/packages/bdb.mk b/depends/packages/bdb.mk
index dc536fd3991..b69276cb154 100644
--- a/depends/packages/bdb.mk
+++ b/depends/packages/bdb.mk
@@ -14,7 +14,7 @@ $(package)_config_opts_freebsd=--with-pic
 $(package)_config_opts_netbsd=--with-pic
 $(package)_config_opts_openbsd=--with-pic
 $(package)_config_opts_android=--with-pic
-$(package)_cflags+=-Wno-error=implicit-function-declaration
+$(package)_cflags+=-Wno-error=implicit-function-declaration -Wno-error=format-security
 $(package)_cxxflags+=-std=c++17
 $(package)_cppflags_mingw32=-DUNICODE -D_UNICODE
 endef

```

But I don't know if this is the right fix or if there possibly is a real bug in the code causing the warning."
bitcoin/bitcoin,2022-05-16 17:48:13,bug,Starting with an unsupported wallet configured leads to a segfault (master only?),"```
#0  __ubsan::UBsanOnDeadlySignal(int, void*, void*) ()
    at /var/tmp/portage/sys-libs/compiler-rt-sanitizers-13.0.1/work/compiler-rt/lib/ubsan/ubsan_signals_standalone.cpp:53
#1  <signal handler called>
#2  std::__detail::_List_node_base::_M_unhook (this=0x13dca9a70)
    at /var/tmp/portage/sys-devel/gcc-11.2.0/work/gcc-11.2.0/libstdc++-v3/src/c++98/list.cc:141
#3  0x000000011f25c9c0 in std::__cxx11::list<std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>, std::allocator<std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)> > >::_M_erase(std::_List_iterator<std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)> >) (this=0x7ffef8013e98, __position=...)
    at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/stl_list.h:1922
#4  0x000000011f241cc4 in std::__cxx11::list<std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>, std::allocator<std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)> > >::erase(std::_List_const_iterator<std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)> >) (this=0x7ffef8013e98, __position=...)
    at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/list.tcc:158
#5  wallet::HandleLoadWallet(wallet::WalletContext&, std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>)::$_1::operator()() const (this=<optimized out>) at wallet/wallet.cpp:165
#6  std::__invoke_impl<void, wallet::HandleLoadWallet(wallet::WalletContext&, std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>)::$_1&>(std::__invoke_other, wallet::HandleLoadWallet(wallet::WalletContext&, std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>)::$_1&) (__f=...) at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/invoke.h:61
#7  std::__invoke_r<void, wallet::HandleLoadWallet(wallet::WalletContext&, std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>)::$_1&>(wallet::HandleLoadWallet(wallet::WalletContext&, std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>)::$_1&) (__fn=...) at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/invoke.h:111
#8  std::_Function_handler<void (), wallet::HandleLoadWallet(wallet::WalletContext&, std::function<void (std::unique_ptr<interfaces::Wallet, std::default_delete<interfaces::Wallet> >)>)::$_1>::_M_invoke(std::_Any_data const&) (__functor=...)
    at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/std_function.h:291
#9  0x000000011e8fb1f8 in std::function<void ()>::operator()() const (this=<optimized out>)
    at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/std_function.h:560
#10 0x000000011f08d6c0 in interfaces::(anonymous namespace)::CleanupHandler::~CleanupHandler (this=0x7ffef801edd0) at interfaces/handler.cpp:28
#11 0x000000011f08d7fc in interfaces::(anonymous namespace)::CleanupHandler::~CleanupHandler (this=0x7ffef801edd0) at interfaces/handler.cpp:28
#12 0x000000011e7fcd34 in std::default_delete<interfaces::Handler>::operator() (__ptr=0x7ffef801edd0, this=<optimized out>) at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/unique_ptr.h:85
#13 std::unique_ptr<interfaces::Handler, std::default_delete<interfaces::Handler> >::~unique_ptr (this=<optimized out>) at /usr/lib/gcc/powerpc64le-unknown-linux-gnu/11.2.0/include/g++-v11/bits/unique_ptr.h:361
#14 0x000000011e90e038 in SplashScreen::~SplashScreen (this=0x13dc49f00) at qt/splashscreen.cpp:138
#15 0x000000011e90e6ec in SplashScreen::~SplashScreen (this=0x13dc49f00) at qt/splashscreen.cpp:136
#16 0x00007fffa4ff35f4 in qDeleteInEventHandler (o=<optimized out>) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qobject.cpp:4815
#17 0x00007fffa4ff8550 in QObject::event (this=<optimized out>, e=<optimized out>) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qobject.cpp:1301
#18 0x00007fffa45bd41c in QWidget::event (this=0x13dc49f00, event=0x7fff98023f40) at /var/tmp/portage/dev-qt/qtwidgets-5.15.3/work/qtbase-everywhere-src-5.15.3/src/widgets/kernel/qwidget.cpp:9094
#19 0x00007fffa455da70 in QApplicationPrivate::notify_helper (this=<optimized out>, receiver=0x13dc49f00, e=0x7fff98023f40) at /var/tmp/portage/dev-qt/qtwidgets-5.15.3/work/qtbase-everywhere-src-5.15.3/src/widgets/kernel/qapplication.cpp:3637
#20 0x00007fffa4569374 in QApplication::notify (this=0x7ffff9f207a0, receiver=0x13dc49f00, e=0x7fff98023f40) at /var/tmp/portage/dev-qt/qtwidgets-5.15.3/work/qtbase-everywhere-src-5.15.3/src/widgets/kernel/qapplication.cpp:3587
#21 0x00007fffa4faec80 in QCoreApplication::notifyInternal2 (receiver=0x13dc49f00, event=0x7fff98023f40) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qcoreapplication.cpp:1064
#22 0x00007fffa4faf00c in QCoreApplication::sendEvent (receiver=<optimized out>, event=<optimized out>) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qcoreapplication.cpp:1462
#23 0x00007fffa4fb3ee4 in QCoreApplicationPrivate::sendPostedEvents (receiver=0x0, event_type=0, data=0x13dad8900) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qcoreapplication.cpp:1821
#24 0x00007fffa4fb4244 in QCoreApplication::sendPostedEvents (receiver=0x0, event_type=<optimized out>) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qcoreapplication.cpp:1680
#25 0x00007fffa5037290 in postEventSourceDispatch (s=0x13dbb9ce0) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qeventdispatcher_glib.cpp:277
#26 0x00007fffa22e9794 in g_main_dispatch (context=context@entry=0x7fff98019230) at ../glib-2.70.4/glib/gmain.c:3381
#27 0x00007fffa22ee930 in g_main_context_dispatch (context=0x7fff98019230) at ../glib-2.70.4/glib/gmain.c:4099
#28 0x00007fffa22eeb58 in g_main_context_iterate (context=context@entry=0x7fff98019230, block=block@entry=1, dispatch=dispatch@entry=1, self=<optimized out>) at ../glib-2.70.4/glib/gmain.c:4175
#29 0x00007fffa22eec60 in g_main_context_iteration (context=0x7fff98019230, may_block=<optimized out>) at ../glib-2.70.4/glib/gmain.c:4240
#30 0x00007fffa5036e7c in QEventDispatcherGlib::processEvents (this=0x13dbbcc70, flags=...) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qeventdispatcher_glib.cpp:423
#31 0x00007fff9ef44e64 in QXcbGlibEventDispatcher::processEvents (this=<optimized out>, flags=...) at /var/tmp/portage/dev-qt/qtgui-5.15.3/work/qtbase-everywhere-src-5.15.3/src/plugins/platforms/xcb/qxcbeventdispatcher.cpp:143
#32 0x00007fffa4fabcc8 in QEventLoop::processEvents (this=<optimized out>, flags=...) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/src/corelib/kernel/qeventloop.cpp:139
#33 0x00007fffa4fac488 in QEventLoop::exec (this=0x7ffff9f204c8, flags=...) at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/include/QtCore/../../src/corelib/global/qflags.h:69
#34 0x00007fffa4fb9588 in QCoreApplication::exec () at /var/tmp/portage/dev-qt/qtcore-5.15.3/work/qtbase-everywhere-src-5.15.3/include/QtCore/../../src/corelib/global/qflags.h:121
#35 0x00007fffa3d5704c in QGuiApplication::exec () at /var/tmp/portage/dev-qt/qtgui-5.15.3/work/qtbase-everywhere-src-5.15.3/src/gui/kernel/qguiapplication.cpp:1867
#36 0x00007fffa455d98c in QApplication::exec () at /var/tmp/portage/dev-qt/qtwidgets-5.15.3/work/qtbase-everywhere-src-5.15.3/src/widgets/kernel/qapplication.cpp:2829
#37 0x000000011e7b4354 in GuiMain (argc=<optimized out>, argv=<optimized out>) at qt/bitcoin.cpp:661
#38 0x000000011e7ac070 in main (argc=<optimized out>, argv=<optimized out>) at qt/main.cpp:21
```"
bitcoin/bitcoin,2022-05-13 12:33:52,bug,rpc: createmultisig adds incorrect warning for address type p2sh-segwit,"The `createmultisig` RPC adds a spurious warning message when creating for address type p2sh-segwit.

```
createmultisig 2 '[""0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798"", ""0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798""]' 'p2sh-segwit'
{
  ""address"": ""3QfZQY7wQrBGEUB7E5vVLggeeAUVZ1Bbg9"",
  ""redeemScript"": ""52210279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798210279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f8179852ae"",
  ""descriptor"": ""sh(wsh(multi(2,0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798,0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798)))#m8ww0c9m"",
  ""warnings"": [
    ""Unable to make chosen address type, please ensure no uncompressed public keys are present.""
  ]
}
```

I think this traces back to https://github.com/bitcoin/bitcoin/pull/23113

In the code, the comparison at https://github.com/bitcoin/bitcoin/blob/225e5b57b2ee2bc1acd7f09c89ccccc15ef8c85f/src/rpc/output_script.cpp#L166 fails since `output_type` is `OutputType::P2SH_SEGWIT` and https://github.com/bitcoin/bitcoin/blob/225e5b57b2ee2bc1acd7f09c89ccccc15ef8c85f/src/outputtype.cpp#L112 returns `OutputType::LEGACY`

**Expected behavior**

No warning message. For example:

```
createmultisig 2 '[""0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798"", ""0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798""]' 'p2sh-segwit'
{
  ""address"": ""3QfZQY7wQrBGEUB7E5vVLggeeAUVZ1Bbg9"",
  ""redeemScript"": ""52210279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798210279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f8179852ae"",
  ""descriptor"": ""sh(wsh(multi(2,0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798,0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798)))#m8ww0c9m""
}
```"
bitcoin/bitcoin,2022-05-07 21:38:45,bug,Guix build w/o substitutes failing at libgit2 check,"This is an upstream Guix issue ([55273](https://debbugs.gnu.org/cgi/bugreport.cgi?bug=55273)), but they seem to be planning to resolve it with a version bump, and either way we have versions pinned I think.

```
building /gnu/store/myai2xf4f0z2nr331mx2y4xr4jv1lwid-libgit2-1.3.0.drv...
| 'unpack' phaseild-log 356 178
`/gnu/store/xa8yg9nvawhfvk6hv8lhif9z5pybzan5-libgit2-1.3.0-checkout/tests/resources/status/staged_delete_modified_file' -> `./tests/resources/status/staged_delete_modified_file'
 17% [########################                                                                                                                           ]ild-log 356 189
/tmp/guix-build-libgit2-1.3.0.drv-0/source/src/regexp.c:148:5: warning: ?error? may be used uninitialized in this function [-Wmaybe-uninitialized]
  148 |  if (error < 0)
      |     ^
 17% [########################                                                                                                                           ]ild-log 356 72
[ 18%] Building C object src/CMakeFiles/git2internal.dir/repository.c.o
| 'check' phasenote: keeping build directory `/tmp/guix-build-libgit2-1.3.0.drv-0'
builder for `/gnu/store/myai2xf4f0z2nr331mx2y4xr4jv1lwid-libgit2-1.3.0.drv' failed with exit code 1
build of /gnu/store/myai2xf4f0z2nr331mx2y4xr4jv1lwid-libgit2-1.3.0.drv failed
```

```
refs::revparse.................F

  1) Failure:
refs::revparse::date [/tmp/guix-build-libgit2-1.3.0.drv-0/source/tests/refs/revparse.c:31]
  Function call succeeded: error
  no error, expected non-zero return
```

"
bitcoin/bitcoin,2022-05-05 09:52:51,bug,Bitcoin Core wallet -> HD key generation disabled,"The Bitcoin Core wallet window has icons in the lower right corner. One of those icons is the letters ""HD"". With the v.22.0 version when passing the mouse cursor over this icon, a message appeared which said ""HD key generation is enabled"". However, after downloading the latest version of Bitcoin Core, 23.0, the message that appears to me is the opposite: ""HD key generation is disabled"". (1st screenshot).

The wallet had no funds and, in that sense, I have not lost anything. But I am concerned that after upgrading Bitcoin Core to the latest version, the HD key generation has changed. I'm pretty new to this and don't understand much. I have asked, read and looked for some solution but no one has been able to tell me what happens, whether it is normal or not, what the solution is...etc.

Also note that, when using the ""getwalletinfo"" command in the Bitcoin Core console, appeared this (2nd screenshot) and that I do not know if it refers to the same (HD key generation) or not.

Also tried to upgrade the bitcoin core wallet with the ""upgradewallet"" comand. (3rd screenshot)

I got the latest version of bitcoin core from: https://bitcoincore.org/. And i got this url from the Bitcoin Core Project profile on twitter.

My OS is windows 10 Pro. And my CPU is a Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz   3.20 GHz.

For me this is first time doing this...so sorry for what might be wrong, and sorry for my english (i do not speak it well enough)


![Captura de pantalla 2022-05-05 113132](https://user-images.githubusercontent.com/102556812/166897054-de8b92e4-dd8c-4aa1-8036-a6afed27cdcd.png)
![Captura de pantalla 2022-05-01 200018](https://user-images.githubusercontent.com/102556812/166898222-f384fe51-f54d-4636-96fd-566b46ee8d69.png)
![UPGRADE WALLET](https://user-images.githubusercontent.com/102556812/166899581-9801e82e-94f7-4c8e-a37e-ec07580255c8.png)

"
bitcoin/bitcoin,2022-05-02 08:34:02,bug,Automatic prune on Tails OS,"Running Bitcoin Core full node on Tails OS

New version 23.0 automatically prunes when started. I don't want to prune and have therefore set prune=0 in bitcoin.conf. But that won't stop 23.0 from pruning. Have to manually un-tick the tick box at startup. This was never the case in 22.0 so wondering if prune=0 is disabled even though its stated in options:

![image](https://user-images.githubusercontent.com/83304971/166206911-47aa4148-d79a-4106-98bf-e62efd016a1e.png)
"
bitcoin/bitcoin,2022-04-29 21:07:48,bug,BUG  ./configure  /install,"
After the latest update
Can not be installed
In the ./configure section with the following problem

 ./configure

.
.
.
checking dependency style of g++... gcc3
checking whether g++ supports C++17 features with -std=c++17... yes
checking whether std::atomic can be used without link library... yes
checking whether std::filesystem can be used without link library... no
checking whether std::filesystem needs -lstdc++fs... no
checking whether std::filesystem needs -lc++fs... configure: error: in `/home/bi                                                                             tcoin':
configure: error: cannot figure out how to use std::filesystem
See `config.log' for more details


"
bitcoin/bitcoin,2022-04-29 14:23:59,bug,"wallet_taproot.py fails with ""Insufficient funds (-4)""","```
 test  2022-04-29T13:16:35.409000Z TestFramework (ERROR): JSONRPC error 
                                   Traceback (most recent call last):
                                     File ""/private/var/folders/xx/vl5f934s6k927z1vyyl9cxth0000gn/T/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-apple-darwin/test/functional/test_framework/test_framework.py"", line 133, in main
                                       self.run_test()
                                     File ""/private/var/folders/xx/vl5f934s6k927z1vyyl9cxth0000gn/T/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-apple-darwin/test/functional/wallet_taproot.py"", line 448, in run_test
                                       psbt = self.psbt_online.walletcreatefundedpsbt([], [{self.boring.getnewaddress(): self.psbt_online.getbalance()}], None, {""subtractFeeFromOutputs"": [0]})['psbt']
                                     File ""/private/var/folders/xx/vl5f934s6k927z1vyyl9cxth0000gn/T/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-apple-darwin/test/functional/test_framework/coverage.py"", line 49, in __call__
                                       return_val = self.auth_service_proxy_instance.__call__(*args, **kwargs)
                                     File ""/private/var/folders/xx/vl5f934s6k927z1vyyl9cxth0000gn/T/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-apple-darwin/test/functional/test_framework/authproxy.py"", line 144, in __call__
                                       raise JSONRPCException(response['error'], status)
                                   test_framework.authproxy.JSONRPCException: Insufficient funds (-4)
```

https://cirrus-ci.com/task/5522204518514688?logs=ci#L1609

"
bitcoin/bitcoin,2022-04-25 23:57:58,bug,wallet: ignore chainStateFlushed notifications while attaching chain,"Fixes #24487

When a rescan is performed during `CWallet::AttachChain()` (e.g. when loading an old wallet) but this is interrupted by a shutdown signal, the wallet will currently stop the rescan, receive a `chainStateFlushed` signal, set the saved best block to the tip and shut down. At next startup, the rescan is not continued or repeated because of this. But some blocks have never been scanned by the wallet, which could lead to an incorrect balance.

Fix this by ignoring `chainStateFlushed` notifications until the chain is attached. Since `CWallet::chainStateFlushed` is being manually called by `AttachChain()` anyway after finishing with the rescan, it is not a problem if intermediate notifications are ignored.

Manual rescans started / aborted by the `rescanblockchain` / `abortrescan` RPCs are not affected by this.

I didn't choose alternative ways of fixing this issue that would delay the validationinterface registration or change anything else about the handling of `blockConnected` signals for the reasons mentioned in [this existing comment](https://github.com/bitcoin/bitcoin/blob/master/src/wallet/wallet.cpp#L2937-L2944)."
bitcoin/bitcoin,2022-04-25 18:12:35,bug,"-onlynet=onion plus -onlynet=ipv4/etc, without -onion=, in spite of -torcontrol= specified, incorrectly kills startup","In v22, using the options: -onlynet=onion -onlynet=ipv4 -onlynet=ipv6, combined with the options -torcontrol= (etc) functioned and bitcoind correctly pulled the onion socks address via a probe to tor. In v23, that combination of options no longer functions and -onion= is required.

** expected **

Using -onlynet=onion (and ipv4 and ipv6) if -torcontrol= is specified should still work.

**Actual behavior**

bitcoind refuses to start up due to commitid e53a8505db preventing it from doing so in init.cpp.

**To reproduce**

Run as per above.

**System information**

Sources built from fcf6c8f4eb217763545ede1766831a6b93f583bd (tag v23.0 as of this writing I .. think?)

Error message in debug.log is:

Error: Outbound connections restricted to Tor (-onlynet=onion) but the proxy for reaching the Tor network is not provided
(no -proxy= and no -onion= given) or it is explicitly forbidden (-onion=0)
Shutdown: In progress...
scheduler thread exit
Shutdown: done
"
bitcoin/bitcoin,2022-04-22 14:55:18,bug,RPC: Calls to Bitcoin RPC are truncated.,"# RPC: Calls to Bitcoin RPC are truncated.

I'm having a problem making batching calls to Bitcoin RPC it is returning a truncated JSON, my suspicions is that there is some max-size for the response of requests, if that is true it should return a `message error`.

Bitcoin Core Version: `22.0`

To reproduce the problem:

```bash
curl -X POST http://user:password@127.0.0.1:8332 -d '[{""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000000b3f09b8c8543f319154284e73974313edf8cc0fadefb"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000005fd813bc5abf8406a428fdc2d998ae1fcda34c618282b"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""000000000000000000056f516b8d0c5810f6d22d5172093fd4b9ccdb5a5b51c3"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""0000000000000000000677330a2cb375a6b4098e79f6c5c5de147ec7007a05e6"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""0000000000000000000076b356851724eafeb9e402d8ca3d28876c811e64822f"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""000000000000000000070b1e3f9ed6b431dd31e4e2c6715aa0a0adb4a358bc12"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000008e0074bc06cf8f802c1f78de66782d9555688e3fe8b2f"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""0000000000000000000990e84241724e4cbd313f6a50dd9c6e7fa8cb0a186e8f"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""0000000000000000000362f6e349459fe90a1aeddc9c24cae12377146db32e54"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000006c9812479c7c1e3b352e3347830cae56cef62713ac070"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000006d5ca16560698cf9452715fad427a1b8fe371d23794c6"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000000081808279c53523533773e56593d8dc383c01764ac64"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""000000000000000000002f582f11911747441be90bb63337079d39b7a844f4e4"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000003017b46d0da7ff6865b79248510656997108a00db1855"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""000000000000000000068bea85c817bf7ebb3128126e5c6ed50d514c81356835"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""0000000000000000000196fc11d94c524ae490382c8ed5ea383e8c8a5fd6998c"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000003ea4bc617c404920643c75b94ffc090304b19a9d51391"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""000000000000000000078c80926de91a3b6b7b8572acf09ca80b945789fe55b7"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""000000000000000000059710e78d84f7e3e35e61b0e254b957d58b7c325bf2d2"", 0]}, {""jsonrpc"": ""2.0"", ""method"": ""getblock"", ""params"": [""00000000000000000000b054a83708138c04ab9c97f5d9983e34b9f145d24f73"", 0]}]' -H 'Content-Type:application/json' --silent
```
"
bitcoin/bitcoin,2022-04-09 22:41:23,bug,Unresponsive CLI,"Issue report #24810 reminds me that I've been seeing a similar issue since several months on master built with --enable-debug in my development environment, where the CLI becomes unresponsive and eventually returns:

```
error: timeout on transient error: Could not connect to the server 127.0.0.1:8332 (error code 0 - ""timeout reached"")

Make sure the bitcoind server is running and that you are connecting to the correct RPC port.
```

Once the CLI becomes unresponsive, it seems to happen with any CLI command.  This didn't occur for me with v21 and I'm not sure about v22, as IIRC it began sometime last Fall (2021) for me.  Until now I've been discounting it as something related to my local environment and working around it by restarting, since I restart very often for review and testing.

Debian testing, currently Debian 5.16.18-1 (2022-03-29) x86_64 GNU/Linux.

I'm going to try to narrow down the issue more.

Is anyone else running into this?
"
bitcoin/bitcoin,2022-04-05 17:14:06,bug,build: Do not modify `common.init.vcxproj` directly,"When building with MSVC, and using a non-default toolset, the following command
```
>python build_msvc\\msvc-autogen.py -toolset v143
```
actually modifies the source tree:
```diff
>git diff
warning: LF will be replaced by CRLF in build_msvc/common.init.vcxproj.
The file will have its original line endings in your working directory
diff --git a/build_msvc/common.init.vcxproj b/build_msvc/common.init.vcxproj
index 0cbe2effd..44b7efff3 100644
--- a/build_msvc/common.init.vcxproj
+++ b/build_msvc/common.init.vcxproj
@@ -39,7 +39,7 @@
   <PropertyGroup Condition=""'$(Configuration)'=='Release'"" Label=""Configuration"">
     <LinkIncremental>false</LinkIncremental>
     <UseDebugLibraries>false</UseDebugLibraries>
-    <PlatformToolset>v142</PlatformToolset>
+    <PlatformToolset>v143</PlatformToolset>
     <CharacterSet>Unicode</CharacterSet>
     <GenerateManifest>No</GenerateManifest>
     <OutDir>$(SolutionDir)$(Platform)\\$(Configuration)\\$(ProjectName)\\</OutDir>
@@ -49,7 +49,7 @@
   <PropertyGroup Condition=""'$(Configuration)'=='Debug'"" Label=""Configuration"">
     <LinkIncremental>true</LinkIncremental>
     <UseDebugLibraries>true</UseDebugLibraries>
-    <PlatformToolset>v142</PlatformToolset>
+    <PlatformToolset>v143</PlatformToolset>
     <CharacterSet>Unicode</CharacterSet>
     <OutDir>$(SolutionDir)$(Platform)\\$(Configuration)\\$(ProjectName)\\</OutDir>
     <IntDir>$(Platform)\\$(Configuration)\\$(ProjectName)\\</IntDir>

```

This PR fixes this bug."
bitcoin/bitcoin,2022-04-01 06:55:10,bug,Race in generatetoaddress?,"Test failure at https://cirrus-ci.com/task/5291668088815616?logs=ci#L3216 seems to indicate `generatetoaddress` has a path that doesn't set the height in coinbase correctly.

RPC call:

```
 node1 2022-03-31T22:42:56.024486Z [httpworker.2] [rpc/request.cpp:179] [parse] ThreadRPCServer method=generatetoaddress user=__cookie__ 
```

A new block immediately arrives over the network via the `msghand` thread:

```
 node1 2022-03-31T22:42:56.024658Z [httpworker.2] [logging/timer.h:57] [Log] Enter: lock contention cs_main, rpc/mining.cpp:156 started 
 node1 2022-03-31T22:42:56.026452Z [msghand] [validationinterface.cpp:254] [NewPoWValidBlock] NewPoWValidBlock: block hash=7b7df2920d9870cb286408956ea95f6d307bb87dfd446bce18e4c35f7fe3651b 
 node1 2022-03-31T22:42:56.028907Z [httpworker.2] [logging/timer.h:57] [Log] Enter: lock contention cs_main, rpc/mining.cpp:156 completed (4225μs)
 ```

Then `msghand` gets held up in the middle of `ActivateBestChain`:
 
``` 
[...short lock contention...]
 node1 2022-03-31T22:42:56.029082Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention cs_main, validation.cpp:2889 started 
 node1 2022-03-31T22:42:56.029188Z [httpworker.2] [node/miner.cpp:160] [CreateNewBlock] CreateNewBlock(): block weight: 892 txs: 0 fees: 0 sigops 400 
 node1 2022-03-31T22:42:56.029339Z [httpworker.2] [validation.cpp:1988] [ConnectBlock]     - Sanity checks: 0.01ms [0.00s (0.00ms/blk)] 
 node1 2022-03-31T22:42:56.029411Z [httpworker.2] [validation.cpp:2087] [ConnectBlock]     - Fork checks: 0.08ms [0.01s (0.08ms/blk)] 
 node1 2022-03-31T22:42:56.029448Z [httpworker.2] [validation.cpp:2172] [ConnectBlock]       - Connect 1 transactions: 0.04ms (0.035ms/tx, 0.000ms/txin) [0.01s (0.05ms/blk)] 
 node1 2022-03-31T22:42:56.029486Z [httpworker.2] [validation.cpp:2185] [ConnectBlock]     - Verify 0 txins: 0.07ms (0.000ms/txin) [0.01s (0.10ms/blk)] 
 node1 2022-03-31T22:42:56.029522Z [httpworker.2] [node/miner.cpp:175] [CreateNewBlock] CreateNewBlock() packages: 0.15ms (0 packages, 0 updated descendants), validity: 0.40ms (total 0.55ms) 
 node1 2022-03-31T22:42:56.029554Z [httpworker.2] [logging/timer.h:57] [Log] Enter: lock contention cs_main, rpc/mining.cpp:124 started 
 node1 2022-03-31T22:42:56.029586Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention cs_main, validation.cpp:2889 completed (446μs)
```

At this point `msghand` has the ball again, and `httpworker.2` is waiting before calling `IncrementExtraNonce` which is where the height in coinbase is set.

```
 node1 2022-03-31T22:42:56.029678Z [msghand] [validation.cpp:2617] [ConnectTip]   - Load block from disk: 0.00ms [0.00s] 
 node1 2022-03-31T22:42:56.029743Z [msghand] [validation.cpp:1988] [ConnectBlock]     - Sanity checks: 0.00ms [0.00s (0.00ms/blk)] 
 node1 2022-03-31T22:42:56.029823Z [msghand] [validation.cpp:2087] [ConnectBlock]     - Fork checks: 0.08ms [0.01s (0.08ms/blk)] 
 node1 2022-03-31T22:42:56.029877Z [msghand] [validation.cpp:2172] [ConnectBlock]       - Connect 1 transactions: 0.05ms (0.049ms/tx, 0.000ms/txin) [0.01s (0.05ms/blk)] 
 node1 2022-03-31T22:42:56.029919Z [msghand] [validation.cpp:2185] [ConnectBlock]     - Verify 0 txins: 0.09ms (0.000ms/txin) [0.01s (0.10ms/blk)] 
 node1 2022-03-31T22:42:56.030054Z [msghand] [validation.cpp:2204] [ConnectBlock]     - Index writing: 0.14ms [0.01s (0.08ms/blk)] 
 node1 2022-03-31T22:42:56.030101Z [msghand] [validationinterface.cpp:249] [BlockChecked] BlockChecked: block hash=7b7df2920d9870cb286408956ea95f6d307bb87dfd446bce18e4c35f7fe3651b state=Valid 
 node1 2022-03-31T22:42:56.030173Z [msghand] [validation.cpp:2629] [ConnectTip]   - Connect total: 0.50ms [0.05s (0.37ms/blk)] 
 node1 2022-03-31T22:42:56.030208Z [msghand] [validation.cpp:2634] [ConnectTip]   - Flush: 0.04ms [0.00s (0.03ms/blk)] 
 node1 2022-03-31T22:42:56.030268Z [msghand] [validation.cpp:2640] [ConnectTip]   - Writing chainstate: 0.06ms [0.01s (0.04ms/blk)] 
 node1 2022-03-31T22:42:56.031702Z [msghand] [policy/fees.cpp:654] [processBlock] Blockpolicy estimates updated by 0 of 0 block txs, since last block 0 of 0 tracked, mempool map size 0, max target 51 from current 
 node1 2022-03-31T22:42:56.031821Z [msghand] [validation.cpp:2433] [UpdateTipLog] UpdateTip: new best=7b7df2920d9870cb286408956ea95f6d307bb87dfd446bce18e4c35f7fe3651b height=305 version=0x30000000 log2_work=9.257388 tx=310 date='2022-03-31T22:43:07Z' progress=1.000000 cache=0.0MiB(112txo) 
 node1 2022-03-31T22:42:56.031851Z [msghand] [validation.cpp:2651] [ConnectTip]   - Connect postprocess: 1.58ms [0.16s (1.14ms/blk)] 
 node1 2022-03-31T22:42:56.031877Z [msghand] [validation.cpp:2652] [ConnectTip] - Connect block: 2.18ms [0.22s (1.58ms/blk)] 
 node1 2022-03-31T22:42:56.031914Z [msghand] [txmempool.cpp:722] [check] Checking mempool with 0 transactions and 0 inputs 
 node1 2022-03-31T22:42:56.032021Z [msghand] [validationinterface.cpp:226] [BlockConnected] Enqueuing BlockConnected: block hash=7b7df2920d9870cb286408956ea95f6d307bb87dfd446bce18e4c35f7fe3651b block height=305 
 node1 2022-03-31T22:42:56.032089Z [msghand] [validationinterface.cpp:199] [UpdatedBlockTip] Enqueuing UpdatedBlockTip: new block hash=7b7df2920d9870cb286408956ea95f6d307bb87dfd446bce18e4c35f7fe3651b fork block hash=7b0602dccb1e34108167e32238ec6011d29eae6da3f9e4430165bc0ecd5283d7 (in IBD=false)
```

Now the tip has been updated. Looks like `msghand` releases the lock, but manages to reacquire it before any other thread:

 ```
 node1 2022-03-31T22:42:56.032134Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention newTaskMutex, scheduler.cpp:78 started 
 node1 2022-03-31T22:42:56.032167Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention newTaskMutex, scheduler.cpp:78 completed (3μs) 
```

The `scheduler` thread seems to get the lock next:

```
 node1 2022-03-31T22:42:56.032194Z [scheduler] [validationinterface.cpp:226] [operator()] BlockConnected: block hash=7b7df2920d9870cb286408956ea95f6d307bb87dfd446bce18e4c35f7fe3651b block height=305 
 node1 2022-03-31T22:42:56.032261Z [scheduler] [logging/timer.h:57] [Log] Enter: lock contention cs_main, net_processing.cpp:1596 started 
 node1 2022-03-31T22:42:56.034681Z [scheduler] [logging/timer.h:57] [Log] Enter: lock contention cs_main, net_processing.cpp:1596 completed (2398μs) 
```

And finally `httpworker.2` gets it, incrementing the extra nonce, and presumably updating to the new block.

```
 node1 2022-03-31T22:42:56.034725Z [httpworker.2] [logging/timer.h:57] [Log] Enter: lock contention cs_main, rpc/mining.cpp:124 
completed (5139μs) 
```

Other threads do their thing:

```
 node1 2022-03-31T22:42:56.034760Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention ::cs_main, validation.cpp:5081 started 
 node1 2022-03-31T22:42:56.034826Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention ::cs_main, validation.cpp:5081 completed (32μs) 
 node1 2022-03-31T22:42:56.034855Z [scheduler] [validationinterface.cpp:199] [operator()] UpdatedBlockTip: new block hash=7b7df2920d9870cb286408956ea95f6d307bb87dfd446bce18e4c35f7fe3651b fork block hash=7b0602dccb1e34108167e32238ec6011d29eae6da3f9e4430165bc0ecd5283d7 (in IBD=false) 
```

Then `httpworker.2` is calling `ProcessNewblock` and everything falls apart:

```
 node1 2022-03-31T22:42:56.034887Z [httpworker.2] [logging/timer.h:57] [Log] Enter: lock contention cs_main, validation.cpp:3687 started 
 node1 2022-03-31T22:42:56.034970Z [httpworker.2] [logging/timer.h:57] [Log] Enter: lock contention cs_main, validation.cpp:3687 completed (58μs) 
 node1 2022-03-31T22:42:56.035025Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention ::cs_main, validation.cpp:5081 started 
 test  2022-03-31T22:42:56.036000Z TestFramework (ERROR): JSONRPC error 
                                   Traceback (most recent call last):
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 132, in main
                                       self.run_test()
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/wallet_listreceivedby.py"", line 258, in run_test
                                       self.generatetoaddress(self.nodes[1], COINBASE_MATURITY + 1, address2, sync_fun=self.no_op)
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 649, in generatetoaddress
                                       blocks = generator.generatetoaddress(*args, invalid_call=False, **kwargs)
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/test_framework/test_node.py"", line 311, in generatetoaddress
                                       return self.__getattr__('generatetoaddress')(*args, **kwargs)
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/test_framework/coverage.py"", line 49, in __call__
                                       return_val = self.auth_service_proxy_instance.__call__(*args, **kwargs)
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/test_framework/authproxy.py"", line 144, in __call__
                                       raise JSONRPCException(response['error'], status)
                                   test_framework.authproxy.JSONRPCException: ProcessNewBlock, block not accepted (-32603)
 node1 2022-03-31T22:42:56.036311Z [httpworker.2] [util/system.h:51] [error] ERROR: AcceptBlock: bad-cb-height, block height mismatch in coinbase 
 node1 2022-03-31T22:42:56.036345Z [httpworker.2] [validationinterface.cpp:249] [BlockChecked] BlockChecked: block hash=2f267e107b619688b165b81e220b7012a48537ec711c044b19a9527ae7615421 state=bad-cb-height, block height mismatch in coinbase 
 node1 2022-03-31T22:42:56.036381Z [httpworker.2] [util/system.h:51] [error] ERROR: ProcessNewBlock: AcceptBlock FAILED (bad-cb-height, block height mismatch in coinbase) 
 node1 2022-03-31T22:42:56.036425Z [msghand] [logging/timer.h:57] [Log] Enter: lock contention ::cs_main, validation.cpp:5081 completed (1364μs) 
```"
bitcoin/bitcoin,2022-03-29 21:26:46,bug,wallet: Postpone wallet loading notification for encrypted wallets,"Fixes bitcoin-core/gui#571.

`CWallet::Create()` notifies about wallet loading too early, that results the notification goes before `DescriptorScriptPubKeyMan`s were created and added to an encrypted wallet.

And `interfaces::Wallet::taprootEnabled()` in https://github.com/bitcoin/bitcoin/blob/ecf692b466860f44334a1da967fc2559da913bec/src/qt/receivecoinsdialog.cpp#L100-L102 erroneously returns `false` for just created encrypted descriptor wallets."
bitcoin/bitcoin,2022-03-22 02:40:05,bug,bench: `MempoolCheck` actually runs with `check_ratio = 0`,"For `MempoolCheck`, it seems that the intention was to have a mempool with `check_ratio = 1` (see `-checkmempool=1`):

https://github.com/bitcoin/bitcoin/blob/e66630cc87c017f40ec29f6c1edf2ed5a286e49d/src/bench/mempool_stress.cpp#L102-L116

However in the subsequent line in the above snippet, a `CTxMemPool` gets constructed with no arguments, which means that `check_ratio` will default to 0:

https://github.com/bitcoin/bitcoin/blob/e66630cc87c017f40ec29f6c1edf2ed5a286e49d/src/txmempool.h#L571

Manually specifying `check_ratio` to 1 (according to the original intention) and running the `MempoolCheck` benchmark results in an assertion error:

```
diff --git a/src/bench/mempool_stress.cpp b/src/bench/mempool_stress.cpp
index afa4618e1b..32cdb70539 100644
--- a/src/bench/mempool_stress.cpp
+++ b/src/bench/mempool_stress.cpp
@@ -105,7 +105,7 @@ static void MempoolCheck(benchmark::Bench& bench)
     const int childTxs = bench.complexityN() > 1 ? static_cast<int>(bench.complexityN()) : 2000;
     const std::vector<CTransactionRef> ordered_coins = CreateOrderedCoins(det_rand, childTxs, /* min_ancestors */ 5);
     const auto testing_setup = MakeNoLogFileContext<const TestingSetup>(CBaseChainParams::MAIN, {""-checkmempool=1""});
-    CTxMemPool pool;
+    CTxMemPool pool{nullptr, 1};
     LOCK2(cs_main, pool.cs);
     const CCoinsViewCache& coins_tip = testing_setup.get()->m_node.chainman->ActiveChainstate().CoinsTip();
     for (auto& tx : ordered_coins) AddTx(tx, pool);
```

```sh
$ ./src/bench/bench_bitcoin -filter='MempoolCheck'
...
bench_bitcoin: txmempool.cpp:759: void CTxMemPool::check(const CCoinsViewCache &, int64_t) const: Assertion `mempoolDuplicate.HaveCoin(txin.prevout)' failed.
```

Aside from this problem, we should also probably just re-use the `CTxMemPool` in `TestingSetup`.

Ping @glozow"
bitcoin/bitcoin,2022-03-16 19:21:46,bug,guix: Linker warning for darwin builds,"```
  CXXLD    libbitcoinconsensus.la
ld: warning: double slash removed from -install_name (//lib/libbitcoinconsensus.0.dylib)
```"
bitcoin/bitcoin,2022-03-15 19:16:20,bug,feature_init intermittent issue:                                    UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 1215-1217: unexpected end of data,"Presumably because a Unicode character was only written partially.


```
 test  2022-03-15T19:13:39.817000Z TestFramework (ERROR): Unexpected exception caught during testing 
                                   Traceback (most recent call last):
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 132, in main
                                       self.run_test()
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/feature_init.py"", line 79, in run_test
                                       node.start(extra_args=['-txindex=1', '-blockfilterindex=1', '-coinstatsindex=1'])
                                     File ""/usr/lib/python3.8/contextlib.py"", line 120, in __exit__
                                       next(self.gen)
                                     File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-i686-pc-linux-gnu/test/functional/test_framework/test_node.py"", line 442, in wait_for_debug_log
                                       log = dl.read()
                                     File ""/usr/lib/python3.8/codecs.py"", line 322, in decode
                                       (result, consumed) = self._buffer_decode(data, self.errors, final)
                                   UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 1215-1217: unexpected end of data
```

https://cirrus-ci.com/task/5773197005029376?logs=ci#L5215"
bitcoin/bitcoin,2022-03-11 13:13:15,bug,Use designated initializers,"Designated initializers are supported since gcc 4.7 (Our minimum required is 8) and clang 3 (Our minimum required is 7). They work out of the box with C++17, and only msvc requires the C++20 flag to be set. I don't expect any of our msvc users will run into issues due to this. See also https://bitcoin.jonasschnelli.ch/ircmeetings/logs/bitcoin-core-dev/2022/bitcoin-core-dev.2022-03-10-19.00.log.html#l-114"
bitcoin/bitcoin,2022-03-05 23:49:28,bug,Bitcoind repeatedly crashing at `UpdateTip` with no error message,"<!-- Describe the issue -->

**Expected behavior**

Bitcoind either doesn't crash, or provides some error information in `debug.log` about the crash.

**Actual behavior**

About 10 seconds after starting `bitcoind`, it reliably crashes right after:
```
2022-03-05T23:47:40Z UpdateTip: new best=0000000000000000025faae44cda1e306fdfb468c30870a3731bbdadf24c5f
5f height=425259 version=0x20000000 log2_work=85.132165 tx=149305533 date='2016-08-15T01:43:46Z' progre
ss=0.211905 cache=0.1MiB(867txo)
2022-03-05T23:47:40Z UpdateTip: new best=00000000000000000287a137cfe12343e83667c5ab290f2c6ee75fe323a1c8
ec height=425260 version=0x20000000 log2_work=85.132195 tx=149307741 date='2016-08-15T02:03:56Z' progre
ss=0.211908 cache=1.2MiB(9061txo)
```
I'm currently stuck on block `425258` but that's after trying to run `-reindex` when this was happening more up towards the high 600000s, so I'm not sure if it's anything particular with this block or not.

**To reproduce**

This happens every time consistently for me.

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
```
bitcoind --version
Bitcoin Core version v22.0
```
Originally tried with building my own, then tried again with the pre-build binary from bitcoincore.org to make sure I didn't do something wrong, same issue.

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
```
> lsb_release -a

No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 20.04.3 LTS
Release:	20.04
Codename:	focal
```
```
> lscpu

Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
CPU(s):                          4
Vendor ID:                       GenuineIntel
CPU family:                      6
Model:                           158
Model name:                      Intel(R) Core(TM) i3-7100 CPU @ 3.90GHz
...
```
```
> lsmem

lsmem
RANGE                                  SIZE  STATE REMOVABLE  BLOCK
0x0000000000000000-0x000000008fffffff  2.3G online        no   0-17
0x0000000100000000-0x000000046fffffff 13.8G online        no 32-141

Memory block size:       128M
Total online memory:      16G
Total offline memory:      0B
```
```
> sudo smartctl --all /dev/sda

=== START OF INFORMATION SECTION ===
Model Family:     Western Digital Red
LU WWN Device Id: 5 0014ee 26488ca44
Firmware Version: 82.00A82
User Capacity:    3,000,592,982,016 bytes [3.00 TB]
Sector Sizes:     512 bytes logical, 4096 bytes physical
Rotation Rate:    5400 rpm
ATA Version is:   ACS-2 (minor revision not indicated)
SATA Version is:  SATA 3.0, 6.0 Gb/s (current: 6.0 Gb/s)
SMART support is: Available - device has SMART capability.
SMART support is: Enabled

=== START OF READ SMART DATA SECTION ===
SMART overall-health self-assessment test result: PASSED
...
```

I put my `debug.log`s over in this gist, one default logging and one with `debug=1`: https://gist.github.com/wbobeirne/c32a5ef6d6778dc1ace63e74144dc0c5
"
bitcoin/bitcoin,2022-02-22 09:46:10,bug,Homebrew Boost 1.78 breaks external signer configure,"Test on macOS 12.2.1 against the master branch. #24397 doesn't fix it.

```
brew info boost
boost: stable 1.78.0 (bottled), HEAD
...
./configure --enable-external-signer
...
checking for boostlib >= 1.64.0 (106400)... yes
checking whether Boost.Process can be used... no
configure: error: External signing is not supported for this Boost version
```

It does work with boost 1.76 (there was no 1.77 release in home-brew):

```
brew install boost@1.76
...
LDFLAGS=""-L/usr/local/opt/boost@1.76/lib"" CPPFLAGS=""-I/usr/local/opt/boost@1.76/include"" ./configure --enable-external-signer
...
checking for boostlib >= 1.64.0 (106400)... yes
checking whether Boost.Process can be used... yes
...
Options used to compile and link:
  external signer = yes
```

There's nothing in the release notes about Boost.Process for either [1.77](https://www.boost.org/users/history/version_1_77_0.html) or [1.78](https://www.boost.org/users/history/version_1_78_0.html).

The Homebrew [formula changes](https://github.com/Homebrew/homebrew-core/commits/master/Formula/boost.rb) are nothing but a trivial version and hash bump."
bitcoin/bitcoin,2022-02-19 12:43:35,bug,"GUI: ""registerShutdownBlockReason: Successfully registered: Dogecoin Core didn't yet exit safely..."" and ERROR: AcceptToMemoryPool: non-final","<!-- This is a dogecoincore qt not sync.

-->

<!-- sorry for my english -->

**To reproduce file log debug**

<!--- ERROR: AcceptToMemoryPool: non-final -->

**System information**

<!-- What version ofDogecoin Core versione v1.10.0.0-bb4b082 (64-bit)-->

<!-- What type of machine are you observing the error on (OS/CPU win 10/i5 and disk type SSD) -->
[debug.log](https://github.com/bitcoin/bitcoin/files/8102180/debug.log)

"
bitcoin/bitcoin,2022-02-19 10:15:52,bug,"Segmentation fault. ""b-httpworker.0""","<!-- Describe the issue -->
After calling `importaddress` trough HTTP RPC, i get segmentation fault at the end of sync(tracked by progress.

**Expected behavior**
Should complete importaddress

<!--- What behavior did you expect? -->
Should complete importaddress

**Actual behavior**
Segmentation fault

**To reproduce**
Just try to call `importaddress` trought wallet RPC in bitcoin testnet.

<!--- How reliably can you reproduce the issue, what are the steps to do so? -->
10/10 times

**System information**
Ubuntu

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->
0.21.1

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->
Digital ocean Ubuntu instance

<!-- Any extra information that might be useful in the debugging process. -->
gdb

<!--- This is normally the contents of a `debug.log` or `config.log` file. Raw text or a link to a pastebin type site are preferred. -->
Heres log right before crash:
```
2022-02-19T10:11:15Z sending verack (0 bytes) peer=2291
2022-02-19T10:11:15Z receive version message: /Satoshi:0.17.1/: version 70013, blocks=0, us=68.183.75.14:18333, peer=2291
2022-02-19T10:11:15Z socket closed for peer=2290
2022-02-19T10:11:15Z disconnecting peer=2290
2022-02-19T10:11:15Z received: verack (0 bytes) peer=2290
2022-02-19T10:11:15Z sending sendheaders (0 bytes) peer=2290

Thread 11 ""b-httpworker.0"" received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7fffcffff700 (LWP 1008189)]
```
"
bitcoin/bitcoin,2022-02-17 20:49:56,bug,Test-only UB in fuzz tests,"This line:

```c++
    ConnmanTestMsg& connman = *static_cast<ConnmanTestMsg*>(g_setup->m_node.connman.get());
```

in src/test/fuzz/process_message.cpp:37, is constructing a reference to a ConnmanTestMsg, which actually refers to an object of type Connman. Even though ConnmanTestMsg inherits from Connman, and adds no fields, I am pretty sure this is undefined behavior.

It isn't detected by the sanitizer because they're not polymorphic types for which runtime type information is tracked, but if you make `Connman::~Connman()` `virtual`, it does get detected:

```
test/fuzz/util.cpp:265:23: runtime error: member call on address 0x619000034380 which does not point to an object of type 'ConnmanTestMsg'
0x619000034380: note: object is of type 'CConnman'
 00 00 00 00  90 8e a0 29 19 56 00 00  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  01 00 00 00
              ^~~~~~~~~~~~~~~~~~~~~~~
              vptr for 'CConnman'
```

I don't know how to quickly solve this myself, as I'm unfamiliar with this part of the code, so I'm opening an issue to discuss it."
bitcoin/bitcoin,2022-02-15 13:36:39,bug,build: compilation error in `tinyformat.h` on Manjaro Linux,"Here's the output from `make`:
```
./wallet/wallet.h:802:9:   required from ‘void wallet::CWallet::WalletLogPrintf(std::string, Params ...) const [with Params = {std::optional<int>}; std::string = std::__cxx11::basic_string<char>]’
wallet/wallet.cpp:2931:44:   required from here
./tinyformat.h:291:9: error: no match for ‘operator<<’ (operand types are ‘std::ostringstream’ {aka ‘std::__cxx11::basic_ostringstream<char>’} and ‘const std::optional<int>’)
  291 |     tmp << value;
      |     ~~~~^~~~~~~~
./tinyformat.h:291:9: note: candidate: ‘operator<<(int, int)’ (built-in)
```
...
```
./wallet/wallet.h:802:9:   required from ‘void wallet::CWallet::WalletLogPrintf(std::string, Params ...) const [with Params = {std::optional<int>}; std::string = std::__cxx11::basic_string<char>]’
wallet/wallet.cpp:2931:44:   required from here
/usr/include/c++/11.1.0/ostream:773:5: error: no type named ‘type’ in ‘struct std::enable_if<false, std::basic_ostream<char>&>’
In file included from /usr/include/c++/11.1.0/bits/fs_path.h:39,
                 from /usr/include/c++/11.1.0/filesystem:45,
                 from ./fs.h:11,
                 from ./wallet/wallet.h:10,
                 from wallet/wallet.cpp:6:
./tinyformat.h: In instantiation of ‘void tinyformat::detail::formatTruncated(std::ostream&, const T&, int) [with T = std::optional<int>; std::ostream = std::basic_ostream<char>]’:
./tinyformat.h:355:32:   required from ‘void tinyformat::formatValue(std::ostream&, const char*, const char*, int, const T&) [with T = std::optional<int>; std::ostream = std::basic_ostream<char>]’
./tinyformat.h:543:24:   required from ‘static void tinyformat::detail::FormatArg::formatImpl(std::ostream&, const char*, const char*, int, const void*) [with T = std::optional<int>; std::ostream = std::basic_ostream<char>]’
./tinyformat.h:519:13:   required from ‘tinyformat::detail::FormatArg::FormatArg(const T&) [with T = std::optional<int>]’
./tinyformat.h:975:32:   required from ‘tinyformat::detail::FormatListN<N>::FormatListN(const Args& ...) [with Args = {std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::optional<int>}; int N = 2]’
./tinyformat.h:1028:20:   required from ‘tinyformat::detail::FormatListN<sizeof... (Args)> tinyformat::makeFormatList(const Args& ...) [with Args = {std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::optional<int>}]’
./tinyformat.h:1064:37:   required from ‘void tinyformat::format(std::ostream&, const char*, const Args& ...) [with Args = {std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::optional<int>}; std::ostream = std::basic_ostream<char>]’
./tinyformat.h:1073:11:   required from ‘std::string tinyformat::format(const char*, const Args& ...) [with Args = {std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::optional<int>}; std::string = std::__cxx11::basic_string<char>]’
```

Same with `clang`:

```
/usr/bin/../lib64/gcc/x86_64-pc-linux-gnu/11.1.0/../../../../include/c++/11.1.0/ostream:276:7: note: candidate function not viable: no known conversion from 'const std::optional<int>' to 'std::basic_ostream<char>::__streambuf_type *' (aka 'basic_streambuf<char, std::char_traits<char>> *') for 1st argument
      operator<<(__streambuf_type* __sb);
      ^
In file included from wallet/wallet.cpp:6:
In file included from ./wallet/wallet.h:10:
In file included from ./fs.h:8:
./tinyformat.h:291:9: error: invalid operands to binary expression ('std::ostringstream' (aka 'basic_ostringstream<char>') and 'const std::optional<int>')
    tmp << value;
    ~~~ ^  ~~~~~
```"
bitcoin/bitcoin,2022-02-14 00:08:53,bug,Segmentation Fault in V21 and V22 releases,"OS: Ubuntu 20.04.
Releases: Bitcoin Core V21 and V22.

The problem:
I have a lot of HD wallets, with the first transaction in Dic 2017, encrypted, not checked for 5 years.

It starts reescaning and segmentation fault error. Tried with bitcoin-qt, bitcoind, reindex the whole blockchain, and still segmentation fault.
After loading the GUI, load the wallet, again it closes with segmentation fault

V21 and V22 downloaded and checked for signatures and hashes.

The same wallets, if checked after mid-2018-2019 (a year or more) work.

The machine is a DELL inspiron with 16Gb of ram (dbcache=8000). Tried a lot of other things (-rescan, etc) that didn't work.

All other wallets work fine, no problems, but these ones fail with newer versions of bitcoin core. Run bitcoin-wallet info, the wallets are ok, (not corrupted or anything).

If I do the reindex while the wallet is loaded, it crashes the moment the reindex gets to Dic 2017-Jan 2018. Then I reestart without the wallet loaded and it finishes reindexing OK.

In the log says it loads the wallet OK (5s :)), starts reescaning and then nothing else (it crashes).

It crashes 4 or 5 seconds after reescaning (really fast) both bitcoin-qt and bitcoind.
"
bitcoin/bitcoin,2022-02-11 14:56:17,bug,`gestdescriptorinfo` ignores hardened paths in origin info for computing the checksum (therefore returns invalid checksums),"Let's say i have two xpubs, derived at `m/1'/2'/3'/0` from a master xpub. I'd like to create a descriptor describing a multisig between those 2 keys.

I create a descriptor wallet
```
$ bcreg1 -named createwallet wallet_name=repro disable_private_keys=true descriptors=true
{
  ""name"": ""repro"",
  ""warning"": """"
}
```

Since i won't compute the checksum by hand i use the hack of getting it from `getdescriptorinfo`
```
$ bcreg1 getdescriptorinfo ""wsh(multi(2,[0a0a0a0a/1'/2'/3'/0]tpubD6NzVbkrYhZ4WkU5UCcpShsnkYoYPSH9Lor6Kg7J6ytgCjcrpZKtpLPT4NtWLoVirjiWPhgupH1V1UkKaTJoFCRPbcZwMN6kxepTUzKg6mM/*,[bbbbbbbb/1'/2'/3'/0]tpubD6NzVbkrYhZ4Xm62aaUb6DiTMqnnbQNKQsBddsiHwx2Q2KaqYApSCizhyZcEaCRSvr5QSZKuF53pJ6ZQcRzFFDJ6HaKAkpdJAfZt8h1ZzDz/*))""
{
  ""descriptor"": ""wsh(multi(2,[0a0a0a0a/1'/2'/3'/0]tpubD6NzVbkrYhZ4WkU5UCcpShsnkYoYPSH9Lor6Kg7J6ytgCjcrpZKtpLPT4NtWLoVirjiWPhgupH1V1UkKaTJoFCRPbcZwMN6kxepTUzKg6mM/*,[bbbbbbbb/1'/2'/3'/0]tpubD6NzVbkrYhZ4Xm62aaUb6DiTMqnnbQNKQsBddsiHwx2Q2KaqYApSCizhyZcEaCRSvr5QSZKuF53pJ6ZQcRzFFDJ6HaKAkpdJAfZt8h1ZzDz/*))#hs0kuwwv"",
  ""checksum"": ""hs0kuwwv"",
  ""isrange"": true,
  ""issolvable"": true,
  ""hasprivatekeys"": false
}
```

Now i use the output of `getdescriptorinfo` to import the descriptor and...
```
$ bcreg1 -rpcwallet=repro importdescriptors '[{""desc"":""wsh(multi(2,[0a0a0a0a/1'/2'/3'/0]tpubD6NzVbkrYhZ4WkU5UCcpShsnkYoYPSH9Lor6Kg7J6ytgCjcrpZKtpLPT4NtWLoVirjiWPhgupH1V1UkKaTJoFCRPbcZwMN6kxepTUzKg6mM/*,[bbbbbbbb/1'/2'/3'/0]tpubD6NzVbkrYhZ4Xm62aaUb6DiTMqnnbQNKQsBddsiHwx2Q2KaqYApSCizhyZcEaCRSvr5QSZKuF53pJ6ZQcRzFFDJ6HaKAkpdJAfZt8h1ZzDz/*))#hs0kuwwv"",""timestamp"":""now""}]'
[
  {
    ""success"": false,
    ""error"": {
      ""code"": -5,
      ""message"": ""Provided checksum 'hs0kuwwv' does not match computed checksum 'rgsu3znf'""
    }
  }
]
```

Hmm. Turns out the checksum `getdescriptorinfo` gave me is invalid (both in the `""descriptor""` and `""checksum""` fields). I remember some discussions around canonicalization and the `h` vs `'` notation for hardened paths, so i try by using `h` instead. 
```
$ bcreg1 getdescriptorinfo ""wsh(multi(2,[0a0a0a0a/1h/2h/3h/0]tpubD6NzVbkrYhZ4WkU5UCcpShsnkYoYPSH9Lor6Kg7J6ytgCjcrpZKtpLPT4NtWLoVirjiWPhgupH1V1UkKaTJoFCRPbcZwMN6kxepTUzKg6mM/*,[bbbbbbbb/1h/2h/3h/0]tpubD6NzVbkrYhZ4Xm62aaUb6DiTMqnnbQNKQsBddsiHwx2Q2KaqYApSCizhyZcEaCRSvr5QSZKuF53pJ6ZQcRzFFDJ6HaKAkpdJAfZt8h1ZzDz/*))""
{
  ""descriptor"": ""wsh(multi(2,[0a0a0a0a/1'/2'/3'/0]tpubD6NzVbkrYhZ4WkU5UCcpShsnkYoYPSH9Lor6Kg7J6ytgCjcrpZKtpLPT4NtWLoVirjiWPhgupH1V1UkKaTJoFCRPbcZwMN6kxepTUzKg6mM/*,[bbbbbbbb/1'/2'/3'/0]tpubD6NzVbkrYhZ4Xm62aaUb6DiTMqnnbQNKQsBddsiHwx2Q2KaqYApSCizhyZcEaCRSvr5QSZKuF53pJ6ZQcRzFFDJ6HaKAkpdJAfZt8h1ZzDz/*))#hs0kuwwv"",
  ""checksum"": ""6nuh6ujc"",
  ""isrange"": true,
  ""issolvable"": true,
  ""hasprivatekeys"": false
}
```

It outputs the same invalid descriptor in the `""descriptor""` field. Fortunately the checksum in `""checksum""` is actually valid, so i can use that in `importdescriptors`.


Maybe worth mentioning, before trying on latest master i had an additional issue with `22.0` where `getdescriptorinfo` would literally remove the hardened paths from the origin info:
```
$ bc getdescriptorinfo 'wsh(sortedmulti(2,[f4d84203/48'/0'/0']xpub6BqGLdDLrAeSfoaxcU4VPLrLjWnVAdTcE1jFaocxupbqpyU6tdUA6nZoU17RrYQaGxpjWh7eLempM6W8d6C4p5siF8rWvgvwnASKyzKn14S/0/*,[ff620a62/48'/0'/0']xpub6C7cPJJsmrM6hQuqX2DEdqn38VF2csDeC5BmQbSzpga4EP64V211hYSCSStkFKnELchieG2WKMckrKRdHrUjeaCbRszHJJ7nP4E68rPViPE/0/*))'        
{                                                                                                                                                                                                                                                                                                                                                                          
  ""descriptor"": ""wsh(sortedmulti(2,[f4d84203/48/0/0]xpub6BqGLdDLrAeSfoaxcU4VPLrLjWnVAdTcE1jFaocxupbqpyU6tdUA6nZoU17RrYQaGxpjWh7eLempM6W8d6C4p5siF8rWvgvwnASKyzKn14S/0/*,[ff620a62/48/0/0]xpub6C7cPJJsmrM6hQuqX2DEdqn38VF2csDeC5BmQbSzpga4EP64V211hYSCSStkFKnELchieG2WKMckrKRdHrUjeaCbRszHJJ7nP4E68rPViPE/0/*))#kvvtf4uz"",                                                  
  ""checksum"": ""kvvtf4uz"",                                                                                                                                                                                                                                                                                                                                                  
  ""isrange"": true,                                                                                                                                                                                                                                                                                                                                                         
  ""issolvable"": true,                                                                                                                                                                                                                                                                                                                                                      
  ""hasprivatekeys"": false                                                                                                                                                                                                                                                                                                                                                  
}
```

So maybe the bad checksum above was the checksum without the hardened paths?
```
$ bcreg1 getdescriptorinfo ""wsh(multi(2,[0a0a0a0a/1/2/3/0]tpubD6NzVbkrYhZ4WkU5UCcpShsnkYoYPSH9Lor6Kg7J6ytgCjcrpZKtpLPT4NtWLoVirjiWPhgupH1V1UkKaTJoFCRPbcZwMN6kxepTUzKg6mM/*,[bbbbbbbb/1/2/3/0]tpubD6NzVbkrYhZ4Xm62aaUb6DiTMqnnbQNKQsBddsiHwx2Q2KaqYApSCizhyZcEaCRSvr5QSZKuF53pJ6ZQcRzFFDJ6HaKAkpdJAfZt8h1ZzDz/*))""                     

{
  ""descriptor"": ""wsh(multi(2,[0a0a0a0a/1/2/3/0]tpubD6NzVbkrYhZ4WkU5UCcpShsnkYoYPSH9Lor6Kg7J6ytgCjcrpZKtpLPT4NtWLoVirjiWPhgupH1V1UkKaTJoFCRPbcZwMN6kxepTUzKg6mM/*,[bbbbbbbb/1/2/3/0]tpubD6NzVbkrYhZ4Xm62aaUb6DiTMqnnbQNKQsBddsiHwx2Q2KaqYApSCizhyZcEaCRSvr5QSZKuF53pJ6ZQcRzFFDJ6HaKAkpdJAfZt8h1ZzDz/*))#rgsu3znf"",
  ""checksum"": ""rgsu3znf"",
  ""isrange"": true,
  ""issolvable"": true,
  ""hasprivatekeys"": false
}
```
Bingo!"
bitcoin/bitcoin,2022-02-08 11:53:10,bug,segfault when compiled with depends DEBUG=1 and libc++,"See also https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=44466 and https://github.com/bitcoin/bitcoin/pull/20744#issuecomment-1031507383

Steps to reproduce on a fresh install of Ubuntu Focal:

```
export DEBIAN_FRONTEND=noninteractive && apt update && apt install curl wget htop git vim ccache -y && git clone https://github.com/bitcoin/bitcoin.git bitcoin-core && cd bitcoin-core && apt install build-essential libtool autotools-dev automake pkg-config bsdmainutils python3-zmq make automake cmake curl clang llvm libc++-dev libc++abi-dev g++-multilib libtool binutils-gold bsdmainutils pkg-config python3 patch bison -y  && ( cd depends && make DEBUG=1  NO_QT=1 NO_WALLET=1 NO_ZMQ=1 NO_UPNP=1 NO_NATPMP=1 -j $(nproc)  ) && ./autogen.sh && CONFIG_SITE=""$PWD/depends/x86_64-pc-linux-gnu/share/config.site"" ./configure CC='clang ' CXX='clang++ -stdlib=libc++' --enable-fuzz --with-sanitizers=fuzzer && make  -j $(nproc)
```

```
$ FUZZ=tx_pool ./src/test/fuzz/fuzz 
UndefinedBehaviorSanitizer:DEADLYSIGNAL
==52419==ERROR: UndefinedBehaviorSanitizer: SEGV on unknown address 0x000000000008 (pc 0x7f5d814ccb47 bp 0x7fff699e4ef0 sp 0x7fff699e4ea0 T52419)
==52419==The signal is caused by a READ memory access.
==52419==Hint: address points to the zero page.
    #0 0x7f5d814ccb47 in std::__1::__libcpp_db::swap(void*, void*) (/lib/x86_64-linux-gnu/libc++.so.1+0x43b47)
    #1 0x564aea7e1377 in std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::basic_string(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >&&) (/bitcoin-core/src/test/fuzz/fuzz+0x577377)
    #2 0x564aea80cf94 in std::__1::__fs::filesystem::path::path(std::__1::__fs::filesystem::path&&) (/bitcoin-core/src/test/fuzz/fuzz+0x5a2f94)
    #3 0x564aea80bd04 in fs::path::path(std::__1::__fs::filesystem::path) (/bitcoin-core/src/test/fuzz/fuzz+0x5a1d04)
    #4 0x564aeb1f46ad in fs::absolute(fs::path const&) (/bitcoin-core/src/test/fuzz/fuzz+0xf8a6ad)
    #5 0x564aeb1f4c8b in ArgsManager::GetDataDir(bool) const (/bitcoin-core/src/test/fuzz/fuzz+0xf8ac8b)
    #6 0x564aea80bbfa in ArgsManager::GetDataDirNet() const (/bitcoin-core/src/test/fuzz/fuzz+0x5a1bfa)
    #7 0x564aeb1fa2bb in AbsPathForConfigVal(fs::path const&, bool) (/bitcoin-core/src/test/fuzz/fuzz+0xf902bb)
    #8 0x564aeb0d5074 in init::SetLoggingOptions(ArgsManager const&) (/bitcoin-core/src/test/fuzz/fuzz+0xe6b074)
    #9 0x564aeaaddd15 in InitLogging(ArgsManager const&) (/bitcoin-core/src/test/fuzz/fuzz+0x873d15)
    #10 0x564aeaa06412 in BasicTestingSetup::BasicTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) (/bitcoin-core/src/test/fuzz/fuzz+0x79c412)
    #11 0x564aeaa073e2 in ChainTestingSetup::ChainTestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) (/bitcoin-core/src/test/fuzz/fuzz+0x79d3e2)
    #12 0x564aeaa0877f in TestingSetup::TestingSetup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) (/bitcoin-core/src/test/fuzz/fuzz+0x79e77f)
    #13 0x564aea85508d in std::__1::__unique_if<TestingSetup const>::__unique_single std::__1::make_unique<TestingSetup const, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) (/bitcoin-core/src/test/fuzz/fuzz+0x5eb08d)
    #14 0x564aea852a22 in std::__1::unique_ptr<TestingSetup const, std::__1::default_delete<TestingSetup const> > MakeNoLogFileContext<TestingSetup const>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::vector<char const*, std::__1::allocator<char const*> > const&) (/bitcoin-core/src/test/fuzz/fuzz+0x5e8a22)
    #15 0x564aea9c5817 in (anonymous namespace)::initialize_tx_pool() (/bitcoin-core/src/test/fuzz/fuzz+0x75b817)
    #16 0x564aea7c8d20 in decltype(std::__1::forward<void (*&)()>(fp)()) std::__1::__invoke<void (*&)()>(void (*&)()) (/bitcoin-core/src/test/fuzz/fuzz+0x55ed20)
    #17 0x564aea7c8c6d in void std::__1::__invoke_void_return_wrapper<void>::__call<void (*&)()>(void (*&)()) (/bitcoin-core/src/test/fuzz/fuzz+0x55ec6d)
    #18 0x564aea7c8c0d in std::__1::__function::__alloc_func<void (*)(), std::__1::allocator<void (*)()>, void ()>::operator()() (/bitcoin-core/src/test/fuzz/fuzz+0x55ec0d)
    #19 0x564aea7c7049 in std::__1::__function::__func<void (*)(), std::__1::allocator<void (*)()>, void ()>::operator()() (/bitcoin-core/src/test/fuzz/fuzz+0x55d049)
    #20 0x564aeaab965c in std::__1::__function::__value_func<void ()>::operator()() const (/bitcoin-core/src/test/fuzz/fuzz+0x84f65c)
    #21 0x564aeaab95e5 in std::__1::function<void ()>::operator()() const (/bitcoin-core/src/test/fuzz/fuzz+0x84f5e5)
    #22 0x564aeb25ac9d in initialize() (/bitcoin-core/src/test/fuzz/fuzz+0xff0c9d)
    #23 0x564aeb25b71f in LLVMFuzzerInitialize (/bitcoin-core/src/test/fuzz/fuzz+0xff171f)
    #24 0x564aea743437 in fuzzer::FuzzerDriver(int*, char***, int (*)(unsigned char const*, unsigned long)) (/bitcoin-core/src/test/fuzz/fuzz+0x4d9437)
    #25 0x564aea76df22 in main (/bitcoin-core/src/test/fuzz/fuzz+0x503f22)
    #26 0x7f5d810e60b2 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x270b2)
    #27 0x564aea719e7d in _start (/bitcoin-core/src/test/fuzz/fuzz+0x4afe7d)

UndefinedBehaviorSanitizer can not provide additional info.
SUMMARY: UndefinedBehaviorSanitizer: SEGV (/lib/x86_64-linux-gnu/libc++.so.1+0x43b47) in std::__1::__libcpp_db::swap(void*, void*)
==52419==ABORTING
"
bitcoin/bitcoin,2022-02-04 02:44:51,bug,bitcoind and bitcoin-cli does not supports symbolic link anymore,"I just pulled latest master at https://github.com/bitcoin/bitcoin/commit/3ace3a17c9bce606cea05192f0da3ac62ac69dda and I cannot run bitcoind or bitcoin-cli without providing a full path for data directory using `-datadir` option. It was working fine couple of days ago (while running https://github.com/bitcoin/bitcoin/commit/807169e10b4a18324356ed6ee4d69587b96a7c70). I suspect it may be related to latest switch to the standard std::filesystem library https://github.com/bitcoin/bitcoin/pull/20744

**Expected behavior**

I use a symbolic link to point my /home/me/.bitcoin to an external hard drive. When running `bitcoind` from command line, or executing `bitcoin-cli` commands, without using the `-datadir` option, it should not terminate or crash unexpectedly. Those commands should be able to follow the symbolic link and be able to read/write into the final folder.

**Actual behavior**

`bitcoind` and `bitcoin-cli` are not able to follow the symbolic link. `bitcoin-qt` runs fine, even when running it from command line. See below commands examples.

```
# Create a symbolic link
$~/btc-things/bitcoin$ ln -s /media/DATA/Bitcoin /home/me/.bitcoin

# Try to run bitcoind - Crashes
$~/btc-things/bitcoin$ ./bitcoind 


************************
EXCEPTION: NSt10filesystem7__cxx1116filesystem_errorE       
filesystem error: cannot create directories: Not a directory [/home/me/.bitcoin]       
bitcoin in AppInit()       

bitcoind: chainparamsbase.cpp:35: const CBaseChainParams& BaseParams(): Assertion `globalChainBaseParams' failed.
Aborted (core dumped)

# Run bitcoin-qt, it works fine, the node runs
$~/btc-things/bitcoin$ ./bitcoin-qt 
qt5ct: using qt5ct plugin

# Try to run a bitcoin-cli command to interact with the running node, does not work
$~/btc-things/bitcoin$ ./bitcoin-cli getblockhash 501726


************************
EXCEPTION: NSt10filesystem7__cxx1116filesystem_errorE       
filesystem error: cannot create directories: Not a directory [/home/me/.bitcoin]       
bitcoin in AppInitRPC()       

# Try the same previous command but give an absolute path for -datadir, works fine
$~/btc-things/bitcoin$ ./bitcoin-cli -datadir=/media/DATA/Bitcoin getblockhash 501726
0000000000000000004b27f9ee7ba33d6f048f684aaeb0eea4befd80f1701126
```

**To reproduce**

Steps are indicated previously.

**System information**

<!-- What version of Bitcoin Core are you using, where did you get it (website, self-compiled, etc)? -->

Running `Bitcoin Core version v22.99.0-3ace3a17c9bc`. Self compiled from `master` branch.

<!-- What type of machine are you observing the error on (OS/CPU and disk type)? -->

I'm using Linux Mint with the following kernel `Linux 5.4.0-96-generic x86_64`.
I'm using an additional hard drive to store the full blockchain (SSD).

<!-- Any extra information that might be useful in the debugging process. -->

I had no prior issues before pulling latest changes. I was previously running at https://github.com/bitcoin/bitcoin/commit/807169e10b4a18324356ed6ee4d69587b96a7c70"
bitcoin/bitcoin,2022-02-02 20:14:05,bug,-reindex-chainstate with -prune hangs,"Steps to reproduce:

* Create a datadir that is pruned
* Start with `-prune=550 -reindex-chainstate`
* Hangs with idle CPU

(`-reindex` works)"
opencv/opencv,2023-09-29 12:54:33,bug,Fixed OpenCL FP16 fallback in Einsum layer,"Fixes: https://github.com/opencv/opencv/issues/24311

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-09-25 11:56:10,bug,error loading onnx model while reading it from opencv dnn module,"### System Information

ubuntu 22.04
python 3.8
python 4.8.0
opset version = 14

### Detailed description

Hello i have converted the raf-db-model_best.pth model into onnx for facial emotion recognition
i am able to read the model using onnxruntime and able to generate inference, but when read it using cv2.dnn.readNetFromONNX, it's throwing me error

> OpenCV(4.8.0) [/io/opencv/modules/dnn/src/onnx/onnx_importer.cpp:1083](https://file+.vscode-resource.vscode-cdn.net/io/opencv/modules/dnn/src/onnx/onnx_importer.cpp:1083): error: (-2:Unspecified error) in function 'handleNode'
    Node [[Transpose@ai.onnx](mailto:Transpose@ai.onnx)]:(onnx_node!/attn2/Transpose_1) parse error: OpenCV(4.8.0) [/io/opencv/modules/dnn/src/layers/permute_layer.cpp:162](https://file+.vscode-resource.vscode-cdn.net/io/opencv/modules/dnn/src/layers/permute_layer.cpp:162): error: (-215:Assertion failed) (int)_numAxes == inputs[0].size() in function 'getMemoryShapes'

can someone explain me how to solve this error?

### Steps to reproduce

using cv2.readNetFromONNX(""model_path"")

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-21 10:11:11,bug,dnn: wrong internal results in `expand_neg_batch` in Test_ONNX_layers.Expand,"### System Information

lastest opencv and lastest onnxruntime (1.16.0, released just now)

### Detailed description

The model `expand_neg_batch.onnx` is as follows (Note that I manually added output ""8"".),

![image](https://github.com/opencv/opencv/assets/17219438/ad0a8b5e-3c8d-4d4c-828f-5caf821f59fa)

For output ""8"", onnxruntime produces value [2, 1, 1, 1]; dnn produces value [2, -1, -1, -1]. My own calculation is the same as onnxruntime's.

Model is attached here: [expand_neg_batch.new.onnx.zip](https://github.com/opencv/opencv/files/12683076/expand_neg_batch.new.onnx.zip)

---

@asmorkalov 

**Should we run every single onnx model in `test_onnx_importer.cpp` with onnxruntime and verify with our input and output data to see whether the model is correctly built and dnn can produce correct results?**

### Steps to reproduce

1. Download the model and run inference to get outputs with onnxruntime

```python
import numpy as np

import onnxruntime as ort
import cv2 as cv

x = np.random.randn(1, 2, 2).astype(np.float32)

def ort_inference(model_path):
    net = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])
    out = net.run([""8""], {})[0]
    print(""ort result="", out)

def ocv_inference(model_path):
    net = cv.dnn.readNet(model_path)
    net.setInput(x)

    out = net.forward(""8"")
    print(""ocv result="", out)

ort_inference(""./expand_neg_batch.new.onnx"")
# forget this, small 3d tensor is parsed incorrectly because of opencv python binding
#ocv_inference(""./expand_neg_batch.new.onnx"")
```

2. Clone my Expand refactor PR https://github.com/opencv/opencv/pull/24295, add the following code to print `shape` in `onnx_importer.cpp::parseExpand` (about line 2318):

```cpp
for (int i = 0; i < mat_input_shape.total(); ++i) {
    std::cout << *(mat_input_shape.ptr<int>() + i) << "" "";
    // CV_Check(i, *(mat_input_shape.ptr<int>() + i) >= 0, ""DNN/ONNXImporter-Expand: invalid shape dimension"");
}
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-18 14:48:37,bug,Fix memory leak and handle realloc failure,"In the previous code, there was a memory leak issue where the previously allocated memory was not freed upon a failed realloc operation. This commit addresses the problem by releasing the old memory before setting the pointer to NULL in case of a realloc failure. This ensures that memory is properly managed and avoids potential memory leaks.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
"
opencv/opencv,2023-09-12 21:00:42,bug,RISC-V: fix compilation in RVV scalable mode,"Tested with Clang 16 and GCC 13 (RISC-V RVV scalable variant). Also on x86_64 (default Ubuntu 22.04 GCC).

```
force_builders=Custom
build_image:Custom=riscv-clang-rvv
Xbuild_image:Custom=riscv-clang-rvv-128
Xbuild_image:Custom=riscv-gcc-rvv-07
test_modules:Custom=core,imgproc,dnn
buildworker:Custom=linux-1
test_timeout:Custom=600
build_contrib:Custom=OFF
```"
opencv/opencv,2023-09-09 17:40:50,bug,Build with OpenVINO in Debug,"### Pull Request Readiness Checklist

resolves https://github.com/opencv/opencv/issues/24249

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-09-08 11:06:37,bug,"fix type cast in drawDetectedMarkers, drawDetectedCornersCharuco, drawDetectedDiamonds","- drawDetectedMarkers(), drawDetectedCornersCharuco(), drawDetectedDiamonds() uses only `Point2f` (`CV_32FC2`) for detected corners. But this corners are casted to `int` later in the code.
- drawDetectedMarkers(), drawDetectedDiamonds() has a requirement on CV_32FC2 for corners. This requirement is lost in drawDetectedCornersCharuco().

Strict input data requirements have been removed. Added only the requirement to have 2 channels. The input corners are then casted to CV_32SC2.

added tests


### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-09-07 16:47:37,bug,SIGILL in `merge`,"### System Information

OpenCV version: 4.5.4
Operating System / Platform: Ubuntu 22.04.3 LTS
Compiler & compiler version: g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0

I also reproduced error on CV 4.6.0 on windows but the minimal example has been tested on Ubuntu with CV4.5.4.

### Detailed description

Using `cv::merge` with NULL matrix is causing SIGILL.
I'm fully expecting a crash or any error but not a SIGILL as this leads to not executing the final stacktrace in our application.

### Steps to reproduce

main.cpp:
```c++
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char *argv[])
{   
    cv::Mat planes[4];
    cv::Mat mm;
    std::cout<< ""hello there before""<<std::endl;
    cv::merge(planes,3,mm);
    std::cout<< ""hello there after""<<std::endl;

    return 0;
}
```
compile with:
```
g++ -o your_program_name main.cpp `pkg-config opencv4 --cflags --libs`
``` 

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-05 11:38:50,bug,Revert PR 24186 as it forces skipping tests,"Reverts https://github.com/opencv/opencv/pull/24186

Current test skipping issue:
```
./bin/opencv_test_dnn --gtest_filter=Test_Caffe_layers*
...
[       OK ] Test_Caffe_layers.DeConvolution/3 (3 ms)
[ RUN      ] Test_Caffe_layers.InnerProduct/0, where GetParam() = NGRAPH/CPU
[       OK ] Test_Caffe_layers.InnerProduct/0 (8 ms)
[ RUN      ] Test_Caffe_layers.InnerProduct/1, where GetParam() = OCV/OCL
[       OK ] Test_Caffe_layers.InnerProduct/1 (4 ms)
[ RUN      ] Test_Caffe_layers.InnerProduct/2, where GetParam() = OCV/OCL_FP16
[     SKIP ] Test with tag 'dnn_skip_ocl_fp16' is skipped ('dnn_skip_ocl_fp16' is in skip list)
[       OK ] Test_Caffe_layers.InnerProduct/2 (0 ms)
[ RUN      ] Test_Caffe_layers.InnerProduct/3, where GetParam() = OCV/CPU
[     SKIP ] 
[       OK ] Test_Caffe_layers.InnerProduct/3 (0 ms)
[ RUN      ] Test_Caffe_layers.Pooling_max/0, where GetParam() = NGRAPH/CPU
[     SKIP ] 
[       OK ] Test_Caffe_layers.Pooling_max/0 (0 ms)
[ RUN      ] Test_Caffe_layers.Pooling_max/1, where GetParam() = OCV/OCL
[     SKIP ] 
[       OK ] Test_Caffe_layers.Pooling_max/1 (0 ms)
[ RUN      ] Test_Caffe_layers.Pooling_max/2, where GetParam() = OCV/OCL_FP16
[     SKIP ] 
[       OK ] Test_Caffe_layers.Pooling_max/2 (0 ms)
[ RUN      ] Test_Caffe_layers.Pooling_max/3, where GetParam() = OCV/CPU
[     SKIP ] 
[       OK ] Test_Caffe_layers.Pooling_max/3 (0 ms)
```
All further tests are skipped.

More focused test invocation works well:
```
./bin/opencv_test_dnn --gtest_filter=Test_Caffe_layers.Pooling_max*
...
[ RUN      ] Test_Caffe_layers.Pooling_max/0, where GetParam() = NGRAPH/CPU
[       OK ] Test_Caffe_layers.Pooling_max/0 (23 ms)
[ RUN      ] Test_Caffe_layers.Pooling_max/1, where GetParam() = OCV/OCL
[       OK ] Test_Caffe_layers.Pooling_max/1 (4 ms)
[ RUN      ] Test_Caffe_layers.Pooling_max/2, where GetParam() = OCV/OCL_FP16
[       OK ] Test_Caffe_layers.Pooling_max/2 (2 ms)
[ RUN      ] Test_Caffe_layers.Pooling_max/3, where GetParam() = OCV/CPU
[       OK ] Test_Caffe_layers.Pooling_max/3 (1 ms)
[----------] 4 tests from Test_Caffe_layers (30 ms total)

[----------] Global test environment tear-down
[==========] 4 tests from 1 test case ran. (30 ms total)
[  PASSED  ] 4 tests.
```

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-09-02 10:05:50,bug,"core: arm64: v_round() works with round to nearest, ties to even.","fix https://github.com/opencv/opencv/issues/24213

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-09-01 09:53:35,bug,[RFC] rounding rule for cv::divide(),"### System Information

OpenCV version: 4.x branch
Operating System / Platform: Ubuntu 20.04 (Raspi4, arm64)
Compiler & compiler version: GCC 9.3.0

### Detailed description

This issue is about `cv::divide()`. related with https://github.com/opencv/opencv/pull/24074
Rounding rule for it is not describled at [cv::divide()](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga6db555d30115642fedae0cda05604874)

In arm64, it works with [Round to nearest, ties away from zero](https://en.wikipedia.org/wiki/Rounding#Rounding_half_away_from_zero)
In x86-64, it works with [Round to nearest, ties to even](https://en.wikipedia.org/wiki/Rounding#Rounding_half_to_even).
(Possibly, the behavior may change according to the rounding mode specification of the floating point unit.)

Q. Their results are different. Which are these behaviours correct/better ?

If arm64 behaviours should be fixed...
---------------------------------------
For arm64, I think it can fix following patch.
However `v_round()` function seems to used many times.
I feel the risk of breaking backwards compatibility.

I would appreciate it if you could comment on this issue.

before : https://developer.arm.com/architectures/instruction-sets/intrinsics/vcvtaq_s64_f64
after : https://developer.arm.com/architectures/instruction-sets/intrinsics/vcvtnq_s64_f64

```diff
diff --git a/modules/core/include/opencv2/core/hal/intrin_neon.hpp b/modules/core/include/opencv2/core/hal/intrin_neon.hpp
index 6f8973231b..14eb180819 100644
--- a/modules/core/include/opencv2/core/hal/intrin_neon.hpp
+++ b/modules/core/include/opencv2/core/hal/intrin_neon.hpp
@@ -1997,12 +1997,12 @@ inline v_int32x4 v_trunc(const v_float32x4& a)
 inline v_int32x4 v_round(const v_float64x2& a)
 {
     static const int32x2_t zero = vdup_n_s32(0);
-    return v_int32x4(vcombine_s32(vmovn_s64(vcvtaq_s64_f64(a.val)), zero));
+    return v_int32x4(vcombine_s32(vmovn_s64(vcvtnq_s64_f64(a.val)), zero));
 }

 inline v_int32x4 v_round(const v_float64x2& a, const v_float64x2& b)
 {
-    return v_int32x4(vcombine_s32(vmovn_s64(vcvtaq_s64_f64(a.val)), vmovn_s64(vcvtaq_s64_f64(b.val))));
+    return v_int32x4(vcombine_s32(vmovn_s64(vcvtnq_s64_f64(a.val)), vmovn_s64(vcvtnq_s64_f64(b.val))));
 }
```




### Steps to reproduce

```cpp
#include <opencv2/core.hpp>
#include <iostream>

int main(void)
{
  cv::Mat src1 = (cv::Mat_<uchar>(3,3) << 25,23,0, 0,0,0, 0,0,0 );
  std::cout << src1 << std::endl;
  cv::Mat dst;
  cv::divide(src1, 2, dst );
  std::cout << dst << std::endl;
  return 0;
}
```

```bash
[x86-64]
kmtr@kmtr-VMware-Virtual-Platform:~/work/studyT2$ ./a.out
[ 25,  23,   0;
   0,   0,   0;
   0,   0,   0]
[ 12,  12,   0;
   0,   0,   0;
   0,   0,   0]

[arm64]
kmtr@ubuntu:~/work/build4-main/study$ ./a.out
[ 25,  23,   0;
   0,   0,   0;
   0,   0,   0]
[ 13,  12,   0;
   0,   0,   0;
   0,   0,   0]
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-31 15:45:41,bug,Fixed bug with the last 4 bytes in MJPEG encoder,"resolves #19634
resolves #24171
Enabled parallel processing, that was temporary disabled in #19812 because of the issue #19634
"
opencv/opencv,2023-08-30 03:53:56,bug,The cmake cann libopsproto.so library compiled with opencv4.8.0 could not be found,"### System Information

My device CPU: Kunpeng 920 +NPU: ascend310，AArch64 platform

### Detailed description

Ascend-cann-toolkit Download address. The download version is 6.0.1, 
OpenCV compiler options reference: https://github.com/opencv/opencv/wiki/Huawei-CANN-Backend




### Steps to reproduce

Trial version opencv version 4.8.0 and cann_backend_221010 seem to have been tried by 4.6.
 
Download toolkit :
[https://www.hiascend.com/document/detail/zh/quick-installation/22.0.0/quickinstg/500_Pro_3000/quickinstg_500_Pro_3000_0003.html](https://gitee.com/link?target=https%3A%2F%2Fwww.hiascend.com%2Fdocument%2Fdetail%2Fzh%2Fquick-installation%2F22.0.0%2Fquickinstg%2F500_Pro_3000%2Fquickinstg_500_Pro_3000_0003.html)

Ascend-cann-toolkit Installation command:
`./Ascend-cann-toolkit_6.0.1_linux-aarch64.run --install --install-for-all`

First step：
`source /usr/local/Ascend/ascend-toolkit/set_env.sh`

Second step:
cmake -D WITH_CANN=ON
-D BUILD_opencv_gapi=OFF
-D CMAKE_INSTALL_PREFIX=install ..

Error message ：

-- CANN: updated CANN_INSTALL_DIR from ASCEND_TOOLKIT_HOME=/usr/local/Ascend/ascend-toolkit/latest
-- CANN: libascendcl.so is found at /usr/local/Ascend/ascend-toolkit/latest/acllib/lib64/libascendcl.so
-- CANN: libgraph.so is found at /usr/local/Ascend/ascend-toolkit/latest/compiler/lib64/libgraph.so
-- CANN: libge_compiler.so is found at /usr/local/Ascend/ascend-toolkit/latest/compiler/lib64/libge_compiler.so
-- CANN: Missing libopsproto.so. Turning off HAVE_CANN



### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-27 08:59:24,bug,ONNX DNN inference produce Wrong result compare to 4.7.0,"### System Information

OpenCV version: 4.8.0
Operating System / Platform: Windows10
Compiler & compiler version: Visual Studio 17.0 for cpp
and
Python version: 3.9.15
OpenCV python version: 4.8.0.76 for python



### Detailed description

I had a model in Python using the Pytorch platform and converted it into onnx using ``` torch.export.onnx``` and I wanted to infer it in cpp. after hours, I only got weird results compared to the torch version. I ran it ```onnxruntime``` and the results were the same as the PyTorch model. then I inferred it in Python and got the result exactly the same as cpp and very different from ```onnxruntime``` and Pytorch. here are the pictures of the results in ONNXRunTime/Pytorch vs. Opencv DNN:
ONNXRunTime/Pytorch
![image](https://github.com/opencv/opencv/assets/95086211/2f250d01-6fcf-4240-9e0a-d9e79016faf6)
Opencv DNN:
![image](https://github.com/opencv/opencv/assets/95086211/ff2dd5bd-8ac7-4887-81b1-577c83f8b6dc)


I don't know what exactly going on but there is no problem in using Opencv 4.7.0

### Steps to reproduce

![raw](https://github.com/opencv/opencv/assets/95086211/91a87b00-46eb-459e-a0f8-60c1f57cfcf1)
[wide.onnx](https://drive.google.com/file/d/1kzFIl__M33DuVUGCoSeDwBm0DiU0kPx3/view?usp=drive_link)
This is the image for testing in Python for ONNXRunTime and Opencv, and you can access the model file with the link above. to load the image: 
```
c=cv2.imread(""raw.jpg"")
c=np.transpose(c,(2,1,0))
x=np.expand_dims(c, axis=0).astype(np.float32)
```
then infer it with ONNXRunTime:
```
import onnxruntime as ort
import numpy as np

ort_sess = ort.InferenceSession('wide.onnx')
outputs = ort_sess.run(None, {'input': x})
res=outputs[0][0,0,:,:]

plt.imshow(cv2.normalize(res,None, 0, 255, cv2.NORM_MINMAX),cmap='gray')
```

To reproduce the result in OpenCV, set the image as input of the Net:
```
model = cv2.dnn.readNetFromONNX(""wide.onnx"")
model.setInput(x)
output_blob = model.forward(model.getUnconnectedOutLayersNames())
plt.imshow(cv2.normalize(output_blob[0][0,0,:,:],None, 0, 255, cv2.NORM_MINMAX),cmap='gray')
```



 

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-22 17:57:50,bug,Why  OpenCV CUDA morphology SLOWER than my simple cu kernel?,"### System Information

c++ user
OpenCV version: 4.8.0
win10
MSVC2019
GPU  nvidia3060ti  
CUDA 12.2

### Detailed description

img size 3k*2k  , element size: 43 * 43  

_use opencv CPU spend 4ms，my CPU is AMD R5 5500_

opencvCUDA spend 380ms

this is  my cuda code spend 28ms

CUDA NPP spend 54ms




### Steps to reproduce

img size 3k*2k  , element size: 43 * 43  

_use opencv CPU spend 4ms，my CPU is AMD R5 5500_


_Although there are three main functions blow, I have placed them in one project to ensure consistency in the environment. I comment out two main functions when using them._

this is opencvCUDA morphology code:
spend 380ms

------------------------------------------------------------------
```
#include <opencv2/opencv.hpp>
#include <opencv2/cudaarithm.hpp>
#include <opencv2/cudaimgproc.hpp>
#include <opencv2/cudafilters.hpp>
#include ""cuda_runtime.h""
#include ""device_launch_parameters.h""
#if 0
int main() {
    cv::Mat inputImage = cv::imread(""C:\\\\Users\\\\59526\\\\Desktop\\\\test.jpg"");

    cv::cvtColor(inputImage, inputImage, cv::COLOR_BGR2GRAY);
    cv::cuda::GpuMat src;

    src.upload(inputImage);

    cv::cuda::printShortCudaDeviceInfo(cv::cuda::getDevice());

    int an = 21;
    cv::Mat element = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(an * 2 + 1, an * 2 + 1), cv::Point(an, an));
    cv::Ptr<cv::cuda::Filter> erodeFilter = cv::cuda::createMorphologyFilter(cv::MORPH_ERODE, src.type(), element);

    cv::cuda::GpuMat gpuOutputImage;

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    cudaEventRecord(start);

    //auto startTime = std::chrono::high_resolution_clock::now();

    //double start = cv::getTickCount();
   

    erodeFilter->apply(src, gpuOutputImage);


    //double fps = cv::getTickFrequency() / (cv::getTickCount() - start);
    //std::cout << ""FPS : "" << fps << std::endl;


    //auto endTime = std::chrono::high_resolution_clock::now();
    //auto duration = std::chrono::duration_cast<std::chrono::microseconds>(endTime - startTime).count();
    //std::cout << """" << duration / 1000 << "" ms."" << std::endl;

    cudaEventRecord(stop);
    cudaEventSynchronize(stop);
    float milliseconds = 0;
    cudaEventElapsedTime(&milliseconds, start, stop);
    std::cout << ""GPU runtime: "" << milliseconds << "" ms"" << std::endl;

    cv::Mat outputImage;
    gpuOutputImage.download(outputImage);

    cv::imshow(""Input Image"", inputImage);
    cv::imshow(""Eroded Image"", outputImage);

    cv::waitKey(0);

    return 0;
}
```
-----------------------------------------------------------------------
### **this is  my cuda code**
### **spend  28ms**
```
#include <iostream>
#include <opencv2/opencv.hpp>
#include ""cuda_runtime.h""
#include ""device_launch_parameters.h""
#include <algorithm>

__global__ void erodeKernel_junk(const uchar* input, uchar* output, int rows, int cols, int kernelSize, int kernelSize2) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    if (x < cols && y < rows) {
        const int halfSize = kernelSize / 2;
        const int halfSize2 = kernelSize2 / 2;
        uchar minVal = 255;
        for (int i = -halfSize2; i <= halfSize2; ++i) {
            for (int j = -halfSize; j <= halfSize; ++j) {
                int px = x + j;
                int py = y + i;
                if (px >= 0 && px < cols && py >= 0 && py < rows) {
                    uchar val = input[py * cols + px];
                    if (val < minVal) {
                        minVal = val;
                    }
                }
            }
        }
        output[y * cols + x] = minVal;
    }
}

int main() {
    cv::Mat inputImage = cv::imread(""C:/Users/59526/Desktop/test.jpg"");
    cv::cvtColor(inputImage, inputImage, cv::COLOR_BGR2GRAY);
  
    int w = 43;
    int h = 43;
    cv::Mat inputImage2;
    cv::Mat element = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(w, h));
    auto startTime = std::chrono::steady_clock::now();
    cv::erode(inputImage, inputImage2, element);
    auto endTime = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(endTime - startTime).count();
    std::cout << ""程序运行时间: "" << duration << "" 毫秒"" << std::endl << std::endl << std::endl;

    int numGPUs;
    cudaGetDeviceCount(&numGPUs);

    if (numGPUs <= 0) {
        std::cerr << ""No CUDA-capable devices found."" << std::endl;
        return 1;
    }
    int deviceId = 0; 
    cudaDeviceProp deviceProp;
    cudaGetDeviceProperties(&deviceProp, deviceId);

    int inRows = inputImage.rows;
    int inCols = inputImage.cols;

    uchar* d_inputImage, * d_outputImage, * d_tempImage;
    size_t inputSize = inRows * inCols * sizeof(uchar);
    size_t outputSize = (inRows) * (inCols) * sizeof(uchar);

    cudaMalloc(&d_inputImage, inputSize);
    cudaMalloc(&d_outputImage, outputSize);
 
    cudaMemcpy(d_inputImage, inputImage.data, inputSize, cudaMemcpyHostToDevice);

    dim3 block(16, 16);
    dim3 grid((inCols + block.x - 1) / block.x, (inRows + block.y - 1) / block.y);

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    cudaEventRecord(start);

    erodeKernel_junk << <grid, block >> > (d_inputImage, d_outputImage, inRows, inCols, w, h);

    cudaEventRecord(stop);
    cudaEventSynchronize(stop);
    {
        float milliseconds = 0;
        cudaEventElapsedTime(&milliseconds, start, stop);
        std::cout << ""GPU runtime: "" << milliseconds << "" ms"" << std::endl;
    }

    cv::Mat outputImage(inRows, inCols, CV_8UC1);
    cudaMemcpy(outputImage.data, d_outputImage, outputSize, cudaMemcpyDeviceToHost);

    cudaFree(d_inputImage);
    cudaFree(d_outputImage);

    cv::namedWindow(""Eroded"", cv::WINDOW_KEEPRATIO);
    cv::imshow(""Eroded"", outputImage);
    cv::waitKey(0);
    return 0;
}
```
------------------------------------------------------------------------------------------------------------
this is CUDA NPP code
```
#include <opencv2/opencv.hpp>
#include <nppi_morphological_operations.h>

int main() {
    cv::Mat inputImage = cv::imread(""C:/Users/59526/Desktop/test.jpg"");
    cv::cvtColor(inputImage, inputImage, cv::COLOR_BGR2GRAY);
    if (inputImage.empty()) {
        std::cout << ""Failed to load image."" << std::endl;
        return -1;
    }


    Npp8u* pu8srcData_dev = NULL;
    cudaMalloc((void**)&pu8srcData_dev, inputImage.cols * inputImage.rows * sizeof(Npp8u));
    cudaMemcpy(pu8srcData_dev, inputImage.data, inputImage.cols * inputImage.rows * sizeof(Npp8u), cudaMemcpyHostToDevice);


    cv::Mat element = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(43, 43));
    Npp8u* pu8tmpl_dev = NULL;
    cudaMalloc((void**)&pu8tmpl_dev, element.cols * element.rows * sizeof(Npp8u));
    cudaMemcpy(pu8tmpl_dev, element.data, element.cols * element.rows * sizeof(Npp8u), cudaMemcpyHostToDevice);

    NppiSize tmplSize = { element.cols, element.rows };
    NppiPoint anchor = { element.cols>>1, element.rows>>1 };

    Npp8u* pu8dstData_dev = NULL;
    cudaMalloc((void**)&pu8dstData_dev, inputImage.cols * inputImage.rows * sizeof(Npp8u));

    NppiSize oSizeROI = { inputImage.cols , inputImage.rows };

    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);

    NppStatus status;
    cudaEventRecord(start);
    

     status = nppiErode_8u_C1R(pu8srcData_dev, inputImage.cols, pu8dstData_dev, inputImage.cols, oSizeROI,
        pu8tmpl_dev, tmplSize, anchor);


    cudaEventRecord(stop);

    cudaEventSynchronize(stop);
    {

        float milliseconds = 0;
        cudaEventElapsedTime(&milliseconds, start, stop);
        std::cout << ""NPP GPU runtime: "" << milliseconds << "" ms"" << std::endl;
    }

    cv::Mat outputImage(inputImage.rows, inputImage.cols, CV_8UC1);
    cudaMemcpy(outputImage.data, pu8dstData_dev, inputImage.rows* inputImage.cols, cudaMemcpyDeviceToHost);
    cv::namedWindow(""Dilated Image"", cv::WINDOW_KEEPRATIO);
    cv::imshow(""Dilated Image"", outputImage);
    cv::waitKey(0);

    return 0;
}
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-17 10:06:16,bug,Use STRING instead of PATH to fix #24141,"Resolves #24141

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [X] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-16 19:50:56,bug,add missing include,Backport of #24167
opencv/opencv,2023-08-15 06:14:56,bug,DNN: fix the issue in layer_fuse,"Fix issue: https://github.com/opencv/opencv/issues/24041
relates #22401

Handling when the `operation` of the `Elemtwise layer` is missing.
`nextData->params.get<String>(""operation"")` will fail when the `operation` is missing. This patch adds default value for such case.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-12 10:07:34,bug,why minMaxIdx  Restored reduced IPP calls,"### System Information

// example for c++ user
OpenCV version: 4.0 or later
Operating System / Platform: Centos 7.9
Compiler & compiler version: GCC 4.8.5

### Detailed description

cv::minMaxIdx   Unable to use IPP acceleration


/modules/core/src
/minmax.cpp
#undef HAVE_IPP
#undef CV_IPP_RUN_FAST
#define CV_IPP_RUN_FAST(f, ...)
#undef CV_IPP_RUN
#define CV_IPP_RUN(c, f, ...)

#define IPP_DISABLE_MINMAXIDX_MANY_ROWS 1  // see Core_MinMaxIdx.rows_overflow test

After restored reduced IPP calls,  cv::minMaxIdx need more time to run, why unable to use IPP acceleration?

### Steps to reproduce

run cv::minMaxIdx and statistical time

### Issue submission checklist

- [X] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-11 17:23:14,bug,mac m1  ld: symbol(s) not found for architecture arm64.    build java opencv for opencv-4.8.0,"### System Information

```
(base) guoquanhao@MacBook-Pro build % clang --version
Apple clang version 14.0.3 (clang-1403.0.22.14.1)
Target: arm64-apple-darwin22.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

(base) guoquanhao@MacBook-Pro build % java --version
java 17.0.8 2023-07-18 LTS
Java(TM) SE Runtime Environment (build 17.0.8+9-LTS-211)
Java HotSpot(TM) 64-Bit Server VM (build 17.0.8+9-LTS-211, mixed mode, sharing)
(base) guoquanhao@MacBook-Pro build %
```
<img width=""530"" alt=""image"" src=""https://github.com/opencv/opencv/assets/49911294/5d8b8cb8-1987-44b5-8bbc-2cd0be3a57c5"">

<img width=""280"" alt=""image"" src=""https://github.com/opencv/opencv/assets/49911294/12bb04d4-a0c8-4193-ad2c-c3d042c72af9"">

Using following command
```
cmake \\
-DCMAKE_SYSTEM_PROCESSOR=arm64 \\
-DCMAKE_OSX_ARCHITECTURES=arm64 \\
-DWITH_OPENJPEG=OFF \\
-DWITH_IPP=OFF \\
-DCMAKE_BUILD_TYPE=RELEASE \\
-DCMAKE_INSTALL_PREFIX=/usr/local/opencv \\
-DJAVA_INCLUDE_PATH=$JAVA_HOME/include \\
-DBUILD_opencv_python2=OFF \\
-DBUILD_opencv_java=ON \\
-DINSTALL_PYTHON_EXAMPLES=OFF \\
-DINSTALL_C_EXAMPLES=OFF \\
-DBUILD_ZLIB=OFF \\
-DOPENCV_ENABLE_NONFREE=ON \\
-DOPENCV_EXTRA_MODULES_PATH=/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules \\
-DBUILD_EXAMPLES=ON ..
```



### Detailed description

```
est/test_niblack_threshold.cpp.o
[ 73%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/onevpl/data_provider_dispatcher.cpp.o
[ 73%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/onevpl/cfg_param_device_selector.cpp.o
[ 73%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/onevpl/device_selector_interface.cpp.o
[ 73%] Building CXX object modules/xobjdetect/tools/waldboost_detector/CMakeFiles/opencv_waldboost_detector.dir/waldboost_detector.cpp.o
[ 73%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_radon_transform.cpp.o
[ 73%] Linking CXX executable ../../bin/example_ximgproc_structured_edge_detection
[ 73%] Built target example_ximgproc_structured_edge_detection
[ 73%] Building CXX object modules/aruco/CMakeFiles/opencv_test_aruco.dir/test/test_aruco_tutorial.cpp.o
[ 73%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_ridge_detection_filter.cpp.o
[ 73%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/gstreamer/gstreamer_pipeline_facade.cpp.o
[ 73%] Linking CXX executable ../../bin/example_ximgproc_thinning
[ 73%] Built target example_ximgproc_thinning
[ 73%] Building CXX object modules/aruco/CMakeFiles/opencv_perf_aruco.dir/perf/perf_main.cpp.o
[ 74%] Linking CXX executable ../../../../bin/opencv_waldboost_detector
[ 74%] Built target opencv_waldboost_detector
[ 74%] Building CXX object modules/aruco/CMakeFiles/opencv_test_aruco.dir/test/test_main.cpp.o
[ 74%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_rolling_guidance_filter.cpp.o
[ 74%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_run_length_morphology.cpp.o
[ 74%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_scansegment.cpp.o
[ 74%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/gstreamer/gstreamerpipeline.cpp.o
[ 74%] Building CXX object modules/aruco/CMakeFiles/example_aruco_calibrate_camera.dir/samples/calibrate_camera.cpp.o
[ 74%] Linking CXX executable ../../bin/opencv_perf_aruco
[ 74%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_slic.cpp.o
[ 74%] Built target opencv_perf_aruco
[ 74%] Building CXX object modules/aruco/CMakeFiles/example_aruco_calibrate_camera_charuco.dir/samples/calibrate_camera_charuco.cpp.o
[ 74%] Linking CXX executable ../../bin/opencv_test_aruco
[ 74%] Built target opencv_test_aruco
[ 74%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/gstreamer/gstreamersource.cpp.o
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/calibrate_camera.cpp:12:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
[ 74%] Building CXX object modules/aruco/CMakeFiles/example_aruco_create_board.dir/samples/create_board.cpp.o
[ 74%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/gstreamer/gstreamer_buffer_utils.cpp.o
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/calibrate_camera_charuco.cpp:11:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
1 warning generated.
[ 74%] Linking CXX executable ../../bin/example_aruco_calibrate_camera
[ 74%] Building CXX object modules/aruco/CMakeFiles/example_aruco_create_board_charuco.dir/samples/create_board_charuco.cpp.o
[ 74%] Built target example_aruco_calibrate_camera
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/create_board.cpp:43:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
[ 74%] Building CXX object modules/aruco/CMakeFiles/example_aruco_create_diamond.dir/samples/create_diamond.cpp.o
1 warning generated.
[ 74%] Linking CXX executable ../../bin/example_aruco_calibrate_camera_charuco
[ 74%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/gstreamer/gstreamer_media_adapter.cpp.o
1 warning generated.
[ 74%] Built target example_aruco_calibrate_camera_charuco
[ 74%] Linking CXX executable ../../bin/example_aruco_create_board
[ 74%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_sparse_match_interpolator.cpp.o
[ 74%] Built target example_aruco_create_board
[ 75%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/streaming/gstreamer/gstreamerenv.cpp.o
[ 75%] Building CXX object modules/aruco/CMakeFiles/example_aruco_create_marker.dir/samples/create_marker.cpp.o
[ 75%] Building CXX object modules/gapi/CMakeFiles/opencv_gapi.dir/src/utils/itt.cpp.o
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/create_board_charuco.cpp:43:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
[ 75%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_structured_edge_detection.cpp.o
1 warning generated.
[ 75%] Linking CXX executable ../../bin/example_aruco_create_board_charuco
[ 75%] Linking CXX executable ../../bin/example_aruco_create_diamond
[ 75%] Built target example_aruco_create_board_charuco
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/create_marker.cpp:43:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
[ 75%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_thinning.cpp.o
[ 75%] Built target example_aruco_create_diamond
[ 75%] Building CXX object modules/aruco/CMakeFiles/example_aruco_detect_board.dir/samples/detect_board.cpp.o
[ 75%] Building CXX object modules/aruco/CMakeFiles/example_aruco_detect_board_charuco.dir/samples/detect_board_charuco.cpp.o
[ 75%] Building CXX object modules/ximgproc/CMakeFiles/opencv_test_ximgproc.dir/test/test_weighted_median_filter.cpp.o
1 warning generated.
[ 75%] Linking CXX executable ../../bin/example_aruco_create_marker
[ 75%] Linking CXX shared library ../../lib/libopencv_gapi.dylib
[ 75%] Built target example_aruco_create_marker
[ 75%] Building CXX object modules/aruco/CMakeFiles/example_aruco_detect_diamonds.dir/samples/detect_diamonds.cpp.o
[ 75%] Built target opencv_gapi
[ 75%] Building CXX object modules/aruco/CMakeFiles/example_aruco_detect_markers.dir/samples/detect_markers.cpp.o
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/detect_board.cpp:44:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/detect_board_charuco.cpp:44:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/detect_diamonds.cpp:44:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
1 warning generated.
1 warning generated.
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/detect_markers.cpp:43:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
[ 75%] Linking CXX executable ../../bin/example_aruco_detect_board_charuco
[ 75%] Linking CXX executable ../../bin/example_aruco_detect_board
[ 75%] Building CXX object modules/aruco/CMakeFiles/example_aruco_tutorial_charuco_create_detect.dir/samples/tutorial_charuco_create_detect.cpp.o
[ 75%] Built target example_aruco_detect_board
[ 75%] Built target example_aruco_detect_board_charuco
[ 75%] Building CXX object modules/bgsegm/CMakeFiles/example_bgsegm_bgfg.dir/samples/bgfg.cpp.o
[ 75%] Building CXX object modules/bgsegm/CMakeFiles/opencv_test_bgsegm.dir/test/test_backgroundsubtractor_gbh.cpp.o
[ 75%] Building CXX object modules/dpm/CMakeFiles/example_dpm_cascade_detect_camera.dir/samples/cascade_detect_camera.cpp.o
1 warning generated.
[ 76%] Linking CXX executable ../../bin/example_aruco_detect_markers
1 warning generated.
[ 76%] Linking CXX executable ../../bin/example_aruco_detect_diamonds
[ 76%] Built target example_aruco_detect_markers
[ 76%] Building CXX object modules/bgsegm/CMakeFiles/opencv_test_bgsegm.dir/test/test_backgroundsubtractor_lsbp.cpp.o
[ 76%] Built target example_aruco_detect_diamonds
[ 76%] Building CXX object modules/bgsegm/CMakeFiles/opencv_test_bgsegm.dir/test/test_main.cpp.o
[ 77%] Building CXX object modules/dpm/CMakeFiles/example_dpm_cascade_detect_sequence.dir/samples/cascade_detect_sequence.cpp.o
In file included from /Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/tutorial_charuco_create_detect.cpp:7:
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/aruco/samples/aruco_samples_utility.hpp:35:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
        sprintf(buf, ""flags: %s%s%s%s"",
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
[ 77%] Linking CXX executable ../../bin/opencv_test_ximgproc
[ 77%] Built target opencv_test_ximgproc
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_bif.cpp.o
[ 77%] Linking CXX executable ../../bin/example_bgsegm_bgfg
1 warning generated.
[ 77%] Linking CXX executable ../../bin/example_aruco_tutorial_charuco_create_detect
[ 77%] Linking CXX executable ../../bin/example_dpm_cascade_detect_camera
[ 77%] Built target example_bgsegm_bgfg
[ 77%] Built target example_aruco_tutorial_charuco_create_detect
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facemark_demo_aam.dir/samples/facemark_demo_aam.cpp.o
[ 77%] Built target example_dpm_cascade_detect_camera
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facemark_demo_lbf.dir/samples/facemark_demo_lbf.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_face_align.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facemark_lbf_fitting.dir/samples/facemark_lbf_fitting.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_facemark.cpp.o
[ 77%] Linking CXX executable ../../bin/example_dpm_cascade_detect_sequence
[ 77%] Built target example_dpm_cascade_detect_sequence
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facerec_demo.dir/samples/facerec_demo.cpp.o
[ 77%] Linking CXX executable ../../bin/opencv_test_bgsegm
[ 77%] Built target opencv_test_bgsegm
/Users/guoquanhao/OpenCV/opencv_contrib-4.8.0/modules/face/samples/facemark_lbf_fitting.cpp:136:9: warning: 'sprintf' is deprecated: This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead. [-Wdeprecated-declarations]
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_facemark_aam.cpp.o
        sprintf(buff, ""faces: %i %03.2f fps, fit:%03.0f ms"",nfaces,fps,fittime*1000);
        ^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/stdio.h:188:1: note: 'sprintf' has been explicitly marked deprecated here
__deprecated_msg(""This function is provided for compatibility reasons only.  Due to security concerns inherent in the design of sprintf(3), it is highly recommended that you use snprintf(3) instead."")
^
/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX13.3.sdk/usr/include/sys/cdefs.h:215:48: note: expanded from macro '__deprecated_msg'
        #define __deprecated_msg(_msg) __attribute__((__deprecated__(_msg)))
                                                      ^
[ 77%] Linking CXX executable ../../bin/example_face_facemark_demo_lbf
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_facemark_lbf.cpp.o
[ 77%] Built target example_face_facemark_demo_lbf
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_loadsave.cpp.o
1 warning generated.
[ 77%] Linking CXX executable ../../bin/example_face_facemark_lbf_fitting
[ 77%] Built target example_face_facemark_lbf_fitting
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facerec_eigenfaces.dir/samples/facerec_eigenfaces.cpp.o
[ 77%] Linking CXX executable ../../bin/example_face_facemark_demo_aam
[ 77%] Built target example_face_facemark_demo_aam
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_mace.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facerec_fisherfaces.dir/samples/facerec_fisherfaces.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/opencv_test_face.dir/test/test_main.cpp.o
[ 77%] Linking CXX executable ../../bin/example_face_facerec_demo
[ 77%] Built target example_face_facerec_demo
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facerec_lbph.dir/samples/facerec_lbph.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facerec_save_load.dir/samples/facerec_save_load.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_facerec_video.dir/samples/facerec_video.cpp.o
[ 77%] Linking CXX executable ../../bin/example_face_facerec_eigenfaces
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_mace_webcam.dir/samples/mace_webcam.cpp.o
[ 77%] Built target example_face_facerec_eigenfaces
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_sampleDetectLandmarks.dir/samples/sampleDetectLandmarks.cpp.o
[ 77%] Linking CXX executable ../../bin/example_face_facerec_fisherfaces
[ 77%] Built target example_face_facerec_fisherfaces
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_sampleDetectLandmarksvideo.dir/samples/sampleDetectLandmarksvideo.cpp.o
[ 77%] Linking CXX executable ../../bin/opencv_test_face
[ 77%] Linking CXX executable ../../bin/example_face_facerec_lbph
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_sample_face_swapping.dir/samples/sample_face_swapping.cpp.o
[ 77%] Built target opencv_test_face
[ 77%] Built target example_face_facerec_lbph
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_sample_train_landmark_detector.dir/samples/sample_train_landmark_detector.cpp.o
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_sample_train_landmark_detector2.dir/samples/sample_train_landmark_detector2.cpp.o
[ 77%] Linking CXX executable ../../bin/example_face_facerec_save_load
[ 77%] Linking CXX executable ../../bin/example_face_mace_webcam
[ 77%] Built target example_face_facerec_save_load
[ 77%] Built target example_face_mace_webcam
[ 77%] Building CXX object modules/face/CMakeFiles/example_face_samplewriteconfigfile.dir/samples/samplewriteconfigfile.cpp.o
[ 77%] Linking CXX executable ../../bin/example_face_sampleDetectLandmarks
[ 77%] Linking CXX executable ../../bin/example_face_facerec_video
[ 77%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/common/gapi_compoundkernel_tests.cpp.o
[ 77%] Built target example_face_facerec_video
[ 77%] Built target example_face_sampleDetectLandmarks
[ 78%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/common/gapi_core_tests.cpp.o
[ 78%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/common/gapi_imgproc_tests.cpp.o
[ 78%] Linking CXX executable ../../bin/example_face_sampleDetectLandmarksvideo
[ 78%] Built target example_face_sampleDetectLandmarksvideo
[ 78%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/common/gapi_core_perf_tests.cpp.o
[ 78%] Linking CXX executable ../../bin/example_face_sample_train_landmark_detector2
[ 78%] Linking CXX executable ../../bin/example_face_sample_train_landmark_detector
[ 78%] Built target example_face_sample_train_landmark_detector2
[ 78%] Building CXX object modules/gapi/CMakeFiles/example_gapi_api_example.dir/samples/api_example.cpp.o
[ 78%] Linking CXX executable ../../bin/example_face_sample_face_swapping
[ 78%] Built target example_face_sample_train_landmark_detector
[ 78%] Building CXX object modules/gapi/CMakeFiles/example_gapi_draw_example.dir/samples/draw_example.cpp.o
[ 78%] Built target example_face_sample_face_swapping
[ 79%] Linking CXX executable ../../bin/example_face_samplewriteconfigfile
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_face_detection_mtcnn.dir/samples/face_detection_mtcnn.cpp.o
[ 79%] Built target example_face_samplewriteconfigfile
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_gaze_estimation.dir/samples/gaze_estimation.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_api_example
[ 79%] Linking CXX executable ../../bin/example_gapi_draw_example
[ 79%] Built target example_gapi_api_example
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/common/gapi_operators_tests.cpp.o
[ 79%] Built target example_gapi_draw_example
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/common/gapi_imgproc_perf_tests.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_gaze_estimation
[ 79%] Built target example_gapi_gaze_estimation
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_infer_ie_onnx_hybrid.dir/samples/infer_ie_onnx_hybrid.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/common/gapi_render_tests.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/common/gapi_render_perf_tests.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_face_detection_mtcnn
[ 79%] Built target example_gapi_face_detection_mtcnn
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_infer_single_roi.dir/samples/infer_single_roi.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_infer_ie_onnx_hybrid
[ 79%] Built target example_gapi_infer_ie_onnx_hybrid
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/common/gapi_stereo_tests.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/common/gapi_video_perf_tests.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_infer_single_roi
[ 79%] Built target example_gapi_infer_single_roi
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/common/gapi_video_tests.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_core_tests_cpu.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_infer_ssd_onnx.dir/samples/infer_ssd_onnx.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_core_tests_fluid.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_infer_ssd_onnx
[ 79%] Built target example_gapi_infer_ssd_onnx
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_imgproc_tests_cpu.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_oak_basic_infer.dir/samples/oak_basic_infer.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_imgproc_tests_fluid.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/cpu/gapi_core_perf_tests_cpu.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_oak_basic_infer
[ 79%] Built target example_gapi_oak_basic_infer
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_oak_copy.dir/samples/oak_copy.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_oak_copy
[ 79%] Built target example_gapi_oak_copy
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_oak_rgb_camera_encoding.dir/samples/oak_rgb_camera_encoding.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_ocv_stateful_kernel_tests.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/cpu/gapi_core_perf_tests_fluid.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_oak_rgb_camera_encoding
[ 79%] Built target example_gapi_oak_rgb_camera_encoding
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_oak_small_hetero_pipeline.dir/samples/oak_small_hetero_pipeline.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_oak_small_hetero_pipeline
[ 79%] Built target example_gapi_oak_small_hetero_pipeline
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/cpu/gapi_imgproc_perf_tests_cpu.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_onevpl_infer_with_advanced_device_selection.dir/samples/onevpl_infer_with_advanced_device_selection.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/cpu/gapi_imgproc_perf_tests_fluid.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_onevpl_source_to_bgr_conv.dir/samples/onevpl_source_to_bgr_conv.cpp.o
[ 79%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/cpu/gapi_video_perf_tests_cpu.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_onevpl_source_to_bgr_conv
[ 79%] Built target example_gapi_onevpl_source_to_bgr_conv
[ 79%] Building CXX object modules/gapi/CMakeFiles/example_gapi_pipeline_modeling_tool.dir/samples/pipeline_modeling_tool.cpp.o
[ 79%] Linking CXX executable ../../bin/example_gapi_onevpl_infer_with_advanced_device_selection
[ 79%] Built target example_gapi_onevpl_infer_with_advanced_device_selection
[ 80%] Building CXX object modules/gapi/CMakeFiles/example_gapi_privacy_masking_camera.dir/samples/privacy_masking_camera.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_operators_tests_cpu.cpp.o
[ 80%] Linking CXX executable ../../bin/example_gapi_privacy_masking_camera
[ 80%] Built target example_gapi_privacy_masking_camera
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/gpu/gapi_core_perf_tests_gpu.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/example_gapi_semantic_segmentation.dir/samples/semantic_segmentation.cpp.o
[ 80%] Linking CXX executable ../../bin/example_gapi_pipeline_modeling_tool
[ 80%] Built target example_gapi_pipeline_modeling_tool
[ 80%] Building CXX object modules/gapi/CMakeFiles/example_gapi_slides_blur_gapi.dir/samples/slides_blur_gapi.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/gpu/gapi_imgproc_perf_tests_gpu.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/internal/gapi_compiler_perf_tests.cpp.o
[ 80%] Linking CXX executable ../../bin/example_gapi_slides_blur_gapi
[ 80%] Built target example_gapi_slides_blur_gapi
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_operators_tests_fluid.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/example_gapi_slides_sobel_cv.dir/samples/slides_sobel_cv.cpp.o
[ 80%] Linking CXX executable ../../bin/example_gapi_semantic_segmentation
[ 80%] Built target example_gapi_semantic_segmentation
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_stereo_tests_cpu.cpp.o
[ 80%] Linking CXX executable ../../bin/example_gapi_slides_sobel_cv
[ 80%] Built target example_gapi_slides_sobel_cv
[ 80%] Building CXX object modules/gapi/CMakeFiles/example_gapi_slides_sobel_gapi.dir/samples/slides_sobel_gapi.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/cpu/gapi_video_tests_cpu.cpp.o
[ 80%] Linking CXX executable ../../bin/example_gapi_slides_sobel_gapi
[ 80%] Built target example_gapi_slides_sobel_gapi
[ 80%] Building CXX object modules/gapi/CMakeFiles/example_gapi_text_detection.dir/samples/text_detection.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/executor/gtbbexecutor_internal_tests.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_array_tests.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/perf_bench.cpp.o
[ 80%] Processing OpenCL kernels (optflow)
[ 80%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/deepflow.cpp.o
[ 80%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/perf_main.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/interfaces.cpp.o
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/conditioning.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/motempl.cpp.o
[ 81%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/render/gapi_render_perf_tests_ocv.cpp.o
[ 81%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_async_test.cpp.o
[ 81%] Linking CXX executable ../../bin/example_gapi_text_detection
[ 81%] Built target example_gapi_text_detection
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/fundamental.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/pcaflow.cpp.o
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/io.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/rlof/geo_interpolation.cpp.o
[ 81%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_basic_hetero_tests.cpp.o
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/numeric.cpp.o
[ 81%] Processing OpenCL kernels (stitching)
[ 81%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/autocalib.cpp.o
[ 81%] Building CXX object modules/gapi/CMakeFiles/opencv_perf_gapi.dir/perf/streaming/gapi_streaming_source_perf_tests.cpp.o
[ 81%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_compile_args_tests.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/rlof/rlof_localflow.cpp.o
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/projection.cpp.o
[ 81%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/blenders.cpp.o
[ 81%] Building CXX object modules/tracking/CMakeFiles/opencv_test_tracking.dir/test/test_aukf.cpp.o
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/reconstruct.cpp.o
[ 81%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/camera.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/rlofflow.cpp.o
[ 81%] Linking CXX executable ../../bin/opencv_perf_gapi
[ 81%] Building CXX object modules/tracking/CMakeFiles/opencv_perf_tracking.dir/perf/perf_main.cpp.o
[ 81%] Built target opencv_perf_gapi
[ 81%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_desc_tests.cpp.o
[ 81%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/exposure_compensate.cpp.o
[ 81%] Building CXX object modules/tracking/CMakeFiles/opencv_test_tracking.dir/test/test_main.cpp.o
[ 81%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_fluid_parallel_rois_test.cpp.o
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/robust.cpp.o
[ 81%] Building CXX object modules/tracking/CMakeFiles/opencv_perf_tracking.dir/perf/perf_trackers.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/simpleflow.cpp.o
[ 81%] Building CXX object modules/tracking/CMakeFiles/opencv_test_tracking.dir/test/test_trackerParametersIO.cpp.o
[ 81%] Building CXX object modules/tracking/CMakeFiles/example_tracking_benchmark.dir/samples/benchmark.cpp.o
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/simple_pipeline.cpp.o
[ 81%] Building CXX object modules/tracking/CMakeFiles/opencv_test_tracking.dir/test/test_trackers.cpp.o
[ 81%] Linking CXX executable ../../bin/example_tracking_benchmark
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/sparse_matching_gpc.cpp.o
[ 81%] Built target example_tracking_benchmark
[ 81%] Building CXX object modules/sfm/CMakeFiles/opencv_sfm.dir/src/triangulation.cpp.o
[ 81%] Linking CXX executable ../../bin/opencv_perf_tracking
[ 81%] Built target opencv_perf_tracking
[ 81%] Building CXX object modules/tracking/CMakeFiles/example_tracking_csrt.dir/samples/csrt.cpp.o
[ 81%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/matchers.cpp.o
[ 81%] Building CXX object modules/tracking/CMakeFiles/opencv_test_tracking.dir/test/test_ukf.cpp.o
[ 81%] Linking CXX executable ../../bin/example_tracking_csrt
[ 81%] Built target example_tracking_csrt
[ 81%] Building CXX object modules/tracking/CMakeFiles/example_tracking_goturnTracker.dir/samples/goturnTracker.cpp.o
[ 81%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/sparsetodenseflow.cpp.o
[ 82%] Linking CXX shared library ../../lib/libopencv_sfm.dylib
Undefined symbols for architecture arm64:
  ""google::InitVLOG3__(int**, int*, char const*, int)"", referenced from:
      libmv::EstimateFundamentalFromCorrespondences(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, libmv::EstimateFundamentalOptions const&, Eigen::Matrix<double, 3, 3, 0, 3, 3>*) in libmultiview.a(fundamental.cc.o)
      libmv::EuclideanReprojectionError(libmv::Tracks const&, libmv::EuclideanReconstruction const&, libmv::CameraIntrinsics const&) in libsimple_pipeline.a(pipeline.cc.o)
      libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::EightPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>::Model libmv::Estimate<libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::EightPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>, libmv::MLEScorer<libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::EightPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>>>(libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::EightPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>> const&, libmv::MLEScorer<libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::EightPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>> const&, libmv::vector<int, Eigen::aligned_allocator<int>>*, double*, double) in libmultiview.a(robust_fundamental.cc.o)
      libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::SevenPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>::Model libmv::Estimate<libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::SevenPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>, libmv::MLEScorer<libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::SevenPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>>>(libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::SevenPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>> const&, libmv::MLEScorer<libmv::two_view::kernel::Kernel<libmv::two_view::kernel::NormalizedSolver<libmv::fundamental::kernel::SevenPointSolver, libmv::UnnormalizerT>, libmv::fundamental::kernel::SampsonError, Eigen::Matrix<double, 3, 3, 0, 3, 3>>> const&, libmv::vector<int, Eigen::aligned_allocator<int>>*, double*, double) in libmultiview.a(robust_fundamental.cc.o)
      libmv::EuclideanResect(libmv::vector<libmv::Marker, Eigen::aligned_allocator<libmv::Marker>> const&, libmv::EuclideanReconstruction*, bool) in libsimple_pipeline.a(resect.cc.o)
      libmv::EuclideanIntersect(libmv::vector<libmv::Marker, Eigen::aligned_allocator<libmv::Marker>> const&, libmv::EuclideanReconstruction*) in libsimple_pipeline.a(intersect.cc.o)
      libmv::EstimateHomography2DFromCorrespondences(Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, Eigen::Matrix<double, -1, -1, 0, -1, -1> const&, libmv::EstimateHomographyOptions const&, Eigen::Matrix<double, 3, 3, 0, 3, 3>*) in libmultiview.a(homography.cc.o)
      ...
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[2]: *** [lib/libopencv_sfm.4.8.0.dylib] Error 1
make[1]: *** [modules/sfm/CMakeFiles/opencv_sfm.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_fluid_resize_test.cpp.o
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/motion_estimators.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_fluid_roi_test.cpp.o
[ 82%] Linking CXX executable ../../bin/example_tracking_goturnTracker
[ 82%] Built target example_tracking_goturnTracker
[ 82%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/src/tvl1flow.cpp.o
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/seam_finders.cpp.o
[ 82%] Building CXX object modules/optflow/CMakeFiles/opencv_optflow.dir/opencl_kernels_optflow.cpp.o
[ 82%] Linking CXX executable ../../bin/opencv_test_tracking
[ 82%] Built target opencv_test_tracking
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/stitcher.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_fluid_test.cpp.o
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/timelapsers.cpp.o
[ 82%] Linking CXX shared library ../../lib/libopencv_optflow.dylib
[ 82%] Built target opencv_optflow
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_fluid_test_kernels.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_frame_tests.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_gcompiled_tests.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_gcomputation_tests.cpp.o
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/util.cpp.o
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/warpers.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_gpu_test.cpp.o
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/warpers_cuda.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_graph_meta_tests.cpp.o
[ 82%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/opencl_kernels_stitching.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_kernel_tests.cpp.o
[ 82%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_opaque_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_plaidml_pipelines.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_planar_test.cpp.o
[ 83%] Linking CXX shared library ../../lib/libopencv_stitching.dylib
[ 83%] Built target opencv_stitching
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_sample_pipelines.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_scalar_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_smoke_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_transform_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_typed_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gapi_util_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gpu/gapi_core_tests_gpu.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gpu/gapi_imgproc_tests_gpu.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/gpu/gapi_operators_tests_gpu.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/infer/gapi_infer_ie_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/infer/gapi_infer_onnx_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/infer/gapi_infer_ov_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/infer/gapi_infer_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_backend_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_dynamic_graph.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_executor_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_garg_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_gmetaarg_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_gmodel_builder_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_island_fusion_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_island_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_pattern_matching_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_perform_substitution_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_proto_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_recompilation_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_int_vectorref_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/internal/gapi_transactions_test.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/oak/gapi_tests_oak.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/own/conc_queue_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/own/gapi_types_tests.cpp.o
[ 83%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/own/last_written_value_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/own/mat_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/own/scalar_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/render/ftp_render_test.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/render/gapi_render_tests_ocv.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/rmat/rmat_integration_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/rmat/rmat_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/rmat/rmat_view_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/s11n/gapi_s11n_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/s11n/gapi_sample_pipelines_s11n.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_gstreamer_pipeline_facade_int_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_gstreamersource_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_streaming_sync_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_streaming_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_streaming_utils_test.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_streaming_vpl_core_test.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_streaming_vpl_data_provider.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_streaming_vpl_device_selector.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/streaming/gapi_streaming_vpp_preproc_test.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/test_main.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/util/any_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/util/optional_tests.cpp.o
[ 84%] Building CXX object modules/gapi/CMakeFiles/opencv_test_gapi.dir/test/util/variant_tests.cpp.o
[ 84%] Linking CXX executable ../../bin/opencv_test_gapi
[ 84%] Built target opencv_test_gapi
make: *** [all] Error 2
```

### Steps to reproduce

as above

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-11 08:41:59,bug,Modify the outputVideoFormat after changing the output format in MSMF backend,"After changing the output format, need to modify the outputVideoFormat, otherwise the outputVideoFormat is always CV_CAP_MODE_BGR, and an error will occur when converting the format in retrieveVideoFrame(), and will always enter ""case CV_CAP_MODE_BGR:"" process.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-10 15:21:58,bug,fix refineDetectedMarkers,"Fixes #24127

To refine corners of ArUco markers we need to call matchImagePoints() from base class Board. The method matchImagePoints() implemented in Pimpl and we need to create temp Board object.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-09 10:48:52,bug,Fixed bug when MSMF webcamera doesn't start when build with VIDEOIO_PLUGIN_ALL,"Fixed #23937 and #23056
"
opencv/opencv,2023-08-08 11:29:40,bug,RefineDetectedMarkers fails if cameraMatrix is given as a param,"### System Information

OpenCV python version: 4.8.0
Operating System / Platform: Windows 10
Python version: 3.9.16

### Detailed description

`refineDetectedMarkers `method of `ArucoDetector `fails if optional `cameraMatrix `param is given. 

When running following line, 
```
corners, ids, rejected, _ = aruco_detector.refineDetectedMarkers(
    image=grayscale_image,
    board=charucoboard,
    detectedCorners=aruco_corners,
    detectedIds=aruco_ids,
    rejectedCorners=aruco_rejected,
    cameraMatrix=camera_matrix,
    distCoeffs=dist_coeffs,
)
```
An assertion error is raised: 
```
    corners, ids, rejected, _ = aruco_detector.refineDetectedMarkers(
cv2.error: OpenCV(4.8.0) D:\\bld\\libopencv_1690022693676\\work\\modules\\objdetect\\src\\aruco\\aruco_board.cpp:460: error: (-215:Assertion failed) (int)detectedCharucoVecMat[i].total() * detectedCharucoVecMat[i].channels() == 2 in function 'cv::aruco::CharucoBoardImpl::matchImagePoints'
```
No error is raised if no `cameraMatrix` is specified. 


### Steps to reproduce

```python 
import imageio.v3 as iio
import numpy as np
import cv2

grayscale_image = iio.imread( r""C:\\Users\\jnicks\\Documents\\repositories\\camera-characterization\\gray_scale_image.png"")
camera_matrix = np.array(
    [
        [1.08444638e03, 0.00000000e00, 6.99703945e02],
        [0.00000000e00, 1.08545749e03, 5.24978509e02],
        [0.00000000e00, 0.00000000e00, 1.00000000e00],
    ]
)
dist_coeffs = np.array([0.01183206, 0.01096358, 0.0, 0.0])

charucoboard = cv2.aruco.CharucoBoard(
    (11, 8),
    35,
    26,
    cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50),
)
charucoboard.setLegacyPattern(True)
aruco_detector = cv2.aruco.ArucoDetector(
    dictionary=charucoboard.getDictionary(), detectorParams=cv2.aruco.DetectorParameters()
)
aruco_corners, aruco_ids, aruco_rejected = aruco_detector.detectMarkers(image=grayscale_image)
# following line works
# corners, ids, rejected, _ = aruco_detector.refineDetectedMarkers(
#     image=grayscale_image,
#     board=charucoboard,
#     detectedCorners=aruco_corners,
#     detectedIds=aruco_ids,
#     rejectedCorners=aruco_rejected,
#     distCoeffs=dist_coeffs,
# )
# following line fails
corners, ids, rejected, _ = aruco_detector.refineDetectedMarkers(
    image=grayscale_image,
    board=charucoboard,
    detectedCorners=aruco_corners,
    detectedIds=aruco_ids,
    rejectedCorners=aruco_rejected,
    cameraMatrix=camera_matrix,
    distCoeffs=dist_coeffs,
)

```
Following image is used as input: ![gray_scale_image](https://github.com/opencv/opencv/assets/135614855/5b57639b-0e25-4003-b071-3cf83638f84e)


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-08 11:11:41,bug,Fix v_pack_store alignment issue on Windows 32-bit.,"Nightly build issue: https://pullrequest.opencv.org/buildbot/builders/5_x-win32-vc14/builds/100205
The issue introduced in: https://github.com/opencv/opencv/pull/23865

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-07 12:31:15,bug,Python sample code tst_scene_render.py not compatible with modern NumPy when using one image or no image,"### System Information

OpenCV python version: 4.8.0.74
Operating System / Platform: macOS 13.4.1
Python version: 3.11.4, NumPy 1.25

### Detailed description
samples.python/tst_scene_render.py is outdated and needs minor changes. 

1) np.int is deprecated since [NumPy 1.20 release](https://numpy.org/devdocs/release/1.20.0-notes.html#using-the-aliases-of-builtin-types-like-np-int-is-deprecated).

When getting next frame with no foreground image provided to the class, np.int is used to update a rectangle and gives error messages (NumPy>=1.20). 

in opencv/samples/python/tst_scene_render.py
 ```
class TestSceneRender():
    ...
    def getNextFrame(self):
        if self.foreground is not None:
            ...
        else:
            self.currentRect = ... + np.int(...)
```

#Error message 1:
```
Traceback (most recent call last):
  File ""/opencv/samples/python/tst_scene_render.py"", line 120, in <module>
    main()
  File ""/opencv/samples/python/tst_scene_render.py"", line 108, in main
    img = render.getNextFrame()
  File ""/opencv/samples/python/tst_scene_render.py"", line 88, in getNextFrame
    self.currentRect = self.initialRect + np.int( 30*cos(self.time*self.speed) + 50*sin(self.time*self.speed))
  File ""/usr/local/lib/python3.11/site-packages/numpy/__init__.py"", line 313, in __getattr__
    raise AttributeError(__former_attrs__[attr])
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'inf'?
```
Change np.int to int or np.int_ seems to be ok.

2) np.zeros takes take int or tuple of ints for shape parameter [(NumPy 1.25)](https://numpy.org/doc/stable/reference/generated/numpy.zeros.html#numpy.zeros).

When initializing the class with no background image, two ints are given for shape parameter of np.zeros and gives error messages (tested with NumPy 1.25)

in opencv/samples/python/tst_scene_render.py
 ```
class TestSceneRender():
    ...
    def __init__(... bgImg ...):
        if bgImg is not None:#
            ...
        else:
            self.sceneBg = np.zeros(defaultSize, defaultSize, np.uint8)
```
#NumPy reference
```
numpy.zeros(shape, dtype=float, ...)
    Parameters:
        shape: int or tuple of ints
```

#Error message 2:
```
Traceback (most recent call last):
  File ""/opencv/samples/python/tst_scene_render.py"", line 120, in <module>
    main()
  File ""/opencv/samples/python/tst_scene_render.py"", line 104, in main
    render = TestSceneRender(fgImg = fgr)
  File ""opencv/samples/python/tst_scene_render.py"", line 28, in __init__
    self.sceneBg = np.zeros(defaultSize, defaultSize, np.uint8)
TypeError: Cannot interpret '512' as a data type
```


### Steps to reproduce

Import TestSceneRender and prepare images (working directory: /opencv/samples/python/)

```
import cv2 as cv
from tst_scene_render import TestSceneRender

backGr = cv.imread(cv.samples.findFile('digits.png'))
fgr = cv.imread(cv.samples.findFile('board.jpg'))
```

Test with both foreground and background images (works fine)
```
render = TestSceneRender(bgImg = backGr, fgImg = fgr)
img = render.getNextFrame()
cv.imshow('img',img)
cv.waitKey(10000)
cv.destroyAllWindows()
```

Test with passing None to foreground image (#Error message 1)
```
render = TestSceneRender(bgImg = backGr, fgImg = None)
img = render.getNextFrame()
```

Test with passing None to ### background image (#Error message 2)
```
render = TestSceneRender(bgImg = None, fgImg = fgr)
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-04 19:58:46,bug,Solved bug in Reduce layer #24044,"### Pull Request Readiness Checklist

resolves https://github.com/opencv/opencv/issues/24044

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-03 10:13:10,bug,Invalid memory access fix for ONNX split layer parser #24076,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work https://github.com/opencv/opencv/issues/24076
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-02 13:00:10,bug,Port stereoRectify grid fix #24035,"Review and merge after https://github.com/opencv/opencv/pull/24084
Address #24035 in 5.x
Manual port of https://github.com/opencv/opencv/pull/24035

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-31 14:59:23,bug,VideoWriter resulting size one off error,"### System Information

OpenCV python version: 4.8.0.74
Operating System / Platform: Ubuntu 20.04
Python version: 3.8.10

### Detailed description

Saving an image of shape `960, 1699, 3` gives shape `960, 1698, 3` (1699 vs 1698).


### Steps to reproduce

```python
import numpy as np
import cv2
writer = cv2.VideoWriter('res%02d.png', cv2.VideoWriter_fourcc(*'MJPG'), 1, (1699, 960))
writer.write(np.zeros((960, 1699, 3), np.uint8))
writer.release()
print(cv2.imread('res01.png').shape)
```
The reproducer also prints `OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'image2 / image2 sequence'` after line `writer = cv2.VideoWriter('res%02d.png', cv2.VideoWriter_fourcc(*'MJPG'), 1, (1699, 960))`

Also reproducible for C++ (tested commit 1794cdc03c9505bb46f33a5cde5e210c1c7f65a4).

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-29 14:38:58,bug,Exception in ONNX::parseSplit ,"### System Information
```

General configuration for OpenCV 4.8.0-dev =====================================
  Version control:               4.8.0-113-g0323761ea6

  Extra modules:
    Location (extra):            C:/lib/opencv_contrib/modules
    Version control (extra):     4.8.0-12-gdaaf6451

  Platform:
    Timestamp:                   2023-07-29T12:25:25Z
    Host:                        Windows 10.0.22621 AMD64
    CMake:                       3.26.1
    CMake generator:             Visual Studio 17 2022
    CMake build tool:            C:/Program Files/Microsoft Visual Studio/2022/Community/MSBuild/Current/Bin/amd64/MSBuild.exe
    MSVC:                        1935
    Configuration:               Debug Release

  CPU/HW features:
    Baseline:                    SSE SSE2 SSE3
      requested:                 SSE3
    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX
      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
      SSE4_1 (18 files):         + SSSE3 SSE4_1
      SSE4_2 (2 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
      FP16 (1 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
      AVX (8 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX
      AVX2 (37 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
      AVX512_SKX (8 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX

  C/C++:
    Built as dynamic libs?:      YES
    C++ standard:                11
    C++ Compiler:                C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe  (ver 19.35.32215.0)
    C++ flags (Release):         /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MD /O2 /Ob2 /DNDEBUG
    C++ flags (Debug):           /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MDd /Zi /Ob0 /Od /RTC1
    C Compiler:                  C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe
    C flags (Release):           /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP   /MD /O2 /Ob2 /DNDEBUG
    C flags (Debug):             /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP /MDd /Zi /Ob0 /Od /RTC1
    Linker flags (Release):      /machine:x64  /INCREMENTAL:NO
    Linker flags (Debug):        /machine:x64  /debug /INCREMENTAL
    ccache:                      NO
    Precompiled headers:         YES
    Extra dependencies:          cudart_static.lib nppc.lib nppial.lib nppicc.lib nppidei.lib nppif.lib nppig.lib nppim.lib nppist.lib nppisu.lib nppitc.lib npps.lib cublas.lib cudnn.lib cufft.lib -LIBPATH:C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1/lib/x64
    3rdparty dependencies:

  OpenCV modules:
    To be built:                 alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform java line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab viz wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto
    Disabled:                    world
    Disabled by dependency:      -
    Unavailable:                 cvv freetype hdf julia matlab ovis python2
    Applications:                tests perf_tests examples apps
    Documentation:               doxygen python javadoc
    Non-free algorithms:         YES

  Windows RT support:            NO

  GUI:                           WIN32UI
    Win32 UI:                    YES
    OpenGL support:              YES (opengl32 glu32)
    VTK support:                 YES (ver 9.2.5)

  Media I/O:
    ZLib:                        optimized C:/install/zlib/lib/zlib.lib debug C:/install/zlib/lib/zlibd.lib (ver 1.2.13)    JPEG:                        build-libjpeg-turbo (ver 2.1.3-62)
      SIMD Support Request:      YES
      SIMD Support:              NO
    WEBP:                        build (ver encoder: 0x020f)
    PNG:                         optimized C:/install/libpng/lib/libpng16.lib debug C:/install/libpng/lib/libpng16d.lib (ver 1.6.40)
    TIFF:                        build (ver 42 - 4.2.0)
    JPEG 2000:                   build (ver 2.5.0)
    OpenEXR:                     build (ver 2.3.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:
    DC1394:                      NO
    FFMPEG:                      YES (prebuilt binaries)
      avcodec:                   YES (58.134.100)
      avformat:                  YES (58.76.100)
      avutil:                    YES (56.70.100)
      swscale:                   YES (5.9.100)
      avresample:                YES (4.0.0)
    GStreamer:                   NO
    DirectShow:                  YES
    Media Foundation:            YES
      DXVA:                      YES

  Parallel framework:            TBB (ver 2020.3 interface 11103)

  Other third-party libraries:
    Intel IPP:                   2021.8 [2021.8.0]
           at:                   C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/icv
    Intel IPP IW:                sources (2021.8.0)
              at:                C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/iw
    Lapack:                      NO
    OpenVINO:                    YES (2022.3.0)
    Eigen:                       YES (ver ..)
    Custom HAL:                  NO
    Protobuf:                    build (3.19.1)
    Flatbuffers:                 builtin/3rdparty (23.5.9)

  NVIDIA CUDA:                   YES (ver 12.1, CUFFT CUBLAS)
    NVIDIA GPU arch:             86
    NVIDIA PTX archs:

  cuDNN:                         YES (ver 8.8.0)

  OpenCL:                        YES (NVD3D11)
    Include path:                C:/lib/opencv/3rdparty/include/opencl/1.2
    Link libraries:              Dynamic load

  Python 3:
    Interpreter:                 C:/Program Files/Python310/python.exe (ver 3.10.10)
    Libraries:                   optimized C:/Program Files/Python310/libs/python310.lib debug C:/Program Files/Python310/libs/python310_d.lib (ver 3.10.10)
    numpy:                       C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/numpy/core/include (ver 1.23.5)
    install path:                C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/cv2/python-3.10

  Python (for build):            C:/Program Files/Python310/python.exe

  Java:
    ant:                         C:/apache-ant-1.10.13/bin/ant.bat (ver 1.10.13)
    Java:                        NO
    JNI:                         C:/Program Files/Java/jdk-17/include C:/Program Files/Java/jdk-17/include/win32 C:/Program Files/Java/jdk-17/include
    Java wrappers:               YES (ANT)
    Java tests:                  YES

  Install to:                    C:/install/opencv
-----------------------------------------------------------------
```





### Detailed description

Model is [here]( https://drive.google.com/drive/folders/110JBApuq0_37C0gTlMzqs9B3var2oCGY?usp=sharing) thanks to @fengyuentau

I can read this model in python or in C++ in release but not in Debug. Output is

```
Reading sam_vit_b.fixed.nopost.sim.onnx
[ INFO:0@3.872] global onnx_importer.cpp:835 cv::dnn::dnn4_v20230620::ONNXImporter::populateNet DNN/ONNX: loading ONNX v8 model produced by 'pytorch':2.0.0. Number of nodes = 313, initializers = 168, inputs = 5, outputs = 2
[ INFO:0@3.873] global onnx_importer.cpp:728 cv::dnn::dnn4_v20230620::ONNXImporter::parseOperatorSet DNN/ONNX: ONNX opset version = 17
[ INFO:0@3.950] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/Add) from domain='ai.onnx'
[ INFO:0@3.950] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Div]:(onnx_node!/Div) from domain='ai.onnx'
[ INFO:0@3.950] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul) from domain='ai.onnx'
[ INFO:0@3.951] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Sub]:(onnx_node!/Sub) from domain='ai.onnx'
[ INFO:0@3.951] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [MatMul]:(onnx_node!/MatMul) from domain='ai.onnx'
[ INFO:0@3.952] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_1) from domain='ai.onnx'
[ INFO:0@3.952] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sin]:(onnx_node!/Sin) from domain='ai.onnx'
[ INFO:0@3.952] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cos]:(onnx_node!/Cos) from domain='ai.onnx'
[ INFO:0@3.952] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Concat]:(onnx_node!/Concat) from domain='ai.onnx'
[ INFO:0@3.953] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Unsqueeze]:(onnx_node!/Unsqueeze) from domain='ai.onnx'
[ INFO:0@3.953] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Expand]:(onnx_node!/Expand) from domain='ai.onnx'
[ INFO:0@3.961] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Equal]:(onnx_node!/Equal) from domain='ai.onnx'
[ INFO:0@3.961] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Not]:(onnx_node!/Not) from domain='ai.onnx'
[ INFO:0@3.962] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/Cast) from domain='ai.onnx'
[ INFO:0@3.962] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_2) from domain='ai.onnx'
[ INFO:0@3.962] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Equal]:(onnx_node!/Equal_1) from domain='ai.onnx'
[ INFO:0@3.962] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/Cast_1) from domain='ai.onnx'
[ INFO:0@3.962] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_3) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/Add_1) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Equal]:(onnx_node!/Equal_2) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/Cast_2) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_4) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/Add_2) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Equal]:(onnx_node!/Equal_3) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/Cast_3) from domain='ai.onnx'
[ INFO:0@3.963] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_5) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/Add_3) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Equal]:(onnx_node!/Equal_4) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/Cast_4) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_6) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/Add_4) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Equal]:(onnx_node!/Equal_5) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/Cast_5) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_7) from domain='ai.onnx'
[ INFO:0@3.964] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/Add_5) from domain='ai.onnx'
[ INFO:0@3.965] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/mask_downscaling/mask_downscaling.0/Conv) from domain='ai.onnx'
[ INFO:0@3.965] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ReduceMean]:(onnx_node!/mask_downscaling/mask_downscaling.1/ReduceMean) from domain='ai.onnx'
[ INFO:0@3.965] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Sub]:(onnx_node!/mask_downscaling/mask_downscaling.1/Sub) from domain='ai.onnx'
[ INFO:0@3.965] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Pow]:(onnx_node!/mask_downscaling/mask_downscaling.1/Pow) from domain='ai.onnx'
[ INFO:0@3.965] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ReduceMean]:(onnx_node!/mask_downscaling/mask_downscaling.1/ReduceMean_1) from domain='ai.onnx'
[ INFO:0@3.965] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/mask_downscaling/mask_downscaling.1/Add) from domain='ai.onnx'
[ INFO:0@3.965] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sqrt]:(onnx_node!/mask_downscaling/mask_downscaling.1/Sqrt) from domain='ai.onnx'
[ INFO:0@3.966] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Div]:(onnx_node!/mask_downscaling/mask_downscaling.1/Div) from domain='ai.onnx'
[ INFO:0@3.966] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/mask_downscaling/mask_downscaling.1/Mul) from domain='ai.onnx'
[ INFO:0@3.966] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/mask_downscaling/mask_downscaling.1/Add_1) from domain='ai.onnx'
[ INFO:0@3.966] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Gelu]:(onnx_node!/mask_downscaling/mask_downscaling.2/Mul_1) from domain='ai.onnx'
[ INFO:0@3.966] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/mask_downscaling/mask_downscaling.3/Conv) from domain='ai.onnx'
[ INFO:0@3.966] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ReduceMean]:(onnx_node!/mask_downscaling/mask_downscaling.4/ReduceMean) from domain='ai.onnx'
[ INFO:0@3.967] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Sub]:(onnx_node!/mask_downscaling/mask_downscaling.4/Sub) from domain='ai.onnx'
[ INFO:0@3.967] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Pow]:(onnx_node!/mask_downscaling/mask_downscaling.4/Pow) from domain='ai.onnx'
[ INFO:0@3.967] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ReduceMean]:(onnx_node!/mask_downscaling/mask_downscaling.4/ReduceMean_1) from domain='ai.onnx'
[ INFO:0@3.967] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/mask_downscaling/mask_downscaling.4/Add) from domain='ai.onnx'
[ INFO:0@3.967] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sqrt]:(onnx_node!/mask_downscaling/mask_downscaling.4/Sqrt) from domain='ai.onnx'
[ INFO:0@3.967] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Div]:(onnx_node!/mask_downscaling/mask_downscaling.4/Div) from domain='ai.onnx'
[ INFO:0@3.967] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/mask_downscaling/mask_downscaling.4/Mul) from domain='ai.onnx'
[ INFO:0@3.968] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/mask_downscaling/mask_downscaling.4/Add_1) from domain='ai.onnx'
[ INFO:0@3.968] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Gelu]:(onnx_node!/mask_downscaling/mask_downscaling.5/Mul_1) from domain='ai.onnx'
[ INFO:0@3.968] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/mask_downscaling/mask_downscaling.6/Conv) from domain='ai.onnx'
[ INFO:0@3.968] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_8) from domain='ai.onnx'
[ INFO:0@3.968] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Sub]:(onnx_node!/Sub_1) from domain='ai.onnx'
[ INFO:0@3.968] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/Mul_9) from domain='ai.onnx'
[ INFO:0@3.969] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/Add_6) from domain='ai.onnx'
[ INFO:0@3.969] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Concat]:(onnx_node!/Concat_1) from domain='ai.onnx'
[ INFO:0@3.969] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Split]:(onnx_node!/Split_1) from domain='ai.onnx'
```
Exception is 
```
Program: C:\\install\\opencv\\x64\\vc17\\bin\\opencv_dnn480d.dll
File: C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.35.32215\\include\\vector
Line: 1949

Expression: vector subscript out of range
```

It's here
https://github.com/opencv/opencv/blob/0323761ea685e03b106bd7612a10756c7fbd6ef9/modules/dnn/src/onnx/onnx_importer.cpp#L1394

slicePoint size is 0 and hence there is no adress for slicePoints[0]
and stack strace is

```
opencv_dnn480d.dll!std::vector<int,std::allocator<int>>::operator[](const unsigned __int64 _Pos) Line 1948
	at C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.35.32215\\include\\vector(1948)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::ONNXImporter::parseSplit(cv::dnn::dnn4_v20230620::LayerParams & layerParams, const opencv_onnx::NodeProto & node_proto) Line 1394
	at C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp(1394)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::ONNXImporter::handleNode(const opencv_onnx::NodeProto & node_proto) Line 1029
	at C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp(1029)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::ONNXImporter::populateNet() Line 919
	at C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp(919)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::ONNXImporter::ONNXImporter(cv::dnn::dnn4_v20230620::Net & net, const char * onnxFile) Line 282
	at C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp(282)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::detail::readNet<cv::dnn::dnn4_v20230620::ONNXImporter,char const *>(const char * && <args_0>) Line 77
	at C:\\lib\\opencv\\modules\\dnn\\src\\dnn_common.hpp(77)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::detail::readNetDiagnostic<cv::dnn::dnn4_v20230620::ONNXImporter,char const *>(const char * && <args_0>) Line 84
	at C:\\lib\\opencv\\modules\\dnn\\src\\dnn_common.hpp(84)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::readNetFromONNX(const std::string & onnxFile) Line 4076
	at C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp(4076)
opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::readNet(const std::string & _model, const std::string & _config, const std::string & _framework) Line 54
	at C:\\lib\\opencv\\modules\\dnn\\src\\dnn_read.cpp(54)
```







### Steps to reproduce

In c++ and in debug : 
Net netMask = readNet( ""sam_vit_b.fixed.nopost.sim.onnx"");

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-26 16:30:13,bug,Doesnt use cuda for specific layer,"### System Information

OpenCV version: 4.8.0 (current 4.x branch) 
Windows
Compiler: msvc 2022

Running a onnx file (same as here: https://github.com/opencv/opencv/issues/22713 )
I noticed very high CPU usage (GPU also gets used but its bottlenecked by the CPU)
So we went and profiled with intel vtune

Turns out that most of the time is spent on opt_AVC2::fastGEMM1T 
is this op only available for CPU? why doesn't the full model run on GPU

![image](https://github.com/opencv/opencv/assets/77390911/c205b517-2245-44a9-ac37-43db567d0893)


Cuda runtime is enabled I can run many other models without issue on GPU 



### Detailed description

![image](https://github.com/opencv/opencv/assets/77390911/093051f4-13b9-4d24-b404-b9a14e050338)


### Steps to reproduce

Very basic just use net->forward with the model linked in the other issue (https://drive.google.com/file/d/1UHkudK8wjHoE9UM81x9H07nVRz_xjT9i/view?usp=sharing)

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-25 18:36:56,bug,Subtracting a tuple from an image gives `error: (-215:Assertion failed) type2 == CV_64F && (sz2.height == 1 || sz2.height == 4) in function 'cv::arithm_op'`,"### System Information

```
OpenCV python version: 4.8.0.74
Operating system: Windows 11 22H2
Python version: 3.10.11
```

### Detailed description

From what I understand of the [docs](https://docs.opencv.org/4.8.0/d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b), `cv2.subtract()` should be able to subtract a tuple from an array if it has the same width as the array has channels:
> Difference between an array and a scalar, when src2 is constructed from Scalar or has the same number of elements as src1.channels():

However, loading an image with `imread` and attempting to subtract a tuple gives
```
>>> cv2.subtract(mat, (10, 10, 10))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
cv2.error: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:652: error: (-215:Assertion failed) type2 == CV_64F && (sz2.height == 1 || sz2.height == 4) in function 'cv::arithm_op'
```
The same error occurs when trying to use a tuple of floats
```
>>> cv2.subtract(mat, (10.0, 10.0, 10.0))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
cv2.error: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:652: error: (-215:Assertion failed) type2 == CV_64F && (sz2.height == 1 || sz2.height == 4) in function 'cv::arithm_op'
```
and numpy arrays of various types
```
>>> cv2.subtract(mat, np.uint8([10, 10, 10]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
cv2.error: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:652: error: (-215:Assertion failed) type2 == CV_64F && (sz2.height == 1 || sz2.height == 4) in function 'cv::arithm_op'

>>> cv2.subtract(mat, np.array([10, 10, 10]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
cv2.error: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:652: error: (-215:Assertion failed) type2 == CV_64F && (sz2.height == 1 || sz2.height == 4) in function 'cv::arithm_op'

>>> cv2.subtract(mat, np.float64([10, 10, 10]))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
cv2.error: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:652: error: (-215:Assertion failed) type2 == CV_64F && (sz2.height == 1 || sz2.height == 4) in function 'cv::arithm_op'
```
Subtracting a number works,
```
>>> cv2.subtract(mat, 5)
array([[[103, 122, 116],
        [102, 122, 114],
        [106, 122, 114],
        ...,
```
as does subtracting the tuple using `numpy` (but that won't work in my case because `numpy` doesn't saturate the subtraction like OpenCV does).
```
>>> mat - (10, 20, 30)
array([[[ 98, 102,  86],
        [ 97, 102,  84],
        [101, 102,  84],
        ...,
```
The error message is also correct if I remove a channel from the tuple:
```
>>> cv2.subtract(mat, (10, 10))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
cv2.error: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:650: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'
```

### Steps to reproduce

```py
import cv2

mat = cv2.imread(""C:\\\\[...].png"")
print(cv2.subtract(mat, (10, 10, 10)))
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [x] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-24 16:27:52,bug,Test_TensorFlow_layers.tf2_prelu fails with OpenVINO CPU backend,"### System Information

OS: Linux x64
OpenVINO: 2023.0.1 (official docker image)
CI link: https://github.com/opencv/ci-gha-workflow/actions/runs/5646941329/job/15295960583?pr=109

### Detailed description

```
[ RUN      ] Test_TensorFlow_layers.tf2_prelu/0, where GetParam() = NGRAPH/CPU
unknown file: Failure
C++ exception with description ""OpenCV(4.8.0-dev) /home/openvino/opencv/modules/dnn/src/ie_ngraph.cpp:865: error: (-2:Unspecified error) in function 'initPlugin'
> Failed to initialize Inference Engine backend (device = CPU): Check 'false' failed at src/inference/src/core.cpp:114:
> Check 'PartialShape::broadcast_merge_into(tmpPShape, inShape, ::ngraph::op::AutoBroadcastType::NUMPY)' failed at src/common/snippets/src/op/subgraph.cpp:296:
> While validating node 'SnippetsOpset::Subgraph StatefulPartitionedCall/StatefulPartitionedCall/sequential/p_re_lu/add (Parameter_11102076[0]:f32[1,3,1,2], Parameter_11102077[0]:f32[6]) -> (f32[1,3,1,2])' with friendly_name 'StatefulPartitionedCall/StatefulPartitionedCall/sequential/p_re_lu/add':
> Failed to create broadcastable shapes in snippets canonicalization
> 
> "" thrown in the test body.
[  FAILED  ] Test_TensorFlow_layers.tf2_prelu/0, where GetParam() = NGRAPH/CPU (7 ms)
```

### Steps to reproduce

./bin/opencv_test_dnn --gtest_filter=Test_TensorFlow_layers.tf2_prelu*

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-21 12:31:24,bug,"fix compilation error on Windows ARM, use vaddq_f32 instead of +=","### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-21 09:25:14,bug,cv.cuda.GpuMat.convertTo failed to convert data types,"### System Information

// example for python user
OpenCV python version: 4.7.0
Operating System / Platform: Ubuntu 18.04
Python version: 3.7.16



### Detailed description
```
image = frame.convertTo(cv2.CV_32F)
```
```
cv2.error: OpenCV(4.7.0) /data/work/opencv-cuda-4.7.0/opencv-4.7.0/modules/core/src/matrix_wrap.cpp:342: error: (-213:The function/feature is not implemented) getGpuMat is available only for cuda::GpuMat and cuda::HostMem in function 'getGpuMat'
```
I use `cv2. Cudacodec. CreateVideoReader()` read the video streaming, Mat type for `<cv2.cuda.GpuMat 0x7f826b934a50>;`  The data type is `8UC4` and I tried to convert the data type to float32 but got an error

### Steps to reproduce

```
cap = cv2.cudacodec.createVideoReader(file_path)
ret, frame = cap.nextFrame()
image = frame.convertTo(cv2.CV_32F)
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-20 21:26:35,bug,Fix stereoRectify image boundaries.,"This should have been fixed with https://github.com/opencv/opencv/issues/23304

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-19 18:54:27,bug,feat: add cuda_Stream and cuda_GpuMat to simple types mapping,"This patch fixes usage of `cuda::Stream` in function arguments.

Affected modules: `cudacodec`: 
[`using namespace cuda`](https://github.com/opencv/opencv_contrib/blob/9dfe233020f669f17021dfc456fe77531e776b74/modules/cudacodec/include/opencv2/cudacodec.hpp#L62)  in public `cudacodec.hpp` header can be removed after merge of the patch.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-19 14:24:13,bug,fix: preserve NumPY writeable flag in output arguments,"Example error output:
```
OpenCV(4.8.0-dev) :-1: error: (-5:Bad argument) in function 'rectangle'
> Overload resolution failed:
>  - img marked as output argument, but provided NumPy array marked as readonly
>  - Expected Ptr<cv::UMat> for argument 'img'
>  - img marked as output argument, but provided NumPy array marked as readonly
>  - Expected Ptr<cv::UMat> for argument 'img'
```

resolves opencv/opencv-python#859

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-19 12:09:20,bug,Fix python typing stubs generation for CUDA modules,"resolves #23946
resolves #23945
resolves opencv/opencv-python#871

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-19 08:38:08,bug,Test_Caffe_nets.FasterRCNN_vgg16 fails with ENABLE_FAST_MATH option,"### System Information

OpenCV: current 4.x (4.8.0-dev)
Platform: Ubuntu 18.04, GCC 7.5
Hardware: Core i5 2500k (no avx2 and no avx512)

### Detailed description

Net inference accuracy issue is raised.

### Steps to reproduce

```
cmake -DENABLE_FAST_MATH=1 ../opencv
make -j4
./bin/opencv_test_dnn --gtest_filter=""Test_Caffe_nets.FasterRCNN_vgg16/*""
```

Log:
```
[ RUN      ] Test_Caffe_nets.FasterRCNN_vgg16/2, where GetParam() = OCV/CPU
Unmatched prediction: class 7 score 0.997029 box [235.421 x 83.0574 from (483.244, 92.7312)]
Highest IoU: 0.970777
/home/alexander/Projects/OpenCV/opencv-master/modules/dnn/test/test_common.impl.hpp:145: Failure
Value of: matched
  Actual: false
Expected: true
model name: VGG16_faster_rcnn_final.caffemodel
Unmatched prediction: class 12 score 0.993107 box [213.524 x 372.432 from (136.32, 189.653)]
Highest IoU: 0
/home/alexander/Projects/OpenCV/opencv-master/modules/dnn/test/test_common.impl.hpp:145: Failure
Value of: matched
  Actual: false
Expected: true
model name: VGG16_faster_rcnn_final.caffemodel
Unmatched prediction: class 2 score 0.948399 box [502.178 x 251.37 from (98.8219, 211.123)]
Highest IoU: 0
/home/alexander/Projects/OpenCV/opencv-master/modules/dnn/test/test_common.impl.hpp:145: Failure
Value of: matched
  Actual: false
Expected: true
model name: VGG16_faster_rcnn_final.caffemodel
Unmatched reference: class 2 score 0.949398 box [501.96 x 252.708 from (99.2454, 210.141)] IoU diff: 1
/home/alexander/Projects/OpenCV/opencv-master/modules/dnn/test/test_common.impl.hpp:157: Failure
Expected: (refScores[i]) <= (confThreshold), actual: 0.949398 vs 0.8
model name: VGG16_faster_rcnn_final.caffemodel
Unmatched reference: class 7 score 0.997022 box [240.844 x 83.6312 from (481.841, 92.3218)] IoU diff: 0.0292231
/home/alexander/Projects/OpenCV/opencv-master/modules/dnn/test/test_common.impl.hpp:157: Failure
Expected: (refScores[i]) <= (confThreshold), actual: 0.997022 vs 0.8
model name: VGG16_faster_rcnn_final.caffemodel
Unmatched reference: class 12 score 0.993028 box [217.773 x 373.789 from (133.221, 189.377)] IoU diff: 1
/home/alexander/Projects/OpenCV/opencv-master/modules/dnn/test/test_common.impl.hpp:157: Failure
Expected: (refScores[i]) <= (confThreshold), actual: 0.993028 vs 0.8
model name: VGG16_faster_rcnn_final.caffemodel
[  FAILED  ] Test_Caffe_nets.FasterRCNN_vgg16/2, where GetParam() = OCV/CPU (9083 ms)
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-17 17:40:51,bug,[TFLite] Pack layer and other fixes for SSD from Keras,"### Pull Request Readiness Checklist

resolves https://github.com/opencv/opencv/issues/23992

**Merge with extra**: https://github.com/opencv/opencv_extra/pull/1076

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-14 13:06:48,bug,It is not possible to redirect some error printed directly to cerr,"### System Information

Problem in source code at any platform
https://github.com/opencv/opencv/blob/4.x/modules/imgcodecs/src/loadsave.cpp#L440
and on other places


### Detailed description

The code uses direct print to std::cerr (e.g. https://github.com/opencv/opencv/blob/4.x/modules/imgcodecs/src/loadsave.cpp#L440)
Then it is not possible to redirect via `cv::redirectError`.

### Steps to reproduce

See code https://github.com/opencv/opencv/blob/4.x/modules/imgcodecs/src/loadsave.cpp#L440

### Issue submission checklist

- [X] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-13 06:07:30,bug,Opencv Build form source,"### System Information

OpenCV version: 4.8.0
Operating System / Platform: windows10
Compiler & compiler version: cmake+vs2022+x64
![image](https://github.com/opencv/opencv/assets/33416196/e7f288a7-b029-436b-9d95-d0ae85b0cc9a)
![image](https://github.com/opencv/opencv/assets/33416196/e0e2f030-1db7-45b2-b329-426fc997256b)
![image](https://github.com/opencv/opencv/assets/33416196/9c27a5b7-00e2-4afc-92c0-1a543a981b99)
![image](https://github.com/opencv/opencv/assets/33416196/1a94f9e5-7d40-4a65-a2c7-e23e74e155c6)
![image](https://github.com/opencv/opencv/assets/33416196/9b7787aa-0fed-4d8f-8413-c64e9ae86fae)








### Detailed description

```
Build started...
1>------ Build started: Project: opencv_world, Configuration: Release x64 ------
1>normalize_bbox_layer.cpp
1>region_layer.cpp
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): error C2666: 'operator >': 14 overloads have similar conversions (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.inl.hpp(2410,6): message : could be 'bool cv::operator >(const cv::MatConstIterator &,const cv::MatConstIterator &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(3724,20): message : or       'cv::MatExpr cv::operator >(double,const cv::Mat &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(3723,20): message : or       'cv::MatExpr cv::operator >(const cv::Mat &,double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(3722,20): message : or       'cv::MatExpr cv::operator >(const cv::Mat &,const cv::Mat &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_fp16.hpp(720,42): message : or       'bool operator >(const __half &,const __half &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_fp16.hpp(923,42): message : or       'bool operator >(const __half2 &,const __half2 &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_bf16.hpp(706,42): message : or       'bool operator >(const __nv_bfloat16 &,const __nv_bfloat16 &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_bf16.hpp(909,42): message : or       'bool operator >(const __nv_bfloat162 &,const __nv_bfloat162 &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(float, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(signed char, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(unsigned char, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(char, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(short, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(unsigned short, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(int, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(unsigned int, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(long, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(unsigned long, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(__int64, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(unsigned __int64, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : or       'built-in C++ operator>(bool, int)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(124,1): message : while trying to match the argument list '(T, int)'
1>        with
1>        [
1>            T=half
1>        ] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/region.hpp(98): message : while compiling class template member function 'void cv::dnn::cuda4dnn::RegionOp<half>::forward(const std::vector<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>,std::allocator<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>>> &,const std::vector<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>,std::allocator<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>>> &,cv::dnn::cuda4dnn::csl::Workspace &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../op_cuda.hpp(194): message : see reference to class template instantiation 'cv::dnn::cuda4dnn::RegionOp<half>' being compiled (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\region_layer.cpp(447): message : see reference to function template instantiation 'cv::Ptr<cv::dnn::dnn4_v20230620::BackendNode> cv::dnn::make_cuda_node<cv::dnn::cuda4dnn::RegionOp,cv::dnn::cuda4dnn::csl::Stream,_Ty&,cv::dnn::cuda4dnn::RegionConfiguration<float>&>(int,cv::dnn::cuda4dnn::csl::Stream &&,_Ty &,cv::dnn::cuda4dnn::RegionConfiguration<float> &)' being compiled
1>        with
1>        [
1>            _Ty=cv::Mat
1>        ]
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): error C2666: 'operator !=': 14 overloads have similar conversions (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/persistence.hpp(1332,17): message : could be 'bool cv::operator !=(const cv::FileNodeIterator &,const cv::FileNodeIterator &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.inl.hpp(2807,6): message : or       'bool cv::operator !=(const cv::SparseMatConstIterator &,const cv::SparseMatConstIterator &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.inl.hpp(2398,6): message : or       'bool cv::operator !=(const cv::MatConstIterator &,const cv::MatConstIterator &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(3708,20): message : or       'cv::MatExpr cv::operator !=(double,const cv::Mat &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(3707,20): message : or       'cv::MatExpr cv::operator !=(const cv::Mat &,double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(3706,20): message : or       'cv::MatExpr cv::operator !=(const cv::Mat &,const cv::Mat &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(583,1): message : or       'bool cv::operator !=(const cv::UMatData::MemoryFlag &,const int &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(266,1): message : or       'bool cv::operator !=(const cv::_InputArray::KindFlag &,const int &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/mat.hpp(66,1): message : or       'bool cv::operator !=(const cv::AccessFlag &,const int &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/types.hpp(2086,6): message : or       'bool cv::operator !=(const cv::Range &,const cv::Range &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1279,1): message : or       'cv::hal_baseline::v_int64x2 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int64x2 &,const cv::hal_baseline::v_int64x2 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1278,1): message : or       'cv::hal_baseline::v_uint64x2 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint64x2 &,const cv::hal_baseline::v_uint64x2 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1261,1): message : or       'cv::hal_baseline::v_float64x2 cv::hal_baseline::operator !=(const cv::hal_baseline::v_float64x2 &,const cv::hal_baseline::v_float64x2 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1260,1): message : or       'cv::hal_baseline::v_float32x4 cv::hal_baseline::operator !=(const cv::hal_baseline::v_float32x4 &,const cv::hal_baseline::v_float32x4 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1244,1): message : or       'cv::hal_baseline::v_int32x4 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int32x4 &,const cv::hal_baseline::v_int32x4 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1244,1): message : or       'cv::hal_baseline::v_uint32x4 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint32x4 &,const cv::hal_baseline::v_uint32x4 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1243,1): message : or       'cv::hal_baseline::v_int16x8 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int16x8 &,const cv::hal_baseline::v_int16x8 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1243,1): message : or       'cv::hal_baseline::v_uint16x8 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint16x8 &,const cv::hal_baseline::v_uint16x8 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1242,1): message : or       'cv::hal_baseline::v_int8x16 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int8x16 &,const cv::hal_baseline::v_int8x16 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1242,1): message : or       'cv::hal_baseline::v_uint8x16 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint8x16 &,const cv::hal_baseline::v_uint8x16 &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_fp16.hpp(714,42): message : or       'bool operator !=(const __half &,const __half &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_fp16.hpp(917,42): message : or       'bool operator !=(const __half2 &,const __half2 &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_bf16.hpp(700,42): message : or       'bool operator !=(const __nv_bfloat16 &,const __nv_bfloat16 &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_bf16.hpp(903,42): message : or       'bool operator !=(const __nv_bfloat162 &,const __nv_bfloat162 &)' [found using argument-dependent lookup] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(float, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(signed char, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(unsigned char, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(char, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(short, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(unsigned short, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(int, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(unsigned int, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(long, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(unsigned long, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(__int64, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(unsigned __int64, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : or       'built-in C++ operator!=(bool, double)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114,1): message : while trying to match the argument list '(T, double)'
1>        with
1>        [
1>            T=half
1>        ] (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(93): message : while compiling class template member function 'void cv::dnn::cuda4dnn::NormalizeOp<half>::forward(const std::vector<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>,std::allocator<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>>> &,const std::vector<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>,std::allocator<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>>> &,cv::dnn::cuda4dnn::csl::Workspace &)' (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\../op_cuda.hpp(194): message : see reference to class template instantiation 'cv::dnn::cuda4dnn::NormalizeOp<half>' being compiled (compiling source file D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp)
1>D:\\CppProject\\opencv-4.8.0\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp(332): message : see reference to function template instantiation 'cv::Ptr<cv::dnn::dnn4_v20230620::BackendNode> cv::dnn::make_cuda_node<cv::dnn::cuda4dnn::NormalizeOp,cv::dnn::cuda4dnn::csl::Stream,const cv::Mat&,cv::dnn::cuda4dnn::NormalizeConfiguration<float>&>(int,cv::dnn::cuda4dnn::csl::Stream &&,const cv::Mat &,cv::dnn::cuda4dnn::NormalizeConfiguration<float> &)' being compiled
1>Done building project ""opencv_world.vcxproj"" -- FAILED.
2>------ Build started: Project: opencv_waldboost_detector, Configuration: Release x64 ------
3>------ Build started: Project: opencv_visualisation, Configuration: Release x64 ------
4>------ Build started: Project: opencv_version_win32, Configuration: Release x64 ------
5>------ Build started: Project: opencv_version, Configuration: Release x64 ------
6>------ Build started: Project: opencv_model_diagnostics, Configuration: Release x64 ------
7>------ Build started: Project: opencv_interactive-calibration, Configuration: Release x64 ------
8>------ Build started: Project: opencv_img_hash, Configuration: Release x64 ------
9>------ Build started: Project: opencv_annotation, Configuration: Release x64 ------
10>------ Build started: Project: opencv_test_xphoto, Configuration: Release x64 ------
11>------ Build started: Project: opencv_test_ximgproc, Configuration: Release x64 ------
12>------ Build started: Project: opencv_test_xfeatures2d, Configuration: Release x64 ------
13>------ Build started: Project: opencv_test_wechat_qrcode, Configuration: Release x64 ------
14>------ Build started: Project: opencv_test_videostab, Configuration: Release x64 ------
15>------ Build started: Project: opencv_test_videoio, Configuration: Release x64 ------
16>------ Build started: Project: opencv_test_video, Configuration: Release x64 ------
17>------ Build started: Project: opencv_test_tracking, Configuration: Release x64 ------
18>------ Build started: Project: opencv_test_text, Configuration: Release x64 ------
8>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
8>Done building project ""opencv_img_hash.vcxproj"" -- FAILED.
6>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
6>Done building project ""opencv_model_diagnostics.vcxproj"" -- FAILED.
9>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
9>Done building project ""opencv_annotation.vcxproj"" -- FAILED.
4>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
4>Done building project ""opencv_version_win32.vcxproj"" -- FAILED.
7>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
7>Done building project ""opencv_interactive-calibration.vcxproj"" -- FAILED.
19>------ Build started: Project: opencv_test_superres, Configuration: Release x64 ------
20>------ Build started: Project: opencv_test_structured_light, Configuration: Release x64 ------
21>------ Build started: Project: opencv_test_stitching, Configuration: Release x64 ------
22>------ Build started: Project: opencv_test_img_hash, Configuration: Release x64 ------
2>LINK : fatal error LNK1181: cannot open input file '..\\..\\..\\..\\lib\\Release\\opencv_world480.lib'
2>Done building project ""opencv_waldboost_detector.vcxproj"" -- FAILED.
3>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
3>Done building project ""opencv_visualisation.vcxproj"" -- FAILED.
23>------ Build started: Project: opencv_test_stereo, Configuration: Release x64 ------
5>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
5>Done building project ""opencv_version.vcxproj"" -- FAILED.
24>------ Build started: Project: opencv_test_shape, Configuration: Release x64 ------
25>------ Build started: Project: opencv_test_saliency, Configuration: Release x64 ------
26>------ Build started: Project: opencv_test_rgbd, Configuration: Release x64 ------
27>------ Build started: Project: opencv_test_reg, Configuration: Release x64 ------
28>------ Build started: Project: opencv_test_rapid, Configuration: Release x64 ------
29>------ Build started: Project: opencv_test_quality, Configuration: Release x64 ------
20>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
13>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
18>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
14>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
19>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
20>Done building project ""opencv_test_structured_light.vcxproj"" -- FAILED.
13>Done building project ""opencv_test_wechat_qrcode.vcxproj"" -- FAILED.
30>------ Build started: Project: opencv_test_photo, Configuration: Release x64 ------
18>Done building project ""opencv_test_text.vcxproj"" -- FAILED.
19>Done building project ""opencv_test_superres.vcxproj"" -- FAILED.
14>Done building project ""opencv_test_videostab.vcxproj"" -- FAILED.
12>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
12>Done building project ""opencv_test_xfeatures2d.vcxproj"" -- FAILED.
31>------ Build started: Project: opencv_test_phase_unwrapping, Configuration: Release x64 ------
23>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
23>Done building project ""opencv_test_stereo.vcxproj"" -- FAILED.
32>------ Build started: Project: opencv_test_optflow, Configuration: Release x64 ------
11>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
11>Done building project ""opencv_test_ximgproc.vcxproj"" -- FAILED.
24>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
24>Done building project ""opencv_test_shape.vcxproj"" -- FAILED.
33>------ Build started: Project: opencv_test_objdetect, Configuration: Release x64 ------
25>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
25>Done building project ""opencv_test_saliency.vcxproj"" -- FAILED.
27>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
27>Done building project ""opencv_test_reg.vcxproj"" -- FAILED.
10>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
10>Done building project ""opencv_test_xphoto.vcxproj"" -- FAILED.
28>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
28>Done building project ""opencv_test_rapid.vcxproj"" -- FAILED.
21>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
21>Done building project ""opencv_test_stitching.vcxproj"" -- FAILED.
26>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
26>Done building project ""opencv_test_rgbd.vcxproj"" -- FAILED.
16>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
16>Done building project ""opencv_test_video.vcxproj"" -- FAILED.
34>------ Build started: Project: opencv_test_ml, Configuration: Release x64 ------
35>------ Build started: Project: opencv_test_mcc, Configuration: Release x64 ------
29>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
29>Done building project ""opencv_test_quality.vcxproj"" -- FAILED.
17>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
17>Done building project ""opencv_test_tracking.vcxproj"" -- FAILED.
36>------ Build started: Project: opencv_test_line_descriptor, Configuration: Release x64 ------
15>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
15>Done building project ""opencv_test_videoio.vcxproj"" -- FAILED.
30>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
30>Done building project ""opencv_test_photo.vcxproj"" -- FAILED.
37>------ Build started: Project: opencv_test_intensity_transform, Configuration: Release x64 ------
31>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
31>Done building project ""opencv_test_phase_unwrapping.vcxproj"" -- FAILED.
32>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
32>Done building project ""opencv_test_optflow.vcxproj"" -- FAILED.
38>------ Build started: Project: opencv_test_imgproc, Configuration: Release x64 ------
39>------ Build started: Project: opencv_test_imgcodecs, Configuration: Release x64 ------
40>------ Build started: Project: opencv_test_highgui, Configuration: Release x64 ------
33>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
33>Done building project ""opencv_test_objdetect.vcxproj"" -- FAILED.
41>------ Build started: Project: opencv_test_gapi, Configuration: Release x64 ------
42>------ Build started: Project: opencv_test_fuzzy, Configuration: Release x64 ------
22>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
22>Done building project ""opencv_test_img_hash.vcxproj"" -- FAILED.
43>------ Build started: Project: opencv_test_flann, Configuration: Release x64 ------
44>------ Build started: Project: opencv_test_features2d, Configuration: Release x64 ------
45>------ Build started: Project: opencv_test_face, Configuration: Release x64 ------
46>------ Build started: Project: opencv_test_dnn_superres, Configuration: Release x64 ------
47>------ Build started: Project: opencv_test_dnn, Configuration: Release x64 ------
48>------ Build started: Project: opencv_test_cudawarping, Configuration: Release x64 ------
35>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
35>Done building project ""opencv_test_mcc.vcxproj"" -- FAILED.
34>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
34>Done building project ""opencv_test_ml.vcxproj"" -- FAILED.
36>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
36>Done building project ""opencv_test_line_descriptor.vcxproj"" -- FAILED.
49>------ Build started: Project: opencv_test_cudastereo, Configuration: Release x64 ------
37>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
37>Done building project ""opencv_test_intensity_transform.vcxproj"" -- FAILED.
50>------ Build started: Project: opencv_test_cudaoptflow, Configuration: Release x64 ------
51>------ Build started: Project: opencv_test_cudaobjdetect, Configuration: Release x64 ------
40>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
40>Done building project ""opencv_test_highgui.vcxproj"" -- FAILED.
42>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
42>Done building project ""opencv_test_fuzzy.vcxproj"" -- FAILED.
39>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
39>Done building project ""opencv_test_imgcodecs.vcxproj"" -- FAILED.
52>------ Build started: Project: opencv_test_cudalegacy, Configuration: Release x64 ------
53>------ Build started: Project: opencv_test_cudaimgproc, Configuration: Release x64 ------
43>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
43>Done building project ""opencv_test_flann.vcxproj"" -- FAILED.
45>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
45>Done building project ""opencv_test_face.vcxproj"" -- FAILED.
46>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
46>Done building project ""opencv_test_dnn_superres.vcxproj"" -- FAILED.
48>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
48>Done building project ""opencv_test_cudawarping.vcxproj"" -- FAILED.
47>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
47>Done building project ""opencv_test_dnn.vcxproj"" -- FAILED.
54>------ Build started: Project: opencv_test_cudafilters, Configuration: Release x64 ------
55>------ Build started: Project: opencv_test_cudafeatures2d, Configuration: Release x64 ------
44>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
44>Done building project ""opencv_test_features2d.vcxproj"" -- FAILED.
56>------ Build started: Project: opencv_test_cudacodec, Configuration: Release x64 ------
57>------ Build started: Project: opencv_test_cudabgsegm, Configuration: Release x64 ------
49>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
49>Done building project ""opencv_test_cudastereo.vcxproj"" -- FAILED.
50>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
50>Done building project ""opencv_test_cudaoptflow.vcxproj"" -- FAILED.
58>------ Build started: Project: opencv_test_cudaarithm, Configuration: Release x64 ------
51>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
51>Done building project ""opencv_test_cudaobjdetect.vcxproj"" -- FAILED.
59>------ Build started: Project: opencv_test_core, Configuration: Release x64 ------
60>------ Build started: Project: opencv_test_calib3d, Configuration: Release x64 ------
61>------ Build started: Project: opencv_test_bioinspired, Configuration: Release x64 ------
38>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
38>Done building project ""opencv_test_imgproc.vcxproj"" -- FAILED.
62>------ Build started: Project: opencv_test_bgsegm, Configuration: Release x64 ------
53>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
53>Done building project ""opencv_test_cudaimgproc.vcxproj"" -- FAILED.
63>------ Build started: Project: opencv_test_aruco, Configuration: Release x64 ------
64>------ Build started: Project: opencv_perf_xphoto, Configuration: Release x64 ------
65>------ Build started: Project: opencv_perf_ximgproc, Configuration: Release x64 ------
54>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
54>Done building project ""opencv_test_cudafilters.vcxproj"" -- FAILED.
41>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
41>Done building project ""opencv_test_gapi.vcxproj"" -- FAILED.
55>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
55>Done building project ""opencv_test_cudafeatures2d.vcxproj"" -- FAILED.
66>------ Build started: Project: opencv_perf_xfeatures2d, Configuration: Release x64 ------
52>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
52>Done building project ""opencv_test_cudalegacy.vcxproj"" -- FAILED.
67>------ Build started: Project: opencv_perf_wechat_qrcode, Configuration: Release x64 ------
57>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
57>Done building project ""opencv_test_cudabgsegm.vcxproj"" -- FAILED.
56>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
56>Done building project ""opencv_test_cudacodec.vcxproj"" -- FAILED.
68>------ Build started: Project: opencv_perf_videoio, Configuration: Release x64 ------
69>------ Build started: Project: opencv_perf_video, Configuration: Release x64 ------
70>------ Build started: Project: opencv_perf_tracking, Configuration: Release x64 ------
58>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
58>Done building project ""opencv_test_cudaarithm.vcxproj"" -- FAILED.
71>------ Build started: Project: opencv_perf_superres, Configuration: Release x64 ------
62>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
62>Done building project ""opencv_test_bgsegm.vcxproj"" -- FAILED.
72>------ Build started: Project: opencv_perf_stitching, Configuration: Release x64 ------
73>------ Build started: Project: opencv_perf_stereo, Configuration: Release x64 ------
61>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
61>Done building project ""opencv_test_bioinspired.vcxproj"" -- FAILED.
74>------ Build started: Project: opencv_perf_rgbd, Configuration: Release x64 ------
64>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
64>Done building project ""opencv_perf_xphoto.vcxproj"" -- FAILED.
75>------ Build started: Project: opencv_perf_reg, Configuration: Release x64 ------
63>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
63>Done building project ""opencv_test_aruco.vcxproj"" -- FAILED.
60>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
60>Done building project ""opencv_test_calib3d.vcxproj"" -- FAILED.
65>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
65>Done building project ""opencv_perf_ximgproc.vcxproj"" -- FAILED.
67>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
67>Done building project ""opencv_perf_wechat_qrcode.vcxproj"" -- FAILED.
68>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
68>Done building project ""opencv_perf_videoio.vcxproj"" -- FAILED.
76>------ Build started: Project: opencv_perf_photo, Configuration: Release x64 ------
77>------ Build started: Project: opencv_perf_optflow, Configuration: Release x64 ------
66>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
66>Done building project ""opencv_perf_xfeatures2d.vcxproj"" -- FAILED.
70>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
70>Done building project ""opencv_perf_tracking.vcxproj"" -- FAILED.
78>------ Build started: Project: opencv_perf_objdetect, Configuration: Release x64 ------
79>------ Build started: Project: opencv_perf_line_descriptor, Configuration: Release x64 ------
69>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
69>Done building project ""opencv_perf_video.vcxproj"" -- FAILED.
71>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
71>Done building project ""opencv_perf_superres.vcxproj"" -- FAILED.
80>------ Build started: Project: opencv_perf_imgproc, Configuration: Release x64 ------
73>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
73>Done building project ""opencv_perf_stereo.vcxproj"" -- FAILED.
72>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
72>Done building project ""opencv_perf_stitching.vcxproj"" -- FAILED.
74>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
74>Done building project ""opencv_perf_rgbd.vcxproj"" -- FAILED.
81>------ Build started: Project: opencv_perf_imgcodecs, Configuration: Release x64 ------
82>------ Build started: Project: opencv_perf_gapi, Configuration: Release x64 ------
83>------ Build started: Project: opencv_perf_features2d, Configuration: Release x64 ------
75>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
75>Done building project ""opencv_perf_reg.vcxproj"" -- FAILED.
84>------ Build started: Project: opencv_perf_dnn_superres, Configuration: Release x64 ------
85>------ Build started: Project: opencv_perf_dnn, Configuration: Release x64 ------
77>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
77>Done building project ""opencv_perf_optflow.vcxproj"" -- FAILED.
76>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
76>Done building project ""opencv_perf_photo.vcxproj"" -- FAILED.
86>------ Build started: Project: opencv_perf_cudawarping, Configuration: Release x64 ------
87>------ Build started: Project: opencv_perf_cudastereo, Configuration: Release x64 ------
59>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
59>Done building project ""opencv_test_core.vcxproj"" -- FAILED.
88>------ Build started: Project: opencv_perf_cudaoptflow, Configuration: Release x64 ------
89>------ Build started: Project: opencv_perf_cudaobjdetect, Configuration: Release x64 ------
79>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
79>Done building project ""opencv_perf_line_descriptor.vcxproj"" -- FAILED.
78>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
78>Done building project ""opencv_perf_objdetect.vcxproj"" -- FAILED.
90>------ Build started: Project: opencv_perf_cudalegacy, Configuration: Release x64 ------
81>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
81>Done building project ""opencv_perf_imgcodecs.vcxproj"" -- FAILED.
82>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
82>Done building project ""opencv_perf_gapi.vcxproj"" -- FAILED.
91>------ Build started: Project: opencv_perf_cudaimgproc, Configuration: Release x64 ------
84>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
84>Done building project ""opencv_perf_dnn_superres.vcxproj"" -- FAILED.
83>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
83>Done building project ""opencv_perf_features2d.vcxproj"" -- FAILED.
85>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
85>Done building project ""opencv_perf_dnn.vcxproj"" -- FAILED.
92>------ Build started: Project: opencv_perf_cudafilters, Configuration: Release x64 ------
93>------ Build started: Project: opencv_perf_cudafeatures2d, Configuration: Release x64 ------
86>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
86>Done building project ""opencv_perf_cudawarping.vcxproj"" -- FAILED.
87>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
87>Done building project ""opencv_perf_cudastereo.vcxproj"" -- FAILED.
94>------ Build started: Project: opencv_perf_cudacodec, Configuration: Release x64 ------
89>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
89>Done building project ""opencv_perf_cudaobjdetect.vcxproj"" -- FAILED.
95>------ Build started: Project: opencv_perf_cudabgsegm, Configuration: Release x64 ------
80>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
80>Done building project ""opencv_perf_imgproc.vcxproj"" -- FAILED.
96>------ Build started: Project: opencv_perf_cudaarithm, Configuration: Release x64 ------
97>------ Build started: Project: opencv_perf_core, Configuration: Release x64 ------
90>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
90>Done building project ""opencv_perf_cudalegacy.vcxproj"" -- FAILED.
98>------ Build started: Project: opencv_perf_calib3d, Configuration: Release x64 ------
99>------ Build started: Project: opencv_perf_bioinspired, Configuration: Release x64 ------
100>------ Build started: Project: opencv_perf_aruco, Configuration: Release x64 ------
91>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
91>Done building project ""opencv_perf_cudaimgproc.vcxproj"" -- FAILED.
92>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
92>Done building project ""opencv_perf_cudafilters.vcxproj"" -- FAILED.
93>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
93>Done building project ""opencv_perf_cudafeatures2d.vcxproj"" -- FAILED.
94>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
94>Done building project ""opencv_perf_cudacodec.vcxproj"" -- FAILED.
95>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
95>Done building project ""opencv_perf_cudabgsegm.vcxproj"" -- FAILED.
96>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
96>Done building project ""opencv_perf_cudaarithm.vcxproj"" -- FAILED.
100>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
100>Done building project ""opencv_perf_aruco.vcxproj"" -- FAILED.
99>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
99>Done building project ""opencv_perf_bioinspired.vcxproj"" -- FAILED.
98>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
98>Done building project ""opencv_perf_calib3d.vcxproj"" -- FAILED.
97>LINK : fatal error LNK1181: cannot open input file '..\\..\\lib\\Release\\opencv_world480.lib'
97>Done building project ""opencv_perf_core.vcxproj"" -- FAILED.
========== Build: 0 succeeded, 100 failed, 31 up-to-date, 0 skipped ==========
========== Build started at 2:07 PM and took 04.251 seconds ==========
```

### Steps to reproduce

![image](https://github.com/opencv/opencv/assets/33416196/48b4a3f3-8899-4697-82b6-e33a03321276)
![image](https://github.com/opencv/opencv/assets/33416196/12f3c6fc-a3cd-4f30-95da-8d7322af8d1a)

![image](https://github.com/opencv/opencv/assets/33416196/f399be89-2e31-4931-8842-9dbd34f9d634)




### Issue submission checklist

- [X] I report the issue, it's not a question
- [x] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-12 13:51:13,bug,C++ version of OpenCV 4.8.0 returns wrong matrix size for ONNX model,"### System Information

OpenCV 4.8.0
Operating System: CentOS 
Compiler: GCC11

opencv-python-rolling-4.8.0.20230624
Windows 10

### Detailed description

I am loading the same model with OpenCV Python ok, but get the wrong matrix size for the inference result in the compiled C++ version. Netron confirms the output nodes to be 1170 and 1179 with sizes 1x8400x5 and 1x8400x4. The Python version of OpenCV does return this matrix size, while the C++ version returns [8400 x 1] depth 5 channels() 1 type() 5.

The compile machine is offline and I provided the correct version of ADE by hand.

Other DNN models load and work fine.

Find the model here: https://drive.google.com/file/d/1pvp9WceSrJAREsJ6sEev-cPmHHdr7Cll/view?usp=drive_link

### Steps to reproduce

Compile OpenCV 4.8 offline using the following configuartion:
```
cmake3 -DCMAKE_BUILD_TYPE=Debug -DCMAKE_INSTALL_PREFIX=/build/uk/Frameworks/opencv-4.8.0-ov-AVX2-default-debug-install VERBOSE=1 -DOPENCV_EXTRA_MODULES_PATH=~/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/ -DCPU_BASELINE=AVX2 -DENABLE_OMIT_FRAME_POINTER=OFF -DBUILD_TESTS=OFF -DBUILD_PERF_TESTS=OFF -DBUILD_EXAMPLES=OFF -DBUILD_opencv_apps=OFF  ~/local/Frameworks/opencv/4.8.0_trial/source/lib
-- ocv_init_download: OpenCV source tree is not fetched as git repository. 3rdparty resources will be downloaded from github.com by default.
-- Detected processor: x86_64
Python 2.7.5
-- Looking for ccache - not found
Cleaning INTERNAL cached variable: ZLIB_LIBRARY
Cleaning INTERNAL cached variable: ZLIB_INCLUDE_DIR
-- Could NOT find ZLIB (missing: ZLIB_LIBRARY ZLIB_INCLUDE_DIR) (Required is at least version ""1.2.3"")
Cleaning INTERNAL cached variable: JPEG_LIBRARY
Cleaning INTERNAL cached variable: JPEG_INCLUDE_DIR
-- Could NOT find JPEG (missing: JPEG_LIBRARY JPEG_INCLUDE_DIR)
-- libjpeg-turbo: VERSION = 2.1.3, BUILD = opencv-4.8.0-libjpeg-turbo-debug
Cleaning INTERNAL cached variable: TIFF_LIBRARY
Cleaning INTERNAL cached variable: TIFF_INCLUDE_DIR
-- Could NOT find TIFF (missing: TIFF_LIBRARY TIFF_INCLUDE_DIR)
Cleaning INTERNAL cached variable: WEBP_LIBRARY
Cleaning INTERNAL cached variable: WEBP_INCLUDE_DIR
-- Could NOT find OpenJPEG (minimal suitable version: 2.0, recommended version >= 2.3.1). OpenJPEG will be built from sources
-- OpenJPEG: VERSION = 2.5.0, BUILD = opencv-4.8.0-openjp2-2.5.0-debug
-- OpenJPEG libraries will be built from sources: libopenjp2 (version ""2.5.0"")
Cleaning INTERNAL cached variable: PNG_LIBRARY
Cleaning INTERNAL cached variable: PNG_INCLUDE_DIR
-- Could NOT find PNG (missing: PNG_LIBRARY PNG_PNG_INCLUDE_DIR)
-- IPPICV: Downloading ippicv_2021.8_lnx_intel64_20230330_general.tgz from https://raw.githubusercontent.com/opencv/opencv_3rdparty/1224f78da6684df04397ac0f40c961ed37f79ccb/ippicv/ippicv_2021.8_lnx_intel64_20230330_general.tgz
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at cmake/OpenCVDownload.cmake:248 (message):
  IPPICV: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  3rdparty/ippicv/ippicv.cmake:37 (ocv_download)
  cmake/OpenCVFindIPP.cmake:259 (download_ippicv)
  cmake/OpenCVFindLibsPerf.cmake:12 (include)
  CMakeLists.txt:756 (include)


-- Could not find OpenBLAS include. Turning OpenBLAS_FOUND off
-- Could not find OpenBLAS lib. Turning OpenBLAS_FOUND off
-- Could NOT find Atlas (missing: Atlas_CBLAS_INCLUDE_DIR Atlas_CLAPACK_INCLUDE_DIR Atlas_CBLAS_LIBRARY Atlas_BLAS_LIBRARY Atlas_LAPACK_LIBRARY)
-- Could NOT find BLAS (missing: BLAS_LIBRARIES)
-- LAPACK requires BLAS
-- A library with LAPACK API not found. Please specify library location.
-- Could NOT find Java (missing: Java_JAR_EXECUTABLE Java_JAVAC_EXECUTABLE Java_JAVAH_EXECUTABLE Java_JAVADOC_EXECUTABLE) (found version ""1.8.0_372"")
-- Could NOT find JNI (missing: JAVA_INCLUDE_PATH JAVA_INCLUDE_PATH2 JAVA_AWT_INCLUDE_PATH)
-- VTK is not found. Please set -DVTK_DIR in CMake to VTK build directory, or to VTK install subdirectory with VTKConfig.cmake file
-- Checking for module 'gtk+-3.0'
--   No package 'gtk+-3.0' found
-- Checking for module 'gtk+-2.0'
--   No package 'gtk+-2.0' found
-- Checking for module 'gthread-2.0>=2.32'
--   No package 'gthread-2.0' found
-- Checking for modules 'libavcodec;libavformat;libavutil;libswscale'
--   No package 'libavcodec' found
--   No package 'libavformat' found
--   No package 'libavutil' found
--   No package 'libswscale' found
-- FFMPEG is disabled. Required libraries: libavcodec;libavformat;libavutil;libswscale. Missing libraries: libavcodec;libavformat;libavutil;libswscale
-- Checking for module 'gstreamer-base-1.0'
--   No package 'gstreamer-base-1.0' found
-- Checking for module 'gstreamer-app-1.0'
--   No package 'gstreamer-app-1.0' found
-- Checking for module 'gstreamer-riff-1.0'
--   No package 'gstreamer-riff-1.0' found
-- Checking for module 'gstreamer-pbutils-1.0'
--   No package 'gstreamer-pbutils-1.0' found
-- Checking for module 'gstreamer-video-1.0'
--   No package 'gstreamer-video-1.0' found
-- Checking for module 'gstreamer-audio-1.0'
--   No package 'gstreamer-audio-1.0' found
-- Checking for module 'libdc1394-2'
--   No package 'libdc1394-2' found
-- Module opencv_alphamat disabled because the following dependencies are not found: Eigen
-- Checking for module 'freetype2'
--   No package 'freetype2' found
-- Checking for module 'harfbuzz'
--   No package 'harfbuzz' found
-- freetype2:   NO
-- harfbuzz:    NO
-- Could NOT find HDF5 (missing: HDF5_LIBRARIES HDF5_INCLUDE_DIRS) (found version """")
-- Julia not found. Not compiling Julia Bindings.
-- Module opencv_ovis disabled because OGRE3D was not found
-- No preference for use of exported gflags CMake configuration set, and no hints for include/library directories provided. Defaulting to preferring an installed/exported gflags CMake configuration if available.
-- Failed to find installed gflags CMake configuration, searching for gflags build directories exported with CMake.
-- Failed to find gflags - Failed to find an installed/exported CMake configuration for gflags, will perform search for installed gflags components.
-- Failed to find gflags - Could not find gflags include directory, set GFLAGS_INCLUDE_DIR to directory containing gflags/gflags.h
-- Failed to find glog - Could not find glog include directory, set GLOG_INCLUDE_DIR to directory containing glog/logging.h
-- Module opencv_sfm disabled because the following dependencies are not found: Eigen Glog/Gflags
-- Checking for module 'tesseract'
--   No package 'tesseract' found
-- Tesseract:   NO
-- Allocator metrics storage type: 'long long'
-- Excluding from source files list: modules/imgproc/src/imgwarp.lasx.cpp
-- Excluding from source files list: modules/imgproc/src/resize.lasx.cpp
-- Registering hook 'INIT_MODULE_SOURCES_opencv_dnn': /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/modules/dnn/cmake/hooks/INIT_MODULE_SOURCES_opencv_dnn.cmake
-- opencv_dnn: filter out cuda4dnn source code
-- Excluding from source files list: <BUILD>/modules/dnn/layers/layers_common.rvv.cpp
-- Excluding from source files list: <BUILD>/modules/dnn/layers/layers_common.lasx.cpp
-- Excluding from source files list: <BUILD>/modules/dnn/int8layers/layers_common.lasx.cpp
-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/conv_depthwise.rvv.cpp
-- Excluding from source files list: <BUILD>/modules/dnn/layers/cpu_kernels/conv_depthwise.lasx.cpp
-- imgcodecs: OpenEXR codec is disabled in runtime. Details: https://github.com/opencv/opencv/issues/21326
-- highgui: using builtin backend: NONE
-- rgbd: Eigen support is disabled. Eigen is Required for Posegraph optimization
-- wechat_qrcode: Downloading detect.caffemodel from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/detect.caffemodel
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  wechat_qrcode: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:26 (ocv_download)


CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:37 (message):
  WeChatQRCode: Can't get detect caffemodel file for wechat qrcode.


-- wechat_qrcode: Downloading detect.prototxt from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/detect.prototxt
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  wechat_qrcode: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:26 (ocv_download)


CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:37 (message):
  WeChatQRCode: Can't get detect prototxt file for wechat qrcode.


-- wechat_qrcode: Downloading sr.caffemodel from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/sr.caffemodel
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  wechat_qrcode: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:26 (ocv_download)


CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:37 (message):
  WeChatQRCode: Can't get sr caffemodel file for wechat qrcode.


-- wechat_qrcode: Downloading sr.prototxt from https://raw.githubusercontent.com/WeChatCV/opencv_3rdparty/a8b69ccc738421293254aec5ddb38bd523503252/sr.prototxt
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  wechat_qrcode: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:26 (ocv_download)


CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/wechat_qrcode/CMakeLists.txt:37 (message):
  WeChatQRCode: Can't get sr prototxt file for wechat qrcode.


-- xfeatures2d/boostdesc: Downloading boostdesc_bgm.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/boostdesc: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_boostdesc.cmake:22 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:12 (download_boost_descriptors)


-- xfeatures2d/boostdesc: Downloading boostdesc_bgm_bi.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm_bi.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/boostdesc: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_boostdesc.cmake:22 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:12 (download_boost_descriptors)


-- xfeatures2d/boostdesc: Downloading boostdesc_bgm_hd.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_bgm_hd.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/boostdesc: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_boostdesc.cmake:22 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:12 (download_boost_descriptors)


-- xfeatures2d/boostdesc: Downloading boostdesc_binboost_064.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_064.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/boostdesc: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_boostdesc.cmake:22 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:12 (download_boost_descriptors)


-- xfeatures2d/boostdesc: Downloading boostdesc_binboost_128.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_128.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/boostdesc: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_boostdesc.cmake:22 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:12 (download_boost_descriptors)


-- xfeatures2d/boostdesc: Downloading boostdesc_binboost_256.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_binboost_256.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/boostdesc: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_boostdesc.cmake:22 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:12 (download_boost_descriptors)


-- xfeatures2d/boostdesc: Downloading boostdesc_lbgm.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/34e4206aef44d50e6bbcd0ab06354b52e7466d26/boostdesc_lbgm.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/boostdesc: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_boostdesc.cmake:22 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:12 (download_boost_descriptors)


-- xfeatures2d/vgg: Downloading vgg_generated_48.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_48.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/vgg: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_vgg.cmake:16 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:13 (download_vgg_descriptors)


-- xfeatures2d/vgg: Downloading vgg_generated_64.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_64.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/vgg: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_vgg.cmake:16 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:13 (download_vgg_descriptors)


-- xfeatures2d/vgg: Downloading vgg_generated_80.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_80.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/vgg: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_vgg.cmake:16 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:13 (download_vgg_descriptors)


-- xfeatures2d/vgg: Downloading vgg_generated_120.i from https://raw.githubusercontent.com/opencv/opencv_3rdparty/fccf7cd6a4b12079f73bbfb21745f9babcd4eb1d/vgg_generated_120.i
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  xfeatures2d/vgg: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/cmake/download_vgg.cmake:16 (ocv_download)
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:13 (download_vgg_descriptors)


CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:17 (message):
  features2d: Boost descriptor implementation is not available due to missing
  data (download failed:
  https://github.com/opencv/opencv_contrib/issues/1301)


CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/xfeatures2d/CMakeLists.txt:22 (message):
  features2d: VGG descriptor implementation is not available due to missing
  data (download failed:
  https://github.com/opencv/opencv_contrib/issues/1301)


-- data: Downloading face_landmark_model.dat from https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat
-- Try 1 failed
--
=======================================================================
  Couldn't download files from the Internet.
  Please check the Internet access on this host.
=======================================================================

CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/cmake/OpenCVDownload.cmake:248 (message):
  data: Download failed: 6;""Couldn't resolve host name""

  For details please refer to the download log file:


  /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug/CMakeDownloadLog.txt


Call Stack (most recent call first):
  /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/face/CMakeLists.txt:13 (ocv_download)


CMake Warning at /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules/face/CMakeLists.txt:26 (message):
  Face: Can't get model file for face alignment.


-- Found 'misc' Python modules from /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/modules/python/package/extra_modules
-- Found 'mat_wrapper;utils' Python modules from /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/modules/core/misc/python/package
-- Found 'gapi' Python modules from /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/modules/gapi/misc/python/package
--
-- General configuration for OpenCV 4.8.0 =====================================
--   Version control:               unknown
--
--   Extra modules:
--     Location (extra):            /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/contrib/modules
--     Version control (extra):     unknown
--
--   Platform:
--     Timestamp:                   2023-07-12T11:50:51Z
--     Host:                        Linux 5.4.248-1.el7.elrepo.x86_64 x86_64
--     CMake:                       3.17.5
--     CMake generator:             Unix Makefiles
--     CMake build tool:            /usr/bin/gmake
--     Configuration:               Debug
--
--   CPU/HW features:
--     Baseline:                    SSE SSE2 SSE3 SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
--       requested:                 AVX2
--     Dispatched code generation:  AVX512_SKX
--       requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
--       AVX512_SKX (5 files):      + AVX_512F AVX512_COMMON AVX512_SKX
--
--   C/C++:
--     Built as dynamic libs?:      YES
--     C++ standard:                11
--     C++ Compiler:                /ovde_plugins/gcc11/linux/bin/g++  (ver 11.3.0)
--     C++ flags (Release):         -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mf16c -mfma -mavx -mavx2 -fvisibility=hidden -fvisibility-inlines-hidden -O2 -DNDEBUG  -DNDEBUG
--     C++ flags (Debug):           -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mf16c -mfma -mavx -mavx2 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG
--     C Compiler:                  /ovde_plugins/gcc11/linux/bin/gcc
--     C flags (Release):           -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mf16c -mfma -mavx -mavx2 -fvisibility=hidden -O2 -DNDEBUG  -DNDEBUG
--     C flags (Debug):             -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mf16c -mfma -mavx -mavx2 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG
--     Linker flags (Release):      -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined
--     Linker flags (Debug):        -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined
--     ccache:                      NO
--     Precompiled headers:         NO
--     Extra dependencies:          dl m pthread rt
--     3rdparty dependencies:
--
--   OpenCV modules:
--     To be built:                 aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto
--     Disabled:                    world
--     Disabled by dependency:      -
--     Unavailable:                 alphamat cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv freetype hdf java julia matlab ovis python2 python3 sfm ts viz
--     Applications:                -
--     Documentation:               NO
--     Non-free algorithms:         NO
--
--   GUI:                           NONE
--     GTK+:                        NO
--     VTK support:                 NO
--
--   Media I/O:
--     ZLib:                        zlib (ver 1.2.13)
--     JPEG:                        libjpeg-turbo (ver 2.1.3-62)
--     WEBP:                        build (ver encoder: 0x020f)
--     PNG:                         build (ver 1.6.37)
--     TIFF:                        build (ver 42 - 4.2.0)
--     JPEG 2000:                   build (ver 2.5.0)
--     OpenEXR:                     build (ver 2.3.0)
--     HDR:                         YES
--     SUNRASTER:                   YES
--     PXM:                         YES
--     PFM:                         YES
--
--   Video I/O:
--     DC1394:                      NO
--     FFMPEG:                      NO
--       avcodec:                   NO
--       avformat:                  NO
--       avutil:                    NO
--       swscale:                   NO
--       avresample:                NO
--     GStreamer:                   NO
--     v4l/v4l2:                    YES (linux/videodev2.h)
--
--   Parallel framework:            pthreads
--
--   Trace:                         YES (with Intel ITT)
--
--   Other third-party libraries:
--     VA:                          YES
--     Lapack:                      NO
--     Eigen:                       NO
--     Custom HAL:                  NO
--     Protobuf:                    build (3.19.1)
--     Flatbuffers:                 builtin/3rdparty (23.5.9)
--
--   OpenCL:                        YES (INTELVA)
--     Include path:                /Net/subnet-homes/Development/User/ukoehler/local/Frameworks/opencv/4.8.0_trial/source/lib/3rdparty/include/opencl/1.2
--     Link libraries:              Dynamic load
--
--   Python (for build):            /usr/bin/python2.7
--
--   Java:
--     ant:                         NO
--     Java:                        NO
--     JNI:                         NO
--     Java wrappers:               NO
--     Java tests:                  NO
--
--   Install to:                    /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-default-debug-install
-- -----------------------------------------------------------------
--
-- Configuring done
-- Generating done
-- Build files have been written to: /build/uk/Frameworks/opencv-4.8.0-ov-AVX2-PThreads-OpenMP-debug
```

Compile the test using the following configuration:
```
cmake3 -DCMAKE_BUILD_TYPE=Debug -DCMAKE_INSTALL_PREFIX=/build/uk/Frameworks/opencv-4.8.0-ov-AVX2-default-debug-install VERBOSE=1 ~/local/Frameworks/opencv/4.8.0_trial/source/ovtest
```

The code to load and execute the model

```
std::string modelPath = R""(/build/uk/DNNModels/Selftrained/YOLO-NAS/yolo_nas_m_drone-Sim.onnx)"";

// Load the network
cv::dnn::Net net = cv::dnn::readNetFromONNX(modelPath);
net.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);
net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);

std::vector<cv::Mat> outs;
std::vector<std::string> outputNames = DNNHelper::getOutputsNames(net);
for (int i = 0; i < outputNames.size(); i++) {
    std::cout << ""DNNHelper::getOutputsNames(net) "" << i << ""  "" << DNNHelper::getOutputsNames(net).at(i) << std::endl;
}
net.forward(outs, DNNHelper::getOutputsNames(net));

std::cout << ""outs.size() "" << outs.size() << std::endl;
for (size_t i = 0; i < outs.size(); ++i)
{
    std::cout << i << ""  "" << outs[i].size() << "" depth "" << outs[i].depth() << "" channels() "" << outs[i].channels() << "" type() "" << outs[i].type() << std::endl;
}
```

The output
```
[DEBUG:0@10.440] global system.cpp:2881 restoreFPDenormalsState core: restore FP mxcsr flags = 0x00001fb0
[DEBUG:3@10.440] global system.cpp:2881 restoreFPDenormalsState core: restore FP mxcsr flags = 0x00001fb0
...
DNNHelper::getOutputsNames(net) 0  1170
DNNHelper::getOutputsNames(net) 1  1179
[DEBUG:0@10.492] global system.cpp:2842 setFPDenormalsIgnoreHint core: update FP mxcsr flags = 0x00009ff0
[DEBUG:0@10.492] global system.cpp:2881 restoreFPDenormalsState core: restore FP mxcsr flags = 0x00009ff0
...
outs.size() 2
0  [8400 x 1] depth 5 channels() 1 type() 5
1  [8400 x 1] depth 5 channels() 1 type() 5
```


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-11 01:14:18,bug,cmake: don't export external target twice,"fixup #23842

Error message on `-DWITH_OPENVINO=ON -DBUILD_SHARED_LIBS=OFF`:
```
CMake Error: install(EXPORT ""OpenCVModules"" ...) includes target ""ocv.3rdparty.openvino"" more than once in the export set.
CMake Error in CMakeLists.txt:
  given target ""ocv.3rdparty.openvino"" more than once.
```"
opencv/opencv,2023-07-10 11:36:45,bug,fix: typing stubs overload presence check,"Every function has at least 1 overload (the **main** one), so before the fix `check_overload_presence` always produced `True`

As a coincide, removes unnecessary `import typing` in several modules stubs e.g. `cv2/gapi/core/cpu/__init__.pyi`

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-07 16:30:33,bug,Test_Torch_nets.FastNeuralStyle_accuracy/1 randomly fails with CUDA,"### System Information

Platform: Ubuntu + CUDA
Full test name: Test_Torch_nets.FastNeuralStyle_accuracy/1, where GetParam() = CUDA/CUDA_FP16

### Detailed description

```
[ RUN      ] Test_Torch_nets.FastNeuralStyle_accuracy/1, where GetParam() = CUDA/CUDA_FP16
/home/ci/opencv/modules/dnn/test/test_common.impl.hpp:79: Failure
Expected: (normInf) <= (lInf), actual: 25.654 vs 25
  |ref| = 255
[  FAILED  ] Test_Torch_nets.FastNeuralStyle_accuracy/1, where GetParam() = CUDA/CUDA_FP16 (1900 ms)
```

### Steps to reproduce

https://github.com/opencv/opencv/actions/runs/5487550395/jobs/9999154944?pr=23944

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-07 16:15:03,bug,Python type stubs does not handle cuda::GpuMat and cuda::Stream,"### System Information

Python 3.6+
Platform: CUDA

### Detailed description

```
'Failed to resolve ""cv2.cudacodec"" namespace against ""cv2"". 
Errors: [\\'Failed to resolve ""cv2.cudacodec.createVideoWriter"" function against ""cv2"".
Errors: 
[0]: Failed to resolve ""stream"" argument: Failed to resolve ""Stream"" exposed as ""Stream"", 
[1]: Failed to resolve ""stream"" argument: Failed to resolve ""Stream"" exposed as ""Stream""\\', \\'Failed to resolve ""cv2.cudacodec.EncodeQp"" class against ""cv2"". Errors: [\\\\\\'Failed to resolve ""qpInterP"" property\\\\\\', \\\\\\'Failed to resolve ""qpInterB"" property\\\\\\', \\\\\\'Failed to resolve ""qpIntra"" property\\\\\\']\\', \\'Failed to resolve ""cv2.cudacodec.EncoderParams"" class against ""cv2"". Errors: [\\\\\\'Failed to resolve ""targetQuality"" property\\\\\\']\\', \\'Failed to resolve ""cv2.cudacodec.VideoReader"" class against ""cv2"". Errors: [\\\\\\'Failed to resolve ""cv2.cudacodec.VideoReader.nextFrame"" function against ""cv2"". Errors: [0]: Failed to resolve ""frame"" argument: Failed to resolve one of ""GpuMat | None"" items. Errors: [\\\\\\\\\\\\\\'Failed to resolve ""GpuMat"" exposed as ""GpuMat""\\\\\\\\\\\\\\'], [1]: Failed to resolve ""stream"" argument: Failed to resolve ""Stream"" exposed as ""Stream"", 
[2]: Failed to resolve return type: Failed to resolve one of ""tuple[bool, GpuMat]"" items. Errors: [\\\\\\\\\\\\\\'Failed to resolve ""GpuMat"" exposed as ""GpuMat""\\\\\\\\\\\\\\']\\\\\\', \\\\\\'Failed to resolve ""cv2.cudacodec.VideoReader.grab"" function against ""cv2"". Errors: [0]: Failed to resolve ""stream"" argument: Failed to resolve ""Stream"" exposed as ""Stream""\\\\\\', \\\\\\'Failed to resolve ""cv2.cudacodec.VideoReader.retrieve"" function against ""cv2"". Errors: 
[0]: Failed to resolve ""frame"" argument: Failed to resolve one of ""GpuMat | None"" items. Errors: [\\\\\\\\\\\\\\'Failed to resolve ""GpuMat"" exposed as ""GpuMat""\\\\\\\\\\\\\\'], 
[1]: Failed to resolve return type: Failed to resolve one of ""tuple[bool, GpuMat]"" items. Errors: [\\\\\\\\\\\\\\'Failed to resolve ""GpuMat"" exposed as ""GpuMat""\\\\\\\\\\\\\\']\\\\\\']\\']']
```

### Steps to reproduce

CMake options that work:
`cmake -DBUILD_opencv_cudacodec=OFF -DBUILD_opencv_cudaoptflow=OFF -DPYTHON3_EXECUTABLE=`which python3.8` -DPYTHON_DEFAULT_EXECUTABLE=`which python3.8` -DWITH_CUDA=ON -DCUDA_ARCH_BIN=61 -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules/ ../opencv-master`

CMake options that doe not:
`cmake  -DBUILD_opencv_cudaoptflow=OFF -DPYTHON3_EXECUTABLE=`which python3.8` -DPYTHON_DEFAULT_EXECUTABLE=`which python3.8` -DWITH_CUDA=ON -DCUDA_ARCH_BIN=61 -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules/ ../opencv-master`

CUDA definitions for Python: https://github.com/opencv/opencv/blob/4.x/modules/core/misc/python/pyopencv_cuda.hpp


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-07 06:35:18,bug,Depthwise Convolution layer with 5x5 kernel much slower than 4.7.0,"### System Information

macOS M2
OpenCV 4.7.0 and 4.8.0
python

### Detailed description

mediapipe palm detection model from OpenCV zoo show the inference time is double than the 4.7.0 version. 
reference: https://github.com/opencv/opencv_zoo/pull/190/files#r1252471348

Model file: https://github.com/opencv/opencv_zoo/blob/main/models/palm_detection_mediapipe/palm_detection_mediapipe_2023feb.onnx
Layer by Layer performance test results:
[palm_4.7.txt](https://github.com/opencv/opencv/files/11975324/palm_4.7.txt)
[palm_4.8.txt](https://github.com/opencv/opencv/files/11975325/palm_4.8.txt)

depth wise convolution inference time is 3 times than 4.7.0 version.

### Steps to reproduce

just run benchmark in OpenCV zoo

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-06 11:01:01,bug,VideoCapture MSMF plugin won't open using camera/device index.,"### System Information

OpenCV version: at least from 4.5.5 to master
Operating System / Platform: Windows 10/11
Compiler & compiler version: Visual Studio 2022

### Detailed description

It looks like unnecessary `nullptr` check of optional argument https://github.com/opencv/opencv/blob/4.8.0/modules/videoio/src/cap_msmf.cpp#L2722
Below linked fragment with my comments. By commenting out pointed `filename` check I was able to open camera on my local machine.
```cpp
static
CvResult CV_API_CALL cv_capture_open_with_params(
    const char* filename, int camera_index,
    int* params, unsigned n_params,
    CV_OUT CvPluginCapture* handle
)
{
    if (!handle)
        return CV_ERROR_FAIL;
    *handle = NULL;
    if (!filename)                           // <--- filename is optional, see below
        return CV_ERROR_FAIL;      
    CaptureT* cap = 0;
    try
    {
        cv::VideoCaptureParameters parameters(params, n_params);
        cap = new CaptureT();
        bool res;
        if (filename)                                                    // if filename is true then we use
            res = cap->open(std::string(filename), &parameters);         //
        else                                                             // however if it's nullptr
            res = cap->open(camera_index, &parameters);                  // then we use index to search device
        if (res)
        {
            *handle = (CvPluginCapture)cap;
            return CV_ERROR_OK;
        }
    }
    catch (const std::exception& e)
    {
        CV_LOG_WARNING(NULL, ""MSMF: Exception is raised: "" << e.what());
    }
    catch (...)
    {
        CV_LOG_WARNING(NULL, ""MSMF: Unknown C++ exception is raised"");
    }
    if (cap)
        delete cap;
    return CV_ERROR_FAIL;
}
```

### Steps to reproduce

Open video capture from camera (for example, laptop's built-in camera) using MSMF backend `cv::VideoCapture vc(0, cv::CAP_MSMF);` built as a plugin.

It's also very likely, that it's the same issue as https://github.com/opencv/opencv/issues/23056

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-05 11:22:06,bug,OpenCV solution for Visual Studio 2019 is not building opencv_core.lib when AVX2 is specified in (CPU_DISPATCH = SSE4_1;SSE4_2;AVX;FP16;AVX2) in x86 build,"### System Information

OpenCV solution for Visual Studio 2019 is not building opencv_core.lib when
AVX2 is specified in (CPU_DISPATCH = SSE4_1;SSE4_2;AVX;FP16;AVX2) in x86 build

OpenCV version: 4.8.0
Operating System / Platform:  Windows 10
Compiler & compiler version:  Visual Studio 2019

### Detailed description

By default x64 CMake configuration for Visual Studio 2019 uses:
CPU_BASELINE = SSE3;
CPU_DISPATCH = SSE4_1;SSE4_2;AVX;FP16;AVX2
and x86 configuration uses:
CPU_BASELINE = SSE2;
CPU_DISPATCH = SSE4_1;SSE4_2;AVX;FP16

When I set the same flags in build for x86 as set in x64 build, building
opencv_core module ends with failure:

Logs from building opencv_core module:
Build started...
1>------ Build started: Project: ZERO_CHECK, Configuration: Release Win32 ------
1>Checking Build System
2>------ Build started: Project: ippiw, Configuration: Release Win32 ------
3>------ Build started: Project: ittnotify, Configuration: Release Win32 ------
4>------ Build started: Project: opencv_core_SSE4_1, Configuration: Release Win32 ------
5>------ Build started: Project: opencv_core_SSE4_2, Configuration: Release Win32 ------
6>------ Build started: Project: opencv_core_AVX, Configuration: Release Win32 ------
7>------ Build started: Project: opencv_core_AVX2, Configuration: Release Win32 ------
8>------ Build started: Project: zlib, Configuration: Release Win32 ------
4>Building Custom Rule G:/opencv-4.8.0/modules/core/CMakeLists.txt
2>Building Custom Rule G:/opencv-4.8.0/build_x86_AVX2/3rdparty/ippicv/ippicv_win/iw/CMakeLists.txt
3>Building Custom Rule G:/opencv-4.8.0/3rdparty/ittnotify/CMakeLists.txt
7>Building Custom Rule G:/opencv-4.8.0/modules/core/CMakeLists.txt
6>Building Custom Rule G:/opencv-4.8.0/modules/core/CMakeLists.txt
8>Building Custom Rule G:/opencv-4.8.0/3rdparty/zlib/CMakeLists.txt
5>Building Custom Rule G:/opencv-4.8.0/modules/core/CMakeLists.txt
2>iw_core.c
6>mathfuncs_core.avx.cpp
4>arithm.sse4_1.cpp
2>iw_image.c
2>iw_image_color_convert_all.c
2>iw_image_color_convert_rgbs.c
3>ittnotify_static.c
2>iw_image_filter_bilateral.c
2>iw_image_filter_box.c
4>matmul.sse4_1.cpp
3>jitprofiling.c
2>iw_image_filter_canny.c
2>iw_image_filter_gaussian.c
5>stat.sse4_2.cpp
7>mathfuncs_core.avx2.cpp
7>stat.avx2.cpp
8>adler32.c
8>compress.c
8>crc32.c
8>deflate.c
7>arithm.avx2.cpp
7>convert.avx2.cpp
8>gzclose.c
8>gzlib.c
8>gzread.c
7>convert_scale.avx2.cpp
7>count_non_zero.avx2.cpp
7>has_non_zero.avx2.cpp
7>matmul.avx2.cpp
8>gzwrite.c
2>iw_image_filter_general.c
2>iw_image_filter_laplacian.c
2>iw_image_filter_morphology.c
8>inflate.c
8>infback.c
8>inftrees.c
2>iw_image_filter_scharr.c
2>iw_image_filter_sobel.c
2>iw_image_op_copy.c
2>iw_image_op_copy_channel.c
2>iw_image_op_copy_make_border.c
2>iw_image_op_copy_merge.c
2>iw_image_op_copy_split.c
2>iw_image_op_scale.c
8>inffast.c
8>trees.c
8>uncompr.c
8>zutil.c
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\stat.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\stat.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\stat.avx2.cpp)
7>mean.avx2.cpp
2>iw_image_op_set.c
2>iw_image_op_set_channel.c
2>iw_image_op_swap_channels.c
2>iw_image_transform_mirror.c
2>iw_image_transform_resize.c
2>iw_image_transform_rotate.c
2>iw_image_transform_warpaffine.c
2>iw_own.c
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\arithm.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\arithm.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\arithm.avx2.cpp)
7>merge.avx2.cpp
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\mathfuncs_core.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\mathfuncs_core.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\mathfuncs_core.avx2.cpp)
7>split.avx2.cpp
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\count_non_zero.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\count_non_zero.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\count_non_zero.avx2.cpp)
7>sum.avx2.cpp
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\matmul.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\matmul.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\matmul.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\convert.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\convert.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\convert.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\convert_scale.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\convert_scale.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\convert_scale.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\has_non_zero.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\has_non_zero.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\has_non_zero.avx2.cpp)
3>ittnotify.vcxproj -> G:\\opencv-4.8.0\\build_x86_AVX2\\3rdparty\\lib\\Release\\ittnotify.lib
5>opencv_core_SSE4_2.vcxproj -> G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\opencv_core_SSE4_2.dir\\Release\\opencv_core_SSE4_2.lib
2>ippiw.vcxproj -> G:\\opencv-4.8.0\\build_x86_AVX2\\3rdparty\\lib\\Release\\ippiw.lib
8>zlib.vcxproj -> G:\\opencv-4.8.0\\build_x86_AVX2\\3rdparty\\lib\\Release\\zlib.lib
6>opencv_core_AVX.vcxproj -> G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\opencv_core_AVX.dir\\Release\\opencv_core_AVX.lib
4>opencv_core_SSE4_1.vcxproj -> G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\opencv_core_SSE4_1.dir\\Release\\opencv_core_SSE4_1.lib
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\mean.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\mean.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\mean.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\merge.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\merge.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\merge.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\split.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\split.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\split.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(130,12): error C3861: '_mm256_extract_epi64': identifier not found (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\sum.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin_avx.hpp(2312): message : see reference to function template instantiation 'int64 cv::hal_AVX2::_v256_extract_epi64<3>(const __m256i &)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\sum.avx2.cpp)
7>G:\\opencv-4.8.0\\modules\\core\\include\\opencv2/core/hal/intrin.hpp(1016): message : see reference to function template instantiation 'uint64 cv::hal_AVX2::v_extract_n<3>(cv::hal_AVX2::v_uint64x4)' being compiled (compiling source file G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\sum.avx2.cpp)
7>Done building project ""opencv_core_AVX2.vcxproj"" -- FAILED.
9>------ Build started: Project: opencv_core, Configuration: Release Win32 ------
9>Processing OpenCL kernels (core)
9>-- G:/opencv-4.8.0/build_x86_AVX2/modules/core/opencl_kernels_core.hpp contains the same content
9>Building Custom Rule G:/opencv-4.8.0/modules/core/CMakeLists.txt
9>cmake_pch.cxx
9>algorithm.cpp
9>arithm.cpp
9>arithm.dispatch.cpp
9>array.cpp
9>async.cpp
9>batch_distance.cpp
9>bindings_utils.cpp
9>buffer_area.cpp
9>channels.cpp
9>check.cpp
9>command_line_parser.cpp
9>conjugate_gradient.cpp
9>convert.dispatch.cpp
9>convert_c.cpp
9>convert_scale.dispatch.cpp
9>copy.cpp
9>count_non_zero.dispatch.cpp
9>cuda_gpu_mat.cpp
9>cuda_gpu_mat_nd.cpp
9>cuda_host_mem.cpp
9>cuda_info.cpp
9>cuda_stream.cpp
9>datastructs.cpp
9>directx.cpp
9>downhill_simplex.cpp
9>dxt.cpp
9>gl_core_3_1.cpp
9>glob.cpp
9>hal_internal.cpp
9>has_non_zero.dispatch.cpp
9>kmeans.cpp
9>lapack.cpp
9>lda.cpp
9>logger.cpp
9>lpsolver.cpp
9>lut.cpp
9>mathfuncs.cpp
9>mathfuncs_core.dispatch.cpp
9>matmul.dispatch.cpp
9>matrix.cpp
9>matrix_c.cpp
9>matrix_decomp.cpp
9>matrix_expressions.cpp
9>matrix_iterator.cpp
9>matrix_operations.cpp
9>matrix_sparse.cpp
9>matrix_transform.cpp
9>matrix_wrap.cpp
9>mean.dispatch.cpp
9>merge.dispatch.cpp
9>minmax.cpp
9>norm.cpp
9>ocl.cpp
9>opencl_clblas.cpp
9>opencl_clfft.cpp
9>opencl_core.cpp
9>opengl.cpp
9>out.cpp
9>ovx.cpp
9>parallel_openmp.cpp
9>parallel_tbb.cpp
9>parallel_impl.cpp
9>pca.cpp
9>persistence.cpp
9>persistence_base64_encoding.cpp
9>persistence_json.cpp
9>persistence_types.cpp
9>persistence_xml.cpp
9>persistence_yml.cpp
9>rand.cpp
9>softfloat.cpp
9>split.dispatch.cpp
9>stat.dispatch.cpp
9>stat_c.cpp
9>stl.cpp
9>sum.dispatch.cpp
9>system.cpp
9>tables.cpp
9>trace.cpp
9>types.cpp
9>umatrix.cpp
9>datafile.cpp
9>filesystem.cpp
9>logtagconfigparser.cpp
9>logtagmanager.cpp
9>samples.cpp
9>va_intel.cpp
9>opencl_kernels_core.cpp
9>alloc.cpp
9>parallel.cpp
9>parallel.cpp
9>LINK : fatal error LNK1181: cannot open input file 'G:\\opencv-4.8.0\\build_x86_AVX2\\modules\\core\\opencv_core_AVX2.dir\\Release\\mathfuncs_core.avx2.obj'
9>Done building project ""opencv_core.vcxproj"" -- FAILED.
========== Build: 7 succeeded, 2 failed, 0 up-to-date, 0 skipped ==========


### Steps to reproduce

1. Set Cmake configuration to Visual Studio 2019 x86
2. Set this flags
CPU_BASELINE = SSE3;
CPU_DISPATCH = SSE4_1;SSE4_2;AVX;FP16;AVX2
BUILD_SHARED_LIBS=OFF
3. Build Visual Studio 2019 solution
4. Open solution and build opencv_core module
[CMakeCache.txt](https://github.com/opencv/opencv/files/11957266/CMakeCache.txt)


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-04 19:22:43,bug,Python type stubs: Class `cv2.error` is missing properties,"### System Information

OpenCV python: opencv-python-headless==4.8.0.74
Operating System / Platform: 10.0.19045 Build 19045
Python version: 3.9.13

### Detailed description

Class `cv2.error` is currently typed as:
```py
class error(Exception): ...
```

but should be something like: 
```py
class error(Exception):
    code: int
    err: str
    file: str
    func: str
    line: int
    msg: str
```
(They are technically ClassVars, but would be None)

As inspected with:
```py
>>> import cv2
>>> error_dir = dir(cv2.error)
>>> exception_dir = dir(Exception)
>>> [x for x in error_dir if x not in exception_dir]
['__module__', '__weakref__', 'code', 'err', 'file', 'func', 'line', 'msg']

>>> try:
...   cv2.VideoCapture().read(""aaa"")
... except cv2.error as error:
...   print(type(error.code), type(error.err), type(error.file), type(error.func), type(error.line), type(error.msg))
...
<class 'int'> <class 'str'> <class 'str'> <class 'str'> <class 'int'> <class 'str'>
```

### Steps to reproduce

Actual usage example:
![image](https://github.com/opencv/opencv/assets/1350584/c18539cf-3bb5-425c-ac73-a7d9095c8e5a)

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-07-02 12:20:44,bug,Detection of multiple ChArUco boards with different IDs in one image broken in 4.8.0,"### System Information

OpenCV 4.8.0
Ubuntu 22.04
Python 3.10.6

### Detailed description

In OpenCV 4.7.0 you could separately detect two ChArUco boards visible in a single image:

```python
dict_type = aruco.DICT_6X6_250
squares = (5, 7)
square_length_mm = 20.0
marker_length_mm = 10.0
aruco_dict = aruco.getPredefinedDictionary(dict_type)

board0 = aruco.CharucoBoard(squares, square_length_mm,
    marker_length_mm, aruco_dict, np.arange(17)) # There are 17 white squares, provide 17 markers with ids [0..16]
detector = aruco.CharucoDetector(board0)
charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(image)
aruco.drawDetectedCornersCharuco(image, charuco_corners, charuco_ids, (255, 0, 0))

board1 = aruco.CharucoBoard(squares, square_length_mm,
    marker_length_mm, aruco_dict, np.arange(17) + 17) # 17 markers with ids  [17..33]
detector = aruco.CharucoDetector(board1)
charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(image)
aruco.drawDetectedCornersCharuco(image, charuco_corners, charuco_ids, (0, 255, 0))
```
![Screenshot from 2023-07-02 14-04-06](https://github.com/opencv/opencv/assets/1639297/4ac31e6e-d33e-47d9-a194-75c485b8d860)

In OpenCV 4.8.0, the second `detectBoard` does not return any ChArUco corners. `charuco_corners`and `charuco_ids` are both `None`.

The markers are still returned, so it is not a detection issue.

Sample code and sample image (see below) return under 4.7.0:

```
Running OpenCV 4.7.0
board0
  charuco ids 0..23 (24)
  marker ids 0..33 (34)
board1
  charuco ids 0..23 (24)
  marker ids 0..33 (23)
```

and SAME code under OpenCV 4.8.0:

```
Running OpenCV 4.8.0
board0
  charuco ids 0..23 (24)
  marker ids 0..33 (34)
board1
  no charuco ids
  marker ids 0..33 (23)
```



### Steps to reproduce

```python
import numpy as np
import cv2
import cv2.aruco as aruco

if __name__ == '__main__':

    # Load image
    image = cv2.imread('image.png')

    # Generate Aruco boards
    dict_type = aruco.DICT_6X6_250
    squares = (5, 7)
    square_length_mm = 20.0
    marker_length_mm = 10.0
    aruco_dict = aruco.getPredefinedDictionary(dict_type)
    board0 = aruco.CharucoBoard(squares, square_length_mm,
        marker_length_mm, aruco_dict, np.arange(17))
    board1 = aruco.CharucoBoard(squares, square_length_mm,
        marker_length_mm, aruco_dict, np.arange(17) + 17)

    print(f'Running OpenCV {cv2.__version__}')

    detector = aruco.CharucoDetector(board0)
    charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(image)
    print('board0')
    if charuco_ids is None:
        print('  no charuco ids')
    else:
        print(f'  charuco ids {np.min(charuco_ids)}..{np.max(charuco_ids)} ({len(charuco_ids)})')
        aruco.drawDetectedCornersCharuco(image, charuco_corners, charuco_ids, (255, 0, 0))
    print(f'  marker ids {np.min(marker_ids)}..{np.max(marker_ids)} ({len(marker_ids)})')

    detector = aruco.CharucoDetector(board1)
    charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(image)
    print('board1')
    if charuco_ids is None:
        print('  no charuco ids')
    else:
        print(f'  charuco ids {np.min(charuco_ids)}..{np.max(charuco_ids)} ({len(charuco_ids)})')
        aruco.drawDetectedCornersCharuco(image, charuco_corners, charuco_ids, (0, 255, 0))
    print(f'  marker ids {np.min(marker_ids)}..{np.max(marker_ids)} ({len(marker_ids)})')

    cv2.imshow(f'charuco ids with OpenCV {cv2.__version__}', image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
```

![image](https://github.com/opencv/opencv/assets/1639297/b2f0024d-e1c1-4da0-828f-3dfc22d87b2d)


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-29 15:05:50,bug,CUDA 12.2 fp16 dnn compilation error,"### System Information

OpenCV version: 4.8.0
OS: Windows 11
Compiler: Visual Studio 2022
CUDA: 12.2


### Detailed description

Switching from CUDA 12.1 to 12.2 results in several compilation like the one below when compiling the **dnn** module.

<details>
  <summary>D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): error C2666: 'operator !=': overloaded functions have similar conversions</summary>

```
FAILED: modules/dnn/CMakeFiles/opencv_dnn.dir/src/layers/normalize_bbox_layer.cpp.obj
C:\\PROGRA~1\\MICROS~2\\2022\\COMMUN~1\\VC\\Tools\\MSVC\\1434~1.319\\bin\\Hostx64\\x64\\cl.exe  /nologo /TP -DCVAPI_EXPORTS -DCV_CUDA4DNN=1 -DCV_OCL4DNN=1 -DENABLE_PLUGINS -DHAVE_FLATBUFFERS=1 -DHAVE_PROTOBUF=1 -D_CRT_SECURE_NO_WARNINGS=1 -D_USE_MATH_DEFINES -D_VARIADIC_MAX=10 -D_WIN32_WINNT=0x0601 -D__OPENCV_BUILD=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -ID:\\build\\opencv\\4_8_0\\cuda_12_2_test\\3rdparty\\ippicv\\ippicv_win\\icv\\include -ID:\\build\\opencv\\4_8_0\\cuda_12_2_test\\3rdparty\\ippicv\\ippicv_win\\iw\\include -ID:\\repos\\opencv\\opencv\\modules\\dnn\\src -ID:\\repos\\opencv\\opencv\\modules\\dnn\\include -ID:\\build\\opencv\\4_8_0\\cuda_12_2_test\\modules\\dnn -ID:\\repos\\opencv\\contrib\\modules\\cudev\\include -ID:\\repos\\opencv\\opencv\\modules\\core\\include -ID:\\repos\\opencv\\opencv\\modules\\imgproc\\include -ID:\\repos\\opencv\\opencv\\modules\\dnn\\misc\\caffe -ID:\\repos\\opencv\\opencv\\modules\\dnn\\misc\\tensorflow -ID:\\repos\\opencv\\opencv\\modules\\dnn\\misc\\onnx -ID:\\repos\\opencv\\opencv\\modules\\dnn\\misc\\tflite -ID:\\repos\\opencv\\opencv\\3rdparty\\include\\opencl\\1.2 -ID:\\repos\\opencv\\opencv\\modules\\ts\\include -ID:\\repos\\opencv\\opencv\\modules\\imgcodecs\\include -ID:\\repos\\opencv\\opencv\\modules\\videoio\\include -ID:\\repos\\opencv\\opencv\\modules\\highgui\\include -external:ID:\\build\\opencv\\4_8_0\\cuda_12_2_test -external:I""C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include"" -external:ID:\\repos\\opencv\\opencv\\3rdparty\\flatbuffers\\include -external:ID:\\repos\\opencv\\opencv\\3rdparty\\protobuf\\src -external:W0 /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise /FS     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /wd4244 /wd4267 /wd4018 /wd4355 /wd4800 /wd4251 /wd4996 /wd4146 /wd4305 /wd4127 /wd4100 /wd4512 /wd4125 /wd4389 /wd4510 /wd4610 /wd4702 /wd4456 /wd4457 /wd4065 /wd4310 /wd4661 /wd4506 /wd4125 /wd4267 /wd4127 /wd4244 /wd4512 /wd4702 /wd4456 /wd4510 /wd4610 /wd4800 /wd4701 /wd4703 /wd4505 /wd4458  /MD /O2 /Ob2 /DNDEBUG /showIncludes /Fomodules\\dnn\\CMakeFiles\\opencv_dnn.dir\\src\\layers\\normalize_bbox_layer.cpp.obj /Fdlib\\opencv_dnn480.pdb /FS -c D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): error C2666: 'operator !=': overloaded functions have similar conversions
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/persistence.hpp(1332): note: could be 'bool cv::operator !=(const cv::FileNodeIterator &,const cv::FileNodeIterator &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.inl.hpp(2807): note: or       'bool cv::operator !=(const cv::SparseMatConstIterator &,const cv::SparseMatConstIterator &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.inl.hpp(2398): note: or       'bool cv::operator !=(const cv::MatConstIterator &,const cv::MatConstIterator &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(3708): note: or       'cv::MatExpr cv::operator !=(double,const cv::Mat &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(3707): note: or       'cv::MatExpr cv::operator !=(const cv::Mat &,double)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(3706): note: or       'cv::MatExpr cv::operator !=(const cv::Mat &,const cv::Mat &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(583): note: or       'bool cv::operator !=(const cv::UMatData::MemoryFlag &,const int &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(266): note: or       'bool cv::operator !=(const cv::_InputArray::KindFlag &,const int &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(66): note: or       'bool cv::operator !=(const cv::AccessFlag &,const int &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/types.hpp(2086): note: or       'bool cv::operator !=(const cv::Range &,const cv::Range &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1279): note: or       'cv::hal_baseline::v_int64x2 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int64x2 &,const cv::hal_baseline::v_int64x2 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1278): note: or       'cv::hal_baseline::v_uint64x2 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint64x2 &,const cv::hal_baseline::v_uint64x2 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1261): note: or       'cv::hal_baseline::v_float64x2 cv::hal_baseline::operator !=(const cv::hal_baseline::v_float64x2 &,const cv::hal_baseline::v_float64x2 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1260): note: or       'cv::hal_baseline::v_float32x4 cv::hal_baseline::operator !=(const cv::hal_baseline::v_float32x4 &,const cv::hal_baseline::v_float32x4 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1244): note: or       'cv::hal_baseline::v_int32x4 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int32x4 &,const cv::hal_baseline::v_int32x4 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1244): note: or       'cv::hal_baseline::v_uint32x4 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint32x4 &,const cv::hal_baseline::v_uint32x4 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1243): note: or       'cv::hal_baseline::v_int16x8 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int16x8 &,const cv::hal_baseline::v_int16x8 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1243): note: or       'cv::hal_baseline::v_uint16x8 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint16x8 &,const cv::hal_baseline::v_uint16x8 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1242): note: or       'cv::hal_baseline::v_int8x16 cv::hal_baseline::operator !=(const cv::hal_baseline::v_int8x16 &,const cv::hal_baseline::v_int8x16 &)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/hal/intrin_sse.hpp(1242): note: or       'cv::hal_baseline::v_uint8x16 cv::hal_baseline::operator !=(const cv::hal_baseline::v_uint8x16 &,const cv::hal_baseline::v_uint8x16 &)'
C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_fp16.hpp(714): note: or       'bool operator !=(const __half &,const __half &)' [found using argument-dependent lookup]
C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_fp16.hpp(917): note: or       'bool operator !=(const __half2 &,const __half2 &)' [found using argument-dependent lookup]
C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_bf16.hpp(700): note: or       'bool operator !=(const __nv_bfloat16 &,const __nv_bfloat16 &)' [found using argument-dependent lookup]
C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_bf16.hpp(903): note: or       'bool operator !=(const __nv_bfloat162 &,const __nv_bfloat162 &)' [found using argument-dependent lookup]
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(float, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(signed char, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(unsigned char, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(char, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(short, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(unsigned short, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(int, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(unsigned int, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(long, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(unsigned long, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(__int64, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(unsigned __int64, double)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: or       'built-in C++ operator!=(bool, double)'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.inl.hpp(2718): note: or       'bool cv::operator !=(const cv::MatIterator_<_Tp> &,const cv::MatIterator_<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::MatIterator_<_Tp> &,const cv::MatIterator_<_Tp> &)': could not deduce template argument for 'const cv::MatIterator_<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.inl.hpp(2581): note: or       'bool cv::operator !=(const cv::MatConstIterator_<_Tp> &,const cv::MatConstIterator_<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::MatConstIterator_<_Tp> &,const cv::MatConstIterator_<_Tp> &)': could not deduce template argument for 'const cv::MatConstIterator_<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(3712): note: or       'cv::MatExpr cv::operator !=(const cv::Matx<_Tp,m,n> &,const cv::Mat &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'cv::MatExpr cv::operator !=(const cv::Matx<_Tp,m,n> &,const cv::Mat &)': could not deduce template argument for 'const cv::Matx<_Tp,m,n> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/mat.hpp(3710): note: or       'cv::MatExpr cv::operator !=(const cv::Mat &,const cv::Matx<_Tp,m,n> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'cv::MatExpr cv::operator !=(const cv::Mat &,const cv::Matx<_Tp,m,n> &)': could not deduce template argument for 'const cv::Matx<_Tp,m,n> &' from 'double'
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/types.hpp(2276): note: or       'bool cv::operator !=(const cv::Scalar_<_Tp> &,const cv::Scalar_<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::Scalar_<_Tp> &,const cv::Scalar_<_Tp> &)': could not deduce template argument for 'const cv::Scalar_<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/types.hpp(1964): note: or       'bool cv::operator !=(const cv::Rect_<_Tp> &,const cv::Rect_<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::Rect_<_Tp> &,const cv::Rect_<_Tp> &)': could not deduce template argument for 'const cv::Rect_<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/types.hpp(1795): note: or       'bool cv::operator !=(const cv::Size_<_Tp> &,const cv::Size_<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::Size_<_Tp> &,const cv::Size_<_Tp> &)': could not deduce template argument for 'const cv::Size_<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/types.hpp(1584): note: or       'bool cv::operator !=(const cv::Point3_<_Tp> &,const cv::Point3_<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::Point3_<_Tp> &,const cv::Point3_<_Tp> &)': could not deduce template argument for 'const cv::Point3_<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/types.hpp(1337): note: or       'bool cv::operator !=(const cv::Point_<_Tp> &,const cv::Point_<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::Point_<_Tp> &,const cv::Point_<_Tp> &)': could not deduce template argument for 'const cv::Point_<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/types.hpp(1052): note: or       'bool cv::operator !=(const cv::Complex<_Tp> &,const cv::Complex<_Tp> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::Complex<_Tp> &,const cv::Complex<_Tp> &)': could not deduce template argument for 'const cv::Complex<_Tp> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\core\\include\\opencv2/core/matx.hpp(1365): note: or       'bool cv::operator !=(const cv::Matx<_Tp,m,n> &,const cv::Matx<_Tp,m,n> &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: 'bool cv::operator !=(const cv::Matx<_Tp,m,n> &,const cv::Matx<_Tp,m,n> &)': could not deduce template argument for 'const cv::Matx<_Tp,m,n> &' from 'T'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(114): note: while trying to match the argument list '(T, double)'
        with
        [
            T=half
        ]
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../cuda4dnn/primitives/normalize_bbox.hpp(93): note: while compiling class template member function 'void cv::dnn::cuda4dnn::NormalizeOp<half>::forward(const std::vector<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>,std::allocator<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>>> &,const std::vector<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>,std::allocator<cv::Ptr<cv::dnn::dnn4_v20230620::BackendWrapper>>> &,cv::dnn::cuda4dnn::csl::Workspace &)'
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\../op_cuda.hpp(194): note: see reference to class template instantiation 'cv::dnn::cuda4dnn::NormalizeOp<half>' being compiled
D:\\repos\\opencv\\opencv\\modules\\dnn\\src\\layers\\normalize_bbox_layer.cpp(332): note: see reference to function template instantiation 'cv::Ptr<cv::dnn::dnn4_v20230620::BackendNode> cv::dnn::make_cuda_node<cv::dnn::cuda4dnn::NormalizeOp,cv::dnn::cuda4dnn::csl::Stream,const cv::Mat&,cv::dnn::cuda4dnn::NormalizeConfiguration<float>&>(int,cv::dnn::cuda4dnn::csl::Stream &&,const cv::Mat &,cv::dnn::cuda4dnn::NormalizeConfiguration<float> &)' being compiled
```
</details>

it looks like a result of the [CUDA Math API's](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-math-release-12-2) being reworked in this version of CUDA, specifically changes to the `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.2\\include\\cuda_fp16.hpp` file.

### Steps to reproduce

```
cmake.exe -BBUILD_DIR -HOPENCV_DIR -GNinja -DOPENCV_EXTRA_MODULES_PATH=OPENCV_CONTRIB_MODULES -DBUILD_opencv_world=OFF
-DWITH_CUDA=ON -DCUDA_TOOLKIT_ROOT_DIR=""C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.2"" -DCUDA_ARCH_BIN=8.6

cmake.exe --build BUILD_DIR --target opencv_dnn
```


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-28 10:17:15,bug, error: (-215:Assertion failed) inputs.size() in function 'cv::dnn::dnn4_v20230620::Layer::getMemoryShapes',"```
### System Information

General configuration for OpenCV 4.8.0-pre =====================================
  Version control:               4.7.0-505-gc982be3924

  Extra modules:
    Location (extra):            C:/lib/opencv_contrib/modules
    Version control (extra):     4.7.0-71-g4f66f867

  Platform:
    Timestamp:                   2023-06-05T09:49:58Z
    Host:                        Windows 10.0.22621 AMD64
    CMake:                       3.26.1
    CMake generator:             Visual Studio 17 2022
    CMake build tool:            C:/Program Files/Microsoft Visual Studio/2022/Community/MSBuild/Current/Bin/amd64/MSBuild.exe
    MSVC:                        1935
    Configuration:               Debug Release

  CPU/HW features:
    Baseline:                    SSE SSE2 SSE3
      requested:                 SSE3
    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX
      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
      SSE4_1 (18 files):         + SSSE3 SSE4_1
      SSE4_2 (2 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
      FP16 (1 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
      AVX (8 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX
      AVX2 (37 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
      AVX512_SKX (8 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX

  C/C++:
    Built as dynamic libs?:      YES
    C++ standard:                11
    C++ Compiler:                C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe  (ver 19.35.32215.0)
    C++ flags (Release):         /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MD /O2 /Ob2 /DNDEBUG
    C++ flags (Debug):           /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MDd /Zi /Ob0 /Od /RTC1
    C Compiler:                  C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe
    C flags (Release):           /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP   /MD /O2 /Ob2 /DNDEBUG
    C flags (Debug):             /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP /MDd /Zi /Ob0 /Od /RTC1
    Linker flags (Release):      /machine:x64  /INCREMENTAL:NO
    Linker flags (Debug):        /machine:x64  /debug /INCREMENTAL
    ccache:                      NO
    Precompiled headers:         YES
    Extra dependencies:          cudart_static.lib nppc.lib nppial.lib nppicc.lib nppidei.lib nppif.lib nppig.lib nppim.lib nppist.lib nppisu.lib nppitc.lib npps.lib cublas.lib cudnn.lib cufft.lib -LIBPATH:C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1/lib/x64
    3rdparty dependencies:

  OpenCV modules:
    To be built:                 alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform java line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab viz wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto
    Disabled:                    world
    Disabled by dependency:      -
    Unavailable:                 cvv freetype hdf julia matlab ovis python2
    Applications:                tests perf_tests examples apps
    Documentation:               doxygen python javadoc
    Non-free algorithms:         YES

  Windows RT support:            NO

  GUI:                           WIN32UI
    Win32 UI:                    YES
    OpenGL support:              YES (opengl32 glu32)
    VTK support:                 YES (ver 9.2.5)

  Media I/O:
    ZLib:                        optimized C:/install/zlib/lib/zlib.lib debug C:/install/zlib/lib/zlibd.lib (ver 1.2.13)
    JPEG:                        build-libjpeg-turbo (ver 2.1.3-62)
      SIMD Support Request:      YES
      SIMD Support:              NO
    WEBP:                        build (ver encoder: 0x020f)
    PNG:                         optimized C:/install/libpng/lib/libpng16.lib debug C:/install/libpng/lib/libpng16d.lib (ver 1.6.40)
    TIFF:                        build (ver 42 - 4.2.0)
    JPEG 2000:                   build (ver 2.5.0)
    OpenEXR:                     build (ver 2.3.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:
    DC1394:                      NO
    FFMPEG:                      YES (prebuilt binaries)
      avcodec:                   YES (58.134.100)
      avformat:                  YES (58.76.100)
      avutil:                    YES (56.70.100)
      swscale:                   YES (5.9.100)
      avresample:                YES (4.0.0)
    GStreamer:                   NO
    DirectShow:                  YES
    Media Foundation:            YES
      DXVA:                      YES

  Parallel framework:            Concurrency

  Other third-party libraries:
    Intel IPP:                   2021.8 [2021.8.0]
           at:                   C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/icv
    Intel IPP IW:                sources (2021.8.0)
              at:                C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/iw
    Lapack:                      YES (C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_intel_lp64.lib C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_sequential.lib C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_core.lib)
    OpenVINO:                    YES (2022.3.0)
    Eigen:                       YES (ver ..)
    Custom HAL:                  NO
    Protobuf:                    build (3.19.1)
    Flatbuffers:                 builtin/3rdparty (23.5.9)

  NVIDIA CUDA:                   YES (ver 12.1, CUFFT CUBLAS)
    NVIDIA GPU arch:             86
    NVIDIA PTX archs:

  cuDNN:                         YES (ver 8.8.0)

  OpenCL:                        YES (NVD3D11)
    Include path:                C:/lib/opencv/3rdparty/include/opencl/1.2
    Link libraries:              Dynamic load

  Python 3:
    Interpreter:                 C:/Program Files/Python310/python.exe (ver 3.10.10)
    Libraries:                   optimized C:/Program Files/Python310/libs/python310.lib debug C:/Program Files/Python310/libs/python310_d.lib (ver 3.10.10)
    numpy:                       C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/numpy/core/include (ver 1.23.5)
    install path:                C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/cv2/python-3.10

  Python (for build):            C:/Program Files/Python310/python.exe

  Java:
    ant:                         C:/apache-ant-1.10.13/bin/ant.bat (ver 1.10.13)
    Java:                        NO
    JNI:                         C:/Program Files/Java/jdk-19/include C:/Program Files/Java/jdk-19/include/win32 C:/Program Files/Java/jdk-19/include
    Java wrappers:               YES (ANT)
    Java tests:                  YES

  Install to:                    C:/install/opencv
-------------------------------------------------------------
```
### Detailed description

I converted adaBins_kitty.pth to onnx using pytorch :

error is : 

```
[ INFO:0@0.397] global onnx_importer.cpp:835 cv::dnn::dnn4_v20230620::ONNXImporter::populateNet DNN/ONNX: loading ONNX v7 model produced by 'pytorch':2.1.0. Number of nodes = 1838, initializers = 468, inputs = 1, outputs = 2
[ INFO:0@0.398] global onnx_importer.cpp:728 cv::dnn::dnn4_v20230620::ONNXImporter::parseOperatorSet DNN/ONNX: ONNX opset version = 14
[ INFO:0@1.512] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant) from domain='ai.onnx'
[ INFO:0@1.512] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_1) from domain='ai.onnx'
[ INFO:0@1.512] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_2) from domain='ai.onnx'
[ INFO:0@1.513] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_3) from domain='ai.onnx'
[ INFO:0@1.513] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ConstantOfShape]:(onnx_node!/encoder/conv_stem/ConstantOfShape) from domain='ai.onnx'
[ INFO:0@1.513] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Concat]:(onnx_node!/encoder/conv_stem/Concat) from domain='ai.onnx'
[ INFO:0@1.514] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_4) from domain='ai.onnx'
[ INFO:0@1.514] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Reshape]:(onnx_node!/encoder/conv_stem/Reshape) from domain='ai.onnx'
[ INFO:0@1.514] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_5) from domain='ai.onnx'
[ INFO:0@1.514] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_6) from domain='ai.onnx'
[ INFO:0@1.515] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_7) from domain='ai.onnx'
[ INFO:0@1.515] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_8) from domain='ai.onnx'
[ INFO:0@1.515] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 5 inputs and 1 outputs: [Slice]:(onnx_node!/encoder/conv_stem/Slice) from domain='ai.onnx'
[ INFO:0@1.515] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Transpose]:(onnx_node!/encoder/conv_stem/Transpose) from domain='ai.onnx'
[ INFO:0@1.515] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/conv_stem/Constant_9) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Reshape]:(onnx_node!/encoder/conv_stem/Reshape_1) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/encoder/conv_stem/Cast) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Pad]:(onnx_node!/encoder/conv_stem/Pad) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/conv_stem/Conv) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.0/conv_dw/Conv) from domain='ai.onnx'
[ INFO:0@1.516] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.0/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.0/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ReduceMean]:(onnx_node!/encoder/blocks.0/blocks.0.0/se/ReduceMean) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.0/se/conv_reduce/Conv) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.0/se/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.0/se/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.0/se/conv_expand/Conv) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.0/se/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.0/se/Mul) from domain='ai.onnx'
[ INFO:0@1.517] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.0/conv_pw/Conv) from domain='ai.onnx'
[ INFO:0@1.518] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.1/conv_dw/Conv) from domain='ai.onnx'
[ INFO:0@1.518] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.1/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.518] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.1/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.518] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ReduceMean]:(onnx_node!/encoder/blocks.0/blocks.0.1/se/ReduceMean) from domain='ai.onnx'
[ INFO:0@1.518] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.1/se/conv_reduce/Conv) from domain='ai.onnx'
[ INFO:0@1.518] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.1/se/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.1/se/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.1/se/conv_expand/Conv) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.1/se/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.1/se/Mul) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.1/conv_pw/Conv) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/encoder/blocks.0/blocks.0.1/Add) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.2/conv_dw/Conv) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.2/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.519] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.2/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [ReduceMean]:(onnx_node!/encoder/blocks.0/blocks.0.2/se/ReduceMean) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.2/se/conv_reduce/Conv) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.2/se/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.2/se/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.2/se/conv_expand/Conv) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.0/blocks.0.2/se/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.0/blocks.0.2/se/Mul) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.0/blocks.0.2/conv_pw/Conv) from domain='ai.onnx'
[ INFO:0@1.520] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Add]:(onnx_node!/encoder/blocks.0/blocks.0.2/Add) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_pw/Conv) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Sigmoid]:(onnx_node!/encoder/blocks.1/blocks.1.0/act1/Sigmoid) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Mul]:(onnx_node!/encoder/blocks.1/blocks.1.0/act1/Mul) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Shape]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Shape) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Constant) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Gather]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Gather) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Shape]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Shape_1) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Constant_1) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Gather]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Gather_1) from domain='ai.onnx'
[ INFO:0@1.521] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 0 inputs and 1 outputs: [Constant]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Constant_2) from domain='ai.onnx'
[ INFO:0@1.522] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 2 inputs and 1 outputs: [Div]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Div) from domain='ai.onnx'
[ INFO:0@1.522] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Cast) from domain='ai.onnx'
[ INFO:0@1.522] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Cast]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Cast_1) from domain='ai.onnx'
[ INFO:0@1.522] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Neg]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Neg) from domain='ai.onnx'
OpenCV(4.8.0-pre) Error: Assertion failed (inputs.size()) in cv::dnn::dnn4_v20230620::Layer::getMemoryShapes, file C:\\lib\\opencv\\modules\\dnn\\src\\layer.cpp, line 255
[ERROR:0@1.522] global onnx_importer.cpp:1064 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 1 inputs and 1 outputs: [Neg]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Neg) from domain='ai.onnx'
[ INFO:0@1.522] global onnx_importer.cpp:1068 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode     Input[0] = '/encoder/blocks.1/blocks.1.0/conv_dw/Cast_1_output_0'
[ INFO:0@1.522] global onnx_importer.cpp:1072 cv::dnn::dnn4_v20230620::ONNXImporter::handleNode     Output[0] = '/encoder/blocks.1/blocks.1.0/conv_dw/Neg_output_0'
OpenCV(4.8.0-pre) Error: Unspecified error (> Node [Neg@ai.onnx]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Neg) parse error: OpenCV(4.8.0-pre) C:\\lib\\opencv\\modules\\dnn\\src\\layer.cpp:255: error: (-215:Assertion failed) inputs.size() in function 'cv::dnn::dnn4_v20230620::Layer::getMemoryShapes'
> ) in cv::dnn::dnn4_v20230620::ONNXImporter::handleNode, file C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp, line 1083
OpenCV: terminate handler is called! The last OpenCV error is:
OpenCV(4.8.0-pre) Error: Unspecified error (> Node [Neg@ai.onnx]:(onnx_node!/encoder/blocks.1/blocks.1.0/conv_dw/Neg) parse error: OpenCV(4.8.0-pre) C:\\lib\\opencv\\modules\\dnn\\src\\layer.cpp:255: error: (-215:Assertion failed) inputs.size() in function 'cv::dnn::dnn4_v20230620::Layer::getMemoryShapes'
> ) in cv::dnn::dnn4_v20230620::ONNXImporter::handleNode, file C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp, line 1083

C:\\Users\\laurent\\Documents\\Visual Studio 2022\\build\\dnn_edge\\Debug\\dnn_edge.exe (process 5936) exited with code 3.
```


stack trace is 
>	opencv_core480d.dll!cv::error(const cv::Exception & exc) Line 1283	C++
 	opencv_core480d.dll!cv::error(int _code, const std::string & _err, const char * _func, const char * _file, int _line) Line 1295	C++
 	opencv_dnn480d.dll!`cv::dnn::dnn4_v20230620::ONNXImporter::handleNode'::`1'::catch$35() Line 1083	C++
 	[External Code]	
 	opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::ONNXImporter::handleNode(const opencv_onnx::NodeProto & node_proto) Line 1029	C++
 	opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::ONNXImporter::populateNet() Line 919	C++
 	opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::ONNXImporter::ONNXImporter(cv::dnn::dnn4_v20230620::Net & net, const char * onnxFile) Line 282	C++
 	opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::detail::readNet<cv::dnn::dnn4_v20230620::ONNXImporter,char const *>(const char * && <args_0>) Line 77	C++
 	opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::detail::readNetDiagnostic<cv::dnn::dnn4_v20230620::ONNXImporter,char const *>(const char * && <args_0>) Line 84	C++
 	opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::readNetFromONNX(const std::string & onnxFile) Line 4076	C++
 	opencv_dnn480d.dll!cv::dnn::dnn4_v20230620::readNet(const std::string & _model, const std::string & _config, const std::string & _framework) Line 54	C++


### Steps to reproduce

model is imported using adress given in https://github.com/shariqfarooq123/AdaBins : 

https://doc-14-c8-docs.googleusercontent.com/docs/securesc/3mr94gkfrtq7tuicph1rujatro1o6vr7/2srn7k4nes93shf4n3hsh6pc0r0b8cam/1687698000000/12617225915674687510/04069296435779562625Z/1HMgff-FV6qw1L0ywQZJ7ECa9VPq1bIoj?e=download&uuid=22d02057-f7ee-4cef-94ea-58a0e963be0b&nonce=qiqc5gvsefthk&user=04069296435779562625Z&hash=459bv4bkg110tv1ru6tth06nqskl33n6

```
import onnxscript
import torch
from models import UnetAdaptiveBins
import model_io
import torch.onnx

OPSET_VERSION=14
 
device = torch.device('cpu')
model = UnetAdaptiveBins.build(n_bins=256, min_val=1e-3, max_val=10)
dummy_input = torch.rand((1, 3, 480, 640), requires_grad=True)#.to(device)
model.eval()
model, _, _ = model_io.load_checkpoint(r""C:\\Users\\laurent\\Downloads\\AdaBins_kitti.pt"", model)
print(""EXPORT MODEL TO ONNX"")
torch.onnx.export(model, 
                  dummy_input,
                  'AdaBins_kitti.onnx',
                  verbose=True,
                  opset_version=OPSET_VERSION,
                  input_names=['image_in'],
                  output_names=['depth_out']
                  )

```then I try to download model in opencv

```
        Net net;
        net = readNet(""AdaBins_kitti.onnx"");

```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-26 03:11:30,bug,Mouse coordinates seem to be off if opencv versionhigher than 4.5,"### System Information

OpenCV version: 4.4.0
Operating System / Platform: Windows 10
Python version: 3.810

### Detailed description

 opencv version 4.4.0 seams to be still ok, but somewhere for later versions mouse reading coordinates seems to be off, is that true?  Not sure what version it starts but latest 4.6 or 4.7 for sure 
It could be tested in code below. It is a 2x2 image, so with mouse increase the size of the window. Tt should print proper mouse coordinates. But those latest versions show proper value only for top , left quadrant for a pixel

### Steps to reproduce

```import numpy as np
import cv2
print(f'OpenCV version {cv2.__version__}')

img = np.zeros((2,2,3), np.uint8)
img[0, 0] = (0, 0, 255)
img[1, 0] = (0, 255, 0)
img[0, 1] = (255, 0, 0)

def mouseAction(event,x,y,flags,param=None):
    print(x,y)
    
cv2.namedWindow('image', cv2.WINDOW_NORMAL)
cv2.setWindowProperty('image',cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
cv2.setMouseCallback('image', mouseAction)
cv2.imshow('image', img)
cv2.waitKey(0)
```

"
opencv/opencv,2023-06-23 09:14:09,bug,dnn: fix overflow in sigmoid layer,"Fixes #23850 

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-22 15:09:13,bug,MinGW-w64 Standalone Environment Error: 'pthread_self' was not declared in this scope,"### System Information

OpenCV Version: 4.7.0
Operating System: Windows 11 22H2
Compiler (& version): gcc.exe (x86_64-win32-seh-rev1, Built by MinGW-Builds project) 13.1.0, MinGW-w64

### Detailed description

```
[ 27%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/__/core/src/parallel.cpp.obj
C:\\Users\\thekp\\Desktop\\opencv\\opencv-4.7.0\\modules\\core\\src\\parallel.cpp: In function 'int cv::getThreadNum()':
C:\\Users\\thekp\\Desktop\\opencv\\opencv-4.7.0\\modules\\core\\src\\parallel.cpp:800:32: error: 'pthread_self' was not declared in this scope
  800 |     return (int)(size_t)(void*)pthread_self(); // no zero-based indexing
      |                                ^~~~~~~~~~~~
```

In the case of my machine, I've had only `#define HAVE_PTHREADS_PF` enabled, but the `pthread.h` header was not included for this case, hence the error.

### Steps to reproduce

```cpp
// ...
#elif defined HAVE_OPENMP
    #include <omp.h>
#elif defined HAVE_GCD
    #include <dispatch/dispatch.h>
    #include <pthread.h>
#elif defined WINRT && _MSC_VER < 1900
    #include <ppltasks.h>
#elif defined HAVE_CONCURRENCY
    #include <ppl.h>             // Line 130 in modules/core/src/parallel.cpp
#elif defined HAVE_PTHREADS_PF
    #include <pthread.h>
#endif                           // Line 131 in modules/core/src/parallel.cpp
// ...
```
Adding an `#elif defined HAVE_PTHREADS_PF` condition and a `#include <pthread.h>` snippet allowed
```cpp
#elif defined HAVE_PTHREADS_PF
    return (int)(size_t)(void*)pthread_self(); // no zero-based indexing
```
at line 800 to correctly find `pthread_self()` and moves on correctly. I wonder if this was somehow overlooked, or was a design choice and that I'm just setting my CMake Configs wrong?

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-21 18:24:42,bug,G-API: Fix incorrect OpaqueKind for Kernel outputs,"### Pull Request Readiness Checklist

#### Overview
The PR is going to fix several problems:
1. Major: `GKernel` doesn't hold `kind` for its outputs. Since `GModelBuilder` traverse graph from outputs to inputs once it reaches any output of the operation it will use its `kind` to create  `Data` meta for all operation outputs. Since it essential for `python` to know `GTypeInfo` (which is `shape` and `kind`) it will be confused.

Consider this operation:
```
 @cv.gapi.op('custom.square_mean', in_types=[cv.GArray.Int], out_types=[cv.GOpaque.Float, cv.GArray.Int])
    class GSquareMean:
        @staticmethod
        def outMeta(desc):
            return cv.empty_gopaque_desc(), cv.empty_array_desc()
```
Even though `GOpaque` is `Float`, corresponding metadata might have `Int` kind because it might be taken from `cv.GArray.Int`
so it will be a problem if one of the outputs of these operation is graph output because python will cast it to the wrong type based on `Data` meta.

2. Minor: Some of the OpenVINO `IR`'s doesn't any layout information for input. It's usually true only for `IRv10` but since `OpenVINO 2.0` need this information to correctly configure resize we need to put default layout if there no such assigned in `ov::Model`. 

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-20 17:11:38,bug,fix: conditionally define generic NumPy NDArray alias,"This patch introduces conditional alias definition.

- Fixes compatibility with NumPy versions < 1.20 and Python < 3.9
- Updates enums handling to utilise introduced `ConditionalAliasTypeNode `

Generated `cv2/typing/__init__.py` content after patch:

```python
import cv2.mat_wrapper
import numpy
import sys
import typing

if numpy.lib.NumpyVersion(numpy.__version__) > ""1.20.0"" and sys.version_info >= (3, 9):
    NumPyArrayGeneric = numpy.ndarray[typing.Any, numpy.dtype[numpy.generic]]
else:
    NumPyArrayGeneric = numpy.ndarray


if numpy.lib.NumpyVersion(numpy.__version__) > ""1.20.0"" and sys.version_info >= (3, 9):
    NumPyArrayFloat32 = numpy.ndarray[typing.Any, numpy.dtype[numpy.float32]]
else:
    NumPyArrayFloat32 = numpy.ndarray


if numpy.lib.NumpyVersion(numpy.__version__) > ""1.20.0"" and sys.version_info >= (3, 9):
    NumPyArrayFloat64 = numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]
else:
    NumPyArrayFloat64 = numpy.ndarray

MatLike = typing.Union[cv2.mat_wrapper.Mat, NumPyArrayGeneric]
Matx33f = NumPyArrayFloat32
""""""NDArray(shape=(3, 3), dtype=numpy.float32)""""""
Matx33d = NumPyArrayFloat64
""""""NDArray(shape=(3, 3), dtype=numpy.float64)""""""
Matx44f = NumPyArrayFloat32
""""""NDArray(shape=(4, 4), dtype=numpy.float32)""""""
Matx44d = NumPyArrayFloat64
""""""NDArray(shape=(4, 4), dtype=numpy.float64)""""""
```

Resolves: #23822

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-16 19:25:36,bug,Python Typing module is incompatible with some Numpy versions,"### System Information

OS: Ubuntu 18.04
Python: 3.8.0 (from apt)
OpenCV: 4.x

### Detailed description

Numpy: 1.24.3 Importing issue:
```
alexander@paradox:~/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages$ python3.8
Python 3.8.0 (default, Dec  9 2021, 17:53:27) 
[GCC 8.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import cv2
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/__init__.py"", line 181, in <module>
    bootstrap()
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/__init__.py"", line 175, in bootstrap
    if __load_extra_py_code_for_module(""cv2"", submodule, DEBUG):
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/__init__.py"", line 28, in __load_extra_py_code_for_module
    py_module = importlib.import_module(module_name)
  File ""/usr/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/typing/__init__.py"", line 73, in <module>
    MatLike = typing.Union[cv2.mat_wrapper.Mat, numpy.ndarray[typing.Any, numpy.dtype[numpy.generic]]]
TypeError: Type subscription requires python >= 3.9
```

Numpy 1.20.2:
```
Python 3.8.0 (default, Dec  9 2021, 17:53:27) 
[GCC 8.4.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import cv2
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/__init__.py"", line 181, in <module>
    bootstrap()
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/__init__.py"", line 175, in bootstrap
    if __load_extra_py_code_for_module(""cv2"", submodule, DEBUG):
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/__init__.py"", line 28, in __load_extra_py_code_for_module
    py_module = importlib.import_module(module_name)
  File ""/usr/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/mnt/projects/Projects/OpenCV/opencv-build/install/lib/python3.8/site-packages/cv2/typing/__init__.py"", line 73, in <module>
    MatLike = typing.Union[cv2.mat_wrapper.Mat, numpy.ndarray[typing.Any, numpy.dtype[numpy.generic]]]
TypeError: 'numpy._DTypeMeta' object is not subscriptable
```

### Steps to reproduce

python3.8:
# import cv2

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-15 19:53:26,bug,Export enums ALL_CAPS version to typing stub files,"- Export ALL_CAPS versions alongside from normal names for enum constants, since both versions are available in runtime
- Change enum names entries comments to documentary strings

Before patch
```python
RMat_Access_R: int
RMat_Access_W: int
RMat_Access = int  # One of [R, W]
```
After patch
```python
RMat_Access_R: int
RMAT_ACCESS_R: int
RMat_Access_W: int
RMAT_ACCESS_W: int
RMat_Access = int
""""""One of [RMat_Access_R, RMAT_ACCESS_R, RMat_Access_W, RMAT_ACCESS_W]""""""
```

Resolves: #23776

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-15 13:29:31,bug,CAP_IMAGES: can't find starting number,"### System Information



General configuration for OpenCV 4.7.0-dev =====================================
  Version control:               4.7.0-403-g5d913f4d72

  Extra modules:
    Location (extra):            C:/lib/opencv_contrib/modules
    Version control (extra):     4.7.0-54-g8dfeed73

  Platform:
    Timestamp:                   2023-06-05T09:49:58Z
    Host:                        Windows 10.0.22621 AMD64
    CMake:                       3.26.1
    CMake generator:             Visual Studio 17 2022
    CMake build tool:            C:/Program Files/Microsoft Visual Studio/2022/Community/MSBuild/Current/Bin/amd64/MSBuild.exe
    MSVC:                        1935
    Configuration:               Debug Release

  CPU/HW features:
    Baseline:                    SSE SSE2 SSE3
      requested:                 SSE3
    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX
      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
      SSE4_1 (18 files):         + SSSE3 SSE4_1
      SSE4_2 (2 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
      FP16 (1 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
      AVX (8 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX
      AVX2 (36 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
      AVX512_SKX (8 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX

  C/C++:
    Built as dynamic libs?:      YES
    C++ standard:                11
    C++ Compiler:                C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe  (ver 19.35.32215.0)
    C++ flags (Release):         /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MD /O2 /Ob2 /DNDEBUG
    C++ flags (Debug):           /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MDd /Zi /Ob0 /Od /RTC1
    C Compiler:                  C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe
    C flags (Release):           /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP   /MD /O2 /Ob2 /DNDEBUG
    C flags (Debug):             /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP /MDd /Zi /Ob0 /Od /RTC1
    Linker flags (Release):      /machine:x64  /INCREMENTAL:NO
    Linker flags (Debug):        /machine:x64  /debug /INCREMENTAL
    ccache:                      NO
    Precompiled headers:         YES
    Extra dependencies:          cudart_static.lib nppc.lib nppial.lib nppicc.lib nppidei.lib nppif.lib nppig.lib nppim.lib nppist.lib nppisu.lib nppitc.lib npps.lib cublas.lib cudnn.lib cufft.lib -LIBPATH:C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1/lib/x64
    3rdparty dependencies:

  OpenCV modules:
    To be built:                 alphamat aruco barcode bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform java line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab viz wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto
    Disabled:                    world
    Disabled by dependency:      -
    Unavailable:                 cvv freetype hdf julia matlab ovis python2
    Applications:                tests perf_tests examples apps
    Documentation:               doxygen python javadoc
    Non-free algorithms:         YES

  Windows RT support:            NO

  GUI:                           WIN32UI
    Win32 UI:                    YES
    OpenGL support:              YES (opengl32 glu32)
    VTK support:                 YES (ver 9.2.5)

  Media I/O:
    ZLib:                        optimized C:/install/zlib/lib/zlib.lib debug C:/install/zlib/lib/zlibd.lib (ver 1.2.13)
    JPEG:                        build-libjpeg-turbo (ver 2.1.3-62)
      SIMD Support Request:      YES
      SIMD Support:              NO
    WEBP:                        build (ver encoder: 0x020f)
    PNG:                         optimized C:/install/libpng/lib/libpng16.lib debug C:/install/libpng/lib/libpng16d.lib (ver 1.6.40)
    TIFF:                        build (ver 42 - 4.2.0)
    JPEG 2000:                   build (ver 2.5.0)
    OpenEXR:                     build (ver 2.3.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:
    DC1394:                      NO
    FFMPEG:                      YES (prebuilt binaries)
      avcodec:                   YES (58.134.100)
      avformat:                  YES (58.76.100)
      avutil:                    YES (56.70.100)
      swscale:                   YES (5.9.100)
      avresample:                YES (4.0.0)
    GStreamer:                   NO
    DirectShow:                  YES
    Media Foundation:            YES
      DXVA:                      YES

  Parallel framework:            Concurrency

  Other third-party libraries:
    Intel IPP:                   2021.8 [2021.8.0]
           at:                   C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/icv
    Intel IPP IW:                sources (2021.8.0)
              at:                C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/iw
    Lapack:                      YES (C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_intel_lp64.lib C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_sequential.lib C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_core.lib)
    OpenVINO:                    YES (2022.3.0)
    Eigen:                       YES (ver ..)
    Custom HAL:                  NO
    Protobuf:                    build (3.19.1)
    Flatbuffers:                 builtin/3rdparty (23.5.9)
  NVIDIA CUDA:                   YES (ver 12.1, CUFFT CUBLAS)
    NVIDIA GPU arch:             86
    NVIDIA PTX archs:

  cuDNN:                         YES (ver 8.8.0)

  OpenCL:                        YES (NVD3D11)
    Include path:                C:/lib/opencv/3rdparty/include/opencl/1.2
    Link libraries:              Dynamic load

  Python 3:
    Interpreter:                 C:/Program Files/Python310/python.exe (ver 3.10.10)
    Libraries:                   optimized C:/Program Files/Python310/libs/python310.lib debug C:/Program Files/Python310/libs/python310_d.lib (ver 3.10.10)
    numpy:                       C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/numpy/core/include (ver 1.23.5)
    install path:                C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/cv2/python-3.10

  Python (for build):            C:/Program Files/Python310/python.exe

  Java:
    ant:                         C:/apache-ant-1.10.13/bin/ant.bat (ver 1.10.13)
    JNI:                         C:/Program Files/Java/jdk-19/include C:/Program Files/Java/jdk-19/include/win32 C:/Program Files/Java/jdk-19/include
    Java wrappers:               YES
    Java tests:                  YES

  Install to:                    C:/install/opencv
-----------------------------------------------------------------

### Detailed description


this code gives no error : 
import cv2 as cv

```
img_read = cv.imread(cv.samples.findFile(""lena.jpg""))
vid = cv.VideoCapture(cv.samples.findFile(""lena.jpg""))
ret, img_vid = vid.read()

print(""video open : "", img_vid[0, 0, :])
print(""imread : "", img_read[0, 0, :])

```
and results are not equal because ffmpeg uses its own jpeg decoder

```
video open :  [127 137 224]
imread :  [128 138 225]
```

So I want to use imread I add [apipreference ](https://github.com/opencv/opencv/issues/19740#issuecomment-801449114)[CAP_IMAGES](https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html#ga023786be1ee68a9105bf2e48c700294d)

```
import cv2 as cv

vid = cv.VideoCapture(cv.samples.findFile(""lena.jpg""), cv.CAP_IMAGES)


```
and there is an exception : 

```
Exception 
[ WARN:0@0.088] global samples.cpp:61 cv::samples::findFile cv::samples::findFile('lena.jpg') => 'C:\\lib\\opencv\\samples/data\\lena.jpg'
[ERROR:0@0.088] global cap.cpp:166 cv::VideoCapture::open VIDEOIO(CV_IMAGES): raised OpenCV exception:

OpenCV(4.7.0-dev) C:\\lib\\opencv\\modules\\videoio\\src\\cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): C:\\lib\\opencv\\samples/data\\lena.jpg in function 'cv::icvExtractPattern'


[ WARN:0@0.088] global cap.cpp:206 cv::VideoCapture::open VIDEOIO(CV_IMAGES): backend is generally available but can't be used to capture by name
```
Many example in DNN module uses VideoCapture.Open to read a file
Inference with VideoCapture.Open and imread do not give same results. 




### Steps to reproduce

Same problem in C++
All codes is already given

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-10 21:01:22,bug,Type stubs: `cv2.typing` type aliases don't exist at runtime but are not marked as such,"### System Information

OpenCV python: opencv_python_headless-4.7.0+772599a-cp37-abi3-win_amd64.whl
Operating System / Platform: 10.0.19045 Build 19045
Python version: 3.9.13

### Detailed description

Trying to use `cv2.typing.anything` at runtime will throw an `AttributeError` (ie: `AttributeError: module 'cv2.typing' has no attribute 'MatLike'`). The details of when that's the case will depend on the python version and its annotations parser.

This makes the `cv2.typing` module dangerous to use, because static type checkers will find its use acceptable.

The `@typing.type_check_only` decorator exists for those exact cases, but unfortunately can't be used with type aliases.

There's a couple possible solutions for this, here's some I can think of:
1. Make them exist at runtime. This could be as simple as creating a `cv2/typing/__init__.py` where all the values are assigned the type (but without generic typing to support python < 3.9). This has the added bonus of making them runtime-comparable using `isinstance`.
2. Use classes instead of type aliases that inherits from the aliased type. Those classes can now be marked as `type_check_only`.
3. Use `typeshed`'s workaround of making them private. Not great imo but at least is serves as a reminder for users that these don't exist at runtime. 

### Steps to reproduce

Here's a example that fails in python 3.9. An older version like 3.6-3.7 would have more cases.

```py
from typing import cast
import cv2.typing

# Let's pretend this came from a method that returns a MatLike, but isn't typed correctly
foo = object()
bar = cast(cv2.typing.MatLike, foo)
```

```
Traceback (most recent call last):
  File ""c:\\Users\\Avasam\\Desktop\\import cv2.py"", line 6, in <module>
    bar = cast(cv2.typing.MatLike, foo)
AttributeError: module 'cv2.typing' has no attribute 'MatLike' 
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-10 19:52:11,bug,Type stubs: Slicing a `cv2.mat_wrapper.Mat` or derived type results in partially unknown `ndarray`,"### System Information

OpenCV python: opencv_python_headless-4.7.0+772599a-cp37-abi3-win_amd64.whl
Operating System / Platform: 10.0.19045 Build 19045
Python version: 3.9.13

### Detailed description

pyright uses a special `Unknown` type to represent, well, unknown type, types that can't be inferred, unspecified Generic types, etc. It is semantically different than `Any` (which means literally any type is valid, or used as an escape hatch). This results in type errors when using strict typing.

mypy does not separate that concept and simply infers `Any` when type information is loss or unspecified.

### Steps to reproduce

```py
import cv2.mat_wrapper
import cv2.typing

# Using casts to simplify for static typing testing purposes
mat_like = cast(cv2.typing.MatLike, object())
mat = cast(cv2.mat_wrapper.Mat, object())

# Type of ""mat_like_sliced"" is partially unknown
#   Type of ""mat_like_sliced"" is ""ndarray[Any, Unknown] | ndarray[Any, dtype[generic]]"" Pylance(reportUnknownVariableType)
mat_like_sliced = mat_like[:, :, 3]
# Type of ""mat_sliced"" is partially unknown
#   Type of ""mat_sliced"" is ""ndarray[Any, Unknown]"" Pylance(reportUnknownVariableType)
mat_sliced = mat[:, :, 3]
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-10 18:49:34,bug,Type stubs: `cv2.__init__.pyi` is missing module re-exports,"### System Information

OpenCV python: opencv_python_headless-4.7.0+772599a-cp37-abi3-win_amd64.whl
Operating System / Platform: 10.0.19045 Build 19045
Python version: 3.9.13

### Detailed description

`cv2.__init__.pyi` is missing module re-exports, which should look something like this:
```py 
from cv2 import aruco as aruco
from cv2 import cuda as cuda
from cv2 import data as data
from cv2 import detail as detail
from cv2 import dnn as dnn
from cv2 import Error as Error
from cv2 import fisheye as fisheye
from cv2 import flann as flann
from cv2 import gapi as gapi
from cv2 import ipp as ipp
from cv2 import mat_wrapper as mat_wrapper
from cv2 import misc as misc
from cv2 import ml as ml
from cv2 import ocl as ocl
from cv2 import ogl as ogl
from cv2 import parallel as parallel
from cv2 import samples as samples
from cv2 import segmentation as segmentation
from cv2 import typing as typing
from cv2 import utils as utils
from cv2 import videoio_registry as videoio_registry
```

### Steps to reproduce

The following should be acceptable to static type checkers, but is not:
```py
import cv2

# Argument type is unknown
#  Argument corresponds to parameter ""values"" in function ""print""PylancereportUnknownArgumentType
# ""cuda"" is not a known member of module ""cv2""PylancereportGeneralTypeIssues
# (function) cuda: Unknown
print(cv2.Error)
```

```py
>>> import cv2
>>> cv2.Error.StsOk
0
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-09 13:44:51,bug,converto value,"### System Information

OpenCV version: 4.7.0
Operating System / windows
Compiler & compiler version: GCC 12
simple function frame1.convertTo(frame1, CV_32F, 1.0/255); 
from input value 142.0 give me 0.5566
But real value must be something like this 
```
    float value = 142.0 / 255.0;
    printf(""%.10f\\n"", value); // Display 10 decimal places
    printf(""%.4f\\n"", value);  // Display 4 decimal places
0.5568627715
0.5569
0.556863
```

### Detailed description

not correct value from function  

### Steps to reproduce

input value 142
frame1.convertTo(frame1, CV_32F, 1.0/255); 


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-08 14:12:17,bug,Python Scalar is different with C++,"Hi,
I suspect the following code has different behavior in C++ and Python.
```py
Scalar a = 1.0;
```

For Python, the `Scalar a = 1.0` code will only replace the first `0.0` to `1.0`.
Do something like `a[0] = 1.0`.
For C++, it will do the `Scalar a = Scalar(1.0)`.

Original link: https://forum.opencv.org/t/image2blobparams-c-and-python/13437?u=zihao_mu
My code in python :
```py
paramTF2cedn = cv.dnn.Image2BlobParams()
paramTF2cedn.datalayout = cv.dnn.DNN_LAYOUT_NHWC;
paramTF2cedn.ddepth = cv.CV_32F;
paramTF2cedn.mean = (128, 128, 128)
paramTF2cedn.scalefactor = 1 / 128.
paramTF2cedn.size = (224, 224)
paramTF2cedn.swapRB = False;
paramTF2cedn.paddingmode = cv.dnn.DNN_PMODE_NULL
print(""paramTF2cedn.scalefactor = "", paramTF2cedn.scalefactor)
```
result is
```paramTF2cedn.scalefactor = (0.0078125, 1.0, 1.0, 1.0)```

in C++
```cpp
Image2BlobParams paramTF2cedn;
paramTF2cedn.datalayout = DNN_LAYOUT_NHWC;
paramTF2cedn.ddepth = CV_32F;
paramTF2cedn.mean = (128, 128, 128);
paramTF2cedn.scalefactor = 1 / 128.;
paramTF2cedn.size = Size(224, 224);
paramTF2cedn.swapRB = false;
paramTF2cedn.paddingmode = DNN_PMODE_NULL;
cout << ""paramTF2cedn.scalefactor = "" << paramTF2cedn.scalefactor << endl;
```
result is
```paramTF2cedn.scalefactor = [0.0078125, 0, 0, 0]```

### Detailed description

It is about opencv-python bing.

### Steps to reproduce


install lastest opencv-python

`pip install opencv-python-rolling==4.7.0.20230603`.

```py
param = cv.dnn.Image2BlobParams()
param.mean = np.array([0.2, 0.3, 0.4]) # [0.2, 0.3, 0.4, 0.0]
# then redefine it.
param.mean = 1.0 # it is [1.0, 0.3, 0.4, 0.0]  <<--
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-07 14:44:06,bug,G-API: OpenVINO Backend Hotfix,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-06 17:08:17,bug,Keep inliers for linear remap with BORDER_TRANSPARENT,"### Pull Request Readiness Checklist

resolves https://github.com/opencv/opencv/issues/23562

I do think that this is a bug because with `INTER_CUBIC + BORDER_TRANSPARENT` the last column and row are preserved. So same should be done for `INTER_LINEAR`

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-05 20:09:33,bug, imgproc/cvtColor: fixed invalid read in BGR2HLS,"related PR #22520

* `mhls3` is read outside of array `interTmpM` (3 elements), it is not used anywhere
* ~replacing `max_nlanes` with `vlanes` for array size is still in question, I think it should be OK~ It was not OK :smiley: "
opencv/opencv,2023-06-05 05:50:46,bug,FaceRecognizerSF.feature C++ throws vector subscript out of range,"### System Information

OpenCV version: 4.7.0
Operating System / Platform: Windows 11
Compiler & compiler version: Clang 15.0.1

### Detailed description

the bug is on this line
```
cv::Mat feature1, feature2;

fr->feature(aligned_face1, feature1); // throws an exception vector subscript out of range
feature1 = feature1.clone();
```
of this code
```
#include<iostream>
#include<opencv2/imgcodecs.hpp>
#include<opencv2/highgui.hpp>
#include<opencv2/imgproc.hpp>
#include<opencv2/objdetect.hpp>
#include<opencv2/core/utils/logger.hpp>

#define IS_COSINE_SIMILAR(cosine) (cosine >= 0.363)
#define IS_L2_SIMILAR(norm) (norm <= 1.128)

char const* fd_model = ""D:/Codding/face_detection_yunet_2022mar.onnx"";
char const* fr_model = ""D:/Codding/face_recognition_sface_2021dec.onnx"";
double scale = 1.2;

static
void visualize(cv::Mat& input, cv::Mat& faces, int thickness = 2)
{
    for (int i = 0; i < faces.rows; i++)
    {
        // Draw bounding box
        cv::rectangle(input, cv::Rect2i(int(faces.at<float>(i, 0)), int(faces.at<float>(i, 1)), int(faces.at<float>(i, 2)), int(faces.at<float>(i, 3))), cv::Scalar(0, 255, 0), thickness);
        // Draw landmarks
        cv::circle(input, cv::Point2i(int(faces.at<float>(i, 4)), int(faces.at<float>(i, 5))), 2, cv::Scalar(255, 0, 0), thickness);
        cv::circle(input, cv::Point2i(int(faces.at<float>(i, 6)), int(faces.at<float>(i, 7))), 2, cv::Scalar(0, 0, 255), thickness);
        cv::circle(input, cv::Point2i(int(faces.at<float>(i, 8)), int(faces.at<float>(i, 9))), 2, cv::Scalar(0, 255, 0), thickness);
        cv::circle(input, cv::Point2i(int(faces.at<float>(i, 10)), int(faces.at<float>(i, 11))), 2, cv::Scalar(255, 0, 255), thickness);
        cv::circle(input, cv::Point2i(int(faces.at<float>(i, 12)), int(faces.at<float>(i, 13))), 2, cv::Scalar(0, 255, 255), thickness);
    }
}

int main()
{
    // then set logging to silent
    cv::utils::logging::setLogLevel(cv::utils::logging::LogLevel::LOG_LEVEL_SILENT);

    cv::VideoCapture capture(0);
    if (!capture.isOpened())
    {
        std::cerr << ""FATAL ERROR: cannot open capture device!\\n"";
        return EXIT_FAILURE;
    }
    cv::Size img_size(int(capture.get(cv::CAP_PROP_FRAME_WIDTH) * scale), int(capture.get(cv::CAP_PROP_FRAME_HEIGHT) * scale));

    cv::Ptr<cv::FaceDetectorYN> fd = cv::FaceDetectorYN::create(fd_model, """", img_size);
    cv::Ptr<cv::FaceRecognizerSF> fr = cv::FaceRecognizerSF::create(fr_model, """");

    cv::Mat img1, img2, capImg1, capImg2;
    capture.read(capImg1);
    capture.read(capImg2);

    cv::resize(capImg1, img1, img_size);
    cv::resize(capImg2, img2, img_size);

    cv::Mat faces1, faces2, debug1 = img1.clone(), debug2 = img2.clone();
    fd->detect(img1, faces1);
    if (faces1.rows < 1)
    {
        std::cerr << ""FATAL ERROR: cannot find a face on owner image!\\n"";
        return EXIT_FAILURE;
    }

    fd->detect(img2, faces2);
    if (faces1.rows < 1)
    {
        std::cerr << ""FATAL ERROR: cannot find a face on webcam!\\n"";
        return EXIT_FAILURE;
    }

    visualize(debug1, faces1);
    visualize(debug2, faces2);

    cv::imshow(""Face1"", debug1);
    cv::imshow(""Face2"", debug2);
    cv::waitKey(5000);

    cv::Mat aligned_face1, aligned_face2;
    fr->alignCrop(img1, faces1.row(0), aligned_face1);
    fr->alignCrop(img2, faces2.row(0), aligned_face2);
    std::cout << ""aligned size - "" << aligned_face1.size() << '/' << aligned_face2.size() << '\\n';

    cv::imshow(""Aligned1"", aligned_face1);
    cv::imshow(""Aligned2"", aligned_face2);
    cv::waitKey(3000);

    cv::Mat feature1, feature2;

    fr->feature(aligned_face1, feature1);
    feature1 = feature1.clone();
    fr->feature(aligned_face2, feature2);
    feature2 = feature2.clone();

    double cos_score = fr->match(feature1, feature2, cv::FaceRecognizerSF::DisType::FR_COSINE);

    std::cout << ""score - "" << cos_score << "", is same - "" << IS_COSINE_SIMILAR(cos_score) << ""\\n"";

    return EXIT_SUCCESS;
}
```

### Steps to reproduce

i've checked all your FaceRecognizerSF related issues and i haven't found any solution, do i also need to provide some additional info?
![image_2023-06-05_084517884](https://github.com/opencv/opencv/assets/120710838/f42a1824-928a-44ba-b221-92e22bc7f1cc)

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [x] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-03 12:59:12,bug,opencv.js: QR code test failure,"https://pullrequest.opencv.org/buildbot/builders/4_x_javascript-emscripten-lin64/builds/100401

relates #23264

```
│ QR code detect and decode │ Died on test #1: Cannot construct QRCodeDetector due to unbound types: N2cv18QRCodeDetectorBaseE                                    │ fail   │
│                           │     at Object.global.test.QUnit.test (/build/4_x_javascript-emscripten-lin64/build/bin/node_modules/node-qunit/lib/child.js:132:17) │        │
│                           │     at Object.<anonymous> (/build/4_x_javascript-emscripten-lin64/build/bin/test_objdetect.js:162:7)                                │        │
│                           │     at Module._compile (module.js:653:30)                                                                                           │        │
│                           │     at Object.Module._extensions..js (module.js:664:10)                                                                             │        │
│                           │     at Module.load (module.js:566:32)                                                                                               │        │
│                           │     at tryModuleLoad (module.js:506:12)                                                                                             │        │
│                           │     at Function.Module._load (module.js:498:3)     
```"
opencv/opencv,2023-06-02 12:50:21,bug,how using open cv to maui net,"### System Information

how using open cv to maui net

### Detailed description

how using open cv to maui net

### Steps to reproduce

how using open cv to maui net

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-01 07:54:04,bug,"opencv.js missing ArucoDetector, GridBoard, CharucoBoard","### System Information

opencv.js version: 4.7.0
official build from https://github.com/opencv/opencv/releases/download/4.7.0/opencv-docs-4.7.0.zip


### Detailed description

The classes ArucoDetector, GridBoard, and CharucoBoard, are not available in the opencv.js, despite being whitelisted in the opencv_js.config.py config file:
https://github.com/opencv/opencv/blob/725e440d278aca07d35a5e8963ef990572b07316/platforms/js/opencv_js.config.py#L115
https://github.com/opencv/opencv/blob/725e440d278aca07d35a5e8963ef990572b07316/platforms/js/opencv_js.config.py#L116
https://github.com/opencv/opencv/blob/725e440d278aca07d35a5e8963ef990572b07316/platforms/js/opencv_js.config.py#L117

Tests for such classes are also missing https://github.com/opencv/opencv/blob/master/modules/js/test/test_objdetect.js

Thanks

### Steps to reproduce

Using node.JS code:
```
require('./opencv.js').then((cv)=>{
  console.log(cv.getBuildInformation()); // correctly show build informations
  let detector = new cv.ArucoDetector(); // generate runtime error of missing ArucoDetector constructor
});
```
output:
```
General configuration for OpenCV 4.7.0 =====================================
  Version control:               4.7.0

  Platform:
    Timestamp:                   2022-12-28T15:20:23Z
    Host:                        Linux 5.15.0-56-generic x86_64
    Target:                      Emscripten 1 x86
    CMake:                       3.10.2
    CMake generator:             Unix Makefiles
    CMake build tool:            /usr/bin/make
    Configuration:               Release

  CPU/HW features:
    Baseline:

  C/C++:
    Built as dynamic libs?:      NO
    C++ standard:                11
    C++ Compiler:                /opt/emsdk-portable/upstream/emscripten/em++  (ver 10.0.0)
    C++ flags (Release):         -s USE_PTHREADS=0    -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winconsistent-missing-override -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -ffunction-sections -fdata-sections 
 -fvisibility=hidden -fvisibility-inlines-hidden -DNDEBUG -O2  -DNDEBUG
    C++ flags (Debug):           -s USE_PTHREADS=0    -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winconsistent-missing-override -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -ffunction-sections -fdata-sections 
 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG
    C Compiler:                  /opt/emsdk-portable/upstream/emscripten/emcc
    C flags (Release):           -s USE_PTHREADS=0    -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winconsistent-missing-override -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -ffunction-sections -fdata-sections 
 -fvisibility=hidden -fvisibility-inlines-hidden -DNDEBUG -O2  -DNDEBUG
    C flags (Debug):             -s USE_PTHREADS=0    -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winconsistent-missing-override -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Qunused-arguments -ffunction-sections -fdata-sections 
 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG
    Linker flags (Release):      -Wl,--gc-sections -Wl,--no-undefined -O2
    Linker flags (Debug):        -Wl,--gc-sections -Wl,--no-undefined
    ccache:                      NO
    Precompiled headers:         NO
    Extra dependencies:
    3rdparty dependencies:       zlib libprotobuf quirc

  OpenCV modules:
    To be built:                 calib3d core dnn features2d flann imgproc js objdetect photo video
    Disabled:                    highgui imgcodecs ml stitching videoio world
    Disabled by dependency:      ts
    Unavailable:                 gapi java python2 python3
    Applications:                examples
    Documentation:               js
    Non-free algorithms:         NO

  GUI:

  Media I/O:
    ZLib:                        build (ver 1.2.13)
    JPEG 2000:                   build (ver 2.4.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:

  Parallel framework:            none

  Other third-party libraries:
    VA:                          NO
    Custom HAL:                  NO
    Protobuf:                    build (3.19.1)

  Python (for build):            /usr/bin/python

  Install to:                    /usr/local
-----------------------------------------------------------------


RuntimeError: abort(TypeError: cv.ArucoDetector is not a constructor)
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-28 13:54:06,bug,Generation of getter and setter for the DetectorParameters.cornerRefinementMethod property is skipped during Java wrapper generation.,"### System Information

OpenCV version: 4.7.0
Operating System / Platform: Windows 10 22H2
Compiler & compiler version: CMake 3.24.3

### Detailed description

The creation of the get_cornerRefinementMethod() and set_cornerRefinementMethod (int cornerRefinementMethod) methods are skipped when the Java wrapper is generated. This problem has occurred since opencv 4.7.0. It appears that opencv4.6.0 and opencv4.7.0 have changed the type of the cornerRefinementMethod variable.

opencv4.6.0
https://github.com/opencv/opencv_contrib/blob/4.6.0/modules/aruco/include/opencv2/aruco.hpp#L185
opencv4.7.0
https://github.com/opencv/opencv/blob/4.7.0/modules/objdetect/include/opencv2/objdetect/aruco_detector.hpp#L109

The following code is the Java code generated for each of these versions.

opencv4.6.0
```
    //
    // C++: int DetectorParameters::cornerRefinementMethod
    //

    public int get_cornerRefinementMethod() {
        return get_cornerRefinementMethod_0(nativeObj);
    }


    //
    // C++: void DetectorParameters::cornerRefinementMethod
    //

    public void set_cornerRefinementMethod(int cornerRefinementMethod) {
        set_cornerRefinementMethod_0(nativeObj, cornerRefinementMethod);
    }
```

opencv4.7.0
```
    //
    // C++: CornerRefineMethod DetectorParameters::cornerRefinementMethod
    //

    // Return type 'CornerRefineMethod' is not supported, skipping the function


    //
    // C++: void DetectorParameters::cornerRefinementMethod
    //

    // Unknown type 'CornerRefineMethod' (I), skipping the function
```

### Steps to reproduce

Build with the BUILD_opencv_java_bindings_generator flag ON.

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [x] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-25 20:05:45,bug,Python binding for cuda::GpuMat does not handle float16 properly when downloading to or uploading from a NumPy array,"### System Information

OpenCV python version: 4.7.0.72 with OpenCV 87331ca built with Cuda 11.8
Operating System / Platform: Ubuntu 22.04
Python version: 3.10.8

### Detailed description

Trying to upload a float16 NumPy array to a GpuMat gives an `arr data type = 23 is not supported` error. While trying to download from a float16 GpuMat gives a uint64 NumPy array with garbage content. The test case below shows that float16 CuPy and GpuMat interoperability appears to work fine. Here's the full output log to the code from ""Steps to reproduce"":

```
Original CuPy array and pointer
[[2. 3.]
 [2. 3.]] 140353891991552


GpuMat, initialized and downloaded to NumPy; and pointer
[[140356343578624  94720260377824]
 [     1107312640             260]] 140353891991552
Assert GpuMat type is float16: True
NumPy dtype: uint64

Back to CuPy from GpuMat: value and pointer:
[[2. 3.]
 [2. 3.]] 140353891991552

Now try to upload a float16 NumPy array to GpuMat:
Traceback (most recent call last):
  File ""***/tst_cupy_to_mat.py"", line 75, in <module>
    cv_a.upload(np_a)
cv2.error: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'upload'
> Overload resolution failed:
>  - arr data type = 23 is not supported
>  - Expected Ptr<cv::cuda::GpuMat> for argument 'arr'
>  - Expected Ptr<cv::UMat> for argument 'arr'
>  - cuda_GpuMat.upload() missing required argument 'stream' (pos 2)
>  - cuda_GpuMat.upload() missing required argument 'stream' (pos 2)
>  - cuda_GpuMat.upload() missing required argument 'stream' (pos 2)
```

### Steps to reproduce

```python
import cupy as cp
import numpy as np
import cv2


def cv2cp(mat: cv2.cuda.GpuMat) -> cp.ndarray:
    class CudaArrayInterface:
        def __init__(self, gpu_mat: cv2.cuda.GpuMat):
            w, h = gpu_mat.size()
            type_map = {
                cv2.CV_8U: ""|u1"",
                cv2.CV_8S: ""|i1"",
                cv2.CV_16U: ""<u2"", cv2.CV_16S: ""<i2"",
                cv2.CV_32S: ""<i4"",
                cv2.CV_32F: ""<f4"", cv2.CV_64F: ""<f8"",
                cv2.CV_16F: ""<f2""
            }
            self.__cuda_array_interface__ = {
                ""version"": 3,
                ""shape"": (h, w, gpu_mat.channels()) if gpu_mat.channels() > 1 else (h, w),
                ""typestr"": type_map[gpu_mat.depth()],
                ""descr"": [("""", type_map[gpu_mat.depth()])],
                ""stream"": 1,
                ""strides"": (gpu_mat.step, gpu_mat.elemSize(), gpu_mat.elemSize1()) if gpu_mat.channels() > 1
                else (gpu_mat.step, gpu_mat.elemSize()),
                ""data"": (gpu_mat.cudaPtr(), False),
            }
    arr = cp.asarray(CudaArrayInterface(mat))

    return arr


def cp2cv(arr: cp.ndarray) -> cv2.cuda.GpuMat:
    assert len(arr.shape) in (2, 3), ""CuPy array must have 2 or 3 dimensions to be a valid GpuMat""
    type_map = {
        cp.dtype('uint8'): cv2.CV_8U,
        cp.dtype('int8'): cv2.CV_8S,
        cp.dtype('uint16'): cv2.CV_16U,
        cp.dtype('int16'): cv2.CV_16S,
        cp.dtype('int32'): cv2.CV_32S,
        cp.dtype('float32'): cv2.CV_32F,
        cp.dtype('float64'): cv2.CV_64F,
        cp.dtype('float16'): cv2.CV_16F
    }
    depth = type_map.get(arr.dtype)
    assert depth is not None, ""Unsupported CuPy array dtype""
    channels = 1 if len(arr.shape) == 2 else arr.shape[2]
    mat_type = cv2.CV_MAKETYPE(depth, channels)
    mat = cv2.cuda.createGpuMatFromCudaMemory(arr.__cuda_array_interface__['shape'][1::-1],
                                              mat_type,
                                              arr.__cuda_array_interface__['data'][0])
    return mat


cp_a = cp.random.randint(1, 5, (2, 2)).astype(np.float16)
print('Original CuPy array and pointer')
print(cp_a, cp_a.__cuda_array_interface__['data'][0])
print('')
cv_a = cp2cv(cp_a)
np_a = cv_a.download()
print('')
print('GpuMat, initialized and downloaded to NumPy; and pointer')
print(np_a, cv_a.cudaPtr())
print(f'Assert GpuMat type is float16: {cv_a.type() == cv2.CV_16FC1}')
print('NumPy dtype:', np_a.dtype)
print('')
cp_a2 = cv2cp(cv_a)
print('Back to CuPy from GpuMat: value and pointer:')
print(cp_a2, cp_a2.__cuda_array_interface__['data'][0])
print('')

print('Now try to upload a float16 NumPy array to GpuMat:')
np_a = np.random.randint(1, 5, (2, 2)).astype(np.float16)
cv_a = cv2.cuda_GpuMat()
cv_a.upload(np_a)
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-24 13:59:05,bug,"DNN: fix potential bug, stride should not be set as 0.","### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-23 08:25:10,bug," No rule to make target 'cublas', needed by 'lib/libopencv_sfm.so.4.5.2'.","### System Information

I Use ubuntu 20.04
I have cuda 11.2
I have cuDNN version 8.1.0


### Detailed description

I'm trying to install opencv 4.5.2 with cuda 11.2 and cuDNN 8.1.0 but I'm having a problem with that and it's as follows
```
(AIenv) ai@ai:~/nvidia/opencv-4.5.2/build$ make -j20
-- Detected processor: x86_64
-- Looking for ccache - not found
-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found suitable version ""1.2.11"", minimum required is ""1.2.3"")  
Cleaning INTERNAL cached variable: WEBP_LIBRARY
Cleaning INTERNAL cached variable: WEBP_INCLUDE_DIR
-- Could NOT find OpenJPEG (minimal suitable version: 2.0, recommended version >= 2.3.1). OpenJPEG will be built from sources
-- OpenJPEG: VERSION = 2.4.0, BUILD = opencv-4.5.2-openjp2-2.4.0
-- OpenJPEG libraries will be built from sources: libopenjp2 (version ""2.4.0"")
-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version ""1.2.11"")  
-- Found OpenEXR: /usr/lib/x86_64-linux-gnu/libIlmImf.so
-- Found TBB (cmake): /usr/lib/x86_64-linux-gnu/libtbb.so.2
-- found Intel IPP (ICV version): 2020.0.0 [2020.0.0 Gold]
-- at: /home/ai/nvidia/opencv-4.5.2/build/3rdparty/ippicv/ippicv_lnx/icv
-- found Intel IPP Integration Wrappers sources: 2020.0.0
-- at: /home/ai/nvidia/opencv-4.5.2/build/3rdparty/ippicv/ippicv_lnx/iw
-- CUDA detected: 11.2
-- CUDA: Using CUDA_ARCH_BIN=8.6
-- CUDA NVCC target flags: -gencode;arch=compute_86,code=sm_86;-D_FORCE_INLINES
-- LAPACK(Atlas): LAPACK_LIBRARIES: /usr/lib/x86_64-linux-gnu/liblapack.so;/usr/lib/x86_64-linux-gnu/libcblas.so;/usr/lib/x86_64-linux-gnu/libatlas.so
-- LAPACK(Atlas): Support is enabled.
-- Could NOT find JNI (missing: JAVA_INCLUDE_PATH JAVA_INCLUDE_PATH2 AWT) 
-- VTK is not found. Please set -DVTK_DIR in CMake to VTK build directory, or to VTK install subdirectory with VTKConfig.cmake file
-- OpenCV Python: during development append to PYTHONPATH: /home/ai/nvidia/opencv-4.5.2/build/python_loader
-- Caffe:   NO
-- Protobuf:   NO
-- Glog:   YES
-- freetype2:   YES (ver 23.1.17)
-- harfbuzz:    YES (ver 2.6.4)
-- HDF5 C compiler wrapper is unable to compile a minimal HDF5 program.
-- Julia not found. Not compiling Julia Bindings. 
-- Module opencv_ovis disabled because OGRE3D was not found
-- Found AMD headers in: /usr/include/suitesparse
-- Found AMD library: /usr/lib/x86_64-linux-gnu/libamd.so
-- Found CAMD headers in: /usr/include/suitesparse
-- Found CAMD library: /usr/lib/x86_64-linux-gnu/libcamd.so
-- Found CCOLAMD headers in: /usr/include/suitesparse
-- Found CCOLAMD library: /usr/lib/x86_64-linux-gnu/libccolamd.so
-- Found CHOLMOD headers in: /usr/include/suitesparse
-- Found CHOLMOD library: /usr/lib/x86_64-linux-gnu/libcholmod.so
-- Found COLAMD headers in: /usr/include/suitesparse
-- Found COLAMD library: /usr/lib/x86_64-linux-gnu/libcolamd.so
-- Found SPQR headers in: /usr/include/suitesparse
-- Found SPQR library: /usr/lib/x86_64-linux-gnu/libspqr.so
-- Found Config headers in: /usr/include/suitesparse
-- Found Config library: /usr/lib/x86_64-linux-gnu/libsuitesparseconfig.so
-- Found Intel Thread Building Blocks (TBB) library (2020.1 / 11101) include location: . Assuming SuiteSparseQR was compiled with TBB.
-- Adding librt to SuiteSparse_config libraries (required on Linux & Unix [not OSX] if SuiteSparse is compiled with timing).
-- Could NOT find METIS (missing: METIS_INCLUDE_DIR METIS_LIBRARY) 
-- Tesseract:   YES (ver 4.1.1)
-- Allocator metrics storage type: 'long long'
-- HDF5 C compiler wrapper is unable to compile a minimal HDF5 program.
-- Registering hook 'INIT_MODULE_SOURCES_opencv_dnn': /home/ai/nvidia/opencv-4.5.2/modules/dnn/cmake/hooks/INIT_MODULE_SOURCES_opencv_dnn.cmake
-- Found AMD headers in: /usr/include/suitesparse
-- Found AMD library: /usr/lib/x86_64-linux-gnu/libamd.so
-- Found CAMD headers in: /usr/include/suitesparse
-- Found CAMD library: /usr/lib/x86_64-linux-gnu/libcamd.so
-- Found CCOLAMD headers in: /usr/include/suitesparse
-- Found CCOLAMD library: /usr/lib/x86_64-linux-gnu/libccolamd.so
-- Found CHOLMOD headers in: /usr/include/suitesparse
-- Found CHOLMOD library: /usr/lib/x86_64-linux-gnu/libcholmod.so
-- Found COLAMD headers in: /usr/include/suitesparse
-- Found COLAMD library: /usr/lib/x86_64-linux-gnu/libcolamd.so
-- Found SPQR headers in: /usr/include/suitesparse
-- Found SPQR library: /usr/lib/x86_64-linux-gnu/libspqr.so
-- Found Config headers in: /usr/include/suitesparse
-- Found Config library: /usr/lib/x86_64-linux-gnu/libsuitesparseconfig.so
-- Found Intel Thread Building Blocks (TBB) library (2020.1 / 11101) include location: . Assuming SuiteSparseQR was compiled with TBB.
-- Adding librt to SuiteSparse_config libraries (required on Linux & Unix [not OSX] if SuiteSparse is compiled with timing).
-- Could NOT find METIS (missing: METIS_INCLUDE_DIR METIS_LIBRARY) 
-- Building with NVIDIA Optical Flow API 2.0
-- 
-- General configuration for OpenCV 4.5.2 =====================================
--   Version control:               unknown
-- 
--   Extra modules:
--     Location (extra):            /home/ai/nvidia/opencv_contrib-4.5.2/modules
--     Version control (extra):     unknown
-- 
--   Platform:
--     Timestamp:                   2023-05-21T12:21:47Z
--     Host:                        Linux 5.15.0-72-generic x86_64
--     CMake:                       3.26.0
--     CMake generator:             Unix Makefiles
--     CMake build tool:            /usr/bin/make
--     Configuration:               RELEASE
-- 
--   CPU/HW features:
--     Baseline:                    SSE SSE2 SSE3
--       requested:                 SSE3
--     Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX
--       requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
--       SSE4_1 (17 files):         + SSSE3 SSE4_1
--       SSE4_2 (2 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
--       FP16 (1 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
--       AVX (5 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX
--       AVX2 (31 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
--       AVX512_SKX (7 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX
-- 
--   C/C++:
--     Built as dynamic libs?:      YES
--     C++ standard:                11
--     C++ Compiler:                /usr/bin/c++  (ver 9.4.0)
--     C++ flags (Release):         -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG
--     C++ flags (Debug):           -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG
--     C Compiler:                  /usr/bin/cc
--     C flags (Release):           -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG
--     C flags (Debug):             -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG
--     Linker flags (Release):      -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a   -Wl,--gc-sections -Wl,--as-needed  
--     Linker flags (Debug):        -Wl,--exclude-libs,libippicv.a -Wl,--exclude-libs,libippiw.a   -Wl,--gc-sections -Wl,--as-needed  
--     ccache:                      NO
--     Precompiled headers:         NO
--     Extra dependencies:          m pthread cudart_static dl rt nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas cudnn cufft -L/usr/local/cuda-11.2/lib64 -L/usr/lib/x86_64-linux-gnu
--     3rdparty dependencies:
-- 
--   OpenCV modules:
--     To be built:                 alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann freetype fuzzy gapi hdf hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python2 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto
--     Disabled:                    cudacodec world
--     Disabled by dependency:      -
--     Unavailable:                 cnn_3dobj cvv java julia matlab ovis python3 viz
--     Applications:                tests perf_tests apps
--     Documentation:               NO
--     Non-free algorithms:         YES
-- 
--   GUI: 
--     GTK+:                        YES (ver 3.24.20)
--       GThread :                  YES (ver 2.64.6)
--       GtkGlExt:                  NO
--     OpenGL support:              NO
--     VTK support:                 NO
-- 
--   Media I/O: 
--     ZLib:                        /usr/lib/x86_64-linux-gnu/libz.so (ver 1.2.11)
--     JPEG:                        /usr/lib/x86_64-linux-gnu/libjpeg.so (ver 80)
--     WEBP:                        build (ver encoder: 0x020f)
--     PNG:                         /usr/lib/x86_64-linux-gnu/libpng.so (ver 1.6.37)
--     TIFF:                        /usr/lib/x86_64-linux-gnu/libtiff.so (ver 42 / 4.1.0)
--     JPEG 2000:                   build (ver 2.4.0)
--     OpenEXR:                     /usr/lib/x86_64-linux-gnu/libImath.so /usr/lib/x86_64-linux-gnu/libIlmImf.so /usr/lib/x86_64-linux-gnu/libIex.so /usr/lib/x86_64-linux-gnu/libHalf.so /usr/lib/x86_64-linux-gnu/libIlmThread.so (ver 2_3)
--     HDR:                         YES
--     SUNRASTER:                   YES
--     PXM:                         YES
--     PFM:                         YES
-- 
--   Video I/O:
--     DC1394:                      YES (2.2.5)
--     FFMPEG:                      YES
--       avcodec:                   YES (58.54.100)
--       avformat:                  YES (58.29.100)
--       avutil:                    YES (56.31.100)
--       swscale:                   YES (5.5.100)
--       avresample:                YES (4.0.0)
--     GStreamer:                   YES (1.16.3)
--     v4l/v4l2:                    YES (linux/videodev2.h)
-- 
--   Parallel framework:            TBB (ver 2020.1 interface 11101)
-- 
--   Trace:                         YES (with Intel ITT)
-- 
--   Other third-party libraries:
--     Intel IPP:                   2020.0.0 Gold [2020.0.0]
--            at:                   /home/ai/nvidia/opencv-4.5.2/build/3rdparty/ippicv/ippicv_lnx/icv
--     Intel IPP IW:                sources (2020.0.0)
--               at:                /home/ai/nvidia/opencv-4.5.2/build/3rdparty/ippicv/ippicv_lnx/iw
--     VA:                          YES
--     Lapack:                      YES (/usr/lib/x86_64-linux-gnu/liblapack.so /usr/lib/x86_64-linux-gnu/libcblas.so /usr/lib/x86_64-linux-gnu/libatlas.so)
--     Eigen:                       YES (ver 3.3.7)
--     Custom HAL:                  NO
--     Protobuf:                    build (3.5.1)
-- 
--   NVIDIA CUDA:                   YES (ver 11.2, CUFFT CUBLAS FAST_MATH)
--     NVIDIA GPU arch:             86
--     NVIDIA PTX archs:
-- 
--   cuDNN:                         YES (ver 8.1.0)
-- 
--   OpenCL:                        YES (INTELVA)
--     Include path:                /home/ai/nvidia/opencv-4.5.2/3rdparty/include/opencl/1.2
--     Link libraries:              Dynamic load
-- 
--   Python 2:
--     Interpreter:                 /usr/bin/python2.7 (ver 2.7.18)
--     Libraries:                   /usr/lib/x86_64-linux-gnu/libpython2.7.so (ver 2.7.18)
--     numpy:                       /usr/lib/python2.7/dist-packages/numpy/core/include (ver 1.16.5)
--     install path:                lib/python2.7/dist-packages/cv2/python-2.7
-- 
--   Python (for build):            /usr/bin/python2.7
-- 
--   Java:                          
--     ant:                         NO
--     JNI:                         NO
--     Java wrappers:               NO
--     Java tests:                  NO
-- 
--   Install to:                    /usr/local
-- -----------------------------------------------------------------
-- 
-- Configuring done (3.2s)
-- Generating done (0.9s)
-- Build files have been written to: /home/ai/nvidia/opencv-4.5.2/build
[  0%] Built target gen-pkgconfig
[  0%] Built target opencv_videoio_plugins
[  0%] Built target ittnotify
[  0%] Built target quirc
[  0%] Built target gen_opencv_python_source
[  0%] Built target numeric
[  1%] Built target ippiw
[  2%] Built target libopenjp2
[  2%] Built target ade
[  3%] Built target opencv_cudev
[  3%] Building CXX object modules/sfm/src/libmv/libmv/multiview/CMakeFiles/multiview.dir/fundamental.cc.o
[  3%] Building CXX object modules/sfm/src/libmv/libmv/multiview/CMakeFiles/multiview.dir/homography.cc.o
[  8%] Built target libwebp
[ 11%] Built target libprotobuf
[ 15%] Built target opencv_core
[ 15%] Built target opencv_hdf
[ 15%] Built target opencv_version
[ 15%] Built target opencv_flann
[ 15%] Built target opencv_surface_matching
[ 16%] Built target opencv_ml
[ 18%] Built target opencv_cudaarithm
[ 22%] Built target opencv_imgproc
[ 22%] Built target opencv_plot
[ 22%] Built target opencv_phase_unwrapping
[ 22%] Built target opencv_freetype
[ 22%] Built target opencv_quality
[ 22%] Built target opencv_intensity_transform
[ 22%] Built target opencv_fuzzy
[ 22%] Built target opencv_img_hash
[ 22%] Built target opencv_cudawarping
[ 22%] Built target opencv_alphamat
[ 23%] Built target opencv_hfs
[ 24%] Built target opencv_reg
[ 26%] Built target opencv_cudafilters
[ 27%] Built target opencv_imgcodecs
[ 29%] Built target opencv_features2d
[ 29%] Built target opencv_line_descriptor
[ 29%] Built target opencv_cudafeatures2d
[ 29%] Built target opencv_saliency
[ 29%] Built target opencv_videoio
[ 30%] Built target opencv_cudaimgproc
[ 30%] Built target opencv_highgui
[ 31%] Built target opencv_annotation
[ 31%] Built target opencv_visualisation
[ 32%] Built target opencv_photo
[ 33%] Built target opencv_ts
[ 34%] Built target opencv_bioinspired
[ 35%] Built target opencv_xphoto
[ 35%] Built target opencv_test_phase_unwrapping
[ 35%] Built target opencv_test_intensity_transform
[ 36%] Built target opencv_test_cudafilters
[ 36%] Built target opencv_test_hdf
[ 36%] Built target opencv_test_flann
[ 37%] Built target opencv_test_reg
[ 37%] Built target opencv_perf_reg
[ 37%] Built target opencv_perf_cudaarithm
[ 39%] Built target opencv_calib3d
[ 39%] Built target opencv_test_quality
[ 39%] Built target opencv_perf_cudafilters
[ 39%] Built target opencv_perf_cudawarping
[ 39%] Built target opencv_test_cudaarithm
[ 39%] Built target opencv_perf_imgcodecs
[ 39%] Built target opencv_test_cudawarping
[ 40%] Built target opencv_test_fuzzy
[ 40%] Built target opencv_perf_features2d
[ 41%] Built target opencv_test_ml
[ 41%] Built target opencv_test_img_hash
[ 42%] Built target opencv_perf_cudaimgproc
[ 42%] Built target opencv_test_line_descriptor
[ 42%] Built target opencv_test_cudaimgproc
[ 42%] Built target opencv_perf_line_descriptor
[ 43%] Built target opencv_test_imgcodecs
[ 43%] Built target opencv_test_saliency
[ 43%] Built target opencv_perf_photo
[ 48%] Built target opencv_dnn
[ 48%] Built target opencv_perf_videoio
[ 49%] Built target opencv_test_cudev
[ 49%] Built target opencv_test_cudafeatures2d
[ 49%] Built target opencv_perf_xphoto
[ 49%] Built target opencv_perf_cudafeatures2d
[ 49%] Built target opencv_test_highgui
[ 49%] Built target opencv_rapid
[ 49%] Built target opencv_test_photo
[ 50%] Built target opencv_test_features2d
[ 50%] Built target opencv_perf_calib3d
[ 50%] Built target opencv_test_xphoto
[ 50%] Built target opencv_structured_light
[ 50%] Built target opencv_test_videoio
[ 50%] Built target opencv_test_bioinspired
[ 50%] Built target opencv_cudastereo
[ 50%] Built target opencv_perf_bioinspired
[ 50%] Built target opencv_dnn_objdetect
[ 50%] Built target opencv_model_diagnostics
[ 50%] Built target opencv_aruco
[ 52%] Built target opencv_perf_core
[ 52%] Built target opencv_ccalib
[ 52%] Built target opencv_shape
[ 52%] Built target opencv_objdetect
[ 52%] Built target opencv_dnn_superres
[ 54%] Built target opencv_perf_imgproc
[ 54%] Built target opencv_perf_cudastereo
[ 54%] Built target opencv_test_rapid
[ 54%] Built target opencv_test_cudastereo
[ 55%] Built target opencv_text
[ 55%] Built target opencv_test_dnn_superres
[ 56%] Built target opencv_perf_dnn
[ 57%] Built target opencv_test_structured_light
[ 57%] Built target opencv_test_aruco
[ 57%] Built target opencv_perf_dnn_superres
[ 57%] Built target opencv_interactive-calibration
[ 57%] Built target opencv_test_shape
[ 57%] Built target opencv_test_objdetect
[ 57%] Built target opencv_perf_objdetect
[ 57%] Built target opencv_xobjdetect
[ 58%] Built target opencv_mcc
[ 58%] Built target opencv_test_text
[ 59%] Built target opencv_dpm
[ 60%] Built target opencv_test_dnn
[ 60%] Built target opencv_waldboost_detector
[ 60%] Built target opencv_test_mcc
[ 62%] Built target opencv_test_calib3d
[ 64%] Built target opencv_video
[ 64%] Built target opencv_rgbd
[ 64%] Built target opencv_face
[ 64%] Built target opencv_bgsegm
[ 66%] Built target opencv_wechat_qrcode
[ 66%] Built target opencv_cudabgsegm
[ 67%] Built target opencv_perf_rgbd
[ 68%] Built target opencv_datasets
[ 70%] Built target opencv_test_core
[ 70%] Built target opencv_test_bgsegm
[ 70%] Built target opencv_test_wechat_qrcode
[ 71%] Built target opencv_test_rgbd
[ 71%] Built target opencv_test_face
[ 73%] Built target opencv_xfeatures2d
[ 73%] Built target opencv_test_video
[ 74%] Built target opencv_perf_video
[ 74%] Built target opencv_perf_cudabgsegm
[ 74%] Built target opencv_test_cudabgsegm
[ 75%] Built target opencv_cudalegacy
[ 77%] Built target opencv_test_imgproc
[ 77%] Built target opencv_cudaobjdetect
[ 77%] Built target opencv_perf_cudalegacy
[ 77%] Built target opencv_test_cudaobjdetect
[ 77%] Built target opencv_perf_cudaobjdetect
[ 77%] Built target opencv_perf_xfeatures2d
[ 78%] Built target opencv_test_xfeatures2d
[ 79%] Built target opencv_stitching
[ 80%] Built target opencv_test_cudalegacy
[ 81%] Built target opencv_tracking
[ 81%] Built target opencv_perf_tracking
[ 81%] Built target opencv_stereo
[ 81%] Built target opencv_perf_stitching
[ 81%] Built target opencv_test_tracking
[ 81%] Built target opencv_test_stitching
[ 81%] Built target opencv_perf_stereo
[ 81%] Built target opencv_test_stereo
[ 82%] Built target opencv_ximgproc
[ 85%] Built target opencv_gapi
[ 87%] Built target opencv_perf_ximgproc
[ 87%] Built target opencv_optflow
[ 87%] Built target opencv_perf_optflow
[ 88%] Built target opencv_test_optflow
[ 89%] Built target opencv_cudaoptflow
[ 90%] Built target opencv_test_ximgproc
[ 91%] Built target opencv_perf_gapi
[ 91%] Built target opencv_test_cudaoptflow
[ 91%] Built target opencv_perf_cudaoptflow
[ 91%] Linking CXX shared library ../../lib/libopencv_superres.so
[ 91%] Linking CXX shared library ../../lib/libopencv_videostab.so
[ 94%] Built target opencv_test_gapi
[ 95%] Built target opencv_superres
[ 96%] Built target opencv_videostab
[ 96%] Building CXX object modules/superres/CMakeFiles/opencv_test_superres.dir/test/test_main.cpp.o
[ 96%] Building CXX object modules/superres/CMakeFiles/opencv_test_superres.dir/test/test_superres.cpp.o
[ 96%] Building CXX object modules/superres/CMakeFiles/opencv_perf_superres.dir/perf/perf_main.cpp.o
[ 96%] Building CXX object modules/superres/CMakeFiles/opencv_perf_superres.dir/perf/perf_superres.cpp.o
[ 96%] Building CXX object modules/videostab/CMakeFiles/opencv_test_videostab.dir/test/test_main.cpp.o
[ 96%] Building CXX object modules/videostab/CMakeFiles/opencv_test_videostab.dir/test/test_motion_estimation.cpp.o
[ 96%] Building CXX object modules/videostab/CMakeFiles/opencv_test_videostab.dir/test/test_stabilizer.cpp.o
[ 96%] Linking CXX executable ../../bin/opencv_test_superres
[ 96%] Built target opencv_test_superres
[ 96%] Linking CXX executable ../../bin/opencv_test_videostab
[ 96%] Built target opencv_test_videostab
[ 96%] Linking CXX executable ../../bin/opencv_perf_superres
[ 96%] Built target opencv_perf_superres
[ 96%] Linking CXX static library ../../../../../../lib/libmultiview.a
[ 96%] Built target multiview
[ 96%] Built target correspondence
[ 96%] Building CXX object modules/sfm/src/libmv/libmv/simple_pipeline/CMakeFiles/simple_pipeline.dir/bundle.cc.o
[ 96%] Building CXX object modules/sfm/src/libmv/libmv/simple_pipeline/CMakeFiles/simple_pipeline.dir/intersect.cc.o
[ 96%] Building CXX object modules/sfm/src/libmv/libmv/simple_pipeline/CMakeFiles/simple_pipeline.dir/keyframe_selection.cc.o
[ 97%] Linking CXX static library ../../../../../../lib/libsimple_pipeline.a
[ 97%] Built target simple_pipeline
make[2]: *** No rule to make target 'cublas', needed by 'lib/libopencv_sfm.so.4.5.2'.  Stop.
make[1]: *** [CMakeFiles/Makefile2:9007: modules/sfm/CMakeFiles/opencv_sfm.dir/all] Error 2
make: *** [Makefile:166: all] Error 2
```

Thanks for the help in advance

### Steps to reproduce

None

### Issue submission checklist

- [ ] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-22 09:34:34,bug,Build fix for AVX 256,"@zihaomu Our CI environment started failing after you merged this [commit](https://github.com/opencv/opencv/commit/5229312ad2a4fbf9a6abfd6490b265c39587e6f7). 

```
/build/build_cuda/3p/opencv/linux-x64/ubuntu22.04/Debug/modules/dnn/src/layers/cpu_kernels/convolution.cpp: In function 'void cv::dnn::packData8(char*&, float*&, int&, int&, int&, const int*, int, int, int)':
/build/build_cuda/3p/opencv/linux-x64/ubuntu22.04/Debug/modules/dnn/src/layers/cpu_kernels/convolution.cpp:448:43: error: 'CONV_NR' was not declared in this scope; did you mean 'CONV_3D'?
  448 |                 vx_store(inpbufC_FP32 + k*CONV_NR, vx_load(inptrInC + k1));
      |                                           ^~~~~~~
      |                                           CONV_3D
```

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-19 09:47:46,bug,Build issue: test_qrcode_encode.cpp and usage of std::random_shuffle,"### System Information

C++ user - building from source requires building all the tests, and _opencv/modules/objectdetect/test/test_qrcode_encode.cpp_ uses the function ```std::random_shuffle()``` to generate the input info. However, this function is no longer in std since C++17.

### Detailed description

C++ user - building from source requires building all the tests, and _opencv/modules/objectdetect/test/test_qrcode_encode.cpp_ uses the function ```std::random_shuffle()``` to generate the input info. However, this function is no longer in std since C++17.

My solution, as for now, is to just comment all the code. However, it should be able to build with all versions of C++. A solution would be replacing it with ```std::shuffle()```.

### Steps to reproduce

Build with C++ STD >=17

### Issue submission checklist

- [X] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-18 13:21:23,bug,Add assert to check if layer input size is not empty,"### Check if TF model layer input is not empty

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [] There is a reference to the original bug report and related work
- [] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-17 13:27:14,bug,Fix even input dimensions for INTER_NEAREST_EXACT,"### Pull Request Readiness Checklist

resolves https://github.com/opencv/opencv/issues/22204
related: https://github.com/opencv/opencv/issues/9096#issuecomment-1551306017

/cc @Yosshi999

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-17 08:06:39,bug,Fixed mask handling in AffineFeature,"Address https://github.com/opencv/opencv/issues/20865

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-15 15:54:45,bug,Fixes pixel info color font for dark Qt themes,"For dark Qt themes, it is hard to read the pixel color information on the bottom left, like the coordinates or RGB values. This PR proposes a way on how the dynamically sets the font colors based on the system's theme.
Original Example:

![original](https://github.com/opencv/opencv/assets/18199235/25bdbe5b-98d0-41dd-921c-03a6d6946a54)

With patch:

![image](https://github.com/opencv/opencv/assets/18199235/92c40952-9b15-40fa-9d5b-1555f01088f8)


For Windows, nothing is changed (tested on a windows 11 system), because the font color is #000000 when using the default Qt theme.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-15 15:49:47,bug,Unused variable in frameprocessor.cpp,"### System Information

opencv 4.x 

### Detailed description

in 
https://github.com/opencv/opencv/blob/a8d3d1f6f9aa6a91c5fe4a133d541cab73036c01/apps/interactive-calibration/frameProcessor.cpp#L78

rejected is unused variable

### Steps to reproduce

read source code

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-12 15:39:52,bug,Wrong version for OpenCV 4.7.0 in the releases website for iOS,"### System Information

Doesn't apply.

### Detailed description

The downloaded version for iOS (iOS pack) in https://opencv.org/releases/ for the 4.7.0 seems to download the OpenCV version 3.4.19. 

### Steps to reproduce

Download the 4.7.0 for iOS

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-08 18:24:32,bug,OpenCV 4.7.0 much slower than 4.6.0 for Java Apps,"### System Information

Performance comparisons are between OpenCV 4.7.0 (slow) and 4.6.0. (faster). [4.5.0 runs essentially same faster speed as 4.6.0.]
All runs use Windows 10; HP EliteBook laptop.

My test app (the MRE) built with Java compiler:
openjdk version ""17.0.5"" 2022-10-18
OpenJDK Runtime Environment Temurin-17.0.5+8 (build 17.0.5+8)
OpenJDK 64-Bit Server VM Temurin-17.0.5+8 (build 17.0.5+8, mixed mode, sharing)

Essentially identical results running test on two Java runtime versions:

java version ""12"" 2019-03-19
Java(TM) SE Runtime Environment (build 12+33)
Java HotSpot(TM) 64-Bit Server VM (build 12+33, mixed mode, sharing)
  and
openjdk version ""17.0.5"" 2022-10-18
OpenJDK Runtime Environment Temurin-17.0.5+8 (build 17.0.5+8)
OpenJDK 64-Bit Server VM Temurin-17.0.5+8 (build 17.0.5+8, mixed mode, sharing)

### Detailed description

OpenCV 4.7.0 is much slower than 4.6.0 or 4.5.0 for the test run as shown using `imread` in the test MRE, for a variety of other methods in another app summarized below, and for other Java apps using OpenCV.
```
MRE Run times OpenCV 4.6.0 [seconds]
  2000 `imread` elapsed time 3.339, total CPU time 2.984375, user CPU 2.0625

MRE Run times OpenCV 4.7.0 [seconds]
  2000 `imread` elapsed time 6.915, total CPU time 6.40625, user CPU 5.640625
```
The MRE test case scales correctly as expected:
2000 iterations takes twice as long as 1000 iterations.

MRE Run times OpenCV 4.6.0 with `imread` commented out are nearly zero [seconds]:
  2000 `imread` elapsed time 0.014, total CPU time 0.0, user CPU 0.015625

Instrumenting a complete App showed similar performance differences for most OpenCV Java methods (4.5.0 and 4.6.0 as are essentially identical in performance).

```
              [version/milliseconds]
                 4.5.0       4.7.0
                 _____       _____
 imread          69943      173004
 convert          9054      324540
 resize           2090       44447
 blur                0           0 
 split              78         120
 normalize          21         648
 equalize           25          77
 resize             14          22
 adaptive threshold 14          64
```

### Steps to reproduce

A MRE app with the single method, `imread` was written to demonstrate the slow performance. It is attached and includes generating its own test file to read and it displays the OpenCV version build information for both versions which is included as comments in the file.
[App.java.txt](https://github.com/opencv/opencv/files/11423955/App.java.txt)


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-08 06:04:43,bug,The `matchTemplate` function changes the data of the `mask`.,"### System Information

OpenCV version: 4.7.0
Operating System / Platform: windows 10
Compiler & compiler version: visual studio 2019

### Detailed description

When the `matchTemplate` function is used with a `mask`, the data of the `mask` changes and it is no longer usable.
`mask` is an `InputArray` and should not change, it should be read only.
### Steps to reproduce

```c++
    Mat src = Mat(1, 1, CV_8UC1, Scalar(255));
    Mat templ = Mat(1, 1, CV_8UC1, Scalar(255));
    Mat mask1 = Mat(1, 1, CV_8UC1, Scalar(255));
    printf(""before %d\\n"", mask1.at<uchar>(0, 0));
    Mat res;
    matchTemplate(src, templ, res, TemplateMatchModes::TM_CCOEFF_NORMED, mask1);
    printf(""after  %d\\n"", mask1.at<uchar>(0, 0));
```

Output:

```
before 255
after  1
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-28 13:23:35,bug,Losing last mat row and column during `remap()` with `BORDER_TRANSPARENT`,"### System Information

OpenCV python version: 4.7.0
Operating System / Platform: Windows 11
Python revision: 3.10.8

### Detailed description

[EDIT: unquoted relevant part of my question..]

Hi,

first off thanks for the great work you guys are doing!
I'll try and break this down with the attached python snippet.

The docs say
> When borderMode=BORDER_TRANSPARENT, it means that the pixels in the destination image that corresponds to the ""outliers"" in the source image are not modified by the function.

and sadly I cannot seem to find much more on this anywhere, so I may be using it wrong. In that case apologies for creating this issue. But my understanding is that in the example code, this should lead to pixels in the destination staying black when trying to map to a pixel in the source that doesn't exist (e.g. `20`). However, in the example, all pixels in the mapping mats exist in the source, but still, the last row and column in the destination always remain `0` when using `BORDER_TRANSPARENT`. It works as expected with `BORDER_CONSTANT`:

**`BORDER_CONSTANT`**
![grafik](https://user-images.githubusercontent.com/132071902/235158745-fceac757-281c-491a-b6d3-ee564c7433da.png)


**`BORDER_TRANSPARENT`**
![grafik](https://user-images.githubusercontent.com/132071902/235158805-2be0e936-944c-449d-8b0d-203068f0cb6a.png)



### Steps to reproduce

```python
bgImage = np.zeros((8, 12, 1), dtype=np.float32)

source = np.array([[0.1, 0.2, 0.3],
                   [0.5, 0.6, 0.7],
                   [0.9, 1.0, 0.9]], dtype=np.float32).reshape(3, 3, 1)

imageSize = bgImage.shape[1], bgImage.shape[0]

map1 = np.array([[0, 1, 2],
                 [0, 1, 2],
                 [0, 1, 2]], dtype=np.float32)

map2 = np.array([[0, 0, 0],
                 [1, 1, 1],
                 [2, 2, 2]], dtype=np.float32)

destination = np.zeros((3, 3, 1), dtype=np.float32)

cv2.remap(source,
          map1,
          map2,
          interpolation=cv2.INTER_LINEAR,
          dst=destination,
          borderMode=cv2.BORDER_TRANSPARENT)

result = bgImage.copy()
result[2:2+3, 2:2+3] = destination
upscaledImage = cv2.resize(result, np.array([1200, 800]), interpolation=cv2.INTER_NEAREST)

cv2.imshow(""test"", upscaledImage)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-28 07:53:12,bug,Segfault at countNonZero8u on RISC-V with RVV 0.7.1,"### System Information

OpenCV version: 6dbc5e032fa851d1a25fb4a895d735ed3441975b
Operating System / Platform: [20211230_LicheeRV_debian_d1_hdmi_8723ds](https://mega.nz/folder/lx4CyZBA#PiFhY7oSVQ3gp2ZZ_AnwYA/folder/xtxkABIB) / Sipeed Lichee RV Dock (Allwinner D1 CPU), 
Compiler & compiler version: [Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.6.1-20220906.tar.gz](https://occ.t-head.cn/community/download?id=4090445921563774976)

### Detailed description

```
#0  0x0000003ff7d146ae in vsetvl_e64m1 (a=516770465071103)
    at /home/dkurt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.6.1/lib/gcc/riscv64-unknown-linux-gnu/10.2.0/include/riscv_vector.h:137
#1  vmv_v_x_u64m1 (vl=2225411534743296, a=2199023256079104)
    at /home/dkurt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.6.1/lib/gcc/riscv64-unknown-linux-gnu/10.2.0/include/riscv_vector.h:1002
#2  cv::hal_baseline::v_reduce_sum (a=...)
    at /home/dkurt/halide_riscv/3rdparty/opencv/modules/core/include/opencv2/core/hal/intrin_rvv.hpp:1803
#3  0x0000003ff7d15ae8 in cv::cpu_baseline::countNonZero8u (
    src=0x3ff65e8040 '\\377' <repeats 200 times>..., len=2073600)
    at /home/dkurt/halide_riscv/3rdparty/opencv/modules/core/src/count_non_zero.simd.hpp:61
--Type <RET> for more, q to quit, c to continue without paging--
#4  0x0000003ff7d1655c in cv::countNonZero (_src=...)
    at /home/dkurt/halide_riscv/3rdparty/opencv/modules/core/src/count_non_zero.dispatch.cpp:148
```


### Steps to reproduce

Build options:
```bash
-DCMAKE_BUILD_TYPE=Release
-DCMAKE_TOOLCHAIN_FILE=/path/to/opencv/platforms/linux/riscv64-gcc.toolchain.cmake
-DRISCV_RVV_SCALABLE=OFF
-DCPU_BASELINE=RVV
-DCPU_RVV_FLAGS_ON=-march=rv64gcv0p7
```

<details>
<summary>Build summary</summary>

```
-- General configuration for OpenCV 4.7.0-dev =====================================
--   Version control:               4.7.0-261-g6dbc5e032f
-- 
--   Platform:
--     Timestamp:                   2023-04-28T07:32:56Z
--     Host:                        Linux 5.10.102.1-microsoft-standard-WSL2 x86_64
--     Target:                      Linux 1 riscv64
--     CMake:                       3.24.2
--     CMake generator:             Unix Makefiles
--     CMake build tool:            /usr/bin/make
--     Configuration:               Debug
-- 
--   CPU/HW features:
--     Baseline:                    RVV
-- 
--   C/C++:
--     Built as dynamic libs?:      YES
--     C++ standard:                11
--     C++ Compiler:                /home/dkurt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.6.1/bin/riscv64-unknown-linux-gnu-g++  (ver 10.2.0)
--     C++ flags (Release):         -march=rv64gc   -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -march=rv64gcv0p7 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG
--     C++ flags (Debug):           -march=rv64gc   -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -march=rv64gcv0p7 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG
--     C Compiler:                  /home/dkurt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.6.1/bin/riscv64-unknown-linux-gnu-gcc
--     C flags (Release):           -march=rv64gc   -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -march=rv64gcv0p7 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG
--     C flags (Debug):             -march=rv64gc   -fsigned-char -W -Wall -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -march=rv64gcv0p7 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG
--     Linker flags (Release):      -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  
--     Linker flags (Debug):        -Wl,--gc-sections -Wl,--as-needed -Wl,--no-undefined  
--     ccache:                      YES
--     Precompiled headers:         NO
--     Extra dependencies:          dl m pthread rt
--     3rdparty dependencies:
-- 
--   OpenCV modules:
--     To be built:                 core dnn highgui imgcodecs imgproc ts videoio
--     Disabled:                    world
--     Disabled by dependency:      calib3d features2d flann java_bindings_generator js_bindings_generator ml objc_bindings_generator objdetect photo python_bindings_generator python_tests stitching video
--     Unavailable:                 gapi java python2 python3
--     Applications:                tests
--     Documentation:               NO
--     Non-free algorithms:         NO
-- 
--   GUI:                           NONE
--     GTK+:                        NO
-- 
--   Media I/O: 
--     ZLib:                        zlib (ver 1.2.13)
--     JPEG:                        libjpeg-turbo (ver 2.1.3-62)
--     PNG:                         build (ver 1.6.37)
--     JPEG 2000:                   build (ver 2.4.0)
--     HDR:                         YES
--     SUNRASTER:                   YES
--     PXM:                         YES
--     PFM:                         YES
-- 
--   Video I/O:
--     DC1394:                      NO
--     GStreamer:                   NO
--     v4l/v4l2:                    YES (linux/videodev2.h)
-- 
--   Parallel framework:            pthreads
-- 
--   Trace:                         YES (built-in)
-- 
--   Other third-party libraries:
--     Lapack:                      NO
--     Custom HAL:                  NO
--     Protobuf:                    build (3.19.1)
--     Flatbuffers:                 builtin/3rdparty (23.1.21)
-- 
--   Python (for build):            /usr/bin/python2.7
-- 
--   Install to:                    /home/dkurt/build_rv64/opencv-prefix/src/opencv-build/install
```

</details>

```cpp
Mat src0(1080, 1920, CV_8UC1);
Mat src1(1080, 1920, CV_8UC1);
randu(src0, 0, 256);
randu(src1, 0, 256);
countNonZero(src0 != src1);
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-28 05:58:08,bug,Nary Elementwise Broadcast Failure Cases,"I wrote a brute force test to test elementwise which cases will be wrong, here is the test report
[report.md](https://github.com/opencv/opencv/files/11350407/report.md)

I'm not sure if I should put this brute force test into `test_layer.cpp`, because it will test about **3844** times for each backend and it can't detect case which is fallback from GPU to CPU unless we add something to record this situation. 


### Steps to reproduce

1. If you want to test on CUDA, modify file `nary_eltwise_layer.cpp`. Change all `return Ptr<BackendNode>();` to `throw std::logic_error(""fallback"");` and it will be detected when fallback to CPU.
2. build OpenCV with CUDA and in **Release** mode.
3. use code here to generate this report
```cpp
    // config
    std::vector<std::pair<int, int>> backend_target_list = {{DNN_BACKEND_OPENCV, DNN_TARGET_CPU}, {DNN_BACKEND_CUDA, DNN_TARGET_CUDA}};
    std::vector<int> dims_list = {1, 2, 3, 4, 5};

    struct util{
        // give n to generate all n-D arrays with 0 or 1
        static void get_all_arr(std::vector<std::vector<int>> &arr,  int n){
            int total = 1 << n;
            arr.assign(total, std::vector<int>(n, -1));
            for(int i = 0; i < total; i++)
                for(int j = 0; j < n; j++)
                    arr[i][j] = (i >> (n - j - 1)) & 1;
        }

        // zero will replace all 0, one will replace all 1
        static void replace(std::vector<std::vector<int>> &arr, int zero, int one){
            for(int i = 0; i < arr.size(); i++)
                for(int j = 0; j < arr[0].size(); j++)
                    arr[i][j] = arr[i][j] ? one : zero;
        }

        // test if the shape can be forwarded
        static int test_bcast(const std::vector<int>& a_shape, const std::vector<int>& b_shape, const String& op, const std::pair<int, int> &backend_target)
        {
            Mat a = Mat::zeros((int) a_shape.size(), a_shape.data(), CV_32FC1);
            Mat b = Mat::ones((int) b_shape.size(), b_shape.data(), CV_32FC1);

            Net net;
            LayerParams lp;
            lp.type = ""NaryEltwise"";
            lp.name = ""testLayer"";
            lp.set(""operation"", op);
            int id = net.addLayerToPrev(lp.name, lp.type, lp);
            net.connect(0, 1, id, 1);

            std::vector<String> inpNames(2);
            inpNames[0] = ""a"";
            inpNames[1] = ""b"";
            net.setInputsNames(inpNames);
            net.setInput(a, inpNames[0]);
            net.setInput(b, inpNames[1]);

            net.setPreferableBackend(backend_target.first);
            net.setPreferableTarget(backend_target.second);
            try{
                Mat re = net.forward();
                auto ptr_re = (float *) re.data;
                // check if result is right
                for(int i = 0; i < re.total(); i++)
                    if(op == ""sum"" && ptr_re[i] != 1)
                        return -2; // sum result is wrong
                return 1; // all right
            }catch(std::logic_error& e){
                if((std::string) e.what() == ""fallback"")
                    return -3; // fallback to cpu
                else
                    return -1; // other error
            }
            catch(...){
                return -1; // runtime error
            }
        }

        static void print_result(int type, const std::vector<int> &shp1, const std::vector<int> &shp2){
            std::string error_content;
            switch(type){
                case 1:
                    return;
                case -1:
                    error_content = ""runtime error"";
                    break;
                case -2:
                    error_content = ""result wrong"";
                    break;
                case -3:
                    error_content = ""fallback to cpu"";
                    break;
                default:
                    error_content = """";
                    break;
            }
            std::cout << toString(shp1) << "" op "" << toString(shp2) << "", fail reason is "" << error_content << std::endl;
        }
    };


    std::vector<std::vector<int>> dim_shape_list;
    std::vector<std::vector<int>> sub_shape_list;
    std::cout << ""# Nary Elementwise Broadcast Failure Cases"" << std::endl;
    for(auto backend_target: backend_target_list){
        std::cout << ""## BackendID: "" << backend_target.first << "", TargetID: "" << backend_target.second << std::endl;
        for (int dim: dims_list)
        {
            std::cout << ""### Dimension: "" << dim << std::endl;
            sub_shape_list.insert(sub_shape_list.end(), dim_shape_list.begin(), dim_shape_list.end());
            util::get_all_arr(dim_shape_list, dim);
            util::replace(dim_shape_list, 1, 3);
            // same shape
            std::cout << ""- **Same Shape**"" << std::endl;
            for (int i = 0; i < dim_shape_list.size(); i++)
                for (int j = 0; j < dim_shape_list.size(); j++)
                    util::print_result(util::test_bcast(dim_shape_list[i], dim_shape_list[j], ""sum"", backend_target), dim_shape_list[i], dim_shape_list[j]);

            // diff shape
            std::cout << ""- **Different Shape**"" << std::endl;
            for (const auto & shp1 : dim_shape_list)
                for (const auto & shp2 : sub_shape_list)
                    util::print_result(util::test_bcast(shp1, shp2, ""sum"", backend_target), shp1, shp2);

            // diff shape
            for (const auto & shp1 : sub_shape_list)
                for (const auto & shp2 : dim_shape_list)
                    util::print_result(util::test_bcast(shp1, shp2, ""sum"", backend_target), shp1, shp2);
        }
    }
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [x] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-25 15:01:13,bug,rotatedRectangleIntersection does not return all intersection points as expected,"### System Information

OpenCV python version: 4.7.0
Operating System / Platform: Windows 10
Python version: 3.10.10

### Detailed description

During some testing of a system that used `rotatedRectangleIntersection` and then `contourArea` to get the intersection area of 2 overlapping rectangles, we got a size of ~3500mm² instead of the expected ~7000mm². 

It seems to be related to the fact that one edge of each rectangle are on the same line.

* Rectangle 1: `RotatedRect(center=(824.6421183672817, 280.28737007069833), extent=(565.0, 140.0), angle=-177.80506896972656)`
* Rectangle 2: `RotatedRect(center=(567.3310438828003, 270.42527355719545), extent=(275.0, 50.0), angle=92.19493103027344)`

This seems related to #21659, which should be fixed by #21677, but I haven't tested that as it hasn't been released.

### Steps to reproduce

```py
import cv2 as cv

res, points = cv.rotatedRectangleIntersection(
    ((824.6421183672817, 280.28737007069833), (565.0, 140.0), -177.80506896972656),
    ((567.3310438828003, 270.42527355719545), (275.0, 50.0), 92.19493103027344),
)

assert res == 1
assert points is not None

points = points.reshape(-1, 2)
area = cv.contourArea(points)
print(area)  # expected ~7000, got ~3500
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-23 09:53:52,bug,DNN/CUDA: make 'abcd op 1b11' broadcast eltwise operator support cuda,"This PR will fix #23278 

Current implement is a temp impl. I will try to make more eltwise broadcast cases support CUDA. 

The inference time of [model](https://github.com/opencv/opencv/files/10826659/model3.zip) is from **26.7651 ms** to **17.8416 ms**.

**perf_test result**
run this script to generate result
```shell
.\\bin\\opencv_perf_dnn.exe '--gtest_filter=CUDA/Layer_NaryEltwise.*/*:CUDA/Layer_NaryEltwise/*.*' --gtest_output=xml:../tmp/1th.xml --perf_threads=1
```
use this script to generate summary
```shell
python ../modules/ts/misc/summary.py -m min 1th.xml 0th.xml -o markdown
```
result
|Name of Test|0th|1th|1th vs 0th (x-factor)|
|---|:-:|:-:|:-:|
|NHWC_H::CUDA/Layer_NaryEltwise::CUDA/CUDA|39.003 (fallback to cpu)|17.936|2.17|


**Layer by layer data:**
- before being fixed
    ```shell
    onnx_node!ResNet18/0_conv/Conv2D   0.1515ms
    onnx_node!ResNet18/0_PReLU/Relu   0.0193ms
    onnx_node!ResNet18/0_PReLU/Neg_1   0.0145ms
    onnx_node!ResNet18/0_PReLU/Relu_1   0.0121ms
    ResNet18/0_PReLU/Neg:0   0.0167ms
    onnx_node!ResNet18/0_PReLU/mul   2.071ms
    onnx_node!ResNet18/0_PReLU/add   0.0585ms
    onnx_node!ResNet18/stack1_block1_shortcut_conv/Conv2D   0.1643ms
    onnx_node!ResNet18/stack1_block1_1_bn/FusedBatchNormV3   0.0166ms
    onnx_node!ResNet18/stack1_block1_1_conv/Conv2D   0.1179ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/Relu   0.0192ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/Neg_1   0.0114ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/Relu_1   0.0095ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/mul   4.0522ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/add   0.0857ms
    onnx_node!ResNet18/stack1_block1_2_conv/Conv2D   0.1803ms
    onnx_node!ResNet18/stack1_block2_1_bn/FusedBatchNormV3   0.013ms
    onnx_node!ResNet18/stack1_block2_1_conv/Conv2D   0.0533ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/Relu   0.0145ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/Neg_1   0.0116ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/Relu_1   0.0093ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/mul   2.346ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/add   0.0483ms
    onnx_node!ResNet18/stack1_block2_2_conv/Conv2D   0.0748ms
    onnx_node!ResNet18/stack2_block1_shortcut_conv/Conv2D   0.1015ms
    onnx_node!ResNet18/stack2_block1_1_bn/FusedBatchNormV3   0.0135ms
    onnx_node!ResNet18/stack2_block1_1_conv/Conv2D   0.0639ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/Relu   0.0161ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/Neg_1   0.0137ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/Relu_1   0.0133ms
    ResNet18/stack2_block2_2_PReLU/Neg:0   0.0177ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/mul   2.7318ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/add   0.0643ms
    onnx_node!ResNet18/stack2_block1_2_conv/Conv2D   0.1083ms
    onnx_node!ResNet18/stack2_block2_1_bn/FusedBatchNormV3   0.0139ms
    onnx_node!ResNet18/stack2_block2_1_conv/Conv2D   0.0496ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/Relu   0.0147ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/Neg_1   0.0115ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/Relu_1   0.0096ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/mul   1.79ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/add   0.045ms
    onnx_node!ResNet18/stack2_block2_2_conv/Conv2D   0.0701ms
    onnx_node!ResNet18/stack3_block1_shortcut_conv/Conv2D   0.0776ms
    onnx_node!ResNet18/stack3_block1_1_bn/FusedBatchNormV3   0.016ms
    onnx_node!ResNet18/stack3_block1_1_conv/Conv2D   0.0479ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/Relu   0.0159ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/Neg_1   0.0135ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/Relu_1   0.0121ms
    ResNet18/stack3_block2_2_PReLU/Neg:0   0.0173ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/mul   2.1251ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/add   0.043ms
    onnx_node!ResNet18/stack3_block1_2_conv/Conv2D   0.0793ms
    onnx_node!ResNet18/stack3_block2_1_bn/FusedBatchNormV3   0.012ms
    onnx_node!ResNet18/stack3_block2_1_conv/Conv2D   0.0458ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/Relu   0.0133ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/Neg_1   0.0106ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/Relu_1   0.0091ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/mul   1.7766ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/add   0.043ms
    onnx_node!ResNet18/stack3_block2_2_conv/Conv2D   0.0751ms
    onnx_node!ResNet18/stack4_block1_shortcut_conv/Conv2D   0.0758ms
    onnx_node!ResNet18/stack4_block1_1_bn/FusedBatchNormV3   0.0153ms
    onnx_node!ResNet18/stack4_block1_1_conv/Conv2D   0.048ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/Relu   0.0151ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/Neg_1   0.013ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/Relu_1   0.012ms
    ResNet18/stack4_block1_2_PReLU/Neg:0   0.0176ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/mul   2.1163ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/add   0.0396ms
    onnx_node!ResNet18/stack4_block1_2_conv/Conv2D   0.0751ms
    onnx_node!ResNet18/stack4_block2_1_bn/FusedBatchNormV3   0.0121ms
    onnx_node!ResNet18/stack4_block2_1_conv/Conv2D   0.0485ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/Relu   0.0158ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/Neg_1   0.013ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/Relu_1   0.0121ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/mul   2.0351ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/add   0.037ms
    onnx_node!ResNet18/stack4_block2_2_conv/Conv2D   0.072ms
    onnx_node!ResNet18/E_batchnorm/FusedBatchNormV3   0.0142ms
    onnx_node!ResNet18/E_batchnorm/FusedBatchNormV3__210   0.0169ms
    onnx_node!ResNet18/E_flatten/Reshape   0.0014ms
    onnx_node!ResNet18/E_dense/MatMul   0.0445ms
    ResNet18/E_batchnorm/ReadVariableOp_1:0   0.0165ms
    onnx_node!ResNet18/pre_embedding/batchnorm/mul_1   0.0156ms
    embedding   0.001ms
    ```
- after being fixed
    ```shell
    onnx_node!ResNet18/0_conv/Conv2D   0.255ms
    onnx_node!ResNet18/0_PReLU/Relu   0.0309ms
    onnx_node!ResNet18/0_PReLU/Neg_1   0.0181ms
    onnx_node!ResNet18/0_PReLU/Relu_1   0.0147ms
    ResNet18/0_PReLU/Neg:0   0.0539ms
    onnx_node!ResNet18/0_PReLU/mul   0.0276ms
    onnx_node!ResNet18/0_PReLU/add   0.018ms
    onnx_node!ResNet18/stack1_block1_shortcut_conv/Conv2D   0.1718ms
    onnx_node!ResNet18/stack1_block1_1_bn/FusedBatchNormV3   0.0215ms
    onnx_node!ResNet18/stack1_block1_1_conv/Conv2D   0.1762ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/Relu   0.0201ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/Neg_1   0.0156ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/Relu_1   0.0142ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/mul   0.0199ms
    onnx_node!ResNet18/stack1_block1_2_PReLU/add   0.0478ms
    onnx_node!ResNet18/stack1_block1_2_conv/Conv2D   0.1198ms
    onnx_node!ResNet18/stack1_block2_1_bn/FusedBatchNormV3   0.0139ms
    onnx_node!ResNet18/stack1_block2_1_conv/Conv2D   0.2334ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/Relu   0.0244ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/Neg_1   0.0238ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/Relu_1   0.0196ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/mul   0.0256ms
    onnx_node!ResNet18/stack1_block2_2_PReLU/add   0.0204ms
    onnx_node!ResNet18/stack1_block2_2_conv/Conv2D   0.1101ms
    onnx_node!ResNet18/stack2_block1_shortcut_conv/Conv2D   0.1641ms
    onnx_node!ResNet18/stack2_block1_1_bn/FusedBatchNormV3   0.0296ms
    onnx_node!ResNet18/stack2_block1_1_conv/Conv2D   0.0867ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/Relu   0.0253ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/Neg_1   0.0223ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/Relu_1   0.0208ms
    ResNet18/stack2_block2_2_PReLU/Neg:0   0.0337ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/mul   0.0334ms
    onnx_node!ResNet18/stack2_block1_2_PReLU/add   0.0306ms
    onnx_node!ResNet18/stack2_block1_2_conv/Conv2D   0.1605ms
    onnx_node!ResNet18/stack2_block2_1_bn/FusedBatchNormV3   0.0266ms
    onnx_node!ResNet18/stack2_block2_1_conv/Conv2D   0.0904ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/Relu   0.0712ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/Neg_1   0.0305ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/Relu_1   0.0237ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/mul   0.0299ms
    onnx_node!ResNet18/stack2_block2_2_PReLU/add   0.0257ms
    onnx_node!ResNet18/stack2_block2_2_conv/Conv2D   0.1648ms
    onnx_node!ResNet18/stack3_block1_shortcut_conv/Conv2D   0.147ms
    onnx_node!ResNet18/stack3_block1_1_bn/FusedBatchNormV3   0.0269ms
    onnx_node!ResNet18/stack3_block1_1_conv/Conv2D   0.0805ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/Relu   0.0274ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/Neg_1   0.0214ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/Relu_1   0.0969ms
    ResNet18/stack3_block2_2_PReLU/Neg:0   0.03ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/mul   0.0272ms
    onnx_node!ResNet18/stack3_block1_2_PReLU/add   0.0247ms
    onnx_node!ResNet18/stack3_block1_2_conv/Conv2D   0.1316ms
    onnx_node!ResNet18/stack3_block2_1_bn/FusedBatchNormV3   0.0241ms
    onnx_node!ResNet18/stack3_block2_1_conv/Conv2D   0.0792ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/Relu   0.0259ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/Neg_1   0.0213ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/Relu_1   0.0962ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/mul   0.0633ms
    onnx_node!ResNet18/stack3_block2_2_PReLU/add   0.0246ms
    onnx_node!ResNet18/stack3_block2_2_conv/Conv2D   0.1131ms
    onnx_node!ResNet18/stack4_block1_shortcut_conv/Conv2D   0.1028ms
    onnx_node!ResNet18/stack4_block1_1_bn/FusedBatchNormV3   0.0273ms
    onnx_node!ResNet18/stack4_block1_1_conv/Conv2D   0.0834ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/Relu   0.031ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/Neg_1   0.1031ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/Relu_1   0.0858ms
    ResNet18/stack4_block1_2_PReLU/Neg:0   0.032ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/mul   0.0333ms
    onnx_node!ResNet18/stack4_block1_2_PReLU/add   0.0229ms
    onnx_node!ResNet18/stack4_block1_2_conv/Conv2D   0.1609ms
    onnx_node!ResNet18/stack4_block2_1_bn/FusedBatchNormV3   0.0336ms
    onnx_node!ResNet18/stack4_block2_1_conv/Conv2D   0.0869ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/Relu   0.0314ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/Neg_1   0.0235ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/Relu_1   0.0236ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/mul   0.0368ms
    onnx_node!ResNet18/stack4_block2_2_PReLU/add   0.0234ms
    onnx_node!ResNet18/stack4_block2_2_conv/Conv2D   0.1913ms
    onnx_node!ResNet18/E_batchnorm/FusedBatchNormV3   0.0269ms
    onnx_node!ResNet18/E_batchnorm/FusedBatchNormV3__210   0.0234ms
    onnx_node!ResNet18/E_flatten/Reshape   0.0016ms
    onnx_node!ResNet18/E_dense/MatMul   0.1472ms
    ResNet18/E_batchnorm/ReadVariableOp_1:0   0.0635ms
    onnx_node!ResNet18/pre_embedding/batchnorm/mul_1   0.0692ms
    embedding   0.0019ms
    ```

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-04-20 00:56:24,bug,OpenCV(4.5.5) Error: Gpu API call (CUDA_ERROR_FILE_NOT_FOUND [Code = 301],"### System Information

opencv-4.5.5
opencv_contrib-4.5.5
Video_Codec_SDK_11.1.5
Cmake 3.23.1
Win 10

### Detailed description

Hello, I followed the online tutorial to compile OpenCV hard decoding; I will first attempt to open a local MP4 file for hard decoding testing, which can be run through; When I switch to real-time video rtsp/rtmp, the following issues will occur: OpenCV(4.5.5) Error: Gpu API call (CUDA_ERROR_FILE_NOT_FOUND [Code = 301]) in cv::cudacodec::detail::CuvidVideoSource::CuvidVideoSource, file E:\\Software\\opencv4.5.5.build\\opencv_contrib-4.5.5\\modules\\cudacodec\\src\\cuvid_video_source.cpp, line 66

### Steps to reproduce

// local mp4 video is ok
std::string fname = ""rtmp://ns8.indexforce.com/home/mystream"";
std::cout << ""GPU个数为: "" << cv::cuda::getCudaEnabledDeviceCount() << std::endl;
cv::cuda::GpuMat d_frame;
// error
cv::Ptr<cv::cudacodec::VideoReader> d_reader = cv::cudacodec::createVideoReader(fname);

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-19 12:09:20,bug,"Solve the ""Unrecognized selector"" issue in Objective-C/Swift binding","### System Information

OpenCV version: 4.x latest
Operating System / Platform: MacOS any


### Detailed description

As originally reported in https://github.com/opencv/opencv/issues/17532 there is a frequently occurring problem when trying to use the **-[Mat toUIImage]** method and other similar methods.
The ""unrecognized selector sent to instance"" error can be worked round by modifying the ""Other Linker Flags"" but its a pain to always have to do this. Other functionality like debug Quicklook (https://github.com/opencv/opencv/pull/20457) also requires these flags to be set in order to work correctly and there is no hint in the UI to indicate that this is the case.
To solve the problem we need to move the functionality added to **Mat** using categories in **Mat+Converters** and **Mat+Quicklook** directly into the **Mat** implemenation

### Steps to reproduce

Refer to https://github.com/opencv/opencv/issues/17532

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-19 10:26:17,bug,Error in `generation_onnx_models.py` onnx test data generation script. ,"### System Information

Hi! 

Running `python generate_onnx_models.py` inside `opencv_extra/testdata/dnn/onnx` to generate new test models and data results in error 

It seem that `postprocess_model()` function is not located in wrong place

OpenCV python version: 3.8.10
Operating System / Platform: Ubuntu 20.04, focal
Python version: 3.8.10


### Detailed description

```python
.
.
.
============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============
verbose: False, log level: Level.ERROR
======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================

slice_opset_11_steps_2d input has sizes torch.Size([6, 6])
slice_opset_11_steps_2d output has sizes torch.Size([2, 2])

============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============
verbose: False, log level: Level.ERROR
======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================

Traceback (most recent call last):
  File ""generate_onnx_models.py"", line 530, in <module>
    postprocess_model(""models/slice_opset_11_steps_2d.onnx"", [['height', 'width']])
NameError: name 'postprocess_model' is not defined
```


### Steps to reproduce

Running `python generate_onnx_models.py` inside `opencv_extra/testdata/dnn/onnx` to generate new test models and data results in error 


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-15 12:56:13,bug,Fix aruco module CORNER_REFINE_CONTOUR parameter gets skipped,"### Pull Request Readiness Checklist

Hi @AleksandrPanov the aruco module is using the wrong variable to check whether it should perform corner refinement.

The previous buggy version of code since opencv 4.7 is using the candidates supplied in the function argument from user instead of the candidates returned from `_identifyCandidates`.

Our current workaround is always to run the detectMarkers twice, so the second time will use the ids returned from the first run, however that workaround is not optimal and greatly hurt the performance.

Could you please take a look and get this merged? Thanks!

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work https://github.com/opencv/opencv/issues/23437
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-04-11 08:07:38,bug,DNN: support the split node of onnx opset >= 13,"Merge with test case: https://github.com/opencv/opencv_extra/pull/1053.

The attribute of `split` in `Split layer` has been moved from `attribute` to `input`.
Related link: https://github.com/onnx/onnx/blob/main/docs/Operators.md#inputs-1---2-12
The purpose of this PR is to support the `split` with input type.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-09-26 05:11:28,question,"Using the Java version of opencv, the camera encountered a memory overflow issue while iteratively fetching images ","### System Information

OpenCV python version: 4.8
Operating System / Platform: Windows 11
java version: 4.7

### Detailed description

Exception in thread ""main"" java.lang.Exception: std::exception: bad allocation
	at org.opencv.imgcodecs.Imgcodecs.imencode_1(Native Method)
	at org.opencv.imgcodecs.Imgcodecs.imencode(Imgcodecs.java:631)
	at com.benfei.Grab_Callback.main(Grab_Callback.java:138)



### Steps to reproduce

When I loop through the code below from the camera, there will be a memory overflow bug
MatOfByte mob = new MatOfByte();
imencode("".jpg"", mat, mob);
byte[] array = mob.toArray();

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-21 08:13:15,question,"ERROR COMPILING OPENCV WITH CUDA at 99%, PLEASE HELP ","### System Information

I put the following 2 commands to compile opencv with cuda:

wget -O opencv.zip https://github.com/opencv/opencv/archive/refs/tags/4.8.0.zip ; wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/refs/tags/4.8.0.zip ; unzip opencv.zip ; unzip opencv_contrib.zip ; mv opencv_contrib-4.8.0 opencv_contrib ; cd opencv-4.8.0/build/ ;

AND:
cmake -D CMAKE_BUILD_TYPE=RELEASE -D WITH_CUDA=ON -D OPENCV_DNN_CUDA=ON -D CUDA_ARCH_BIN=7.5 -D CMAKE_C_COMPILER=/usr/bin/gcc-11 -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_opencv_python2=OFF -D BUILD_opencv_java=OFF -D PYTHON3_EXECUTABLE=/home/dani/anaconda3/bin/python3 -D WITH_TBB=ON -D ENABLE_FAST_MATH=1 -D CUDA_FAST_MATH=1 -D WITH_CUBLAS=1 -D BUILD_opencv_cudacodec=ON -D WITH_CUDNN=ON -D CUDNN_VERSION=8.9.5 -D WITH_V4L=ON -D WITH_QT=ON -D WITH_OPENGL=ON -D WITH_GSTREAMER=ON -D OPENCV_GENERATE_PKGCONFIG=YES -D OPENCV_PC_FILE_NAME=opencv.pc -D OPENCV_ENABLE_NONFREE=ON -D OPENCV_PYTHON3_INSTALL_PATH=/home/dani/anaconda3/lib/python3.11/site-packages -D PYTHON_EXECUTABLE=/home/dani/anaconda3/bin/python -D OPENCV_EXTRA_MODULES_PATH=/home/dani/opencv_contrib/modules -D INSTALL_PYTHON_EXAMPLES=OFF -D INSTALL_C_EXAMPLES=OFF -D BUILD_EXAMPLES=OFF … \\

And at 99% i had the next error:
error: conversion from ‘cv::cuda::Stream’ to non-scalar type ‘cv::Ptrcv::cuda::Stream’ requested
39041 | Ptrcv::cuda::Stream stream=cuda::Stream::Null();

My Cuda version is 12.2 , my ubuntu version is 22.04, my cuDNN is 8.7.5 and opencv is 4.8

Thanks in advance for help!!!

### Detailed description

I put the following 2 commands to compile opencv with cuda:

wget -O opencv.zip https://github.com/opencv/opencv/archive/refs/tags/4.8.0.zip ; wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/refs/tags/4.8.0.zip ; unzip opencv.zip ; unzip opencv_contrib.zip ; mv opencv_contrib-4.8.0 opencv_contrib ; cd opencv-4.8.0/build/ ;

AND:
cmake -D CMAKE_BUILD_TYPE=RELEASE -D WITH_CUDA=ON -D OPENCV_DNN_CUDA=ON -D CUDA_ARCH_BIN=7.5 -D CMAKE_C_COMPILER=/usr/bin/gcc-11 -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_opencv_python2=OFF -D BUILD_opencv_java=OFF -D PYTHON3_EXECUTABLE=/home/dani/anaconda3/bin/python3 -D WITH_TBB=ON -D ENABLE_FAST_MATH=1 -D CUDA_FAST_MATH=1 -D WITH_CUBLAS=1 -D BUILD_opencv_cudacodec=ON -D WITH_CUDNN=ON -D CUDNN_VERSION=8.9.5 -D WITH_V4L=ON -D WITH_QT=ON -D WITH_OPENGL=ON -D WITH_GSTREAMER=ON -D OPENCV_GENERATE_PKGCONFIG=YES -D OPENCV_PC_FILE_NAME=opencv.pc -D OPENCV_ENABLE_NONFREE=ON -D OPENCV_PYTHON3_INSTALL_PATH=/home/dani/anaconda3/lib/python3.11/site-packages -D PYTHON_EXECUTABLE=/home/dani/anaconda3/bin/python -D OPENCV_EXTRA_MODULES_PATH=/home/dani/opencv_contrib/modules -D INSTALL_PYTHON_EXAMPLES=OFF -D INSTALL_C_EXAMPLES=OFF -D BUILD_EXAMPLES=OFF … \\

And at 99% i had the next error:
error: conversion from ‘cv::cuda::Stream’ to non-scalar type ‘cv::Ptrcv::cuda::Stream’ requested
39041 | Ptrcv::cuda::Stream stream=cuda::Stream::Null();

My Cuda version is 12.2 , my ubuntu version is 22.04, my cuDNN is 8.7.5 and opencv is 4.8

Thanks in advance for help!!!

### Steps to reproduce

I put the following 2 commands to compile opencv with cuda:

wget -O opencv.zip https://github.com/opencv/opencv/archive/refs/tags/4.8.0.zip ; wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/refs/tags/4.8.0.zip ; unzip opencv.zip ; unzip opencv_contrib.zip ; mv opencv_contrib-4.8.0 opencv_contrib ; cd opencv-4.8.0/build/ ;

AND:
cmake -D CMAKE_BUILD_TYPE=RELEASE -D WITH_CUDA=ON -D OPENCV_DNN_CUDA=ON -D CUDA_ARCH_BIN=7.5 -D CMAKE_C_COMPILER=/usr/bin/gcc-11 -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_opencv_python2=OFF -D BUILD_opencv_java=OFF -D PYTHON3_EXECUTABLE=/home/dani/anaconda3/bin/python3 -D WITH_TBB=ON -D ENABLE_FAST_MATH=1 -D CUDA_FAST_MATH=1 -D WITH_CUBLAS=1 -D BUILD_opencv_cudacodec=ON -D WITH_CUDNN=ON -D CUDNN_VERSION=8.9.5 -D WITH_V4L=ON -D WITH_QT=ON -D WITH_OPENGL=ON -D WITH_GSTREAMER=ON -D OPENCV_GENERATE_PKGCONFIG=YES -D OPENCV_PC_FILE_NAME=opencv.pc -D OPENCV_ENABLE_NONFREE=ON -D OPENCV_PYTHON3_INSTALL_PATH=/home/dani/anaconda3/lib/python3.11/site-packages -D PYTHON_EXECUTABLE=/home/dani/anaconda3/bin/python -D OPENCV_EXTRA_MODULES_PATH=/home/dani/opencv_contrib/modules -D INSTALL_PYTHON_EXAMPLES=OFF -D INSTALL_C_EXAMPLES=OFF -D BUILD_EXAMPLES=OFF … \\

And at 99% i had the next error:
error: conversion from ‘cv::cuda::Stream’ to non-scalar type ‘cv::Ptrcv::cuda::Stream’ requested
39041 | Ptrcv::cuda::Stream stream=cuda::Stream::Null();

My Cuda version is 12.2 , my ubuntu version is 22.04, my cuDNN is 8.7.5 and opencv is 4.8

Thanks in advance for help!!!

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-18 14:17:52,question,Can not set camera to 4k resolution ,"### System Information

OpenCV python version: 4.8.0
Operating System / Platform: Ubuntu 20.04
Python version: 3.8.17
Camera model: Dell Ultrasharp WB7022

### Detailed description

I can not set the camera resolution to 4k with the normal method:

```
import cv2

cap = cv2.VideoCapture(0)

print(cap.isOpened())

cap.set(3,3840)
cap.set(4,2160)
ret, frame = cap.read()

cv2.imshow('display', frame)
print(frame.shape)
if cv2.waitKey(0) & 0xFF == ord('q'):
    exit(0)
```
This prints: 
True
(1080, 1920, 3)

The same code works on windows and the cap is successfully set to 4k

This is the output of v4l2-ctl -d0 --list-formats-ext

> ioctl: VIDIOC_ENUM_FMT
> 	Type: Video Capture
> 
> 	[0]: 'YUYV' (YUYV 4:2:2)
> 		Size: Discrete 640x480
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 640x360
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 1280x720
> 			Interval: Discrete 0.042s (24.000 fps)
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 1920x1080
> 			Interval: Discrete 0.042s (24.000 fps)
> 			Interval: Discrete 0.033s (30.000 fps)
> 	[1]: 'MJPG' (Motion-JPEG, compressed)
> 		Size: Discrete 640x480
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 1280x720
> 			Interval: Discrete 0.042s (24.000 fps)
> 			Interval: Discrete 0.033s (30.000 fps)
> 			Interval: Discrete 0.017s (60.000 fps)
> 		Size: Discrete 1920x1080
> 			Interval: Discrete 0.042s (24.000 fps)
> 			Interval: Discrete 0.033s (30.000 fps)
> 			Interval: Discrete 0.017s (60.000 fps)
> 		Size: Discrete 2560x1440
> 			Interval: Discrete 0.042s (24.000 fps)
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 3840x2160
> 			Interval: Discrete 0.042s (24.000 fps)
> 			Interval: Discrete 0.033s (30.000 fps)
> 	[2]: 'NV12' (Y/CbCr 4:2:0)
> 		Size: Discrete 640x480
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 640x360
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 1280x720
> 			Interval: Discrete 0.033s (30.000 fps)
> 		Size: Discrete 1920x1080
> 			Interval: Discrete 0.033s (30.000 fps)
> 

I have tried this line:
`cap = cv2.VideoCapture(0, cv2.CAP_OPENCV_MJPEG)
`
but I get this error:

> [ WARN:0@0.012] global cap.cpp:342 open VIDEOIO(CV_MJPEG): backend is generally available but can't be used to capture by index
> False
> Traceback (most recent call last):
>   File ""test_open_camera.py"", line 14, in <module>
>     cv2.imshow('display', frame)
> cv2.error: OpenCV(4.8.0) /io

With software like Webcamoid, if I set the video format to MJPG then I can get 4k, this is not the case with YUYV.

Any help would be greatly appreciated.

### Steps to reproduce

I don't know if it can be reproduced by other cameras 

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-17 21:31:39,question,COLOR_RGB2Lab is not reliable for float32 values,"### System Information

OpenCV python version: 4.8.0.74
Operating System / Platform: Win11
Python version: 3.11 x64

### Detailed description

The convert color function  does not convert all RGB-values to the correct corresponding L*a*b*-Values if the RGB values are of type float32.


### Steps to reproduce

import numpy as np
import cv2 as cv

color=np.array([[[255,1,255]]]).astype(np.float32)
lab_color_cv=cv.cvtColor(color, cv.COLOR_RGB2Lab)

print(lab_color_cv)

 output is: [[[100.   0.   0.]]]
 should be: [[[ 60.34288976  98.17767091 -60.79175629]]]
 any value from 1 to 254 for the green value in RGB will lead to the wrong output of [[[100, 0, 0]]]
 while [[[255,0,255]]] and [[[255,255,255]]] are correct



### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-06 14:19:18,question,Cross compiling ARM64 in Windows x86_64 fails,"### System Information

OpenCV version: 4.7.0
OS: Windows 11
Compiler & version (as reported by cmake)
-- Building for: Visual Studio 17 2022
-- The C compiler identification is MSVC 19.37.32822.0
-- The CXX compiler identification is MSVC 19.37.32822.0


### Detailed description

I'm trying to cross-compile: achieve arm64 binaries on a x64 windows 11 desktop.

I create the developer shell for windows visual c++ compilation and linking like this:
```
C:\\Windows\\System32\\cmd.exe /k ""C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\Common7\\Tools\\VsDevCmd.bat"" -arch=arm64 -host_arch=amd64
```

Here is my .bat script to run cmake and to compile & link:
```
:: setting the CL env variable makes no difference:
:: set CL=/D_M_ARM64=1
:: set CL=/arch:armv8.8
set CL=
echo
echo extra vars for compiler: %CL%
echo
set 'CMAKE_GENERATOR_OPTIONS=-G""Visual Studio 17 2022""'
set ""CMAKE_OPTIONS=-DBUILD_PERF_TESTS:BOOL=OFF -DBUILD_TESTS:BOOL=OFF -DBUILD_DOCS:BOOL=OFF -DWITH_CUDA:BOOL=OFF -DBUILD_EXAMPLES:BOOL=OFF -DINSTALL_CREATE_DISTRIB=ON -DBUILD_opencv_java=OFF -DBUILD_opencv_python=OFF -DBUILD_PROTOBUF=OFF -DBUILD_opencv_dnn=OFF""
:: this is required to find the correct compiler!
set ""CMAKE_ARCHITECTURE=-A ARM64""
cd opencv-4.5.4
rmdir /s build
mkdir build
cd build
cmake .. %CMAKE_GENERATOR_OPTIONS% %CMAKE_ARCHITECTURE% %CMAKE_OPTIONS%
:: cmake .. %CMAKE_GENERATOR_OPTIONS% %CMAKE_OPTIONS%
cd ..
cmake --build build --config Release
```

I can see that cmake picks up the correct compiler allright:
```
...
-- Check for working CXX compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.37.32822/bin/Hostx64/arm64/cl.exe - skipped
...
```

Finally, I get tons of these:
```
C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.37.32822\\include\\emmintrin.h(20,1): fatal  error C11
89: #error:  This header is specific to X86, X64, ARM64, and ARM64EC targets (compiling source file C:\\Users\\v-sriikonen\\open
cv\\opencv-4.5.4\\modules\\core\\src\\async.cpp) [C:\\Users\\v-sriikonen\\opencv\\opencv-4.5.4\\build\\modules\\world\\opencv_world.vcxpro
j]
```
With emphasis on:
```
fatal  error C1189: #error:  This header is specific to X86, X64, ARM64, and ARM64EC targets
```
Which is stupid, since we are indeed compiling for ``ARM64`` target.

Origin of the problem is in the header files:
```
#if !defined(_M_IX86) && !defined(_M_X64) && !(defined(_M_ARM64) && defined(USE_SOFT_INTRINSICS))
#error This header is specific to X86, X64, ARM64, and ARM64EC targets
#endif
```
So it seems that ``_M_ARM64`` preprocessor directive is lost somewhere on the way - indeed I can't find it in any of the cache files produced by cmake.

### Steps to reproduce

(see above)


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-09-06 02:39:36,question,"Does ""cv::VideoCapture"" have any thread lock?","### System Information

OpenCV python version: 4.8.0.76
Operating System / Platform: MacOS 14 && Windows 11
Python version: 3.11.5

### Detailed description

VideoCapture Multithreading 

### Steps to reproduce

- When i using ThreadPool, 
```python
import cv2
import time
from concurrent.futures import ThreadPoolExecutor as PoolExecutor


def open_capture(i):
    capture = cv2.VideoCapture()
    begin_time = time.time()
    capture.open(
        'http://devimages.apple.com/iphone/samples/bipbop/gear1/prog_index.m3u8')
    if capture.isOpened():
        print(f'[Open Capture {i}] :{time.time()-begin_time}s')


if __name__ == '__main__':
    pool = PoolExecutor(10)
    pool.submit(open_capture, 1)
    pool.submit(open_capture, 2)
    pool.shutdown()
```
```
[Open Capture 1] :5.037631034851074s
[Open Capture 2] :6.26716685295105s
```
```
[Open Capture 1] :1.4738409519195557s
[Open Capture 2] :2.794524908065796s
```
```
[Open Capture 1] :1.3103349208831787s
[Open Capture 2] :2.629105806350708s
```

- When i using ProcessPool,they are opened almost at the same time.
```python
import cv2
import time
from concurrent.futures import ProcessPoolExecutor as PoolExecutor


def open_capture(i):
    capture = cv2.VideoCapture()
    begin_time = time.time()
    capture.open(
        'http://devimages.apple.com/iphone/samples/bipbop/gear1/prog_index.m3u8')
    if capture.isOpened():
        print(f'[Open Capture {i}] :{time.time()-begin_time}s')


if __name__ == '__main__':
    pool = PoolExecutor(10)
    pool.submit(open_capture, 1)
    pool.submit(open_capture, 2)
    pool.shutdown()
```
```
[Open Capture 1] :1.9312078952789307s
[Open Capture 2] :1.913451910018921s
```
```
[Open Capture 1] :1.5760650634765625s
[Open Capture 2] :1.5881609916687012s
```
```
[Open Capture 1] :1.0843567848205566s
[Open Capture 2] :1.080475091934204s
```

### Issue submission checklist

- [ ] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-12 15:47:30,question,Opencv includes not found after build,"### Describe the doc issue

Hello,

I built the Opencv using cmake. 
Now i need to add OPencv into my application and call its functions. 
I could not find the include\\version.hpp to include in my application. 
(header file)

Your input is appreciated. 




### Fix suggestion

Hello,

I have build the openCV using camke. Now i need to refer OpenCV in my C application.
I need to call the OPencv functions from my application. 

I could not find the include\\version.hpp to include in my application. 

Appreciate your input. 

  
"
opencv/opencv,2023-07-18 16:08:12,question,Can cv2.VideoCapture  read 4 channel video?,"### Describe the doc issue

I want to read 4 channel video, using:
```
cv2.VideoCapture(path)
while True:
    ret, frame = video.read()

```    
But, I find the frame is 3 channel,

### Fix suggestion

_No response_"
opencv/opencv,2023-07-08 04:35:52,question," faceRecognizerSF.feature(alingCrop, feature) Always return the same features for different faces","### System Information

[OpenCV version: 4.7.0](https://github.com/opencv/opencv/releases/download/4.7.0/opencv-4.7.0-windows.exe)
Operating System / Platform: win11

```
<dependency>
  <groupId>org.bytedeco</groupId>
  <artifactId>opencv</artifactId>
  <version>4.7.0-1.5.9</version>
  <!--        <classifier>macosx-x86_64</classifier>-->
  <classifier>windows-x86_64</classifier>
</dependency>
```

### Detailed description

```
 faceRecognizerSF.feature(alingCrop, feature) 
```
Traverse different images to extract features, and the returned dataAddr is always the same.
```java
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af89090, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af89a90, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8aa30, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af89db0, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af88eb0, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8a350, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8a990, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8d690, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8c790, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8bbb0, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8b930, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8bd90, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8db90, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8d730, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8c150, dataAddr=0x2b67b2f7540 ]
Mat [ 1*128*CV_32FC1, isCont=true, isSubmat=true, nativeObj=0x2b67af8d870, dataAddr=0x2b67b2f7540 ]
```

### Steps to reproduce

Reproduction demo
[face_detection_yunet_2022mar_int8.onnx](https://github.com/opencv/opencv_zoo/blob/main/models/face_detection_yunet/face_detection_yunet_2023mar_int8.onnx)
[face_recognition_sface_2021dec_int8.onnx](https://github.com/opencv/opencv_zoo/blob/main/models/face_recognition_sface/face_recognition_sface_2021dec_int8.onnx)
```java
package com.example.asyncdemo.sface;

import cn.hutool.core.io.FileUtil;
import lombok.extern.slf4j.Slf4j;
import org.opencv.core.Mat;
import org.opencv.core.Rect;
import org.opencv.core.Size;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.objdetect.FaceDetectorYN;
import org.opencv.objdetect.FaceRecognizerSF;

import java.io.File;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

@Slf4j
public class demo1 {
    private static FaceDetectorYN faceDetectorYNImg;
    private static FaceRecognizerSF faceRecognizerSF;
    private static Map<String, Mat> features = new ConcurrentHashMap<>();

    static {
        System.load(""D:\\\\AsyncDemo\\\\src\\\\main\\\\java\\\\com\\\\example\\\\asyncdemo\\\\sface\\\\opencv_java470.dll"");
        faceDetectorYNImg = FaceDetectorYN.create(""D:\\\\AsyncDemo\\\\face_detection_yunet_2022mar_int8.onnx"", """", new Size(320, 240), (float) 0.9, (float) 0.3, 5000);
        faceRecognizerSF = FaceRecognizerSF.create(""D:\\\\AsyncDemo\\\\src\\\\main\\\\java\\\\com\\\\example\\\\asyncdemo\\\\sface\\\\face_recognition_sface_2021dec_int8.onnx"", """");
    }

    public static void main(String[] args) {
        initAll();
    }

    private static void initAll() {
        File[] fs = FileUtil.ls(""D:\\\\AsyncDemo\\\\src\\\\main\\\\java\\\\com\\\\example\\\\asyncdemo\\\\sface\\\\images"");
        for (File file : fs) {
            Mat mat = Imgcodecs.imread(file.getAbsolutePath());
            Mat feature = new Mat();
            detect(mat, feature);
            if (!feature.empty()) {
                features.put(file.getName(), feature);
            } else {
                log.error(file.getName());
            }
//            log.info(""{}::{}"", file.getName(), feature);

        }
        log.info(""All files::{},features.size::{}"", fs.length, features.size());
    }

    private static Mat detect(Mat mat1, Mat feature) {
//        faceRecognizerSF = FaceRecognizerSF.create(""D:\\\\AsyncDemo\\\\src\\\\main\\\\java\\\\com\\\\example\\\\asyncdemo\\\\sface\\\\face_recognition_sface_2021dec_int8.onnx"", """");

        Mat face = new Mat();

        Mat alingCrop = new Mat();
        Mat maxFace = null;
        double maxSize = 0;
        try {
            faceDetectorYNImg.setInputSize(mat1.size());
            faceDetectorYNImg.detect(mat1, face);

            for (int i = 0; i < face.rows(); i++) {
                Rect rect = new Rect((int) face.get(i, 0)[0], (int) face.get(i, 1)[0], (int) face.get(i, 2)[0], (int) face.get(i, 3)[0]);
                if (rect.area() > maxSize) {
                    maxFace = face.row(i);
                    maxSize = rect.area();
                }
            }

            if (maxFace != null) {
                faceRecognizerSF.alignCrop(mat1, maxFace, alingCrop);
                faceRecognizerSF.feature(alingCrop, feature);
                System.out.println(feature);
            }
            mat1.release();
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            alingCrop.release();
            face.release();
        }
        return feature;
    }
}

```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-28 18:10:52,question,imshow not implemented,"### System Information

**OpenCV version**: 4.8.0 (also occurs in version 4.7.0)
**Operating system**: Windows
**Compiler**: Microsoft Visual C++ v19.36.32535 (x86)

### Detailed description

**My code is in C++.**

I'm using the HighGUI module (`#include ""opencv2/highgui/highgui.hpp""`), and it seems to me that _the `imshow` function is not implemented_. (Compiler error below.) Why am I sure it's a bug?

1. The function is defined in `highgui.hpp`, and the error says it's _unresolved_ but not undefined. **That means there's no issue with importing the prototypes.**
2. A `namedWindow` call from the same module compiles successfully. (Yes, that's after commenting out the `imshow` call.) **That means there's no issue with importing the implementations.**

Here's the full error message:

```
error LNK2019: reference to unresolved external symbol ""void __cdecl cv::imshow(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class cv::debug_build_guard::_InputArray const &)"" (?imshow@cv@@YAXAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV_InputArray@debug_build_guard@1@@Z) in function main.
```

**This issue doesn't occur in OpenCV 2.4.10.**

### Steps to reproduce

```cpp
#include <iostream>
#include ""opencv2/opencv.hpp""
#include ""opencv2/highgui/highgui.hpp""

using namespace cv;

int main()
{
    VideoCapture capture(CAP_ANY);
    if (!capture.isOpened()) {
        std::cout << ""Cannot open the video stream"";
        return -1;
    }

    namedWindow(""Camera"");

    while (true) {
        Mat frame;
        capture >> frame;
        imshow(""Camera"", frame);
        if (waitKey(30) >= 0) return 0;
    }
}
```

This is my first program working with OpenCV. It just shows a video stream from the built-in camera.

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-23 08:16:35,question,Rotate Parameter for putText() function,"### Describe the feature and motivation

I am trying to rotate my putText() without rotating the whole frame. But it seems like a hard thing to do. Is it possible to add a new ""Rotate"" parameter to putText() function?

TIA

### Additional context

_No response_"
opencv/opencv,2023-06-20 14:26:05,question,How to cite OpenCV?,"### Describe the doc issue

I write a paper with OpenCV, and I want to cite OpenCV in my paper. So can I cite OpenCV in my paper.

### Fix suggestion

_No response_"
opencv/opencv,2023-06-06 04:51:36,question,Ordering of images in stitcher,"

I was performing a 360 degree images stitch operation using SIFT for feature extraction and Brute force matcher for matching.
I observed that the order of images which I provide does not matter as the output I get is in different order.
I used following program for stitching [Stitching detailed](https://raw.githubusercontent.com/opencv/opencv/4.x/samples/cpp/stitching_detailed.cpp)

Questions:

Can I modify the order of images in matching stage so that I get a particular scene in the centre of my panorama?
Do I need to reorder my feature vector before providing it to matcher?

Example 360 degree image:
Can I recenter the “river” to middle?
![output1](https://github.com/opencv/opencv/assets/121230355/a8720483-40f1-48cd-beda-7c6428ad6b6b)


### Additional context

_No response_"
opencv/opencv,2023-05-30 14:43:39,question,error: 'Mutex' in namespace 'cv' does not name a type AND  error: 'recursive_mutex' in namespace 'std' does not name a type,"### System Information

OPENCV version 4.7.0-dev
**Host platform OS**: Ubuntu 22.10
**Cross Compiler used for compilation** - arm-none-eabi-gcc (version gcc-arm-none-eabi-10.3-2021.10)
Used Cmake-GUI for configuring and generation - Not able to get the command line equivalent of the Build command (Advise me how to get)
**Target Platform**: ARM Cortex-R5 CPU, AM273x High performance R5F CPU MCU from Texas Instruments [TRM](https://www.ti.com/lit/ug/spruiu0c/spruiu0c.pdf?ts=1681297045683)

Here is my toolchain_cmake file
```
# set(CMAKE_SYSTEM_NAME               Generic)
# set(CMAKE_SYSTEM_PROCESSOR          arm)
# set(BAREMETAL_ARM_TOOLCHAIN_PATH    /home/kowshik/Documents/gcc/gcc-arm-11.2-2022.02-x86_64-arm-none-linux-gnueabihf/bin/)
# # Without that flag CMake is not able to pass test compilation check
# set(CMAKE_TRY_COMPILE_TARGET_TYPE   STATIC_LIBRARY)

# set(CMAKE_AR                        ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-ar${CMAKE_EXECUTABLE_SUFFIX})
# set(CMAKE_ASM_COMPILER              ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-gcc${CMAKE_EXECUTABLE_SUFFIX})
# set(CMAKE_C_COMPILER                ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-gcc${CMAKE_EXECUTABLE_SUFFIX})
# set(CMAKE_CXX_COMPILER              ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-g++${CMAKE_EXECUTABLE_SUFFIX})
# set(CMAKE_LINKER                    ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-ld${CMAKE_EXECUTABLE_SUFFIX})
# set(CMAKE_OBJCOPY                   ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-objcopy${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")
# set(CMAKE_RANLIB                    ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-ranlib${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")
# set(CMAKE_SIZE                      ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-size${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")
# set(CMAKE_STRIP                     ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-linux-gnueabihf-strip${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")

# set(CMAKE_C_FLAGS                   ""-mcpu=cortex-r5 -mthumb -mfloat-abi=hard -mfpu=vfpv3-d16 -fPIC -Wno-psabi -Wno-dev -fshort-enums -fshort-wchar -fdata-sections -ffunction-sections -Wl,--gc-sections"" CACHE INTERNAL """")
# set(CMAKE_CXX_FLAGS                 ""${CMAKE_C_FLAGS} -std=c++11 -fno-pie -fno-pic -Wno-dev -fpermissive -DCMAKE_CROSSCOMPILING"" CACHE INTERNAL """")
# #--specs=nosys.specs
# set(CMAKE_C_FLAGS_DEBUG             ""-Os -g"" CACHE INTERNAL """")
# set(CMAKE_C_FLAGS_RELEASE           ""-Os -DNDEBUG"" CACHE INTERNAL """")
# set(CMAKE_CXX_FLAGS_DEBUG           ""${CMAKE_C_FLAGS_DEBUG}"" CACHE INTERNAL """")
# set(CMAKE_CXX_FLAGS_RELEASE         ""${CMAKE_C_FLAGS_RELEASE}"" CACHE INTERNAL """")

# set(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)
# set(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)
# set(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)

#=========================================================
set(CMAKE_SYSTEM_NAME               Generic)
set(CMAKE_SYSTEM_PROCESSOR          arm)
set(BAREMETAL_ARM_TOOLCHAIN_PATH    /home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/bin/)
# Without that flag CMake is not able to pass test compilation check
set(CMAKE_TRY_COMPILE_TARGET_TYPE   STATIC_LIBRARY)

set(CMAKE_AR                        ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-ar${CMAKE_EXECUTABLE_SUFFIX})
set(CMAKE_ASM_COMPILER              ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-gcc${CMAKE_EXECUTABLE_SUFFIX})
set(CMAKE_C_COMPILER                ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-gcc${CMAKE_EXECUTABLE_SUFFIX})
set(CMAKE_CXX_COMPILER              ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-g++${CMAKE_EXECUTABLE_SUFFIX})
set(CMAKE_LINKER                    ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-ld${CMAKE_EXECUTABLE_SUFFIX})
set(CMAKE_OBJCOPY                   ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-objcopy${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")
set(CMAKE_RANLIB                    ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-ranlib${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")
set(CMAKE_SIZE                      ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-size${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")
set(CMAKE_STRIP                     ${BAREMETAL_ARM_TOOLCHAIN_PATH}arm-none-eabi-strip${CMAKE_EXECUTABLE_SUFFIX} CACHE INTERNAL """")

set(CMAKE_C_FLAGS                   ""-mcpu=cortex-r5 -mthumb -mfloat-abi=hard -mfpu=vfpv3-d16 -fPIC -Wno-psabi -Wno-dev -fshort-enums -fshort-wchar -fdata-sections -ffunction-sections -Wl,--gc-sections"" CACHE INTERNAL """")
set(CMAKE_CXX_FLAGS                 ""${CMAKE_C_FLAGS} --std=c++11 -fno-pie -fno-pic -Wno-dev -fpermissive"" CACHE INTERNAL """")
#--specs=nosys.specs
set(CMAKE_C_FLAGS_DEBUG             ""-Os -g"" CACHE INTERNAL """")
set(CMAKE_C_FLAGS_RELEASE           ""-Os -DNDEBUG"" CACHE INTERNAL """")
set(CMAKE_CXX_FLAGS_DEBUG           ""${CMAKE_C_FLAGS_DEBUG}"" CACHE INTERNAL """")
set(CMAKE_CXX_FLAGS_RELEASE         ""${CMAKE_C_FLAGS_RELEASE}"" CACHE INTERNAL """")

set(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)
set(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)
set(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)

###############################################
#,-L/home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/arm-none-eabi/lib/libstdc++.a -I/home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/arm-none-eabi/include/c++/10.3.1/arm-none-eabi/thumb/v7-r+fp.sp/hard/ -I/home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/arm-none-eabi/include/c++/10.3.1/ -include /home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/arm-none-eabi/include/c++/10.3.1/arm-none-eabi/thumb/v7-r+fp.sp/hard/bits/c++config.h -include /home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/arm-none-eabi/include/c++/10.3.1/bits/std_mutex.h

# set(CMAKE_SYSTEM_NAME Generic) core,calib3d,flann,imgproc
# set(CMAKE_SYSTEM_PROCESSOR armv7-r)
# set(CMAKE_C_COMPILER arm-none-eabi-gcc)
# set(CMAKE_CXX_COMPILER arm-none-eabi-g++)
# set(CMAKE_ASM_COMPILER arm-none-eabi-gcc)
# set(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)
# set(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)
# set(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)
# set(CMAKE_FIND_ROOT_PATH_MODE_PACKAGE ONLY)

# # Define the toolchain variables
# set(TOOLCHAIN_PREFIX /home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/bin/arm-none-eabi-)
# set(CMAKE_AR ${TOOLCHAIN_PREFIX}ar CACHE FILEPATH ""Archiver"")
# set(CMAKE_LINKER ${TOOLCHAIN_PREFIX}ld CACHE FILEPATH ""Linker"")
# set(CMAKE_NM ${TOOLCHAIN_PREFIX}nm CACHE FILEPATH ""Name tool"")
# set(CMAKE_OBJCOPY ${TOOLCHAIN_PREFIX}objcopy CACHE FILEPATH ""Object copy tool"")
# set(CMAKE_OBJDUMP ${TOOLCHAIN_PREFIX}objdump CACHE FILEPATH ""Object dump tool"")
# set(CMAKE_RANLIB ${TOOLCHAIN_PREFIX}ranlib CACHE FILEPATH ""Ranlib"")

```


### Detailed description

Once I have configured and generated my project here's my configuration log

```
OpenCV: system-specific configuration file is not found: 'Generic'
Detected processor: arm
Cleaning INTERNAL cached variable: ZLIB_LIBRARY
Cleaning INTERNAL cached variable: ZLIB_INCLUDE_DIR
Could NOT find ZLIB (missing: ZLIB_LIBRARY ZLIB_INCLUDE_DIR) (Required is at least version ""1.2.3"")
Could NOT find OpenJPEG (minimal suitable version: 2.0, recommended version >= 2.3.1). OpenJPEG will be built from sources
OpenJPEG: VERSION = 2.4.0, BUILD = opencv-4.7.0-dev-openjp2-2.4.0
OpenJPEG libraries will be built from sources: libopenjp2 (version ""2.4.0"")
math lib 'libm' not found; floating point support disabled
Processing WORLD modules...
    module opencv_core...
    module opencv_imgproc...
    module opencv_features2d...
    module opencv_imgcodecs...
Processing WORLD modules... DONE
Excluding from source files list (optimization is disabled): modules/imgproc/src/corner.avx.cpp
Excluding from source files list (optimization is disabled): modules/imgproc/src/imgwarp.avx2.cpp
Excluding from source files list (optimization is disabled): modules/imgproc/src/imgwarp.lasx.cpp
Excluding from source files list (optimization is disabled): modules/imgproc/src/imgwarp.sse4_1.cpp
Excluding from source files list (optimization is disabled): modules/imgproc/src/resize.avx2.cpp
Excluding from source files list (optimization is disabled): modules/imgproc/src/resize.lasx.cpp
Excluding from source files list (optimization is disabled): modules/imgproc/src/resize.sse4_1.cpp
Excluding from source files list (optimization is disabled): modules/features2d/src/fast.avx2.cpp

General configuration for OpenCV 4.7.0-dev =====================================
  Version control:               4.7.0-98-g0052d46b8e

  Platform:
    Timestamp:                   2023-05-30T14:09:09Z
    Host:                        Linux 5.19.0-21-generic x86_64
    Target:                      Generic arm
    CMake:                       3.22.1
    CMake generator:             Unix Makefiles
    CMake build tool:            /usr/bin/gmake
    Configuration:               Release

  CPU/HW features:
    Baseline:
      requested:                 DETECT
      disabled:                  VFPV3 NEON

  C/C++:
    Built as dynamic libs?:      NO
    C++ standard:                11
    C++ Compiler:                /home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/bin/arm-none-eabi-g++  (ver 10.3.1)
    C++ flags (Release):         -mcpu=cortex-r5 -mthumb -mfloat-abi=hard -mfpu=vfpv3-d16 -fPIC -Wno-psabi -Wno-dev -fshort-enums -fshort-wchar -fdata-sections -ffunction-sections -Wl,--gc-sections --std=c++11 -fno-pie -fno-pic -Wno-dev -fpermissive   -fsigned-char -ffast-math -W -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wno-psabi -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -fvisibility=hidden -fvisibility-inlines-hidden -Os -DNDEBUG  -DNDEBUG
    C++ flags (Debug):           -mcpu=cortex-r5 -mthumb -mfloat-abi=hard -mfpu=vfpv3-d16 -fPIC -Wno-psabi -Wno-dev -fshort-enums -fshort-wchar -fdata-sections -ffunction-sections -Wl,--gc-sections --std=c++11 -fno-pie -fno-pic -Wno-dev -fpermissive   -fsigned-char -ffast-math -W -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wno-psabi -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -fvisibility=hidden -fvisibility-inlines-hidden -Os -g  -DDEBUG -D_DEBUG
    C Compiler:                  /home/kowshik/Documents/gcc/gcc-arm-none-eabi-10.3-2021.10/bin/arm-none-eabi-gcc
    C flags (Release):           -mcpu=cortex-r5 -mthumb -mfloat-abi=hard -mfpu=vfpv3-d16 -fPIC -Wno-psabi -Wno-dev -fshort-enums -fshort-wchar -fdata-sections -ffunction-sections -Wl,--gc-sections   -fsigned-char -ffast-math -W -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-psabi -Wno-unnamed-type-template-args -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -fvisibility=hidden -Os -DNDEBUG  -DNDEBUG
    C flags (Debug):             -mcpu=cortex-r5 -mthumb -mfloat-abi=hard -mfpu=vfpv3-d16 -fPIC -Wno-psabi -Wno-dev -fshort-enums -fshort-wchar -fdata-sections -ffunction-sections -Wl,--gc-sections   -fsigned-char -ffast-math -W -Wreturn-type -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-psabi -Wno-unnamed-type-template-args -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -fno-omit-frame-pointer -ffunction-sections -fdata-sections  -fvisibility=hidden -Os -g  -DDEBUG -D_DEBUG
    Linker flags (Release):      -Wl,--gc-sections  
    Linker flags (Debug):        -Wl,--gc-sections  
    ccache:                      NO
    Precompiled headers:         NO
    Filesystem support is disabled
    Extra dependencies:
    3rdparty dependencies:       libpng libopenjp2 zlib

  OpenCV modules:
    To be built:                 core features2d imgcodecs imgproc world
    Disabled:                    calib3d flann highgui java_bindings_generator js_bindings_generator ml objc_bindings_generator objdetect photo python_bindings_generator python_tests stitching video videoio
    Disabled by dependency:      -
    Unavailable:                 dnn gapi java python2 python3 ts
    Applications:                -
    Documentation:               NO
    Non-free algorithms:         NO

  GUI: 

  Media I/O: 
    ZLib:                        build (ver 1.2.13)
    PNG:                         build (ver 1.6.37)
    JPEG 2000:                   build (ver 2.4.0)
    HDR:                         NO
    SUNRASTER:                   NO
    PXM:                         NO
    PFM:                         NO

  Video I/O:

  Parallel framework:            none

  Other third-party libraries:
    Custom HAL:                  NO

  Python (for build):            /usr/bin/python2.7

  Install to:                    /home/kowshik/Desktop/opencv_porting/opencv_master/opencv/build/install
-----------------------------------------------------------------

Configuring done
Generating done
```
and when the `make -s -j` command is used to compile the source, I am hit with the below error

```
[  0%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/thread.c.obj
[  0%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/bio.c.obj
[  1%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/cio.c.obj
[  1%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/dwt.c.obj
[  1%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/event.c.obj
[  2%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/image.c.obj
[  2%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/invert.c.obj
[  3%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/j2k.c.obj
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c: In function 'opj_j2k_dump_tile_info':
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11005:42: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11005 |         fprintf(out_stream, ""\\t\\t csty=%#x\\n"", l_default_tile->csty);
      |                                        ~~^     ~~~~~~~~~~~~~~~~~~~~
      |                                          |                   |
      |                                          unsigned int        OPJ_UINT32 {aka long unsigned int}
      |                                        %#lx
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11007:46: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11007 |         fprintf(out_stream, ""\\t\\t numlayers=%d\\n"", l_default_tile->numlayers);
      |                                             ~^     ~~~~~~~~~~~~~~~~~~~~~~~~~
      |                                              |                   |
      |                                              int                 OPJ_UINT32 {aka long unsigned int}
      |                                             %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11008:40: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11008 |         fprintf(out_stream, ""\\t\\t mct=%x\\n"", l_default_tile->mct);
      |                                       ~^     ~~~~~~~~~~~~~~~~~~~
      |                                        |                   |
      |                                        unsigned int        OPJ_UINT32 {aka long unsigned int}
      |                                       %lx
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11016:45: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_INT32' {aka 'long int'} [-Wformat=]
11016 |             fprintf(out_stream, ""\\t\\t comp %d {\\n"", compno);
      |                                            ~^       ~~~~~~
      |                                             |       |
      |                                             int     OPJ_INT32 {aka long int}
      |                                            %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11017:48: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11017 |             fprintf(out_stream, ""\\t\\t\\t csty=%#x\\n"", l_tccp->csty);
      |                                              ~~^     ~~~~~~~~~~~~
      |                                                |           |
      |                                                |           OPJ_UINT32 {aka long unsigned int}
      |                                                unsigned int
      |                                              %#lx
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11018:57: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11018 |             fprintf(out_stream, ""\\t\\t\\t numresolutions=%d\\n"", l_tccp->numresolutions);
      |                                                        ~^     ~~~~~~~~~~~~~~~~~~~~~~
      |                                                         |           |
      |                                                         int         OPJ_UINT32 {aka long unsigned int}
      |                                                        %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11019:50: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11019 |             fprintf(out_stream, ""\\t\\t\\t cblkw=2^%d\\n"", l_tccp->cblkw);
      |                                                 ~^     ~~~~~~~~~~~~~
      |                                                  |           |
      |                                                  int         OPJ_UINT32 {aka long unsigned int}
      |                                                 %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11020:50: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11020 |             fprintf(out_stream, ""\\t\\t\\t cblkh=2^%d\\n"", l_tccp->cblkh);
      |                                                 ~^     ~~~~~~~~~~~~~
      |                                                  |           |
      |                                                  int         OPJ_UINT32 {aka long unsigned int}
      |                                                 %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11021:51: warning: format '%x' expects argument of type 'unsigned int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11021 |             fprintf(out_stream, ""\\t\\t\\t cblksty=%#x\\n"", l_tccp->cblksty);
      |                                                 ~~^     ~~~~~~~~~~~~~~~
      |                                                   |           |
      |                                                   |           OPJ_UINT32 {aka long unsigned int}
      |                                                   unsigned int
      |                                                 %#lx
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11022:49: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11022 |             fprintf(out_stream, ""\\t\\t\\t qmfbid=%d\\n"", l_tccp->qmfbid);
      |                                                ~^     ~~~~~~~~~~~~~~
      |                                                 |           |
      |                                                 int         OPJ_UINT32 {aka long unsigned int}
      |                                                %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11026:40: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11026 |                 fprintf(out_stream, ""(%d,%d) "", l_tccp->prcw[resno], l_tccp->prch[resno]);
      |                                       ~^        ~~~~~~~~~~~~~~~~~~~
      |                                        |                    |
      |                                        int                  OPJ_UINT32 {aka long unsigned int}
      |                                       %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11026:43: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11026 |                 fprintf(out_stream, ""(%d,%d) "", l_tccp->prcw[resno], l_tccp->prch[resno]);
      |                                          ~^                          ~~~~~~~~~~~~~~~~~~~
      |                                           |                                      |
      |                                           int                                    OPJ_UINT32 {aka long unsigned int}
      |                                          %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11031:49: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11031 |             fprintf(out_stream, ""\\t\\t\\t qntsty=%d\\n"", l_tccp->qntsty);
      |                                                ~^     ~~~~~~~~~~~~~~
      |                                                 |           |
      |                                                 int         OPJ_UINT32 {aka long unsigned int}
      |                                                %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11032:51: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11032 |             fprintf(out_stream, ""\\t\\t\\t numgbits=%d\\n"", l_tccp->numgbits);
      |                                                  ~^     ~~~~~~~~~~~~~~~~
      |                                                   |           |
      |                                                   int         OPJ_UINT32 {aka long unsigned int}
      |                                                  %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11037:40: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_INT32' {aka 'long int'} [-Wformat=]
11037 |                 fprintf(out_stream, ""(%d,%d) "", l_tccp->stepsizes[bandno].mant,
      |                                       ~^        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |                                        |                                 |
      |                                        int                               OPJ_INT32 {aka long int}
      |                                       %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11037:43: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_INT32' {aka 'long int'} [-Wformat=]
11037 |                 fprintf(out_stream, ""(%d,%d) "", l_tccp->stepsizes[bandno].mant,
      |                                          ~^
      |                                           |
      |                                           int
      |                                          %ld
11038 |                         l_tccp->stepsizes[bandno].expn);
      |                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |                                                  |
      |                                                  OPJ_INT32 {aka long int}
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11043:51: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_INT32' {aka 'long int'} [-Wformat=]
11043 |             fprintf(out_stream, ""\\t\\t\\t roishift=%d\\n"", l_tccp->roishift);
      |                                                  ~^     ~~~~~~~~~~~~~~~~
      |                                                   |           |
      |                                                   int         OPJ_INT32 {aka long int}
      |                                                  %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c: In function 'opj_j2k_dump_MH_index':
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11141:69: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11141 |         fprintf(out_stream, ""\\t\\t nb of tile-part in tile [%d]=%d\\n"", it_tile,
      |                                                            ~^         ~~~~~~~
      |                                                             |         |
      |                                                             int       OPJ_UINT32 {aka long unsigned int}
      |                                                            %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11141:73: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11141 |     fprintf(out_stream, ""\\t\\t nb of tile-part in tile [%d]=%d\\n"", it_tile,
      |                                                            ~^
      |                                                             |
      |                                                             int
      |                                                            %ld
11142 |             nb_of_tile_part);
      |             ~~~~~~~~~~~~~~~                                  
      |             |
      |             OPJ_UINT32 {aka long unsigned int}

/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11146:45: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11146 |                         fprintf(out_stream, ""\\t\\t\\t tile-part[%d]: star_pos=%"" PRIi64 "", end_header=%""
      |                                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
11147 |                                 PRIi64 "", end_pos=%"" PRIi64 "".\\n"",
11148 |                                 it_tile_part,
      |                                 ~~~~~~~~~~~~ 
      |                                 |
      |                                 OPJ_UINT32 {aka long unsigned int}
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c: In function 'opj_j2k_dump_MH_info':
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11179:34: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11179 |     fprintf(out_stream, ""\\t tx0=%d, ty0=%d\\n"", p_j2k->m_cp.tx0, p_j2k->m_cp.ty0);
      |                                 ~^             ~~~~~~~~~~~~~~~
      |                                  |                        |
      |                                  int                      OPJ_UINT32 {aka long unsigned int}
      |                                 %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11179:42: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11179 |     fprintf(out_stream, ""\\t tx0=%d, ty0=%d\\n"", p_j2k->m_cp.tx0, p_j2k->m_cp.ty0);
      |                                         ~^                      ~~~~~~~~~~~~~~~
      |                                          |                                 |
      |                                          int                               OPJ_UINT32 {aka long unsigned int}
      |                                         %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11180:34: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11180 |     fprintf(out_stream, ""\\t tdx=%d, tdy=%d\\n"", p_j2k->m_cp.tdx, p_j2k->m_cp.tdy);
      |                                 ~^             ~~~~~~~~~~~~~~~
      |                                  |                        |
      |                                  int                      OPJ_UINT32 {aka long unsigned int}
      |                                 %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11180:42: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11180 |     fprintf(out_stream, ""\\t tdx=%d, tdy=%d\\n"", p_j2k->m_cp.tdx, p_j2k->m_cp.tdy);
      |                                         ~^                      ~~~~~~~~~~~~~~~
      |                                          |                                 |
      |                                          int                               OPJ_UINT32 {aka long unsigned int}
      |                                         %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11181:33: warning: format '%d' expects argument of type 'int', but argument 3 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11181 |     fprintf(out_stream, ""\\t tw=%d, th=%d\\n"", p_j2k->m_cp.tw, p_j2k->m_cp.th);
      |                                ~^            ~~~~~~~~~~~~~~
      |                                 |                       |
      |                                 int                     OPJ_UINT32 {aka long unsigned int}
      |                                %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11181:40: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11181 |     fprintf(out_stream, ""\\t tw=%d, th=%d\\n"", p_j2k->m_cp.tw, p_j2k->m_cp.th);
      |                                       ~^                     ~~~~~~~~~~~~~~
      |                                        |                                |
      |                                        int                              OPJ_UINT32 {aka long unsigned int}
      |                                       %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c: In function 'j2k_dump_image_header':
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11201:33: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11201 |     fprintf(out_stream, ""%s x0=%d, y0=%d\\n"", tab, img_header->x0, img_header->y0);
      |                                ~^                 ~~~~~~~~~~~~~~
      |                                 |                           |
      |                                 int                         OPJ_UINT32 {aka long unsigned int}
      |                                %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11201:40: warning: format '%d' expects argument of type 'int', but argument 5 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11201 |     fprintf(out_stream, ""%s x0=%d, y0=%d\\n"", tab, img_header->x0, img_header->y0);
      |                                       ~^                          ~~~~~~~~~~~~~~
      |                                        |                                    |
      |                                        int                                  OPJ_UINT32 {aka long unsigned int}
      |                                       %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11202:37: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11202 |     fprintf(out_stream,     ""%s x1=%d, y1=%d\\n"", tab, img_header->x1,
      |                                    ~^                 ~~~~~~~~~~~~~~
      |                                     |                           |
      |                                     int                         OPJ_UINT32 {aka long unsigned int}
      |                                    %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11202:44: warning: format '%d' expects argument of type 'int', but argument 5 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11202 |     fprintf(out_stream,     ""%s x1=%d, y1=%d\\n"", tab, img_header->x1,
      |                                           ~^
      |                                            |
      |                                            int
      |                                           %ld
11203 |             img_header->y1);
      |             ~~~~~~~~~~~~~~                  
      |                       |
      |                       OPJ_UINT32 {aka long unsigned int}
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11204:39: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11204 |     fprintf(out_stream, ""%s numcomps=%d\\n"", tab, img_header->numcomps);
      |                                      ~^          ~~~~~~~~~~~~~~~~~~~~
      |                                       |                    |
      |                                       int                  OPJ_UINT32 {aka long unsigned int}
      |                                      %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11209:50: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11209 |             fprintf(out_stream, ""%s\\t component %d {\\n"", tab, compno);
      |                                                 ~^            ~~~~~~
      |                                                  |            |
      |                                                  int          OPJ_UINT32 {aka long unsigned int}
      |                                                 %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c: In function 'j2k_dump_image_comp_header':
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11233:33: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11233 |     fprintf(out_stream, ""%s dx=%d, dy=%d\\n"", tab, comp_header->dx, comp_header->dy);
      |                                ~^                 ~~~~~~~~~~~~~~~
      |                                 |                            |
      |                                 int                          OPJ_UINT32 {aka long unsigned int}
      |                                %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11233:40: warning: format '%d' expects argument of type 'int', but argument 5 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11233 |     fprintf(out_stream, ""%s dx=%d, dy=%d\\n"", tab, comp_header->dx, comp_header->dy);
      |                                       ~^                           ~~~~~~~~~~~~~~~
      |                                        |                                      |
      |                                        int                                    OPJ_UINT32 {aka long unsigned int}
      |                                       %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11234:35: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11234 |     fprintf(out_stream, ""%s prec=%d\\n"", tab, comp_header->prec);
      |                                  ~^          ~~~~~~~~~~~~~~~~~
      |                                   |                     |
      |                                   int                   OPJ_UINT32 {aka long unsigned int}
      |                                  %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c:11235:35: warning: format '%d' expects argument of type 'int', but argument 4 has type 'OPJ_UINT32' {aka 'long unsigned int'} [-Wformat=]
11235 |     fprintf(out_stream, ""%s sgnd=%d\\n"", tab, comp_header->sgnd);
      |                                  ~^          ~~~~~~~~~~~~~~~~~
      |                                   |                     |
      |                                   int                   OPJ_UINT32 {aka long unsigned int}
      |                                  %ld
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/3rdparty/openjpeg/openjp2/j2k.c: At top level:
cc1: note: unrecognized command-line option '-Wno-implicit-const-int-float-conversion' may have been intended to silence earlier diagnostics
cc1: note: unrecognized command-line option '-Wno-unnamed-type-template-args' may have been intended to silence earlier diagnostics
cc1: note: unrecognized command-line option '-Wno-dev' may have been intended to silence earlier diagnostics
[  3%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/jp2.c.obj
[  3%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/mct.c.obj
[  4%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/mqc.c.obj
[  4%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/openjpeg.c.obj
[  5%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/opj_clock.c.obj
[  5%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/pi.c.obj
[  5%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/t1.c.obj
[  6%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/t2.c.obj
[  6%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/tcd.c.obj
[  6%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/tgt.c.obj
[  7%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/function_list.c.obj
[  7%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/opj_malloc.c.obj
[  8%] Building C object 3rdparty/openjpeg/openjp2/CMakeFiles/libopenjp2.dir/sparse_array.c.obj
[  8%] Linking C static library ../../lib/liblibopenjp2.a
[  8%] Built target libopenjp2
[  9%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/adler32.c.obj
[  9%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/compress.c.obj
[  9%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/crc32.c.obj
[ 10%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/deflate.c.obj
[ 10%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/gzclose.c.obj
[ 11%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/gzlib.c.obj
[ 11%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/gzread.c.obj
[ 11%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/gzwrite.c.obj
[ 12%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/inflate.c.obj
[ 12%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/infback.c.obj
[ 13%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/inftrees.c.obj
[ 13%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/inffast.c.obj
[ 13%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/trees.c.obj
[ 14%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/uncompr.c.obj
[ 14%] Building C object 3rdparty/zlib/CMakeFiles/zlib.dir/zutil.c.obj
[ 15%] Linking C static library ../lib/libzlib.a
[ 15%] Built target zlib
[ 15%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/png.c.obj
[ 16%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngerror.c.obj
[ 16%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngget.c.obj
[ 17%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngmem.c.obj
[ 17%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngpread.c.obj
[ 17%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngread.c.obj
[ 18%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngrio.c.obj
[ 18%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngrtran.c.obj
[ 18%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngrutil.c.obj
[ 19%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngset.c.obj
[ 19%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngtrans.c.obj
[ 20%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngwio.c.obj
[ 20%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngwrite.c.obj
[ 20%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngwtran.c.obj
[ 21%] Building C object 3rdparty/libpng/CMakeFiles/libpng.dir/pngwutil.c.obj
[ 21%] Linking C static library ../lib/liblibpng.a
[ 21%] Built target libpng
[ 21%] Processing OpenCL kernels (imgproc)
-- /home/kowshik/Desktop/opencv_porting/opencv_master/opencv/build/modules/world/opencl_kernels_imgproc.hpp contains the same content
[ 22%] Processing OpenCL kernels (core)
-- /home/kowshik/Desktop/opencv_porting/opencv_master/opencv/build/modules/world/opencl_kernels_core.hpp contains the same content
[ 22%] Processing OpenCL kernels (features2d)
-- /home/kowshik/Desktop/opencv_porting/opencv_master/opencv/build/modules/world/opencl_kernels_features2d.hpp contains the same content
[ 23%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/__/core/src/algorithm.cpp.obj
In file included from /home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/src/precomp.hpp:53,
                 from /home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/src/algorithm.cpp:43:
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/include/opencv2/core/utility.hpp:718:14: error: 'recursive_mutex' in namespace 'std' does not name a type
  718 | typedef std::recursive_mutex Mutex;
      |              ^~~~~~~~~~~~~~~
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/include/opencv2/core/utility.hpp:63:1: note: 'std::recursive_mutex' is defined in header '<mutex>'; did you forget to '#include <mutex>'?
   62 | #include <mutex>  // std::mutex, std::lock_guard
  +++ |+#include <mutex>
   63 | #endif
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/include/opencv2/core/utility.hpp:719:29: error: 'Mutex' is not a member of 'cv'
  719 | typedef std::lock_guard<cv::Mutex> AutoLock;
      |                             ^~~~~
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/include/opencv2/core/utility.hpp:719:29: error: 'Mutex' is not a member of 'cv'
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/include/opencv2/core/utility.hpp:719:34: error: template argument 1 is invalid
  719 | typedef std::lock_guard<cv::Mutex> AutoLock;
      |                                  ^
In file included from /home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/src/algorithm.cpp:43:
/home/kowshik/Desktop/opencv_porting/opencv_master/opencv/modules/core/src/precomp.hpp:369:5: error: 'Mutex' in namespace 'cv' does not name a type
  369 | cv::Mutex& getInitializationMutex();
      |     ^~~~~
cc1plus: note: unrecognized command-line option '-Wno-unnamed-type-template-args' may have been intended to silence earlier diagnostics
cc1plus: note: unrecognized command-line option '-Wno-dev' may have been intended to silence earlier diagnostics
cc1plus: note: unrecognized command-line option '-Wno-dev' may have been intended to silence earlier diagnostics
make[2]: *** [modules/world/CMakeFiles/opencv_world.dir/build.make:161: modules/world/CMakeFiles/opencv_world.dir/__/core/src/algorithm.cpp.obj] Error 1
make[1]: *** [CMakeFiles/Makefile2:811: modules/world/CMakeFiles/opencv_world.dir/all] Error 2
make: *** [Makefile:166: all] Error 2
```

### Steps to reproduce

1. Download the OPENCV source code
2. Download the arm-none-eabi-gcc compiler from this [link](https://developer.arm.com/-/media/Files/downloads/gnu-rm/10.3-2021.10/gcc-arm-none-eabi-10.3-2021.10-x86_64-linux.tar.bz2?rev=78196d3461ba4c9089a67b5f33edf82a&hash=D484B37FF37D6FC3597EBE2877FB666A41D5253B)
3. Configure the Opencv with cmake-gui by using the module as stated in the first section i.e., (core, features2d, imgproc, imgcodecs build list)
4. Compile the `build/` with `make -s` and observe the same errors are received. 

Please note that the reason behind this error is know that the arm-none-eabi-gcc compiler doesn't support the Threads by default and when tried to run `arm-none-eabi-gcc -v` it gave the following output where it says `Thread model :single` instead of posix however I want to solve this error because I am trying to compile opencv for a Embedded platform as stated before.

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-05-23 10:01:05,question,How to compile OpenCV into a single static library file?,"### Describe the feature and motivation

I compiled using -DBUILD_opencv_world=ON -DBUILD_SHARED_LIBS=OFF, which resulted in libopencv_world.a in the lib directory and several .a files in the lib/opencv/3rdparty/ directory. I would like to merge all the .a files from the 3rdparty directory with the libopencv_world.a file into one. I have tried various methods, including using the ar command for merging, but the resulting static library throws various errors when used. Is there any way to compile all the modules or dependencies into a single static library?

### Additional context

_No response_"
opencv/opencv,2023-05-19 09:43:29,question,Image Reshape  in c++,"- Input image = cv::dnn::blobFromImage(image, ScaleFactor, cv::Size(Width, Height), false, false);
- This function return 1 x 3 x  Width x Height.
- But some model requested  1 x  Width x Height x 3.
- In case difficult to reshape image.
- How to convert 1 x 3 x  Width x Height image size to 1 x  Width x Height x 3 in c++?"
opencv/opencv,2023-05-17 13:38:57,question,Creating an ROI on a live video,"### System Information

Jetson AGX Xavier
Jetpack 4.6.1
Opencv 4.1.1
CMake 3.23.1

### Detailed description

I am trying to create an ROI on a live video and for a while it seems to work but after some time the programme seems to think the ROI has moved out of the image plane. I'm not to sure on how this is happening and I've not found any potential fixes which have worked so far. I have attached an image of the error I receive.
![IMG_20230517_143253641_HDR](https://github.com/opencv/opencv/assets/115797971/7a1e9b47-f321-4f4b-bb0b-30cfb13d8b02)


### Steps to reproduce

```
int rx = 450;
int ry = 200;
int rw = 300;
int rh = 100;

VideoCapture cap(0);

while (true) {
cap >> img;

Rect roiRect;
roiRect = Rect(rx,ry,rw,rh);
Mat roi = img(roiRect);

imshow(""frame"", img);
}
```
This is just a small snippet of the main code.

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-24 06:46:09,question,Cannot load TensorFlow SavedModel created with Teachable Machine,"### System Information

OpenCV version: Current Branch 4.x
Operating System: Windows 11
Compiler: Visual Studio 17 2022, Win32 Release build

### Detailed description

I built a simple model with Teachable Machine and downloaded it in the Saved Model format. After unzipping, I tried to load the model in OpenCV:

```cpp
cv::dnn::readNet(onnxPath.getString());
```

This gave me a `cv::Exception` with the following message:

```
OpenCV(4.7.0-dev) C:\\tools\\opencv-4.8.0-pre\\Source\\modules\\dnn\\src\\tensorflow\\tf_io.cpp:42: error: (-2:Unspecified error) FAILED: ReadProtoFromBinaryFile(param_file, param). Failed to parse GraphDef file: C:\\Users\\...\\converted_savedmodel\\model.savedmodel\\saved_model.pb in function 'cv::dnn::ReadTFNetParamsFromBinaryFileOrDie'
```

### Steps to reproduce

To reproduce it, just head over to https://teachablemachine.withgoogle.com/train/image and train a model with two classes, then export it to TensorFlow SavedModel, and try to load the model in OpenCV.

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-11 04:59:43,question,The parameter patternSize behaves unexpected in findCirclesGrid(),"### System Information

OpenCV python version: 4.7.0.72
Operating System / Platform: macOS 13.3.1
Python version: 3.10.10

### Detailed description

According to the [documentation](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#gad1205c4b803a21597c7d6035f5efd775), `patternSize` should be `(points_per_row, points_per_colum)`. However, it seems that only when I set `patternSize` as `(points_per_colum, points_per_row)` can make the return value `retval` of `findCirclesGrid()` become `True`.

### Steps to reproduce

Code:
```python
import cv2

img = cv2.imread(f'test.png')

patternSize = (7, 10)
retval, centers = cv2.findCirclesGrid(img, patternSize, cv2.CirclesGridFinderParameters_SYMMETRIC_GRID)
print(f'{patternSize=} {retval=}')

patternSize = (10, 7)
retval, centers = cv2.findCirclesGrid(img, patternSize, cv2.CirclesGridFinderParameters_SYMMETRIC_GRID)
print(f'{patternSize=} {retval=}')
```
Output:
```
patternSize=(7, 10) retval=False
patternSize=(10, 7) retval=True
```
Test Data:
![test](https://user-images.githubusercontent.com/47266984/231060351-23263d76-710d-4b60-8cdd-7b4fdec76615.png)




### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-04-03 08:06:03,question,How about Edges?,"### Descripe the feature and motivation

They can be detected using edge detection algorithms like Sobel, Canny, or Laplacian. Edges are useful for tasks like object detection, image segmentation, and feature matching.

### Additional context

_No response_"
opencv/opencv,2023-03-10 00:29:28,question,Does DNN support intel N100 processor,"I'd like to buy a mini PC with intel N100 processor.  I am not sure if ""cv2.dnn.readNetFromTensorflow"" support the new processor. I use the function to detect face in real time. Thanks in advance for your help!"
opencv/opencv,2023-03-04 04:50:01,question,How to image process the on the original image like the of the given output.,"### System Information

I have this image Original Image:- 

![img1](https://user-images.githubusercontent.com/105721260/222876300-2f997dc1-9bc1-4eb2-b574-16a78297ad35.jpg)

 ,And after processing it above we want the following output [output image] :-
![3](https://user-images.githubusercontent.com/105721260/222876309-5a4d8fcc-0809-498c-9611-f9617af25cc7.jpg)




### Detailed description

`
I expecting this result is When I process on the original image, the output image given above should come in the same result as this.'`

### Steps to reproduce

`code:
int main()
{
        // Read image
        Mat imgOffice = imread(""img29.jpg"");

        // Remove background using chroma keying
        Mat imgNoBg;
        double threshold = 5; // adjust as necessary
      //  cv::cvtColor(imgOffice, imgOffice, COLOR_BGR2HSV); // Convert to HSV color space
      //  cv::inRange(imgOffice, Scalar(-200, -200, -200), Scalar(150, 50, 50), imgNoBg); // Detect green color range and set as the background
        cv::inRange(imgOffice, Scalar(0, 0, 0), Scalar(50, 110, 100), imgNoBg);
      //  cv::morphologyEx(imgNoBg, imgNoBg, cv::MORPH_CLOSE, cv::getStructuringElement(cv::MORPH_ERODE, cv::Size(250, 10))); // Fill small holes in the foreground
       //  cv::morphologyEx(imgNoBg, imgNoBg, cv::MORPH_CLOSE, cv::getStructuringElement(cv::MORPH_ELLIPSE, cv::Size(150, 20)));
         cv::morphologyEx(imgNoBg, imgNoBg, cv::MORPH_CLOSE, cv::getStructuringElement(cv::MORPH_ELLIPSE, cv::Size(255, 20)));
        // Display both images
        namedWindow(""image"", WINDOW_NORMAL);
        namedWindow(""output"", WINDOW_NORMAL);
        imshow(""image"", imgOffice);
        imshow(""output"", imgNoBg);
        // imwrite(""final-output1(MORPH_ELLIPSE).jpg"", imgNoBg);
        // imwrite(""o2.jpg"", imgNoBg);
        waitKey(0);
        destroyAllWindows();
        return 0;`

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-02-15 00:10:03,question,OpenCV no longer builds with Cuda 12.0.1,"### System Information

OpenCV version: 4.6.0
Operating System / Platform: Gentoo Linux
Compiler & compiler version: GCC 12.2.1_p20230121-r1



### Detailed description

Fails to build due to missing symbols.

[build.log](https://github.com/opencv/opencv/files/10737886/build.log)


### Steps to reproduce

```bash
emerge  -avuDUt --backtrack=30 --verbose-conflicts @world
```

This rebuilds anything needing an update, and the command I used.

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-02-09 06:55:10,question,Colud we use USAC with PNP?,"### Descripe the feature and motivation

Because using RANSAC with PNP shows bad effects.

### Additional context

_No response_"
opencv/opencv,2023-02-02 09:57:37,question,Unable to compile 4.5.5 with ARM,"### System Information

OpenCV version: 4.5.5
Operating System / Platform: Ubuntu 18.04
Compiler & compiler version: GCC 7.5.0

### Detailed description

I tried to build opencv through the options of the command in **Steps to reproduce**.
However, I checked the following error message:
```
[ 97%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/superres/src/super_resolution.cpp.o
[ 97%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/opencl_kernels_superres.cpp.o
[ 97%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/deblurring.cpp.o
[ 97%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/fast_marching.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/frame_source.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/global_motion.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/inpainting.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/log.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/motion_stabilizing.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/optical_flow.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/outlier_rejection.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/stabilizer.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/home/nvidia/opencv_contrib-4.5.5/modules/videostab/src/wobble_suppression.cpp.o
[ 98%] Building CXX object modules/world/CMakeFiles/opencv_world.dir/src/world_init.cpp.o
[ 98%] Linking CXX shared library ../../lib/libopencv_world.so
[ 98%] Built target opencv_world
Scanning dependencies of target opencv_img_hash
Scanning dependencies of target opencv_annotation
Scanning dependencies of target opencv_version
Scanning dependencies of target opencv_interactive-calibration
Scanning dependencies of target opencv_visualisation
Scanning dependencies of target opencv_waldboost_detector
[ 98%] Building CXX object apps/version/CMakeFiles/opencv_version.dir/opencv_version.cpp.o
[ 98%] Building CXX object apps/annotation/CMakeFiles/opencv_annotation.dir/opencv_annotation.cpp.o
[ 98%] Building CXX object apps/visualisation/CMakeFiles/opencv_visualisation.dir/opencv_visualisation.cpp.o
[ 98%] Building CXX object modules/world/tools/waldboost_detector/CMakeFiles/opencv_waldboost_detector.dir/waldboost_detector.cpp.o
[ 98%] Building CXX object apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/calibController.cpp.o
[ 98%] Building CXX object modules/img_hash/CMakeFiles/opencv_img_hash.dir/src/average_hash.cpp.o
[ 98%] Linking CXX executable ../../../../bin/opencv_waldboost_detector
[ 98%] Linking CXX executable ../../bin/opencv_version
[ 99%] Building CXX object modules/img_hash/CMakeFiles/opencv_img_hash.dir/src/block_mean_hash.cpp.o
[ 99%] Linking CXX executable ../../bin/opencv_annotation
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_add_match_subsystem'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_get_list_entry'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_unref'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_unref'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_parent_with_subsystem_devtype'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_sysattr_value'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_scan_devices'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_new'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_name'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_next'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_new_from_syspath'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_devnode'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_unref'
../../../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_new'
collect2: error: ld returned 1 exit status
modules/world/tools/waldboost_detector/CMakeFiles/opencv_waldboost_detector.dir/build.make:95: recipe for target 'bin/opencv_waldboost_detector' failed
make[2]: *** [bin/opencv_waldboost_detector] Error 1
CMakeFiles/Makefile2:2548: recipe for target 'modules/world/tools/waldboost_detector/CMakeFiles/opencv_waldboost_detector.dir/all' failed
make[1]: *** [modules/world/tools/waldboost_detector/CMakeFiles/opencv_waldboost_detector.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
[ 99%] Building CXX object modules/img_hash/CMakeFiles/opencv_img_hash.dir/src/color_moment_hash.cpp.o
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_add_match_subsystem'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_get_list_entry'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_parent_with_subsystem_devtype'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_sysattr_value'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_scan_devices'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_new'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_name'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_next'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_new_from_syspath'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_devnode'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_new'
collect2: error: ld returned 1 exit status
apps/version/CMakeFiles/opencv_version.dir/build.make:95: recipe for target 'bin/opencv_version' failed
make[2]: *** [bin/opencv_version] Error 1
CMakeFiles/Makefile2:3214: recipe for target 'apps/version/CMakeFiles/opencv_version.dir/all' failed
make[1]: *** [apps/version/CMakeFiles/opencv_version.dir/all] Error 2
[ 99%] Building CXX object modules/img_hash/CMakeFiles/opencv_img_hash.dir/src/img_hash_base.cpp.o
[ 99%] Linking CXX executable ../../bin/opencv_visualisation
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_add_match_subsystem'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_get_list_entry'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_parent_with_subsystem_devtype'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_sysattr_value'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_scan_devices'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_new'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_name'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_next'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_new_from_syspath'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_devnode'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_new'
collect2: error: ld returned 1 exit status
apps/annotation/CMakeFiles/opencv_annotation.dir/build.make:95: recipe for target 'bin/opencv_annotation' failed
make[2]: *** [bin/opencv_annotation] Error 1
CMakeFiles/Makefile2:3049: recipe for target 'apps/annotation/CMakeFiles/opencv_annotation.dir/all' failed
make[1]: *** [apps/annotation/CMakeFiles/opencv_annotation.dir/all] Error 2
[ 99%] Building CXX object modules/img_hash/CMakeFiles/opencv_img_hash.dir/src/marr_hildreth_hash.cpp.o
[ 99%] Building CXX object apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/calibPipeline.cpp.o
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_add_match_subsystem'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_get_list_entry'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_parent_with_subsystem_devtype'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_sysattr_value'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_scan_devices'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_new'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_name'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_next'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_new_from_syspath'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_devnode'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_new'
collect2: error: ld returned 1 exit status
apps/visualisation/CMakeFiles/opencv_visualisation.dir/build.make:95: recipe for target 'bin/opencv_visualisation' failed
make[2]: *** [bin/opencv_visualisation] Error 1
CMakeFiles/Makefile2:3104: recipe for target 'apps/visualisation/CMakeFiles/opencv_visualisation.dir/all' failed
make[1]: *** [apps/visualisation/CMakeFiles/opencv_visualisation.dir/all] Error 2
[ 99%] Building CXX object apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/frameProcessor.cpp.o
[ 99%] Building CXX object apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/main.cpp.o
[ 99%] Building CXX object modules/img_hash/CMakeFiles/opencv_img_hash.dir/src/phash.cpp.o
[ 99%] Building CXX object modules/img_hash/CMakeFiles/opencv_img_hash.dir/src/radial_variance_hash.cpp.o
[ 99%] Building CXX object apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/parametersController.cpp.o
[ 99%] Building CXX object apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/rotationConverters.cpp.o
[ 99%] Linking CXX shared library ../../lib/libopencv_img_hash.so
[ 99%] Built target opencv_img_hash
[ 99%] Linking CXX executable ../../bin/opencv_interactive-calibration
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_add_match_subsystem'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_get_list_entry'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_parent_with_subsystem_devtype'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_sysattr_value'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_scan_devices'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_new'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_name'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_list_entry_get_next'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_new_from_syspath'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_device_get_devnode'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_unref'
../../lib/libopencv_world.so.4.5.5: undefined reference to `udev_enumerate_new'
collect2: error: ld returned 1 exit status
apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/build.make:225: recipe for target 'bin/opencv_interactive-calibration' failed
make[2]: *** [bin/opencv_interactive-calibration] Error 1
CMakeFiles/Makefile2:3159: recipe for target 'apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/all' failed
make[1]: *** [apps/interactive-calibration/CMakeFiles/opencv_interactive-calibration.dir/all] Error 2
Makefile:162: recipe for target 'all' failed
make: *** [all] Error 2
```

I thought libudev was not installed on my system. However, it exists in the system.
```
$ pkg-config --cflags --libs libudev
-ludev
$ apt list --installed | grep libudev

WARNING: apt does not have a stable CLI interface. Use with caution in scripts.

libudev-dev/bionic-updates,bionic-security,now 237-3ubuntu10.56 arm64 [installed]
libudev1/bionic-updates,bionic-security,now 237-3ubuntu10.56 arm64 [installed]
$ ll /lib/aarch64-linux-gnu/ | grep libudev*
lrwxrwxrwx  1 root root      12 Sep  6 03:18 libudev.so -> libudev.so.1
lrwxrwxrwx  1 root root      16 Sep  6 03:18 libudev.so.1 -> libudev.so.1.6.9
-rw-r--r--  1 root root  104504 Sep  6 03:18 libudev.so.1.6.9
```

### Steps to reproduce

```
cmake -D CMAKE_BUILD_TYPE=RELEASE \\
-D CMAKE_INSTALL_PREFIX=/usr/local \\
-D BUILD_opencv_python3=ON \\
-D BUILD_opencv_world=ON \\
-D WITH_CUDA=ON \\
-D CUDA_ARCH_BIN=""7.2"" \\
-D CUDA_ARCH_PTX="""" \\
-D WITH_CUDNN=ON \\
-D ENABLE_FAST_MATH=ON \\
-D CUDA_FAST_MATH=ON \\
-D OPENCV_DNN_CUDA=ON \\
-D INSTALL_PYTHON_EXAMPLES=OFF \\
-D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib-4.5.5/modules \\
-D OPENCV_ENABLE_NONFREE=ON \\
-D OPENCV_GENERATE_PKGCONFIG=ON \\
-D BUILD_EXAMPLES=OFF \\
-D WITH_GPHOTO2=OFF \\
-D BUILD_TESTS=OFF \\
-D WITH_VTK=OFF \\
-D WITH_GSTREAMER=OFF \\
-D BUILD_PERF_TESTS=OFF ..
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-01-30 10:14:24,question,putText() documentation is misleading about origin point,"### Descripe the doc issue

There is a mistake in ```putText()``` function documentation:

https://docs.opencv.org/4.x/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576
https://github.com/opencv/opencv/blob/540aa13300b2aede45d328a228f79fb26ad1a5cd/modules/imgproc/include/opencv2/imgproc.hpp#L4781-L4801

> putText(..., Point org, ..., bool bottomLeftOrigin = false)

1) ```org``` - Bottom-left corner of the text string in the image.
2) ```bottomLeftOrigin``` - When true, the image data origin is at the bottom-left corner. Otherwise, it is at the top-left corner.

By default ```bottomLeftOrigin=false```, so documentation about ```org``` argument is wrong.

### Fix suggestion

I see two alternatives:

1) If ```bottomLeftOrigin``` will be changed to ```true``` - documentation is nearly OK (but I think documentation of ```org``` argument should mention ```bottomLeftOrigin```). Probably this is not an option because of backward compatibility concerns.
2) Update documentation like this:

```
@param org Top-left corner of the text string in the image if bottomLeftOrigin is false. Otherwise, it is at the bottom-left corner.
@param bottomLeftOrigin When false, the image data origin is at the top-left corner. Otherwise, it is at the bottom-left corner.
```

If this documentation update is OK - I can create a PR, if I miss something or there are a better way - I will be glad to know."
opencv/opencv,2023-01-23 10:56:30,question,Unable to run the Simple RTSP program in docker,"OpenCV => 4.7
Operating System / Platform => ubuntu 20.04
Compiler => python

I need to take and RTSP stream which is currently from VLC player rtsp://localhost:8554 to the program running inside the docker and the docker container has to give the video output. for that I did like this but everytime I'm getting the same error which is related qt and xcb Please look into below details ind dockerfile and command

Kindly help me to resolve this issue 

Hi I'm trying to dockerize this code
************************************************************************** CODE *********************************************************************
```
import cv2
import os

RTSP_URL = 'rtsp://0.0.0.0:8554/'

os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'rtsp_transport;udp'

cap = cv2.VideoCapture(RTSP_URL, cv2.CAP_FFMPEG)

if not cap.isOpened():
    print('Cannot open RTSP stream')
    exit(-1)

while True:
    _, frame = cap.read()
    cv2.imshow('RTSP stream', frame)

    if cv2.waitKey(1) == 27:
        break

cap.release()
cv2.destroyAllWindows()
```
************************************************************************** CODE *********************************************************************
Dockerfile below:-

*************************************************************************DOCKERFILE**************************************************************
```
FROM ubuntu:20.04
ARG DEBIAN_FRONTEND=noninteractive
RUN mkdir /app

WORKDIR /app
RUN chmod -R 777 /app
RUN apt update
RUN DEBIAN_FRONTEND=noninteractive TZ=Asia/Kolkata apt install -y tzdata
RUN apt install --no-install-recommends -y python3-pip 
RUN apt-get install -y libgl1-mesa-dev
RUN apt-get install -y libglib2.0-0
RUN pip install opencv-python
WORKDIR /app
COPY . .
CMD [""python3"", ""-u"", ""import_cv2.py""]
```
*************************************************************************END*************************************************************************

RUN command: docker run -it --net=host --device /dev/video1 -p 8554:8554 -v /tmp/.X11-unix/:/tmp/.X11-unix abab670c544b
```
ERROR I'm getting is 

qt.qpa.plugin: Could not load the Qt platform plugin ""xcb"" in ""/app/cv2/qt/plugins"" even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: xcb.
```

"
opencv/opencv,2023-01-11 11:12:07,question,How disable MT default on MSVC?,"### Descripe the doc issue

Got errors when link opencv.lib with Unreal Engine:

```
  检测到“RuntimeLibrary”的不匹配项: 值“MT_StaticRelease”不匹配值“MD_DynamicRelease”(SharedPCH.Engine.ShadowErrors.h.obj 中)
```

UE default using MD, but opencv default using MT

How to enable MD while still using static lib?

### Fix suggestion

_No response_"
opencv/opencv,2023-01-04 06:25:57,question,cv::setNumThreads does not work with Apple GCD,"### System Information

OpenCV version: 4.7.0
OS: macOS 13.0.1 on Apple M1
Compiler: Apple clang version 14.0.0 (clang-1400.0.29.202) Target: arm64-apple-darwin22.1.0

### Detailed description

Compile OpenCV with default configuration, which results in using GCD for parallel framework. In this case, calling `cv::setNumThreads` always fails and `cv::getNumThreads()` always returns 8. Using 8 threads on Apple M1 would result in worse performance since half of the cores are relatively weak.

One possible solution is using OpenMP instead on Apple platform. Tried to build with option `-DWITH_OPENMP=ON`, but got the following error when building:

```
modules/core/src/parallel.cpp:123:14: fatal error: 'omp.h' file not found
    #include <omp.h>
```

My `libomp` is installed via homebrew.

### Steps to reproduce

```cpp
#include <iostream>
#include <numeric> // accumulate
#include <algorithm> // min_element

#include ""opencv2/opencv.hpp""

using namespace std;
using namespace cv;

int main()
{
    const vector<int> input_shape{1, 3, 224, 224};
    Mat blob(4, input_shape.data(), CV_32FC1);
    randu(blob, 0.f, 1.f);

    dnn::Net net = dnn::readNet(""../some_nets.onnx"");
    net.setInput(blob);

    // set thread num
    int thread_num = 4;
    setNumThreads(thread_num);
    std::cout << ""thread_num = "" << getNumThreads() << std::endl;

    // warmup
    net.forward();
    // benchmark
    TickMeter tm;
    vector<double> times;
    for (int i = 0; i < 10; ++i)
    {
        tm.reset();
        tm.start();
        net.forward();
        tm.stop();
        times.push_back(tm.getTimeMilli());
    }
    double mean = std::accumulate(times.begin(), times.end(), 0.f) / times.size();
    double median = (times[4] + times[5]) / 2;
    double minimum = *(std::min_element(times.begin(), times.end()));
    std::cout << cv::format(""mean = %f, median = %f, min = %f\\n"", mean, median, minimum);
    return 0;
}
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-01-03 12:07:02,question,Avoid using system zlib,"### Descripe the feature and motivation

How to forely using static build zlib rather than system one?

### Additional context

How to forely using static build zlib rather than system one?"
opencv/opencv,2022-12-28 16:59:10,question,Error trying to build OpenCV 4.5.5 with OpenVINO 2023.2,"### System Information

OpenCV version: 4.5.5
Operating System / Platform: Windows 10
Inference Engine (OpenVINO) version: 2022.3
Python version: 3.9.6

### Detailed description

Hey guys,

So basically I was trying to build OpenCV 4.5.5 with OpenVINO 2022.3 and CUDA and got the following error:

C:\\Users\\cesar.gouveia\\Projects\\OpenCV-Package\\opencv_mirror\\modules\\dnn\\src\\ie_ngraph.cpp(83,1): error C2440: 'initializin
g': cannot convert from 'initializer list' to 'ov::DiscreteTypeInfo' [C:\\Users\\cesar.gouveia\\Projects\\OpenCV-Package\\opencv
_mirror\\build\\modules\\world\\opencv_world.vcxproj]
C:\\Users\\cesar.gouveia\\Projects\\OpenCV-Package\\opencv_mirror\\modules\\dnn\\src\\ie_ngraph.cpp(83,1): message : No constructor
could take the source type, or constructor overload resolution was ambiguous [C:\\Users\\cesar.gouveia\\Projects\\OpenCV-Packag
e\\opencv_mirror\\build\\modules\\world\\opencv_world.vcxproj]
C:\\Users\\cesar.gouveia\\Projects\\OpenCV-Package\\opencv_mirror\\modules\\dnn\\src\\ie_ngraph.cpp(83,56): error C2131: expression
did not evaluate to a constant [C:\\Users\\cesar.gouveia\\Projects\\OpenCV-Package\\opencv_mirror\\build\\modules\\world\\opencv_wor
ld.vcxproj]

I have done this process multiple times and the only thing that I changed was the OpenVINO version (changed from 2021.4 to 2022.3). The cmake finds OpenVINO new version (2022.3) correctly, but when I'm building opencv_world cannot be generated because there are code errors. Does OpenCV 4.5.5 supports OpenVINO 2022.3? Is there any new procedure to build OpenCV with OpenVINO, like a new flag that you need to turn on or something? If there is anything that I should try and if you can help I really appreciate. 
Note: in the meantime I'm building OpenVINO 2022.3 with the new released version of OpenCV (4.7.0) to check if the problem remains.

Thanks,
César.

### Steps to reproduce

OpenCV flags used:

cmake .. -DBUILD_opencv_apps=OFF -DBUILD_opencv_aruco=OFF -DBUILD_opencv_bgsegm=OFF -DBUILD_opencv_bioinspired=OFF -DBUILD_opencv_calib3d=ON -DBUILD_opencv_ccalib=ON -DBUILD_opencv_core=ON -DBUILD_opencv_datasets=OFF -DBUILD_opencv_dnn=ON -DBUILD_opencv_dnn_objdetect=OFF -DBUILD_opencv_dnn_superres=OFF -DBUILD_opencv_dpm=OFF -DBUILD_opencv_face=OFF -DBUILD_opencv_features2d=ON -DBUILD_opencv_flann=ON -DBUILD_opencv_fuzzy=OFF -DBUILD_opencv_gapi=OFF -DBUILD_opencv_hfs=OFF -DBUILD_opencv_highgui=ON -DBUILD_opencv_img_hash=ON -DBUILD_opencv_imgcodecs=ON -DBUILD_opencv_imgproc=ON -DBUILD_opencv_intensity_transform=OFF -DBUILD_java_bindings_generator=OFF -DBUILD_opencv_js=OFF -DBUILD_opencv_line_descriptor=OFF -DBUILD_opencv_mcc=OFF -DBUILD_opencv_ml=ON -DBUILD_opencv_objc_bindings_generator=OFF -DBUILD_opencv_objdetect=ON -DBUILD_opencv_optflow=OFF -DBUILD_opencv_phase_unwrapping=OFF -DBUILD_opencv_photo=ON -DBUILD_opencv_plot=ON -DBUILD_opencv_python3=OFF -DBUILD_opencv_python_bindings_generator=OFF -DBUILD_opencv_python_tests=OFF -DBUILD_opencv_quality=OFF -DBUILD_opencv_rapid=OFF -DBUILD_opencv_reg=OFF -DBUILD_opencv_rgdb=OFF -DBUILD_opencv_saliency=OFF -DBUILD_opencv_shape=OFF -DBUILD_opencv_stereo=OFF -DBUILD_opencv_stitching=OFF -DBUILD_opencv_structured_light=OFF -DBUILD_opencv_superres=OFF -DBUILD_opencv_surface_matching=OFF -DBUILD_opencv_text=OFF -DBUILD_opencv_tracking=OFF -DBUILD_opencv_ts=OFF -DBUILD_opencv_video=ON -DBUILD_opencv_videoio=ON -DBUILD_opencv_videostab=OFF -DBUILD_opencv_world=ON -DBUILD_opencv_xfeatures2d=ON -DBUILD_opencv_ximgproc=ON -DBUILD_opencv_xobjdetect=ON -DBUILD_opencv_xphoto=ON -DCMAKE_CONFIGURATION_TYPES=Release -DCMAKE_GENERATOR_PLATFORM=x64 -T v142 -DWITH_FFMPEG=ON -DWITH_INF_ENGINE=ON -DENABLE_CXX11=ON -DOPENCV_ENABLE_NONFREE=OFF -DBUILD_JAVA=OFF -DWITH_MSMF=OFF -DWITH_MSMF_DXVA=OFF -DOPENCV_EXTRA_MODULES_PATH=""C:/Users/cesar.gouveia/Projects/OpenCV-Package/opencv_contrib/modules"" -DBUILD_ZLIB=ON -DBUILD_opencv_hdf=OFF -DWITH_CUDA=ON -DENABLE_FAST_MATH=1 -DCUDA_FAST_MATH=1 -DWITH_CUBLAS=1

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-12-25 03:39:42,question,How to disable zlib?,"### System Information

I using `BUILD_ZLIB=OFF`, but it still calls some `gzgets` API from zlib.

And I found in code, it hard coded:

<img width=""510"" alt=""image"" src=""https://user-images.githubusercontent.com/21303438/209456235-b80431de-a5c2-4e68-a207-a8e48f35d962.png"">

Am confused here... how to disable zlib totally?

**don;t say features2d or some module need zlib, I just want disable all of them, I don't need zlib at all**

### Detailed description

no

### Steps to reproduce

no

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-12-23 15:05:49,question,OpenCV contrib attribute not found - AttributeError: module 'cv2' has no attribute 'face',"### System Information

In case you get `AttributeError: module 'cv2' has no attribute 'face'` (or any other [module](https://github.com/opencv/opencv_contrib/tree/4.x/modules) (`rgbd`, `ximgproc `, `bgsegm`, etc.) and you already have opencv-contrib-python installed, it might be that `import cv2` is actually importing `opencv-python` library instead of `opencv-contrib-python`.

My solution was to uninstall opencv-python.
```
pip install opencv-contrib-python -U --force

# When running python script that uses cv2.rgbd it crashes
python .\\depth_preview.py
  File "".\\depth_preview.py"", line 44, in <module>
    depthCleaner = cv2.rgbd.DepthCleaner_create(cv2.CV_16U, 7, cv2.rgbd.DepthCleaner_DEPTH_CLEANER_NIL )
AttributeError: module 'cv2' has no attribute 'rgbd'

# Uninstalling opencv-python made it work
python -mpip uninstall opencv-python
```


### Detailed description

opencv-python used instead of opencv-contrib-python

### Steps to reproduce

opencv-python used instead of opencv-contrib-python

### Issue submission checklist

- [X] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-12-21 13:33:25,question,An nparray that uses an inconsistent save from cv2.imwrite,"### System Information

// example for python user
OpenCV python version: 4
Operating System / Platform: Ubuntu 20.04
Python version: 3.8

### Detailed description

I ran the following code, The outputs should be the same. Why are they different?

### Steps to reproduce

import cv2
import numpy as np
from PIL import Image
a = np.zeros([512,512,3]).astype(np.uint8)

for i in range(100):

    if i>50:
        a[i][i][0] = i
        a[i][i][1] = i
        a[i][i][2] = i

    else:
        a[i][i][0] = i
        a[i][i][1] = i
        a[i][i][2] = i

print(a.max())
cv2.imwrite(""1.jpg"",a)

img = cv2.imread(""1.jpg"")
print(img.max())

### Issue submission checklist

- [X] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-12-19 03:19:14,question,Give it option to build opencv x86 static lib on a ARM M1 mac,"### Descripe the feature and motivation

Give it option to build opencv x86 static lib on a ARM M1 mac.

Currently, whenever enviroment set, opencv always build arm static on a arm mac, this is no problem, but sometimes users need  x86 lib on M1 mac, For example, build a thirdparty lib for UE5.



### Additional context

Give it option to build opencv x86 static lib on a ARM M1 mac.

Currently, whenever enviroment set, opencv always build arm static on a arm mac, this is no problem, but sometimes users need  x86 lib on M1 mac, For example, build a thirdparty lib for UE5.
"
opencv/opencv,2022-12-06 08:30:12,question,android jni VideoCapture can't open videofile,"### System Information

OpenCV version: 4.6.0
Operating System / Platform: android 12
Compiler & compiler version: cmake 3.10.2

### Detailed description

```
E/cv::error(): OpenCV(4.6.0) Error: Requested object was not found (could not open directory: /data/app/~~sbu7r1TB_QJQDnKVkr9ABQ==/com.tencent.yolov5ncnn-5hoZtN5FqSkRrIkcIlVUuQ==/base.apk!/lib/arm64-v8a) in glob_rec, file /build/master_pack-android/opencv/modules/core/src/glob.cpp, line 279
A/libc: Fatal signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0x797302f480 in tid 19587 (cent.yolov5ncnn), pid 19587 (cent.yolov5ncnn)
```
i use cv::imread and cv2::imwrite normal,but when i use VideoCapture open video,it will report the error
even if i use 4.5.4,it return the same error
my code is simple,error in line2 `capture.open`

### Steps to reproduce

```
//    // read video
    cv::VideoCapture capture;
    capture.open(""/storage/emulated/0/DCIM/test.mp4"");

```
### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-12-03 18:57:51,question,Protobuf compatibility...,"### Descripe the feature and motivation

My **ENV**:

- Ubuntu 22.04
- gcc: (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
- Protobuf: 3.20.3
- OpenCV 4.6.0 (building)


Failed to build **OpenCV dnn caffe** with this version of **Protobuf**:

```console
/usr/local/include/google/protobuf/arenastring.h:318:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::ClearToEmpty()’
  318 |   void ClearToEmpty();
      |        ^~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:318:8: note:   candidate expects 0 arguments, 2 provided
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘void opencv_caffe::PythonParameter::_internal_set_layer(const string&)’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36145:13: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::Set(const string*, const string&, google::protobuf::Arena*)’
36145 |   layer_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value, GetArena());
      |   ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:266:8: note: candidate: ‘template<class RefWrappedType> void google::protobuf::internal::ArenaStringPtr::Set(std::reference_wrapper<_Tp>, google::protobuf::Arena*)’
  266 |   void Set(std::reference_wrapper<RefWrappedType> const_string_ref,
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:266:8: note:   template argument deduction/substitution failed:
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36145:13: note:   mismatched types ‘std::reference_wrapper<_Tp>’ and ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’}
36145 |   layer_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value, GetArena());
      |   ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:255:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(google::protobuf::ConstStringParam, google::protobuf::Arena*)’
  255 |   void Set(ConstStringParam value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:255:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:256:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(std::string&&, google::protobuf::Arena*)’
  256 |   void Set(std::string&& value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:256:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:401:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, google::protobuf::Arena*)’
  401 | inline void ArenaStringPtr::Set(const char* s, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:401:13: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:405:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, size_t, google::protobuf::Arena*)’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:405:45: note:   no known conversion for argument 1 from ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’} to ‘const char*’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |                                 ~~~~~~~~~~~~^
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘void opencv_caffe::PythonParameter::set_layer(std::string&&)’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36149:13: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::Set(const string*, std::remove_reference<std::__cxx11::basic_string<char>&>::type, google::protobuf::Arena*)’
36149 |   layer_.Set(
      |   ~~~~~~~~~~^
36150 |     &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::move(value), GetArena());
      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:266:8: note: candidate: ‘template<class RefWrappedType> void google::protobuf::internal::ArenaStringPtr::Set(std::reference_wrapper<_Tp>, google::protobuf::Arena*)’
  266 |   void Set(std::reference_wrapper<RefWrappedType> const_string_ref,
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:266:8: note:   template argument deduction/substitution failed:
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36149:13: note:   mismatched types ‘std::reference_wrapper<_Tp>’ and ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’}
36149 |   layer_.Set(
      |   ~~~~~~~~~~^
36150 |     &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::move(value), GetArena());
      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:255:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(google::protobuf::ConstStringParam, google::protobuf::Arena*)’
  255 |   void Set(ConstStringParam value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:255:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:256:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(std::string&&, google::protobuf::Arena*)’
  256 |   void Set(std::string&& value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:256:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:401:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, google::protobuf::Arena*)’
  401 | inline void ArenaStringPtr::Set(const char* s, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:401:13: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:405:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, size_t, google::protobuf::Arena*)’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:405:45: note:   no known conversion for argument 1 from ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’} to ‘const char*’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |                                 ~~~~~~~~~~~~^
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘void opencv_caffe::PythonParameter::set_layer(const char*)’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36156:13: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::Set(const string*, std::string, google::protobuf::Arena*)’
36156 |   layer_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
      |   ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
36157 |               GetArena());
      |               ~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:266:8: note: candidate: ‘template<class RefWrappedType> void google::protobuf::internal::ArenaStringPtr::Set(std::reference_wrapper<_Tp>, google::protobuf::Arena*)’
  266 |   void Set(std::reference_wrapper<RefWrappedType> const_string_ref,
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:266:8: note:   template argument deduction/substitution failed:
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36156:13: note:   mismatched types ‘std::reference_wrapper<_Tp>’ and ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’}
36156 |   layer_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
      |   ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
36157 |               GetArena());
      |               ~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:255:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(google::protobuf::ConstStringParam, google::protobuf::Arena*)’
  255 |   void Set(ConstStringParam value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:255:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:256:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(std::string&&, google::protobuf::Arena*)’
  256 |   void Set(std::string&& value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:256:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:401:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, google::protobuf::Arena*)’
  401 | inline void ArenaStringPtr::Set(const char* s, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:401:13: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:405:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, size_t, google::protobuf::Arena*)’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:405:45: note:   no known conversion for argument 1 from ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’} to ‘const char*’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |                                 ~~~~~~~~~~~~^
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘void opencv_caffe::PythonParameter::set_layer(const char*, size_t)’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36163:13: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::Set(const string*, std::string, google::protobuf::Arena*)’
36163 |   layer_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(
      |   ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
36164 |       reinterpret_cast<const char*>(value), size), GetArena());
      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:266:8: note: candidate: ‘template<class RefWrappedType> void google::protobuf::internal::ArenaStringPtr::Set(std::reference_wrapper<_Tp>, google::protobuf::Arena*)’
  266 |   void Set(std::reference_wrapper<RefWrappedType> const_string_ref,
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:266:8: note:   template argument deduction/substitution failed:
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36163:13: note:   mismatched types ‘std::reference_wrapper<_Tp>’ and ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’}
36163 |   layer_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), ::std::string(
      |   ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
36164 |       reinterpret_cast<const char*>(value), size), GetArena());
      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:255:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(google::protobuf::ConstStringParam, google::protobuf::Arena*)’
  255 |   void Set(ConstStringParam value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:255:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:256:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(std::string&&, google::protobuf::Arena*)’
  256 |   void Set(std::string&& value, Arena* arena);
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:256:8: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:401:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, google::protobuf::Arena*)’
  401 | inline void ArenaStringPtr::Set(const char* s, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:401:13: note:   candidate expects 2 arguments, 3 provided
/usr/local/include/google/protobuf/arenastring.h:405:13: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::Set(const char*, size_t, google::protobuf::Arena*)’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |             ^~~~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:405:45: note:   no known conversion for argument 1 from ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’} to ‘const char*’
  405 | inline void ArenaStringPtr::Set(const char* s, size_t n, Arena* arena) {
      |                                 ~~~~~~~~~~~~^
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘std::string* opencv_caffe::PythonParameter::_internal_mutable_layer()’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36169:24: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::Mutable(const string*, google::protobuf::Arena*)’
36169 |   return layer_.Mutable(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArena());
      |          ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:275:16: note: candidate: ‘std::string* google::protobuf::internal::ArenaStringPtr::Mutable(google::protobuf::Arena*)’
  275 |   std::string* Mutable(Arena* arena);
      |                ^~~~~~~
/usr/local/include/google/protobuf/arenastring.h:275:16: note:   candidate expects 1 argument, 2 provided
/usr/local/include/google/protobuf/arenastring.h:276:16: note: candidate: ‘std::string* google::protobuf::internal::ArenaStringPtr::Mutable(const google::protobuf::internal::LazyString&, google::protobuf::Arena*)’
  276 |   std::string* Mutable(const LazyString& default_value, Arena* arena);
      |                ^~~~~~~
/usr/local/include/google/protobuf/arenastring.h:276:42: note:   no known conversion for argument 1 from ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’} to ‘const google::protobuf::internal::LazyString&’
  276 |   std::string* Mutable(const LazyString& default_value, Arena* arena);
      |                        ~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘std::string* opencv_caffe::PythonParameter::release_layer()’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36177:17: error: ‘struct google::protobuf::internal::ArenaStringPtr’ has no member named ‘ReleaseNonDefault’; did you mean ‘ClearToDefault’?
36177 |   return layer_.ReleaseNonDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArena());
      |                 ^~~~~~~~~~~~~~~~~
      |                 ClearToDefault
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘void opencv_caffe::PythonParameter::set_allocated_layer(std::string*)’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36185:22: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::SetAllocated(const string*, std::string*&, google::protobuf::Arena*)’
36185 |   layer_.SetAllocated(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), layer,
      |   ~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
36186 |       GetArena());
      |       ~~~~~~~~~~~     
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:309:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::SetAllocated(std::string*, google::protobuf::Arena*)’
  309 |   void SetAllocated(std::string* value, Arena* arena);
      |        ^~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:309:8: note:   candidate expects 2 arguments, 3 provided
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘void opencv_caffe::PythonParameter::clear_param_str()’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36199:26: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::ClearToEmpty(const string*, google::protobuf::Arena*)’
36199 |   param_str_.ClearToEmpty(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), GetArena());
      |   ~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:318:8: note: candidate: ‘void google::protobuf::internal::ArenaStringPtr::ClearToEmpty()’
  318 |   void ClearToEmpty();
      |        ^~~~~~~~~~~~
/usr/local/include/google/protobuf/arenastring.h:318:8: note:   candidate expects 0 arguments, 2 provided
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h: In member function ‘void opencv_caffe::PythonParameter::_internal_set_param_str(const string&)’:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36219:17: error: no matching function for call to ‘google::protobuf::internal::ArenaStringPtr::Set(const string*, const string&, google::protobuf::Arena*)’
36219 |   param_str_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value, GetArena());
      |   ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.h:25,
                 from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
/usr/local/include/google/protobuf/arenastring.h:266:8: note: candidate: ‘template<class RefWrappedType> void google::protobuf::internal::ArenaStringPtr::Set(std::reference_wrapper<_Tp>, google::protobuf::Arena*)’
  266 |   void Set(std::reference_wrapper<RefWrappedType> const_string_ref,
      |        ^~~
/usr/local/include/google/protobuf/arenastring.h:266:8: note:   template argument deduction/substitution failed:
In file included from ....../opencv/build/modules/dnn/opencv-caffe.pb.cc:4:
....../opencv/build/modules/dnn/opencv-caffe.pb.h:36219:17: note:   mismatched types ‘std::reference_wrapper<_Tp>’ and ‘const string*’ {aka ‘const std::__cxx11::basic_string<char>*’}
36219 |   param_str_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), value, GetArena());
      |   ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```


Did anybody meet the same issue?




### Additional context

_No response_"
opencv/opencv,2022-11-23 11:03:28,question,remap cv2,"### System Information

OpenCV python version: 4.5.4.6
Operating System / Platform: Ubuntu 20.04
Python version: 3.8.1

### Detailed description

remap function cut end of image

I have x_coords and y_coord and use remap, but output missing end of image 
![image](https://user-images.githubusercontent.com/42369268/203529944-74521cb1-52cf-42fb-8640-8d3af0506113.png)

ori img:
![original](https://user-images.githubusercontent.com/42369268/203530279-82ac558e-5a84-433c-98a8-da28172dbd46.jpg)


### Steps to reproduce

Here is code use remap:
[x_coords.txt](https://github.com/opencv/opencv/files/10074795/x_coords.txt)
[y_coords.txt](https://github.com/opencv/opencv/files/10074797/y_coords.txt)

```
import numpy as np 
import cv2
x_coords = np.loadtxt('x_coords.txt')
y_coords = np.loadtxt('y_coords.txt')
remapped = cv2.remap(ori, x_coords, y_coords,cv2.INTER_CUBIC,
                         None, cv2.BORDER_REPLICATE)

cv2.imshow(""remap"",remapped)
cv2.waitKey()
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [ ] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-11-15 17:49:16,question,Unable to build C++ solution using OpenCV 4.5.5 with OpenVINO 2021.4.689,"### System Information

OpenCV version: 4.5.5
Operating System / Platform: Ubuntu 18.04
CUDA version: 11.2
CuDNN version: 8.1.0

### Detailed description

Hey,

So my ultimate goal is to build OpenCV 4.5.5 with support for CUDA 11.2 and OpenVINO 2021.4.689 and install it so that I can further use it within my C++ solution. OpenCV builds correctly with support for both cuda and openvino versions mencioned above but then when I'm compiling my C++ code I get the following error:

/usr/bin/ld: warning: libinference_engine_transformations.so, needed by //opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so, not found (try using -rpath or -rpath-link)
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `vtable for ngraph::pass::SmartReshape'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `vtable for ngraph::pass::SetBatchSize'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::op::util::has_f16_constants(std::shared_ptr<ngraph::Function const> const&)'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::pass::DisableConvertConstantFoldingOnConstPath::DisableConvertConstantFoldingOnConstPath(std::vector<ngraph::element::Type, std::allocator<ngraph::element::Type> > const&)'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::PrimitivesPriority::getPrimitivesPriority[abi:cxx11]() const'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `vtable for ngraph::pass::Serialize'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::DequantizationAttr::getDequantizationAttr[abi:cxx11]() const'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `typeinfo for ngraph::VariantWrapper<ngraph::DequantizationAttr>'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::pass::Serialize::run_on_function(std::shared_ptr<ngraph::Function>)'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::pass::Serialize::Serialize(std::ostream&, std::ostream&, ngraph::pass::Serialize::Version, std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ngraph::OpSet, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, ngraph::OpSet> > >)'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::FusedNames::getNames[abi:cxx11]() const'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `typeinfo for ngraph::VariantWrapper<ngraph::PrimitivesPriority>'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `typeinfo for ngraph::VariantWrapper<ngraph::FusedNames>'
//opt/intel/openvino_2021/inference_engine/lib/intel64/libinference_engine.so: undefined reference to `ngraph::pass::Serialize::Serialize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, ngraph::pass::Serialize::Version, std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ngraph::OpSet, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, ngraph::OpSet> > >)'

Any other information that you need feel free to ask and thank you so much for the help.

### Steps to reproduce

The OpenCV CMake flags that I used were the following ones:

 cmake .. -DBUILD_opencv_apps=OFF -DBUILD_opencv_aruco=OFF -DBUILD_opencv_bgsegm=OFF -DBUILD_opencv_bioinspired=OFF -DBUILD_opencv_calib3d=ON -DBUILD_opencv_ccalib=ON -DBUILD_opencv_core=ON -DBUILD_opencv_datasets=OFF -DBUILD_opencv_dnn=ON -DBUILD_opencv_dnn_objdetect=OFF -DBUILD_opencv_dnn_superres=OFF -DBUILD_opencv_dpm=OFF -DBUILD_opencv_face=OFF -DBUILD_opencv_features2d=ON -DBUILD_opencv_flann=ON -DBUILD_opencv_fuzzy=OFF -DBUILD_opencv_gapi=OFF -DBUILD_opencv_hfs=OFF -DBUILD_opencv_highgui=ON -DBUILD_opencv_img_hash=ON -DBUILD_opencv_imgcodecs=ON -DBUILD_opencv_imgproc=ON -DBUILD_opencv_intensity_transform=OFF -DBUILD_java_bindings_generator=OFF -DBUILD_opencv_js=OFF -DBUILD_opencv_line_descriptor=OFF -DBUILD_opencv_mcc=OFF -DBUILD_opencv_ml=ON -DBUILD_opencv_objc_bindings_generator=OFF -DBUILD_opencv_objdetect=ON -DBUILD_opencv_optflow=OFF -DBUILD_opencv_phase_unwrapping=OFF -DBUILD_opencv_photo=ON -DBUILD_opencv_plot=ON -DBUILD_opencv_python3=OFF -DBUILD_opencv_python_bindings_generator=OFF -DBUILD_opencv_python_tests=OFF -DBUILD_opencv_quality=OFF -DBUILD_opencv_rapid=OFF -DBUILD_opencv_reg=OFF -DBUILD_opencv_rgdb=OFF -DBUILD_opencv_saliency=OFF -DBUILD_opencv_shape=OFF -DBUILD_opencv_stereo=OFF -DBUILD_opencv_stitching=OFF -DBUILD_opencv_structured_light=OFF -DBUILD_opencv_superres=OFF -DBUILD_opencv_surface_matching=OFF -DBUILD_opencv_text=OFF -DBUILD_opencv_tracking=OFF -DBUILD_opencv_ts=OFF -DBUILD_opencv_video=ON -DBUILD_opencv_videoio=ON -DBUILD_opencv_videostab=OFF -DBUILD_opencv_world=ON -DBUILD_opencv_xfeatures2d=ON -DBUILD_opencv_ximgproc=ON -DBUILD_opencv_xobjdetect=ON -DBUILD_opencv_xphoto=ON -DCMAKE_CONFIGURATION_TYPES=Release -DWITH_FFMPEG=ON -DWITH_INF_ENGINE=ON -DINF_ENGINE_LIB_DIRS=""/opt/intel/openvino_2021/inference_engine/lib/intel64"" -DINF_ENGINE_INCLUDE_DIRS=""/opt/intel/openvino_2021/inference_engine/include"" -DCMAKE_FIND_ROOT_PATH=""/opt/intel/openvino_2021/deployment_tools/ngraph;/opt/intel/openvino_2021/inference_engine/external/tbb"" -DINF_ENGINE_RELEASE=2021040689 -DENABLE_CXX11=ON -DOPENCV_ENABLE_NONFREE=OFF -DBUILD_JAVA=OFF -DWITH_MSMF=OFF -DWITH_MSMF_DXVA=OFF -DOPENCV_EXTRA_MODULES_PATH=~/Development/opencv_contrib-4.5.5/modules/ -DBUILD_ZLIB=ON -DBUILD_opencv_hdf=OFF -DWITH_CUDA=ON -DENABLE_FAST_MATH=1 -DCUDA_FAST_MATH=1 -DWITH_CUBLAS=1 -DCUDA_ARCH_BIN=7.5

The output of those CMake flags is the following:
[CMakeOutputOpenCV.txt](https://github.com/opencv/opencv/files/10014706/CMakeOutputOpenCV.txt)



### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [x] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-11-11 07:34:29,question,The ARM32 Linux platform uses opencv3.4.1,"### Descripe the doc issue

Hello, I use the ARM32 Linux platform and the operating system is Ubuntu16.04. After compiling Opencv3.4.1 with the cross-compiler, the following errors occurred when I generated an opencv program separately:
The above is my error information
![图片](https://user-images.githubusercontent.com/101849755/201290327-9ce51833-d03a-493c-bafb-1d63211cf42d.png)
"
opencv/opencv,2022-11-07 12:00:02,question,Unable to link statically to OpenCV 4.2,"### System Information

OpenCV version: 4.2
Operating System / Platform: Ubuntu 20.04
Compiler & compiler version: GCC 9.4.0

### Detailed description

I am trying to build a shared library that uses OpenCV. I have openCV installed via `apt-get install libopencv-dev` in the docker image where I am building my library, but I need my library to be used in a lean Ubuntu 20.04 machine (ie: no `apt-get install libopencv-dev`, all required `.so` need to be placed in a specific folder).

This means that I need to either

1. place all openCV .so and (their pre-requisites as well) in a specific folder
OR
2. statically link with openCV (and its pre-requisites)

Since 1. seems very painful I was trying to follow 2; apparently it should be a matter of simply setting
`set(OpenCV_STATIC ON)`
before doing
`find_package( OpenCV REQUIRED )`
on my library's `CMakeLists.txt`

Unfortunately this does not seem to work as OpenCV is still dynamically linked. I saw numerous threads about statically linking with OpenCV but they all seem to build opencv from source instead of using the system-installed one. Is it not possible to statically link OpenCV without building from source?

### Steps to reproduce

Build a simple `cmake` project using Opencv with `set(OpenCV_STATIC ON)` and check that the produced library is dynamically linking OpenCV

See snippet below for an example

```
set(OpenCV_STATIC ON)
find_package( OpenCV REQUIRED )

# Set library target
add_library(${LIBRARY_NAME} SHARED ${LIBRARY_DIR}/src/my_lib_file.cpp)

# Include headers
target_include_directories (${LIBRARY_NAME} PUBLIC ${OpenCV_INCLUDE_DIRS})
target_link_libraries(${LIBRARY_NAME} PUBLIC ${OpenCV_LIBS})
link_directories( ${OpenCV_LIB_DIR} )
```


### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-11-02 18:06:18,question,Scan Image Coords issues,"### System Information

We use opencv version 4.5.4. Even the issue is there on the opencv version 3.4.2 also.

""cv::Exception: OpenCV(4.5.4) /home/runner/work/opencv/opencv/opencv-4.5.4/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'
""
When we try to scan the image coordinates, and then crop the image. We are getting this issue.

Need urgent help on it. We are blocked here for many days.




### Detailed description

We use opencv version 4.5.4. Even the issue is there on the opencv version 3.4.2 also.

""cv::Exception: OpenCV(4.5.4) /home/runner/work/opencv/opencv/opencv-4.5.4/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'
""
When we try to scan the image coordinates, and then crop the image. We are getting this issue.

Need urgent help on it. We are blocked here for many days.




### Steps to reproduce

We use opencv version 4.5.4. Even the issue is there on the opencv version 3.4.2 also.

""cv::Exception: OpenCV(4.5.4) /home/runner/work/opencv/opencv/opencv-4.5.4/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'
""
When we try to scan the image coordinates, and then crop the image. We are getting this issue.

Need urgent help on it. We are blocked here for many days.




### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-10-24 11:50:59,question,How to infer unet by opencv?,"### Descripe the feature and motivation

Is there any example with "".cpp"" or "".py"" I can refer to unet inference？

so:

https://github.com/opencv/opencv/blob/master/samples/cpp/segment_objects.cpp

This can be used to unet inference? please help me.

### Additional context

_No response_"
opencv/opencv,2022-10-20 11:48:42,question,"When compiling opencv4.5.5, I find that the objdetect module is not compiled.","### System Information

When compiling opencv4.5.5, I find that the objdetect module is not compiled.
The libopencv_objdetect.so and libopencv_objdetect4.5.so files are not found in the lib directory.
In addition, the objdetect module is included in OpenCv4.5.2 compilation.
Why is that?

### Detailed description
 31%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/cuda_gpu_mat_nd.cpp.o
[ 32%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/cuda_host_mem.cpp.o
[ 32%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/cuda_info.cpp.o
[ 32%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/cuda_stream.cpp.o
[ 32%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/datastructs.cpp.o
[ 32%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/directx.cpp.o
[ 32%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/downhill_simplex.cpp.o
[ 33%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/dxt.cpp.o
[ 33%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/gl_core_3_1.cpp.o
[ 33%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/glob.cpp.o
[ 33%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/hal_internal.cpp.o
[ 33%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/kmeans.cpp.o
[ 34%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/lapack.cpp.o
[ 34%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/lda.cpp.o
[ 34%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/logger.cpp.o
[ 34%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/lpsolver.cpp.o
[ 34%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/lut.cpp.o
[ 34%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/mathfuncs.cpp.o
[ 35%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/mathfuncs_core.dispatch.cpp.o
[ 35%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matmul.dispatch.cpp.o
[ 35%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix.cpp.o
[ 35%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_c.cpp.o
[ 35%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_decomp.cpp.o
[ 36%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_expressions.cpp.o
[ 36%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_iterator.cpp.o
[ 36%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_operations.cpp.o
[ 36%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_sparse.cpp.o
[ 36%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_transform.cpp.o
[ 36%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/matrix_wrap.cpp.o
[ 37%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/mean.dispatch.cpp.o
[ 37%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/merge.dispatch.cpp.o
[ 37%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/minmax.cpp.o
[ 37%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/norm.cpp.o
[ 37%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/ocl.cpp.o
[ 38%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/opencl/runtime/opencl_clblas.cpp.o
[ 38%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/opencl/runtime/opencl_clfft.cpp.o
[ 38%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/opencl/runtime/opencl_core.cpp.o
[ 38%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/opengl.cpp.o
[ 38%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/out.cpp.o
[ 38%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/ovx.cpp.o
[ 39%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/parallel.cpp.o
[ 39%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/parallel/parallel.cpp.o
[ 39%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/parallel/parallel_openmp.cpp.o
[ 39%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/parallel/parallel_tbb.cpp.o
[ 39%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/parallel_impl.cpp.o
[ 40%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/pca.cpp.o
[ 40%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/persistence.cpp.o
[ 40%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/persistence_base64_encoding.cpp.o
[ 40%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/persistence_json.cpp.o
[ 40%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/persistence_types.cpp.o
[ 40%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/persistence_xml.cpp.o
[ 41%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/persistence_yml.cpp.o
[ 41%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/rand.cpp.o
[ 41%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/softfloat.cpp.o
[ 41%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/split.dispatch.cpp.o
[ 41%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/stat.dispatch.cpp.o
[ 42%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/stat_c.cpp.o
[ 42%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/stl.cpp.o
[ 42%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/sum.dispatch.cpp.o
[ 42%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/system.cpp.o
[ 42%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/tables.cpp.o
[ 42%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/trace.cpp.o
[ 43%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/types.cpp.o
[ 43%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/umatrix.cpp.o
[ 43%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/utils/datafile.cpp.o
[ 43%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/utils/filesystem.cpp.o
[ 43%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/utils/logtagconfigparser.cpp.o
[ 44%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/utils/logtagmanager.cpp.o
[ 44%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/utils/samples.cpp.o
[ 44%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/va_intel.cpp.o
[ 44%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/opencl_kernels_core.cpp.o
[ 44%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/arithm.sse4_1.cpp.o
[ 44%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/matmul.sse4_1.cpp.o
[ 45%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/stat.sse4_2.cpp.o
[ 45%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/mathfuncs_core.avx.cpp.o
[ 45%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/mathfuncs_core.avx2.cpp.o
[ 45%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/stat.avx2.cpp.o
[ 45%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/arithm.avx2.cpp.o
[ 45%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/convert.avx2.cpp.o
[ 46%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/convert_scale.avx2.cpp.o
[ 46%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/count_non_zero.avx2.cpp.o
[ 46%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/matmul.avx2.cpp.o
[ 46%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/mean.avx2.cpp.o
[ 46%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/merge.avx2.cpp.o
[ 47%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/split.avx2.cpp.o
[ 47%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/sum.avx2.cpp.o
[ 47%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/matmul.avx512_skx.cpp.o
[ 47%] Linking CXX shared library ../../lib/libopencv_core.so
[ 47%] Built target opencv_core
[ 47%] Processing OpenCL kernels (imgproc)
Scanning dependencies of target opencv_flann
[ 47%] Building CXX object modules/flann/CMakeFiles/opencv_flann.dir/src/miniflann.cpp.o
Scanning dependencies of target opencv_ml
[ 47%] Building CXX object modules/flann/CMakeFiles/opencv_flann.dir/src/flann.cpp.o
[ 47%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/ann_mlp.cpp.o
[ 47%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/boost.cpp.o
[ 47%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/data.cpp.o
[ 47%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/gbt.cpp.o
[ 47%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/em.cpp.o
Scanning dependencies of target opencv_imgproc
[ 48%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/accum.cpp.o
[ 49%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/inner_functions.cpp.o
[ 49%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/accum.dispatch.cpp.o
[ 49%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/kdtree.cpp.o
[ 49%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/approx.cpp.o
[ 49%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/knearest.cpp.o
[ 49%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/bilateral_filter.dispatch.cpp.o
[ 49%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/blend.cpp.o
[ 49%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/lr.cpp.o
[ 50%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/box_filter.dispatch.cpp.o
[ 50%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/nbayes.cpp.o
[ 50%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/canny.cpp.o
[ 51%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/rtrees.cpp.o
[ 51%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/svm.cpp.o
[ 51%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/clahe.cpp.o
[ 51%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/svmsgd.cpp.o
[ 51%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/color.cpp.o
[ 51%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/testset.cpp.o
[ 51%] Building CXX object modules/ml/CMakeFiles/opencv_ml.dir/src/tree.cpp.o
[ 51%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/color_hsv.dispatch.cpp.o
[ 51%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/color_lab.cpp.o
[ 52%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/color_rgb.dispatch.cpp.o
[ 52%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/color_yuv.dispatch.cpp.o
[ 52%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/colormap.cpp.o
[ 52%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/connectedcomponents.cpp.o
[ 52%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/contours.cpp.o
[ 53%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/convhull.cpp.o
[ 53%] Linking CXX shared library ../../lib/libopencv_ml.so
[ 53%] Built target opencv_ml
[ 53%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/corner.cpp.o
[ 53%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/cornersubpix.cpp.o
[ 53%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/demosaicing.cpp.o
[ 53%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/deriv.cpp.o
[ 53%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/distransform.cpp.o
[ 54%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/drawing.cpp.o
[ 54%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/emd.cpp.o
[ 54%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/featureselect.cpp.o
[ 54%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/filter.dispatch.cpp.o
[ 54%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/floodfill.cpp.o
[ 55%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/gabor.cpp.o
[ 55%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/generalized_hough.cpp.o
[ 55%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/geometry.cpp.o
[ 55%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/grabcut.cpp.o
[ 55%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/hershey_fonts.cpp.o
[ 55%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/histogram.cpp.o
[ 55%] Linking CXX shared library ../../lib/libopencv_flann.so
[ 55%] Built target opencv_flann
[ 56%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/hough.cpp.o
[ 56%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/imgwarp.cpp.o
[ 56%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/intelligent_scissors.cpp.o
[ 56%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/intersection.cpp.o
[ 56%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/linefit.cpp.o
[ 57%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/lsd.cpp.o
[ 57%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/main.cpp.o
[ 57%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/matchcontours.cpp.o
[ 57%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/median_blur.dispatch.cpp.o
[ 57%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/min_enclosing_triangle.cpp.o
[ 57%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/moments.cpp.o
[ 58%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/morph.dispatch.cpp.o
[ 58%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/phasecorr.cpp.o
[ 58%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/pyramids.cpp.o
[ 58%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/resize.cpp.o
[ 58%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/rotcalipers.cpp.o
[ 59%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/samplers.cpp.o
[ 59%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/segmentation.cpp.o
[ 59%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/shapedescr.cpp.o
[ 59%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/smooth.dispatch.cpp.o
[ 59%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/spatialgradient.cpp.o
[ 59%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/subdivision2d.cpp.o
[ 60%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/sumpixels.dispatch.cpp.o
[ 60%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/tables.cpp.o
[ 60%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/templmatch.cpp.o
[ 60%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/thresh.cpp.o
[ 60%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/utils.cpp.o
[ 60%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/opencl_kernels_imgproc.cpp.o
[ 61%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/imgwarp.sse4_1.cpp.o
[ 61%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/resize.sse4_1.cpp.o
[ 61%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/accum.sse4_1.cpp.o
[ 61%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/box_filter.sse4_1.cpp.o
[ 61%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/filter.sse4_1.cpp.o
[ 62%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/color_hsv.sse4_1.cpp.o
[ 62%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/color_rgb.sse4_1.cpp.o
[ 62%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/color_yuv.sse4_1.cpp.o
[ 62%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/median_blur.sse4_1.cpp.o
[ 62%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/morph.sse4_1.cpp.o
[ 62%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/smooth.sse4_1.cpp.o
[ 63%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/corner.avx.cpp.o
[ 63%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/accum.avx.cpp.o
[ 63%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/imgwarp.avx2.cpp.o
[ 63%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/src/resize.avx2.cpp.o
[ 63%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/accum.avx2.cpp.o
[ 64%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/bilateral_filter.avx2.cpp.o
[ 64%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/box_filter.avx2.cpp.o
[ 64%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/filter.avx2.cpp.o
[ 64%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/color_hsv.avx2.cpp.o
[ 64%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/color_rgb.avx2.cpp.o
[ 64%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/color_yuv.avx2.cpp.o
[ 65%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/median_blur.avx2.cpp.o
[ 65%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/morph.avx2.cpp.o
[ 65%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/smooth.avx2.cpp.o
[ 65%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/sumpixels.avx2.cpp.o
[ 65%] Building CXX object modules/imgproc/CMakeFiles/opencv_imgproc.dir/sumpixels.avx512_skx.cpp.o
[ 66%] Linking CXX shared library ../../lib/libopencv_imgproc.so
[ 66%] Built target opencv_imgproc
[ 67%] Processing OpenCL kernels (photo)
[ 67%] Processing OpenCL kernels (features2d)
Scanning dependencies of target opencv_photo
[ 67%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/contrast_preserve.cpp.o
[ 67%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/calibrate.cpp.o
[ 67%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/denoise_tvl1.cpp.o
[ 67%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/align.cpp.o
[ 68%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/denoising.cpp.o
[ 68%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/denoising.cuda.cpp.o
Scanning dependencies of target opencv_imgcodecs
[ 69%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/loadsave.cpp.o
Scanning dependencies of target opencv_features2d
[ 69%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/affine_feature.cpp.o
[ 70%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/agast.cpp.o
[ 70%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/agast_score.cpp.o
[ 70%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/utils.cpp.o
[ 70%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/hdr_common.cpp.o
[ 70%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/inpaint.cpp.o
[ 70%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/akaze.cpp.o
[ 70%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_base.cpp.o
[ 70%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/merge.cpp.o
[ 70%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_bmp.cpp.o
[ 70%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_exr.cpp.o
[ 70%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_gdal.cpp.o
[ 70%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/bagofwords.cpp.o
[ 71%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_gdcm.cpp.o
[ 71%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/blobdetector.cpp.o
[ 72%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/brisk.cpp.o
[ 72%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/draw.cpp.o
[ 72%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_hdr.cpp.o
[ 72%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/npr.cpp.o
[ 73%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/seamless_cloning.cpp.o
[ 73%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/seamless_cloning_impl.cpp.o
[ 73%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/src/tonemap.cpp.o
[ 73%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_jpeg.cpp.o
[ 73%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_jpeg2000.cpp.o
[ 73%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_jpeg2000_openjpeg.cpp.o
[ 73%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_pam.cpp.o
[ 73%] Building CXX object modules/photo/CMakeFiles/opencv_photo.dir/opencl_kernels_photo.cpp.o
[ 73%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/dynamic.cpp.o
[ 73%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/evaluation.cpp.o
[ 73%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/fast.cpp.o
[ 74%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_pfm.cpp.o
[ 74%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_png.cpp.o
[ 74%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_pxm.cpp.o
[ 74%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_sunras.cpp.o
[ 74%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_tiff.cpp.o
[ 74%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/fast_score.cpp.o
[ 75%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/grfmt_webp.cpp.o
[ 76%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/feature2d.cpp.o
[ 76%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/gftt.cpp.o
[ 76%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/kaze.cpp.o
[ 76%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/bitstrm.cpp.o
[ 76%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/kaze/AKAZEFeatures.cpp.o
[ 76%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/rgbe.cpp.o
[ 76%] Building CXX object modules/imgcodecs/CMakeFiles/opencv_imgcodecs.dir/src/exif.cpp.o
[ 76%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/kaze/KAZEFeatures.cpp.o
[ 77%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/kaze/fed.cpp.o
[ 77%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/kaze/nldiffusion_functions.cpp.o
[ 77%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/keypoint.cpp.o
[ 77%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/main.cpp.o
[ 77%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/matchers.cpp.o
[ 77%] Linking CXX shared library ../../lib/libopencv_imgcodecs.so
[ 77%] Built target opencv_imgcodecs
[ 77%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/mser.cpp.o
Scanning dependencies of target opencv_videoio
[ 77%] Linking CXX shared library ../../lib/libopencv_photo.so
[ 77%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/videoio_registry.cpp.o
[ 78%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/orb.cpp.o
[ 78%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/videoio_c.cpp.o
[ 78%] Built target opencv_photo
[ 78%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/cap.cpp.o
[ 79%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/cap_images.cpp.o
[ 79%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/sift.dispatch.cpp.o
[ 79%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/opencl_kernels_features2d.cpp.o
[ 79%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/sift.sse4_1.cpp.o
[ 79%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/cap_mjpeg_encoder.cpp.o
[ 79%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/cap_mjpeg_decoder.cpp.o
[ 79%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/backend_plugin.cpp.o
[ 79%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/fast.avx2.cpp.o
[ 79%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/backend_static.cpp.o
[ 80%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/container_avi.cpp.o
[ 80%] Building CXX object modules/videoio/CMakeFiles/opencv_videoio.dir/src/cap_v4l.cpp.o
[ 81%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/sift.avx2.cpp.o
[ 81%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/sift.avx512_skx.cpp.o
[ 81%] Linking CXX shared library ../../lib/libopencv_videoio.so
[ 81%] Built target opencv_videoio
Scanning dependencies of target opencv_highgui
[ 82%] Building CXX object modules/highgui/CMakeFiles/opencv_highgui.dir/src/backend.cpp.o
[ 82%] Building CXX object modules/highgui/CMakeFiles/opencv_highgui.dir/src/roiSelector.cpp.o
[ 82%] Building CXX object modules/highgui/CMakeFiles/opencv_highgui.dir/src/window.cpp.o
[ 82%] Building CXX object modules/highgui/CMakeFiles/opencv_highgui.dir/src/window_gtk.cpp.o
[ 82%] Linking CXX shared library ../../lib/libopencv_features2d.so
[ 82%] Built target opencv_features2d
[ 82%] Processing OpenCL kernels (calib3d)
Scanning dependencies of target opencv_calib3d
[ 83%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/calibinit.cpp.o
[ 83%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/ap3p.cpp.o
[ 83%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/calibration.cpp.o
[ 83%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/calibration_handeye.cpp.o
[ 83%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/checkchessboard.cpp.o
[ 83%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/chessboard.cpp.o
[ 83%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/circlesgrid.cpp.o
[ 84%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/compat_ptsetreg.cpp.o
[ 84%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/dls.cpp.o
[ 84%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/epnp.cpp.o
[ 84%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/fisheye.cpp.o
[ 84%] Linking CXX shared library ../../lib/libopencv_highgui.so
[ 84%] Built target opencv_highgui
[ 84%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/five-point.cpp.o
[ 84%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/fundam.cpp.o
[ 85%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/homography_decomp.cpp.o
[ 85%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/ippe.cpp.o
[ 85%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/levmarq.cpp.o
[ 85%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/main.cpp.o
[ 85%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/p3p.cpp.o
[ 86%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/polynom_solver.cpp.o
[ 86%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/posit.cpp.o
[ 86%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/ptsetreg.cpp.o
[ 86%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/quadsubpix.cpp.o
[ 86%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/rho.cpp.o
[ 86%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/solvepnp.cpp.o
[ 87%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/sqpnp.cpp.o
[ 87%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/stereobm.cpp.o
[ 87%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/stereosgbm.cpp.o
[ 87%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/triangulate.cpp.o
[ 87%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/undistort.dispatch.cpp.o
[ 88%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/upnp.cpp.o
[ 88%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/degeneracy.cpp.o
[ 88%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/dls_solver.cpp.o
[ 88%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/essential_solver.cpp.o
[ 88%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/estimator.cpp.o
[ 88%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/fundamental_solver.cpp.o
[ 89%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/gamma_values.cpp.o
[ 89%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/homography_solver.cpp.o
[ 89%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/local_optimization.cpp.o
[ 89%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/pnp_solver.cpp.o
[ 89%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/quality.cpp.o
[ 90%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/ransac_solvers.cpp.o
[ 90%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/sampler.cpp.o
[ 90%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/termination.cpp.o
[ 90%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/src/usac/utils.cpp.o
[ 90%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/opencl_kernels_calib3d.cpp.o
[ 90%] Building CXX object modules/calib3d/CMakeFiles/opencv_calib3d.dir/undistort.avx2.cpp.o
[ 91%] Linking CXX shared library ../../lib/libopencv_calib3d.so
[ 91%] Built target opencv_calib3d
[ 92%] Processing OpenCL kernels (stitching)
[ 92%] Processing OpenCL kernels (video)
Scanning dependencies of target opencv_stitching
[ 92%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/camera.cpp.o
[ 92%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/blenders.cpp.o
[ 92%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/exposure_compensate.cpp.o
[ 92%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/matchers.cpp.o
[ 93%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/motion_estimators.cpp.o
[ 93%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/seam_finders.cpp.o
[ 93%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/autocalib.cpp.o
Scanning dependencies of target opencv_video
[ 93%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/bgfg_KNN.cpp.o
[ 94%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/bgfg_gaussmix2.cpp.o
[ 94%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/camshift.cpp.o
[ 94%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/stitcher.cpp.o
[ 94%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/dis_flow.cpp.o
[ 94%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/timelapsers.cpp.o
[ 94%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/ecc.cpp.o
[ 94%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/util.cpp.o
[ 94%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/warpers.cpp.o
[ 95%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/src/warpers_cuda.cpp.o
[ 95%] Building CXX object modules/stitching/CMakeFiles/opencv_stitching.dir/opencl_kernels_stitching.cpp.o
[ 95%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/kalman.cpp.o
[ 95%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/lkpyramid.cpp.o
[ 96%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/optflowgf.cpp.o
[ 96%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/optical_flow_io.cpp.o
[ 96%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_feature.cpp.o
[ 96%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_feature_set.cpp.o
[ 96%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_mil_model.cpp.o
[ 97%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_mil_state.cpp.o
[ 97%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_model.cpp.o
[ 97%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_sampler.cpp.o
[ 97%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_sampler_algorithm.cpp.o
[ 97%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracker_state_estimator.cpp.o
[ 97%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracking_feature.cpp.o
[ 98%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/detail/tracking_online_mil.cpp.o
[ 98%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/tracker.cpp.o
[ 98%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/tracker_dasiamrpn.cpp.o
[ 98%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/tracker_goturn.cpp.o
[ 98%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/tracking/tracker_mil.cpp.o
[100%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/src/variational_refinement.cpp.o
[100%] Linking CXX shared library ../../lib/libopencv_stitching.so
[100%] Built target opencv_stitching
[100%] Building CXX object modules/video/CMakeFiles/opencv_video.dir/opencl_kernels_video.cpp.o
[100%] Linking CXX shared library ../../lib/libopencv_video.so
[100%] Built target opencv_video


### Steps to reproduce

CMAKE_OPTION -DCMAKE_BUILD_TYPE=Release -DWITH_PROTOBUF=OFF -DWITH_WEBP=OFF -DWITH_IPP=OFF
            -DWITH_ADE=OFF
            -DBUILD_ZLIB=ON
            -DBUILD_JPEG=ON
            -DBUILD_PNG=ON
            -DWITH_OPENEXR=OFF
            -DBUILD_TESTS=OFF
            -DBUILD_PERF_TESTS=OFF
            -DBUILD_opencv_apps=OFF
            -DCMAKE_SKIP_RPATH=TRUE
            -DBUILD_opencv_python3=OFF
            -DBUILD_opencv_videoio=OFF
            -DWITH_FFMPEG=OFF
            -DWITH_TIFF=ON
            -DBUILD_TIFF=ON
            -DWITH_JASPER=OFF
            -DBUILD_JASPER=OFF
            -DCV_TRACE=OFF

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-10-19 14:05:30,question,Getting Bad argument (Can't read ONNX file: .\\yolov5s.onnx) When Trying to Load YOLOv5 ONNX Model.,"### System Information

OpenCV version 4.6.0
Operating System / Platform: Windows 11 Pro (22000.1098)
Compiler & Compiler Version: Microsoft Visual C++ Compiler (MSVC Toolset) v142 (Visual Studio 2019)

### Detailed description

I'm trying to deploy my YOLOv5 model with OpenCV 4.6.0 using C++. However, no matter what I try to do Open CV's ONNX importer throws the following runtime error:

```text
OpenCV(4.6.0) Error: Bad argument (Can't read ONNX file: .\\yolov5s.onnx) in cv::dnn::dnn4_v20220524::ONNXImporter::ONNXImporter, file C:\\opencv-4.6.0\\opencv-4.6.0\\modules\\dnn\\src\\onnx\\onnx_importer.cpp, line 255
```

This is the command I'm using to export the model in PowerShell:

```text
python .\\yolov5\\export.py --data ""C:\\vehicle_engine_yolov5s_r11\\data.yaml"" --weights ""C:\\vehicle_engine_yolov5s_r11\\weights\\best.pt"" --simplify --include onnx
```

I tried it with my own exported weights using export.py and with the default weights and the result is still the same.

- I have also switched between the `master`, `v7.0` and `v7.0.1` branches and retrying the export.
- I also tried exporting the model in ProtoBuf (.pb) format.
- I even tried building Open CV 4.6.0 from source.

**All to no avail.** 

I've honestly fired all my bullets and couldn't find anything online related to the problem and error, I cannot even know where the process is failing and if there's an error from my end. Here's my `main(void)` function where I load the model. I believe there's a problem with the OpenCV code that loads the onnx model.

Below is the code that produces the said problem:

### Steps to reproduce

```c++
#include <opencv2/opencv.hpp>
#include <fstream>

const float INPUT_WIDTH          { 640.0F };
const float INPUT_HEIGHT         { 640.0F };
const float SCORE_THRESHOLD      {  0.5F };
const float NMS_THRESHOLD        { 0.45F };
const float CONFIDENCE_THRESHOLD { 0.45F };

const float FONT_SCALE { 0.7F };
const   int FONT_FACE  { cv::FONT_HERSHEY_SIMPLEX };
const   int THICKNESS  { 1 };

cv::Scalar BLACK  { cv::Scalar(0, 0, 0) };
cv::Scalar BLUE   { cv::Scalar(255, 178, 50) };
cv::Scalar YELLOW { cv::Scalar(0, 255, 255) };
cv::Scalar RED    { cv::Scalar(0, 0, 255) };

void drawLabel(
	cv::Mat& inputImage, 
	std::string label, 
	int left, 
	int top
)
{
	int baseLine       { 0 };
	cv::Size labelSize { cv::getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS, &baseLine) };
	
	top = cv::max(top, labelSize.height);

	cv::Point topLeftCorner     { cv::Point(left, top) };
	cv::Point bottomRightCorner { cv::Point((left + labelSize.width), (top + labelSize.height + baseLine)) };

	cv::rectangle(inputImage, topLeftCorner, bottomRightCorner, BLACK, cv::FILLED);
	cv::putText(
		inputImage, 
		label, 
		cv::Point(left, (top + labelSize.height)), 
		FONT_FACE, 
		FONT_SCALE, 
		YELLOW, 
		THICKNESS
	);
}

std::vector<cv::Mat> processInput(cv::Mat& inputImage, cv::dnn::Net& net)
{
	cv::Mat blob {};

	cv::dnn::blobFromImage(
		inputImage,
		blob,
		1. / 255.,
		cv::Size(INPUT_WIDTH, INPUT_HEIGHT),
		cv::Scalar(),
		true,
		false
	);

	net.setInput(blob);

	std::vector<cv::Mat> outputs{};
	net.forward(outputs, net.getUnconnectedOutLayersNames());

	return outputs;
}

cv::Mat postProcess(
	cv::Mat& inputImage, 
	std::vector<cv::Mat>& outputs, 
	const std::vector<std::string>& className
)
{
	std::vector<int>      classIds    { };
	std::vector<float>    confidences { };
	std::vector<cv::Rect> boxes       { };

	float  xFactor { inputImage.cols / INPUT_WIDTH  };
	float  yFactor { inputImage.rows / INPUT_HEIGHT };
	float* data    { (float*)outputs[0].data };

	const size_t dims { 85 };
	const size_t rows { 25200 };

	for (size_t i{ 0 }; i < rows; i++)
	{
		float confidence { data[4] };

		if (confidence >= CONFIDENCE_THRESHOLD)
		{
			float*    classesScores { data + 5 };
			cv::Mat   scores        {1, (int)className.size(), CV_32FC1, classesScores };
			cv::Point classId       { };
			double    maxClassScore { 0.0 };

			cv::minMaxLoc(scores, 0, &maxClassScore, 0, &classId);

			if (maxClassScore > SCORE_THRESHOLD)
			{
				confidences.push_back(confidence);
				classIds.push_back(classId.x);

				float centerX   { data[0] };
				float centerY   { data[1] };
				float boxWidth  { data[2] };
				float boxHeight { data[3] };

				int left   { (int)((centerX - 0.5 * boxWidth ) * xFactor) };
				int top    { (int)((centerY - 0.5 * boxHeight) * yFactor) };
				int width  { (int)(boxWidth  * xFactor) };
				int height { (int)(boxHeight * yFactor) };

				boxes.push_back(cv::Rect(left, top, width, height));
			}
		}

		data += 85;
	}

	std::vector<int> indices { };

	cv::dnn::NMSBoxes(boxes, confidences, SCORE_THRESHOLD, NMS_THRESHOLD, indices);

	for (size_t i{ 0 }; i < indices.size(); i++)
	{
		int idx      { indices[i] };
		cv::Rect box { boxes[idx] };
		int left     { box.x };
		int top      { box.y };
		int width    { box.width  };
		int height   { box.height };

		cv::rectangle(
			inputImage, 
			cv::Point(left, top), 
			cv::Point((left + width), (top + height)), 
			BLUE, 
			3*THICKNESS
		);

		std::string label { cv::format(""%.2f"", confidences[idx]) };
		label = className[classIds[idx]] + "":"" + label;

		drawLabel(inputImage, label, left, top);
	}

	return inputImage;
}

cv::Mat postProcess(
	cv::Mat&& inputImage,
	std::vector<cv::Mat>& outputs,
	const std::vector<std::string>& className
)
{
	std::vector<int>      classIds    { };
	std::vector<float>    confidences { };
	std::vector<cv::Rect> boxes       { };

	float  xFactor { inputImage.cols / INPUT_WIDTH };
	float  yFactor { inputImage.rows / INPUT_HEIGHT };
	float* data    { (float*)outputs[0].data };

	const size_t dims { 85 };
	const size_t rows { 25200 };

	for (size_t i{ 0 }; i < rows; i++)
	{
		float confidence{ data[4] };

		if (confidence >= CONFIDENCE_THRESHOLD)
		{
			float* classesScores{ data + 5 };
			cv::Mat   scores        { 1, (int)className.size(), CV_32FC1, classesScores };
			cv::Point classId       { };
			double    maxClassScore { 0.0 };

			cv::minMaxLoc(scores, 0, &maxClassScore, 0, &classId);

			if (maxClassScore > SCORE_THRESHOLD)
			{
				confidences.push_back(confidence);
				classIds.push_back(classId.x);

				float centerX   { data[0] };
				float centerY   { data[1] };
				float boxWidth  { data[2] };
				float boxHeight { data[3] };

				int left{ (int)((centerX - 0.5 * boxWidth) * xFactor) };
				int top{ (int)((centerY - 0.5 * boxHeight) * yFactor) };
				int width{ (int)(boxWidth * xFactor) };
				int height{ (int)(boxHeight * yFactor) };

				boxes.push_back(cv::Rect(left, top, width, height));
			}
		}

		data += 85;
	}

	std::vector<int> indices{ };

	cv::dnn::NMSBoxes(boxes, confidences, SCORE_THRESHOLD, NMS_THRESHOLD, indices);

	for (size_t i{ 0 }; i < indices.size(); i++)
	{
		int idx      { indices[i] };
		cv::Rect box { boxes[idx] };
		int left     { box.x };
		int top      { box.y };
		int width    { box.width };
		int height   { box.height };

		cv::rectangle(
			inputImage,
			cv::Point(left, top),
			cv::Point((left + width), (top + height)),
			BLUE,
			3 * THICKNESS
		);

		std::string label { cv::format(""%.2f"", confidences[idx]) };
		label = className[classIds[idx]] + "":"" + label;

		drawLabel(inputImage, label, left, top);
	}

	return inputImage;
}

int main(void)
{
	try
	{
		std::vector<std::string> classList
		{
			""Bus"",
			""Car"",
			""Truck""
		};

		cv::Mat frame{ cv::imread(""C:\\\\YOLO\\\\datasets\\\\vehicle_dataset\\\\test\\\\images\\\\1.jpg"") };
		cv::dnn::Net net{ cv::dnn::readNet("".\\\\yolov5s.onnx"") }; // The line that throws the runtime error.

		std::vector<double>  layersTimes{ };
		std::vector<cv::Mat> detections{ processInput(frame, net) };

		cv::Mat img{ postProcess(frame.clone(), detections, classList) };

		double freq{ cv::getTickFrequency() / 1000 };
		double timeTaken{ net.getPerfProfile(layersTimes) / freq };

		std::string label{ cv::format(""Inference Time:\\t%.4f ms"", timeTaken) };

		cv::putText(img, label, cv::Point(20, 40), FONT_FACE, FONT_SCALE, RED);
		cv::imshow(""Output"", img);
		cv::waitKey(0);

		return 0;
	}
	catch (cv::Exception& e)
	{
		std::cout << std::endl << e.what() << std::endl;
		return -1;
	}
}
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-10-16 10:20:07,question,'haarcascade_fontalface_default.xml' in read mode,"### Descripe the doc issue

I'm very new to OpenCV and was just running my first program ever in the terminal when I get the phrase:

[ERROR:0@0.012] global /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/persistence.cpp (505) open Can't open file: 'haarcascade_fontalface_default.xml' in read mode

Does anyone know what this means?

Here is my code for reference:

```
import cv2

trained_face_data = cv2.CascadeClassifier('haarcascade_fontalface_default.xml')

img = cv2.imread('RD.png')

cv2.imshow('Clever Programmer Face Detector', img)

cv2.waitKey()

print('Code Completed')
```

### Fix suggestion

_No response_"
opencv/opencv,2022-09-27 03:51:57,question,cv::VideoCapture will affect GPU performance?,"My model takes 6ms when testing a single frame of image, but it takes 8ms when using cv::VideoCapture to get video frame , and after dozens of inferences the time-consuming increases to 12ms.
Win10
Opencv version 4.6



	"
opencv/opencv,2022-09-22 10:48:27,question,OpenCV iOS use in 2022,"Hello, I am just getting into OpenCV and want to understand the following:

1. As I understand OpenCV [doesn't support Metal](https://github.com/opencv/opencv/issues/4898), so as a result there is no way for OpenCV to use GPU on iOS devices. Is that correct ?
2. Is my understanding correct that it only makes sense to use OpenCV on iOS devices where OpenCV performance on CPU is good for app use cases?"
opencv/opencv,2022-09-13 08:21:43,question,Why is the image merge area white,"![SavedScreen1212](https://user-images.githubusercontent.com/60952586/189849095-5e983513-4cc3-4698-b09a-e04c81033ab8.png)
I don't know why two pictures merged, the overlapping area is white
I hope the teacher can give me a solution

this my scripts：
```
 private void WarpTriangle(Mat img1, Mat img2, List<Point2f> tri1, List<Point2f> tri2, Point2f[] _points2f) 
        {
            (List<List<Point2f>> inputPoints, List<List<Point2f>> keyPoints) = this.Init(_points2f);
            for (int i = 0; i < inputPoints.Count; i++) //遍历每个点
            {
                tri1 = keyPoints[i];    //一个点就是一个三角形像素
                tri2 = inputPoints[i];

                OpenCvSharp.Rect r1 = Cv2.BoundingRect(tri1);
                OpenCvSharp.Rect r2 = Cv2.BoundingRect(tri2);

                List<Point2f> tri1Cropped = new List<Point2f>(), tri2Cropped = new List<Point2f>();
                List<Point> tri2CroppedInt = new List<Point>();

                for (int ii = 0; ii < 3; ii++)
                {
                    tri1Cropped.Add(new Point2f(tri1[ii].X - r1.X, tri1[ii].Y - r1.Y));
                    tri2Cropped.Add(new Point2f(tri2[ii].X - r2.X, tri2[ii].Y - r2.Y));

                    // fillConvexPoly needs a vector of Point and not Point2f
                    tri2CroppedInt.Add(new Point(Mathf.Floor(tri2[ii].X - r2.X), Mathf.Floor(tri2[ii].Y - r2.Y)));
                }

                Mat img1Cropped = new Mat();
                img1Cropped = img1.GetRectSubPix(r1.Size, r1.Center);

                Mat warpMat = Cv2.GetAffineTransform(tri1Cropped, tri2Cropped);
                Mat img2Cropped = Mat.Zeros(size, size, img1Cropped.Type());

                Cv2.WarpAffine(img1Cropped, img2Cropped, warpMat, img2Cropped.Size(), InterpolationFlags.Linear, BorderTypes.Reflect101);

                Mat mask = Mat.Zeros(size, size, MatType.CV_32FC3);
                Cv2.FillConvexPoly(mask, tri2CroppedInt, new Scalar(1.0, 1.0, 1.0), LineTypes.AntiAlias, 0);
                Cv2.Multiply(img2Cropped, mask, img2Cropped);
                //Mat matOut = Mat.Zeros(new Size(size, size), img1.Type());
                //Cv2.Add(matOut, img2Cropped, matOut);


                float tx = tri2.Min(x => x.X);
                float ty = tri2.Min(y => y.Y);
                float[] warp_values = { 1.0f, 0.0f, tx, 0.0f, 1.0f, ty };   //图片偏移
                Mat translation_matrix = new Mat(2, 3, MatType.CV_32F, warp_values);
                Cv2.WarpAffine(img2Cropped, img2Cropped, translation_matrix, new Size(size, size));
                Cv2.Multiply(img2Cropped, new Scalar(1.0, 1.0, 1.0) - mask, img2Cropped);
                
                Cv2.Add(img2, img2Cropped, img2);
               

                //float tx = tri2.Min(x => x.X);
                //float ty = tri2.Min(y => y.Y);
                //create the translation matrix using tx and ty
                //float[] warp_values = { 1.0f, 0.0f, tx, 0.0f, 1.0f, ty };   //图片偏移
                //Mat translation_matrix = new Mat(2, 3, MatType.CV_32F, warp_values);
                //Cv2.WarpAffine(matOut, matOut, translation_matrix, new Size(size, size));
                //Cv2.Add(img2, matOut, img2);
            }
            Cv2.Flip(img2, img2, FlipMode.X);   //图片翻转
            Cv2.ImShow(""outPut"", img2);
            //img2.ConvertTo(img2, MatType.CV_8UC3, 255.0);
            //Texture2D _tex = Unity.MatToTexture(img2);
            //byte[] bytes = _tex.EncodeToPNG();
            //System.IO.File.WriteAllBytes(Application.streamingAssetsPath + ""/Texture/SavedScreen.png"", bytes);

            Debug.Log(""输出图像"");
        }
```"
opencv/opencv,2022-09-09 05:25:27,question,Bug (Javascript) mean/meanStdDev broken for 8UC3 images,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => 4.6.0
- Operating System / Platform => MacOS 13.0

##### Detailed description

Javascript functions `mean` and `meanStdDev` (and probably others) cause an uncaught exception when applied with masks on 3-channel images.

<img width=""895"" alt=""image"" src=""https://user-images.githubusercontent.com/62717406/189277229-bf57279d-8f9f-43c3-8f58-15455ad89070.png"">



##### Steps to reproduce

```
let src = ...
let dst1 = cv.Mat.zeros(src.cols, src.rows, cv.CV_8UC1);
let mask1 = cv.Mat.zeros(src.cols, src.rows, dst1.type());

let dst3 = cv.Mat.zeros(src.cols, src.rows, cv.CV_8UC3);
let mask3 = cv.Mat.zeros(src.cols, src.rows, dst3.type());

const mean_val = cv.mean(dst1, mask1);  // <--- works
const mean_val = cv.mean(dst3, mask3);  // <--- causes uncaught exception error
```
"
opencv/opencv,2022-09-08 06:57:28,question,"In file included from /home/xxx/opencv/modules/python/src2/cv2.cpp:11:0: /home/xxx/opencv/build/modules/python_bindings_generator/pyopencv_generated_include.h:19:10: fatal error: opencv2/hdf/hdf5.hpp: no file or directory  #include ""opencv2/hdf/hdf5.hpp""           ^~~~~~~~~~~~~~~~~~~~~~","I'm building opencv-cuda,it happens at the end."
opencv/opencv,2022-08-27 23:32:40,question,How to build for FreeBSD 13.1 ? ,"System information (version):

- OpenCV => 4.6.0
- Operating System / Platform => FreeBSD 13.1
- Compiler => clang/llvm and gcc 11
-KDE5 plasma

Has anyone able to compile OpenCV 4.6.0 successfully for FreeBSD 13.1?

If so what was used to compile opencv and also what commands was used?

Thanks."
opencv/opencv,2022-08-25 07:48:44,question,how opencv load .dylibs under macos,"im working on python==3.9.12, macox==12.5
i import cv2 as cv, and i find the some dylib under cv2/.dylibs are loaded, but i can't find out where the code loads them.
i need help!!!!
"
opencv/opencv,2022-08-20 19:53:12,question,Failed to install opencv 4.6.0 on ubuntu,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.6.0
- Operating System / Platform => Linux 64 Bit
- Compiler => gnu compilers
-->

- OpenCV => :grey_question:
- Operating System / Platform => :grey_question:
- Compiler => :grey_question:

##### Detailed description

Hi
I am a newbie on installing opencv from scratch. I am trying to install opencv-4.6.0 on ubuntu followed the instruction. The first step is successful without any error:
cmake -D CMAKE_INSTALL_PREFIX=my_opencv_4.6.0 /scratch/softwares/packages/opencv-4.6.0
However, in the second step “cmake --build .”
I met the following errors:

/home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw/iw_image.h:72:8: note: in expansion of macro ‘IW_INLINE’
72 | static IW_INLINE IwiBorderSize iwiSizeToBorderSize(
| ^~~~~~~~~
In file included from /home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw_own.h:22,
from /home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/src/iw_core.c:15:
/home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw/iw_image.h:72:32: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘attribute’ before ‘iwiSizeToBorderSize’
72 | static IW_INLINE IwiBorderSize iwiSizeToBorderSize(
| ^~~~~~~~~~~~~~~~~~~
In file included from /home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw_own.h:21,
from /home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/src/iw_core.c:15:
/home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw/iw_core.h:79:19: error: unknown type name ‘inline’
79 | #define IW_INLINE inline
| ^~~~~~
/home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw/iw_image.h:85:8: note: in expansion of macro ‘IW_INLINE’
85 | static IW_INLINE IwiBorderSize iwiSizeSymToBorderSize(
| ^~~~~~~~~
In file included from /home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw_own.h:22,
from /home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/src/iw_core.c:15:
/home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw/iw_image.h:85:32: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘attribute’ before ‘iwiSizeSymToBorderSize’
85 | static IW_INLINE IwiBorderSize iwiSizeSymToBorderSize(
| ^~~~~~~~~~~~~~~~~~~~~~
/home/btan/prodisk/softwares/tmp/3rdparty/ippicv/ippicv_lnx/iw/include/iw/iw_image.h:98:18: error: expected ‘;’ before ‘void’
98 | static IW_INLINE void* iwiShiftPtr(
| ^~~~

Does anyone can help how to correct it?

Thanks

##### Steps to reproduce

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->

##### Issue submission checklist

 - [x] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [ ] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-08-16 18:23:00,question,fatal error,"cloning_demo.cpp:23:10: fatal error: opencv2/photo.hpp: No such file or directory
   23 | #include ""opencv2/photo.hpp""
      |          ^~~~~~~~~~~~~~~~~~~
compilation terminated.
"
opencv/opencv,2022-08-11 03:48:53,question,How to quickly convert RGB to YUV422,"Hello ，I am using `cvtColor`  will RGB to YUV422.

But This funciton param  `mode` don't have BGR2YUV(422).

I use the in-down method to transform

```
void cvtcolor_rgb2yuv422(cv::Mat& rgb, cv::Mat& yuv) {
	cv::Mat yuv444(rgb.rows, rgb.cols, CV_8UC3);
	cv::cvtColor(rgb, yuv444, CV_BGR2YUV);
    // chroma subsampling: yuv444 -> yuv422;
    for (int row = 0; row < yuv444.rows; row++) {
        for (int col = 0; col < yuv444.cols; col+=2) {
        	cv::Vec3b p0_in = yuv444.at<cv::Vec3b>(row, col);
        	cv::Vec3b p1_in = yuv444.at<cv::Vec3b>(row, col+1);
        	cv::Vec2b p0_out, p1_out;
            p0_out.val[0] = p0_in.val[0];
            p0_out.val[1] = p0_in.val[1];
            p1_out.val[0] = p1_in.val[0];
            p1_out.val[1] = p0_in.val[2];
            yuv.at<cv::Vec2b>(row, col) = p0_out;
            yuv.at<cv::Vec2b>(row, col+1) = p1_out;
        }
    }
}
```
But this approach takes a long time.
How to use the parallel computing method for transformation? Or how to make OpencV support YUV422 conversion?

Please provide me with reference"
opencv/opencv,2022-08-02 22:08:38,question,can OpenCV 3.4.16 using cuda 11.6?,can OpenCV 3.4.16 using cuda 11.6?
opencv/opencv,2022-07-27 08:57:28,question,How to automatically obtain the input image size from the ONNX model？,"Is there a function in `OpenCV DNN` that automatically gets the input image size from the only `ONNX` model？

thanks"
opencv/opencv,2022-07-23 05:34:06,question,error: 'off64_t' undeclared here (not in a function); did you mean 'off_t'?,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => :4.6.0
- Operating System / Platform => :Ubuntu 18.04
- Compiler => : gcc

##### Detailed description

I want to build OpenCV 4.6.0  via these options 

```
cmake -D CMAKE_BUILD_TYPE=RELEASE \\
-D CMAKE_INSTALL_PREFIX=/usr/local \\
-D PYTHON_DEFAULT_EXECUTABLE=$(which python3) \\
-D PYTHON_EXECUTABLE=~/.virtualenvs/cv/bin/python \\
-D PYTHON3_EXECUTABLE=$(which python3) \\
-D PYTHON2_EXECUTABLE=$(which python2) \\
-D PYTHON3_INCLUDE_DIR=$(python3 -c ""from distutils.sysconfig import get_python_inc; print(get_python_inc())"") \\
-D PYTHON3_PACKAGES_PATH=$(python3 -c ""from distutils.sysconfig import get_python_lib; print(get_python_lib())"") \\
-D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \\
-D OPENCV_PYTHON3_INSTALL_PATH=$cwd/OpenCV-$cvVersion-py3/lib/python3.5/site-packages \\
-D BUILD_PNG=ON \\
-D BUILD_TIFF=ON \\
-D BUILD_TBB=ON \\
-D BUILD_JPEG=ON \\
-D BUILD_JASPER=ON \\
-D BUILD_ZLIB=ON \\
-D BUILD_EXAMPLES=ON \\
-D BUILD_TESTS=ON \\
-D BUILD_opencv_java=ON \\
-D BUILD_opencv_python2=ON \\
-D BUILD_opencv_python3=ON \\
-D BUILD_OPENCV_ENABLE_NONFREE=ON \\
-D OPENCV_GENERATE_PKGCONFIG=ON \\
-D WITH_OPENCL=ON \\
-D WITH_IPP=ON \\
-D WITH_EIGEN=ON \\
-D BUILD_PERF_TESTS=ON \\
-D BUILD_OPENCV_PYTHON3=YES \\
-D WITH_FFMPEG=ON \\
-D WITH_V4L=ON \\
-D WITH_GSTREAMER=ON \\
-D WITH_GSTREAMER_0_10=ON \\
-D WITH_GTK=ON \\
-D ENABLE_FAST_MATH=ON \\
-D WITH_VTK=ON \\
-D WITH_TBB=ON \\
-D WITH_QT=ON \\
-D WITH_OPENGL=ON \\
-D INSTALL_PYTHON_EXAMPLES=ON \\
-D INSTALL_C_EXAMPLES=ON \\
-D INSTALL_TESTS=ON \\
-D ENABLE_NEON=ON \\
-D WITH_LIBV4L=OFF ..
```

But after building these errors occurred so configuring incomplete. 

CMakeError.log content:

```
opencv/build/CMakeFiles/CheckTypeSize/OFF64_T.c:27:22: error: ‘off64_t’ undeclared here (not in a function); did you mean ‘off_t’?
opencv/build/CMakeFiles/CheckTypeSize/int8.c:27:22: error: ‘INT8’ undeclared here (not in a function); did you mean ‘INT8_C’?
opencv/build/CMakeFiles/CheckTypeSize/int16.c:27:22: error: ‘INT16’ undeclared here (not in a function); did you mean ‘INT16_C’?
opencv/build/CMakeFiles/CheckTypeSize/int32.c:27:22: error: ‘INT32’ undeclared here (not in a function); did you mean ‘INT32_C’?

```

How could I resolve these errors?
##### Steps to reproduce

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->

##### Issue submission checklist

 - [ ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [ ] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
  <!-- - [ ] I updated to the latest OpenCV version and the issue is still there  -->
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
   <!-- - [ ] There is reproducer code and related data files: videos, images, onnx, etc   -->
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-07-14 19:25:18,question,imshow() for .png transparent images with RGBA 4 channels,"Looks like **imshow()** cannot show transparency correctly ?
I prefer **NOT** to show RGB some times, with alpha mask, how can I make the transparency displayed?
I can load, I can save, but with imshow(), I cannot display correctly...."
opencv/opencv,2022-06-30 06:45:17,question,Convcert cvMat to pcd file,"Hi, I would like to convert a cv::Mat to PCL format. Have you an idea ? 
Thanks "
opencv/opencv,2022-06-25 09:03:35,question,Getting cv2.error,"![Screenshot (289)](https://user-images.githubusercontent.com/108174989/175766340-9381f087-65d0-41ba-abe7-c3b0b8dc28bb.png)
Above picture is the code and I am getting this error message which is shown below. Could anyone help me fix this issue?
![Screenshot (290)](https://user-images.githubusercontent.com/108174989/175766410-3c2735ea-3610-4762-bd44-a0f2da75880c.png)

"
opencv/opencv,2022-06-21 18:17:39,question,VideoCapture: read() use video orientation,"If the video orientation is available if should be used by default with reading frames.

- OpenCV => 4.X
- Operating System / Platform => Linux x64
- Compiler => gcc

##### Detailed description

By default imread for images use the EXIF orientation information.
If possible VideoCapture::read() should use the orientation information (if available) by default too.

##### Steps to reproduce

Happens on portrait videos taken by smartphones.
If needed I can provide one.

##### Issue submission checklist

 - [ x ] I report the issue, it's not a question
 - [ x ] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
 - [  ] I updated to the latest OpenCV version and the issue is still there
 - [  ] There is reproducer code and related data files: videos, images, onnx, etc
"
opencv/opencv,2022-06-15 04:17:18,question,About debug,"I debug OpenCV in one step, but I couldn't find the function entry of the matrix plus method."
opencv/opencv,2022-06-09 16:48:21,question,"SyntaxError: invalid syntax   --->frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)","When I tried to use Lucas-Kanade on optical flow, I couldn't figure out why there's always  invalid syntax when I use"" frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)"" 
Here's the code, guys please help me.





import numpy as np
import cv2

cap = cv2.VideoCapture('02_Video/02_Foreground.avi')
feature_params = dict( maxCorners = 100,
                       qualityLevel = 0.3,
                       minDistance = 7 )

lk_params = dict( winSize = (15,15), maxLevel = 2 )

color = np.random.randint(0,255,(100,3))


ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)                         
p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)
mask = np.zeros_like(old_frame)

while(True):
    ret,frame = cap.read()
    frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)                       
    
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)                         
    
    good_new = p1[st==1]  
    good_old = p0[st==1]
    
    for i, (new,old) in enumerate(zip(good_new,good_old)):
        a,b = new.ravel()
        c,d = old.ravel()
        mask = cv2.line(mask,(int(a),int(b),(int(c),int(d)),color[i].tolist(),2)                         
        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)               #<---------------The problem is here!!!!!!!!!!!!!
        #image = cv2.circle(image, center_coordinates, radius, color, thickness)
    img = cv2.add(frame,mask)
    
    cv2.imshow('frame',img)
    k = cv2.waitKey(150) & 0xff
    if k == 27:
        break
        
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1,1,2)
    
cv2.destroyAllWindows()
cap.release()"
opencv/opencv,2022-06-09 08:38:30,question,How to properly use opencl acceleration applied to 360 surround view,"360 surround view, multi-threaded processing of pictures from different cameras, opencv (4.5.5) for image correction and perspective transformation (remap), the CPU usage is very high, so use opencl (1.0) to accelerate, but with the increase of the number of threads, The processing time of a single thread increases several times, and the GPU occupancy rate is also high. How to optimize?
1. Use opencl 2.0?
2. Picture copy, umat has no data pointer, cannot use hardware RGA acceleration, can only use copyto, which is time-consuming
3. It feels that in multi-threading, the operation of opencl is blocked and queued, and the use of mutex has almost no effect on the time consumption"
opencv/opencv,2022-06-03 20:48:16,question,cv2.drawFrameAxes broken,"Using python 3.9, macOS 12.2.1, OpenCV 4.5.5 I am not getting the correct axes displayed.

The axes are defined as ""OX is drawn in red, OY in green and OZ in blue."" in the [reference docs](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#gab3ab7bb2bdfe7d5d9745bb92d13f9564)

Using the code below: 

- zero rotation has the z-axis (blue) right and y-axis (green) down (wrong orientation)
- 90 deg around z-axis, rotates instead around the x-axis (red)
- 60 deg around y-axis, seems to work
- 60 deg around x-axis, rotates instead around the z-axis (blue)

```python
def drawAxes(rvecs):
    tvecs = np.array([0,0,0.])
    width = 400

    im = np.zeros((width,width,3))
    cx, cy = width//2, width//2
    f = width
    K = np.array([[f, 0, cx],[0, f, cy],[0, 0, 1]], dtype=float)
    dist = np.array([0.0, 0.0, 0.0, 0.0, 0.0], dtype=float)

    # set the axes size as a function of the marker's 
    # square size and project onto image space
    s = 4
    axis = np.float32([[s,0,0], [0,s,0], [0,0,s]]).reshape(-1,3)
    imgpts, jac = cv2.projectPoints(
        axis, 
        rvecs, 
        tvecs, 
        K, 
        dist
    )

    cv2.drawFrameAxes(
        im, 
        K, 
        dist, 
        rvecs, tvecs, 
        length=.2, thickness=3) 
    
    return im

plt.figure(figsize=(10,10))
plt.subplot(2,2,1)
plt.imshow(drawAxes(np.array([0,0,0.])))
plt.title(""XYZ = (0,0,0)"");

plt.subplot(2,2,2)
plt.imshow(drawAxes(np.array([0,0,pi/2])))
plt.title(""XYZ = (0,0,90)"");

plt.subplot(2,2,3)
plt.imshow(drawAxes(np.array([0,pi/3,0])))
plt.title(""XYZ = (0,60,0)"");

plt.subplot(2,2,4)
plt.imshow(drawAxes(np.array([pi/3,0,0])))
plt.title(""XYZ = (60,0,0)"");
```

![download](https://user-images.githubusercontent.com/918960/171949439-011340c5-23a0-42ac-aaa4-e48e6638794f.png)

"
opencv/opencv,2022-05-23 11:14:47,question,ORB FeatureDetector has different result between C++ and Python,"I use ORB FeatureDetector to extract feature using Python and C++, code sees below. But the output results is different completely, I am sure my input is same, and OpenCV version all is 3.4.6. I am confuse, I need some help.
 
![36dd59d464c83944dc2cbe65eb050be](https://user-images.githubusercontent.com/68552295/169807195-c3c1a1fa-bccc-4005-a6f6-eacd4db4fbc5.png)
![829fc43294916a32f4ca0a56b405f43](https://user-images.githubusercontent.com/68552295/169807233-b8a13427-d3f9-4a00-8233-f37fe6b53633.png)
"
opencv/opencv,2022-05-18 16:34:25,question,cv2.imread() fails when filenames have multiple dots (.),"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => 4.5.5.64
- Operating System / Platform => Windows
- Compiler => PyCharm Community Edition 2020.1.1

##### Detailed description

When the `cv2.imread()` method encounters a filename with multiple dots (.), a `NoneType` is returned. I think this might be because the file extension is assumed to be everything after the first dot, and not the last, but it could be something completely different.

Example: 

##### Steps to reproduce

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```-->
Running the following code, with two images in the same directory,
```.py
import cv2

im = cv2.imread(""C:/Users/.../Videos/Captures/test project – main.py 18_05_2022 15_44_50.png"")
im2 = cv2.imread(""C:/Users/.../Videos/Captures/Screenshot 16_05_2022 23_40_07.png"")

print(im)
print(im2)
```
gives the result:
```.py
[ WARN:0@0.221] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp (239) cv::findDecoder imread_('C:/Users/.../Videos/Captures/test project – main.py 18_05_2022 15_44_50.png'): can't open/read file: check file path/integrity
None
[[[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 [[153 139 140]
  [152 139 139]
  [151 139 138]
  ...
  [148 136 135]
  [150 138 138]
  [151 140 139]]]
```
which shows that the first image (one dot) loaded successfully, but the second one (with the multiple dots) failed.
##### Issue submission checklist

 - [x] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [x] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [x] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-05-16 03:05:42,question,SystemError: <built-in function writeTextGraph> returned NULL without setting an error when using cv2.dnn.writeTextGraph,"- OpenCV = 4.1.2
- Operating System / Platform = Windows 64 Bit
- Compiler = Google Colab

<!-- your description -->
So I recently created a machine learning model with Keras and saved it using the save_model function into a .pb file. I want to use this model with OpenCV, and therefore have been trying to obtain a .pbtxt file to use alongside the DNN module of OpenCV (net = cv2.dnn_DetectionModel(weightsPath,configPath)). Yet for some reason, I keep getting the error in the title: SystemError: <built-in function writeTextGraph> returned NULL without setting an error.

What I've done: I've been saving the model on Google Colab, so I've tried restarting the runtime a couple of times. I've made sure my file path was correct. I'm not sure how to check if the .pb file is corrupted, but I don't imagine it is since I directly downloaded it from Keras.

This is the code below:
```
model.save('mymodel5',save_format='pb')
loaded_model = tf.keras.models.load_model('/content/mymodel6') // this is the genereated folder from the .save function of keras
import cv2 
cv2.dnn.writeTextGraph(loaded_model, 'graph.pbtxt')
```"
opencv/opencv,2022-05-09 09:49:33,question,Error While Installing openCV 4.5.1 on Ubuntu 18.04 ( jetson nano production module).,"
##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => :grey_question:
- Operating System / Platform => :ubuntu 18.04:
- Compiler => :gcc (Ubuntu/Linaro 7.5.0-3ubuntu1~18.04) 7.5.0:

##### Detailed description

hello !
I'm using a jetson production module running on Ubuntu 18.04!
and I can't install Open CV 4.5.1.
I have already done and sudo apt-get update, and sudo apt-get upgrade.

#######steps :
 i'm running this script : 
#!/bin/bash
set -e
echo ""Installing OpenCV 4.5.1 on your Jetson Nano""
echo ""It will take 2 hours !""

# reveal the CUDA location
cd ~
sudo sh -c ""echo '/usr/local/cuda/lib64' >> /etc/ld.so.conf.d/nvidia-tegra.conf""
sudo ldconfig

# install the dependencies
sudo apt-get install -y build-essential cmake git unzip pkg-config
sudo apt-get install -y libjpeg-dev libpng-dev libtiff-dev
sudo apt-get install -y libavcodec-dev libavformat-dev libswscale-dev
sudo apt-get install -y libgtk2.0-dev libcanberra-gtk*
sudo apt-get install -y python3-dev python3-numpy python3-pip
sudo apt-get install -y libxvidcore-dev libx264-dev libgtk-3-dev
sudo apt-get install -y libtbb2 libtbb-dev libdc1394-22-dev
sudo apt-get install -y gstreamer1.0-tools libv4l-dev v4l-utils
sudo apt-get install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev
sudo apt-get install -y libavresample-dev libvorbis-dev libxine2-dev
sudo apt-get install -y libfaac-dev libmp3lame-dev libtheora-dev
sudo apt-get install -y libopencore-amrnb-dev libopencore-amrwb-dev
sudo apt-get install -y libopenblas-dev libatlas-base-dev libblas-dev
sudo apt-get install -y liblapack-dev libeigen3-dev gfortran
sudo apt-get install -y libhdf5-dev protobuf-compiler
sudo apt-get install -y libprotobuf-dev libgoogle-glog-dev libgflags-dev

# remove old versions or previous builds
cd ~ 
sudo rm -rf opencv*
# download the latest version
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.5.1.zip 
wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.5.1.zip 
# unpack
unzip opencv.zip 
unzip opencv_contrib.zip 
# some administration to make live easier later on
mv opencv-4.5.1 opencv
mv opencv_contrib-4.5.1 opencv_contrib
# clean up the zip files
rm opencv.zip
rm opencv_contrib.zip

# set install dir
cd ~/opencv
mkdir build
cd build

# run cmake
cmake -D CMAKE_BUILD_TYPE=RELEASE \\
-D CMAKE_INSTALL_PREFIX=/usr \\
-D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules \\
-D EIGEN_INCLUDE_PATH=/usr/include/eigen3 \\
-D WITH_OPENCL=OFF \\
-D WITH_CUDA=ON \\
-D CUDA_ARCH_BIN=5.3 \\
-D CUDA_ARCH_PTX="""" \\
-D WITH_CUDNN=ON \\
-D WITH_CUBLAS=ON \\
-D ENABLE_FAST_MATH=ON \\
-D CUDA_FAST_MATH=ON \\
-D OPENCV_DNN_CUDA=ON \\
-D ENABLE_NEON=ON \\
-D WITH_QT=OFF \\
-D WITH_OPENMP=ON \\
-D BUILD_TIFF=ON \\
-D WITH_FFMPEG=ON \\
-D WITH_GSTREAMER=ON \\
-D WITH_TBB=ON \\
-D BUILD_TBB=ON \\
-D BUILD_TESTS=OFF \\
-D WITH_EIGEN=ON \\
-D WITH_V4L=ON \\
-D WITH_LIBV4L=ON \\
-D OPENCV_ENABLE_NONFREE=ON \\
-D INSTALL_C_EXAMPLES=OFF \\
-D INSTALL_PYTHON_EXAMPLES=OFF \\
-D BUILD_NEW_PYTHON_SUPPORT=ON \\
-D BUILD_opencv_python3=TRUE \\
-D OPENCV_GENERATE_PKGCONFIG=ON \\
-D BUILD_EXAMPLES=OFF ..

# run make
FREE_MEM=""$(free -m | awk '/^Swap/ {print $2}')""
# Use ""-j 4"" only swap space is larger than 3.5GB
if [[ ""FREE_MEM"" -gt ""3500"" ]]; then
  NO_JOB=4
else
  echo ""Due to limited swap, make only uses 1 core""
  NO_JOB=1
fi
make -j ${NO_JOB} 

sudo rm -r /usr/include/opencv4/opencv2
sudo make install
sudo ldconfig

# cleaning (frees 300 MB)
make clean
sudo apt-get update

echo ""Congratulations!""
echo ""You've successfully installed OpenCV 4.5.1 on your Jetson Nano""



~#############################output
-- Found PythonInterp: /usr/bin/python2.7 (found suitable version ""2.7.17"", minimum required is ""2.7"")
-- Could NOT find PythonLibs (missing: PYTHON_LIBRARIES PYTHON_INCLUDE_DIRS) (Required is exact version ""2.7.17"")
Traceback (most recent call last):
File """", line 1, in
ImportError: No module named numpy.distutils
-- Found PythonInterp: /usr/bin/python3 (found suitable version ""3.6.9"", minimum required is ""3.2"")
-- Found PythonLibs: /usr/lib/aarch64-linux-gnu/libpython3.6m.so (found suitable exact version ""3.6.9"")
-- Looking for ccache - not found
-- Performing Test HAVE_CXX_FSIGNED_CHAR
-- Performing Test HAVE_CXX_FSIGNED_CHAR - Success
-- Performing Test HAVE_C_FSIGNED_CHAR
-- Performing Test HAVE_C_FSIGNED_CHAR - Success
-- Performing Test HAVE_CXX_FFAST_MATH
-- Performing Test HAVE_CXX_FFAST_MATH - Success
-- Performing Test HAVE_C_FFAST_MATH
-- Performing Test HAVE_C_FFAST_MATH - Success
-- Performing Test HAVE_CXX_W
-- Performing Test HAVE_CXX_W - Success
-- Performing Test HAVE_C_W
-- Performing Test HAVE_C_W - Success
-- Performing Test HAVE_CXX_WALL
-- Performing Test HAVE_CXX_WALL - Success
-- Performing Test HAVE_C_WALL
-- Performing Test HAVE_C_WALL - Success
-- Performing Test HAVE_CXX_WERROR_RETURN_TYPE
-- Performing Test HAVE_CXX_WERROR_RETURN_TYPE - Success
-- Performing Test HAVE_C_WERROR_RETURN_TYPE
-- Performing Test HAVE_C_WERROR_RETURN_TYPE - Success
-- Performing Test HAVE_CXX_WERROR_NON_VIRTUAL_DTOR
-- Performing Test HAVE_CXX_WERROR_NON_VIRTUAL_DTOR - Success
-- Performing Test HAVE_C_WERROR_NON_VIRTUAL_DTOR
-- Performing Test HAVE_C_WERROR_NON_VIRTUAL_DTOR - Failed
-- Performing Test HAVE_CXX_WERROR_ADDRESS
-- Performing Test HAVE_CXX_WERROR_ADDRESS - Success
-- Performing Test HAVE_C_WERROR_ADDRESS
-- Performing Test HAVE_C_WERROR_ADDRESS - Success
-- Performing Test HAVE_CXX_WERROR_SEQUENCE_POINT
-- Performing Test HAVE_CXX_WERROR_SEQUENCE_POINT - Success
-- Performing Test HAVE_C_WERROR_SEQUENCE_POINT
-- Performing Test HAVE_C_WERROR_SEQUENCE_POINT - Success
-- Performing Test HAVE_CXX_WFORMAT
-- Performing Test HAVE_CXX_WFORMAT - Success
-- Performing Test HAVE_C_WFORMAT
-- Performing Test HAVE_C_WFORMAT - Success
-- Performing Test HAVE_CXX_WERROR_FORMAT_SECURITY
-- Performing Test HAVE_CXX_WERROR_FORMAT_SECURITY - Success
-- Performing Test HAVE_C_WERROR_FORMAT_SECURITY
-- Performing Test HAVE_C_WERROR_FORMAT_SECURITY - Success
-- Performing Test HAVE_CXX_WMISSING_DECLARATIONS
-- Performing Test HAVE_CXX_WMISSING_DECLARATIONS - Success
-- Performing Test HAVE_C_WMISSING_DECLARATIONS
-- Performing Test HAVE_C_WMISSING_DECLARATIONS - Success
-- Performing Test HAVE_CXX_WMISSING_PROTOTYPES
-- Performing Test HAVE_CXX_WMISSING_PROTOTYPES - Failed
-- Performing Test HAVE_C_WMISSING_PROTOTYPES
-- Performing Test HAVE_C_WMISSING_PROTOTYPES - Success
-- Performing Test HAVE_CXX_WSTRICT_PROTOTYPES
-- Performing Test HAVE_CXX_WSTRICT_PROTOTYPES - Failed
-- Performing Test HAVE_C_WSTRICT_PROTOTYPES
-- Performing Test HAVE_C_WSTRICT_PROTOTYPES - Success
-- Performing Test HAVE_CXX_WUNDEF
-- Performing Test HAVE_CXX_WUNDEF - Success
-- Performing Test HAVE_C_WUNDEF
-- Performing Test HAVE_C_WUNDEF - Success
-- Performing Test HAVE_CXX_WINIT_SELF
-- Performing Test HAVE_CXX_WINIT_SELF - Success
-- Performing Test HAVE_C_WINIT_SELF
-- Performing Test HAVE_C_WINIT_SELF - Success
-- Performing Test HAVE_CXX_WPOINTER_ARITH
-- Performing Test HAVE_CXX_WPOINTER_ARITH - Success
-- Performing Test HAVE_C_WPOINTER_ARITH
-- Performing Test HAVE_C_WPOINTER_ARITH - Success
-- Performing Test HAVE_CXX_WSHADOW
-- Performing Test HAVE_CXX_WSHADOW - Success
-- Performing Test HAVE_C_WSHADOW
-- Performing Test HAVE_C_WSHADOW - Success
-- Performing Test HAVE_CXX_WSIGN_PROMO
-- Performing Test HAVE_CXX_WSIGN_PROMO - Success
-- Performing Test HAVE_C_WSIGN_PROMO
-- Performing Test HAVE_C_WSIGN_PROMO - Failed
-- Performing Test HAVE_CXX_WUNINITIALIZED
-- Performing Test HAVE_CXX_WUNINITIALIZED - Success
-- Performing Test HAVE_C_WUNINITIALIZED
-- Performing Test HAVE_C_WUNINITIALIZED - Success
-- Performing Test HAVE_CXX_WSUGGEST_OVERRIDE
-- Performing Test HAVE_CXX_WSUGGEST_OVERRIDE - Success
-- Performing Test HAVE_C_WSUGGEST_OVERRIDE
-- Performing Test HAVE_C_WSUGGEST_OVERRIDE - Failed
-- Performing Test HAVE_CXX_WNO_DELETE_NON_VIRTUAL_DTOR
-- Performing Test HAVE_CXX_WNO_DELETE_NON_VIRTUAL_DTOR - Success
-- Performing Test HAVE_C_WNO_DELETE_NON_VIRTUAL_DTOR
-- Performing Test HAVE_C_WNO_DELETE_NON_VIRTUAL_DTOR - Failed
-- Performing Test HAVE_CXX_WNO_UNNAMED_TYPE_TEMPLATE_ARGS
-- Performing Test HAVE_CXX_WNO_UNNAMED_TYPE_TEMPLATE_ARGS - Failed
-- Performing Test HAVE_C_WNO_UNNAMED_TYPE_TEMPLATE_ARGS
-- Performing Test HAVE_C_WNO_UNNAMED_TYPE_TEMPLATE_ARGS - Failed
-- Performing Test HAVE_CXX_WNO_COMMENT
-- Performing Test HAVE_CXX_WNO_COMMENT - Success
-- Performing Test HAVE_C_WNO_COMMENT
-- Performing Test HAVE_C_WNO_COMMENT - Success
-- Performing Test HAVE_CXX_WIMPLICIT_FALLTHROUGH_3
-- Performing Test HAVE_CXX_WIMPLICIT_FALLTHROUGH_3 - Success
-- Performing Test HAVE_C_WIMPLICIT_FALLTHROUGH_3
-- Performing Test HAVE_C_WIMPLICIT_FALLTHROUGH_3 - Success
-- Performing Test HAVE_CXX_WNO_STRICT_OVERFLOW
-- Performing Test HAVE_CXX_WNO_STRICT_OVERFLOW - Success
-- Performing Test HAVE_C_WNO_STRICT_OVERFLOW
-- Performing Test HAVE_C_WNO_STRICT_OVERFLOW - Success
-- Performing Test HAVE_CXX_FDIAGNOSTICS_SHOW_OPTION
-- Performing Test HAVE_CXX_FDIAGNOSTICS_SHOW_OPTION - Success
-- Performing Test HAVE_C_FDIAGNOSTICS_SHOW_OPTION
-- Performing Test HAVE_C_FDIAGNOSTICS_SHOW_OPTION - Success
-- Performing Test HAVE_CXX_PTHREAD
-- Performing Test HAVE_CXX_PTHREAD - Success
-- Performing Test HAVE_C_PTHREAD
-- Performing Test HAVE_C_PTHREAD - Success
-- Performing Test HAVE_CXX_FOMIT_FRAME_POINTER
-- Performing Test HAVE_CXX_FOMIT_FRAME_POINTER - Success
-- Performing Test HAVE_C_FOMIT_FRAME_POINTER
-- Performing Test HAVE_C_FOMIT_FRAME_POINTER - Success
-- Performing Test HAVE_CXX_FFUNCTION_SECTIONS
-- Performing Test HAVE_CXX_FFUNCTION_SECTIONS - Success
-- Performing Test HAVE_C_FFUNCTION_SECTIONS
-- Performing Test HAVE_C_FFUNCTION_SECTIONS - Success
-- Performing Test HAVE_CXX_FDATA_SECTIONS
-- Performing Test HAVE_CXX_FDATA_SECTIONS - Success
-- Performing Test HAVE_C_FDATA_SECTIONS
-- Performing Test HAVE_C_FDATA_SECTIONS - Success
-- Performing Test HAVE_CPU_NEON_SUPPORT (check file: cmake/checks/cpu_neon.cpp)
-- Performing Test HAVE_CPU_NEON_SUPPORT - Success
-- Performing Test HAVE_CPU_FP16_SUPPORT (check file: cmake/checks/cpu_fp16.cpp)
-- Performing Test HAVE_CPU_FP16_SUPPORT - Success
-- Performing Test HAVE_CPU_BASELINE_FLAGS
-- Performing Test HAVE_CPU_BASELINE_FLAGS - Success
-- Performing Test HAVE_CXX_FVISIBILITY_HIDDEN
-- Performing Test HAVE_CXX_FVISIBILITY_HIDDEN - Success
-- Performing Test HAVE_C_FVISIBILITY_HIDDEN
-- Performing Test HAVE_C_FVISIBILITY_HIDDEN - Success
-- Performing Test HAVE_CXX_FVISIBILITY_INLINES_HIDDEN
-- Performing Test HAVE_CXX_FVISIBILITY_INLINES_HIDDEN - Success
-- Performing Test HAVE_C_FVISIBILITY_INLINES_HIDDEN
-- Performing Test HAVE_C_FVISIBILITY_INLINES_HIDDEN - Failed
-- Performing Test HAVE_LINK_AS_NEEDED
-- Performing Test HAVE_LINK_AS_NEEDED - Success
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Looking for posix_memalign
-- Looking for posix_memalign - found
-- Looking for malloc.h
-- Looking for malloc.h - found
-- Looking for memalign
-- Looking for memalign - found
-- Check if the system is big endian
-- Searching 16 bit integer
-- Looking for sys/types.h
-- Looking for sys/types.h - found
-- Looking for stdint.h
-- Looking for stdint.h - found
-- Looking for stddef.h
-- Looking for stddef.h - found
-- Check size of unsigned short
-- Check size of unsigned short - done
-- Using unsigned short
-- Check if the system is big endian - little endian
-- Found OpenMP_C: -fopenmp (found version ""4.5"")
-- Found OpenMP_CXX: -fopenmp (found version ""4.5"")
-- Found OpenMP: TRUE (found version ""4.5"")
-- Found ZLIB: /usr/lib/aarch64-linux-gnu/libz.so (found suitable version ""1.2.11"", minimum required is ""1.2.3"")
-- Found JPEG: /usr/lib/aarch64-linux-gnu/libjpeg.so
-- Looking for assert.h
-- Looking for assert.h - found
-- Looking for dlfcn.h
-- Looking for dlfcn.h - found
-- Looking for fcntl.h
-- Looking for fcntl.h - found
-- Looking for inttypes.h
-- Looking for inttypes.h - found
-- Looking for io.h
-- Looking for io.h - not found
-- Looking for limits.h
-- Looking for limits.h - found
-- Looking for memory.h
-- Looking for memory.h - found
-- Looking for search.h
-- Looking for search.h - found
-- Looking for string.h
-- Looking for string.h - found
-- Looking for strings.h
-- Looking for strings.h - found
-- Looking for sys/time.h
-- Looking for sys/time.h - found
-- Looking for unistd.h
-- Looking for unistd.h - found
-- Performing Test C_HAS_inline
-- Performing Test C_HAS_inline - Success
-- Check size of signed short
-- Check size of signed short - done
-- Check size of unsigned short
-- Check size of unsigned short - done
-- Check size of signed int
-- Check size of signed int - done
-- Check size of unsigned int
-- Check size of unsigned int - done
-- Check size of signed long
-- Check size of signed long - done
-- Check size of unsigned long
-- Check size of unsigned long - done
-- Check size of signed long long
-- Check size of signed long long - done
-- Check size of unsigned long long
-- Check size of unsigned long long - done
-- Check size of unsigned char *
-- Check size of unsigned char * - done
-- Check size of size_t
-- Check size of size_t - done
-- Check size of ptrdiff_t
-- Check size of ptrdiff_t - done
-- Check size of INT8
-- Check size of INT8 - failed
-- Check size of INT16
-- Check size of INT16 - failed
-- Check size of INT32
-- Check size of INT32 - failed
-- Looking for floor
-- Looking for floor - found
-- Looking for pow
-- Looking for pow - found
-- Looking for sqrt
-- Looking for sqrt - found
-- Looking for isascii
-- Looking for isascii - found
-- Looking for memset
-- Looking for memset - found
-- Looking for mmap
-- Looking for mmap - found
-- Looking for getopt
-- Looking for getopt - found
-- Looking for memmove
-- Looking for memmove - found
-- Looking for setmode
-- Looking for setmode - not found
-- Looking for strcasecmp
-- Looking for strcasecmp - found
-- Looking for strchr
-- Looking for strchr - found
-- Looking for strrchr
-- Looking for strrchr - found
-- Looking for strstr
-- Looking for strstr - found
-- Looking for strtol
-- Looking for strtol - found
-- Looking for strtol
-- Looking for strtol - found
-- Looking for strtoull
-- Looking for strtoull - found
-- Looking for lfind
-- Looking for lfind - found
-- Performing Test HAVE_SNPRINTF
-- Performing Test HAVE_SNPRINTF - Success
-- Check if the system is big endian
-- Searching 16 bit integer
-- Using unsigned short
-- Check if the system is big endian - little endian
-- Performing Test HAVE_C_WNO_UNUSED_BUT_SET_VARIABLE
-- Performing Test HAVE_C_WNO_UNUSED_BUT_SET_VARIABLE - Success
-- Performing Test HAVE_C_WNO_MISSING_PROTOTYPES
-- Performing Test HAVE_C_WNO_MISSING_PROTOTYPES - Success
-- Performing Test HAVE_C_WNO_MISSING_DECLARATIONS
-- Performing Test HAVE_C_WNO_MISSING_DECLARATIONS - Success
-- Performing Test HAVE_C_WNO_UNDEF
-- Performing Test HAVE_C_WNO_UNDEF - Success
-- Performing Test HAVE_C_WNO_UNUSED
-- Performing Test HAVE_C_WNO_UNUSED - Success
-- Performing Test HAVE_C_WNO_SIGN_COMPARE
-- Performing Test HAVE_C_WNO_SIGN_COMPARE - Success
-- Performing Test HAVE_C_WNO_CAST_ALIGN
-- Performing Test HAVE_C_WNO_CAST_ALIGN - Success
-- Performing Test HAVE_C_WNO_SHADOW
-- Performing Test HAVE_C_WNO_SHADOW - Success
-- Performing Test HAVE_C_WNO_MAYBE_UNINITIALIZED
-- Performing Test HAVE_C_WNO_MAYBE_UNINITIALIZED - Success
-- Performing Test HAVE_C_WNO_POINTER_TO_INT_CAST
-- Performing Test HAVE_C_WNO_POINTER_TO_INT_CAST - Success
-- Performing Test HAVE_C_WNO_INT_TO_POINTER_CAST
-- Performing Test HAVE_C_WNO_INT_TO_POINTER_CAST - Success
-- Performing Test HAVE_C_WNO_MISLEADING_INDENTATION
-- Performing Test HAVE_C_WNO_MISLEADING_INDENTATION - Success
-- Performing Test HAVE_C_WNO_IMPLICIT_FALLTHROUGH
-- Performing Test HAVE_C_WNO_IMPLICIT_FALLTHROUGH - Success
-- Performing Test HAVE_C_WNO_UNUSED_PARAMETER
-- Performing Test HAVE_C_WNO_UNUSED_PARAMETER - Success
-- Performing Test HAVE_CXX_WNO_MISSING_DECLARATIONS
-- Performing Test HAVE_CXX_WNO_MISSING_DECLARATIONS - Success
-- Performing Test HAVE_CXX_WNO_UNUSED_PARAMETER
-- Performing Test HAVE_CXX_WNO_UNUSED_PARAMETER - Success
-- Performing Test HAVE_CXX_WNO_MISSING_PROTOTYPES
-- Performing Test HAVE_CXX_WNO_MISSING_PROTOTYPES - Failed
-- Performing Test HAVE_CXX_WNO_UNDEF
-- Performing Test HAVE_CXX_WNO_UNDEF - Success
-- Performing Test HAVE_C_STD_C99
-- Performing Test HAVE_C_STD_C99 - Success
-- Performing Test HAVE_C_WNO_UNUSED_VARIABLE
-- Performing Test HAVE_C_WNO_UNUSED_VARIABLE - Success
-- Performing Test HAVE_C_WNO_UNUSED_FUNCTION
-- Performing Test HAVE_C_WNO_UNUSED_FUNCTION - Success
-- Could NOT find OpenJPEG (minimal suitable version: 2.0, recommended version >= 2.3.1). OpenJPEG will be built from sources
-- Performing Test HAVE_C_WNO_IMPLICIT_CONST_INT_FLOAT_CONVERSION
-- Performing Test HAVE_C_WNO_IMPLICIT_CONST_INT_FLOAT_CONVERSION - Failed
-- OpenJPEG: VERSION = 2.3.1, BUILD = opencv-4.5.1-openjp2-2.3.1
-- Check if the system is big endian
-- Searching 16 bit integer
-- Using unsigned short
-- Check if the system is big endian - little endian
-- Looking for stdlib.h
-- Looking for stdlib.h - found
-- Looking for stdio.h
-- Looking for stdio.h - found
-- Looking for math.h
-- Looking for math.h - found
-- Looking for float.h
-- Looking for float.h - found
-- Looking for time.h
-- Looking for time.h - found
-- Looking for stdarg.h
-- Looking for stdarg.h - found
-- Looking for ctype.h
-- Looking for ctype.h - found
-- Looking for stdint.h
-- Looking for stdint.h - found
-- Looking for inttypes.h
-- Looking for inttypes.h - found
-- Looking for sys/stat.h
-- Looking for sys/stat.h - found
-- Looking for include file malloc.h
-- Looking for include file malloc.h - found
-- Looking for _aligned_malloc
-- Looking for _aligned_malloc - not found
-- Looking for posix_memalign
-- Looking for posix_memalign - found
-- Looking for memalign
-- Looking for memalign - found
-- Performing Test HAVE_C_WNO_STRICT_PROTOTYPES
-- Performing Test HAVE_C_WNO_STRICT_PROTOTYPES - Success
-- Performing Test HAVE_C_WNO_CAST_FUNCTION_TYPE
-- Performing Test HAVE_C_WNO_CAST_FUNCTION_TYPE - Failed
-- OpenJPEG libraries will be built from sources: libopenjp2 (version ""2.3.1"")
-- Found ZLIB: /usr/lib/aarch64-linux-gnu/libz.so (found version ""1.2.11"")
-- Found PNG: /usr/lib/aarch64-linux-gnu/libpng.so (found version ""1.6.34"")
-- Looking for /usr/include/libpng/png.h
-- Looking for /usr/include/libpng/png.h - found
-- Looking for semaphore.h
-- Looking for semaphore.h - found
-- Performing Test HAVE_CXX_WNO_SHADOW
-- Performing Test HAVE_CXX_WNO_SHADOW - Success
-- Performing Test HAVE_CXX_WNO_UNUSED
-- Performing Test HAVE_CXX_WNO_UNUSED - Success
-- Performing Test HAVE_CXX_WNO_SIGN_COMPARE
-- Performing Test HAVE_CXX_WNO_SIGN_COMPARE - Success
-- Performing Test HAVE_CXX_WNO_UNINITIALIZED
-- Performing Test HAVE_CXX_WNO_UNINITIALIZED - Success
-- Performing Test HAVE_CXX_WNO_SWITCH
-- Performing Test HAVE_CXX_WNO_SWITCH - Success
-- Performing Test HAVE_CXX_WNO_PARENTHESES
-- Performing Test HAVE_CXX_WNO_PARENTHESES - Success
-- Performing Test HAVE_CXX_WNO_ARRAY_BOUNDS
-- Performing Test HAVE_CXX_WNO_ARRAY_BOUNDS - Success
-- Performing Test HAVE_CXX_WNO_EXTRA
-- Performing Test HAVE_CXX_WNO_EXTRA - Success
-- Performing Test HAVE_CXX_WNO_DEPRECATED_DECLARATIONS
-- Performing Test HAVE_CXX_WNO_DEPRECATED_DECLARATIONS - Success
-- Performing Test HAVE_CXX_WNO_MISLEADING_INDENTATION
-- Performing Test HAVE_CXX_WNO_MISLEADING_INDENTATION - Success
-- Performing Test HAVE_CXX_WNO_DEPRECATED
-- Performing Test HAVE_CXX_WNO_DEPRECATED - Success
-- Performing Test HAVE_CXX_WNO_SUGGEST_OVERRIDE
-- Performing Test HAVE_CXX_WNO_SUGGEST_OVERRIDE - Success
-- Performing Test HAVE_CXX_WNO_INCONSISTENT_MISSING_OVERRIDE
-- Performing Test HAVE_CXX_WNO_INCONSISTENT_MISSING_OVERRIDE - Failed
-- Performing Test HAVE_CXX_WNO_IMPLICIT_FALLTHROUGH
-- Performing Test HAVE_CXX_WNO_IMPLICIT_FALLTHROUGH - Success
-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_COMPARE
-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_COMPARE - Success
-- Performing Test HAVE_CXX_WNO_REORDER
-- Performing Test HAVE_CXX_WNO_REORDER - Success
-- Performing Test HAVE_CXX_WNO_UNUSED_RESULT
-- Performing Test HAVE_CXX_WNO_UNUSED_RESULT - Success
-- Performing Test HAVE_CXX_WNO_IMPLICIT_CONST_INT_FLOAT_CONVERSION
-- Performing Test HAVE_CXX_WNO_IMPLICIT_CONST_INT_FLOAT_CONVERSION - Failed
-- Checking for module 'gtk+-3.0'
-- Found gtk+-3.0, version 3.22.30
-- Checking for module 'gthread-2.0'
-- Found gthread-2.0, version 2.56.4
-- TBB: Download: v2020.2.tar.gz
-- Performing Test HAVE_CXX_WNO_CLASS_MEMACCESS
-- Performing Test HAVE_CXX_WNO_CLASS_MEMACCESS - Failed
CMake Warning at cmake/OpenCVFindLibsPerf.cmake:45 (message):
OpenCV is not able to find/configure CUDA SDK (required by WITH_CUDA).

CUDA support will be disabled in OpenCV build.

To eliminate this warning remove WITH_CUDA=ON CMake configuration option.

Call Stack (most recent call first):
CMakeLists.txt:700 (include)

-- Could not find OpenBLAS include. Turning OpenBLAS_FOUND off
-- Could not find OpenBLAS lib. Turning OpenBLAS_FOUND off
-- Could NOT find Atlas (missing: Atlas_CLAPACK_INCLUDE_DIR)
-- Looking for sgemm_
-- Looking for sgemm_ - found
-- Found Threads: TRUE
-- A library with BLAS API found.
-- Looking for cheev_
-- Looking for cheev_ - found
-- A library with LAPACK API found.
-- Performing Test HAVE_CXX_WNO_UNUSED_LOCAL_TYPEDEFS
-- Performing Test HAVE_CXX_WNO_UNUSED_LOCAL_TYPEDEFS - Success
-- Performing Test HAVE_CXX_WNO_SIGN_PROMO
-- Performing Test HAVE_CXX_WNO_SIGN_PROMO - Success
-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_UNDEFINED_COMPARE
-- Performing Test HAVE_CXX_WNO_TAUTOLOGICAL_UNDEFINED_COMPARE - Failed
-- Performing Test HAVE_CXX_WNO_IGNORED_QUALIFIERS
-- Performing Test HAVE_CXX_WNO_IGNORED_QUALIFIERS - Success
-- Performing Test HAVE_CXX_WNO_UNUSED_FUNCTION
-- Performing Test HAVE_CXX_WNO_UNUSED_FUNCTION - Success
-- Performing Test HAVE_CXX_WNO_UNUSED_CONST_VARIABLE
-- Performing Test HAVE_CXX_WNO_UNUSED_CONST_VARIABLE - Success
-- Performing Test HAVE_CXX_WNO_SHORTEN_64_TO_32
-- Performing Test HAVE_CXX_WNO_SHORTEN_64_TO_32 - Failed
-- Performing Test HAVE_CXX_WNO_INVALID_OFFSETOF
-- Performing Test HAVE_CXX_WNO_INVALID_OFFSETOF - Success
-- Performing Test HAVE_CXX_WNO_ENUM_COMPARE_SWITCH
-- Performing Test HAVE_CXX_WNO_ENUM_COMPARE_SWITCH - Failed
-- Could NOT find JNI (missing: JAVA_AWT_LIBRARY JAVA_JVM_LIBRARY JAVA_INCLUDE_PATH JAVA_INCLUDE_PATH2 JAVA_AWT_INCLUDE_PATH)
-- VTK is not found. Please set -DVTK_DIR in CMake to VTK build directory, or to VTK install subdirectory with VTKConfig.cmake file
-- Looking for dlerror in dl
-- Looking for dlerror in dl - found
-- ADE: Download: v0.1.1f.zip
-- OpenCV Python: during development append to PYTHONPATH: /home/nvidia/opencv/build/python_loader
-- Checking for modules 'libavcodec;libavformat;libavutil;libswscale'
-- Found libavcodec, version 57.107.100
-- Found libavformat, version 57.83.100
-- Found libavutil, version 55.78.100
-- Found libswscale, version 4.8.100
-- Checking for module 'libavresample'
-- Found libavresample, version 3.7.0
-- Checking for module 'gstreamer-base-1.0'
-- Found gstreamer-base-1.0, version 1.14.5
-- Checking for module 'gstreamer-app-1.0'
-- Found gstreamer-app-1.0, version 1.14.5
-- Checking for module 'gstreamer-riff-1.0'
-- Found gstreamer-riff-1.0, version 1.14.5
-- Checking for module 'gstreamer-pbutils-1.0'
-- Found gstreamer-pbutils-1.0, version 1.14.5
-- Checking for module 'libdc1394-2'
-- Found libdc1394-2, version 2.2.5
-- Caffe: NO
-- Protobuf: NO
-- Glog: YES
-- Checking for module 'freetype2'
-- Found freetype2, version 21.0.15
-- Checking for module 'harfbuzz'
-- Found harfbuzz, version 1.7.2
-- freetype2: YES (ver 21.0.15)
-- harfbuzz: YES (ver 1.7.2)
-- HDF5: Using hdf5 compiler wrapper to determine C configuration
-- Found HDF5: /usr/lib/aarch64-linux-gnu/hdf5/serial/libhdf5.so;/usr/lib/aarch64-linux-gnu/libpthread.so;/usr/lib/aarch64-linux-gnu/libsz.so;/usr/lib/aarch64-linux-gnu/libz.so;/usr/lib/aarch64-linux-gnu/libdl.so;/usr/lib/aarch64-linux-gnu/libm.so (found version ""1.10.0.1"")
-- Julia not found. Not compiling Julia Bindings.
-- Module opencv_ovis disabled because OGRE3D was not found
-- Checking SFM glog/gflags deps... TRUE
-- CERES support is disabled. Ceres Solver for reconstruction API is required.
-- Checking for module 'tesseract'
-- No package 'tesseract' found
-- Tesseract: NO
-- Allocator metrics storage type: 'int'
-- HDF5: Using hdf5 compiler wrapper to determine C configuration
-- Excluding from source files list: modules/imgproc/src/corner.avx.cpp
-- Excluding from source files list: modules/imgproc/src/imgwarp.avx2.cpp
-- Excluding from source files list: modules/imgproc/src/imgwarp.sse4_1.cpp
-- Excluding from source files list: modules/imgproc/src/resize.avx2.cpp
-- Excluding from source files list: modules/imgproc/src/resize.sse4_1.cpp
CMake Error at modules/dnn/CMakeLists.txt:35 (message):
DNN: CUDA backend requires CUDA Toolkit. Please resolve dependency or
disable OPENCV_DNN_CUDA=OFF

-- Registering hook 'INIT_MODULE_SOURCES_opencv_dnn': /home/nvidia/opencv/modules/dnn/cmake/hooks/INIT_MODULE_SOURCES_opencv_dnn.cmake
-- opencv_dnn: filter out ocl4dnn source code
-- opencv_dnn: filter out cuda4dnn source code
-- Excluding from source files list: /modules/dnn/layers/layers_common.avx.cpp
-- Excluding from source files list: /modules/dnn/layers/layers_common.avx2.cpp
-- Excluding from source files list: /modules/dnn/layers/layers_common.avx512_skx.cpp
-- Excluding from source files list: modules/features2d/src/fast.avx2.cpp
-- Performing Test HAVE_CXX_WNO_OVERLOADED_VIRTUAL
-- Performing Test HAVE_CXX_WNO_OVERLOADED_VIRTUAL - Success
-- rgbd: CERES support is disabled. Ceres Solver is Required for Posegraph optimization
-- xfeatures2d/boostdesc: Download: boostdesc_bgm.i
-- xfeatures2d/boostdesc: Download: boostdesc_bgm_bi.i
-- xfeatures2d/boostdesc: Download: boostdesc_bgm_hd.i
-- xfeatures2d/boostdesc: Download: boostdesc_binboost_064.i
-- xfeatures2d/boostdesc: Download: boostdesc_binboost_128.i
-- xfeatures2d/boostdesc: Download: boostdesc_binboost_256.i
-- xfeatures2d/boostdesc: Download: boostdesc_lbgm.i
-- xfeatures2d/vgg: Download: vgg_generated_48.i
-- xfeatures2d/vgg: Download: vgg_generated_64.i
-- xfeatures2d/vgg: Download: vgg_generated_80.i
-- xfeatures2d/vgg: Download: vgg_generated_120.i
-- data: Download: face_landmark_model.dat
-- CERES support is disabled. Ceres Solver for reconstruction API is required.
-- Performing Test HAVE_CXX_WNO_UNUSED_BUT_SET_VARIABLE
-- Performing Test HAVE_CXX_WNO_UNUSED_BUT_SET_VARIABLE - Success
-- Performing Test HAVE_CXX_WNO_UNUSED_PRIVATE_FIELD
-- Performing Test HAVE_CXX_WNO_UNUSED_PRIVATE_FIELD - Failed
-- General configuration for OpenCV 4.5.1 =====================================
-- Version control: unknown
-- Extra modules:
-- Location (extra): /home/nvidia/opencv_contrib/modules
-- Version control (extra): unknown
-- Platform:
-- Timestamp: 2022-05-09T08:07:01Z
-- Host: Linux 4.9.201-tegra aarch64
-- CMake: 3.10.2
-- CMake generator: Unix Makefiles
-- CMake build tool: /usr/bin/make
-- Configuration: RELEASE
-- CPU/HW features:
-- Baseline: NEON FP16
-- required: NEON
-- C/C++:
-- Built as dynamic libs?: YES
-- C++ standard: 11
-- C++ Compiler: /usr/bin/c++ (ver 7.5.0)
-- C++ flags (Release): -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections -fvisibility=hidden -fvisibility-inlines-hidden -fopenmp -O3 -DNDEBUG -DNDEBUG
-- C++ flags (Debug): -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections -fvisibility=hidden -fvisibility-inlines-hidden -fopenmp -g -O0 -DDEBUG -D_DEBUG
-- C Compiler: /usr/bin/cc
-- C flags (Release): -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections -fvisibility=hidden -fopenmp -O3 -DNDEBUG -DNDEBUG
-- C flags (Debug): -fsigned-char -ffast-math -W -Wall -Werror=return-type -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections -fvisibility=hidden -fopenmp -g -O0 -DDEBUG -D_DEBUG
-- Linker flags (Release): -Wl,--gc-sections -Wl,--as-needed
-- Linker flags (Debug): -Wl,--gc-sections -Wl,--as-needed
-- ccache: NO
-- Precompiled headers: NO
-- Extra dependencies: dl m pthread rt
-- 3rdparty dependencies:
-- OpenCV modules:
-- To be built: alphamat aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnn_objdetect dnn_superres dpm face features2d flann freetype fuzzy gapi hdf hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab xfeatures2d ximgproc xobjdetect xphoto
-- Disabled: world
-- Disabled by dependency: -
-- Unavailable: cnn_3dobj cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv java julia matlab ovis python2 viz
-- Applications: perf_tests apps
-- Documentation: NO
-- Non-free algorithms: YES
-- GUI:
-- GTK+: YES (ver 3.22.30)
-- GThread : YES (ver 2.56.4)
-- GtkGlExt: NO
-- VTK support: NO
-- Media I/O:
-- ZLib: /usr/lib/aarch64-linux-gnu/libz.so (ver 1.2.11)
-- JPEG: /usr/lib/aarch64-linux-gnu/libjpeg.so (ver 80)
-- WEBP: build (ver encoder: 0x020f)
-- PNG: /usr/lib/aarch64-linux-gnu/libpng.so (ver 1.6.34)
-- TIFF: build (ver 42 - 4.0.10)
-- JPEG 2000: build (ver 2.3.1)
-- OpenEXR: build (ver 2.3.0)
-- HDR: YES
-- SUNRASTER: YES
-- PXM: YES
-- PFM: YES
-- Video I/O:
-- DC1394: YES (2.2.5)
-- FFMPEG: YES
-- avcodec: YES (57.107.100)
-- avformat: YES (57.83.100)
-- avutil: YES (55.78.100)
-- swscale: YES (4.8.100)
-- avresample: YES (3.7.0)
-- GStreamer: YES (1.14.5)
-- v4l/v4l2: YES (linux/videodev2.h)
-- Parallel framework: TBB (ver 2020.2 interface 11102)
-- Trace: YES (with Intel ITT)
-- Other third-party libraries:
-- Lapack: NO
-- Eigen: YES (ver 3.3.4)
-- Custom HAL: YES (carotene (ver 0.0.1))
-- Protobuf: build (3.5.1)
-- NVIDIA CUDA: NO
-- cuDNN: NO
-- Python 3:
-- Interpreter: /usr/bin/python3 (ver 3.6.9)
-- Libraries: /usr/lib/aarch64-linux-gnu/libpython3.6m.so (ver 3.6.9)
-- numpy: /usr/lib/python3/dist-packages/numpy/core/include (ver 1.13.3)
-- install path: lib/python3.6/dist-packages/cv2/python-3.6
-- Python (for build): /usr/bin/python2.7
-- Java:
-- ant: NO
-- JNI: NO
-- Java wrappers: NO
-- Java tests: NO
-- Install to: /usr

--
-- Configuring incomplete, errors occurred!
See also ""/home/nvidia/opencv/build/CMakeFiles/CMakeOutput.log"".
See also ""/home/nvidia/opencv/build/CMakeFiles/CMakeError.log""."
opencv/opencv,2022-05-07 06:20:16,question,JS version cannot find the undistortpoints function 。how to compute distorted image points position in opencv.js？,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => :grey_question:
- Operating System / Platform => :grey_question:
- Compiler => :grey_question:

##### Detailed description

<!-- your description -->

##### Steps to reproduce

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->

##### Issue submission checklist

 - [ ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [ ] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [ ] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-05-06 08:53:54,question,common.hpp,"```
##### System information 
- OpenCV => 4.5.5
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2022
```


Hi
I just installing openCV, and I trying this code : https://docs.opencv.org/4.x/d5/de7/tutorial_dnn_googlenet.html
But, i have an error : VS2022 can not found ""common.hpp"".

Someone know how to resolve this ? I need to replace it with another lib?

Thanks a lot :D
"
opencv/opencv,2022-05-01 14:20:12,question, Iplimage has not been declared,"`#ifndef MM3D_H
#define MM3D_H

#include <math.h>
#include ""3DMMGlobal.h""
//#include <cv.h> pf注释的,找不到这个文件


#include <opencv2/opencv.hpp>
#include <algorithm>
//#include <Windows.h> pf注释的,找不到这个文件
//#include <gl\\GL.h> pf注释的,找不到这个文件
//#include <GL\\GLU.h> pf注释的,找不到这个文件

using namespace std;
using namespace cv;

#define INF 1E20

class MM3D
{
public:
	// 3DMM and Reference Frame Mapping
	void Cartesian2Ref(double* vertex, double* tri, double* texture, int width, int height, int nver, int ntri, double* ref, double* refco, double* tri_ind);
	void ZBuffer(double* vertex, double* tri, double* texture, int nver, int ntri, double* src_img, int width, int height, int nChannels, double* img, double* tri_ind);
	void ZBufferTri(double* vertex, double* tri, double* texture_tri, int nver, int ntri, double* src_img, int width, int height, int nChannels, double* img, double* tri_ind);
	void GetCoverTri(double* vertex, double* tri, double* r, double* p, int nver, int ntri, double* coverTri);
	void VisibleSurf(double* vertex, double* tri, double* r, int nver, int ntri, double* vis_bin);
	bool PointInTri(Mat* point, Mat* pt1, Mat* pt2, Mat* pt3);
	void DistanceTransform(double* dt, double* im, int width, int height);
	void dt(float *d, float *f, int n); 
	void Lighting(double* vertex, double* tri, double* tex, int _nv, int _nt, Illum_Para para, IplImage* img);
	void DrawModal(float* _shape, unsigned int* _triangle, float* _color, int _nt, int _nv, Illum_Para para, unsigned char* face, int widthstep);
	void NormDirection(float* vertex, unsigned int* tri, int nt, int nv, float* norm);
	void MeshMap(double* vertex, double* tri, int nver, int ntri, double* meshMap, int width, int height);
	void OcclusionQuery(double* vertex, double* tri, int ntri, int nver, int width, int height, double* visibility, double threshold);
	// OpenGL related
	HGLRC _hrc;	
	HDC _hdc;
	BYTE* _data;
	HBITMAP _bitmap;	// for face
	int _width;
	int _height;
	BOOL PrepareGL();
	BOOL ReleaseGL();
	double xmin;
	double xmax;
	double ymin;
	double ymax;
	double zmin;
	double zmax;

};



#endif`

-----------

![1](https://user-images.githubusercontent.com/100210045/166149927-0697e128-a8a5-4f92-9a5c-e0420f8cae2f.png)
----
my opencv version is 4.5.5. I use matlab  mex compile opencv, but i got a bug. I have no idea"
opencv/opencv,2022-04-22 15:15:11,question,Difference in predictions when running on GPU vs CPU,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV =4.5.0
- Operating System / Platform = Ubuntu 20.04.3
- Compiler => Visual Studio 2017
-->

- OpenCV = 4.5.0
- Operating System / Platform =Ubuntu 20.04.3 LTS
- Python 3.8.10
- CUDA Driver Version / Runtime Version: 11.50 / 11.40
-  CUDA Capability Major/Minor version number: 8.6

##### Detailed description

Hi there, at the moment I'm trying to use my GPU (NVIDIA RTX 3060Ti) for inference of some darknet models using OpenCV dnn module. However, I've run into something that I can't quite explain. When running on CPU I get better results in terms of prediction accuracy compared to when running on GPU. 

Outcomes:  [(x-position,  y-position,    width,     height,    confidence)]
Using CPU: [(1660.1124, 137.18239, 6.899952, 9.705516, 0.75609446)]
Using GPU: [(1661.1267, 137.38803, 7.0430055, 10.015738, 0.4337875)]

The big difference here is the confidence scores which seem to be off. This happens when running on the out-of-the-box YOLOv3 model (weights and config) but also when running custom models. 

##### Steps to reproduce 
(uncomment lines stating setPreferableBackend and setPreferableTarget to enable GPU usage)
Also did a quick check on the output of cv2.dnn.blobFromImage(). This returns the exact same image when running with CPU or GPU enabled.
```
import cv2
import numpy as np

if __name__ == '__main__':
    net = cv2.dnn.readNet(
        r""network.weights"",
        r""network.cfg""
    )
    # net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
    # net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
    img = cv2.imread(r""test_image.jpg"")
    blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(1056, 1056), mean=(0, 0, 0), swapRB=True, crop=False)

    output_layers = net.getUnconnectedOutLayersNames()
    net.setInput(blob)
    outputs = net.forward(output_layers)

    detections = np.array([detection for output in outputs for detection in output])
    scores = detections[:, 5:]
    data = detections[:, :4]
    class_ids = np.argmax(scores, axis=1)

    main_scores = scores[np.arange(len(scores)), class_ids]

    # Keep only detections which have score higher than conf
    suff_scores = main_scores > 0.3
    # Class ID and score
    class_ids = class_ids[suff_scores]
    confs = main_scores[suff_scores]
    data = data[suff_scores]
    w = data[:, 2] * 1920
    h = data[:, 3] * 1080
    center_x = data[:, 0] * 1920
    center_y = data[:, 1] * 1080
    print([(a, b, c, d, e) for a, b, c, d, e in zip(center_x, center_y, w, h, confs)])

```

Thanks in advance!"
opencv/opencv,2022-04-14 20:45:32,question,Missing libraries in OpenCV 3.3.1,"I tried installing opencv3.3.1 using the exe at https://github.com/opencv/opencv/releases/tag/3.3.1
However it seems to be missing some libraries that I need to run my application. How can I obtain the complete set of libraries?
![image](https://user-images.githubusercontent.com/92061625/163472350-91f0caf5-a21c-4b08-973c-6e0bd6e08c0d.png)
"
opencv/opencv,2022-04-14 01:06:49,question,Why are there 3 compiled dynamic libraries? What's the difference between them?,"<img width=""200"" alt=""5738e7a7591e792495cc5b2252574c2"" src=""https://user-images.githubusercontent.com/48303408/163294064-57e147bd-e087-452d-8c52-30026710ba29.png"">
"
opencv/opencv,2022-04-13 19:53:23,question,`cv.imdecode` can't open the dib(bmp) images from clipboard,"##### System information (version)
- OpenCV => opencv-python 3.5.5
- Operating System / Platform => win10
- Compiler => pre-compiled

##### Detailed description
`cv.imdecode` can't open the dib(bmp) images from clipboard, but can from file

##### Steps to reproduce
work:
```py
with open('Untitled.bmp','rb') as f:
    src = f.read()
cv.imdecode(np.frombuffer(src, dtype=np.uint8), cv.IMREAD_COLOR)
```

can't work:
```py
# take a screenshoot or anything
win32clipboard.OpenClipboard()
src = win32clipboard.GetClipboardData(win32con.CF_DIB) # or win32con.CF_DIBV5
win32clipboard.CloseClipboard()
cv.imdecode(np.frombuffer(src, dtype=np.uint8), cv.IMREAD_COLOR)
```
the `imdecode` return `null`.
Is it able to support this kind of format of `BMP(aka DIB)` for OpenCV?

##### Issue submission checklist

 - [x] I report the issue, it's not a question
 - [x] I checked the problem with documentation, FAQ, open issues,
 - [x] I updated to the latest OpenCV version and the issue is still there
 - [x] There is reproducer code and related data files: videos, images, onnx, etc"
opencv/opencv,2022-04-10 11:32:58,question,Python and Java don't decode JPG in the same way,"##### System information (version)
- OpenCV => 4.5.3
- Operating System / Platform => Linux/Debian
- Compiler => System default

##### Detailed description

JPG images read from python or java aren't exactly equal.
I would expect that they get decoded to exactly the same uint8 values.
Below an example

##### Steps to reproduce

    ```python
    img1 = cv.imread("".2.jpg"")
    img1.max(axis=(0,1))
    ```
Result: array([194, 188, 190], dtype=uint8)

    ``` java
        String imgFile = ""2.jpg"";
        Mat img = Imgcodecs.imread(imgFile);
        List<Mat> channels = new ArrayList<Mat>();
        Core.split(img, channels);
        channels.forEach(ch -> System.out.println(Core.minMaxLoc(ch).maxVal));
Result: 
189.0
184.0
189.0
    ```
I've attached the input file `2.jpg`

##### Issue submission checklist

 - [X ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [ X] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [ X] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [ X] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
![2](https://user-images.githubusercontent.com/4727509/162615997-3aeb9c56-52ab-4b77-a079-378133b1d61f.jpg)

"
opencv/opencv,2022-04-01 23:57:57,question,"Undefined symbols for architecture arm64:   ""std::__1::basic_istream, (built on m1 mac)","I followed that instructions on #21571 and successfully built an xcframework. When I tried to import it the follow error show.

`Undefined symbols for architecture arm64:
  ""std::__1::basic_istream<char, std::__1::char_traits<char> >::sentry::sentry(std::__1::basic_istream<char, std::__1::char_traits<char> >&, bool)"", referenced from:`

Platform: macbook pro with m1 pro chip
swift-driver version: 1.45.2 Apple Swift version 5.6 (swiftlang-5.6.0.323.62 clang-1316.0.20.8)
Target: arm64-apple-macosx12.0
Apple clang version 13.1.6 (clang-1316.0.21.2)"
opencv/opencv,2022-03-31 04:37:05,question,some issue with cmake and opencv ,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->





##### Detailed description

recently i am working on my first project, which is using intel d455 to track skeleton. i am planning use opencv to complete. i had read some articles, and one of them is from intel.
[https://www.intel.com/content/www/us/en/support/articles/000036986/emerging-technologies/intel-realsense-technology.html](url)
this site lead me to
[https://github.com/IntelRealSense/librealsense/tree/master/wrappers/opencv](url)
i follow the description down below, and find out an error which i can't solved.
↓ after clicking configure and this occurred.
[https://imgur.com/a/eJP3AhC](url)
↓error description
[https://imgur.com/a/d9fifsB](url)
honestly, i had no idea what happened to my CMake, and what i done so far seem to be unrelated to my current project.
i am confused.
can someone point out the problem in my cmake, and how can i do to solve. 





##### Steps to reproduce

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->

##### Issue submission checklist

 - [ ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [ ] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [ ] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-03-25 04:49:27,question,  OpenCV: Include directory doesn't exist:   '/usr/local/stow/absl/include/opencv4'.  OpenCV installation may be broken.,"System information (version)
    OpenCV 4.5.5
    Operating System  Linux Ubuntu 20.04 

cmake&make&install:
cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local  -D OPENCV_EXTRA_MODULES_PATH=/home/algo/software/opencv/opencv_contrib_4.5.5/modules -D WITH_EIGEN=ON -D WITH_QT=ON -D OPENCV_ENABLE_NONFREE=ON -D INSTALL_C_EXAMPLES=OFF -D INSTALL_PYTHON_EXAMPLES=OFF -D PYTHON3_PACKAGES_PATH=/usr/lib/python3/dist-packages -D OPENCV_GENERATE_PKGCONFIG=ON -D BUILD_EXAMPLES=OFF ..
make -j8
sudo make install

algo@algo:~/software/opencv/opencv_4.5.5/samples/cpp/example_cmake/build$ pkg-config --modversion opencv4
4.5.5
algo@algo:~/software/opencv/opencv_4.5.5/samples/cpp/example_cmake/build$ pkg-config --libs opencv4
-L/usr/local/lib -lopencv_gapi -lopencv_stitching -lopencv_alphamat -lopencv_aruco -lopencv_barcode -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_cvv -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_sfm -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_videostab -lopencv_videoio -lopencv_viz -lopencv_wechat_qrcode -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core

CMakelist.txt:
cmake_minimum_required(VERSION 3.5)
project(opencv_helloworld LANGUAGES CXX)
FIND_PACKAGE(OpenCV REQUIRED)
INCLUDE_DIRECTORIES(${OpenCV_INCLUDE_DIRS})

find_package( OpenCV REQUIRED )
add_executable(opencv_helloworld
  main.cpp
)
target_link_libraries(opencv_helloworld ${OpenCV_LIBS})

ERROR:
CMake Warning at /usr/local/lib/cmake/opencv4/OpenCVConfig.cmake:116 (message):
  OpenCV: Include directory doesn't exist:
  '/usr/local/stow/absl/include/opencv4'.  OpenCV installation may be broken.
  Skip...
Call Stack (most recent call first):
  CMakeLists.txt:5 (FIND_PACKAGE)

"
opencv/opencv,2022-03-23 16:24:20,question,readNetFromTensorflow don't work,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => 4.5.5.64
- Operating System / Platform => Windows 11 64 Bit
- Compiler => Python 3.10.2

##### Detailed description

When I want to load my ``saved_model.pb`` which is on the same directory with ``cv.dnn.readNetFromTensorflow('saved_model.pb')``, I got this error :
``cv2.error: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\tensorflow\\tf_io.cpp:42: error: (-2:Unspecified error) FAILED: ReadProtoFromBinaryFile(param_file, param). Failed to parse GraphDef file: saved_model.pb in function 'cv::dnn::ReadTFNetParamsFromBinaryFileOrDie'``

I saw everyone use already trained model and nobody train its own model for use it in OpenCV. I don't see anything related with my error on internet or to load a custom model in OpenCV. :/

##### Steps to reproduce

```model = tf.keras.models.Sequential([
  tf.keras.layers.Rescaling(1./255),
  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(2)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=10
)

model.save('./')
model = cv.dnn.readNetFromTensorflow('saved_model.pb')
``` 

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->

##### Issue submission checklist

 - [x] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [x] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [x] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-03-17 14:12:53,question,confused about the principle of cvFindExtrinsicCameraParams2() interface ?,"could tell me about the principle of following code in cvFindExtrinsicCameraParams2() interface ? any theory or paper ?
```
// initialize extrinsic parameters
if( W[2]/W[1] < 1e-3)
{
    // a planar structure case (all M's lie in the same plane)
    double tt[3], h[9], h1_norm, h2_norm;
    CvMat* R_transform = &matV;
    CvMat T_transform = cvMat( 3, 1, CV_64F, tt );
    CvMat matH = cvMat( 3, 3, CV_64F, h );
    CvMat _h1, _h2, _h3;

    if( V[2]*V[2] + V[5]*V[5] < 1e-10 )
        cvSetIdentity( R_transform );

    if( cvDet(R_transform) < 0 )
        cvScale( R_transform, R_transform, -1 );

    cvGEMM( R_transform, &_Mc, -1, 0, 0, &T_transform, CV_GEMM_B_T );

    for( i = 0; i < count; i++ )
    {
        const double* Rp = R_transform->data.db;
        const double* Tp = T_transform.data.db;
        const double* src = matM->data.db + i*3;
        double* dst = _Mxy->data.db + i*2;

        dst[0] = Rp[0]*src[0] + Rp[1]*src[1] + Rp[2]*src[2] + Tp[0];
        dst[1] = Rp[3]*src[0] + Rp[4]*src[1] + Rp[5]*src[2] + Tp[1];
    }

    cvFindHomography( _Mxy, _mn, &matH );

    if( cvCheckArr(&matH, CV_CHECK_QUIET) )
    {
        cvGetCol( &matH, &_h1, 0 );
        _h2 = _h1; _h2.data.db++;
        _h3 = _h2; _h3.data.db++;
        h1_norm = std::sqrt(h[0]*h[0] + h[3]*h[3] + h[6]*h[6]);
        h2_norm = std::sqrt(h[1]*h[1] + h[4]*h[4] + h[7]*h[7]);

        cvScale( &_h1, &_h1, 1./MAX(h1_norm, DBL_EPSILON) );
        cvScale( &_h2, &_h2, 1./MAX(h2_norm, DBL_EPSILON) );
        cvScale( &_h3, &_t, 2./MAX(h1_norm + h2_norm, DBL_EPSILON));
        cvCrossProduct( &_h1, &_h2, &_h3 );

        cvRodrigues2( &matH, &_r );
        cvRodrigues2( &_r, &matH );
        cvMatMulAdd( &matH, &T_transform, &_t, &_t );
        cvMatMul( &matH, R_transform, &matR );
    }
    else
    {
        cvSetIdentity( &matR );
        cvZero( &_t );
    }

    cvRodrigues2( &matR, &_r );
}
```
"
opencv/opencv,2022-03-16 03:16:34,question,cv::cudacodec::VideoReader throw_no_cuda,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

#### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => 4.5.0
- Operating System / Platform => Windows 10 64Bit
- Compiler => Visual Studio 2019
- CUDA => 11.2
- GPU => GTX 3070

#### Detailed description

<!-- your description -->

this is my source code：

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->
```.cpp
#include <iostream>
#include ""opencv2/opencv.hpp""
#include ""opencv2/cudacodec.hpp""

using namespace std;
using namespace cv;

int main()
{
    const string videoName = ""D:/renzhenfeng/vframe_segment_pose_server/pre_data.mp4"";
    cv::cuda::GpuMat d_frame;
    cv::Ptr<cv::cudacodec::VideoReader> d_reader = cv::cudacodec::createVideoReader(videoName);
    while (true)
    {
        if (!d_reader->nextFrame(d_frame))
            break;
        cv::waitKey(1);
    }
    return 0;
}
```

when I run the ""cv::Ptr<cv::cudacodec::VideoReader> d_reader = cv::cudacodec::createVideoReader(videoName);"", 
an error occurred in the program：

```
OpenCV: terminate handler is called! The last OpenCV error is:
OpenCV(4.5.0) Error: The function/feature is not implemented (The called functionality is disabled for current build or platform) in throw_no_cuda, file D:\\opencv\\opencv\\sources\\modules\\core\\include\\opencv2/core/private.cuda.hpp, line 112
```

The information of cmake is as follows：
```
Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.19042.
Detected processor: AMD64
libjpeg-turbo: VERSION = 2.0.5, BUILD = opencv-4.5.0-libjpeg-turbo
Could NOT find OpenJPEG (minimal suitable version: 2.0, recommended version >= 2.3.1). OpenJPEG will be built from sources
OpenJPEG: VERSION = 2.3.1, BUILD = opencv-4.5.0-openjp2-2.3.1
OpenJPEG libraries will be built from sources: libopenjp2 (version ""2.3.1"")
found Intel IPP (ICV version): 2020.0.0 [2020.0.0 Gold]
at: D:/opencv/opencv/build_cuda/3rdparty/ippicv/ippicv_win/icv
found Intel IPP Integration Wrappers sources: 2020.0.0
at: D:/opencv/opencv/build_cuda/3rdparty/ippicv/ippicv_win/iw
CUDA detected: 11.2
CUDA: Using CUDA_ARCH_BIN=8.6
CUDA NVCC target flags: -gencode;arch=compute_86,code=sm_86;-D_FORCE_INLINES
CUDA: MSVS generator is detected. Disabling CMake re-run checks (CMAKE_SUPPRESS_REGENERATION=ON). You need to run CMake manually if updates are required.
Could not find OpenBLAS include. Turning OpenBLAS_FOUND off
Could not find OpenBLAS lib. Turning OpenBLAS_FOUND off
Could NOT find BLAS (missing: BLAS_LIBRARIES) 
Could NOT find LAPACK (missing: LAPACK_LIBRARIES) 
    Reason given by package: LAPACK could not be found because dependency BLAS could not be found.

VTK is not found. Please set -DVTK_DIR in CMake to VTK build directory, or to VTK install subdirectory with VTKConfig.cmake file
OpenCV Python: during development append to PYTHONPATH: D:/opencv/opencv/build_cuda/python_loader
Module opencv_alphamat disabled because the following dependencies are not found: Eigen
Caffe:   NO
Protobuf:   NO
Glog:   NO
freetype2:   NO
harfbuzz:    NO
Julia not found. Not compiling Julia Bindings. 
Module opencv_ovis disabled because OGRE3D was not found
No preference for use of exported gflags CMake configuration set, and no hints for include/library directories provided. Defaulting to preferring an installed/exported gflags CMake configuration if available.
Failed to find installed gflags CMake configuration, searching for gflags build directories exported with CMake.
Failed to find gflags - Failed to find an installed/exported CMake configuration for gflags, will perform search for installed gflags components.
Failed to find gflags - Could not find gflags include directory, set GFLAGS_INCLUDE_DIR to directory containing gflags/gflags.h
Failed to find glog - Could not find glog include directory, set GLOG_INCLUDE_DIR to directory containing glog/logging.h
Module opencv_sfm disabled because the following dependencies are not found: Eigen Glog/Gflags
Tesseract:   NO
Processing WORLD modules...
    module opencv_cudev...
    module opencv_core...
Allocator metrics storage type: 'long long'
    module opencv_cudaarithm...
    module opencv_flann...
    module opencv_imgproc...
    module opencv_intensity_transform...
    module opencv_ml...
    module opencv_phase_unwrapping...
    module opencv_plot...
    module opencv_quality...
    module opencv_reg...
    module opencv_surface_matching...
    module opencv_cudafilters...
    module opencv_cudaimgproc...
    module opencv_cudawarping...
    module opencv_dnn...
Registering hook 'INIT_MODULE_SOURCES_opencv_dnn': D:/opencv/opencv/sources/modules/dnn/cmake/hooks/INIT_MODULE_SOURCES_opencv_dnn.cmake
    module opencv_dnn_superres...
    module opencv_features2d...
    module opencv_fuzzy...
    module opencv_hfs...
    module opencv_imgcodecs...
    module opencv_line_descriptor...
    module opencv_photo...
    module opencv_saliency...
    module opencv_text...
    module opencv_videoio...
    module opencv_xphoto...
    module opencv_calib3d...
    module opencv_cudacodec...
    module opencv_cudafeatures2d...
    module opencv_cudastereo...
    module opencv_datasets...
    module opencv_highgui...
    module opencv_mcc...
    module opencv_objdetect...
    module opencv_rapid...
    module opencv_rgbd...
    module opencv_shape...
    module opencv_structured_light...
    module opencv_video...
    module opencv_xfeatures2d...
    module opencv_ximgproc...
    module opencv_xobjdetect...
    module opencv_aruco...
    module opencv_bgsegm...
    module opencv_bioinspired...
    module opencv_ccalib...
    module opencv_cudabgsegm...
    module opencv_cudalegacy...
    module opencv_cudaobjdetect...
    module opencv_dnn_objdetect...
    module opencv_dpm...
    module opencv_face...
    module opencv_gapi...
    module opencv_optflow...
    module opencv_stitching...
    module opencv_tracking...
    module opencv_cudaoptflow...
    module opencv_stereo...
    module opencv_superres...
    module opencv_videostab...
Processing WORLD modules... DONE
CMake Warning at cmake/OpenCVGenSetupVars.cmake:54 (message):
  CONFIGURATION IS NOT SUPPORTED: validate setupvars script in install
  directory
Call Stack (most recent call first):
  CMakeLists.txt:976 (include)



General configuration for OpenCV 4.5.0 =====================================
  Version control:               unknown

  Extra modules:
    Location (extra):            D:/opencv/opencv_contrib-4.5.0/opencv_contrib-4.5.0/modules
    Version control (extra):     unknown

  Platform:
    Timestamp:                   2022-03-04T08:03:33Z
    Host:                        Windows 10.0.19042 AMD64
    CMake:                       3.19.3
    CMake generator:             Visual Studio 16 2019
    CMake build tool:            C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/MSBuild/Current/Bin/MSBuild.exe
    MSVC:                        1929

  CPU/HW features:
    Baseline:                    SSE SSE2 SSE3
      requested:                 SSE3
    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX
      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
      SSE4_1 (17 files):         + SSSE3 SSE4_1
      SSE4_2 (2 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
      FP16 (1 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
      AVX (5 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX
      AVX2 (31 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
      AVX512_SKX (7 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX

  C/C++:
    Built as dynamic libs?:      YES
    C++ standard:                11
    C++ Compiler:                C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.29.30037/bin/Hostx64/x64/cl.exe  (ver 19.29.30038.1)
    C++ flags (Release):         /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:fast     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /MP  /MD /O2 /Ob2 /DNDEBUG 
    C++ flags (Debug):           /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:fast     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /MP  /MDd /Zi /Ob0 /Od /RTC1 
    C Compiler:                  C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.29.30037/bin/Hostx64/x64/cl.exe
    C flags (Release):           /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:fast     /MP   /MD /O2 /Ob2 /DNDEBUG 
    C flags (Debug):             /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:fast     /MP /MDd /Zi /Ob0 /Od /RTC1 
    Linker flags (Release):      /machine:x64  /INCREMENTAL:NO 
    Linker flags (Debug):        /machine:x64  /debug /INCREMENTAL 
    ccache:                      NO
    Precompiled headers:         NO
    Extra dependencies:          opengl32 glu32 cudart_static.lib nppc.lib nppial.lib nppicc.lib nppidei.lib nppif.lib nppig.lib nppim.lib nppist.lib nppisu.lib nppitc.lib npps.lib cublas.lib cudnn.lib cufft.lib -LIBPATH:C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/lib/x64
    3rdparty dependencies:

  OpenCV modules:
    To be built:                 aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab world xfeatures2d ximgproc xobjdetect xphoto
    Disabled:                    python3 python_bindings_generator python_tests
    Disabled by dependency:      -
    Unavailable:                 alphamat cnn_3dobj cvv freetype hdf java js julia matlab ovis python2 python2 sfm viz
    Applications:                tests perf_tests apps
    Documentation:               NO
    Non-free algorithms:         YES

  Windows RT support:            NO

  GUI: 
    Win32 UI:                    YES
    OpenGL support:              YES (opengl32 glu32)
    VTK support:                 NO

  Media I/O: 
    ZLib:                        build (ver 1.2.11)
    JPEG:                        build-libjpeg-turbo (ver 2.0.5-62)
    WEBP:                        build (ver encoder: 0x020f)
    PNG:                         build (ver 1.6.37)
    TIFF:                        build (ver 42 - 4.0.10)
    JPEG 2000:                   build (ver 2.3.1)
    OpenEXR:                     build (ver 2.3.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:
    DC1394:                      NO
    FFMPEG:                      YES (prebuilt binaries)
      avcodec:                   YES (58.91.100)
      avformat:                  YES (58.45.100)
      avutil:                    YES (56.51.100)
      swscale:                   YES (5.7.100)
      avresample:                YES (4.0.0)
    GStreamer:                   NO
    DirectShow:                  YES
    Media Foundation:            YES
      DXVA:                      YES

  Parallel framework:            Concurrency

  Trace:                         YES (with Intel ITT)

  Other third-party libraries:
    Intel IPP:                   2020.0.0 Gold [2020.0.0]
           at:                   D:/opencv/opencv/build_cuda/3rdparty/ippicv/ippicv_win/icv
    Intel IPP IW:                sources (2020.0.0)
              at:                D:/opencv/opencv/build_cuda/3rdparty/ippicv/ippicv_win/iw
    Lapack:                      NO
    Eigen:                       NO
    Custom HAL:                  NO
    Protobuf:                    build (3.5.1)

  NVIDIA CUDA:                   YES (ver 11.2, CUFFT CUBLAS NVCUVID FAST_MATH)
    NVIDIA GPU arch:             86
    NVIDIA PTX archs:

  cuDNN:                         YES (ver 8.2.1)

  OpenCL:                        YES (NVD3D11)
    Include path:                D:/opencv/opencv/sources/3rdparty/include/opencl/1.2
    Link libraries:              Dynamic load

  Python (for build):            D:/python39/python.exe

  Java:                          
    ant:                         NO
    JNI:                         D:/java/include D:/java/include/win32 D:/java/include
    Java wrappers:               NO
    Java tests:                  NO

  Install to:                    D:/opencv/opencv/build_cuda/install
-----------------------------------------------------------------

Configuring done
Generating done
```

Why it does not run successfully with  “NVCUVID” displayed？I am very confused, please help me？"
opencv/opencv,2022-03-15 05:52:15,question,"undefined reference to `cv::Mat::Mat(int, int, int, cv::Scalar_<double> const&)'","When I ran this code, It went wrong.

##### Detailed description
cv::Mat M(2,2,CV_8UC3,cv::Scalar(0,0,255));


##### System information (version)
<!-- 
opencv 4.5.3(code in question pulled from [here](https://github.com/opencv/opencv/tree/4.x/doc/pattern_tools)
ubuntu 20.04
-->

- OpenCV => :4.5.3:
- Ubuntu => 20.04


It reported:

undefined reference to `cv::Mat::Mat(int, int, int, cv::Scalar_<double> const&)'
undefined reference to `cv::Formatter::get(cv::Formatter::FormatType)'


Issue submission checklist

[ X] I report the issue, it's not a question
[X ] I checked the problem with documentation, FAQ, open issues,
forum.opencv.org, Stack Overflow, etc and have not found any solution
[ X] I updated to the latest OpenCV version and the issue is still there"
opencv/opencv,2022-03-07 13:46:03,question,Inconsistant conversion from BGRA to BGR on png image,"

##### System information (version)
- OpenCV => 4.5.5
- Operating System / Platform => Ubuntu 20.04
- Compiler => g++

##### Detailed description

Usually in opencv, the conversion from  BGRA to BGR via `IMREAD_COLOR` or `cvtColor` set the transparent background as black.
However, for this image it seem to generate an inconsistant background.

<!-- your description -->

##### Steps to reproduce

```python3
import cv2

img = cv2.imread(path, cv2.IMREAD_COLOR)
cv2.imshow('window', img)
cv2.waitKey(0)
```

Original image: ![img_rgba](https://user-images.githubusercontent.com/8860364/157045444-2b4cdb11-07b5-4534-a6c6-fa8371ac181b.png)
Output image:
![out_rgba](https://user-images.githubusercontent.com/8860364/157045620-a026af15-564f-4789-a4c9-749d2b7ec11d.png)


##### Issue submission checklist

 - [X] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [X] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [X] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [X] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->

"
opencv/opencv,2022-03-04 10:02:56,question,Unable to launch app with brew version OpenCV 4.5.5 linked,"##### System information (version)
- OpenCV => 4.5.5
- Operating System / Platform => macOS 11.6.4 (Apple M1)
- Compiler => Apple clang version 13.0.0 (c++)

##### Detailed description

When I write CMakeFiles.txt to link OpenCV 4.5.5 installed by brew, the built program will not be able to run. the OS kills my program. I think errors of loading `.dylib`s occur when the application is launched.

Reproduction is very easy. Here is a simple code. Am I doing something wrong?

##### Steps to reproduce

1. C++ source code `main.cpp` (anything is OK)

    ```main.cpp
    int main(int argc, char* argv[])
    {
    }
    ```

2. CMakeLists.txt
  Just link this code (above) with the OpenCV library.

    ```cmake
    CMAKE_MINIMUM_REQUIRED(VERSION 3.21.1)
    set(CMAKE_VERBOSE_MAKEFILE 1) # for verbose mode. run like ""VERBOSE=1 make -j8 ...""
    PROJECT(CVLink)
    ADD_EXECUTABLE(cvLink)
    TARGET_SOURCES(cvLink PRIVATE ./main.cpp)

    FIND_PACKAGE(OpenCV REQUIRED)
    TARGET_LINK_LIBRARIES(cvLink
            ${OpenCV_LIBS}
    )
    ```

3. Build
  Build normally in the manner of cmake  

    ```zsh
    $ brew install opencv # if not yet
    $ mkdir build; cd build; cmake ..; make 
    ```
4. Run, but fails.
  
    ```zsh
    $ ./cvLink
    zsh: killed     ./cvLink
    ```

5. I would like to confirm my OpenCV version.

    ```zsh
    $ opencv_version 
    4.5.5
    $ which opencv_version
    /opt/homebrew/bin/opencv_version
    ```
I think it is an issue with the brew version of OpenCV. Here is the build log of my reproduction code.


```
[mymac: 18:42:09: build]$ make
/opt/homebrew/Cellar/cmake/3.22.2/bin/cmake -S/Users/myname/tmp/CVLink -B/Users/myname/tmp/CVLink/build --check-build-system CMakeFiles/Makefile.cmake 0
/opt/homebrew/Cellar/cmake/3.22.2/bin/cmake -E cmake_progress_start /Users/myname/tmp/CVLink/build/CMakeFiles /Users/myname/tmp/CVLink/build//CMakeFiles/progress.marks
/Applications/Xcode.app/Contents/Developer/usr/bin/make  -f CMakeFiles/Makefile2 all
/Applications/Xcode.app/Contents/Developer/usr/bin/make  -f CMakeFiles/cvLink.dir/build.make CMakeFiles/cvLink.dir/depend
cd /Users/myname/tmp/CVLink/build && /opt/homebrew/Cellar/cmake/3.22.2/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/myname/tmp/CVLink /Users/myname/tmp/CVLink /Users/myname/tmp/CVLink/build /Users/myname/tmp/CVLink/build /Users/myname/tmp/CVLink/build/CMakeFiles/cvLink.dir/DependInfo.cmake --color=
/Applications/Xcode.app/Contents/Developer/usr/bin/make  -f CMakeFiles/cvLink.dir/build.make CMakeFiles/cvLink.dir/build
[ 50%] Building CXX object CMakeFiles/cvLink.dir/main.cpp.o
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++  -isystem /opt/homebrew/Cellar/opencv/4.5.5/include/opencv4 -arch arm64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX12.1.sdk -mmacosx-version-min=11.6 -std=gnu++11 -MD -MT CMakeFiles/cvLink.dir/main.cpp.o -MF CMakeFiles/cvLink.dir/main.cpp.o.d -o CMakeFiles/cvLink.dir/main.cpp.o -c /Users/myname/tmp/CVLink/main.cpp
[100%] Linking CXX executable cvLink
/opt/homebrew/Cellar/cmake/3.22.2/bin/cmake -E cmake_link_script CMakeFiles/cvLink.dir/link.txt --verbose=1
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++  -arch arm64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX12.1.sdk -mmacosx-version-min=11.6 -Wl,-search_paths_first -Wl,-headerpad_max_install_names -L/opt/homebrew/opt/libffi/lib -L/opt/homebrew/opt/openblas/lib -L/opt/homebrew/opt/python@3.9/lib -L/opt/homebrew/opt/libffi/lib -L/opt/homebrew/opt/openblas/lib -L/opt/homebrew/opt/python@3.9/lib  -L/opt/homebrew/lib CMakeFiles/cvLink.dir/main.cpp.o -o cvLink  /opt/homebrew/lib/libopencv_gapi.4.5.5.dylib /opt/homebrew/lib/libopencv_stitching.4.5.5.dylib /opt/homebrew/lib/libopencv_alphamat.4.5.5.dylib /opt/homebrew/lib/libopencv_aruco.4.5.5.dylib /opt/homebrew/lib/libopencv_barcode.4.5.5.dylib /opt/homebrew/lib/libopencv_bgsegm.4.5.5.dylib /opt/homebrew/lib/libopencv_bioinspired.4.5.5.dylib /opt/homebrew/lib/libopencv_ccalib.4.5.5.dylib /opt/homebrew/lib/libopencv_dnn_objdetect.4.5.5.dylib /opt/homebrew/lib/libopencv_dnn_superres.4.5.5.dylib /opt/homebrew/lib/libopencv_dpm.4.5.5.dylib /opt/homebrew/lib/libopencv_face.4.5.5.dylib /opt/homebrew/lib/libopencv_freetype.4.5.5.dylib /opt/homebrew/lib/libopencv_fuzzy.4.5.5.dylib /opt/homebrew/lib/libopencv_hfs.4.5.5.dylib /opt/homebrew/lib/libopencv_img_hash.4.5.5.dylib /opt/homebrew/lib/libopencv_intensity_transform.4.5.5.dylib /opt/homebrew/lib/libopencv_line_descriptor.4.5.5.dylib /opt/homebrew/lib/libopencv_mcc.4.5.5.dylib /opt/homebrew/lib/libopencv_quality.4.5.5.dylib /opt/homebrew/lib/libopencv_rapid.4.5.5.dylib /opt/homebrew/lib/libopencv_reg.4.5.5.dylib /opt/homebrew/lib/libopencv_rgbd.4.5.5.dylib /opt/homebrew/lib/libopencv_saliency.4.5.5.dylib /opt/homebrew/lib/libopencv_sfm.4.5.5.dylib /opt/homebrew/lib/libopencv_stereo.4.5.5.dylib /opt/homebrew/lib/libopencv_structured_light.4.5.5.dylib /opt/homebrew/lib/libopencv_superres.4.5.5.dylib /opt/homebrew/lib/libopencv_surface_matching.4.5.5.dylib /opt/homebrew/lib/libopencv_tracking.4.5.5.dylib /opt/homebrew/lib/libopencv_videostab.4.5.5.dylib /opt/homebrew/lib/libopencv_viz.4.5.5.dylib /opt/homebrew/lib/libopencv_wechat_qrcode.4.5.5.dylib /opt/homebrew/lib/libopencv_xfeatures2d.4.5.5.dylib /opt/homebrew/lib/libopencv_xobjdetect.4.5.5.dylib /opt/homebrew/lib/libopencv_xphoto.4.5.5.dylib /opt/homebrew/lib/libopencv_shape.4.5.5.dylib /opt/homebrew/lib/libopencv_highgui.4.5.5.dylib /opt/homebrew/lib/libopencv_datasets.4.5.5.dylib /opt/homebrew/lib/libopencv_plot.4.5.5.dylib /opt/homebrew/lib/libopencv_text.4.5.5.dylib /opt/homebrew/lib/libopencv_ml.4.5.5.dylib /opt/homebrew/lib/libopencv_phase_unwrapping.4.5.5.dylib /opt/homebrew/lib/libopencv_optflow.4.5.5.dylib /opt/homebrew/lib/libopencv_ximgproc.4.5.5.dylib /opt/homebrew/lib/libopencv_video.4.5.5.dylib /opt/homebrew/lib/libopencv_videoio.4.5.5.dylib /opt/homebrew/lib/libopencv_imgcodecs.4.5.5.dylib /opt/homebrew/lib/libopencv_objdetect.4.5.5.dylib /opt/homebrew/lib/libopencv_calib3d.4.5.5.dylib /opt/homebrew/lib/libopencv_dnn.4.5.5.dylib /opt/homebrew/lib/libopencv_features2d.4.5.5.dylib /opt/homebrew/lib/libopencv_flann.4.5.5.dylib /opt/homebrew/lib/libopencv_photo.4.5.5.dylib /opt/homebrew/lib/libopencv_imgproc.4.5.5.dylib /opt/homebrew/lib/libopencv_core.4.5.5.dylib 
[100%] Built target cvLink
/opt/homebrew/Cellar/cmake/3.22.2/bin/cmake -E cmake_progress_start /Users/myname/tmp/CVLink/build/CMakeFiles 0
[mymac: 18:42:10: build]$ 
```

Because there were too many .dylibs included in the build, I tried to link and launch only one library to isolate the problem for all of the libraries. I found that out of 56 libraries, the following 10 libraries failed to launch if I linked even one of each of them. The other 46 can be linked all at once without any problem. I don't know but, is there any common characteristics of these?

```
bad /opt/homebrew/lib/libopencv_bioinspired.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_ccalib.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_dnn_objdetect.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_dpm.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_highgui.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_stereo.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_superres.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_tracking.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_videoio.4.5.5.dylib
bad /opt/homebrew/lib/libopencv_videostab.4.5.5.dylib
```

##### Issue submission checklist
 - [x] I report the issue, it's not a question
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
 - [x] I updated to the latest OpenCV version and the issue is still there
 - [x] There is reproducer code and related data files: videos, images, onnx, etc
"
opencv/opencv,2022-03-03 14:57:44,question,CMake detects a non-existent external dependency,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.5.5
- Operating System / Platform => Ubuntu 20.08
- Compiler => gcc 9.3.0
- CMake =>  3.16.3
-->

- OpenCV => 4.5.5
- Operating System / Platform => Ubuntu 20.04
- Compiler => gcc 9.3.0
- CMake =>  3.16.3
- CUDA = 11.6
- CuDNN = 8.2.1
- Nvidia Driver = 510.47.03
- 

##### Detailed description

cmake detects non-existent library ""lib"". I am trying to compile OpenCV with CUDA support. 

When I run cmake, it detects the following external dependencies:
--     Extra dependencies:          m pthread cudart_static dl rt nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas lib cufft -L/usr/local/cuda-11.6/lib64 -L/usr/lib/x86_64-linux-gnu -L/home/boyangli/.conda/envs/denseflow

The problem is that lib is not a valid library. This leads to failures during linking. 


##### Steps to reproduce
I used the following CMake command. 

    ```cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/home/boyangli/app -D WITH_CUDA=ON -D ENABLE_FAST_MATH=1 -D CUDA_FAST_MATH=1 -D WITH_CUBLAS=1 -D INSTALL_PYTHON_EXAMPLES=ON -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules -D PYTHON_EXECUTABLE=$python_exec -D PYTHON_DEFAULT_EXECUTABLE=$default_exec -D PYTHON_INCLUDE_DIRS=$include_dir -D PYTHON_LIBRARY=$library -D BUILD_EXAMPLES=ON -DBUILD_opencv_dpm=OFF \\
   -DBUILD_opencv_face=OFF \\
   -DBUILD_opencv_dnn_superres=OFF \\
   -DBUILD_opencv_dnn_objdetect=OFF \\
   -DBUILD_opencv_bgsegm=OFF \\
   -DBUILD_opencv_cvv=OFF \\
   -DBUILD_opencv_ccalib=OFF \\
   -DBUILD_opencv_bioinspired=OFF \\
   -DBUILD_opencv_dnn_modern=OFF \\
   -DBUILD_opencv_dnns_easily_fooled=OFF \\
   -DBUILD_JAVA=OFF \\
   -DBUILD_opencv_python2=OFF \\
   -DBUILD_NEW_PYTHON_SUPPORT=ON \\
   -DBUILD_opencv_python3=ON \\
   -DHAVE_opencv_python3=ON \\
   -DWITH_OPENGL=OFF \\
   -DWITH_VTK=OFF \\
   -DFORCE_VTK=OFF \\
   -DWITH_TBB=ON \\
   -DWITH_GDAL=ON \\
   -DCUDA_FAST_MATH=ON \\
   -DWITH_CUBLAS=ON \\
   -DWITH_MKL=ON \\
   -DMKL_USE_MULTITHREAD=ON \\
   -DOPENCV_ENABLE_NONFREE=ON \\
   -DWITH_CUDA=ON \\
   -DNVCC_FLAGS_EXTRA=""--default-stream per-thread"" \\
   -DWITH_NVCUVID=OFF \\
   -DBUILD_opencv_cudacodec=OFF \\
   -DMKL_WITH_TBB=ON \\
   -DWITH_FFMPEG=ON \\
   -DMKL_WITH_OPENMP=ON \\
   -DWITH_XINE=ON \\
   -DENABLE_PRECOMPILED_HEADERS=OFF \\
   -DCMAKE_INSTALL_PREFIX=""$ROOTDIR"" \\
   -DOPENCV_GENERATE_PKGCONFIG=ON \\
   -DOPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \\
   -DCUDNN_INCLUDE_DIR='/home/boyangli/.conda/envs/denseflow/include' \\
   -DCUDNN_LIBRARY='/home/boyangli/.conda/envs/denseflow/lib' \\
   -DC_INCLUDE_PATH='/home/boyangli/.conda/envs/denseflow/include:/usr/local/include:/usr/include/x86_64-linux-gnu' \\
   -DINCLUDE_PATH='/home/boyangli/.conda/envs/denseflow/include:/usr/local/include:/usr/include/x86_64-linux-gnu' \\
   -DC_PATH='/home/boyangli/.conda/envs/denseflow/include:/usr/local/include:/usr/include/x86_64-linux-gnu' \\
   -DLD_LIBARY_PATH='/home/boyangli/.conda/envs/denseflow/lib:/usr/lib/x86_64-linux-gnu' \\
   -DCMAKE_VERBOSE_MAKEFILE=ON ..
    ```

##### Issue submission checklist

 - [x ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [x ] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [ x] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [x ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-02-23 20:14:36,question,undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)',"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->


##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => :4.5.5:
- Operating System / Platform => :Ubuntu 20.04.3 64 bit:
- Compiler => :gcc/g++ 10.3.1:


##### Detailed description

Just use **cmake** to build current **opencv 4.x** with **opencv_contrib 4.x** .

```console
$ git show

commit 92312fbc0cbd8d110c4eeb480f1cfc6de224eeea (HEAD -> 4.x, upstream/master, upstream/HEAD, upstream/4.x, origin/4.x)
Merge: 2efcaa9e8e 33f219dfe6
Author: Alexander Alekhin <alexander.a.alekhin@gmail.com>
Date:   Tue Feb 22 19:23:32 2022 +0000

    Merge pull request #21613 from YusukeKameda:patch-1
```

##### Steps to reproduce

```configure
- BUILD_PROTOBUF                   OFF
- PROTOBUF_UPDATE_FILES            ON
- BUILD_opencv_datasets            ON
- BUILD_opencv_dnn                 ON
- BUILD_opencv_dnn_objdetect       ON
- BUILD_opencv_dnn_superres        ON
- BUILD_opencv_dpm                 ON
- OPENCV_DNN_CUDA                  ON
- OPENCV_DNN_OPENCL                OFF
- OPENCV_DNN_OPENVINO              OFF
- OPENCV_DNN_PERF_CAFFE            OFF
- OPENCV_DNN_PERF_CLCAFFE          OFF
```


##### Error Messages After **make -j16**

<details>

```console
[ 29%] Linking CXX shared library ../../lib/libopencv_cvv.so
cd ....../opencv/build/modules/cvv && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/opencv_cvv.dir/link.txt --verbose=1
/usr/local/bin/c++ -fPIC    -fsigned-char -ffast-math -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wundef -Winit-self -Wpointer-arith -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fno-omit-frame-pointer -pg -g  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -fopenmp -Wno-shadow -Wno-missing-declarations -O3 -DNDEBUG  -DNDEBUG   -Wl,--as-needed -Wl,--no-undefined -shared -Wl,-soname,libopencv_cvv.so.405 -o ../../lib/libopencv_cvv.so.4.5.5 CMakeFiles/opencv_cvv.dir/opencv_cvv_autogen/mocs_compilation.cpp.o CMakeFiles/opencv_cvv.dir/src/controller/view_controller.cpp.o CMakeFiles/opencv_cvv.dir/src/extension_api/api.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/call_window.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/image_call_tab.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/main_call_window.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/overview_group_subtable.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/overview_panel.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/overview_table.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/overview_table_row.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/rawview_group_subtable.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/rawview_table.cpp.o CMakeFiles/opencv_cvv.dir/src/gui/rawview_table_row.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/call.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/data_controller.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/dmatch.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/filter.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/filter_call.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/final_show.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/init.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/match_call.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/show_image.cpp.o CMakeFiles/opencv_cvv.dir/src/impl/single_image_call.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/accordion.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/collapsable.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/filter/changed_pixels_widget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/filter/channelreorderfilter.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/filter/diffFilterWidget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/filter/grayfilterwidget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/filter/overlayfilterwidget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/filter/sobelfilterwidget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/histogram.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/histogramoptpanel.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/cvvkeypoint.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/cvvmatch.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/cvvpointmatch.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/falsecolorkeypointpen.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/falsecolormatchpen.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/keypointintervallselection.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/keypointmanagement.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/keypointportionselector.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/keypointselectionselector.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/keypointsettingsselector.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/keypointshowsetting.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/keypointvaluechooser.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/matchintervallselection.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/matchmanagement.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/matchportionselector.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/matchscene.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/matchselectionselector.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/matchsettingsselector.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/matchshowsetting.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/rawview_window.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/showinrawviewwidget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/singlecolorkeypointpen.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/singlecolormatchpen.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/matchview/zoomableproxyobject.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/stfl_query_widget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/stfl_query_widget_lineedit.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/synczoomwidget.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/util.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/zoomableimage.cpp.o CMakeFiles/opencv_cvv.dir/src/qtutil/zoomableimageoptpanel.cpp.o CMakeFiles/opencv_cvv.dir/src/stfl/stringutils.cpp.o CMakeFiles/opencv_cvv.dir/src/view/defaultfilterview.cpp.o CMakeFiles/opencv_cvv.dir/src/view/dual_filter_view.cpp.o CMakeFiles/opencv_cvv.dir/src/view/image_view.cpp.o CMakeFiles/opencv_cvv.dir/src/view/linematchview.cpp.o CMakeFiles/opencv_cvv.dir/src/view/pointmatchview.cpp.o CMakeFiles/opencv_cvv.dir/src/view/rawview.cpp.o CMakeFiles/opencv_cvv.dir/src/view/singlefilterview.cpp.o CMakeFiles/opencv_cvv.dir/src/view/translationsmatchview.cpp.o   -L/usr/local/cuda/lib64  -Wl,-rpath,/usr/local/cuda/lib64:....../opencv/build/lib:/opt/Qt/5/lib: ../../lib/libopencv_features2d.so.4.5.5 -ldl -lm -lpthread -lrt -lcudart_static -ldl -lrt -lnppc -lnppial -lnppicc -lnppidei -lnppif -lnppig -lnppim -lnppist -lnppisu -lnppitc -lnpps -lcublas -lcudnn -lcufft -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu /opt/Qt/5/lib/libQt5Widgets.so.5.15.2 -lcudart_static -ldl -lrt -lnppc -lnppial -lnppicc -lnppidei -lnppif -lnppig -lnppim -lnppist -lnppisu -lnppitc -lnpps ../../lib/libopencv_flann.so.4.5.5 ../../lib/libopencv_imgproc.so.4.5.5 ../../lib/libopencv_core.so.4.5.5 ../../lib/libopencv_cudev.so.4.5.5 -lm -lpthread -lcublas -lcudnn -lcufft /opt/Qt/5/lib/libQt5Gui.so.5.15.2 /opt/Qt/5/lib/libQt5Core.so.5.15.2 
make[2]: Leaving directory '....../opencv/build'
[ 29%] Built target example_bioinspired_OpenEXRimages_HDR_Retina_toneMapping
CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o:/usr/local/include/google/protobuf/arena.h:522: more undefined references to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o:/usr/local/include/google/protobuf/parse_context.h:213: more undefined references to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<google::protobuf::internal::InternalMetadata::Container<google::protobuf::UnknownFieldSet> >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-caffe.pb.cc.o: in function `_GLOBAL__sub_I_opencv_caffe.pb.cc':
....../opencv/build/modules/dnn/opencv-caffe.pb.cc:3537: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
make[2]: Leaving directory '....../opencv/build'
/usr/bin/ld: [ 29%] Built target example_bioinspired_retinaDemo
CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o:/usr/local/include/google/protobuf/parse_context.h:213: more undefined references to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/opencv-onnx.pb.cc.o: in function `_GLOBAL__sub_I_opencv_onnx.pb.cc':
....../opencv/build/modules/dnn/opencv-onnx.pb.cc:586: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
Buildfile: ....../opencv/build/modules/java/jar/opencv/build.xml
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void google::protobuf::Arena::OwnDestructor<google::protobuf::internal::WrappedMutex>(google::protobuf::internal::WrappedMutex*)':
/usr/local/include/google/protobuf/arena.h:388: undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void google::protobuf::Arena::OwnDestructor<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*)':
/usr/local/include/google/protobuf/arena.h:388: undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void google::protobuf::Arena::OwnInternal<opencv_tensorflow::NameAttrList_AttrEntry_DoNotUse>(opencv_tensorflow::NameAttrList_AttrEntry_DoNotUse*, std::integral_constant<bool, true>)':
/usr/local/include/google/protobuf/arena.h:654: undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `_GLOBAL__sub_I_attr_value.pb.cc':
....../opencv/build/modules/dnn/attr_value.pb.cc:199: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<google::protobuf::RepeatedPtrField<google::protobuf::Message> >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/attr_value.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `void google::protobuf::Arena::OwnInternal<opencv_tensorflow::FunctionDef_Node_AttrEntry_DoNotUse>(opencv_tensorflow::FunctionDef_Node_AttrEntry_DoNotUse*, std::integral_constant<bool, true>)':
/usr/local/include/google/protobuf/arena.h:654: undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `_GLOBAL__sub_I_function.pb.cc':
....../opencv/build/modules/dnn/function.pb.cc:220: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<google::protobuf::RepeatedPtrField<google::protobuf::Message> >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/function.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
make[2]: Leaving directory '....../opencv/build'
[ 29%] Built target example_line_descriptor_knn_matching
/usr/bin/ld: make[2]: Leaving directory '....../opencv/build'
[ 29%] Built target example_line_descriptor_compute_descriptors
CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `void google::protobuf::Arena::OwnInternal<opencv_tensorflow::NodeDef_AttrEntry_DoNotUse>(opencv_tensorflow::NodeDef_AttrEntry_DoNotUse*, std::integral_constant<bool, true>)':
/usr/local/include/google/protobuf/arena.h:654: undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `_GLOBAL__sub_I_graph.pb.cc':
....../opencv/build/modules/dnn/graph.pb.cc:162: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<google::protobuf::RepeatedPtrField<google::protobuf::Message> >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `void* google::protobuf::Arena::AllocateInternal<std::map<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const>, void*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, google::protobuf::internal::MapAllocator<std::pair<std::reference_wrapper<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const> const, void*> > > >(bool)':
/usr/local/include/google/protobuf/arena.h:538: undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/graph.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: /usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/op_def.pb.cc.o: in function `_GLOBAL__sub_I_op_def.pb.cc':
....../opencv/build/modules/dnn/op_def.pb.cc:241: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor.pb.cc.o: in function `_GLOBAL__sub_I_tensor.pb.cc':
....../opencv/build/modules/dnn/tensor.pb.cc:102: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::internal::VerifyUTF8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, char const*)':
/usr/local/include/google/protobuf/parse_context.h:642: undefined reference to `google::protobuf::internal::VerifyUTF8(google::protobuf::StringPiece, char const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: /usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o:/usr/local/include/google/protobuf/generated_message_util.h:240: more undefined references to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/tensor_shape.pb.cc.o: in function `_GLOBAL__sub_I_tensor_shape.pb.cc':
....../opencv/build/modules/dnn/tensor_shape.pb.cc:110: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/versions.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/versions.pb.cc.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/versions.pb.cc.o: in function `google::protobuf::internal::EpsCopyInputStream::DoneWithCheck(char const**, int)':
/usr/local/include/google/protobuf/parse_context.h:213: undefined reference to `google::protobuf::internal::EpsCopyInputStream::DoneFallback(char const*, int)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/versions.pb.cc.o: in function `google::protobuf::internal::InitSCC(google::protobuf::internal::SCCInfoBase*)':
/usr/local/include/google/protobuf/generated_message_util.h:240: undefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/versions.pb.cc.o: in function `_GLOBAL__sub_I_versions.pb.cc':
....../opencv/build/modules/dnn/versions.pb.cc:80: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
make[2]: Leaving directory '....../opencv/build'
[ 29%] Built target example_line_descriptor_radius_matching

jar:
make[2]: Leaving directory '....../opencv/build'
    [javac] Compiling 280 source files to ....../opencv/build/modules/java/jar/opencv/build/classes
[ 29%] Built target example_line_descriptor_lines_extraction
make[2]: Leaving directory '....../opencv/build'
make[2]: Leaving directory '....../opencv/build'
[ 29%] Built target example_line_descriptor_matching
[ 29%] Built target example_line_descriptor_lsd_lines_extraction
make[2]: Leaving directory '....../opencv/build'
[ 29%] Built target example_saliency_computeSaliency
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/src/tensorflow/tf_graph_simplifier.cpp.o: in function `google::protobuf::Arena::AllocHook(std::type_info const*, unsigned long) const':
/usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: /usr/local/include/google/protobuf/arena.h:522: undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/src/tensorflow/tf_importer.cpp.o:/usr/local/include/google/protobuf/arena.h:522: more undefined references to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const' follow
/usr/bin/ld: CMakeFiles/opencv_dnn.dir/types.pb.cc.o: in function `_GLOBAL__sub_I_types.pb.cc':
....../opencv/build/modules/dnn/types.pb.cc:60: undefined reference to `google::protobuf::internal::AddDescriptors(google::protobuf::internal::DescriptorTable const*)'
cd ....../opencv/build/modules/cvv && /usr/local/bin/cmake -E cmake_symlink_library ../../lib/libopencv_cvv.so.4.5.5 ../../lib/libopencv_cvv.so.405 ../../lib/libopencv_cvv.so
make[2]: Leaving directory '....../opencv/build'
[ 32%] Built target opencv_cvv
make  -f modules/cvv/CMakeFiles/example_cvv_cvv_demo_autogen.dir/build.make modules/cvv/CMakeFiles/example_cvv_cvv_demo_autogen.dir/depend
make[2]: Entering directory '....../opencv/build'
cd ....../opencv/build && /usr/local/bin/cmake -E cmake_depends ""Unix Makefiles"" ....../opencv ....../opencv_contrib/modules/cvv ....../opencv/build ....../opencv/build/modules/cvv ....../opencv/build/modules/cvv/CMakeFiles/example_cvv_cvv_demo_autogen.dir/DependInfo.cmake --color=
make[2]: Leaving directory '....../opencv/build'
make  -f modules/cvv/CMakeFiles/example_cvv_cvv_demo_autogen.dir/build.make modules/cvv/CMakeFiles/example_cvv_cvv_demo_autogen.dir/build
make[2]: Entering directory '....../opencv/build'
```

</details>

Cheers
"
opencv/opencv,2022-02-17 05:09:25,question,Cannot write files in ProRes codecs,"I am attempting to write a video file using opencv in the ProRes 4444 codec. I have tried other codecs, such as XVID, and the code works perfectly, however no ProRes codec of any kind seems to be working.

Relavent code:
//Above code specifies clipName, which increments for each clip created in the loop below
subClip = cv.VideoWriter(clipName, cv.VideoWriter_fourcc(*'apch'), 24, size)
//Adds frames to subClip
f = 0
//clipRange contains new frames every time this code is run
while f < len(clipRange):
   subClip.write(clipRange[f])
    f += 1
print(""Clip Created"")
subClip.release()

When I run this code I get a runtime error for every attempted file-write:
`[prores @ 0x7fb8e4986600] Specified pixel format yuv420p is invalid or not supported
[ERROR:0] global /private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-req-build-xxsyexfp/opencv/modules/videoio/src/cap_ffmpeg_impl.hpp (2774) open Could not open codec prores, error: Unspecified error
[ERROR:0] global /private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-req-build-xxsyexfp/opencv/modules/videoio/src/cap_ffmpeg_impl.hpp (2791) open VIDEOIO/FFMPEG: Failed to initialize VideoWriter`

I'm guessing that, by default, opencv or ffmpeg are using the format yuv420p when trying to write these files.

Upon checking the file path listed ""/private/var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T/pip-req-build-xxsyexfp/opencv/modules/videoio/src/cap_ffmpeg_impl.hpp"" is invalid. In fact, the folder ""/private/var/folders"" has no directory named ""24"", and the file ""cap_ffmpeg_impl.hpp"" does not appear to be anywhere on my computer.

Do I need to download this format? Or update some software? Or possibly change some settings to enable it? Or even update some setting to have ProRes encoded with a different pixel format?

Settings:
- OpenCV 4.5.3
- MacOS 11.5.2 on Intel (not apple silicon)
- Python 3.8.8
- ffmpeg 4.2.2
built with clang version 4.0.1 (tags/RELEASE_401/final)
configuration: --prefix=/Users/zury.cutler/opt/anaconda3 --cc=x86_64-apple-darwin13.4.0-clang --disable-doc --enable-avresample --enable-gmp --enable-hardcoded-tables --enable-libfreetype --enable-libvpx --enable-pthreads --enable-libopus --enable-postproc --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --disable-nonfree --enable-gpl --enable-gnutls --disable-openssl --enable-libopenh264 --enable-libx264
libavutil      56. 31.100 / 56. 31.100
libavcodec     58. 54.100 / 58. 54.100
libavformat    58. 29.100 / 58. 29.100
libavdevice    58.  8.100 / 58.  8.100
libavfilter     7. 57.100 /  7. 57.100
libavresample   4.  0.  0 /  4.  0.  0
libswscale      5.  5.100 /  5.  5.100
libswresample   3.  5.100 /  3.  5.100
libpostproc    55.  5.100 / 55.  5.100
"
opencv/opencv,2022-02-15 10:42:49,question,Opencv error with GPU backend,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue that can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)

- OpenCV => 4.5.5-dev
- Operating System / Platform => Ubuntu 20
- Compiler => GCC

##### Detailed description

I cannot run anymore my cv2.dnn on GPU. 
I tried to run the code in CPU and its workings. I also tested with the older version of OpenCV and is working. I think the new commit merged in February changed the dnn output is an np.array[] and is not compatible with 4.5.5 release version. Could you please give an example of how to use the new output?

##### Steps to reproduce
    ```.python
     //with CUDA enabled
    net = cv2.dnn.readNetFromONNX(model_yolo_v5))
    net.setInput(_image)
    results = net.forward()
    ```
##### Issue submission checklist

 - [ ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [x] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-02-02 14:39:36,question,"Warning: libmediandk.so, needed by ../../lib/arm64-v8a/libopencv_videoio.so, not found (try using -rpath or -rpath-link)","Hi I was trying to cross compile opencv for android. My NDK version is 19 and API Level is 28. The make is crashing stating warning: libmediandk.so, was not found. Any guidance on rectifying the issue will be useful.
![image](https://user-images.githubusercontent.com/30999857/152175139-b8b51355-c72a-4330-ad6d-b7f1bea008ca.png)

I used the instructions here for the same: https://www.sisik.eu/blog/android/ndk/opencv-without-java 

The cmake command I used is: `cmake .. -DCMAKE_TOOLCHAIN_FILE=/home/ubuntu/android/android-ndk-r19c/build/cmake/android.toolchain.cmake -DANDROID_NDK=/home/ubuntu/android/android-ndk-r19c -DANDROID_NATIVE_API_LEVEL=android-28 -DBUILD_JAVA=OFF -DBUILD_ANDROID_EXAMPLES=OFF -DBUILD_ANDROID_PROJECTS=OFF -DANDROID_STL=c++_shared -DBUILD_SHARED_LIBS=ON -DCMAKE_INSTALL_PREFIX:PATH=/home/ubuntu/opencv/android_build/out -DANDROID_ABI=arm64-v8a -DCMAKE_CXX_FLAGS=""-llog""
`
"
opencv/opencv,2022-01-27 01:47:22,question,Unable to Compile GAPI Code returning contours from cv::gapi::findContours,"##### System information (version)
- OpenCV => 4.5.5
- Operating System / Platform => Windows 10 64 Bit
- Compiler => Visual Studio 2017 c++14 & 2022 c++14,17,20

##### Detailed description
I have compiled version 4.5.5 on windows with Visual Studio.
I am unable to compile code dealing with GAPI that calls findContours and returns the contours.
In my example I have a conditional compilation that returns a GMat instead of contours, the code compiles.

Compiler Error from VS (Error List Window)
Error	C2338	Type not found	testGAPI	opencv\\include\\opencv2\\gapi\\util\\variant.hpp	37	

'''

Compiler Warning from VS (Output Window)
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(37,56): error C2338: Type not found
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(31): message : see reference to class template instantiation 'cv::util::detail::type_list_index_helper<5,Target,cv::detail::GOpaqueU>' being compiled
1>        with
1>        [
1>            Target=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(31): message : see reference to class template instantiation 'cv::util::detail::type_list_index_helper<4,Target,cv::detail::GArrayU,cv::detail::GOpaqueU>' being compiled
1>        with
1>        [
1>            Target=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(31): message : see reference to class template instantiation 'cv::util::detail::type_list_index_helper<3,Target,cv::GScalar,cv::detail::GArrayU,cv::detail::GOpaqueU>' being compiled
1>        with
1>        [
1>            Target=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(31): message : see reference to class template instantiation 'cv::util::detail::type_list_index_helper<2,Target,cv::GFrame,cv::GScalar,cv::detail::GArrayU,cv::detail::GOpaqueU>' being compiled
1>        with
1>        [
1>            Target=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(31): message : see reference to class template instantiation 'cv::util::detail::type_list_index_helper<1,Target,cv::GMatP,cv::GFrame,cv::GScalar,cv::detail::GArrayU,cv::detail::GOpaqueU>' being compiled
1>        with
1>        [
1>            Target=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(45): message : see reference to class template instantiation 'cv::util::detail::type_list_index_helper<0,Target,cv::GMat,cv::GMatP,cv::GFrame,cv::GScalar,cv::detail::GArrayU,cv::detail::GOpaqueU>' being compiled
1>        with
1>        [
1>            Target=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\util\\variant.hpp(351): message : see reference to class template instantiation 'cv::util::type_list_index<int,cv::GMat,cv::GMatP,cv::GFrame,cv::GScalar,cv::detail::GArrayU,cv::detail::GOpaqueU>' being compiled
1>opencv\\include\\opencv2\\gapi\\gproto.hpp(50): message : see reference to function template instantiation 'cv::util::variant<cv::GMat,cv::GMatP,cv::GFrame,cv::GScalar,cv::detail::GArrayU,cv::detail::GOpaqueU>::variant<_Ty,void>(T &&)' being compiled
1>        with
1>        [
1>            _Ty=int,
1>            T=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\gproto.hpp(51): message : see reference to function template instantiation 'cv::util::variant<cv::GMat,cv::GMatP,cv::GFrame,cv::GScalar,cv::detail::GArrayU,cv::detail::GOpaqueU>::variant<_Ty,void>(T &&)' being compiled
1>        with
1>        [
1>            _Ty=int,
1>            T=int
1>        ]
1>opencv\\include\\opencv2\\gapi\\gproto.hpp(97): message : see reference to function template instantiation 'cv::GProtoArgs cv::detail::packArgs<cv::GMat,int,int>(cv::GMat,int,int)' being compiled
1>testGAPI\\testGAPI.cpp(44): message : see reference to function template instantiation 'cv::GProtoInputArgs cv::GIn<cv::GMat&,int&,int&>(cv::GMat &,int &,int &)' being compiled
1>Done building project ""testGAPI.vcxproj"" -- FAILED.

'''

##### Steps to reproduce

```
    
#include <iostream>

#include <opencv2/opencv.hpp>
#include <opencv2/gapi.hpp>
#include <opencv2/gapi/core.hpp>
#include <opencv2/gapi/imgproc.hpp>

#define DOES_NOT_COMPILE 1  // COMMENT THIS LINE TO COMPILE SUCCESSFULLY

cv::GComputation mGComputation([]() {
  cv::GMat in;
#ifdef DOES_NOT_COMPILE
  int numDilation;
  int numErosions;
#else
  int numDilation(3);
  int numErosions(3);
#endif

  cv::GMat mask(cv::gapi::gaussianBlur(in, cv::Size(11, 11), 0.0));
  mask = cv::gapi::erode3x3(mask, numErosions);
  mask = cv::gapi::dilate3x3(mask, numDilation);
#ifdef DOES_NOT_COMPILE
  cv::GArray<cv::GArray<cv::Point>> contours = cv::gapi::findContours(mask, cv::RetrievalModes::RETR_EXTERNAL, cv::ContourApproximationModes::CHAIN_APPROX_SIMPLE);
  return cv::GComputation(cv::GIn(in,numDilation,numErosions), cv::GOut(contours));
#else
  return cv::GComputation(in, mask);
#endif
});

const cv::Scalar white(cv::Scalar(255));

int main(int argc, char** argv)
{
  int nDilation(3), nErosions(3), rw(60), rh(40), ofs(50), lw(1);
  int x(ofs), y(ofs),i;
  cv::Mat input(cv::Mat::zeros(640, 480, CV_8UC1));

  for (i = 0; i < 3; i++) {
    cv::rectangle(input, cv::Rect(x, y, rw, rh), white, lw, cv::FILLED);
    x += rw + ofs;
    y += rh + ofs;
  }
#ifdef DOES_NOT_COMPILE
  std::vector<std::vector<cv::Point>> contours;
  mGComputation.apply(cv::gin(input,nDilation,nErosions),cv::gout(contours));
#else
  cv::Mat output;
  mGComputation.apply(input,output);           
#endif
           
#ifdef DOES_NOT_COMPILE
  if (contours.empty()) {
    std::cout << ""No Contours found."" << std::endl;
  } else {
    std::cout << ""Found "" << contours.size() << "" contours."" << std::endl;
  }
#endif
  return 0;
}

    ```

"
opencv/opencv,2022-01-25 01:51:01,question,How to confirm the version of the OpenCV 3rdParty libs,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
- OpenCV = 4.5.2
- Operating System / Platform => Linux
- Compiler => gcc version 4.8.5


##### Detailed description
I need to obtain each software version in the 3rdparty directory in the source code of OpenCV 4.5.2 to analyze whether OpenCV 4.5.2 has dependency vulnerabilities.But the third-party software version is not found in the code repository or in the document.For example, the versions of open-source software such as carotene, cpufeatures, ippicv, and ittnotify cannot be confirmed.
![image](https://user-images.githubusercontent.com/98326538/150894923-7303e9a0-ddc4-4b8e-be37-77a0ff583cf1.png)



##### Steps to reproduce


##### Issue submission checklist

 - [x] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with questions without a real issue statement will be
   closed.
   -->
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [x] I updated to the latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only the latest release for each branch.
   The ticket is closed if the problem is not reproduced with the modern version.
   -->
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as an archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-01-17 08:18:06,question,relocation R_X86_64_PC32 against symbol `ff_pw_9' can not be used when making a shared object; recompile with -fPIC,"

##### System information (version)
```
Detected processor: x86_64
Could NOT find PythonInterp (missing: PYTHON_EXECUTABLE) (Required is at least version ""2.7"")
Looking for ccache - not found
Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found suitable version ""1.2.11"", minimum required is ""1.2.3"") 
Could NOT find OpenJPEG (minimal suitable version: 2.0, recommended version >= 2.3.1)
Could NOT find Jasper (missing: JASPER_LIBRARIES JASPER_INCLUDE_DIR) 
Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version ""1.2.11"") 
Checking for module 'gtk+-3.0'
  No package 'gtk+-3.0' found
CUDA detected: 11.4
CUDA: Using CUDA_ARCH_BIN=3.5;3.7;5.0;5.2;6.0;6.1;7.0;7.5;8.0
CUDA NVCC target flags: -gencode;arch=compute_35,code=sm_35;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-D_FORCE_INLINES
Could not find OpenBLAS include. Turning OpenBLAS_FOUND off
Could not find OpenBLAS lib. Turning OpenBLAS_FOUND off
Could NOT find Atlas (missing: Atlas_CLAPACK_INCLUDE_DIR) 
A library with LAPACK API found.
VTK is not found. Please set -DVTK_DIR in CMake to VTK build directory, or to VTK install subdirectory with VTKConfig.cmake file
OpenCV Python: during development append to PYTHONPATH: /home/mosaic/Downloads/OpenCV4/build/python_loader
Checking for module 'libavresample'
  No package 'libavresample' found
Checking for module 'gstreamer-base-1.0'
  No package 'gstreamer-base-1.0' found
Checking for module 'gstreamer-app-1.0'
  No package 'gstreamer-app-1.0' found
Checking for module 'gstreamer-riff-1.0'
  No package 'gstreamer-riff-1.0' found
Checking for module 'gstreamer-pbutils-1.0'
  No package 'gstreamer-pbutils-1.0' found
Checking for module 'libdc1394-2'
  No package 'libdc1394-2' found
Caffe:   NO
Protobuf:   NO
Glog:   NO
freetype2:   YES (ver 23.1.17)
harfbuzz:    YES (ver 2.6.4)
Could NOT find HDF5 (missing: HDF5_LIBRARIES HDF5_INCLUDE_DIRS) (found version """")
Julia not found. Not compiling Julia Bindings. 
Module opencv_ovis disabled because OGRE3D was not found
No preference for use of exported gflags CMake configuration set, and no hints for include/library directories provided. Defaulting to preferring an installed/exported gflags CMake configuration if available.
Failed to find installed gflags CMake configuration, searching for gflags build directories exported with CMake.
Failed to find gflags - Failed to find an installed/exported CMake configuration for gflags, will perform search for installed gflags components.
Failed to find gflags - Could not find gflags include directory, set GFLAGS_INCLUDE_DIR to directory containing gflags/gflags.h
Failed to find glog - Could not find glog include directory, set GLOG_INCLUDE_DIR to directory containing glog/logging.h
Module opencv_sfm disabled because the following dependencies are not found: Glog/Gflags
Checking for module 'tesseract'
  No package 'tesseract' found
Tesseract:   NO
Allocator metrics storage type: 'long long'
Registering hook 'INIT_MODULE_SOURCES_opencv_dnn': /home/mosaic/Downloads/OpenCV4/opencv-4.4.0/modules/dnn/cmake/hooks/INIT_MODULE_SOURCES_opencv_dnn.cmake

General configuration for OpenCV 4.4.0 =====================================
  Version control:               unknown

  Extra modules:
    Location (extra):            /home/mosaic/Downloads/OpenCV4/opencv_contrib-4.4.0/modules
    Version control (extra):     unknown

  Platform:
    Timestamp:                   2022-01-17T07:14:53Z
    Host:                        Linux 5.11.0-46-generic x86_64
    CMake:                       3.16.3
    CMake generator:             Unix Makefiles
    CMake build tool:            /usr/bin/make
    Configuration:               Release

  CPU/HW features:
    Baseline:                    SSE SSE2 SSE3
      requested:                 SSE3
    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX
      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
      SSE4_1 (14 files):         + SSSE3 SSE4_1
      SSE4_2 (1 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
      FP16 (0 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
      AVX (4 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX
      AVX2 (28 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
      AVX512_SKX (4 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX

  C/C++:
    Built as dynamic libs?:      YES
    C++ standard:                11
    C++ Compiler:                /usr/bin/c++  (ver 9.3.0)
    C++ flags (Release):         -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG
    C++ flags (Debug):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG
    C Compiler:                  /usr/bin/cc
    C flags (Release):           -fsigned-char -W -Wall -Werror=return-type -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG
    C flags (Debug):             -fsigned-char -W -Wall -Werror=return-type -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wuninitialized -Winit-self -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG
    Linker flags (Release):      -Wl,--gc-sections -Wl,--as-needed  
    Linker flags (Debug):        -Wl,--gc-sections -Wl,--as-needed  
    ccache:                      NO
    Precompiled headers:         NO
    Extra dependencies:          dl m pthread rt cudart nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas cudnn cufft -L/usr/local/cuda/lib64
    3rdparty dependencies:

  OpenCV modules:
    To be built:                 alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm features2d flann freetype fuzzy hfs highgui img_hash imgcodecs imgproc intensity_transform line_descriptor ml objdetect optflow phase_unwrapping photo plot quality rapid reg rgbd saliency shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab xfeatures2d ximgproc xobjdetect xphoto
    Disabled:                    face java_bindings_generator python_bindings_generator python_tests world
    Disabled by dependency:      -
    Unavailable:                 cnn_3dobj cvv gapi hdf java js julia matlab ovis python2 python3 sfm viz
    Applications:                apps
    Documentation:               NO
    Non-free algorithms:         YES

  GUI: 
    GTK+:                        YES (ver 2.24.32)
      GThread :                  YES (ver 2.64.6)
      GtkGlExt:                  NO
    VTK support:                 NO

  Media I/O: 
    ZLib:                        /usr/lib/x86_64-linux-gnu/libz.so (ver 1.2.11)
    JPEG:                        /usr/lib/x86_64-linux-gnu/libjpeg.so (ver 80)
    WEBP:                        build (ver encoder: 0x020f)
    PNG:                         /usr/lib/x86_64-linux-gnu/libpng.so (ver 1.6.37)
    TIFF:                        build (ver 42 - 4.0.10)
    JPEG 2000:                   build Jasper (ver 1.900.1)
    OpenEXR:                     build (ver 2.3.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:
    DC1394:                      NO
    FFMPEG:                      YES
      avcodec:                   YES (58.134.100)
      avformat:                  YES (58.76.100)
      avutil:                    YES (56.70.100)
      swscale:                   YES (5.9.100)
      avresample:                NO
    GStreamer:                   NO
    v4l/v4l2:                    YES (linux/videodev2.h)

  Parallel framework:            pthreads

  Trace:                         YES (with Intel ITT)

  Other third-party libraries:
    Lapack:                      NO
    Eigen:                       YES (ver 3.3.7)
    Custom HAL:                  NO
    Protobuf:                    build (3.5.1)

  NVIDIA CUDA:                   YES (ver 11.4, CUFFT CUBLAS)
    NVIDIA GPU arch:             35 37 50 52 60 61 70 75 80
    NVIDIA PTX archs:

  cuDNN:                         YES (ver 8.2.4)

  OpenCL:                        YES (no extra features)
    Include path:                /home/mosaic/Downloads/OpenCV4/opencv-4.4.0/3rdparty/include/opencl/1.2
    Link libraries:              Dynamic load

  Python (for build):            /usr/bin/python3

  Install to:                    /usr/local
-----------------------------------------------------------------

Configuring done

```

##### Detailed description
```
/usr/bin/ld: /usr/local/lib/libavcodec.a(vc1dsp_mmx.o): relocation R_X86_64_PC32 against symbol `ff_pw_9' can not be used when making a shared object; recompile with -fPIC
/usr/bin/ld: 最后的链结失败: bad value
collect2: error: ld returned 1 exit status
make[2]: *** [modules/videoio/CMakeFiles/opencv_videoio.dir/build.make:258：lib/libopencv_videoio.so.4.4.0] 错误 1
make[1]: *** [CMakeFiles/Makefile2:6482：modules/videoio/CMakeFiles/opencv_videoio.dir/all] 错误 2
make[1]: *** 正在等待未完成的任务....

```
+ I don't know whether this error is caused by ffmpeg or OpenCV

##### Steps to reproduce
```
 + enable cuda、cudnn、ffmpeg(refer to System information (version))

```

##### Issue submission checklist

 - [ ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with question without real issue statement will be
   closed.
   -->
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [ ] I updated to latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only latest release for each branch.
   The ticket is closed, if the problem is not reproduced with modern version.
   -->
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-01-14 03:16:34,question,compile opencv with inference-engine,"hello when I use cmake to compile opencv with inferenceEngine I get problem next:
![image](https://user-images.githubusercontent.com/38007233/149445505-7448ca18-4933-448a-a7e1-8677cc57b0c7.png)
how to solve it"
opencv/opencv,2022-01-13 07:39:06,question,Android NDK 23b LTS Compile Error ,"Hey! Please advise changes required I can PR fixes 

Following Error for arm64/x86/x86_64 when targeting NDK 23b
```
Error at /opt/homebrew/Cellar/cmake/3.22.1/share/cmake/Modules/Platform/Android-Determine.cmake:584 (message):
  Android: CMAKE_ANDROID_ARM_MODE is set but is valid only for 'armeabi'
  ```
All is working with NDK target 21b in all architectures with the following build script

##### System information (version)
- OpenCV => 4.5.5
- Operating System / Platform => macOS ARM 64 Bit M1
- Compiler => Clang++

##### Detailed description
```
android_configure: cmake config
NDK_VESION_MAJOR: 23
NDK_PLATFORM: android-21
ANDROID_NDK_HOME: /Users/one/Library/Android/sdk/ndk/23.1.7779620
SYSROOT: /Users/one/Library/Android/sdk/ndk/23.1.7779620/toolchains/llvm/prebuilt/darwin-x86_64/sysroot
Toolchain: /Users/one/Library/Android/sdk/ndk/23.1.7779620/toolchains/llvm/prebuilt/darwin-x86_64/sysroot/usr/include
AR: /Users/one/Library/Android/sdk/ndk/23.1.7779620/toolchains/llvm/prebuilt/darwin-x86_64/bin/llvm-ar
/Users/one/Library/Android/sdk/ndk/23.1.7779620
/Users/one/SOURCE/apothecary/apothecary/build/opencv/build_android_arm64
CMake Error at /opt/homebrew/Cellar/cmake/3.22.1/share/cmake/Modules/Platform/Android-Determine.cmake:584 (message):
  Android: CMAKE_ANDROID_ARM_MODE is set but is valid only for 'armeabi'
  architectures.
Call Stack (most recent call first):
  /opt/homebrew/Cellar/cmake/3.22.1/share/cmake/Modules/CMakeDetermineSystem.cmake:160 (include)
  CMakeLists.txt:113 (enable_language)


CMake Error: CMake was unable to find a build program corresponding to ""Unix Makefiles"".  CMAKE_MAKE_PROGRAM is not set.  You probably need to select a different build tool.
-- Configuring incomplete, errors occurred!

 ^ Received error ^

```

Compilation Successful in NDK 23b:
- arm-v7a / armv7 

**Failures in:**
- x86
- x86_64
- arm-v8a / arm64

##### Steps to reproduce

CMake Compile:
```
rm -rf $BUILD_FOLDER
    mkdir $BUILD_FOLDER
    cd $BUILD_FOLDER


    if [ ""$ABI"" = ""armeabi-v7a"" ]; then
      export ARM_MODE=""-DANDROID_FORCE_ARM_BUILD=TRUE""
    elif [ $ABI = ""arm64-v8a"" ]; then
      export ARM_MODE=""-DANDROID_FORCE_ARM_BUILD=TRUE""
    elif [ ""$ABI"" = ""x86_64"" ]; then
      export ARM_MODE=""-DANDROID_FORCE_ARM_BUILD=FALSE"" 
    elif [ ""$ABI"" = ""x86"" ]; then
      export ARM_MODE=""-DANDROID_FORCE_ARM_BUILD=FALSE""
    fi

    ANDROID_NDK=${NDK_ROOT}

    export ANDROID_NATIVE_API_LEVEL=21
  
    echo ${ANDROID_NDK}
    pwd
    cmake  \\
      -DANDROID_TOOLCHAIN=clang++ \\
      -DCMAKE_TOOLCHAIN_FILE=${NDK_ROOT}/build/cmake/android.toolchain.cmake  \\
      -DCMAKE_CXX_COMPILER_RANLIB=${RANLIB} \\
      -DCMAKE_C_COMPILER=${CC} \\
      -DCMAKE_CXX_COMPILER=${CXX} \\
      -DCMAKE_CXX_FLAGS=""-fvisibility-inlines-hidden -stdlib=libc++ -O3 -fPIC -Wno-implicit-function-declaration"" \\
      -DCMAKE_C_FLAGS=""-fvisibility-inlines-hidden -stdlib=libc++ -O3 -fPIC -Wno-implicit-function-declaration "" \\
      ${ARM_MODE} \\
      -D ANDROID_PLATFORM=${ANDROID_PLATFORM} \\
      -DANDROID_ABI=${ABI} \\
      -DBUILD_ANDROID_PROJECTS=OFF \\
      -D BUILD_ANDROID_EXAMPLES=OFF \\
      -D BUILD_opencv_objdetect=OFF \\
      -D BUILD_opencv_video=OFF \\
      -D BUILD_opencv_videoio=OFF \\
      -D BUILD_opencv_features2d=OFF \\
      -D BUILD_opencv_flann=OFF \\
      -D BUILD_opencv_highgui=ON \\
      -D BUILD_opencv_ml=ON \\
      -D BUILD_opencv_photo=OFF \\
      -D BUILD_opencv_python=OFF \\
      -D BUILD_opencv_shape=OFF \\
      -D BUILD_opencv_stitching=OFF \\
      -D BUILD_opencv_superres=OFF \\
      -D BUILD_opencv_ts=OFF \\
      -D BUILD_opencv_videostab=OFF \\
      -D WITH_MATLAB=OFF \\
      -D WITH_CUDA=OFF \\
      -DBUILD_SHARED_LIBS=OFF \\
      -DBUILD_DOCS=OFF \\
      -DBUILD_EXAMPLES=OFF \\
      -DBUILD_FAT_JAVA_LIB=OFF \\
      -DBUILD_JASPER=OFF \\
      -DBUILD_PACKAGE=OFF \\
      -DBUILD_opencv_java=OFF \\
      -DBUILD_opencv_apps=OFF \\
      -DBUILD_JPEG=OFF \\
      -DBUILD_PNG=OFF \\
      -DHAVE_opencv_androidcamera=OFF \\
      -DWITH_CAROTENE=OFF \\
      -DWITH_CPUFEATURES=OFF \\
      -DWITH_TIFF=OFF \\
      -DWITH_OPENEXR=OFF \\
      -DWITH_1394=OFF \\
      -DWITH_JPEG=OFF \\
      -DWITH_PNG=OFF \\
      -DWITH_FFMPEG=OFF \\
      -DWITH_OPENCL=OFF \\
      -DWITH_GIGEAPI=OFF \\
      -DWITH_CUDA=OFF \\
      -DWITH_CUFFT=OFF \\
      -DWITH_JASPER=OFF \\
      -DWITH_IMAGEIO=OFF \\
      -DWITH_IPP=OFF \\
      -DWITH_OPENNI=OFF \\
      -DWITH_QT=OFF \\
      -DWITH_V4L=OFF \\
      -DWITH_PVAPI=OFF \\
      -DWITH_EIGEN=OFF \\
      -DBUILD_TESTS=OFF \\
      -DANDROID_NDK=${NDK_ROOT} \\
      -DCMAKE_BUILD_TYPE=Release \\
      -DANDROID_ABI=$ABI \\
      -DANDROID_STL=c++_static \\
      -DANDROID_PLATFORM=$ANDROID_PLATFORM \\
      -DCMAKE_TOOLCHAIN_FILE=$ANDROID_CMAKE_TOOLCHAIN \\
      -DBUILD_PERF_TESTS=OFF ..
    make -j${PARALLEL_MAKE}
    make install
    
 ```

##### Issue submission checklist

 - [x] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with question without real issue statement will be
   closed.
   -->
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [x] I updated to latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only latest release for each branch.
   The ticket is closed, if the problem is not reproduced with modern version.
   -->
 - [x] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-01-07 15:04:40,question,haarcascade_frontalcatface muslim women detection,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)
<!-- Example
- OpenCV => 4.2
- Operating System / Platform => Windows 64 Bit
- Compiler => Visual Studio 2017
-->

- OpenCV => :grey_question:
- Operating System / Platform => :grey_question:
- Compiler => :grey_question:

##### Detailed description

<!-- your description -->
The haarcascade_frontalcatface can't detect faces of Mulsim women who wear Hijab. Also, it didn't work in detecting far faces, some children faces although it is clear.

like this image 
https://www.bing.com/images/search?view=detailV2&ccid=4X8we8cs&id=C8748C00071E6295ECC7E8CCDBB08B41F06F5890&thid=OIP.4X8we8csodWo774bfslTewHaEo&mediaurl=https%3A%2F%2Fhart.ca%2Fwp-content%2Fuploads%2F2015%2F10%2FGypsySchool-800x500.jpg&cdnurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.e17f307bc72ca1d5a8efbe1b7ec9537b%3Frik%3DkFhv8EGLsNvM6A%26pid%3DImgRaw%26r%3D0&exph=500&expw=800&q=images+of+people+groups+musims&simid=608029999084930295&form=IRPRST&ck=0881D21EE8E2F0F7365DC02E15CDB038&selectedindex=1&ajaxhist=0&ajaxserp=0&pivotparams=insightsToken%3Dccid_AABB9%252BFi*cp_B18603B6EC4A98BB426DC964DF441597*mid_0D8C02857F006EBD198C7F1401EEEDA8522CAADD*simid_608047982103961465*thid_OIP.AABB9-FibKsqUyNWiEdCKQAAAA&vt=0&sim=11&iss=VSI&ajaxhist=0&ajaxserp=0



##### Steps to reproduce

<!-- to add code example fence it with triple backticks and optional file extension
    ```.cpp
    // C++ code example
    ```
 or attach as .txt or .zip file
-->

##### Issue submission checklist

 - [ ] I report the issue, it's not a question
   <!--
   OpenCV team works with forum.opencv.org, Stack Overflow and other communities
   to discuss problems. Tickets with question without real issue statement will be
   closed.
   -->
 - [ ] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found solution
   <!--
   Places to check:
   * OpenCV documentation: https://docs.opencv.org
   * FAQ page: https://github.com/opencv/opencv/wiki/FAQ
   * OpenCV forum: https://forum.opencv.org
   * OpenCV issue tracker: https://github.com/opencv/opencv/issues?q=is%3Aissue
   * Stack Overflow branch: https://stackoverflow.com/questions/tagged/opencv
   -->
 - [ ] I updated to latest OpenCV version and the issue is still there
   <!--
   master branch for OpenCV 4.x and 3.4 branch for OpenCV 3.x releases.
   OpenCV team supports only latest release for each branch.
   The ticket is closed, if the problem is not reproduced with modern version.
   -->
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc
   <!--
   The best reproducer -- test case for OpenCV that we can add to the library.
   Recommendations for media files and binary files:
   * Try to reproduce the issue with images and videos in opencv_extra repository
     to reduce attachment size
   * Use PNG for images, if you report some CV related bug, but not image reader
     issue
   * Attach the image as archive to the ticket, if you report some reader issue.
     Image hosting services compress images and it breaks the repro code.
   * Provide ONNX file for some public model or ONNX file with with random weights,
     if you report ONNX parsing or handling issue. Architecture details diagram
     from netron tool can be very useful too. See https://lutzroeder.github.io/netron/
   -->
"
opencv/opencv,2022-01-06 10:14:17,question,[ONNX] inference different result between Python and C++,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

### System information

- OpenCV => 4.4
- Operating System / Platform =>MacOS
- Compiler => GCC-11

### Detailed description

with same model,same Image,ONNX inference  diffrent result between Python and C++;

Model download [link](https://github.com/Hexmagic/FaceBoxes-ONNX/blob/main/FaceBoxes.onnx)
Image download [link](https://github.com/Hexmagic/FaceBoxes-ONNX/blob/main/data/test.jpg)

### Steps to reproduce
with python code below :

```python
import cv2
import numpy as np

img = cv2.imread(""data/test.jpg"")
img = cv2.resize(img,None,None,2.5,2.5,cv2.INTER_LINEAR);
img = np.float32(img)
net = cv2.dnn.readNetFromONNX(""FaceBoxes.onnx"")
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)

blobImage = cv2.dnn.blobFromImage(img,1.0,(img.shape[1],img.shape[0]),(104, 117, 123),False,False)
outNames = net.getUnconnectedOutLayersNames()
net.setInput(blobImage)
outs = net.forward(outNames)
loc,conf = outs  
boxes = loc[0].tolist()
scores = conf[0].tolist()
# loc=> 45279x4  conf=> 45279x2
with open('pyout.csv', 'w') as f:
    for i in range(len(boxes)):
        if (scores[i][1]<0.99):
            continue
        print(scores[i][1])
        line = f'{i},{boxes[i][0]:.4f},{boxes[i][1]:.4f},{boxes[i][2]:.4f},{boxes[i][3]:.4f},{scores[i][1]:.6f}\\n'
        f.write(line)
```
I get 83 locs(score>=0.99),and this is python eval [result](https://github.com/Hexmagic/FaceBoxes-ONNX/blob/main/pyout.csv) top 7 lines:
```
pyout.csv
15349,-1.0067,2.5144,-1.2562,-0.3501,0.991678
16250,0.6271,1.1616,-0.6419,0.4609,0.999528
16252,0.5942,-1.3030,-0.6872,0.4833,0.999476
16270,-1.8484,1.2117,-0.6368,0.5557,0.997658
16272,-1.8312,-1.2853,-0.6489,0.5659,0.997315
16439,1.5782,1.7922,-1.4676,-0.3414,0.991359
16441,1.6717,-0.9027,-1.4335,-0.4099,0.997423
...
83 lines in total
```

while c++ code only  get 29 locs(score>=0.99)
```c++
#include <iostream>
#include <string>
#include <opencv2/opencv.hpp>
#include <opencv2/dnn.hpp>
#include <fstream>
using namespace std;
using namespace cv;
int main()
{
    string model_path = ""/Users/mix/FaceBoxes.PyTorch/FaceBoxes.onnx"";
    string image_path = ""data/test.jpg"";
    Mat clr = imread(image_path,IMREAD_COLOR);
    Mat image,blob,conf,loc;
    resize(clr, image, Size(), 2.5, 2.5, INTER_LINEAR);
    dnn::blobFromImage(image, blob, 1.0, Size(image.cols, image.rows), Scalar(104.0, 117.0, 123.0), false, false);
    auto net = dnn::readNetFromONNX(""FaceBoxes.onnx"");
    net.setPreferableBackend(dnn::DNN_BACKEND_OPENCV);
    net.setPreferableTarget(dnn::DNN_TARGET_CPU);
    net.setInput(blob);
    std::vector<string> outLayerNames = net.getUnconnectedOutLayersNames();
    std::vector<Mat> outs;
    net.forward(outs, outLayerNames);
    Mat(outs[0].size[1], outs[0].size[2], CV_32F, outs[0].data).copyTo(loc);
    Mat(outs[1].size[1], outs[1].size[2], CV_32F, outs[1].data).copyTo(conf);
    ofstream ofs(""out.csv"");
    for (int i = 0; i < conf.rows; i++)
    {
        if (conf.at<float>(i, 1) > 0.999)
        {
            ofs << i << "","" << loc.at<float>(i, 0) << "","" << loc.at<float>(i, 1) << "","" << loc.at<float>(i, 2) << "","" << loc.at<float>(i, 3) << "","" << conf.at<float>(i, 1) << endl;
        }
    }
    ofs.close();
}
```
and this is c++ eval [result](https://github.com/Hexmagic/FaceBoxes-ONNX/blob/main/out.csv) top 7 lines:
```csv
out.csv
16250,0.62713,1.16155,-0.641878,0.460859,0.999528
16252,0.59424,-1.30304,-0.687168,0.483299,0.999476
16461,-0.901199,-0.75866,-1.37947,-0.355771,0.999146
16585,1.51934,0.0613557,-1.24159,-0.457869,0.999461
16586,-0.89196,0.0268208,-1.23652,-0.379888,0.999453
17782,0.968584,-0.3158,-0.939803,-0.0735131,0.999688
17783,-1.54759,-0.40074,-0.848909,-0.0779193,0.999503
...
29 lines in total
```"
opencv/opencv,2023-09-18 13:04:25,feature,add Intel® oneAPI DPC++/C++ Compiler (icx),"Intel® C++ Compiler Classic (icc) is deprecated and will be removed in a oneAPI release in the second half of 2023 ([deprecation notice](https://community.intel.com/t5/Intel-oneAPI-IoT-Toolkit/DEPRECATION-NOTICE-Intel-C-Compiler-Classic/m-p/1412267#:~:text=Intel%C2%AE%20C%2B%2B%20Compiler%20Classic%20(icc)%20is%20deprecated%20and%20will,the%20second%20half%20of%202023.)). This commit is intended to add support for the next-generation compiler, Intel® oneAPI DPC++/C++ Compiler (icx) (the documentation for the compiler is available on the [link](https://www.intel.com/content/www/us/en/docs/dpcpp-cpp-compiler/developer-guide-reference/2023-2/overview.html)). 

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-08-24 18:49:30,feature,CUDA compilation is not using ccache,"### System Information

OpenCV version: 4.8.0
Operating System / Platform: Ubuntu 20.04.6 LTS
Compiler & compiler version: GCC 9.4.0
CUDA: 11.4



### Detailed description

Using ccache 3.7.7 (Ubuntu version) or latest version (4.8.2), ccache is found by OpenCV's cmake but used only to compile C/C++

### Steps to reproduce

```
cd opencv
mkdir build && cd build
cmake -DWITH_CUDA=ON -DBUILD_LIST=core,cudev,cudaimgproc \\
  -DCUDA_ARCH_BIN=""7.2"" \\
  -DOPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules ..

VERBOSE=1 make opencv_core
VERBOSE=1 make opencv_cudaimgproc
```

We could see that `ccache` is used for C++ files

```
[ 22%] Building CXX object modules/core/CMakeFiles/opencv_core.dir/src/alloc.cpp.o
cd /home/dgeld/src/opencv/build/modules/core && /usr/bin/ccache /usr/bin/c++ -DCVAPI_EXPORTS -DOPENCV_ALLOCATOR_STATS_COUNTER_TYPE=""long long"" -DOPENCV_WITH_ITT=1 -D_USE_MATH_DEFINES -D__OPENCV_BUILD=1 -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -DHAVE_MALLOC_H=1 -DHAVE_MEMALIGN=1 -DHAVE_POSIX_MEMALIGN=1 -I/home/dgeld/src/opencv/build/3rdparty/ippicv/ippicv_lnx/icv/include -I/home/dgeld/src/opencv/build/3rdparty/ippicv/ippicv_lnx/iw/include -I/home/dgeld/src/opencv/build -I/home/dgeld/src/opencv/modules/core/include -I/home/dgeld/src/opencv/build/modules/core -I/home/dgeld/src/opencv_contrib/modules/cudev/include -I/home/dgeld/src/opencv/3rdparty/include/opencl/1.2 -I/home/dgeld/src/opencv/3rdparty/ittnotify/include -isystem /usr/local/cuda-11.4/include -fsigned-char -W -Wall -Wreturn-type -Wnon-virtual-dtor -Waddress -Wsequence-point -Wformat -Wformat-security -Wmissing-declarations -Winit-self -Wpointer-arith -Wsign-promo -Wuninitialized -Wsuggest-override -Wno-delete-non-virtual-dtor -Wno-comment -Wimplicit-fallthrough=3 -Wno-strict-overflow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -Wno-undef -Wno-enum-compare -Wno-unused-function -Wno-shadow -O3 -DNDEBUG  -DNDEBUG -std=c++11 -fPIC -MD -MT modules/core/CMakeFiles/opencv_core.dir/src/alloc.cpp.o -MF CMakeFiles/opencv_core.dir/src/alloc.cpp.o.d -o CMakeFiles/opencv_core.dir/src/alloc.cpp.o -c /home/dgeld/src/opencv/modules/core/src/alloc.cpp
```

But CUDA files are not cached:

```
[ 14%] Building NVCC (Device) object modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o
cd /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda && /snap/cmake/1329/bin/cmake -E make_directory /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/.
cd /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda && /snap/cmake/1329/bin/cmake -D verbose:BOOL=1 -D build_configuration:STRING=Release -D generated_file:STRING=/home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/./cuda_compile_1_generated_gpu_mat.cu.o -D generated_cubin_file:STRING=/home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/./cuda_compile_1_generated_gpu_mat.cu.o.cubin.txt -P /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.Release.cmake
-- Removing /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/./cuda_compile_1_generated_gpu_mat.cu.o
/snap/cmake/1329/bin/cmake -E rm -f /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/./cuda_compile_1_generated_gpu_mat.cu.o
-- Generating dependency file: /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.NVCC-depend
/usr/local/cuda-11.4/bin/nvcc -M -D__CUDACC__ /home/dgeld/src/opencv/modules/core/src/cuda/gpu_mat.cu -o /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.NVCC-depend -ccbin /usr/bin/cc -m64 -D_USE_MATH_DEFINES -D__STDC_CONSTANT_MACROS -D__STDC_LIMIT_MACROS -D__STDC_FORMAT_MACROS -DOPENCV_WITH_ITT=1 ""-DOPENCV_ALLOCATOR_STATS_COUNTER_TYPE=long long"" -D__OPENCV_BUILD=1 -Xcompiler ,\\""-fsigned-char\\"",\\""-W\\"",\\""-Wall\\"",\\""-Wreturn-type\\"",\\""-Wnon-virtual-dtor\\"",\\""-Waddress\\"",\\""-Wsequence-point\\"",\\""-Wformat\\"",\\""-Wformat-security\\"",\\""-Wmissing-declarations\\"",\\""-Winit-self\\"",\\""-Wpointer-arith\\"",\\""-Wuninitialized\\"",\\""-Wno-comment\\"",\\""-Wno-strict-overflow\\"",\\""-fdiagnostics-show-option\\"",\\""-Wno-long-long\\"",\\""-pthread\\"",\\""-fomit-frame-pointer\\"",\\""-ffunction-sections\\"",\\""-fdata-sections\\"",\\""-msse\\"",\\""-msse2\\"",\\""-msse3\\"",\\""-fvisibility=hidden\\"",\\""-Wno-undef\\"",\\""-Wno-enum-compare\\"",\\""-Wno-unused-function\\"",\\""-Wno-shadow\\"",\\""-Wno-unused-but-set-variable\\"",\\""-O3\\"",\\""-DNDEBUG\\"",\\""-DNDEBUG\\"" -gencode arch=compute_72,code=sm_72 -D_FORCE_INLINES -Xcompiler -DCVAPI_EXPORTS -Xcompiler -fPIC --std=c++14 -DNVCC -I/usr/local/cuda-11.4/include -I/home/dgeld/src/opencv/build/3rdparty/ippicv/ippicv_lnx/icv/include -I/home/dgeld/src/opencv/build/3rdparty/ippicv/ippicv_lnx/iw/include -I/home/dgeld/src/opencv/build -I/home/dgeld/src/opencv/modules/core/include -I/home/dgeld/src/opencv/build/modules/core -I/home/dgeld/src/opencv_contrib/modules/cudev/include -I/home/dgeld/src/opencv/3rdparty/include/opencl/1.2 -I/home/dgeld/src/opencv/3rdparty/ittnotify/include
-- Generating temporary cmake readable file: /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend.tmp
/snap/cmake/1329/bin/cmake -D input_file:FILEPATH=/home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.NVCC-depend -D output_file:FILEPATH=/home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend.tmp -D verbose=1 -P /snap/cmake/1329/share/cmake-3.27/Modules/FindCUDA/make2cmake.cmake
-- Copy if different /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend.tmp to /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend
/snap/cmake/1329/bin/cmake -E copy_if_different /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend.tmp /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend
-- Removing /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend.tmp and /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.NVCC-depend
/snap/cmake/1329/bin/cmake -E rm -f /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.depend.tmp /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/cuda_compile_1_generated_gpu_mat.cu.o.NVCC-depend
-- Generating /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/./cuda_compile_1_generated_gpu_mat.cu.o
/usr/local/cuda-11.4/bin/nvcc /home/dgeld/src/opencv/modules/core/src/cuda/gpu_mat.cu -c -o /home/dgeld/src/opencv/build/modules/core/CMakeFiles/cuda_compile_1.dir/src/cuda/./cuda_compile_1_generated_gpu_mat.cu.o -ccbin /usr/bin/cc -m64 -D_USE_MATH_DEFINES -D__STDC_CONSTANT_MACROS -D__STDC_LIMIT_MACROS -D__STDC_FORMAT_MACROS -DOPENCV_WITH_ITT=1 ""-DOPENCV_ALLOCATOR_STATS_COUNTER_TYPE=long long"" -D__OPENCV_BUILD=1 -Xcompiler ,\\""-fsigned-char\\"",\\""-W\\"",\\""-Wall\\"",\\""-Wreturn-type\\"",\\""-Wnon-virtual-dtor\\"",\\""-Waddress\\"",\\""-Wsequence-point\\"",\\""-Wformat\\"",\\""-Wformat-security\\"",\\""-Wmissing-declarations\\"",\\""-Winit-self\\"",\\""-Wpointer-arith\\"",\\""-Wuninitialized\\"",\\""-Wno-comment\\"",\\""-Wno-strict-overflow\\"",\\""-fdiagnostics-show-option\\"",\\""-Wno-long-long\\"",\\""-pthread\\"",\\""-fomit-frame-pointer\\"",\\""-ffunction-sections\\"",\\""-fdata-sections\\"",\\""-msse\\"",\\""-msse2\\"",\\""-msse3\\"",\\""-fvisibility=hidden\\"",\\""-Wno-undef\\"",\\""-Wno-enum-compare\\"",\\""-Wno-unused-function\\"",\\""-Wno-shadow\\"",\\""-Wno-unused-but-set-variable\\"",\\""-O3\\"",\\""-DNDEBUG\\"",\\""-DNDEBUG\\"" -gencode arch=compute_72,code=sm_72 -D_FORCE_INLINES -Xcompiler -DCVAPI_EXPORTS -Xcompiler -fPIC --std=c++14 -DNVCC -I/usr/local/cuda-11.4/include -I/home/dgeld/src/opencv/build/3rdparty/ippicv/ippicv_lnx/icv/include -I/home/dgeld/src/opencv/build/3rdparty/ippicv/ippicv_lnx/iw/include -I/home/dgeld/src/opencv/build -I/home/dgeld/src/opencv/modules/core/include -I/home/dgeld/src/opencv/build/modules/core -I/home/dgeld/src/opencv_contrib/modules/cudev/include -I/home/dgeld/src/opencv/3rdparty/include/opencl/1.2 -I/home/dgeld/src/opencv/3rdparty/ittnotify/include
```

I would expect the last line `/usr/local/cuda-11.4/bin/nvcc /home/dgeld/src/opencv/modules/core/src/cuda/gpu_mat.cu` to use ccache.




### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [x] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-08-03 20:19:33,feature,Convert BGR to RGB NOW!!!,"### Describe the feature and motivation

""The reason why the early developers at OpenCV chose BGR color format is probably that back then BGR color format was popular among camera manufacturers and software providers. E.g. in Windows, when specifying color value using COLORREF they use the BGR format 0x00bbggrr.

BGR was a choice made for historical reasons and now we have to live with it. In other words, BGR is the horse’s ass in OpenCV.""

RGB Revolution. 

Give a like if you support the cause.

### Additional context

_No response_"
opencv/opencv,2023-07-21 14:06:37,feature,G-API: Support DirectML Execution Provider for ONNXRT Backend,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-07-12 05:35:24,feature,Google Summer of Code Support ONNX operator gather elements,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake

This is a draft pull request for GSoC review purposes. Edits need to be made."
opencv/opencv,2023-07-10 15:08:13,feature,feat: update NumPy type to Mat type fail message,"Output string representation of NumPy array type if it is not convertible to OpenCV Mat type

Example output from the test:

```
cv2.error: OpenCV(4.8.0-dev) :-1: error: (-5:Bad argument) in function 'dumpInputArray'
> Overload resolution failed:
>  - argument data type = object is not supported
>  - Expected Ptr<cv::UMat> for argument 'argument'
```

Resolves: #23106

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-21 19:22:42,feature,Expose list of VideoCapture devices,"### Describe the feature and motivation

There is no way currently, within OpenCV, to list existing devices to let the user select them. This means that they must be obtained in a different manner (either by re-implementing manually, or using a third-party library), which may not match OpenCV's indexes and may not work on all platforms.

There is a workaround to try every indexes individually, but this has 4 main issues:
1. Some VideoCapture devices will freeze if opened and closed quickly or if it was already in use.
    - The popular SD capture card `GV-USB2` (confirmed myself)
    - I've had reports that an `AverMedia` capture card is affected as well
2. Some devices take a long time to boot, making this technique quite slow (like my `Logitech c920` webcam)
3. The total amount of devices is unknown, and usable devices may not be sequential. So we have to guess how many devices maximum the user may have, trying to balance between time spent or risking missing some
4. Even if you get all the IDs after this, you don't have access to the names to present to the user. (see #23537)

### Additional context

_No response_"
opencv/opencv,2023-06-15 19:31:35,feature,Add single image support to VideoCapture,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work https://github.com/opencv/opencv/issues/23808
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-13 12:39:38,feature,Added Aruco-based QR code detection method to python sample,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-06-08 14:14:59,feature,Weird behaviour when I use Image2BlobParams,"### Describe the feature and motivation

Full post is https://forum.opencv.org/t/image2blobparams-c-and-python/13437

My code in python : 

```
paramTF2cedn = cv.dnn.Image2BlobParams()
paramTF2cedn.datalayout = cv.dnn.DNN_LAYOUT_NHWC;
paramTF2cedn.ddepth = cv.CV_32F;
paramTF2cedn.mean = (128, 128, 128)
paramTF2cedn.scalefactor = 1 / 128.
paramTF2cedn.size = (224, 224)
paramTF2cedn.swapRB = False;
paramTF2cedn.paddingmode = cv.dnn.DNN_PMODE_NULL
print(""paramTF2cedn.scalefactor = "", paramTF2cedn.scalefactor)
```

result is 
`paramTF2cedn.scalefactor = (0.0078125, 1.0, 1.0, 1.0)`

in C++

```
    Image2BlobParams paramTF2cedn;
    paramTF2cedn.datalayout = DNN_LAYOUT_NHWC;
    paramTF2cedn.ddepth = CV_32F;
    paramTF2cedn.mean = (128, 128, 128);
    paramTF2cedn.scalefactor = 1 / 128.;
    paramTF2cedn.size = Size(224, 224);
    paramTF2cedn.swapRB = false;
    paramTF2cedn.paddingmode = DNN_PMODE_NULL;
    cout << ""paramTF2cedn.scalefactor = "" << paramTF2cedn.scalefactor << endl;
```
Result is

paramTF2cedn.scalefactor = [0.0078125, 0, 0, 0]


difference is in constructor (thanks to @zihaomu)
https://github.com/opencv/opencv/blob/4.x/modules/dnn/src/dnn_utils.cpp#L14-L16


I think something must be write in doc or constructor change




### Additional context

_No response_"
opencv/opencv,2023-06-05 09:32:13,feature,"OpenCV(4.7.0-dev) Error: Assertion failed (interp_mode != ""tf_half_pixel_for_nn"") ","### System Information

```
General configuration for OpenCV 4.7.0-dev =====================================
  Version control:               4.7.0-389-g9fa014edcd

  Extra modules:
    Location (extra):            C:/lib/opencv_contrib/modules
    Version control (extra):     4.7.0-54-g8dfeed73

  Platform:
    Timestamp:                   2023-06-05T09:49:58Z
    Host:                        Windows 10.0.22621 AMD64
    CMake:                       3.26.1
    CMake generator:             Visual Studio 17 2022
    CMake build tool:            C:/Program Files/Microsoft Visual Studio/2022/Community/MSBuild/Current/Bin/amd64/MSBuild.exe
    MSVC:                        1935
    Configuration:               Debug Release

  CPU/HW features:
    Baseline:                    SSE SSE2 SSE3
      requested:                 SSE3
    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX
      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
      SSE4_1 (18 files):         + SSSE3 SSE4_1
      SSE4_2 (2 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
      FP16 (1 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
      AVX (8 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX
      AVX2 (36 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2
      AVX512_SKX (8 files):      + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_COMMON AVX512_SKX

  C/C++:
    Built as dynamic libs?:      YES
    C++ standard:                11
    C++ Compiler:                C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe  (ver 19.35.32215.0)
    C++ flags (Release):         /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MD /O2 /Ob2 /DNDEBUG
    C++ flags (Debug):           /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MDd /Zi /Ob0 /Od /RTC1
    C Compiler:                  C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.35.32215/bin/Hostx64/x64/cl.exe
    C flags (Release):           /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP   /MD /O2 /Ob2 /DNDEBUG
    C flags (Debug):             /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP /MDd /Zi /Ob0 /Od /RTC1
    Linker flags (Release):      /machine:x64  /INCREMENTAL:NO
    Linker flags (Debug):        /machine:x64  /debug /INCREMENTAL
    ccache:                      NO
    Precompiled headers:         YES
    Extra dependencies:          cudart_static.lib nppc.lib nppial.lib nppicc.lib nppidei.lib nppif.lib nppig.lib nppim.lib nppist.lib nppisu.lib nppitc.lib npps.lib cublas.lib cudnn.lib cufft.lib -LIBPATH:C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.1/lib/x64
    3rdparty dependencies:

  OpenCV modules:
    To be built:                 alphamat aruco barcode bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnn_objdetect dnn_superres dpm face features2d flann fuzzy gapi hfs highgui img_hash imgcodecs imgproc intensity_transform java line_descriptor mcc ml objdetect optflow phase_unwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structured_light superres surface_matching text tracking ts video videoio videostab viz wechat_qrcode xfeatures2d ximgproc xobjdetect xphoto
    Disabled:                    world
    Disabled by dependency:      -
    Unavailable:                 cvv freetype hdf julia matlab ovis python2
    Applications:                tests perf_tests examples apps
    Documentation:               doxygen python javadoc
    Non-free algorithms:         YES

  Windows RT support:            NO

  GUI:                           WIN32UI
    Win32 UI:                    YES
    OpenGL support:              YES (opengl32 glu32)
    VTK support:                 YES (ver 9.2.5)

  Media I/O:
    ZLib:                        optimized C:/install/zlib/lib/zlib.lib debug C:/install/zlib/lib/zlibd.lib (ver 1.2.13)    JPEG:                        build-libjpeg-turbo (ver 2.1.3-62)
      SIMD Support Request:      YES
      SIMD Support:              NO
    WEBP:                        build (ver encoder: 0x020f)
    PNG:                         optimized C:/install/libpng/lib/libpng16.lib debug C:/install/libpng/lib/libpng16d.lib (ver 1.6.40)
    TIFF:                        build (ver 42 - 4.2.0)
    JPEG 2000:                   build (ver 2.5.0)
    OpenEXR:                     build (ver 2.3.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:
    DC1394:                      NO
    FFMPEG:                      YES (prebuilt binaries)
      avcodec:                   YES (58.134.100)
      avformat:                  YES (58.76.100)
      avutil:                    YES (56.70.100)
      swscale:                   YES (5.9.100)
      avresample:                YES (4.0.0)
    GStreamer:                   NO
    DirectShow:                  YES
    Media Foundation:            YES
      DXVA:                      YES

  Parallel framework:            Concurrency

  Other third-party libraries:
    Intel IPP:                   2021.8 [2021.8.0]
           at:                   C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/icv
    Intel IPP IW:                sources (2021.8.0)
              at:                C:/lib/build/opencv/3rdparty/ippicv/ippicv_win/iw
    Lapack:                      YES (C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_intel_lp64.lib C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_sequential.lib C:/Program Files (x86)/Intel/oneAPI/mkl/2023.0.0/lib/intel64/mkl_core.lib)
    OpenVINO:                    YES (2022.3.0)
    Eigen:                       YES (ver ..)
    Custom HAL:                  NO
    Protobuf:                    build (3.19.1)
    Flatbuffers:                 builtin/3rdparty (23.5.9)

  NVIDIA CUDA:                   YES (ver 12.1, CUFFT CUBLAS)
    NVIDIA GPU arch:             86
    NVIDIA PTX archs:

  cuDNN:                         YES (ver 8.8.0)

  OpenCL:                        YES (NVD3D11)
    Include path:                C:/lib/opencv/3rdparty/include/opencl/1.2
    Link libraries:              Dynamic load

  Python 3:
    Interpreter:                 C:/Program Files/Python310/python.exe (ver 3.10.10)
    Libraries:                   optimized C:/Program Files/Python310/libs/python310.lib debug C:/Program Files/Python310/libs/python310_d.lib (ver 3.10.10)
    numpy:                       C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/numpy/core/include (ver 1.23.5)
    install path:                C:/Users/laurent/AppData/Roaming/Python/Python310/site-packages/cv2/python-3.10

  Python (for build):            C:/Program Files/Python310/python.exe

  Java:
    ant:                         C:/apache-ant-1.10.13/bin/ant.bat (ver 1.10.13)
    JNI:                         C:/Program Files/Java/jdk-19/include C:/Program Files/Java/jdk-19/include/win32 C:/Program Files/Java/jdk-19/include
    Java wrappers:               YES
    Java tests:                  YES

  Install to:                    C:/install/opencv
-----------------------------------------------------------------
```

### Detailed description

I train my own cedn network using tensorflow 2.12.0
I used this script to freeze and convert .pb to .onnx (https://medium.com/nerd-for-tech/how-to-convert-tensorflow2-model-to-onnx-using-tf2onnx-when-there-is-custom-ops-6e703376ef20): 
```
# freeze model
import tensorflow as tf
from tensorflow import keras
from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2
import numpy as np

from tensorflow.python.util import compat
from tf2onnx import tf_loader
from tf2onnx.tfonnx import process_tf_graph
from tf2onnx.optimizer import optimize_graph
from tf2onnx import utils, constants
from tf2onnx.handler import tf_op

class perte(tf.keras.losses.Loss):

    def __init__(self):
        super().__init__()

    def call(self,y_vrai,y_pred):
        mse1 = tf.reduce_sum(tf.square(tf.subtract(y_vrai,y_pred)), [0, 1, 2])
        mse2 = tf.reduce_sum(y_vrai * tf.square(y_vrai-y_pred), [0, 1, 2])
        return 10*mse2+mse1 


mon_modele = tf.keras.models.load_model(""c:/tmp/log_dirtocd/cedn_pb"",
                                   custom_objects={'perte':perte()},
                                   compile=False)
infer = mon_modele.signatures[""serving_default""]

f = tf.function(infer).get_concrete_function(tf.TensorSpec(shape=mon_modele.inputs[0].shape,
                                                                   dtype=mon_modele.inputs[0].dtype))
frozen_func = convert_variables_to_constants_v2(f)
graph_def = frozen_func.graph.as_graph_def()


output_names = [out.name for out in frozen_func.outputs]
input_names = [inp.name for inp in frozen_func.inputs]
extra_opset = [utils.make_opsetid(constants.CONTRIB_OPS_DOMAIN, 1)]
with tf.Graph().as_default() as tf_graph:
    tf.import_graph_def(frozen_func.graph.as_graph_def(), name='')
with tf_loader.tf_session(graph=tf_graph):
    g = process_tf_graph(tf_graph, input_names=input_names,
                         output_names=output_names, extra_opset=extra_opset)
onnx_graph = optimize_graph(g)
model_proto = onnx_graph.make_model(""converted"")
utils.save_protobuf(""model2b.onnx"", model_proto)
print(""Conversion ONNX complete!"")
```
I tried too 
python -m tf2onnx.convert --saved-model c:/tmp/log_dirtocd/cedn_pb --output c:/tmp/cedn.onnx --opset 11
but results does not change. opset must be >=11
My c++ code is

```
    dnn::Net my_net;
    utils::logging::setLogLevel(utils::logging::LogLevel::LOG_LEVEL_VERBOSE);
    my_net = dnn::readNet(""C:/tmp/cedn/model2b.onnx"");
```

I run program and I ve got an execption : 

```
[DEBUG:0@11.168] global system.cpp:2842 cv::details::setFPDenormalsIgnoreHint core: update FP mxcsr flags = 0x00009fe0
[DEBUG:0@11.172] global onnx_importer.cpp:269 cv::dnn::dnn4_v20221220::ONNXImporter::ONNXImporter DNN/ONNX: processing ONNX model from file: C:/tmp/cedn/model2b.onnx
[ INFO:0@11.687] global onnx_importer.cpp:835 cv::dnn::dnn4_v20221220::ONNXImporter::populateNet DNN/ONNX: loading ONNX v8 model produced by 'tf2onnx':1.14.0 8f8d49. Number of nodes = 54, initializers = 45, inputs = 1, outputs = 1
[DEBUG:0@11.689] global onnx_importer.cpp:723 cv::dnn::dnn4_v20221220::ONNXImporter::parseOperatorSet DNN/ONNX: using non-standard ONNX opset[1]: domain='ai.onnx.ml' version=2
[DEBUG:0@11.689] global onnx_importer.cpp:723 cv::dnn::dnn4_v20221220::ONNXImporter::parseOperatorSet DNN/ONNX: using non-standard ONNX opset[2]: domain='ai.onnx.contrib' version=1
[ INFO:0@11.689] global onnx_importer.cpp:728 cv::dnn::dnn4_v20221220::ONNXImporter::parseOperatorSet DNN/ONNX: ONNX opset version = 15
[ INFO:0@11.690] global onnx_importer.cpp:743 cv::dnn::dnn4_v20221220::ONNXImporter::parseOperatorSet DNN/ONNX: unknown domain='ai.onnx.contrib' version=15. No dispatch map, you may need to register 'custom' layers.
[ INFO:0@11.690] global onnx_importer.cpp:743 cv::dnn::dnn4_v20221220::ONNXImporter::parseOperatorSet DNN/ONNX: unknown domain='ai.onnx.ml' version=15. No dispatch map, you may need to register 'custom' layers.
[DEBUG:0@11.700] global onnx_importer.cpp:842 cv::dnn::dnn4_v20221220::ONNXImporter::populateNet DNN/ONNX: graph simplified to 54 nodes
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[0 as 'scales__146'] shape=[ 4 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[1 as 'roi__133'] shape=[ 0 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[2 as 'new_shape__187'] shape=[ 4 ] data_type=7
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[3 as 'Func/StatefulPartitionedCall/input/_9__12'] shape=[ 256 128 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[4 as 'Func/StatefulPartitionedCall/input/_8__33'] shape=[ 128 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[5 as 'Func/StatefulPartitionedCall/input/_7__32'] shape=[ 128 128 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[6 as 'Func/StatefulPartitionedCall/input/_6__30'] shape=[ 128 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[7 as 'Func/StatefulPartitionedCall/input/_5__26'] shape=[ 128 64 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[8 as 'Func/StatefulPartitionedCall/input/_4__6'] shape=[ 64 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[9 as 'Func/StatefulPartitionedCall/input/_42__22'] shape=[ 1 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[10 as 'Func/StatefulPartitionedCall/input/_41__17'] shape=[ 1 32 5 5 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[11 as 'Func/StatefulPartitionedCall/input/_40__11'] shape=[ 32 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[12 as 'Func/StatefulPartitionedCall/input/_3__42'] shape=[ 64 64 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[13 as 'Func/StatefulPartitionedCall/input/_39__27'] shape=[ 32 64 5 5 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[14 as 'Func/StatefulPartitionedCall/input/_38__31'] shape=[ 64 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[15 as 'Func/StatefulPartitionedCall/input/_37__29'] shape=[ 64 128 5 5 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[16 as 'Func/StatefulPartitionedCall/input/_36__25'] shape=[ 128 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[17 as 'Func/StatefulPartitionedCall/input/_35__21'] shape=[ 128 256 5 5 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[18 as 'Func/StatefulPartitionedCall/input/_34__16'] shape=[ 256 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[19 as 'Func/StatefulPartitionedCall/input/_33__10'] shape=[ 256 512 5 5 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[20 as 'Func/StatefulPartitionedCall/input/_32__47'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[21 as 'Func/StatefulPartitionedCall/input/_31__24'] shape=[ 512 512 5 5 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[22 as 'Func/StatefulPartitionedCall/input/_30__46'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[23 as 'Func/StatefulPartitionedCall/input/_2__19'] shape=[ 64 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[24 as 'Func/StatefulPartitionedCall/input/_29__9'] shape=[ 512 4096 1 1 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[25 as 'Func/StatefulPartitionedCall/input/_28__39'] shape=[ 4096 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[26 as 'Func/StatefulPartitionedCall/input/_27__37'] shape=[ 4096 512 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[27 as 'Func/StatefulPartitionedCall/input/_26__20'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[28 as 'Func/StatefulPartitionedCall/input/_25__15'] shape=[ 512 512 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[29 as 'Func/StatefulPartitionedCall/input/_24__35'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[30 as 'Func/StatefulPartitionedCall/input/_23__8'] shape=[ 512 512 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[31 as 'Func/StatefulPartitionedCall/input/_22__41'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[32 as 'Func/StatefulPartitionedCall/input/_21__38'] shape=[ 512 512 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[33 as 'Func/StatefulPartitionedCall/input/_20__36'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[34 as 'Func/StatefulPartitionedCall/input/_1__43'] shape=[ 64 3 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[35 as 'Func/StatefulPartitionedCall/input/_19__14'] shape=[ 512 512 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[36 as 'Func/StatefulPartitionedCall/input/_18__45'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[37 as 'Func/StatefulPartitionedCall/input/_17__23'] shape=[ 512 512 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[38 as 'Func/StatefulPartitionedCall/input/_16__44'] shape=[ 512 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[39 as 'Func/StatefulPartitionedCall/input/_15__28'] shape=[ 512 256 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[40 as 'Func/StatefulPartitionedCall/input/_14__40'] shape=[ 256 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[41 as 'Func/StatefulPartitionedCall/input/_13__18'] shape=[ 256 256 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[42 as 'Func/StatefulPartitionedCall/input/_12__7'] shape=[ 256 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[43 as 'Func/StatefulPartitionedCall/input/_11__34'] shape=[ 256 256 3 3 ] data_type=1
global onnx_importer.cpp:365 cv::dnn::dnn4_v20221220::dumpTensorProto DNN/ONNX: initializer[44 as 'Func/StatefulPartitionedCall/input/_10__13'] shape=[ 256 ] data_type=1
[DEBUG:0@11.770] global onnx_importer.cpp:867 cv::dnn::dnn4_v20221220::ONNXImporter::populateNet DNN/ONNX: input[0] dim[0] = <unk__188> (dynamic)
[DEBUG:0@11.770] global onnx_importer.cpp:882 cv::dnn::dnn4_v20221220::ONNXImporter::populateNet DNN/ONNX: input[0 as 'args_0:0'] shape=[ 0 224 224 3 ]
[DEBUG:0@11.773] global onnx_importer.cpp:340 cv::dnn::dnn4_v20221220::dumpValueInfoProto DNN/ONNX: output[0] dim[0] = <unk__189> (dynamic)
[DEBUG:0@11.773] global onnx_importer.cpp:349 cv::dnn::dnn4_v20221220::dumpValueInfoProto DNN/ONNX: output[0 as 'Identity:0'] shape=[ 0 224 224 1 ]
[ INFO:0@11.773] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Transpose]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv1a/BiasAdd__53) from domain='ai.onnx'
[ INFO:0@11.779] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv1a/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.785] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv1a/Relu) from domain='ai.onnx'
[ INFO:0@11.789] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv1b/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.789] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv1b/Relu) from domain='ai.onnx'
[ INFO:0@11.789] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [MaxPool]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/mpconv1/MaxPool) from domain='ai.onnx'
[ INFO:0@11.792] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv2a/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.792] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv2a/Relu) from domain='ai.onnx'
[ INFO:0@11.792] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv2b/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.792] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv2b/Relu) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [MaxPool]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/mpconv2/MaxPool) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv3a/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv3a/Relu) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv3b/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv3b/Relu) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv3c/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv3c/Relu) from domain='ai.onnx'
[ INFO:0@11.793] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [MaxPool]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/mpconv3/MaxPool) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv4a/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv4a/Relu) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv4b/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv4b/Relu) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv4c/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv4c/Relu) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [MaxPool]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/mpconv4/MaxPool) from domain='ai.onnx'
[ INFO:0@11.794] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv5a/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv5a/Relu) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv5b/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv5b/Relu) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv5c/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv5c/Relu) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [MaxPool]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/mpconv5/MaxPool) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv6/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.795] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/conv6/Relu) from domain='ai.onnx'
[ INFO:0@11.796] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Conv]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/deconv6/BiasAdd) from domain='ai.onnx'
[ INFO:0@11.796] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 1 inputs and 1 outputs: [Relu]:(onnx_node!StatefulPartitionedCall/StatefulPartitionedCall/model/deconv6/Relu) from domain='ai.onnx'
[ INFO:0@11.796] global onnx_importer.cpp:1006 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: processing node with 3 inputs and 1 outputs: [Resize]:(onnx_node!Resize__137) from domain='ai.onnx'
OpenCV(4.7.0-dev) Error: Assertion failed (interp_mode != ""tf_half_pixel_for_nn"") in cv::dnn::dnn4_v20221220::ONNXImporter::parseResize, file C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp, line 2772
[ERROR:0@11.802] global onnx_importer.cpp:1064 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 3 inputs and 1 outputs: [Resize]:(onnx_node!Resize__137) from domain='ai.onnx'
[ INFO:0@11.802] global onnx_importer.cpp:1068 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode     Input[0] = 'StatefulPartitionedCall/StatefulPartitionedCall/model/deconv6/Relu:0'
[ INFO:0@11.802] global onnx_importer.cpp:1068 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode     Input[1] = 'roi__133'
[ INFO:0@11.802] global onnx_importer.cpp:1068 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode     Input[2] = 'scales__146'
[ INFO:0@11.802] global onnx_importer.cpp:1072 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode     Output[0] = 'Resize__137:0'
OpenCV(4.7.0-dev) Error: Unspecified error (> Node [Resize@ai.onnx]:(onnx_node!Resize__137) parse error: OpenCV(4.7.0-dev) C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:2772: error: (-215:Assertion failed) interp_mode != ""tf_half_pixel_for_nn"" in function 'cv::dnn::dnn4_v20221220::ONNXImporter::parseResize'
> ) in cv::dnn::dnn4_v20221220::ONNXImporter::handleNode, file C:\\lib\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp, line 1083

```


### Steps to reproduce

All data can be downloaded
[TF2 model ](http://perso.univ-lemans.fr/~berger/Afsd56/cedn_bug/cedn_pb.zip)
[ONNX model](http://perso.univ-lemans.fr/~berger/Afsd56/cedn_bug/cedn_pb.zip)

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-06-01 09:51:41,feature,Build Java without ANT,"### Pull Request Readiness Checklist

Enables a path of building Java bindings without ANT

* Able to build OpenCV JAR and Docs without ANT
  ```
  --   Java:                          
  --     ant:                         NO
  --     JNI:                         /usr/lib/jvm/default-java/include /usr/lib/jvm/default-java/include/linux /usr/lib/jvm/default-java/include
  --     Java wrappers:               YES
  --     Java tests:                  NO
  ```
* Possible to build OpenCV JAR without ANT but tests still require ANT

**Merge with**: https://github.com/opencv/opencv_contrib/pull/3502

Notes:
- Use `OPENCV_JAVA_IGNORE_ANT=1` to force ""Java"" flow for building Java bindings
- Java tests still require Apache ANT
- JAR doesn't include `.java` source code files.


See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-24 11:34:13,feature,Moved barcode from opencv_contrib,"Merge with https://github.com/opencv/opencv_contrib/pull/3497

##### TODO
- [x] Documentation (bib)
- [x] Tutorial (references)
- [x] Sample app (refactored)
- [x] Java (test passes)
- [x] Python (test passes)
- [x] Build without DNN


```
allow_multiple_commits=1
force_builders=Custom
build_image:Docs=docs-js:18.04
build_image:Custom=javascript
buildworker:Custom=linux-1,linux-4
```"
opencv/opencv,2023-05-16 14:11:42,feature,"Exposing CV_MAKETYPE(depth, cn) and CV_8UC(n), CV_8SC(n) etc., macros to the Python binding for arbitrary channel number handling in cv2.cuda.GpuMat","### Describe the feature and motivation

It would be great to expose the following macros to the Python binding:
```C
#define CV_MAKETYPE(depth, cn)   (CV_MAT_DEPTH(depth) + (((cn)-1) << CV_CN_SHIFT))
#define CV_8UC(n)   CV_MAKETYPE(CV_8U,(n))
#define CV_8SC(n)   CV_MAKETYPE(CV_8S,(n))
#define CV_16UC(n)   CV_MAKETYPE(CV_16U,(n))
#define CV_16SC(n)   CV_MAKETYPE(CV_16S,(n))
#define CV_32SC(n)   CV_MAKETYPE(CV_32S,(n))
#define CV_32FC(n)   CV_MAKETYPE(CV_32F,(n))
#define CV_64FC(n)   CV_MAKETYPE(CV_64F,(n))
```
While they aren't of much use for the general Python interface (which uses NumPy arrays with `shape` and `dtype` attributes readily available), they can be useful for Cuda `GpuMat` handling. Consider the following code to initialize a `GpuMat` from Cuda memory from a CuPy array (it uses `createGpuMatFromCudaMemory` from #23371):
```python
import cv2
import cupy as cp


def cv_cuda_gpumat_from_cp_array(arr: cp.ndarray) -> cv2.cuda.GpuMat:
    assert len(arr.shape) in (2, 3), ""CuPy array must have 2 or 3 dimensions to be a valid GpuMat""
    type_map = {
        cp.dtype('uint8'): cv2.CV_8U,
        cp.dtype('int8'): cv2.CV_8S,
        cp.dtype('uint16'): cv2.CV_16U,
        cp.dtype('int16'): cv2.CV_16S,
        cp.dtype('int32'): cv2.CV_32S,
        cp.dtype('float32'): cv2.CV_32F,
        cp.dtype('float64'): cv2.CV_64F
    }
    depth = type_map.get(arr.dtype)
    assert depth is not None, ""Unsupported CuPy array dtype""
    channels = 1 if len(arr.shape) == 2 else arr.shape[2]
    # equivalent to unexposed opencv C++ macro CV_MAKETYPE(depth,channels):
    # (depth&7) + ((channels - 1) << 3)
    mat_type = depth + ((channels - 1) << 3)
    mat = cv2.cuda.createGpuMatFromCudaMemory(arr.__cuda_array_interface__['shape'][1::-1],
                                              mat_type,
                                              arr.__cuda_array_interface__['data'][0])
    return mat
```
The ` mat_type =...` line would be more readable with `CV_MAKETYPE` available, e.g.,
```python
mat_type = cv2.CV_MAKETYPE(depth, channels)
```

Thanks in advance!

### Additional context

_No response_"
opencv/opencv,2023-05-11 12:54:29,feature,"videoio/FFmpeg: increased packet read attempt limit, allow configuring it","resolves #9455
related #3225

* Use different counters for wrong packets recieved by demuxer and errors from decoder
* Allow modifying these counters via environment variables `OPENCV_FFMPEG_READ_ATTEMPTS`/`OPENCV_FFMPEG_DECODE_ATTEMPTS`
* Added logging when reading breaks at one of error limits

Notes:
* I've been able to reproduce original issue with a video file with 14 total streams (video + audio + subtitles), at some point in the video only packets from the last stream are being sent by the demuxer, thus exceeding our limit. For my specific video total number of packets from wrong stream was about 2700. I've chosen 4096 as default value.
* Default limit of decoding attempts is quite low, because I'm not sure in which cases it can be exceeded (network stream?). I tried to read 8k video from the disk, but it did not cause break at decode point."
opencv/opencv,2023-05-09 13:28:38,feature,Add AVIF support through libavif.,"This is to fix https://github.com/opencv/opencv/issues/19271
Extra: https://github.com/opencv/opencv_extra/pull/1069

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-05-09 07:54:38,feature,"Add int64, uint64, bool, uint data type.","Since we only have three bits for the data type, this PR wants to expand the number of bits of the data type to 4 bits.

At present, there are many aspects of this PR that have not been considered. Any suggestions are welcome.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-04-18 04:06:26,feature,Unable to call LMSolver in python.,"### Descripe the feature and motivation

I want to solve a Levenberg-Marquardt problem with LMSolver or CvLevMarq in OpenCV.
But I find I can't call LMSolver or CvLevMarq with Python.
Are these two interfaces not available in Python?

### Additional context

_No response_"
opencv/opencv,2023-04-07 11:44:34,feature,Meta's Segment Anything with dnn,"### Descripe the feature and motivation

A novel model with published trained weights https://github.com/facebookresearch/segment-anything.
- [x] Export model to ONNX. Need to export carefully. See [below](https://github.com/opencv/opencv/issues/23470#issuecomment-1506627997) for details.
- [x] Model can be imported with dnn. Requires a fix for Expand to support broadcast axis > 1.
- [x] Model can be inferred
- [ ] Compare accuracy with PyTorch
- [ ] Create a sample

### Additional context

_No response_"
opencv/opencv,2023-03-30 14:17:34,feature,Newton PNP Solver,"### Newton-PnP: Real-time Visual Navigation for Autonomous Toy-Drones
**Ibrahim Jubran, Fares Fares, Yuval Alfassi, Firas Ayoub, Dan Feldman**

Link for the article with information and proof of working:
https://arxiv.org/pdf/2203.02686.pdf
https://arxiv.org/abs/2203.02686

The Perspective-n-Point problem aims to estimate the relative pose between a calibrated monocular camera and a known 3D model, by aligning pairs of 2D captured image points to their corresponding 3D points in the model. We suggest an algorithm that runs on weak IoT devices in real-time but still provides provable theoretical guarantees for both running time and correctness. Existing solvers provide only one of these requirements. Our main motivation was to turn the popular DJI's Tello Drone (<90gr, <$100) into an autonomous drone that navigates in an indoor environment with no external human/laptop/sensor, by simply attaching a Raspberry PI Zero (<9gr, <$25) to it. This tiny micro-processor takes as input a real-time video from a tiny RGB camera, and runs our PnP solver on-board. Extensive experimental results, open source code, and a demonstration video are included.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-03-26 07:31:09,feature,request emplace_back() in class Mat defined in mat.hpp,"### Descripe the feature and motivation

C++11 introduce emplace_back into STL, which can  In-place Constructe that can improve performance. I am trying to working on it (add a similar one to `Mat` ) but I am new to this project and I dont think I can do it very well, so I issued this issue. If anyone want to work on this, I may help something.

### Additional context

_No response_"
opencv/opencv,2023-03-20 15:40:01,feature,Add  ScrollWheel in Cocoa ,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-03-16 08:52:16,feature,imshow速度太慢，如何能加快imshow,"### Descripe the feature and motivation

imshow速度太慢，如何能加快imshow

### Additional context

_No response_"
opencv/opencv,2023-02-22 13:02:45,feature,OpenCV cannot import ONNX model: Inconsistent shape for ConcatLayer in function 'cv::dnn::ConcatLayerImpl::getMemoryShapes',"### System Information

OpenCV = Python opencv-python-rolling-4.7.0.20230211
Operating System / Platform Windows 10 64 bit
Python =3.10.4

### Detailed description

I converted the MODNet-MobileNetV2 model from PaddleSeg https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.7/Matting to ONNX. OpenCV cannot load the model (I do not get any errors or warnings from Netron). Find the offending model here: https://drive.google.com/file/d/1lOGcYYHSxfaa3fTbhuPHixa6bH3hUg3S/view?usp=sharing
```
[ERROR:0@0.123] global onnx_importer.cpp:1055 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 2 inputs and 1 outputs: [Concat]:(onnx_node!p2o.Concat.12) from domain='ai.onnx'
Traceback (most recent call last):
  File ""d:\\Local\\devel\\Python\\OpenCV\\dnn_matting_modnet-mobilenetv2\\inference.py"", line 99, in <module>
    model = cv2.dnn.readNet(model_path)
cv2.error: OpenCV(4.7.0-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:1074: error: (-2:Unspecified error) in function 'cv::dnn::dnn4_v20221220::ONNXImporter::handleNode'
> Node [Concat@ai.onnx]:(onnx_node!p2o.Concat.12) parse error: OpenCV(4.7.0-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\layers\\concat_layer.cpp:109: error: (-201:Incorrect size of input array) Inconsistent shape for ConcatLayer in function 'cv::dnn::ConcatLayerImpl::getMemoryShapes'
```

### Steps to reproduce

Load model with the following code

``` Python
model = cv2.dnn.readNet(model_path)
```

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-02-18 16:33:26,feature,dnn(tflite): add 3rdparty flatbuffers with pre-generated schema,"relates #23161
https://github.com/google/flatbuffers/releases/tag/v23.1.21 (Apache 2.0)

TODO:

- [x] fix build issues (32-bit and static libraries)
- [x] fix tests
- [x] readme and licensing information

<cut/>

```
force_builders=Custom,Custom Win,Linux AVX2,Linux OpenCL,linux,windows,docs,Win32,linux32
build_image:Custom=ubuntu:16.04
build_shared:Custom=OFF
build_examples:Custom=OFF
build_shared:Custom Win=OFF
Xbuild_shared:Linux AVX2=OFF
```"
opencv/opencv,2023-02-11 08:24:24,feature,videoio: add support for Orbbec Femto Mega RGB-D camera,"### videoio: add support for Orbbec Femto Mega RGB-D camera
[ About Femto Mega](https://orbbec3d.com/index/Product/info.html?cate=38&id=11)

### New feature
Be able to open the depth and color stream of the Orbbec Femto Mega Camera

### Bug Fix
OBSensor：Fix the problem that takes too long to turn off the stream on Windows platform

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch

OS | Compiler | Camera | Result
-- | -- | -- | --
Windows11 | (VS2022)MSVC17.3 | Femto Mega | Pass
Ubuntu22.04 | GCC11.2 | Femto Mega | Pass


"
opencv/opencv,2023-02-06 14:00:05,feature,feat: named arguments handling in Python interface,"Named arguments handling back-port from [PR #19156](https://github.com/opencv/opencv/pull/19156) to 4.x branch.
Different arguments and code generation logic is used for easier integration with PR #14590 .

Named arguments mimic normal arguments and reveal their nature only during function call inter-opt.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2023-01-31 03:22:10,feature,OpenCV 4.7.0 Huawei CANN support error: CANN graph check failed in function ‘compileCannGraph’ ,"### System Information

OpenCV version: 4.7.0
Operating System / Platform: Ubuntu 18.04
Compiler & compiler version: GCC 7.5.0

### Detailed description

I’m testing Huawei Ascend CANN hardware. 

The example code is as in [Huawei CANN Backend · opencv/opencv Wiki · GitHub](https://github.com/opencv/opencv/wiki/Huawei-CANN-Backend)

but the sample code result in error:

```
[ERROR:0@0.822] global net_cann.cpp:286 compileCannGraph CANN graph check failed, ret = 4294967295
terminate called after throwing an instance of ‘cv::Exception’
what(): OpenCV(4.7.0) /usr/huaweitest1/OpenCV_4.7/opencv-4.7.0/modules/dnn/src/net_cann.cpp:286: error: (-2:Unspecified error) CANN graph check failed in function ‘compileCannGraph’

[ERROR:0@1.427] global net_cann.cpp:286 compileCannGraph CANN graph check failed, ret = 4294967295
terminate called after throwing an instance of ‘cv::Exception’
what(): OpenCV(4.7.0) /usr/huaweitest1/OpenCV_4.7/opencv-4.7.0/modules/dnn/src/net_cann.cpp:286: error: (-2:Unspecified error) CANN graph check failed in function ‘compileCannGraph’

[ERROR:0@1.959] global op_cann.cpp:258 loadToDevice CANN check failed, ret = 100000
terminate called after throwing an instance of ‘cv::Exception’
what(): OpenCV(4.7.0) /usr/huaweitest1/OpenCV_4.7/opencv-4.7.0/modules/dnn/src/op_cann.cpp:258: error: (-2:Unspecified error) CANN check failed in function ‘loadToDevice’

Aborted (core dumped)
```

I checked OpenCV 4.7 and CANN installation, seems fine.  CANN's own sample code could run as well.



### Steps to reproduce

```
#include <iostream>
#include <vector>

#include ""opencv2/opencv.hpp""

void preprocess(const cv::Mat& src, cv::Mat& dst)
{
    src.convertTo(dst, CV_32FC3);

    cv::cvtColor(dst, dst, cv::COLOR_BGR2RGB);
    // center crop
    cv::resize(dst, dst, cv::Size(256, 256));
    cv::Rect roi(16, 16, 224, 224);
    dst = dst(roi);

    dst = cv::dnn::blobFromImage(dst, 1.0/255.0, cv::Size(), cv::Scalar(0.485, 0.456, 0.406));
    cv::divide(dst, cv::Scalar(0.229, 0.224, 0.225), dst);
}

void softmax(const cv::Mat& src, cv::Mat& dst, int axis=1)
{
    using namespace cv::dnn;

    LayerParams lp;
    Net netSoftmax;
    netSoftmax.addLayerToPrev(""softmaxLayer"", ""Softmax"", lp);
    netSoftmax.setPreferableBackend(DNN_BACKEND_OPENCV);

    netSoftmax.setInput(src);
    cv::Mat out = netSoftmax.forward();
    out.copyTo(dst);
}

int main(int argc, char** argv)
{
    using namespace cv;

    Mat image = imread(""/path/to/image""); // replace with the path to your image
    Mat input_blob;
    preprocess(image, input_blob);

    dnn::Net net = dnn::readNet(""/path/to/image_classification_ppresnet50_2022jan.onnx""); // replace with the path to the model
    net.setPreferableBackend(dnn::DNN_BACKEND_CANN);
    net.setPreferableTarget(dnn::DNN_TARGET_NPU);

    net.setInput(input_blob);
    Mat out = net.forward(""save_infer_model/scale_0.tmp_0"");

    Mat prob;
    softmax(out, prob, 1);

    double min_val, max_val;
    Point min_loc, max_loc;
    minMaxLoc(prob, &min_val, &max_val, &min_loc, &max_loc);

    std::cout << cv::format(""cls = %d, score = %.4f\\n"", max_loc.x, max_val);

    return 0;
}
```

The onnx model is as link  https://github.com/opencv/opencv_zoo/blob/master/models/image_classification_ppresnet/image_classification_ppresnet50_2022jan.onnx

### Issue submission checklist

- [x] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2023-01-24 15:35:46,feature,Cancel prints in roiSelector.cpp,"### Descripe the feature and motivation

Hello,

Is it possible to add a boolean argument to the cv2.ROISelector method to prevent the method to print the following messages:
Select a ROI and then press SPACE or ENTER button!
Cancel the selection process by pressing c button!

Thanks !

### Additional context

_No response_"
opencv/opencv,2023-01-20 14:57:58,feature,TFLite models importer,"### Pull Request Readiness Checklist

**Merge with:** https://github.com/opencv/opencv_extra/pull/1042

resolves https://github.com/opencv/opencv/issues/13918

#### How to build (tested on Ubuntu 20.04)
```
git clone -b v23.1.21 https://github.com/google/flatbuffers
cmake -S flatbuffers -B fbs_build
cmake --build fbs_build -j4
cmake --install fbs_build --prefix fbs_install
```
```
export flatbuffers_DIR=$HOME/fbs_install/lib/cmake/flatbuffers/
cmake \\
    -DCMAKE_BUILD_TYPE=Release \\
    -DBUILD_LIST=ts,dnn,python3 \\
    -DWITH_FLATBUFFERS=ON \\
    -S opencv -B opencv_build
```

#### How to build for OpenCV.js:

```
emcmake python3 ./opencv/platforms/js/build_js.py build_wasm \\
  --build_wasm \\
  --cmake_option=""-DWITH_FLATBUFFERS=ON"" \\
  --cmake_option=""-Dflatbuffers_DIR=$HOME/fbs_install/lib/cmake/flatbuffers/""
```

<cut/>

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake

```
force_builders=Linux OpenCL,Linux AVX2
buildworker:Linux OpenCL=linux-1
```"
opencv/opencv,2023-01-17 16:59:06,feature,"OpenCV cannot import ONNX model: Can't create layer ""..."" of type ""Exp""","### System Information

OpenCV => Python opencv-python 4.5.1
Operating System / Platform Windows 10 64 bit
Python =>3.7.11

### Detailed description

I have a Darknet YOLOv4 model that I can use with cv::dnn::readNetFromDarknet. I converted the model to an ONNX file using [this](https://github.com/Tianxiaomo/pytorch-YOLOv4) codebase. I load the ONNX file with cv::dnn::readNetFromONNX and ran my application, but got the following error.


```
[ERROR:0] global C:\\Ocv_Bri_Build\\opencv-4.5.1\\modules\\dnn\\src\\onnx\\onnx_importer.cpp (1878) cv::dnn::dnn4_v20201117::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 1 inputs and 1 outputs: [Exp]:(365)
Traceback (most recent call last):
  File ""run.py"", line 16, in <module>
    AiAS.run(proj_config)
RuntimeError: OpenCV(4.5.1) C:\\Ocv_Bri_Build\\opencv-4.5.1\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:1887: error: (-2:Unspecified error) in function 'cv::dnn::dnn4_v20201117::ONNXImporter::handleNode'
> Node [Exp]:(365) parse error: OpenCV(4.5.1) C:\\Ocv_Bri_Build\\opencv-4.5.1\\modules\\dnn\\src\\dnn.cpp:614: error: (-2:Unspecified error) Can't create layer ""365"" of type ""Exp"" in function 'cv::dnn::dnn4_v20201117::LayerData::getLayerInstance'
```

Issue submission checklist
- [ ] I report the issue, it's not a question
- [x] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [ ] I updated to the latest OpenCV version and the issue is still there
- [ ] There is reproducer code and related data files (videos, images, onnx, etc)
"
opencv/opencv,2023-01-12 02:46:41,feature,The Einsum Layer will be supported in the future,"### Descripe the feature and motivation

[ERROR:0@2.968] global onnx_importer.cpp:1054 cv::dnn::dnn4_v20221220::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 2 inputs and 1 outputs: [Einsum]:(onnx_node!Einsum_155) from domain='ai.onnx

### Additional context

_No response_"
opencv/opencv,2023-01-03 21:48:46,feature,Support GraphCutSeamFinder in stitching_detailed.py,"### Descripe the feature and motivation

with the release of [OpenCV 4.7](https://github.com/opencv/opencv/releases/tag/4.7.0) this [PR](https://github.com/opencv/opencv/pull/22329) becomes available so we can add

```
SEAM_FIND_CHOICES['gc_color'] = cv.detail_GraphCutSeamFinder('COST_COLOR')
SEAM_FIND_CHOICES['gc_colorgrad'] = cv.detail_GraphCutSeamFinder('COST_COLOR_GRAD')
```

to https://github.com/opencv/opencv/blob/4.x/samples/python/stitching_detailed.py

Previously it was [removed](https://github.com/opencv/opencv/commit/dbd65a3b01bbeca7405bf4c5c3971c85f5fa6d89) since python bindings were corrupt. Thanks to @chinery for fixing this.

### Additional context

_No response_"
opencv/opencv,2022-12-29 06:42:46,feature,A redundant logic in `distanceTransform`.,"## Version

OpenCV 4.7.0.

## Issue

https://github.com/opencv/opencv/blob/9208dcb07c015e1fda44e40bb07b43c700b4bf46/modules/imgproc/src/distransform.cpp#L729-L746

```C++
if( need_labels ) 
{ 
    ……
    maskSize = CV_DIST_MASK_5; 
} 
```

The `maskSize` is set to `CV_DIST_MASK_5` `if (need_labels)`. Meaning, the follow-up code

```C++
if( distType == CV_DIST_C || distType == CV_DIST_L1 ) 
    maskSize = !need_labels ? CV_DIST_MASK_3 : CV_DIST_MASK_5; 
else if( distType == CV_DIST_L2 && need_labels ) 
    maskSize = CV_DIST_MASK_5; 
```

does the same as

```C++
if((distType == CV_DIST_C || distType == CV_DIST_L1) && !need_labels) 
    maskSize = CV_DIST_MASK_3;
```

.

-----

- The redundant code should be removed.
- _The `maskSize` being set to `CV_DIST_MASK_5` `if (need_labels)`, no matter what `maskSize` is provided_, is undocumented behavior, and should be properly documented.
"
opencv/opencv,2022-12-15 07:04:26,feature,Replace all instances of CUDA texture references with texture objects,"See https://github.com/opencv/opencv_contrib/pull/3378 and https://github.com/opencv/opencv_contrib/issues/3390.  

CUDA texture references have now been completley removed in the latest SDK (CUDA 12.0).

If https://github.com/opencv/opencv_contrib/pull/3378 is merged this code block which is causing builds to fail against CUDA 12.0 (https://github.com/opencv/opencv_contrib/issues/3390) will become redundant.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-12-12 13:51:45,feature,VCPKG feature for Intel's Inference Engine,"### Descripe the feature and motivation

Hi!

I think actually there is no ""feature"" to build opencv with Intel's Inference Engine support (OpenVINO, I guess). I don't know if is it there any fast solution from compile opencv from source code with the -DWITH_OPENVINO=ON flag and that stuff.

So I'm requesting if it is possible to have a “feature” like the others for cuda support, dnn modules, contrib, etc. but for the Intel's Inference Engine,

Thank you so much!

### Additional context

_No response_"
opencv/opencv,2022-12-09 02:17:18,feature,videoio: add Orbbec Gemini 2 and Astra 2 camera support,"### Pull Request Readiness Checklist
- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] The feature is well documented and sample code can be built with the project CMake


### Test Result


| OS | Compiler | Camera | Result |
|-----|-----------|---------|--------|
|Windows11| (VS2022)MSVC17.3|Orbbec Gemini 2|Pass|
|Windows11| (VS2022)MSVC17.3|Orbbec Astra 2|Pass|
|Ubuntu22.04|GCC9.2|Orbbec Gemini 2|Pass|
|Ubuntu22.04|GCC9.2|Orbbec Astra 2|Pass|
"
opencv/opencv,2022-12-06 23:39:10,feature,core(logger): strip opencv's modules base path,"- Strip path from logger, keep file name only.
- Reverted `CV_Error()` changes."
opencv/opencv,2022-12-01 09:48:35,feature,dnn: support ONNX Slice with negative steps by adding and using cv::flipND,"Fixes https://github.com/opencv/opencv/issues/22794

Merge with https://github.com/opencv/opencv_extra/pull/1023.

Current workaround for negative steps is computing the forward indexing range for slice and flip at axis with negative step:

> x of shape [5, 10], x[5:0:-1, 10:1:-3] <=> np.flip(x[1:5:1, 2:10:3], aixs=(0, 1))

We can also extend `Range` to support backward indexing and steps like Python `list`, which needs more effort to do so I think.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-11-30 14:02:55,feature,Use QR code alignment markers,"merge with https://github.com/opencv/opencv_extra/pull/1024

Added detect QR code alignment marker (1 marker for 2-6 versions, 6 markers for 7-40 versions). Alignment marker uses to find the correct position of the fourth corner.

To check the correctness, a benchmark [was launched](https://github.com/opencv/opencv_benchmarks):
[qr.py.txt](https://github.com/opencv/opencv/files/10210080/qr.py.txt)
- +2% total decode (~+5% against detected QR codes)
- +0.4 pixels total accuracy for corner detect
Logging from benchmark:
[METRIC_CORNER_DIST_default.txt](https://github.com/opencv/opencv/files/10190260/METRIC_CORNER_DIST_default.txt)
[METRIC_CORNER_DIST_new.txt](https://github.com/opencv/opencv/files/10221133/METRIC_CORNER_DIST_new.txt)

No decode regression now.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-11-27 05:09:40,feature,Depth Encoding FFMPEG 16bit file support,"### Descripe the feature and motivation

Depth images typically come as type uint16. I've been looking online, and there is pretty lackluster support for depth video compression, which I think is an extremely important problem. For example, I am a part of a group collecting a large robot dataset, and we need to compress our depth data.

Some existing approaches include using:
1) FFV1, but opencv FFMPEG doesn't support 16bit datatypes as of now
2) Converting depth images to color, and then encoding normally: https://dev.intelrealsense.com/docs/depth-image-compression-by-colorization-for-intel-realsense-depth-cameras

It would be super helpful if cv2 could provide some built in functionality for this :)

### Additional context

_No response_"
opencv/opencv,2022-11-25 16:29:24,feature,Now there is no way to control GStreamer drop timeout when ip-camera drops,"### Descripe the feature and motivation

I'm using OpenCV with GStreamer, and sometimes my camera can disconnect. And when its happened, i just have program freezing for 20 s. And (maybe i didn't find) there is no way to change that timeout. Similar thing - is CAP_PROP_READ_TIMEOUT_MSEC for ffmpeg, but it didnt work for GStreamer.

### Additional context

_No response_"
opencv/opencv,2022-11-23 07:09:58,feature,Batched NMSBoxes,"### Descripe the feature and motivation

Batched NMS is especially useful for modern generic object detection postprocessing. Generic object detection has multiple classes, and it is important to perform NMS on each class to give correct results. However, the existing API for NMS in dnn module `NMSBoxes` does not support multiple classes.

We can use the same strategy from https://github.com/pytorch/vision/blob/main/torchvision/ops/boxes.py#L79-L95 to implement batched NMS:

1. get the maximum coordinate from boxes,
2. calculate the offset based on the maximum coordinate and class ids,
3. add offsets to boxes,
4. run `NMSBoxes` with boxes with offsets, scores and thresholds.

Although this is quite simple to implement for experienced developers, it would still be better if we put it in the dnn module as a new API (Let's call it `BatchedNMSBoxes`), and it can be done by calling a single API instead of wasting time implementing every time we need it.

### Additional context

_No response_"
opencv/opencv,2022-11-18 05:22:35,feature,DNN: make MatMul support 3D or 4D with broadcast,"**Merge with extra:** https://github.com/opencv/opencv_extra/pull/1018

This PR follows the https://github.com/opencv/opencv/pull/22775

The main purpose of this PR is making `MatMul` support the broadcast that the second input has less dimention than the first one.  And let the operation support SIMD and multi-thread. Beacuse it doesn't support 1D Mat, only support MatMul like 
```
2x3x4 mul 4x5 -> 2x3x5
2x3x4x5 mul 3x5x6 -> 2x3x4x6
```
- **2 const inputs:** create a virtual layer for the first input
- **1 const input with CPU (whether or not using broadcast):** use the SIMD and multi-thread flow which for `InnerProduct`
- **1 const input with CUDA:** broadcast inputs will fallback to CPU. Inputs with the same shape will use the cuda. 

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-11-17 10:00:44,feature,OpenCV cannot import ONNX model: (bool)layer in function 'cv::dnn::dnn4_v20220524::runLayer',"### System Information

OpenCV => Python opencv-python-rolling 4.6.0.20221022
Operating System / Platform Windows 10 64 bit
Python =>3.10.4

### Detailed description

I converted the DecoupledSeg from PaddleSeg to ONNX (the ONNX file opens fine in Netron):

https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/configs/emanet

This fails to load in OpenCV 4.6 pre-release:
```
[ERROR:0@0.667] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp (1050) cv::dnn::dnn4_v20220524::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 2 inputs and 1 outputs: [Tile]:(onnx_node!p2o.Tile.0) from domain='ai.onnx'
Traceback (most recent call last):
  File ""d:\\Local\\devel\\Python\\OpenCV\\dnn_segmentation_paddle_emanet_voc\\inference.py"", line 
123, in <module>
    model = cv2.dnn.readNet(model_path)
cv2.error: OpenCV(4.6.0-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:1069: error: (-2:Unspecified error) in function 'cv::dnn::dnn4_v20220524::ONNXImporter::handleNode'
> Node [Tile@ai.onnx]:(onnx_node!p2o.Tile.0) parse error: OpenCV(4.6.0-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:374: error: (-215:Assertion failed) (bool)layer in function 'cv::dnn::dnn4_v20220524::runLayer'
```

### Steps to reproduce

```
model = cv2.dnn.readNet(model_path)
```
Find the model here:
https://drive.google.com/file/d/1cSJ3hBIpnn51n4UBLAaYU26W9BqJbPJQ/view?usp=sharing

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-11-15 10:01:42,feature,core: support CV_Check*() macros with 'bool' parameters,"Added support for:
- `CV_Check{EQ,NE}(bool, bool, msg)`  (LT,GE,etc variants doesn't makes sense with `bool` and should not be used)
- `CV_CheckTrue(bool_expr_must_be_true, msg)`
- `CV_CheckFalse(bool_expr_must_be_false, msg)`

Also eliminates related build warning: http://pullrequest.opencv.org/buildbot/builders/precommit_linux32/builds/100058

```
force_builders=Linux32
build_image:Custom Win=msvs2019
```"
opencv/opencv,2022-11-15 05:29:14,feature,support Nanotrack in video module,"[teset data in opencv_extra](https://github.com/opencv/opencv_extra/pull/1016)

NanoTrack is an extremely lightweight and fast object-tracking model. 
The total size is **1.1 MB**.
And the FPS on M1 chip is **150**, on Raspberry Pi 4 is about **30**. (Float32 CPU only)

With this model, many users can run object tracking on the edge device.

The author of NanoTrack is @HonglinChu.
The original repo is https://github.com/HonglinChu/NanoTrack.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-11-10 17:22:25,feature,Add support for CAP_PROP_ORIENTATION_AUTO to AVFoundation backend,"This is an extension to #15499. I pulled some of the code up, so now it would be somewhat easier to add support for orientation metadata into the other backends as well.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-11-10 13:53:52,feature,"OpenCV cannot import ONNX model: Can't create layer ""..."" of type ""Tile""","### System Information

OpenCV => Python opencv-python-rolling 4.6.0.20221022
Operating System / Platform Windows 10 64 bit
Python =>3.10.4

### Detailed description

I converted the DANets from PaddleSeg to ONNX: 

https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/configs/danet 

This fails to load in OpenCV 4.6 pre-release:
```
[ERROR:0@0.494] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp (1050) cv::dnn::dnn4_v20220524::ONNXImporter::handleNode DNN/ONNX: ERROR during processing node with 2 inputs and 1 outputs: [Tile]:(onnx_node!p2o.Tile.0) from domain='ai.onnx'
Traceback (most recent call last):
  File ""d:\\Local\\devel\\Python\\OpenCV\\dnn_segmentation_paddle_danet_resnet50_os8_voc12aug\\inference.py"", line 123, in <module>
    model = cv2.dnn.readNet(model_path)
cv2.error: OpenCV(4.6.0-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:1069: error: (-2:Unspecified error) in function 'cv::dnn::dnn4_v20220524::ONNXImporter::handleNode'
> Node [Tile@ai.onnx]:(onnx_node!p2o.Tile.0) parse error: OpenCV(4.6.0-dev) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\net_impl.hpp:107: error: (-2:Unspecified error) Can't create layer ""onnx_node!p2o.Tile.0"" of type ""Tile"" in function 'cv::dnn::dnn4_v20220524::Net::Impl::getLayerInstance'
```

### Steps to reproduce

```
model = cv2.dnn.readNet(model_path)
```
Find one of the models here:
https://drive.google.com/file/d/1ajtfuQ9pCsirxxb6JPJJv9N29gayTLvk/view?usp=sharing

### Issue submission checklist

- [X] I report the issue, it's not a question
- [X] I checked the problem with documentation, FAQ, open issues, forum.opencv.org, Stack Overflow, etc and have not found any solution
- [X] I updated to the latest OpenCV version and the issue is still there
- [X] There is reproducer code and related data files (videos, images, onnx, etc)"
opencv/opencv,2022-11-10 04:48:01,feature,Create _InputArray/_OutputArray from fixed size array,"### Descripe the feature and motivation

I think we could add an extra constructor to `_InputArray`/`_OutputArray` so that it can convert directly from a C++ fixed size array, like this:

```c++
template<typename _Tp, std::size_t _Nm> _InputArray(const _Tp (&vec)[_Nm]);
```

Traditionally, we need to explicitly convert it to a combination of pointer + size, like:

```c++
auto arr = _InputArray(vec, std::size(vec));
```

It would be more convenient to have something like:

```c++
auto arr = _InputArray(vec);
```

### Additional context

_No response_"
opencv/opencv,2022-11-04 08:26:47,feature,cv.LUT is missing in openCv 4.6.0,"### Descripe the feature and motivation

Hi,
Thank-you for this awesome js library.  There was a use case which involved useing cv.LUT however it is not available as of now. This function is available in openCV c++ and python versions.  Requesting you to please add this function in opencv js library with a proper documentation which will help developers like me

Kind Regards,
Aditya

### Additional context

_No response_"
opencv/opencv,2022-11-03 08:45:01,feature,"stitching_detailed.py: It can not be spliced well , Request help","### Descripe the feature and motivation

stitching_detailed.py: It can not be spliced well , Request help

```
Direction transverse

1.jpg
4500 * 16000

2.jpg
4500 * 16000

3.jpg
4500 * 16000
```

I need to splice, but I can't complete the requirements very well. I need help
Pictures can be sent to email


### Additional context

_No response_"
opencv/opencv,2022-10-27 01:04:40,feature,Pass the AVDictionary generated from OPENCV_FFMPEG_CAPTURE_OPTIONS and OPENCV_FFMPEG_WRITER_OPTIONS to avformat_find_stream_info as well to gain access to more ffmpeg options,"### Describe the feature and motivation

While working on https://github.com/opencv/opencv/issues/22622 i realized that the environment variables ```OPENCV_FFMPEG_CAPTURE_OPTIONS``` and ```OPENCV_FFMPEG_WRITER_OPTIONS``` can only configure a very small subset of the ffmpeg options (the options listed in https://git.ffmpeg.org/gitweb/ffmpeg.git/blob/419d2524a8239a8f00b4c1702c91065b259615a2:/libavutil/opt.c#l465). That prevented me from passing all necessary options to fully specify the stream (https://github.com/opencv/opencv/issues/22622#issuecomment-1279731722).
Anyway i suggest passing the AVDictionary not just to ```avformat_open_input``` but to ```avformat_find_stream_info``` as well https://github.com/opencv/opencv/blob/a60496f9dfcb2070e1adf935055d1a5b531e3a96/modules/videoio/src/cap_ffmpeg_impl.hpp#L1147 and maybe even to ```avcodec_open2``` https://github.com/opencv/opencv/blob/a60496f9dfcb2070e1adf935055d1a5b531e3a96/modules/videoio/src/cap_ffmpeg_impl.hpp#L1266

### Additional context

_No response_"
opencv/opencv,2022-10-26 22:24:35,feature,print a debug message if the environment variables OPENCV_FFMPEG_CAPTURE_OPTIONS and OPENCV_FFMPEG_WRITER_OPTIONS are set,"### Descripe the feature and motivation

The environment variables ```OPENCV_FFMPEG_CAPTURE_OPTIONS``` and ```OPENCV_FFMPEG_WRITER_OPTIONS``` potentially have great impact on the internals of the ffmpeg video backend. but when they are used the log files don't show it. 
I'd like to print a debug message containing the value of those variables (in case they are set).

### Additional context

This issue https://github.com/opencv/opencv/issues/22622 contains examples of how those variables can be used."
opencv/opencv,2022-10-20 00:54:13,feature,DNN: let Quant and Dequant of ONNX_importer support the Constant input.,"Merge with extra: [opencv_extra/#1014](https://github.com/opencv/opencv_extra/pull/1014)

For zeropoint and scale can be 1-D tensor, only exists in `Quant`, `Deaunt` and weight of `QLinearConv`. We have supported 1-D tensor case in `QLinearConv`. For `Quant` and `Deaunt`, we can support the constant input case, which is very common situation in per-channel QDQ quantized format. Model examples can be found at PR of extra.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-10-09 05:32:28,feature,DNN: More stable DB text detection API,"**Merge with extra**: https://github.com/opencv/opencv_extra/pull/1011

The followings are the purpose of the PR:
1. Let `blobFromImage` support `Scalar` scale to feed the requirement of Standard Deviation value.
2. more stable DB text detection API, the old post-processing will get assert errors when `length == 0.;`. [The related code part](https://github.com/opencv/opencv/blob/4.x/modules/dnn/src/model.cpp#L1461).
3. Output the correct confidence or score instead of always being **1.**.
4. Support PP-OCR-v2 and PP-OCR-v3 DB models. The original inference code can be found [here](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/tools/infer/predict_det.py#L48-L51).

[Related regression test model](https://github.com/opencv/opencv_extra/pull/1011).

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-10-05 20:59:19,feature,add cvGetPropVisible_COCOA,"naive fix for the #22595 issue.

tested 'not visible' behaviour via `cv::waitKey(12345);` and minimising the window during that wait.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [X] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-09-23 16:15:05,feature,Add bindings to CUDA photo denoising functions,"Python bindings were missing from the CUDA photo denoising functions.  The function signatures have been updated and python test added to verify their existence.

Are these supposed to be in the main repository?

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-09-18 14:17:48,feature,DNN: supports Scatter and ScatterND from ONNX,"Fixes #22528 

Merge with: https://github.com/opencv/opencv_extra/pull/1009

Checklist:
- [x] Scatter impl
- [x] Scatter impl for negative indices
- [x] Test data for Scatter
- [x] ScatterND impl
- [x] ScatterND impl for negative indices
- [x] Test data for ScatterND
- [x] Disable the perf test to save CI server resources before merge


ONNX operator doc: https://github.com/onnx/onnx/blob/main/docs/Operators.md#Scatter

## Benchmark

Benchmark was done on M1 Macbook Air (16G mem). Time is in milliseconds.

*: Shapes of input, indices, updates are all [8, 256, 128, 100].

| Version | Operation | mean | median | min |
| - | - | - | - | - |
| intial | Scatter | 223.53 | 223.44 | 220.77 |
| initial | Scatter-add | 241.19 | 241.86 | 238.11 |
| + passing_mat | Scatter | 228.51 | 228.36 | 226.45 |
| + passing_mat | Scatter-add | 249.08 | 249.20 | 247.54 |
| current impl: + optm + pm | Scatter | 154.62 | 153.80 | 153.38 |
| current impl: + optm + pm | Scatter-add | 169.39 | 169.63 | 168.20 |

*: Shapes of input, indices, updates are [8, 256, 128, 100], [8, 256, 128, 100, 4], [8, 256, 128, 100] respectively.

| Version | Operation | mean | median | min |
| - | - | - | - | - |
| intial | ScatterND | 465.92 | 465.25 | 464.78 |
| initial | ScatterND-add | 475.01 | 473.86 | 473.13 |
| + passing_mat | ScatterND | 464.59 | 464.40 | 464.13 |
| + passing_mat | ScatterND-add | 473.80 | 470.24 | 465.80 |
| + pm + ng index | ScatterND | 511.17 | 508.44 | 507.73 |
| + pm + ng index | ScatterND-add | 518.91 | 518.56 | 510.94 |
| + optm1 + pm + ng index | ScatterND | 227.04 | 226.29 | 225.21 |
| + optm1 + pm + ng index | ScatterND-add | 218.58 | 218.37 | 217.26 |
| current impl: + optm2 + optm1 + pm + ng index | ScatterND | 132.87 | 132.94 | 132.09 |
| current impl: + optm2 + optm1 + pm + ng index | ScatterND-add | 135.17 | 135.05 | 133.93 |

## Potential issue

ScatterND should support duplicate indices if reduction is not none. Also ScatterND permits negative indices. See [here](https://github.com/onnx/onnx/issues/4548) for more details.

***Notice***: Current impl does not check for duplicate indices if reduction is none.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-09-14 15:48:30,feature,Color conversion: RGB => NV12 / NV21,"Add color conversion for RGB / RGBA / BGR / BGRA to NV12 / NV21.

##### System information (version)
- OpenCV => 4.x
- Operating System / Platform => all

##### Detailed description

There are conversions from NV12 / NV21 to RGB / RGBA / BGR / BGRA / GRAY but not the reverse.
This can be useful if we need to pass the an image to a video encoder that expect that.

https://docs.opencv.org/4.x/d8/d01/group__imgproc__color__conversions.html#ga4e0972be5de079fed4e3a10e24ef5ef0

##### Steps to reproduce

##### Issue submission checklist

 - [x] I report the issue, it's not a question
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
 - [x] I updated to the latest OpenCV version and the issue is still there
 - [ ] There is reproducer code and related data files: videos, images, onnx, etc"
opencv/opencv,2022-09-12 10:22:02,feature,Add H264 / H265 writter support for Android,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-09-10 18:31:16,feature,G-API Expose all core operations to python,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake


### Motivation
Python bindings are available since a long time, but only a few operations (`operation::on(...)` wrappers) were exposed.
There was a great plan to implement feature in python parser that could automatically detect `G-API` operation (via `GAPI_TYPED_KERNEL` macro or so) and expose it into python, but this functionality is more about giving an opportunity to user to implement python `kernels` for already existing in G-API operations. 

This PR is going to expose just `operation::on` wrappers to python in order to give user everything that is available from c++, because now, for developers who don't build from source and change the code only available a small amount of functionality.
Since a lot of developers use `opencv` from `pip` let's expose it once and forever.

Great example of G-API usage: https://github.com/xiong-jie-y/g_api_examples

TODO list:
- [x] Expose `core`
- [ ] Expose `imgproc`
- [ ] Expose `video` 
- [ ] Expose `stereo` 
- [ ] Other stuff (e.g constant initialization for `G-Type`'s & some compiler args) 


"
opencv/opencv,2022-08-31 11:13:37,feature,Add support for V4L2_PIX_FMT_Y16_BE,"OpenCV currently only has support for `V4L2_PIX_FMT_Y16` but not for the Big Endian version of this format: `V4L2_PIX_FMT_Y16_BE`.

Would it be possible to add it to [`cap_v4l.cpp`](https://github.com/opencv/opencv/blob/master/modules/videoio/src/cap_v4l.cpp)?

The handling should be a lot similar to the little endian version of the format.
But can openCV handle big endian data?
Or are there any functions to swap the endianess?
"
opencv/opencv,2022-08-29 02:28:46,feature,4-bit_palette_color,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-08-22 02:53:06,feature,DNN: support silu activation in darknet,"Related issue #22409

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-08-10 23:33:43,feature,add multiview calibration [GSOC 2022],"### Pull Request Readiness Checklist

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake

The usage tutorial is on Google Docs following this link: https://docs.google.com/document/d/1k6YpD0tpSVqnVnvU2nzE34K3cp_Po6mLWqXV06CUHwQ/edit?usp=sharing"
opencv/opencv,2022-08-08 02:33:53,feature,[GSoC] Add more universal intrinsic implementations for RVV.,"This is a patch of my GSoC project that the goal is to make the existing Universal Intrinsic compatible with scalable (variable-length) backends.

In #22179, we have already introduce a new framework of universal intrinsic for RISC-V Vector backend and few implementations and test cases are also added.

In this patch, we are going to add more universal intrinsic implementations for RVV.

Tested with QEMU for RVV backend in various VLEN:
```
qemu-riscv64 -cpu rv64,x-v=true,vlen=128 ./bin/opencv_test_core --gtest_filter=""hal*""
qemu-riscv64 -cpu rv64,x-v=true,vlen=512 ./bin/opencv_test_core --gtest_filter=""hal*""
```
Also tested for AVX and SSE backend on Linux.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-07-26 10:43:48,feature,DNN: Add qgemm and squeeze op13 supported on ONNXImporter,"[Squeeze node of ONNX](https://github.com/onnx/onnx/blob/main/docs/Operators.md#squeeze) has moved the axes from attribute to input.

[Test Data](https://github.com/opencv/opencv_extra/pull/989)

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-07-14 10:24:11,feature,VideoCapture FFMpeg RTSP low fps fixes,"When using `VideoCapture` with the FFMpeg backend to stream from an RTSP source at a low frame rate on a machine with a large number of CPU cores, `VideoCapture::read/grab` can fail due to the interrupt timer exceeding `timeout_after_ms`.  To try and fix this, this PR adds the `CAP_PROP_N_THREADS` which can be set on open to reduce the number of threads in this case.  This is related to https://github.com/opencv/opencv/issues/20002 but I cannot tell if it fixes the issue as I am unable to re-create it on a machine with reading from a file with only 20 CPU cores.

In addition to this `VideoCapture::open` can get stuck and therefore interupted on the call to `err = avformat_find_stream_info(ic, NULL);` when streaming from an RTSP source at a low frame rate regardless of the number of CPU cores.  The call to `open` still succeeds and the frame can be read but because the flag `interrupt_metadata.timeout` has been set in `open` the call to `grab/read` fails.  To fix this the `interrupt_metadata.timeout` flag is reset on entry to `grab/read`.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-07-13 01:13:03,feature,V4L2: Add multi-planar capture support,"Devices which only support multi-planar capture cannot be processed as
single-planar.

Add multi-planar support to v4l driver.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-07-06 12:10:54,feature,DNN: Reduce Layer (add dynamic batch and ReduceSum support) ,"Related ReduceSum issue #22195 
Related Dynamic Batch of Reduce Layer issue #22086
In this PR, we supported two input of `ReduceSum layer` and dynamic batch size in `Reduce Layer` of `ONNX_importer.cpp`.

[Regression test](https://github.com/opencv/opencv_extra/pull/987).

The [pervious PR](https://github.com/opencv/opencv/pull/22140) on Dynamic Batch of Reduce Layer has been closed.
### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-07-05 12:42:09,feature,videoio: add support for obsensor (Orbbec RGB-D Camera ),"# VideoCapture for OBSensor
OBSensor is Orbbec's new generation RGB-D camera brand, based on UVC protocol. The purpose is to let OpenCV read RGB and depth data from Orbbec RGB-D Camera via UVC protocol, rather than relying on the 3rdparty library (like OpenNI). This will greatly facilitate users to directly read, use and process the depth camera in OpenCV.

Supported Orbbec Device
* Orbbec Astra+: [detail](https://orbbec3d.com/index/Product/info.html?cate=38&id=9)
   * Depth Stream (640x480x30 fps CV_16UC1)
   * RGB Stream (640x480x30fps BGR)
* Orbbec Femto: [detail](https://orbbec3d.com/index/Product/info.html?cate=38&id=18)
   * Depth Stream (640x480x30 fps CV_16UC1)
   * RGB Stream (640x480x30fps BGR)
* Orbbec future device:
   * ...
 
Supported OS: Windows and Linux. (MacOX will be supported in near future.)
Supported HW: x86, x64, ARM.

Since the new Orbbec devices rely on UVC, while old devices still rely on OpenNI. This will cause OBSensor doesn't support some old Orbbec cameras, and the following is a list of specific unsupported devices:
- Orbbec Astra
- Orbbec Astra Pro

For these unspported devices, we still need the support of `OpenNI`, please refer to the [detailed tutorial of Using Orbbec Astra 3D cameras in OpenCV](https://docs.opencv.org/4.x/d4/d65/tutorial_orbbec_astra.html).

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] The feature is well documented and sample code can be built with the project CMake
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
"
opencv/opencv,2022-06-29 11:39:15,feature,CUDA: add support for Orin GPU,"### Pull Request Readiness Checklist

reference: https://forums.developer.nvidia.com/t/what-is-the-compute-capability-for-the-orion-update-your-page/211447

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-06-22 13:13:44,feature,Add zoom factor to interactive calibration tool,"Can be useful when the screen is smaller than the image from camera.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [X] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-06-20 18:04:43,feature,HOGDescriptor,"resolves https://github.com/opencv/opencv/issues/22129

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-06-14 22:48:58,feature,highgui Wayland xdg_shell,"-enable using -DWITH_WAYLAND=ON
-adapted from https://github.com/pfpacket/opencv-wayland
-using stable protocol
-overrides HAVE_QT if HAVE_WAYLAND and WITH_WAYLAND are set

Signed-off-by: Joel Winarske <joel.winarske@gmail.com>

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake

@pfpacket"
opencv/opencv,2022-06-08 11:02:03,feature,Save Frames option for interactive calibration tool,"The option to save all frames that contribute to final calibration result.
Useful for dataset collection and further offline tuning.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ ] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-06-03 06:25:01,feature,imgcodecs: jpeg: add IMWRITE_JPEG_SAMPLING_FACTOR parameter,"fix https://github.com/opencv/opencv/issues/22052

This merge request contains sample and test program.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [X] There is a reference to the original bug report and related work
- [X] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [X] The feature is well documented and sample code can be built with the project CMake

```
force_builders=Custom
build_image:Custom=centos:7
buildworker:Custom=linux-f1
```"
opencv/opencv,2022-05-23 02:18:52,feature,Consider video meta on GStreamer video capture,"Some GStreamer elements may produce buffers with very non
standard strides, offsets and/or even transport each plane
in different, non-contiguous pointers. This non-standard
layout is communicated via GstVideoMeta structures attached
to the buffers. Given this, when a GstVideoMeta is available,
one should parse the layout from it instead of generating
a generic one from the caps.

The GstVideoFrame utility does precisely this: if the buffer
contains a video meta, it uses that to fill the format and
memory layout. If there is no meta available, the layout is
inferred from the caps.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-05-19 14:01:53,feature,OpenCV fails to import ONNX model,"##### System information (version)
- OpenCV => 4.5.5
- Operating System / Platform => Windows 10 64 bit
- Compiler => Python 3.10.4
- Installed packages:
> numpy                 1.22.3
>opencv-contrib-python 4.5.5.64
>pip                   22.0.4
>setuptools            58.1.0

##### Detailed description
When running the demo.py for [opencv_zoo](https://github.com/opencv/opencv_zoo)/[models](https://github.com/opencv/opencv_zoo/tree/master/models)/image_classification_mobilenet/ the models fails to import. All the other models I tried to import did work well.

I wrote a Python script in a different venv to check the model with onnx and infer with the model with onnxruntime. The model imports and executes fine. This is not a problem with the models, but with the importer.

Error message:
```
[ERROR:0@0.223] global D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\o
nnx\\onnx_importer.cpp (909) cv::dnn::dnn4_v20211220::ONNXImporter::handleNode DN
N/ONNX: ERROR during processing node with 3 inputs and 1 outputs: [Clip]:(317) f
rom domain='ai.onnx'
Traceback (most recent call last):
  File ""D:\\Local\\devel\\Python\\OpenCV\\image_classification_mobilenet\\demo.py"", li
ne 41, in <module>
    'v2': MobileNetV2(modelPath='./image_classification_mobilenetv2_2022apr.onnx
', labelPath=args.label, backendId=args.backend, targetId=args.target),
  File ""D:\\Local\\devel\\Python\\OpenCV\\image_classification_mobilenet\\mobilenet_v2
.py"", line 11, in __init__
    self.model = cv.dnn.readNet(self.model_path)
cv2.error: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src
\\onnx\\onnx_importer.cpp:928: error: (-2:Unspecified error) in function 'cv::dnn:
:dnn4_v20211220::ONNXImporter::handleNode'
> Node [Clip@ai.onnx]:(317) parse error: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv
-python\\opencv\\modules\\dnn\\src\\onnx\\onnx_importer.cpp:1613: error: (-2:Unspecifi
ed error) in function 'void __cdecl cv::dnn::dnn4_v20211220::ONNXImporter::parse
Clip(class cv::dnn::dnn4_v20211220::LayerParams &,const class opencv_onnx::NodeP
roto &)'
> >  (expected: 'node_proto.input_size() == 1'), where
> >     'node_proto.input_size()' is 3
> > must be equal to
> >     '1' is 1
>
```

##### Steps to reproduce
- Reproducible: yes
- Enforceable: yes

Run the provided demo.py in [opencv_zoo](https://github.com/opencv/opencv_zoo)/[models](https://github.com/opencv/opencv_zoo/tree/master/models)/image_classification_mobilenet/

##### Issue submission checklist

 - [x] I report the issue, it's not a question
 - [x] I checked the problem with documentation, FAQ, open issues,
       forum.opencv.org, Stack Overflow, etc and have not found any solution
 - [x] I updated to the latest OpenCV version and the issue is still there
 - [x] There is reproducer code and related data files: videos, images, onnx, etc

"
opencv/opencv,2022-05-11 02:09:58,feature,support use memory buffer as input to read multi-page image,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-05-01 19:57:25,feature,added blob contours to blob detector,"


This PR adds an option to collect blob contours during blob detection (SimpleBlobDetector).

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [X] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-04-13 20:21:51,feature,Reimplementation of Element-wise layers with broadcasting support,"This version supports element-wise n-ary operations on k-dimensional tensors with broadcast-compatible shapes.

=== **Update by** @fengyuentau ===
ONNX operators that needs broadcasting: https://github.com/onnx/onnx/blob/main/docs/Broadcasting.md

Benchmarks on Apple M1:
Input tensor A of shape [8, 256, 128, 100], input tensor B of shape [8, 256, 128, 100]

| Operation | Eltwise layers (ms) | This PR (ms)    |
| --------- | ------------------- | --------------- |
| Add       | Not supported       | 5.60            |
| And       | Not supported       | -   |
| Div       | 8.30                | **5.55**        |
| Equal     | Not supported       | 5.58            |
| Greater   | Not supported       | 5.50            |
| Less      | Not supported       | 5.45            |
| Max       | 8.30                | **5.64** (nary) |
| Mean      | Not supported       | 5.44 (nary)     |
| Min       | 8.30                | **5.60** (nary) |
| Mul       | 8.59                | **5.69**        |
| Or        | Not supported       | -   |
| Pow       | Not supported       | 213.38          |
| Sub       | Not supported       | 5.70            |
| Sum       | 8.34                | **5.56** (nary) |
| Xor       | Not supported       | -   |

=== **End of updates** ===

Benchmarks: 
Sum of two tensors with shape=(8,256,128,100)
Eltwise layer takes 24ms
this implementation takes 49ms

Note: small_vector doesn't speed up anything right now, so it'll probably get removed.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [X] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-04-07 06:38:16,feature,"DNN: Add sign, shrink and reciprocal for onnx_impoter","Add `sign`, `shrink` and `reciprocal` for `onnx_importer.cpp`.
Implemented with OpenCV, CUDA, and OpenCL backend.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-04-01 08:13:25,feature,python binding for matches and inliers_mask attributes of cv2.detail_MatchesInfo class,"In respect to the issue  #21364, the pull request makes **matches** and **inliers_mask** attributes of the **cv2.detail_MatchesInfo** class accessible from python interface. By this way, developers could be able to make  changes on the computed matches.

### Pull Request Readiness Checklist

- [Yes] I agree to contribute to the project under Apache 2 License.
- [Yes] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [Yes] The PR is proposed to the proper branch
- [Yes] There is a reference to the original bug report and related work"
opencv/opencv,2022-03-19 17:16:59,feature,videoio: initial FFmpeg 5.0 support,"resolves #20147
closes #21766

<cut/>

_FFmpeg@n5.0_ (debug)
```.sh
./configure \\
  --enable-shared --disable-static --enable-pic --enable-gpl --enable-nonfree \\
  --enable-libxvid --enable-libx264 --enable-swresample \\
  --prefix=/home/user/ffmpeg/install \\
  --enable-debug=3 --disable-stripping --extra-cflags=""-gstabs+ -Og -g -fno-inline -fno-omit-frame-pointer"" --disable-optimizations 
```

TODO:
* [x] check HW acceleration support (va)
* [x] check and fix compatibility with older FFmpeg versions (up to 2.0 [releases](https://ffmpeg.org/download.html#releases))
* [ ] ~backport to OpenCV 3.4(?)~


```
build_contrib:Custom=OFF
build_contrib:Custom Win=OFF

build_shared:Custom=OFF
build_examples:Custom=OFF

build_image:Linux AVX2=ubuntu:20.04

Xbuild_image:Win64=msvs2019

force_builders=Custom,Custom Win,Linux AVX2
Xbuild_image:Custom=centos:7
Xbuild_image:Custom=ubuntu:20.04
build_image:Custom=gstreamer:16.04
buildworker:Custom=linux-1,linux-4,linux-6
test_opencl:Custom=ON

build_image:Custom Win=ffmpeg
Xbuild_image:Custom Win=ffmpeg-plugin
buildworker:Custom Win=windows-2
test_modules:Custom Win=videoio
test_opencl:Custom Win=ON
```"
opencv/opencv,2022-03-17 11:43:37,feature,add Gather implementation,"**Merge with extra:** https://github.com/opencv/opencv_extra/pull/1007
Should resolve #20439, resolve #19957

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [X] There is a reference to the original bug report and related work
- [X] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [X] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-03-09 13:53:55,feature,Add n-dimensional transpose to core,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [X] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [X] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [X] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-03-08 15:57:27,feature,TIFFDecoder does not support 12 bits (integer),"OpenCV 4.5

As of OpenCV 4.5, the TIFFDecoder does not support 12 bits (integer).
It looks like a deliberate choice since decoding 8 and 16 are supported with optimized icv conversion functions.

Would it be accepted to add a ""slow"" unpacking step for non-standard bit depths ?

There are at least two problems :
-it would be logical to automatically scale the resulting cv::Mat (here by 1<<(16-12)), but the caller would not be aware that such a conversion was done
-TIFF is so complex that it's hard to ensure that all and every packing scheme is supported"
opencv/opencv,2022-03-05 08:03:20,feature,G-API: VPP preprocessing GIEBackend integration,"Integration of VPP preprocessing into GIEBackend. This PR had done in term  of https://github.com/opencv/opencv/pull/21554 PR.
InferROI is supported only


### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake

### Build Configuration

```
force_builders=XCustom,Custom Win,Custom Mac
build_gapi_standalone:Linux x64=ade-0.1.1f
build_gapi_standalone:Win64=ade-0.1.1f
build_gapi_standalone:Mac=ade-0.1.1f
build_gapi_standalone:Linux x64 Debug=ade-0.1.1f

Xbuild_image:Custom=centos:7
Xbuildworker:Custom=linux-1
build_gapi_standalone:Custom=ade-0.1.1f

build_image:Custom=ubuntu-openvino-2021.3.0:20.04
Xbuild_image:Custom Win=openvino-2021.2.0
build_image:Custom Mac=openvino-2021.2.0

test_modules:Custom=gapi,python2,python3,java
test_modules:Custom Win=gapi,python2,python3,java
test_modules:Custom Mac=gapi,python2,python3,java

buildworker:Custom=linux-1
test_opencl:Custom=OFF
test_bigdata:Custom=1
test_filter:Custom=*

build_image:Custom Win=gapi-onevpl-2021.6.0
buildworker:Custom Win=windows-3
build_contrib:Custom Win=OFF
```"
opencv/opencv,2022-03-01 13:51:37,feature,G-API: Added reshape() functionality to CPU backend,"### Summary

* Added reshape functionality to CPU backend
* Fixed fluid heterogeneous reshape

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake

### Build configuration

```
force_builders=Custom,Custom Win,Custom Mac
build_gapi_standalone:Linux x64=ade-0.1.1f
build_gapi_standalone:Win64=ade-0.1.1f
build_gapi_standalone:Mac=ade-0.1.1f
build_gapi_standalone:Linux x64 Debug=ade-0.1.1f

Xbuild_image:Custom=centos:7
Xbuildworker:Custom=linux-1
build_gapi_standalone:Custom=ade-0.1.1f

build_image:Custom=ubuntu-openvino-2021.4.1:20.04
build_image:Custom Win=openvino-2021.4.1
build_image:Custom Mac=openvino-2021.4.1

test_modules:Custom=gapi,python2,python3,java
test_modules:Custom Win=gapi,python2,python3,java
test_modules:Custom Mac=gapi,python2,python3,java

buildworker:Custom=linux-1
# disabled due high memory usage: test_opencl:Custom=ON
test_opencl:Custom=OFF
test_bigdata:Custom=1
test_filter:Custom=*
```
"
opencv/opencv,2022-02-17 08:48:59,feature,Added NEON support in builds for Windows on ARM,"Since ~Visual Studio 16.11~ Visual Studio 2022 (17.0), the data types (e.g. `int32x4_t`) used by ARM NEON instructions are now defined, so the blocking of NEON support in builds for Windows on ARM has been resolved.

- `_ARM64_DISTINCT_NEON_TYPES` preprocessor
- [ARM64 vector intrinsics typedefs float32x4_t and int32x4_t to the same type - Visual Studio Feedback](https://developercommunity.visualstudio.com/t/arm64-vector-intrinsics-typedefs-float32x4-t-and-i/335464)
- #16027

TODO:
- [x] (**alalek**) Fix `BUILD_SAMPLES=ON` mode
    * `find_package(OpenCL)` founds OpenCL from CUDA SDK which can't work with ARM64 cross-compialtion
    * added `-DWITH_OPENCL=OFF -DCMAKE_DISABLE_FIND_PACKAGE_OpenCL=ON`
- [x] (**alalek**) Configure MSVS 2022 build image

<cut/>

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [ ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake

```
force_builders=Custom Win
Xbuild_image:Custom Win=msvs2019-arm64
build_image:Custom Win=msvs2022-arm64
buildworker:Custom Win=windows-1
build_contrib:Custom Win=OFF
Xbuild_examples:Custom Win=OFF
```"
opencv/opencv,2022-02-07 14:19:10,feature,Issues 21537,"The patch will try to use 15 bits / channel to generate 16 bits / channel panoramas.

<cut/>

Example of input files:

![1](https://user-images.githubusercontent.com/7062741/152804143-cbca982e-b28a-4be7-aa49-772e6690cc98.jpg)
![2](https://user-images.githubusercontent.com/7062741/152804145-8e44c619-c15b-46a0-bd76-04b5772aeadb.jpg)

Example of the panorama using the 4.2.0 (from standard LinuxMint packages):
![panorama-8-bit-ref](https://user-images.githubusercontent.com/7062741/152804453-7f3430c3-de63-4bfc-bbd3-fa0e9ec448d2.jpg)

Example of the panorama using the branch 4.x with the patch:
![panorama-8-bit](https://user-images.githubusercontent.com/7062741/152804540-68dcb990-4445-4af3-9e25-53e9e436b7b2.jpg)

Example of the panorama using the branch 4.x with the patch with the images converted to 16 bits / channel (CV_16UC3 and multiply by 256):
![panorama-16-bit](https://user-images.githubusercontent.com/7062741/152804691-dd61204a-df31-41e5-97d7-e687edcd896f.jpg)

Somehow the result seems to keep more details when the images was converted to 16 bits / channel, see the attached crops:

Original input image | Panorama using 4.2.0 (8 bits / channel) | Panorama using the patch and 8 bits / channel | Panorama using the patch and 16 bits / channel
--- | --- | --- | ---
![1_zoom](https://user-images.githubusercontent.com/7062741/152804864-11b05a7a-5dbc-4cbb-a083-2c736b67bc97.jpg) |  ![panorama-8-bit-ref-zoom](https://user-images.githubusercontent.com/7062741/152804867-cf4517a4-9d65-43b7-af35-91ef15c3564d.jpg) |  ![panorama-8-bit-zoom](https://user-images.githubusercontent.com/7062741/152804869-0751cdc8-c268-4beb-8605-10c26ca78fd2.jpg) | ![panorama-16-bit-zoom](https://user-images.githubusercontent.com/7062741/152804871-94038df0-dc80-442a-bb63-f01ac7b1fdb1.jpg)


### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ x ] I agree to contribute to the project under Apache 2 License.
- [ x ] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [ x ] The PR is proposed to the proper branch
- [ x ] There is a reference to the original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-01-29 00:24:15,feature,cv::va_intel::convertFromVASurface always fails on AMD devices using mesa,"<!--
If you have a question rather than reporting a bug please go to https://forum.opencv.org where you get much faster responses.
If you need further assistance please read [How To Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute).

This is a template helping you to create an issue which can be processed as quickly as possible. This is the bug reporting section for the OpenCV library.
-->

##### System information (version)

- OpenCV => 4.5.5
- Operating System / Platform => Slackware-current

##### Detailed description

cv::va_intel::convertFromVASurface always fails on AMD devices using mesa

##### Steps to reproduce

I am trying to convert a VAAPI image from FFMPEG in an AVFrame to a UMat, so my code is like this:
```
bool MotionOpenCV::process_frame(const AVFrame *frame, bool video){
    //check if the incoming frame is VAAPI
    if (video && frame->format == AV_PIX_FMT_VAAPI && frame->hw_frames_ctx){
        AVHWFramesContext *hw_frames = (AVHWFramesContext *)frame->hw_frames_ctx->data;
        AVHWDeviceContext *device_ctx = hw_frames->device_ctx;
        AVVAAPIDeviceContext *hwctx;
        if (device_ctx->type != AV_HWDEVICE_TYPE_VAAPI){
            LERROR(""VAAPI frame does not have VAAPI device"");
            return false;
        }
        hwctx = static_cast<AVVAAPIDeviceContext*>(device_ctx->hwctx);
        cv::UMat tmp;
        const VASurfaceID surf = reinterpret_cast<uintptr_t const>(frame->data[3]);
        try {
            cv::va_intel::convertFromVASurface(hwctx->display, surf, cv::Size(frame->width, frame->height), tmp);
        } catch (cv::Exception &e){
            LWARN(""Error converting image from VA-API To OpenCV: "" + e.msg);
            return false;
        }
```

Digging into it, modules/core/src/va_intel.cpp calls `vaDeriveImage` which if using mesa, calls `vlVaDeriveImage`. but per the comment in mesa, that always fails on AMD devices unless your program name is ""vlc"", ""h264encode"", or ""hevcencode""

```
/* This function is used by some programs to test for hardware decoding, but on
    * AMD devices, the buffers default to interlaced, which causes this function to fail.
    * Some programs expect this function to fail, while others, assume this means
    * hardware acceleration is not available and give up without trying the fall-back
    * vaCreateImage + vaPutImage
    */
```

https://gitlab.freedesktop.org/mesa/mesa/-/blob/main/src/gallium/frontends/va/image.c#L213

The solution then, is modules/core/src/va_intel.cpp should have the vaCreateImage + vaPutImage fallback that mesa requires."
opencv/opencv,2022-01-26 11:32:44,feature,dnn: apply hint to ignore denormals processing,"reworks #17295 continues #21506
resolves #21046"
opencv/opencv,2022-01-24 10:48:13,feature,core: FP denormals support,"relates #21046

- support x86 SSE FTZ+DAZ flags

Info: https://en.wikipedia.org/wiki/Subnormal_number

```
force_builders=Custom
build_image:Custom=openmp:16.04
buildworker:Custom=linux-1

allow_multiple_commits=1
```"
opencv/opencv,2022-01-20 12:40:55,feature,feature: submodule or a class scope for exported classes,"All classes are registered in the scope that corresponds to C++ namespace or exported class.
Example:
`cv::ml::Boost` is exported as `cv.ml.Boost`
`cv::SimpleBlobDetector::Params` is exported as `cv.SimpleBlobDetector.Params`

For backward compatibility all classes are registered in the global module with their mangling name containing scope information. Example:
`cv::ml::Boost` has `cv.ml_Boost` alias to `cv.ml.Boost` type

Closes #14730  

Backport for 4.x is required to handle [GAPI aliases](https://github.com/opencv/opencv/blob/6ae8103022cdb3cd79f417945fd8332c28298b7b/modules/gapi/misc/python/package/gapi/__init__.py#L291) in the right way:

```python
cv.gapi.wip.draw.Rect = cv.gapi_wip_draw_Rect
cv.gapi.wip.draw.Text = cv.gapi_wip_draw_Text
cv.gapi.wip.draw.Circle = cv.gapi_wip_draw_Circle
cv.gapi.wip.draw.Line = cv.gapi_wip_draw_Line
cv.gapi.wip.draw.Mosaic = cv.gapi_wip_draw_Mosaic
cv.gapi.wip.draw.Image = cv.gapi_wip_draw_Image
cv.gapi.wip.draw.Poly = cv.gapi_wip_draw_Poly

cv.gapi.streaming.queue_capacity = cv.
```

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or another license that is incompatible with OpenCV
- [x] The PR is proposed to the proper branch
- [x] There is a reference to the original bug report and related work
- [x] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [x] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-01-15 02:39:22,feature,Reading BigTiff images,"**Merge with extra: https://github.com/opencv/opencv_extra/pull/952**
resolves #18717

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [ ] I agree to contribute to the project under Apache 2 License.
- [ ] To the best of my knowledge, the proposed patch is not based on a code under GPL or other license that is incompatible with OpenCV
- [ ] The PR is proposed to proper branch
- [ ] There is reference to original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake
"
opencv/opencv,2022-01-14 15:37:53,feature,Add general broadcasting layer,"Performance details(broadcasting 1x1 to 16x2048x2048 mat of CV_32FC1 ~260Mb):

OCL copyTo: for dims <= 3, there is `clEnqueueCopyBufferRect`, that runs in 1ms and can work on strided data, but higher dimensions are not supported.
OCL memcpy: 22ms

CPU copyTo: 36ms
CPU memcpy: 20ms

CUDA memcpy: 11ms

Tests: this doesn't enable any of the conformance tests, since the only two we could use - `add_bcast` and `sub_bcast` - use 1-d inputs and we convert them to 2d, inserting 1 in the wrong spot, rendering the shape layouts non-compatible. Other tests with broadcasting(and,or,xor, less, equal, greater, and such) require bool output.

### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [X] I agree to contribute to the project under Apache 2 License.
- [X] To the best of my knowledge, the proposed patch is not based on a code under GPL or other license that is incompatible with OpenCV
- [X] The PR is proposed to proper branch
- [ ] There is reference to original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake


```
force_builders=Custom,Custom Win
buildworker:Custom=linux-4,linux-6
build_image:Custom=ubuntu-cuda:18.04

build_image:Custom Win=openvino-2021.4.2
buildworker:Custom Win=windows-3
test_bigdata:Custom Win=1
test_filter:Custom Win=*
test_modules:Custom Win=dnn,gapi,python2,python3,java
test_opencl:Custom Win=ON
build_contrib:Custom Win=OFF

```"
opencv/opencv,2022-01-11 16:30:53,feature,Adapt remote inference to operate with NV12 blobs,"### Pull Request Readiness Checklist

See details at https://github.com/opencv/opencv/wiki/How_to_contribute#making-a-good-pull-request

- [x] I agree to contribute to the project under Apache 2 License.
- [x] To the best of my knowledge, the proposed patch is not based on a code under GPL or other license that is incompatible with OpenCV
- [x] The PR is proposed to proper branch
- [ ] There is reference to original bug report and related work
- [ ] There is accuracy test, performance test and test data in opencv_extra repository, if applicable
      Patch to opencv_extra has the same branch name.
- [ ] The feature is well documented and sample code can be built with the project CMake

```
force_builders=Custom,Custom Win,Custom Mac
build_gapi_standalone:Linux x64=ade-0.1.1f
build_gapi_standalone:Win64=ade-0.1.1f
build_gapi_standalone:Mac=ade-0.1.1f
build_gapi_standalone:Linux x64 Debug=ade-0.1.1f

Xbuild_image:Custom=centos:7
Xbuildworker:Custom=linux-1
build_gapi_standalone:Custom=ade-0.1.1f

build_image:Custom=ubuntu-openvino-2021.4.1:20.04
build_image:Custom Win=openvino-2021.4.1
build_image:Custom Mac=openvino-2021.4.1

test_modules:Custom=gapi,python2,python3,java
test_modules:Custom Win=gapi,python2,python3,java
test_modules:Custom Mac=gapi,python2,python3,java

buildworker:Custom=linux-1
# disabled due high memory usage: test_opencl:Custom=ON
test_opencl:Custom=OFF
test_bigdata:Custom=1
test_filter:Custom=*
```
"
